{"2023-02-28T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2302.14828v1","updated":"2023-02-28T18:23:17Z","published":"2023-02-28T18:23:17Z","title":"Automatic Scoring of Dream Reports' Emotional Content with Large\n  Language Models","summary":"  In the field of dream research, the study of dream content typically relies\non the analysis of verbal reports provided by dreamers upon awakening from\ntheir sleep. This task is classically performed through manual scoring provided\nby trained annotators, at a great time expense. While a consistent body of work\nsuggests that natural language processing (NLP) tools can support the automatic\nanalysis of dream reports, proposed methods lacked the ability to reason over a\nreport's full context and required extensive data pre-processing. Furthermore,\nin most cases, these methods were not validated against standard manual scoring\napproaches. In this work, we address these limitations by adopting large\nlanguage models (LLMs) to study and replicate the manual annotation of dream\nreports, using a mixture of off-the-shelf and bespoke approaches, with a focus\non references to reports' emotions. Our results show that the off-the-shelf\nmethod achieves a low performance probably in light of inherent linguistic\ndifferences between reports collected in different (groups of) individuals. On\nthe other hand, the proposed bespoke text classification method achieves a high\nperformance, which is robust against potential biases. Overall, these\nobservations indicate that our approach could find application in the analysis\nof large dream datasets and may favour reproducibility and comparability of\nresults across studies.\n","authors":["Lorenzo Bertolini","Valentina Elce","Adriana Michalak","Giulio Bernardi","Julie Weeds"],"pdf_url":"https://arxiv.org/pdf/2302.14828v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12746v2","updated":"2023-02-28T17:54:00Z","published":"2023-02-24T16:59:54Z","title":"Spanish Built Factual Freectianary (Spanish-BFF): the first AI-generated\n  free dictionary","summary":"  Dictionaries are one of the oldest and most used linguistic resources.\nBuilding them is a complex task that, to the best of our knowledge, has yet to\nbe explored with generative Large Language Models (LLMs). We introduce the\n\"Spanish Built Factual Freectianary\" (Spanish-BFF) as the first Spanish\nAI-generated dictionary. This first-of-its-kind free dictionary uses GPT-3. We\nalso define future steps we aim to follow to improve this initial commitment to\nthe field, such as more additional languages.\n","authors":["Miguel Ortega-Martín","Óscar García-Sierra","Alfonso Ardoiz","Juan Carlos Armenteros","Jorge Álvarez","Adrián Alonso"],"pdf_url":"https://arxiv.org/pdf/2302.12746v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14785v1","updated":"2023-02-28T17:39:43Z","published":"2023-02-28T17:39:43Z","title":"Joint Representations of Text and Knowledge Graphs for Retrieval and\n  Evaluation","summary":"  A key feature of neural models is that they can produce semantic vector\nrepresentations of objects (texts, images, speech, etc.) ensuring that similar\nobjects are close to each other in the vector space. While much work has\nfocused on learning representations for other modalities, there are no aligned\ncross-modal representations for text and knowledge base (KB) elements. One\nchallenge for learning such representations is the lack of parallel data, which\nwe use contrastive training on heuristics-based datasets and data augmentation\nto overcome, training embedding models on (KB graph, text) pairs. On WebNLG, a\ncleaner manually crafted dataset, we show that they learn aligned\nrepresentations suitable for retrieval. We then fine-tune on annotated data to\ncreate EREDAT (Ensembled Representations for Evaluation of DAta-to-Text), a\nsimilarity metric between English text and KB graphs. EREDAT outperforms or\nmatches state-of-the-art metrics in terms of correlation with human judgments\non WebNLG even though, unlike them, it does not require a reference text to\ncompare against.\n","authors":["Teven Le Scao","Claire Gardent"],"pdf_url":"https://arxiv.org/pdf/2302.14785v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.05131v3","updated":"2023-02-28T17:20:36Z","published":"2022-05-10T19:32:20Z","title":"UL2: Unifying Language Learning Paradigms","summary":"  Existing pre-trained models are generally geared towards a particular class\nof problems. To date, there seems to be still no consensus on what the right\narchitecture and pre-training setup should be. This paper presents a unified\nframework for pre-training models that are universally effective across\ndatasets and setups. We begin by disentangling architectural archetypes with\npre-training objectives -- two concepts that are commonly conflated. Next, we\npresent a generalized & unified perspective for self-supervision in NLP and\nshow how different pre-training objectives can be cast as one another and how\ninterpolating between different objectives can be effective. We then propose\nMixture-of-Denoisers (MoD), a pre-training objective that combines diverse\npre-training paradigms together. We furthermore introduce a notion of mode\nswitching, wherein downstream fine-tuning is associated with specific\npre-training schemes. We conduct extensive ablative experiments to compare\nmultiple pre-training objectives and find that our method pushes the\nPareto-frontier by outperforming T5 & GPT-like models across multiple diverse\nsetups. By scaling our model up to 20B parameters, we achieve SOTA performance\non 50 well-established supervised finetuning based NLP tasks. Our model also\nachieve strong results at in-context learning, outperforming 175B GPT-3 on\nzero-shot SuperGLUE and tripling the performance of T5-XXL on one-shot\nsummarization. On 0-shot MMLU, UL2 20B outperforms T0 and T5 models. UL2 20B\nalso works well with chain-of-thought prompting and reasoning, making it an\nappealing choice for research into reasoning at a small to medium scale of 20B\nparameters. Finally, we apply FLAN instruction tuning to the UL2 20B model,\nachieving MMLU and Big-Bench scores competitive to FLAN-PaLM 62B. We release\nFlax-based T5X checkpoints for the UL2 20B & Flan-UL2 20B.\n","authors":["Yi Tay","Mostafa Dehghani","Vinh Q. Tran","Xavier Garcia","Jason Wei","Xuezhi Wang","Hyung Won Chung","Siamak Shakeri","Dara Bahri","Tal Schuster","Huaixiu Steven Zheng","Denny Zhou","Neil Houlsby","Donald Metzler"],"pdf_url":"https://arxiv.org/pdf/2205.05131v3.pdf","comment":"Updated Q1 2023 with Flan-UL2 20B release! :)"},{"id":"http://arxiv.org/abs/2302.14727v1","updated":"2023-02-28T16:34:55Z","published":"2023-02-28T16:34:55Z","title":"Automatically Classifying Emotions based on Text: A Comparative\n  Exploration of Different Datasets","summary":"  Emotion Classification based on text is a task with many applications which\nhas received growing interest in recent years. This paper presents a\npreliminary study with the goal to help researchers and practitioners gain\ninsight into relatively new datasets as well as emotion classification in\ngeneral. We focus on three datasets that were recently presented in the related\nliterature, and we explore the performance of traditional as well as\nstate-of-the-art deep learning models in the presence of different\ncharacteristics in the data. We also explore the use of data augmentation in\norder to improve performance. Our experimental work shows that state-of-the-art\nmodels such as RoBERTa perform the best for all cases. We also provide\nobservations and discussion that highlight the complexity of emotion\nclassification in these datasets and test out the applicability of the models\nto actual social media posts we collected and labeled.\n","authors":["Anna Koufakou","Jairo Garciga","Adam Paul","Joseph Morelli","Christopher Frank"],"pdf_url":"https://arxiv.org/pdf/2302.14727v1.pdf","comment":"Accepted at IEEE International Conference on Tools with Artificial\n  Intelligence (ICTAI 2022)"},{"id":"http://arxiv.org/abs/2302.14719v1","updated":"2023-02-28T16:31:17Z","published":"2023-02-28T16:31:17Z","title":"Self-training through Classifier Disagreement for Cross-Domain Opinion\n  Target Extraction","summary":"  Opinion target extraction (OTE) or aspect extraction (AE) is a fundamental\ntask in opinion mining that aims to extract the targets (or aspects) on which\nopinions have been expressed. Recent work focus on cross-domain OTE, which is\ntypically encountered in real-world scenarios, where the testing and training\ndistributions differ. Most methods use domain adversarial neural networks that\naim to reduce the domain gap between the labelled source and unlabelled target\ndomains to improve target domain performance. However, this approach only\naligns feature distributions and does not account for class-wise feature\nalignment, leading to suboptimal results. Semi-supervised learning (SSL) has\nbeen explored as a solution, but is limited by the quality of pseudo-labels\ngenerated by the model. Inspired by the theoretical foundations in domain\nadaptation [2], we propose a new SSL approach that opts for selecting target\nsamples whose model output from a domain-specific teacher and student network\ndisagree on the unlabelled target data, in an effort to boost the target domain\nperformance. Extensive experiments on benchmark cross-domain OTE datasets show\nthat this approach is effective and performs consistently well in settings with\nlarge domain shifts.\n","authors":["Kai Sun","Richong Zhang","Samuel Mensah","Nikolaos Aletras","Yongyi Mao","Xudong Liu"],"pdf_url":"https://arxiv.org/pdf/2302.14719v1.pdf","comment":"Accepted at TheWebConf 2023"},{"id":"http://arxiv.org/abs/2302.14708v1","updated":"2023-02-28T16:19:24Z","published":"2023-02-28T16:19:24Z","title":"Is Japanese CCGBank empirically correct? A case study of passive and\n  causative constructions","summary":"  The Japanese CCGBank serves as training and evaluation data for developing\nJapanese CCG parsers. However, since it is automatically generated from the\nKyoto Corpus, a dependency treebank, its linguistic validity still needs to be\nsufficiently verified. In this paper, we focus on the analysis of\npassive/causative constructions in the Japanese CCGBank and show that, together\nwith the compositional semantics of ccg2lambda, a semantic parsing system, it\nyields empirically wrong predictions for the nested construction of passives\nand causatives.\n","authors":["Daisuke Bekki","Hitomi Yanaka"],"pdf_url":"https://arxiv.org/pdf/2302.14708v1.pdf","comment":"To appear in Proceedings of Treebanks and Linguistic Theories (TLT)\n  2023, the workshop in the Georgetown University Round Table on Linguistics\n  2023 (GURT2023)"},{"id":"http://arxiv.org/abs/2302.14691v1","updated":"2023-02-28T16:06:35Z","published":"2023-02-28T16:06:35Z","title":"In-Context Instruction Learning","summary":"  Instruction learning of Large Language Models (LLMs) has enabled zero-shot\ntask generalization. However, instruction learning has been predominantly\napproached as a fine-tuning problem, including instruction tuning and\nreinforcement learning from human feedback, where LLMs are multi-task\nfine-tuned on various tasks with instructions. In this paper, we present a\nsurprising finding that applying in-context learning to instruction learning,\nreferred to as In-Context Instruction Learning (ICIL), significantly improves\nthe zero-shot task generalization performance for both pretrained and\ninstruction-fine-tuned models. One of the core advantages of ICIL is that it\nuses a single fixed prompt to evaluate all tasks, which is a concatenation of\ncross-task demonstrations. In particular, we demonstrate that the most powerful\ninstruction-fine-tuned baseline (text-davinci-003) also benefits from ICIL by\n9.3%, indicating that the effect of ICIL is complementary to instruction-based\nfine-tuning.\n","authors":["Seonghyeon Ye","Hyeonbin Hwang","Sohee Yang","Hyeongu Yun","Yireun Kim","Minjoon Seo"],"pdf_url":"https://arxiv.org/pdf/2302.14691v1.pdf","comment":"Work In Progress"},{"id":"http://arxiv.org/abs/2302.14680v1","updated":"2023-02-28T15:45:20Z","published":"2023-02-28T15:45:20Z","title":"Which One Are You Referring To? Multimodal Object Identification in\n  Situated Dialogue","summary":"  The demand for multimodal dialogue systems has been rising in various\ndomains, emphasizing the importance of interpreting multimodal inputs from\nconversational and situational contexts. We explore three methods to tackle\nthis problem and evaluate them on the largest situated dialogue dataset, SIMMC\n2.1. Our best method, scene-dialogue alignment, improves the performance by\n~20% F1-score compared to the SIMMC 2.1 baselines. We provide analysis and\ndiscussion regarding the limitation of our methods and the potential directions\nfor future works. Our code is publicly available at\nhttps://github.com/holylovenia/multimodal-object-identification.\n","authors":["Holy Lovenia","Samuel Cahyawijaya","Pascale Fung"],"pdf_url":"https://arxiv.org/pdf/2302.14680v1.pdf","comment":"Accepted at EACL SRW 2023"},{"id":"http://arxiv.org/abs/2302.04023v2","updated":"2023-02-28T15:20:21Z","published":"2023-02-08T12:35:34Z","title":"A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on\n  Reasoning, Hallucination, and Interactivity","summary":"  This paper proposes a framework for quantitatively evaluating interactive\nLLMs such as ChatGPT using publicly available data sets. We carry out an\nextensive technical evaluation of ChatGPT using 23 data sets covering 8\ndifferent common NLP application tasks. We evaluate the multitask, multilingual\nand multi-modal aspects of ChatGPT based on these data sets and a newly\ndesigned multimodal dataset. We find that ChatGPT outperforms LLMs with\nzero-shot learning on most tasks and even outperforms fine-tuned models on some\ntasks. We find that it is better at understanding non-Latin script languages\nthan generating them. It is able to generate multimodal content from textual\nprompts, via an intermediate code generation step. Moreover, we find that\nChatGPT is 63.41% accurate on average in 10 different reasoning categories\nunder logical reasoning, non-textual reasoning, and commonsense reasoning,\nhence making it an unreliable reasoner. It is, for example, better at deductive\nthan inductive reasoning. ChatGPT suffers from hallucination problems like\nother LLMs and it generates more extrinsic hallucinations from its parametric\nmemory as it does not have access to an external knowledge base. Finally, the\ninteractive feature of ChatGPT enables human collaboration with the underlying\nLLM to improve its performance, i.e, 8% ROUGE-1 on summarization and 2% ChrF++\non machine translation, in a multi-turn \"prompt engineering\" fashion. We also\nrelease codebase for evaluation set extraction.\n","authors":["Yejin Bang","Samuel Cahyawijaya","Nayeon Lee","Wenliang Dai","Dan Su","Bryan Wilie","Holy Lovenia","Ziwei Ji","Tiezheng Yu","Willy Chung","Quyet V. Do","Yan Xu","Pascale Fung"],"pdf_url":"https://arxiv.org/pdf/2302.04023v2.pdf","comment":"52 pages"},{"id":"http://arxiv.org/abs/2302.14635v1","updated":"2023-02-28T15:14:15Z","published":"2023-02-28T15:14:15Z","title":"H-AES: Towards Automated Essay Scoring for Hindi","summary":"  The use of Natural Language Processing (NLP) for Automated Essay Scoring\n(AES) has been well explored in the English language, with benchmark models\nexhibiting performance comparable to human scorers. However, AES in Hindi and\nother low-resource languages remains unexplored. In this study, we reproduce\nand compare state-of-the-art methods for AES in the Hindi domain. We employ\nclassical feature-based Machine Learning (ML) and advanced end-to-end models,\nincluding LSTM Networks and Fine-Tuned Transformer Architecture, in our\napproach and derive results comparable to those in the English language domain.\nHindi being a low-resource language, lacks a dedicated essay-scoring corpus. We\ntrain and evaluate our models using translated English essays and empirically\nmeasure their performance on our own small-scale, real-world Hindi corpus. We\nfollow this up with an in-depth analysis discussing prompt-specific behavior of\ndifferent language models implemented.\n","authors":["Shubhankar Singh","Anirudh Pupneja","Shivaansh Mital","Cheril Shah","Manish Bawkar","Lakshman Prasad Gupta","Ajit Kumar","Yaman Kumar","Rushali Gupta","Rajiv Ratn Shah"],"pdf_url":"https://arxiv.org/pdf/2302.14635v1.pdf","comment":"9 pages, 3 Tables, To be published as a part of Proceedings of the\n  37th AAAI Conference on Artificial Intelligence"},{"id":"http://arxiv.org/abs/2302.14624v1","updated":"2023-02-28T15:05:33Z","published":"2023-02-28T15:05:33Z","title":"The 2022 NIST Language Recognition Evaluation","summary":"  In 2022, the U.S. National Institute of Standards and Technology (NIST)\nconducted the latest Language Recognition Evaluation (LRE) in an ongoing series\nadministered by NIST since 1996 to foster research in language recognition and\nto measure state-of-the-art technology. Similar to previous LREs, LRE22 focused\non conversational telephone speech (CTS) and broadcast narrowband speech (BNBS)\ndata. LRE22 also introduced new evaluation features, such as an emphasis on\nAfrican languages, including low resource languages, and a test set consisting\nof segments containing between 3s and 35s of speech randomly sampled and\nextracted from longer recordings. A total of 21 research organizations, forming\n16 teams, participated in this 3-month long evaluation and made a total of 65\nvalid system submissions to be evaluated. This paper presents an overview of\nLRE22 and an analysis of system performance over different evaluation\nconditions. The evaluation results suggest that Oromo and Tigrinya are easier\nto detect while Xhosa and Zulu are more challenging. A greater confusability is\nseen for some language pairs. When speech duration increased, system\nperformance significantly increased up to a certain duration, and then a\ndiminishing return on system performance is observed afterward.\n","authors":["Yooyoung Lee","Craig Greenberg","Eliot Godard","Asad A. Butt","Elliot Singer","Trang Nguyen","Lisa Mason","Douglas Reynolds"],"pdf_url":"https://arxiv.org/pdf/2302.14624v1.pdf","comment":"5 pages, 10 figures"},{"id":"http://arxiv.org/abs/2207.02098v3","updated":"2023-02-28T13:22:17Z","published":"2022-07-05T15:06:11Z","title":"Neural Networks and the Chomsky Hierarchy","summary":"  Reliable generalization lies at the heart of safe ML and AI. However,\nunderstanding when and how neural networks generalize remains one of the most\nimportant unsolved problems in the field. In this work, we conduct an extensive\nempirical study (20'910 models, 15 tasks) to investigate whether insights from\nthe theory of computation can predict the limits of neural network\ngeneralization in practice. We demonstrate that grouping tasks according to the\nChomsky hierarchy allows us to forecast whether certain architectures will be\nable to generalize to out-of-distribution inputs. This includes negative\nresults where even extensive amounts of data and training time never lead to\nany non-trivial generalization, despite models having sufficient capacity to\nfit the training data perfectly. Our results show that, for our subset of\ntasks, RNNs and Transformers fail to generalize on non-regular tasks, LSTMs can\nsolve regular and counter-language tasks, and only networks augmented with\nstructured memory (such as a stack or memory tape) can successfully generalize\non context-free and context-sensitive tasks.\n","authors":["Grégoire Delétang","Anian Ruoss","Jordi Grau-Moya","Tim Genewein","Li Kevin Wenliang","Elliot Catt","Chris Cundy","Marcus Hutter","Shane Legg","Joel Veness","Pedro A. Ortega"],"pdf_url":"https://arxiv.org/pdf/2207.02098v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14534v1","updated":"2023-02-28T12:44:10Z","published":"2023-02-28T12:44:10Z","title":"Spacerini: Plug-and-play Search Engines with Pyserini and Hugging Face","summary":"  We present Spacerini, a modular framework for seamless building and\ndeployment of interactive search applications, designed to facilitate the\nqualitative analysis of large scale research datasets. Spacerini integrates\nfeatures from both the Pyserini toolkit and the Hugging Face ecosystem to ease\nthe indexing text collections and deploy them as search engines for ad-hoc\nexploration and to make the retrieval of relevant data points quick and\nefficient. The user-friendly interface enables searching through massive\ndatasets in a no-code fashion, making Spacerini broadly accessible to anyone\nlooking to qualitatively audit their text collections. This is useful both to\nIR~researchers aiming to demonstrate the capabilities of their indexes in a\nsimple and interactive way, and to NLP~researchers looking to better understand\nand audit the failure modes of large language models. The framework is open\nsource and available on GitHub: https://github.com/castorini/hf-spacerini, and\nincludes utilities to load, pre-process, index, and deploy local and web search\napplications. A portfolio of applications created with Spacerini for a\nmultitude of use cases can be found by visiting https://hf.co/spacerini.\n","authors":["Christopher Akiki","Odunayo Ogundepo","Aleksandra Piktus","Xinyu Zhang","Akintunde Oladipo","Jimmy Lin","Martin Potthast"],"pdf_url":"https://arxiv.org/pdf/2302.14534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14523v1","updated":"2023-02-28T12:33:12Z","published":"2023-02-28T12:33:12Z","title":"Automatic Heteronym Resolution Pipeline Using RAD-TTS Aligners","summary":"  Grapheme-to-phoneme (G2P) transduction is part of the standard text-to-speech\n(TTS) pipeline. However, G2P conversion is difficult for languages that contain\nheteronyms -- words that have one spelling but can be pronounced in multiple\nways. G2P datasets with annotated heteronyms are limited in size and expensive\nto create, as human labeling remains the primary method for heteronym\ndisambiguation. We propose a RAD-TTS Aligner-based pipeline to automatically\ndisambiguate heteronyms in datasets that contain both audio with text\ntranscripts. The best pronunciation can be chosen by generating all possible\ncandidates for each heteronym and scoring them with an Aligner model. The\nresulting labels can be used to create training datasets for use in both\nmulti-stage and end-to-end G2P systems.\n","authors":["Jocelyn Huang","Evelina Bakhturina","Oktai Tatanov"],"pdf_url":"https://arxiv.org/pdf/2302.14523v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14520v1","updated":"2023-02-28T12:23:48Z","published":"2023-02-28T12:23:48Z","title":"Large Language Models Are State-of-the-Art Evaluators of Translation\n  Quality","summary":"  We describe GEMBA, a GPT-based metric for assessment of translation quality,\nwhich works both with a reference translation and without. In our evaluation,\nwe focus on zero-shot prompting, comparing four prompt variants in two modes,\nbased on the availability of the reference. We investigate seven versions of\nGPT models, including ChatGPT. We show that our method for translation quality\nassessment only works with GPT 3.5 and larger models. Comparing to results from\nWMT22's Metrics shared task, our method achieves state-of-the-art accuracy in\nboth modes when compared to MQM-based human labels. Our results are valid on\nthe system level for all three WMT22 Metrics shared task language pairs, namely\nEnglish into German, English into Russian, and Chinese into English. This\nprovides a first glimpse into the usefulness of pre-trained, generative large\nlanguage models for quality assessment of translations. We publicly release all\nour code and prompt templates used for the experiments described in this work,\nas well as all corresponding scoring results, to allow for external validation\nand reproducibility.\n","authors":["Tom Kocmi","Christian Federmann"],"pdf_url":"https://arxiv.org/pdf/2302.14520v1.pdf","comment":"10 pages, 8 tables, one figure"},{"id":"http://arxiv.org/abs/2210.12921v2","updated":"2023-02-28T11:56:22Z","published":"2022-10-24T02:18:03Z","title":"Investigating the effect of domain selection on automatic speech\n  recognition performance: a case study on Bangladeshi Bangla","summary":"  The performance of data-driven natural language processing systems is\ncontingent upon the quality of corpora. However, principal corpus design\ncriteria are often not identified and examined adequately, particularly in the\nspeech processing discipline. Speech corpora development requires additional\nattention with regard to clean/noisy, read/spontaneous, multi-talker speech,\naccents/dialects, etc. Domain selection is also a crucial decision point in\nspeech corpus development. In this study, we demonstrate the significance of\ndomain selection by assessing a state-of-the-art Bangla automatic speech\nrecognition (ASR) model on a novel multi-domain Bangladeshi Bangla ASR\nevaluation benchmark - BanSpeech, which contains 7.2 hours of speech and 9802\nutterances from 19 distinct domains. The ASR model has been trained with deep\nconvolutional neural network (CNN), layer normalization technique, and\nConnectionist Temporal Classification (CTC) loss criterion on SUBAK.KO, a\nmostly read speech corpus for the low-resource and morphologically rich\nlanguage Bangla. Experimental evaluation reveals the ASR model on SUBAK.KO\nfaces difficulty recognizing speech from domains with mostly spontaneous speech\nand has a high number of out-of-vocabulary (OOV) words. The same ASR model, on\nthe other hand, performs better in read speech domains and contains fewer OOV\nwords. In addition, we report the outcomes of our experiments with layer\nnormalization, input feature extraction, number of convolutional layers, etc.,\nand set a baseline on SUBAK.KO. The BanSpeech will be publicly available to\nmeet the need for a challenging evaluation benchmark for Bangla ASR.\n","authors":["Ahnaf Mozib Samin","M. Humayan Kobir","Md. Mushtaq Shahriyar Rafee","M. Firoz Ahmed","Mehedi Hasan","Partha Ghosh","Shafkat Kibria","M. Shahidur Rahman"],"pdf_url":"https://arxiv.org/pdf/2210.12921v2.pdf","comment":"To be submitted"},{"id":"http://arxiv.org/abs/2302.14502v1","updated":"2023-02-28T11:34:30Z","published":"2023-02-28T11:34:30Z","title":"A Survey on Long Text Modeling with Transformers","summary":"  Modeling long texts has been an essential technique in the field of natural\nlanguage processing (NLP). With the ever-growing number of long documents, it\nis important to develop effective modeling methods that can process and analyze\nsuch texts. However, long texts pose important research challenges for existing\ntext models, with more complex semantics and special characteristics. In this\npaper, we provide an overview of the recent advances on long texts modeling\nbased on Transformer models. Firstly, we introduce the formal definition of\nlong text modeling. Then, as the core content, we discuss how to process long\ninput to satisfy the length limitation and design improved Transformer\narchitectures to effectively extend the maximum context length. Following this,\nwe discuss how to adapt Transformer models to capture the special\ncharacteristics of long texts. Finally, we describe four typical applications\ninvolving long text modeling and conclude this paper with a discussion of\nfuture directions. Our survey intends to provide researchers with a synthesis\nand pointer to related work on long text modeling.\n","authors":["Zican Dong","Tianyi Tang","Lunyi Li","Wayne Xin Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.14502v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.05735v2","updated":"2023-02-28T11:26:32Z","published":"2023-02-11T16:04:38Z","title":"Divergence-Based Domain Transferability for Zero-Shot Classification","summary":"  Transferring learned patterns from pretrained neural language models has been\nshown to significantly improve effectiveness across a variety of language-based\ntasks, meanwhile further tuning on intermediate tasks has been demonstrated to\nprovide additional performance benefits, provided the intermediate task is\nsufficiently related to the target task. However, how to identify related tasks\nis an open problem, and brute-force searching effective task combinations is\nprohibitively expensive. Hence, the question arises, are we able to improve the\neffectiveness and efficiency of tasks with no training examples through\nselective fine-tuning? In this paper, we explore statistical measures that\napproximate the divergence between domain representations as a means to\nestimate whether tuning using one task pair will exhibit performance benefits\nover tuning another. This estimation can then be used to reduce the number of\ntask pairs that need to be tested by eliminating pairs that are unlikely to\nprovide benefits. Through experimentation over 58 tasks and over 6,600 task\npair combinations, we demonstrate that statistical measures can distinguish\neffective task pairs, and the resulting estimates can reduce end-to-end runtime\nby up to 40%.\n","authors":["Alexander Pugantsov","Richard McCreadie"],"pdf_url":"https://arxiv.org/pdf/2302.05735v2.pdf","comment":"Accepted at EACL 2023, Findings. Figure 1 caption corrected to\n  describe NDCG@K graph (Figure 1 caption was mistakenly describing Figure 2\n  before correction)"},{"id":"http://arxiv.org/abs/2302.14494v1","updated":"2023-02-28T11:21:24Z","published":"2023-02-28T11:21:24Z","title":"Text classification dataset and analysis for Uzbek language","summary":"  Text classification is an important task in Natural Language Processing\n(NLP), where the goal is to categorize text data into predefined classes. In\nthis study, we analyse the dataset creation steps and evaluation techniques of\nmulti-label news categorisation task as part of text classification. We first\npresent a newly obtained dataset for Uzbek text classification, which was\ncollected from 10 different news and press websites and covers 15 categories of\nnews, press and law texts. We also present a comprehensive evaluation of\ndifferent models, ranging from traditional bag-of-words models to deep learning\narchitectures, on this newly created dataset. Our experiments show that the\nRecurrent Neural Network (RNN) and Convolutional Neural Network (CNN) based\nmodels outperform the rule-based models. The best performance is achieved by\nthe BERTbek model, which is a transformer-based BERT model trained on the Uzbek\ncorpus. Our findings provide a good baseline for further research in Uzbek text\nclassification.\n","authors":["Elmurod Kuriyozov","Ulugbek Salaev","Sanatbek Matlatipov","Gayrat Matlatipov"],"pdf_url":"https://arxiv.org/pdf/2302.14494v1.pdf","comment":"Preprint of the paper accepted to The 10th Language & Technology\n  Conference: Human Language Technologies as a Challenge for Computer Science\n  and Linguistics. April 21-23, 2023, Poznan, Poland"},{"id":"http://arxiv.org/abs/2301.11596v2","updated":"2023-02-28T11:10:43Z","published":"2023-01-27T08:45:53Z","title":"ThoughtSource: A central hub for large language model reasoning data","summary":"  Large language models (LLMs) such as GPT-3 and ChatGPT have recently\ndemonstrated impressive results across a wide range of tasks. LLMs are still\nlimited, however, in that they frequently fail at complex reasoning, their\nreasoning processes are opaque, they are prone to 'hallucinate' facts, and\nthere are concerns about their underlying biases. Letting models verbalize\nreasoning steps as natural language, a technique known as chain-of-thought\nprompting, has recently been proposed as a way to address some of these issues.\nHere we present the first release of ThoughtSource, a meta-dataset and software\nlibrary for chain-of-thought (CoT) reasoning. The goal of ThoughtSource is to\nimprove future artificial intelligence systems by facilitating qualitative\nunderstanding of CoTs, enabling empirical evaluations, and providing training\ndata. This first release of ThoughtSource integrates six scientific/medical,\nthree general-domain and five math word question answering datasets.\n","authors":["Simon Ott","Konstantin Hebenstreit","Valentin Liévin","Christoffer Egeberg Hother","Milad Moradi","Maximilian Mayrhauser","Robert Praas","Ole Winther","Matthias Samwald"],"pdf_url":"https://arxiv.org/pdf/2301.11596v2.pdf","comment":"Revision adds information on further AI-generated data\n  ('ThoughtSource-100')"},{"id":"http://arxiv.org/abs/2203.07893v3","updated":"2023-02-28T10:50:17Z","published":"2022-03-15T13:40:22Z","title":"Gold Doesn't Always Glitter: Spectral Removal of Linear and Nonlinear\n  Guarded Attribute Information","summary":"  We describe a simple and effective method (Spectral Attribute removaL; SAL)\nto remove private or guarded information from neural representations. Our\nmethod uses matrix decomposition to project the input representations into\ndirections with reduced covariance with the guarded information rather than\nmaximal covariance as factorization methods normally use. We begin with linear\ninformation removal and proceed to generalize our algorithm to the case of\nnonlinear information removal using kernels. Our experiments demonstrate that\nour algorithm retains better main task performance after removing the guarded\ninformation compared to previous work. In addition, our experiments demonstrate\nthat we need a relatively small amount of guarded attribute data to remove\ninformation about these attributes, which lowers the exposure to sensitive data\nand is more suitable for low-resource scenarios. Code is available at\nhttps://github.com/jasonshaoshun/SAL.\n","authors":["Shun Shao","Yftah Ziser","Shay B. Cohen"],"pdf_url":"https://arxiv.org/pdf/2203.07893v3.pdf","comment":"Accepted to the Conference of the European Chapter of the Association\n  for Computational Linguistics (EACL), 2023; 12 pages"},{"id":"http://arxiv.org/abs/2302.13539v2","updated":"2023-02-28T10:45:04Z","published":"2023-02-27T06:32:45Z","title":"Finding Supporting Examples for In-Context Learning","summary":"  In-context learning is a new learning paradigm where a language model\nobserves a few examples and then straightly outputs the test input's\nprediction. Previous works have shown that in-context learning is sensitive to\nthe provided examples and randomly sampled examples show significantly unstable\nperformance. In this paper, we propose to find ``supporting examples'' for\nin-context learning: Given the training dataset, we need to select one\npermutation of a few examples, which are informative for the task's in-context\nlearning and lead to superior performance. Although in traditional\ngradient-based learning, e.g., fine-tuning, there are numerous methods to find\na ``coreset'' from the entire dataset, they are sub-optimal and not suitable\nfor this problem since in-context learning occurs in the language model's\ninference without gradients or parameter updates. Additionally, the strong\ndependence among in-context examples makes this problem an NP-hard\ncombinatorial optimization problem and enumerating all possible permutations is\ninfeasible. Hence we propose a two-stage method to tackle this challenge. First\nwe propose a novel metric to select informative examples based on the language\nmodel's feedback, with a progressive filtering strategy. And then we propose a\ndiversity-guided beam search method to refine and evaluate the selected\nexamples, iteratively. The experimental results show our method significantly\noutperforms a wide range of baselines, and further analyses show the\neffectiveness of our method and shed light on the properties of supporting\nexamples and in-context learning.\n","authors":["Xiaonan Li","Xipeng Qiu"],"pdf_url":"https://arxiv.org/pdf/2302.13539v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14413v1","updated":"2023-02-28T08:47:20Z","published":"2023-02-28T08:47:20Z","title":"SMoA: Sparse Mixture of Adapters to Mitigate Multiple Dataset Biases","summary":"  Recent studies reveal that various biases exist in different NLP tasks, and\nover-reliance on biases results in models' poor generalization ability and low\nadversarial robustness. To mitigate datasets biases, previous works propose\nlots of debiasing techniques to tackle specific biases, which perform well on\nrespective adversarial sets but fail to mitigate other biases. In this paper,\nwe propose a new debiasing method Sparse Mixture-of-Adapters (SMoA), which can\nmitigate multiple dataset biases effectively and efficiently. Experiments on\nNatural Language Inference and Paraphrase Identification tasks demonstrate that\nSMoA outperforms full-finetuning, adapter tuning baselines, and prior strong\ndebiasing methods. Further analysis indicates the interpretability of SMoA that\nsub-adapter can capture specific pattern from the training data and specialize\nto handle specific bias.\n","authors":["Yanchen Liu","Jing Yan","Yan Chen","Jing Liu","Hua Wu"],"pdf_url":"https://arxiv.org/pdf/2302.14413v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14406v1","updated":"2023-02-28T08:41:53Z","published":"2023-02-28T08:41:53Z","title":"Instruction Clarification Requests in Multimodal Collaborative Dialogue\n  Games: Tasks, and an Analysis of the CoDraw Dataset","summary":"  In visual instruction-following dialogue games, players can engage in repair\nmechanisms in face of an ambiguous or underspecified instruction that cannot be\nfully mapped to actions in the world. In this work, we annotate Instruction\nClarification Requests (iCRs) in CoDraw, an existing dataset of interactions in\na multimodal collaborative dialogue game. We show that it contains lexically\nand semantically diverse iCRs being produced self-motivatedly by players\ndeciding to clarify in order to solve the task successfully. With 8.8k iCRs\nfound in 9.9k dialogues, CoDraw-iCR (v1) is a large spontaneous iCR corpus,\nmaking it a valuable resource for data-driven research on clarification in\ndialogue. We then formalise and provide baseline models for two tasks:\nDetermining when to make an iCR and how to recognise them, in order to\ninvestigate to what extent these tasks are learnable from data.\n","authors":["Brielen Madureira","David Schlangen"],"pdf_url":"https://arxiv.org/pdf/2302.14406v1.pdf","comment":"Accepted to EACL 2023"},{"id":"http://arxiv.org/abs/2302.14401v1","updated":"2023-02-28T08:35:28Z","published":"2023-02-28T08:35:28Z","title":"GLM-Dialog: Noise-tolerant Pre-training for Knowledge-grounded Dialogue\n  Generation","summary":"  We present GLM-Dialog, a large-scale language model (LLM) with 10B parameters\ncapable of knowledge-grounded conversation in Chinese using a search engine to\naccess the Internet knowledge. GLM-Dialog offers a series of applicable\ntechniques for exploiting various external knowledge including both helpful and\nnoisy knowledge, enabling the creation of robust knowledge-grounded dialogue\nLLMs with limited proper datasets. To evaluate the GLM-Dialog more fairly, we\nalso propose a novel evaluation method to allow humans to converse with\nmultiple deployed bots simultaneously and compare their performance implicitly\ninstead of explicitly rating using multidimensional metrics.Comprehensive\nevaluations from automatic to human perspective demonstrate the advantages of\nGLM-Dialog comparing with existing open source Chinese dialogue models. We\nrelease both the model checkpoint and source code, and also deploy it as a\nWeChat application to interact with users. We offer our evaluation platform\nonline in an effort to prompt the development of open source models and\nreliable dialogue evaluation systems. The additional easy-to-use toolkit that\nconsists of short text entity linking, query generation, and helpful knowledge\nclassification is also released to enable diverse applications. All the source\ncode is available on Github.\n","authors":["Jing Zhang","Xiaokang Zhang","Daniel Zhang-Li","Jifan Yu","Zijun Yao","Zeyao Ma","Yiqi Xu","Haohua Wang","Xiaohan Zhang","Nianyi Lin","Sunrui Lu","Juanzi Li","Jie Tang"],"pdf_url":"https://arxiv.org/pdf/2302.14401v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13114v2","updated":"2023-02-28T08:31:33Z","published":"2023-02-25T16:33:53Z","title":"Sequential Query Encoding For Complex Query Answering on Knowledge\n  Graphs","summary":"  Complex Query Answering (CQA) is an important and fundamental task for\nknowledge graph (KG) reasoning. Query encoding (QE) is proposed as a fast and\nrobust solution to CQA. In the encoding process, most existing QE methods first\nparse the logical query into an executable computational direct-acyclic graph\n(DAG), then use neural networks to parameterize the operators, and finally,\nrecursively execute these neuralized operators. However, the\nparameterization-and-execution paradigm may be potentially over-complicated, as\nit can be structurally simplified by a single neural network encoder.\nMeanwhile, sequence encoders, like LSTM and Transformer, proved to be effective\nfor encoding semantic graphs in related tasks. Motivated by this, we propose\nsequential query encoding (SQE) as an alternative to encode queries for CQA.\nInstead of parameterizing and executing the computational graph, SQE first uses\na search-based algorithm to linearize the computational graph to a sequence of\ntokens and then uses a sequence encoder to compute its vector representation.\nThen this vector representation is used as a query embedding to retrieve\nanswers from the embedding space according to similarity scores. Despite its\nsimplicity, SQE demonstrates state-of-the-art neural query encoding performance\non FB15k, FB15k-237, and NELL on an extended benchmark including twenty-nine\ntypes of in-distribution queries. Further experiment shows that SQE also\ndemonstrates comparable knowledge inference capability on out-of-distribution\nqueries, whose query types are not observed during the training process.\n","authors":["Jiaxin Bai","Tianshi Zheng","Yangqiu Song"],"pdf_url":"https://arxiv.org/pdf/2302.13114v2.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2302.14389v1","updated":"2023-02-28T08:16:18Z","published":"2023-02-28T08:16:18Z","title":"Information-Restricted Neural Language Models Reveal Different Brain\n  Regions' Sensitivity to Semantics, Syntax and Context","summary":"  A fundamental question in neurolinguistics concerns the brain regions\ninvolved in syntactic and semantic processing during speech comprehension, both\nat the lexical (word processing) and supra-lexical levels (sentence and\ndiscourse processing). To what extent are these regions separated or\nintertwined? To address this question, we trained a lexical language model,\nGlove, and a supra-lexical language model, GPT-2, on a text corpus from which\nwe selectively removed either syntactic or semantic information. We then\nassessed to what extent these information-restricted models were able to\npredict the time-courses of fMRI signal of humans listening to naturalistic\ntext. We also manipulated the size of contextual information provided to GPT-2\nin order to determine the windows of integration of brain regions involved in\nsupra-lexical processing. Our analyses show that, while most brain regions\ninvolved in language are sensitive to both syntactic and semantic variables,\nthe relative magnitudes of these effects vary a lot across these regions.\nFurthermore, we found an asymmetry between the left and right hemispheres, with\nsemantic and syntactic processing being more dissociated in the left hemisphere\nthan in the right, and the left and right hemispheres showing respectively\ngreater sensitivity to short and long contexts. The use of\ninformation-restricted NLP models thus shed new light on the spatial\norganization of syntactic processing, semantic processing and compositionality.\n","authors":["Alexandre Pasquiou","Yair Lakretz","Bertrand Thirion","Christophe Pallier"],"pdf_url":"https://arxiv.org/pdf/2302.14389v1.pdf","comment":"19 pages, 8 figures, 10 pages of Appendix, 5 appendix figures"},{"id":"http://arxiv.org/abs/2302.14383v1","updated":"2023-02-28T08:11:56Z","published":"2023-02-28T08:11:56Z","title":"Linear Spaces of Meanings: the Compositional Language of VLMs","summary":"  We investigate compositional structures in vector data embeddings from\npre-trained vision-language models (VLMs). Traditionally, compositionality has\nbeen associated with algebraic operations on embeddings of words from a\npre-existing vocabulary. In contrast, we seek to approximate label\nrepresentations from a text encoder as combinations of a smaller set of vectors\nin the embedding space. These vectors can be seen as \"ideal words\" which can be\nused to generate new concepts in an efficient way. We present a theoretical\nframework for understanding linear compositionality, drawing connections with\nmathematical representation theory and previous definitions of disentanglement.\nWe provide theoretical and empirical evidence that ideal words provide good\ncompositional approximations of composite concepts and can be more effective\nthan token-based decompositions of the same concepts.\n","authors":["Matthew Trager","Pramuditha Perera","Luca Zancato","Alessandro Achille","Parminder Bhatia","Bing Xiang","Stefano Soatto"],"pdf_url":"https://arxiv.org/pdf/2302.14383v1.pdf","comment":"24 pages, 4 figures, 4 tables"},{"id":"http://arxiv.org/abs/2302.12578v2","updated":"2023-02-28T08:08:29Z","published":"2023-02-24T11:25:50Z","title":"Fairness in Language Models Beyond English: Gaps and Challenges","summary":"  With language models becoming increasingly ubiquitous, it has become\nessential to address their inequitable treatment of diverse demographic groups\nand factors. Most research on evaluating and mitigating fairness harms has been\nconcentrated on English, while multilingual models and non-English languages\nhave received comparatively little attention. This paper presents a survey of\nfairness in multilingual and non-English contexts, highlighting the\nshortcomings of current research and the difficulties faced by methods designed\nfor English. We contend that the multitude of diverse cultures and languages\nacross the world makes it infeasible to achieve comprehensive coverage in terms\nof constructing fairness datasets. Thus, the measurement and mitigation of\nbiases must evolve beyond the current dataset-driven practices that are\nnarrowly focused on specific dimensions and types of biases and, therefore,\nimpossible to scale across languages and cultures.\n","authors":["Krithika Ramesh","Sunayana Sitaram","Monojit Choudhury"],"pdf_url":"https://arxiv.org/pdf/2302.12578v2.pdf","comment":"Accepted to EACL 2023 (Findings)"},{"id":"http://arxiv.org/abs/2302.05138v2","updated":"2023-02-28T07:20:06Z","published":"2023-02-10T09:43:15Z","title":"Plan-then-Seam: Towards Efficient Table-to-Text Generation","summary":"  Table-to-text generation aims at automatically generating text to help people\nconveniently obtain salient information in tables. Recent works explicitly\ndecompose the generation process into content planning and surface generation\nstages, employing two autoregressive networks for them respectively. However,\nthey are computationally expensive due to the non-parallelizable nature of\nautoregressive decoding and the redundant parameters of two networks. In this\npaper, we propose the first totally non-autoregressive table-to-text model\n(Plan-then-Seam, PTS) that produces its outputs in parallel with one single\nnetwork. PTS firstly writes and calibrates one plan of the content to be\ngenerated with a novel rethinking pointer predictor, and then takes the plan as\nthe context for seaming to decode the description. These two steps share\nparameters and perform iteratively to capture token inter-dependency while\nkeeping parallel decoding. Experiments on two public benchmarks show that PTS\nachieves 3.0~5.6 times speedup for inference time, reducing 50% parameters,\nwhile maintaining as least comparable performance against strong two-stage\ntable-to-text competitors.\n","authors":["Liang Li","Ruiying Geng","Chengyang Fang","Bing Li","Can Ma","Binhua Li","Yongbin Li"],"pdf_url":"https://arxiv.org/pdf/2302.05138v2.pdf","comment":"Accepted to Findings of EACL 2023"},{"id":"http://arxiv.org/abs/2302.13939v2","updated":"2023-02-28T06:28:43Z","published":"2023-02-27T16:43:04Z","title":"SpikeGPT: Generative Pre-trained Language Model with Spiking Neural\n  Networks","summary":"  As the size of large language models continue to scale, so does the\ncomputational resources required to run it. Spiking neural networks (SNNs) have\nemerged as an energy-efficient approach to deep learning that leverage sparse\nand event-driven activations to reduce the computational overhead associated\nwith model inference. While they have become competitive with non-spiking\nmodels on many computer vision tasks, SNNs have also proven to be more\nchallenging to train. As a result, their performance lags behind modern deep\nlearning, and we are yet to see the effectiveness of SNNs in language\ngeneration. In this paper, inspired by the RWKV language model, we successfully\nimplement `SpikeGPT', a generative language model with pure binary,\nevent-driven spiking activation units. We train the proposed model on three\nmodel variants: 45M, 125M and 260M parameters. To the best of our knowledge,\nthis is 4x larger than any functional backprop-trained SNN to date. We achieve\nthis by modifying the transformer block to replace multi-head self attention to\nreduce quadratic computational complexity to linear with increasing sequence\nlength. Input tokens are instead streamed in sequentially to our attention\nmechanism (as with typical SNNs). Our preliminary experiments show that\nSpikeGPT remains competitive with non-spiking models on tested benchmarks,\nwhile maintaining 5x less energy consumption when processed on neuromorphic\nhardware that can leverage sparse, event-driven activations. Our code\nimplementation is available at https://github.com/ridgerchu/SpikeGPT.\n","authors":["Rui-Jie Zhu","Qihang Zhao","Jason K. Eshraghian"],"pdf_url":"https://arxiv.org/pdf/2302.13939v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2105.01306v2","updated":"2023-02-28T06:17:38Z","published":"2021-05-04T05:58:27Z","title":"Discourse Relation Embeddings: Representing the Relations between\n  Discourse Segments in Social Media","summary":"  Discourse relations are typically modeled as a discrete class that\ncharacterizes the relation between segments of text (e.g. causal explanations,\nexpansions). However, such predefined discrete classes limits the universe of\npotential relationships and their nuanced differences. Analogous to contextual\nword embeddings, we propose representing discourse relations as points in high\ndimensional continuous space. However, unlike words, discourse relations often\nhave no surface form (relations are between two segments, often with no word or\nphrase in that gap) which presents a challenge for existing embedding\ntechniques. We present a novel method for automatically creating discourse\nrelation embeddings (DiscRE), addressing the embedding challenge through a\nweakly supervised, multitask approach to learn diverse and nuanced relations\nbetween discourse segments in social media. Results show DiscRE can: (1) obtain\nthe best performance on Twitter discourse relation classification task (macro\nF1=0.76) (2) improve the state of the art in social media causality prediction\n(from F1=.79 to .81), (3) perform beyond modern sentence and contextual word\nembeddings at traditional discourse relation classification, and (4) capture\nnovel nuanced relations (e.g. relations semantically at the intersection of\ncausal explanations and counterfactuals).\n","authors":["Youngseo Son","Vasudha Varadarajan","H Andrew Schwartz"],"pdf_url":"https://arxiv.org/pdf/2105.01306v2.pdf","comment":"Published in EMNLP 2022 UM-IoS"},{"id":"http://arxiv.org/abs/2302.14337v1","updated":"2023-02-28T06:05:43Z","published":"2023-02-28T06:05:43Z","title":"UniFLG: Unified Facial Landmark Generator from Text or Speech","summary":"  Talking face generation has been extensively investigated owing to its wide\napplicability. The two primary frameworks used for talking face generation\ncomprise a text-driven framework, which generates synchronized speech and\ntalking faces from text, and a speech-driven framework, which generates talking\nfaces from speech. To integrate these frameworks, this paper proposes a unified\nfacial landmark generator (UniFLG). The proposed system exploits end-to-end\ntext-to-speech not only for synthesizing speech but also for extracting a\nseries of latent representations that are common to text and speech, and feeds\nit to a landmark decoder to generate facial landmarks. We demonstrate that our\nsystem achieves higher naturalness in both speech synthesis and facial landmark\ngeneration compared to the state-of-the-art text-driven method. We further\ndemonstrate that our system can generate facial landmarks from speech of\nspeakers without facial video data or even speech data.\n","authors":["Kentaro Mitsui","Yukiya Hono","Kei Sawada"],"pdf_url":"https://arxiv.org/pdf/2302.14337v1.pdf","comment":"5 pages, 2 figures, 3 tables"},{"id":"http://arxiv.org/abs/2302.14286v1","updated":"2023-02-28T03:38:26Z","published":"2023-02-28T03:38:26Z","title":"HugNLP: A Unified and Comprehensive Library for Natural Language\n  Processing","summary":"  In this paper, we introduce HugNLP, a unified and comprehensive library for\nnatural language processing (NLP) with the prevalent backend of HuggingFace\nTransformers, which is designed for NLP researchers to easily utilize\noff-the-shelf algorithms and develop novel methods with user-defined models and\ntasks in real-world scenarios. HugNLP consists of a hierarchical structure\nincluding models, processors and applications that unifies the learning process\nof pre-trained language models (PLMs) on different NLP tasks. Additionally, we\npresent some featured NLP applications to show the effectiveness of HugNLP,\nsuch as knowledge-enhanced PLMs, universal information extraction, low-resource\nmining, and code understanding and generation, etc. The source code will be\nreleased on GitHub (https://github.com/wjn1996/HugNLP).\n","authors":["Jianing Wang","Nuo Chen","Qiushi Sun","Wenkang Huang","Chengyu Wang","Ming Gao"],"pdf_url":"https://arxiv.org/pdf/2302.14286v1.pdf","comment":"8 Pages"},{"id":"http://arxiv.org/abs/2302.14261v1","updated":"2023-02-28T02:37:30Z","published":"2023-02-28T02:37:30Z","title":"Augmented Transformers with Adaptive n-grams Embedding for Multilingual\n  Scene Text Recognition","summary":"  While vision transformers have been highly successful in improving the\nperformance in image-based tasks, not much work has been reported on applying\ntransformers to multilingual scene text recognition due to the complexities in\nthe visual appearance of multilingual texts. To fill the gap, this paper\nproposes an augmented transformer architecture with n-grams embedding and\ncross-language rectification (TANGER). TANGER consists of a primary transformer\nwith single patch embeddings of visual images, and a supplementary transformer\nwith adaptive n-grams embeddings that aims to flexibly explore the potential\ncorrelations between neighbouring visual patches, which is essential for\nfeature extraction from multilingual scene texts. Cross-language rectification\nis achieved with a loss function that takes into account both language\nidentification and contextual coherence scoring. Extensive comparative studies\nare conducted on four widely used benchmark datasets as well as a new\nmultilingual scene text dataset containing Indonesian, English, and Chinese\ncollected from tourism scenes in Indonesia. Our experimental results\ndemonstrate that TANGER is considerably better compared to the\nstate-of-the-art, especially in handling complex multilingual scene texts.\n","authors":["Xueming Yan","Zhihang Fang","Yaochu Jin"],"pdf_url":"https://arxiv.org/pdf/2302.14261v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12921v2","updated":"2023-02-28T02:28:41Z","published":"2023-02-24T22:38:54Z","title":"Pre-Finetuning for Few-Shot Emotional Speech Recognition","summary":"  Speech models have long been known to overfit individual speakers for many\nclassification tasks. This leads to poor generalization in settings where the\nspeakers are out-of-domain or out-of-distribution, as is common in production\nenvironments. We view speaker adaptation as a few-shot learning problem and\npropose investigating transfer learning approaches inspired by recent success\nwith pre-trained models in natural language tasks. We propose pre-finetuning\nspeech models on difficult tasks to distill knowledge into few-shot downstream\nclassification objectives. We pre-finetune Wav2Vec2.0 on every permutation of\nfour multiclass emotional speech recognition corpora and evaluate our\npre-finetuned models through 33,600 few-shot fine-tuning trials on the\nEmotional Speech Dataset.\n","authors":["Maximillian Chen","Zhou Yu"],"pdf_url":"https://arxiv.org/pdf/2302.12921v2.pdf","comment":"5 pages, 4 figures. Code available at\n  https://github.com/maxlchen/Speech-PreFinetuning"},{"id":"http://arxiv.org/abs/2302.13814v2","updated":"2023-02-28T02:06:53Z","published":"2023-02-23T16:06:16Z","title":"An Independent Evaluation of ChatGPT on Mathematical Word Problems (MWP)","summary":"  We study the performance of a commercially available large language model\n(LLM) known as ChatGPT on math word problems (MWPs) from the dataset DRAW-1K.\nTo our knowledge, this is the first independent evaluation of ChatGPT. We found\nthat ChatGPT's performance changes dramatically based on the requirement to\nshow its work, failing 20% of the time when it provides work compared with 84%\nwhen it does not. Further several factors about MWPs relating to the number of\nunknowns and number of operations that lead to a higher probability of failure\nwhen compared with the prior, specifically noting (across all experiments) that\nthe probability of failure increases linearly with the number of addition and\nsubtraction operations. We also have released the dataset of ChatGPT's\nresponses to the MWPs to support further work on the characterization of LLM\nperformance and present baseline machine learning models to predict if ChatGPT\ncan correctly answer an MWP. We have released a dataset comprised of ChatGPT's\nresponses to support further research in this area.\n","authors":["Paulo Shakarian","Abhinav Koyyalamudi","Noel Ngu","Lakshmivihari Mareedu"],"pdf_url":"https://arxiv.org/pdf/2302.13814v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.12542v3","updated":"2023-02-28T02:04:00Z","published":"2022-05-25T07:31:43Z","title":"ER-Test: Evaluating Explanation Regularization Methods for Language\n  Models","summary":"  By explaining how humans would solve a given task, human rationales can\nprovide strong learning signal for neural language models (LMs). Explanation\nregularization (ER) aims to improve LM generalization by pushing the LM's\nmachine rationales (Which input tokens did the LM focus on?) to align with\nhuman rationales (Which input tokens would humans focus on?). Though prior\nworks primarily study ER via in-distribution (ID) evaluation,\nout-of-distribution (OOD) generalization is often more critical in real-world\nscenarios, yet ER's effect on OOD generalization has been underexplored. In\nthis paper, we introduce ER-Test, a framework for evaluating ER models' OOD\ngeneralization along three dimensions: unseen dataset tests, contrast set\ntests, and functional tests. Using ER-Test, we extensively analyze how ER\nmodels' OOD generalization varies with different ER design choices. Across two\ntasks and six datasets, ER-Test shows that ER has little impact on ID\nperformance but can yield large OOD performance gains. Also, we find that ER\ncan improve OOD performance even with limited rationale supervision. ER-Test's\nresults help demonstrate ER's utility and establish best practices for using ER\neffectively.\n","authors":["Brihi Joshi","Aaron Chan","Ziyi Liu","Shaoliang Nie","Maziar Sanjabi","Hamed Firooz","Xiang Ren"],"pdf_url":"https://arxiv.org/pdf/2205.12542v3.pdf","comment":"Findings of EMNLP 2022"},{"id":"http://arxiv.org/abs/2302.13007v2","updated":"2023-02-28T01:53:14Z","published":"2023-02-25T06:58:16Z","title":"ChatAug: Leveraging ChatGPT for Text Data Augmentation","summary":"  Text data augmentation is an effective strategy for overcoming the challenge\nof limited sample sizes in many natural language processing (NLP) tasks. This\nchallenge is especially prominent in the few-shot learning scenario, where the\ndata in the target domain is generally much scarcer and of lowered quality. A\nnatural and widely-used strategy to mitigate such challenges is to perform data\naugmentation on the training data to better capture the data invariance and\nincrease the sample size. However, current text data augmentation methods\neither can not ensure the correct labeling of the generated data (lacking\nfaithfulness) or can not ensure sufficient diversity in the generated data\n(lacking completeness), or both. Inspired by the recent success of large\nlanguage models, especially the development of ChatGPT, which demonstrated\nimproved language comprehension abilities, in this work, we propose a text data\naugmentation approach based on ChatGPT (named ChatAug). ChatGPT is trained on\ndata with unparalleled linguistic richness and employs a reinforcement training\nprocess with large-scale human feedback, which endows the model with affinity\nto the naturalness of human language. Our text data augmentation approach\nChatAug rephrases each sentence in the training samples into multiple\nconceptually similar but semantically different samples. The augmented samples\ncan then be used in downstream model training. Experiment results on few-shot\nlearning text classification tasks show the superior performance of the\nproposed ChatAug approach over state-of-the-art text data augmentation methods\nin terms of testing accuracy and distribution of the augmented samples.\n","authors":["Haixing Dai","Zhengliang Liu","Wenxiong Liao","Xiaoke Huang","Zihao Wu","Lin Zhao","Wei Liu","Ninghao Liu","Sheng Li","Dajiang Zhu","Hongmin Cai","Quanzheng Li","Dinggang Shen","Tianming Liu","Xiang Li"],"pdf_url":"https://arxiv.org/pdf/2302.13007v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14233v1","updated":"2023-02-28T01:32:32Z","published":"2023-02-28T01:32:32Z","title":"Goal Driven Discovery of Distributional Differences via Language\n  Descriptions","summary":"  Mining large corpora can generate useful discoveries but is time-consuming\nfor humans. We formulate a new task, D5, that automatically discovers\ndifferences between two large corpora in a goal-driven way. The task input is a\nproblem comprising a research goal \"$\\textit{comparing the side effects of drug\nA and drug B}$\" and a corpus pair (two large collections of patients'\nself-reported reactions after taking each drug). The output is a language\ndescription (discovery) of how these corpora differ (patients taking drug A\n\"$\\textit{mention feelings of paranoia}$\" more often). We build a D5 system,\nand to quantitatively measure its performance, we 1) contribute a meta-dataset,\nOpenD5, aggregating 675 open-ended problems ranging across business, social\nsciences, humanities, machine learning, and health, and 2) propose a set of\nunified evaluation metrics: validity, relevance, novelty, and significance.\nWith the dataset and the unified metrics, we confirm that language models can\nuse the goals to propose more relevant, novel, and significant candidate\ndiscoveries. Finally, our system produces discoveries previously unknown to the\nauthors on a wide range of applications in OpenD5, including temporal and\ndemographic differences in discussion topics, political stances and stereotypes\nin speech, insights in commercial reviews, and error patterns in NLP models.\n","authors":["Ruiqi Zhong","Peter Zhang","Steve Li","Jinwoo Ahn","Dan Klein","Jacob Steinhardt"],"pdf_url":"https://arxiv.org/pdf/2302.14233v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14229v1","updated":"2023-02-28T01:27:37Z","published":"2023-02-28T01:27:37Z","title":"Cross-Lingual Summarization via ChatGPT","summary":"  Given a document in a source language, cross-lingual summarization (CLS) aims\nto generate a summary in a different target language. Recently, the emergence\nof ChatGPT has attracted wide attention from the computational linguistics\ncommunity. However, it is not yet known the performance of ChatGPT on CLS. In\nthis report, we empirically use various prompts to guide ChatGPT to perform\nzero-shot CLS from different paradigms (i.e., end-to-end and pipeline), and\nprovide a preliminary evaluation on its generated summaries.We find that\nChatGPT originally prefers to produce lengthy summaries with more detailed\ninformation. But with the help of an interactive prompt, ChatGPT can balance\nbetween informativeness and conciseness, and significantly improve its CLS\nperformance. Experimental results on three widely-used CLS datasets show that\nChatGPT outperforms the advanced GPT 3.5 model (i.e., text-davinci-003). In\naddition, we provide qualitative case studies to show the superiority of\nChatGPT on CLS.\n","authors":["Jiaan Wang","Yunlong Liang","Fandong Meng","Zhixu Li","Jianfeng Qu","Jie Zhou"],"pdf_url":"https://arxiv.org/pdf/2302.14229v1.pdf","comment":"Technical Report, 8 pages"},{"id":"http://arxiv.org/abs/2302.11752v3","updated":"2023-02-28T01:25:52Z","published":"2023-02-23T02:38:39Z","title":"VLSP2022-EVJVQA Challenge: Multilingual Visual Question Answering","summary":"  Visual Question Answering (VQA) is a challenging task of natural language\nprocessing (NLP) and computer vision (CV), attracting significant attention\nfrom researchers. English is a resource-rich language that has witnessed\nvarious developments in datasets and models for visual question answering.\nVisual question answering in other languages also would be developed for\nresources and models. In addition, there is no multilingual dataset targeting\nthe visual content of a particular country with its own objects and cultural\ncharacteristics. To address the weakness, we provide the research community\nwith a benchmark dataset named EVJVQA, including 33,000+ pairs of\nquestion-answer over three languages: Vietnamese, English, and Japanese, on\napproximately 5,000 images taken from Vietnam for evaluating multilingual VQA\nsystems or models. EVJVQA is used as a benchmark dataset for the challenge of\nmultilingual visual question answering at the 9th Workshop on Vietnamese\nLanguage and Speech Processing (VLSP 2022). This task attracted 62 participant\nteams from various universities and organizations. In this article, we present\ndetails of the organization of the challenge, an overview of the methods\nemployed by shared-task participants, and the results. The highest performances\nare 0.4392 in F1-score and 0.4009 in BLUE on the private test set. The\nmultilingual QA systems proposed by the top 2 teams use ViT for the pre-trained\nvision model and mT5 for the pre-trained language model, a powerful pre-trained\nlanguage model based on the transformer architecture. EVJVQA is a challenging\ndataset that motivates NLP and CV researchers to further explore the\nmultilingual models or systems for visual question answering systems.\n","authors":["Ngan Luu-Thuy Nguyen","Nghia Hieu Nguyen","Duong T. D Vo","Khanh Quoc Tran","Kiet Van Nguyen"],"pdf_url":"https://arxiv.org/pdf/2302.11752v3.pdf","comment":"VLSP2022 EVJVQA challenge"},{"id":"http://arxiv.org/abs/2203.03539v2","updated":"2023-02-28T01:24:30Z","published":"2022-02-02T06:20:59Z","title":"Understanding The Robustness of Self-supervised Learning Through Topic\n  Modeling","summary":"  Self-supervised learning has significantly improved the performance of many\nNLP tasks. However, how can self-supervised learning discover useful\nrepresentations, and why is it better than traditional approaches such as\nprobabilistic models are still largely unknown. In this paper, we focus on the\ncontext of topic modeling and highlight a key advantage of self-supervised\nlearning - when applied to data generated by topic models, self-supervised\nlearning can be oblivious to the specific model, and hence is less susceptible\nto model misspecification. In particular, we prove that commonly used\nself-supervised objectives based on reconstruction or contrastive samples can\nboth recover useful posterior information for general topic models.\nEmpirically, we show that the same objectives can perform on par with posterior\ninference using the correct model, while outperforming posterior inference\nusing misspecified models.\n","authors":["Zeping Luo","Shiyou Wu","Cindy Weng","Mo Zhou","Rong Ge"],"pdf_url":"https://arxiv.org/pdf/2203.03539v2.pdf","comment":"Accepted at ICLR 2023. Camera ready version"},{"id":"http://arxiv.org/abs/2302.14225v1","updated":"2023-02-28T01:07:39Z","published":"2023-02-28T01:07:39Z","title":"Weighted Sampling for Masked Language Modeling","summary":"  Masked Language Modeling (MLM) is widely used to pretrain language models.\nThe standard random masking strategy in MLM causes the pre-trained language\nmodels (PLMs) to be biased toward high-frequency tokens. Representation\nlearning of rare tokens is poor and PLMs have limited performance on downstream\ntasks. To alleviate this frequency bias issue, we propose two simple and\neffective Weighted Sampling strategies for masking tokens based on the token\nfrequency and training loss. We apply these two strategies to BERT and obtain\nWeighted-Sampled BERT (WSBERT). Experiments on the Semantic Textual Similarity\nbenchmark (STS) show that WSBERT significantly improves sentence embeddings\nover BERT. Combining WSBERT with calibration methods and prompt learning\nfurther improves sentence embeddings. We also investigate fine-tuning WSBERT on\nthe GLUE benchmark and show that Weighted Sampling also improves the transfer\nlearning capability of the backbone PLM. We further analyze and provide\ninsights into how WSBERT improves token embeddings.\n","authors":["Linhan Zhang","Qian Chen","Wen Wang","Chong Deng","Xin Cao","Kongzhang Hao","Yuxin Jiang","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2302.14225v1.pdf","comment":"6 pages, 2 figures"},{"id":"http://arxiv.org/abs/2110.06651v3","updated":"2023-02-28T00:54:45Z","published":"2021-10-13T11:29:17Z","title":"MDERank: A Masked Document Embedding Rank Approach for Unsupervised\n  Keyphrase Extraction","summary":"  Keyphrase extraction (KPE) automatically extracts phrases in a document that\nprovide a concise summary of the core content, which benefits downstream\ninformation retrieval and NLP tasks. Previous state-of-the-art (SOTA) methods\nselect candidate keyphrases based on the similarity between learned\nrepresentations of the candidates and the document. They suffer performance\ndegradation on long documents due to discrepancy between sequence lengths which\ncauses mismatch between representations of keyphrase candidates and the\ndocument. In this work, we propose a novel unsupervised embedding-based KPE\napproach, Masked Document Embedding Rank (MDERank), to address this problem by\nleveraging a mask strategy and ranking candidates by the similarity between\nembeddings of the source document and the masked document. We further develop a\nKPE-oriented BERT (KPEBERT) model by proposing a novel self-supervised\ncontrastive learning method, which is more compatible to MDERank than vanilla\nBERT. Comprehensive evaluations on six KPE benchmarks demonstrate that the\nproposed MDERank outperforms state-of-the-art unsupervised KPE approach by\naverage 1.80 $F1@15$ improvement. MDERank further benefits from KPEBERT and\noverall achieves average 3.53 $F1@15$ improvement over the SOTA SIFRank. Our\ncode is available at \\url{https://github.com/LinhanZ/mderank}.\n","authors":["Linhan Zhang","Qian Chen","Wen Wang","Chong Deng","Shiliang Zhang","Bing Li","Wei Wang","Xin Cao"],"pdf_url":"https://arxiv.org/pdf/2110.06651v3.pdf","comment":"13 pages, 5 figures"},{"id":"http://arxiv.org/abs/2302.14220v1","updated":"2023-02-28T00:50:19Z","published":"2023-02-28T00:50:19Z","title":"Are Character-level Translations Worth the Wait? An Extensive Comparison\n  of Character- and Subword-level Models for Machine Translation","summary":"  Pretrained large character-level language models have been recently\nrevitalized and shown to be competitive with subword models across a range of\nNLP tasks. However, there has not been any research showing their effectiveness\nin neural machine translation (NMT). This work performs an extensive comparison\nacross multiple languages and experimental conditions of state-of-the-art\ncharacter- and subword-level pre-trained models (ByT5 and mT5, respectively) on\nNMT, and shows that the former not only are effective in translation, but\nfrequently outperform subword models, particularly in cases where training data\nis limited. The only drawback of character models appears to be their\ninefficiency (at least 4 times slower to train and for inference). Further\nanalysis indicates that character models are capable of implicitly translating\non the word or subword level, thereby nullifying a major potential weakness of\noperating on the character level.\n","authors":["Lukas Edman","Antonio Toral","Gertjan van Noord"],"pdf_url":"https://arxiv.org/pdf/2302.14220v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.05032v3","updated":"2023-02-28T23:46:24Z","published":"2022-12-09T18:30:24Z","title":"Training-Free Structured Diffusion Guidance for Compositional\n  Text-to-Image Synthesis","summary":"  Large-scale diffusion models have achieved state-of-the-art results on\ntext-to-image synthesis (T2I) tasks. Despite their ability to generate\nhigh-quality yet creative images, we observe that attribution-binding and\ncompositional capabilities are still considered major challenging issues,\nespecially when involving multiple objects. In this work, we improve the\ncompositional skills of T2I models, specifically more accurate attribute\nbinding and better image compositions. To do this, we incorporate linguistic\nstructures with the diffusion guidance process based on the controllable\nproperties of manipulating cross-attention layers in diffusion-based T2I\nmodels. We observe that keys and values in cross-attention layers have strong\nsemantic meanings associated with object layouts and content. Therefore, we can\nbetter preserve the compositional semantics in the generated image by\nmanipulating the cross-attention representations based on linguistic insights.\nBuilt upon Stable Diffusion, a SOTA T2I model, our structured cross-attention\ndesign is efficient that requires no additional training samples. We achieve\nbetter compositional skills in qualitative and quantitative results, leading to\na 5-8% advantage in head-to-head user comparison studies. Lastly, we conduct an\nin-depth analysis to reveal potential causes of incorrect image compositions\nand justify the properties of cross-attention layers in the generation process.\n","authors":["Weixi Feng","Xuehai He","Tsu-Jui Fu","Varun Jampani","Arjun Akula","Pradyumna Narayana","Sugato Basu","Xin Eric Wang","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2212.05032v3.pdf","comment":"ICLR 2023 Camera Ready version"},{"id":"http://arxiv.org/abs/2303.00135v1","updated":"2023-02-28T23:40:41Z","published":"2023-02-28T23:40:41Z","title":"Deep learning for COVID-19 topic modelling via Twitter: Alpha, Delta and\n  Omicron","summary":"  Topic modelling with innovative deep learning methods has gained interest for\na wide range of applications that includes COVID-19. Topic modelling can\nprovide, psychological, social and cultural insights for understanding human\nbehaviour in extreme events such as the COVID-19 pandemic. In this paper, we\nuse prominent deep learning-based language models for COVID-19 topic modelling\ntaking into account data from emergence (Alpha) to the Omicron variant. We\napply topic modeling to review the public behaviour across the first, second\nand third waves based on Twitter dataset from India. Our results show that the\ntopics extracted for the subsequent waves had certain overlapping themes such\nas covers governance, vaccination, and pandemic management while novel issues\naroused in political, social and economic situation during COVID-19 pandemic.\nWe also found a strong correlation of the major topics qualitatively to news\nmedia prevalent at the respective time period. Hence, our framework has the\npotential to capture major issues arising during different phases of the\nCOVID-19 pandemic which can be extended to other countries and regions.\n","authors":["Janhavi Lande","Arti Pillay","Rohitash Chandra"],"pdf_url":"https://arxiv.org/pdf/2303.00135v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.01433v2","updated":"2023-02-28T23:06:09Z","published":"2022-12-02T20:30:59Z","title":"Avoiding spurious correlations via logit correction","summary":"  Empirical studies suggest that machine learning models trained with empirical\nrisk minimization (ERM) often rely on attributes that may be spuriously\ncorrelated with the class labels. Such models typically lead to poor\nperformance during inference for data lacking such correlations. In this work,\nwe explicitly consider a situation where potential spurious correlations are\npresent in the majority of training data. In contrast with existing approaches,\nwhich use the ERM model outputs to detect the samples without spurious\ncorrelations and either heuristically upweight or upsample those samples, we\npropose the logit correction (LC) loss, a simple yet effective improvement on\nthe softmax cross-entropy loss, to correct the sample logit. We demonstrate\nthat minimizing the LC loss is equivalent to maximizing the group-balanced\naccuracy, so the proposed LC could mitigate the negative impacts of spurious\ncorrelations. Our extensive experimental results further reveal that the\nproposed LC loss outperforms state-of-the-art solutions on multiple popular\nbenchmarks by a large margin, an average 5.5\\% absolute improvement, without\naccess to spurious attribute labels. LC is also competitive with oracle methods\nthat make use of the attribute labels. Code is available at\nhttps://github.com/shengliu66/LC.\n","authors":["Sheng Liu","Xu Zhang","Nitesh Sekhar","Yue Wu","Prateek Singhal","Carlos Fernandez-Granda"],"pdf_url":"https://arxiv.org/pdf/2212.01433v2.pdf","comment":"17 pages, 6 figures"},{"id":"http://arxiv.org/abs/2205.05656v4","updated":"2023-02-28T20:58:22Z","published":"2022-05-11T17:38:24Z","title":"Ontology-Driven and Weakly Supervised Rare Disease Identification from\n  Clinical Notes","summary":"  Computational text phenotyping is the practice of identifying patients with\ncertain disorders and traits from clinical notes. Rare diseases are challenging\nto be identified due to few cases available for machine learning and the need\nfor data annotation from domain experts. We propose a method using ontologies\nand weak supervision, with recent pre-trained contextual representations from\nBi-directional Transformers (e.g. BERT). The ontology-based framework includes\ntwo steps: (i) Text-to-UMLS, extracting phenotypes by contextually linking\nmentions to concepts in Unified Medical Language System (UMLS), with a Named\nEntity Recognition and Linking (NER+L) tool, SemEHR, and weak supervision with\ncustomised rules and contextual mention representation; (ii) UMLS-to-ORDO,\nmatching UMLS concepts to rare diseases in Orphanet Rare Disease Ontology\n(ORDO). The weakly supervised approach is proposed to learn a phenotype\nconfirmation model to improve Text-to-UMLS linking, without annotated data from\ndomain experts. We evaluated the approach on three clinical datasets, MIMIC-III\ndischarge summaries, MIMIC-III radiology reports, and NHS Tayside brain imaging\nreports from two institutions in the US and the UK, with annotations. The\nimprovements in the precision were pronounced (by over 30% to 50% absolute\nscore for Text-to-UMLS linking), with almost no loss of recall compared to the\nexisting NER+L tool, SemEHR. Results on radiology reports from MIMIC-III and\nNHS Tayside were consistent with the discharge summaries. The overall pipeline\nprocessing clinical notes can extract rare disease cases, mostly uncaptured in\nstructured data (manually assigned ICD codes). We discuss the usefulness of the\nweak supervision approach and propose directions for future studies.\n","authors":["Hang Dong","Víctor Suárez-Paniagua","Huayu Zhang","Minhong Wang","Arlene Casey","Emma Davidson","Jiaoyan Chen","Beatrice Alex","William Whiteley","Honghan Wu"],"pdf_url":"https://arxiv.org/pdf/2205.05656v4.pdf","comment":"Structured abstract in full text, 16 pages, 4 figures (and extra 6\n  pages, 1 figure in the supplementary material)"},{"id":"http://arxiv.org/abs/2303.00077v1","updated":"2023-02-28T20:49:38Z","published":"2023-02-28T20:49:38Z","title":"Beyond the limitations of any imaginable mechanism: large language\n  models and psycholinguistics","summary":"  Large language models are not detailed models of human linguistic processing.\nThey are, however, extremely successful at their primary task: providing a\nmodel for language. For this reason and because there are no animal models for\nlanguage, large language models are important in psycholinguistics: they are\nuseful as a practical tool, as an illustrative comparative, and\nphilosophically, as a basis for recasting the relationship between language and\nthought.\n","authors":["Conor Houghton","Nina Kazanina","Priyanka Sukumaran"],"pdf_url":"https://arxiv.org/pdf/2303.00077v1.pdf","comment":"This is a commentary on Bowers Et. Al. (2023)\n  doi:10.1017/S0140525X22002813"},{"id":"http://arxiv.org/abs/2301.08771v2","updated":"2023-02-28T20:24:00Z","published":"2023-01-20T19:13:09Z","title":"Matching Exemplar as Next Sentence Prediction (MeNSP): Zero-shot Prompt\n  Learning for Automatic Scoring in Science Education","summary":"  Developing models to automatically score students' written responses to\nscience problems is critical for science education. However, collecting and\nlabeling sufficient student responses for training models is time and\ncost-consuming. Recent studies suggest that pre-trained language models (PLMs)\ncan be adapted to downstream tasks without fine-tuning with prompts. However,\nno research has employed such a prompt approach in science education. As\nstudent responses are presented with natural language, aligning the scoring\nprocedure as the next sentence prediction task using prompts can skip the\ncostly fine-tuning stage. In this study, we developed a zero-shot approach to\nautomatically score student responses via Matching Exemplars as Next Sentence\nPrediction (MeNSP). This approach employs no training samples. We first apply\nMeNSP in scoring three assessment tasks of scientific argumentation and found\nmachine-human scoring agreements, Cohen's Kappa ranges from 0.30 to 0.57, and\nF1 score ranges from 0.54 to 0.81. To improve the performance, we extend our\nresearch to the few-shots setting, either randomly selecting labeled student\nresponses or manually constructing responses to fine-tune the models. We find\nthat one task's performance is improved with more samples, Cohen's Kappa from\n0.30 to 0.38, and F1 score from 0.54 to 0.59; for the two others, scoring\nperformance is not improved. We also find that randomly selected few-shots\nperform better than the human expert-crafted approach. This study suggests that\nMeNSP can yield referable automatic scoring for student responses while\nsignificantly reducing the cost of model training. This method can benefit\nlow-stakes classroom assessment practices in science education. Future research\nshould further explore the applicability of the MeNSP in different types of\nassessment tasks in science education and improve the model performance.\n","authors":["Xuansheng Wu","Xinyu He","Tianming Li","Ninghao Liu","Xiaoming Zhai"],"pdf_url":"https://arxiv.org/pdf/2301.08771v2.pdf","comment":"10+3 pages"},{"id":"http://arxiv.org/abs/2303.00069v1","updated":"2023-02-28T20:18:59Z","published":"2023-02-28T20:18:59Z","title":"ClArTTS: An Open-Source Classical Arabic Text-to-Speech Corpus","summary":"  At present, Text-to-speech (TTS) systems that are trained with high-quality\ntranscribed speech data using end-to-end neural models can generate speech that\nis intelligible, natural, and closely resembles human speech. These models are\ntrained with relatively large single-speaker professionally recorded audio,\ntypically extracted from audiobooks. Meanwhile, due to the scarcity of freely\navailable speech corpora of this kind, a larger gap exists in Arabic TTS\nresearch and development. Most of the existing freely available Arabic speech\ncorpora are not suitable for TTS training as they contain multi-speaker casual\nspeech with variations in recording conditions and quality, whereas the corpus\ncurated for speech synthesis are generally small in size and not suitable for\ntraining state-of-the-art end-to-end models. In a move towards filling this gap\nin resources, we present a speech corpus for Classical Arabic Text-to-Speech\n(ClArTTS) to support the development of end-to-end TTS systems for Arabic. The\nspeech is extracted from a LibriVox audiobook, which is then processed,\nsegmented, and manually transcribed and annotated. The final ClArTTS corpus\ncontains about 12 hours of speech from a single male speaker sampled at 40100\nkHz. In this paper, we describe the process of corpus creation and provide\ndetails of corpus statistics and a comparison with existing resources.\nFurthermore, we develop two TTS systems based on Grad-TTS and Glow-TTS and\nillustrate the performance of the resulting systems via subjective and\nobjective evaluations. The corpus will be made publicly available at\nwww.clartts.com for research purposes, along with the baseline TTS systems\ndemo.\n","authors":["Ajinkya Kulkarni","Atharva Kulkarni","Sara Abedalmonem Mohammad Shatnawi","Hanan Aldarmaki"],"pdf_url":"https://arxiv.org/pdf/2303.00069v1.pdf","comment":"None"},{"id":"http://arxiv.org/abs/2302.14679v1","updated":"2023-02-28T15:42:30Z","published":"2023-02-28T15:42:30Z","title":"Synthesizing Mixed-type Electronic Health Records using Diffusion Models","summary":"  Electronic Health Records (EHRs) contain sensitive patient information, which\npresents privacy concerns when sharing such data. Synthetic data generation is\na promising solution to mitigate these risks, often relying on deep generative\nmodels such as Generative Adversarial Networks (GANs). However, recent studies\nhave shown that diffusion models offer several advantages over GANs, such as\ngeneration of more realistic synthetic data and stable training in generating\ndata modalities, including image, text, and sound. In this work, we investigate\nthe potential of diffusion models for generating realistic mixed-type tabular\nEHRs, comparing TabDDPM model with existing methods on four datasets in terms\nof data quality, utility, privacy, and augmentation. Our experiments\ndemonstrate that TabDDPM outperforms the state-of-the-art models across all\nevaluation metrics, except for privacy, which confirms the trade-off between\nprivacy and utility.\n","authors":["Taha Ceritli","Ghadeer O. Ghosheh","Vinod Kumar Chauhan","Tingting Zhu","Andrew P. Creagh","David A. Clifton"],"pdf_url":"https://arxiv.org/pdf/2302.14679v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.09217v3","updated":"2023-02-28T09:47:49Z","published":"2022-07-17T03:12:27Z","title":"Contextual Similarity is More Valuable than Character Similarity: An\n  Empirical Study for Chinese Spell Checking","summary":"  Chinese Spell Checking (CSC) task aims to detect and correct Chinese spelling\nerrors. Recently, related researches focus on introducing character similarity\nfrom confusion set to enhance the CSC models, ignoring the context of\ncharacters that contain richer information. To make better use of contextual\ninformation, we propose a simple yet effective Curriculum Learning (CL)\nframework for the CSC task. With the help of our model-agnostic CL framework,\nexisting CSC models will be trained from easy to difficult as humans learn\nChinese characters and achieve further performance improvements. Extensive\nexperiments and detailed analyses on widely used SIGHAN datasets show that our\nmethod outperforms previous state-of-the-art methods. More instructively, our\nstudy empirically suggests that contextual similarity is more valuable than\ncharacter similarity for the CSC task.\n","authors":["Ding Zhang","Yinghui Li","Qingyu Zhou","Shirong Ma","Yangning Li","Yunbo Cao","Hai-Tao Zheng"],"pdf_url":"https://arxiv.org/pdf/2207.09217v3.pdf","comment":"Accepted by ICASSP2023"},{"id":"http://arxiv.org/abs/2303.01241v1","updated":"2023-02-28T21:53:48Z","published":"2023-02-28T21:53:48Z","title":"PANACEA: An Automated Misinformation Detection System on COVID-19","summary":"  In this demo, we introduce a web-based misinformation detection system\nPANACEA on COVID-19 related claims, which has two modules, fact-checking and\nrumour detection. Our fact-checking module, which is supported by novel natural\nlanguage inference methods with a self-attention network, outperforms\nstate-of-the-art approaches. It is also able to give automated veracity\nassessment and ranked supporting evidence with the stance towards the claim to\nbe checked. In addition, PANACEA adapts the bi-directional graph convolutional\nnetworks model, which is able to detect rumours based on comment networks of\nrelated tweets, instead of relying on the knowledge base. This rumour detection\nmodule assists by warning the users in the early stages when a knowledge base\nmay not be available.\n","authors":["Runcong Zhao","Miguel Arana-Catania","Lixing Zhu","Elena Kochkina","Lin Gui","Arkaitz Zubiaga","Rob Procter","Maria Liakata","Yulan He"],"pdf_url":"https://arxiv.org/pdf/2303.01241v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01249v1","updated":"2023-02-28T14:43:49Z","published":"2023-02-28T14:43:49Z","title":"Language-Universal Adapter Learning with Knowledge Distillation for\n  End-to-End Multilingual Speech Recognition","summary":"  In this paper, we propose a language-universal adapter learning framework\nbased on a pre-trained model for end-to-end multilingual automatic speech\nrecognition (ASR). For acoustic modeling, the wav2vec 2.0 pre-trained model is\nfine-tuned by inserting language-specific and language-universal adapters. An\nonline knowledge distillation is then used to enable the language-universal\nadapters to learn both language-specific and universal features. The linguistic\ninformation confusion is also reduced by leveraging language identifiers\n(LIDs). With LIDs we perform a position-wise modification on the multi-head\nattention outputs. In the inference procedure, the language-specific adapters\nare removed while the language-universal adapters are kept activated. The\nproposed method improves the recognition accuracy and addresses the linear\nincrease of the number of adapters' parameters with the number of languages in\ncommon multilingual ASR systems. Experiments on the BABEL dataset confirm the\neffectiveness of the proposed framework. Compared to the conventional\nmultilingual model, a 3.3% absolute error rate reduction is achieved. The code\nis available at: https://github.com/shen9712/UniversalAdapterLearning.\n","authors":["Zhijie Shen","Wu Guo","Bin Gu"],"pdf_url":"https://arxiv.org/pdf/2303.01249v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2302.14859v1","updated":"2023-02-28T18:58:03Z","published":"2023-02-28T18:58:03Z","title":"BakedSDF: Meshing Neural SDFs for Real-Time View Synthesis","summary":"  We present a method for reconstructing high-quality meshes of large unbounded\nreal-world scenes suitable for photorealistic novel view synthesis. We first\noptimize a hybrid neural volume-surface scene representation designed to have\nwell-behaved level sets that correspond to surfaces in the scene. We then bake\nthis representation into a high-quality triangle mesh, which we equip with a\nsimple and fast view-dependent appearance model based on spherical Gaussians.\nFinally, we optimize this baked representation to best reproduce the captured\nviewpoints, resulting in a model that can leverage accelerated polygon\nrasterization pipelines for real-time view synthesis on commodity hardware. Our\napproach outperforms previous scene representations for real-time rendering in\nterms of accuracy, speed, and power consumption, and produces high quality\nmeshes that enable applications such as appearance editing and physical\nsimulation.\n","authors":["Lior Yariv","Peter Hedman","Christian Reiser","Dor Verbin","Pratul P. Srinivasan","Richard Szeliski","Jonathan T. Barron","Ben Mildenhall"],"pdf_url":"https://arxiv.org/pdf/2302.14859v1.pdf","comment":"Video and interactive web demo available at\n  https://bakedsdf.github.io/"},{"id":"http://arxiv.org/abs/2210.06184v2","updated":"2023-02-28T18:40:52Z","published":"2022-10-07T17:27:50Z","title":"Images as Weight Matrices: Sequential Image Generation Through Synaptic\n  Learning Rules","summary":"  Work on fast weight programmers has demonstrated the effectiveness of\nkey/value outer product-based learning rules for sequentially generating a\nweight matrix (WM) of a neural net (NN) by another NN or itself. However, the\nweight generation steps are typically not visually interpretable by humans,\nbecause the contents stored in the WM of an NN are not. Here we apply the same\nprinciple to generate natural images. The resulting fast weight painters (FPAs)\nlearn to execute sequences of delta learning rules to sequentially generate\nimages as sums of outer products of self-invented keys and values, one rank at\na time, as if each image was a WM of an NN. We train our FPAs in the generative\nadversarial networks framework, and evaluate on various image datasets. We show\nhow these generic learning rules can generate images with respectable visual\nquality without any explicit inductive bias for images. While the performance\nlargely lags behind the one of specialised state-of-the-art image generators,\nour approach allows for visualising how synaptic learning rules iteratively\nproduce complex connection patterns, yielding human-interpretable meaningful\nimages. Finally, we also show that an additional convolutional U-Net (now\npopular in diffusion models) at the output of an FPA can learn one-step\n\"denoising\" of FPA-generated images to enhance their quality. Our code is\npublic.\n","authors":["Kazuki Irie","Jürgen Schmidhuber"],"pdf_url":"https://arxiv.org/pdf/2210.06184v2.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2210.09879v3","updated":"2023-02-28T18:35:23Z","published":"2022-10-18T14:13:20Z","title":"Unsupervised visualization of image datasets using contrastive learning","summary":"  Visualization methods based on the nearest neighbor graph, such as t-SNE or\nUMAP, are widely used for visualizing high-dimensional data. Yet, these\napproaches only produce meaningful results if the nearest neighbors themselves\nare meaningful. For images represented in pixel space this is not the case, as\ndistances in pixel space are often not capturing our sense of similarity and\ntherefore neighbors are not semantically close. This problem can be\ncircumvented by self-supervised approaches based on contrastive learning, such\nas SimCLR, relying on data augmentation to generate implicit neighbors, but\nthese methods do not produce two-dimensional embeddings suitable for\nvisualization. Here, we present a new method, called t-SimCNE, for unsupervised\nvisualization of image data. T-SimCNE combines ideas from contrastive learning\nand neighbor embeddings, and trains a parametric mapping from the\nhigh-dimensional pixel space into two dimensions. We show that the resulting 2D\nembeddings achieve classification accuracy comparable to the state-of-the-art\nhigh-dimensional SimCLR representations, thus faithfully capturing semantic\nrelationships. Using t-SimCNE, we obtain informative visualizations of the\nCIFAR-10 and CIFAR-100 datasets, showing rich cluster structure and\nhighlighting artifacts and outliers.\n","authors":["Jan Niklas Böhm","Philipp Berens","Dmitry Kobak"],"pdf_url":"https://arxiv.org/pdf/2210.09879v3.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2302.09956v2","updated":"2023-02-28T18:30:37Z","published":"2023-02-20T12:57:31Z","title":"Because Every Sensor Is Unique, so Is Every Pair: Handling Dynamicity in\n  Traffic Forecasting","summary":"  Traffic forecasting is a critical task to extract values from cyber-physical\ninfrastructures, which is the backbone of smart transportation. However owing\nto external contexts, the dynamics at each sensor are unique. For example, the\nafternoon peaks at sensors near schools are more likely to occur earlier than\nthose near residential areas. In this paper, we first analyze real-world\ntraffic data to show that each sensor has a unique dynamic. Further analysis\nalso shows that each pair of sensors also has a unique dynamic. Then, we\nexplore how node embedding learns the unique dynamics at every sensor location.\nNext, we propose a novel module called Spatial Graph Transformers (SGT) where\nwe use node embedding to leverage the self-attention mechanism to ensure that\nthe information flow between two sensors is adaptive with respect to the unique\ndynamic of each pair. Finally, we present Graph Self-attention WaveNet (G-SWaN)\nto address the complex, non-linear spatiotemporal traffic dynamics. Through\nempirical experiments on four real-world, open datasets, we show that the\nproposed method achieves superior performance on both traffic speed and flow\nforecasting. Code is available at: https://github.com/aprbw/G-SWaN\n","authors":["Arian Prabowo","Wei Shao","Hao Xue","Piotr Koniusz","Flora D. Salim"],"pdf_url":"https://arxiv.org/pdf/2302.09956v2.pdf","comment":"20 pages, IoTDI 2023; Correction on Fig. 4"},{"id":"http://arxiv.org/abs/2302.14831v1","updated":"2023-02-28T18:28:35Z","published":"2023-02-28T18:28:35Z","title":"FacEDiM: A Face Embedding Distribution Model for Few-Shot Biometric\n  Authentication of Cattle","summary":"  This work proposes to solve the problem of few-shot biometric authentication\nby computing the Mahalanobis distance between testing embeddings and a\nmultivariate Gaussian distribution of training embeddings obtained using\npre-trained CNNs. Experimental results show that models pre-trained on the\nImageNet dataset significantly outperform models pre-trained on human faces.\nWith a VGG16 model, we obtain a FRR of 1.18% for a FAR of 1.25% on a dataset of\n20 cattle identities.\n","authors":["Meshia Cédric Oveneke","Rucha Vaishampayan","Deogratias Lukamba Nsadisa","Jenny Ambukiyenyi Onya"],"pdf_url":"https://arxiv.org/pdf/2302.14831v1.pdf","comment":"4 pages, 1 figure, 1 table, paper accepted at Black In AI at the 36th\n  Conference on Neural Information Processing Systems (NeurIPS 2022), New\n  Orleans, USA"},{"id":"http://arxiv.org/abs/2302.14816v1","updated":"2023-02-28T18:08:21Z","published":"2023-02-28T18:08:21Z","title":"Monocular Depth Estimation using Diffusion Models","summary":"  We formulate monocular depth estimation using denoising diffusion models,\ninspired by their recent successes in high fidelity image generation. To that\nend, we introduce innovations to address problems arising due to noisy,\nincomplete depth maps in training data, including step-unrolled denoising\ndiffusion, an $L_1$ loss, and depth infilling during training. To cope with the\nlimited availability of data for supervised training, we leverage pre-training\non self-supervised image-to-image translation tasks. Despite the simplicity of\nthe approach, with a generic loss and architecture, our DepthGen model achieves\nSOTA performance on the indoor NYU dataset, and near SOTA results on the\noutdoor KITTI dataset. Further, with a multimodal posterior, DepthGen naturally\nrepresents depth ambiguity (e.g., from transparent surfaces), and its zero-shot\nperformance combined with depth imputation, enable a simple but effective\ntext-to-3D pipeline. Project page: https://depth-gen.github.io\n","authors":["Saurabh Saxena","Abhishek Kar","Mohammad Norouzi","David J. Fleet"],"pdf_url":"https://arxiv.org/pdf/2302.14816v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14808v1","updated":"2023-02-28T17:58:54Z","published":"2023-02-28T17:58:54Z","title":"Opto-UNet: Optimized UNet for Segmentation of Varicose Veins in Optical\n  Coherence Tomography","summary":"  Human veins are important for carrying the blood from the body-parts to the\nheart. The improper functioning of the human veins may arise from several\nvenous diseases. Varicose vein is one such disease wherein back flow of blood\ncan occur, often resulting in increased venous pressure or restricted blood\nflow due to changes in the structure of vein. To examine the functional\ncharacteristics of the varicose vein, it is crucial to study the physical and\nbio mechanical properties of the vein. This work proposes a segmentation model\nOpto-UNet, for segmenting the venous wall structure. Optical Coherence\nTomography system is used to acquire images of varicose vein. As the extracted\nvein is not uniform in shape, hence adequate method of segmentation is required\nto segment the venous wall. Opto-UNet model is based on the U-Net architecture\nwherein a new block is integrated into the architecture, employing atrous and\nseparable convolution to extract spatially wide-range and separable features\nmaps for attaining advanced performance. Furthermore, the depth wise separable\nconvolution significantly reduces the complexity of the network by optimizing\nthe number of parameters. The model achieves accuracy of 0.9830, sensitivity of\n0.8425 and specificity of 0.9980 using 8.54 million number of parameters. These\nresults indicate that model is highly adequate in segmenting the varicose vein\nwall without deteriorating the segmentation quality along with reduced\ncomplexity\n","authors":["Maryam Viqar","Violeta Madjarova","Vipul Baghel","Elena Stoykova"],"pdf_url":"https://arxiv.org/pdf/2302.14808v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14807v1","updated":"2023-02-28T17:57:06Z","published":"2023-02-28T17:57:06Z","title":"DFR-FastMOT: Detection Failure Resistant Tracker for Fast Multi-Object\n  Tracking Based on Sensor Fusion","summary":"  Persistent multi-object tracking (MOT) allows autonomous vehicles to navigate\nsafely in highly dynamic environments. One of the well-known challenges in MOT\nis object occlusion when an object becomes unobservant for subsequent frames.\nThe current MOT methods store objects information, like objects' trajectory, in\ninternal memory to recover the objects after occlusions. However, they retain\nshort-term memory to save computational time and avoid slowing down the MOT\nmethod. As a result, they lose track of objects in some occlusion scenarios,\nparticularly long ones. In this paper, we propose DFR-FastMOT, a light MOT\nmethod that uses data from a camera and LiDAR sensors and relies on an\nalgebraic formulation for object association and fusion. The formulation boosts\nthe computational time and permits long-term memory that tackles more occlusion\nscenarios. Our method shows outstanding tracking performance over recent\nlearning and non-learning benchmarks with about 3% and 4% margin in MOTA,\nrespectively. Also, we conduct extensive experiments that simulate occlusion\nphenomena by employing detectors with various distortion levels. The proposed\nsolution enables superior performance under various distortion levels in\ndetection over current state-of-art methods. Our framework processes about\n7,763 frames in 1.48 seconds, which is seven times faster than recent\nbenchmarks. The framework will be available at\nhttps://github.com/MohamedNagyMostafa/DFR-FastMOT.\n","authors":["Mohamed Nagy","Majid Khonji","Jorge Dias","Sajid Javed"],"pdf_url":"https://arxiv.org/pdf/2302.14807v1.pdf","comment":"\\c{opyright} 2023 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works"},{"id":"http://arxiv.org/abs/2302.14795v1","updated":"2023-02-28T17:46:25Z","published":"2023-02-28T17:46:25Z","title":"3D Coronary Vessel Reconstruction from Bi-Plane Angiography using Graph\n  Convolutional Networks","summary":"  X-ray coronary angiography (XCA) is used to assess coronary artery disease\nand provides valuable information on lesion morphology and severity. However,\nXCA images are 2D and therefore limit visualisation of the vessel. 3D\nreconstruction of coronary vessels is possible using multiple views, however\nlumen border detection in current software is performed manually resulting in\nlimited reproducibility and slow processing time. In this study we propose\n3DAngioNet, a novel deep learning (DL) system that enables rapid 3D vessel mesh\nreconstruction using 2D XCA images from two views. Our approach learns a coarse\nmesh template using an EfficientB3-UNet segmentation network and projection\ngeometries, and deforms it using a graph convolutional network. 3DAngioNet\noutperforms similar automated reconstruction methods, offers improved\nefficiency, and enables modelling of bifurcated vessels. The approach was\nvalidated using state-of-the-art software verified by skilled cardiologists.\n","authors":["Kit Mills Bransby","Vincenzo Tufaro","Murat Cap","Greg Slabaugh","Christos Bourantas","Qianni Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.14795v1.pdf","comment":"Pre-print for IEEE International Symposium on Biomedical Imaging 2023\n  (ISBI)"},{"id":"http://arxiv.org/abs/2302.14794v1","updated":"2023-02-28T17:46:18Z","published":"2023-02-28T17:46:18Z","title":"Meta Learning to Bridge Vision and Language Models for Multimodal\n  Few-Shot Learning","summary":"  Multimodal few-shot learning is challenging due to the large domain gap\nbetween vision and language modalities. Existing methods are trying to\ncommunicate visual concepts as prompts to frozen language models, but rely on\nhand-engineered task induction to reduce the hypothesis space. To make the\nwhole process learnable, we introduce a multimodal meta-learning approach.\nSpecifically, our approach decomposes the training of the model into a set of\nrelated multimodal few-shot tasks. We define a meta-mapper network, acting as a\nmeta-learner, to efficiently bridge frozen large-scale vision and language\nmodels and leverage their already learned capacity. By updating the learnable\nparameters only of the meta-mapper, it learns to accrue shared meta-knowledge\namong these tasks. Thus, it can rapidly adapt to newly presented samples with\nonly a few gradient updates. Importantly, it induces the task in a completely\ndata-driven manner, with no need for a hand-engineered task induction. We\nevaluate our approach on recently proposed multimodal few-shot benchmarks,\nmeasuring how rapidly the model can bind novel visual concepts to words and\nanswer visual questions by observing only a limited set of labeled examples.\nThe experimental results show that our meta-learning approach outperforms the\nbaseline across multiple datasets and various training settings while being\ncomputationally more efficient.\n","authors":["Ivona Najdenkoska","Xiantong Zhen","Marcel Worring"],"pdf_url":"https://arxiv.org/pdf/2302.14794v1.pdf","comment":"International Conference on Learning Representations 2023"},{"id":"http://arxiv.org/abs/2106.13201v3","updated":"2023-02-28T17:36:38Z","published":"2021-06-24T17:27:32Z","title":"DROID: Driver-centric Risk Object Identification","summary":"  Identification of high-risk driving situations is generally approached\nthrough collision risk estimation or accident pattern recognition. In this\nwork, we approach the problem from the perspective of subjective risk. We\noperationalize subjective risk assessment by predicting driver behavior changes\nand identifying the cause of changes. To this end, we introduce a new task\ncalled driver-centric risk object identification (DROID), which uses egocentric\nvideo to identify object(s) influencing a driver's behavior, given only the\ndriver's response as the supervision signal. We formulate the task as a\ncause-effect problem and present a novel two-stage DROID framework, taking\ninspiration from models of situation awareness and causal inference. A subset\nof data constructed from the Honda Research Institute Driving Dataset (HDD) is\nused to evaluate DROID. We demonstrate state-of-the-art DROID performance, even\ncompared with strong baseline models using this dataset. Additionally, we\nconduct extensive ablative studies to justify our design choices. Moreover, we\ndemonstrate the applicability of DROID for risk assessment.\n","authors":["Chengxi Li","Stanley H. Chan","Yi-Ting Chen"],"pdf_url":"https://arxiv.org/pdf/2106.13201v3.pdf","comment":"Submitted to TPAMI"},{"id":"http://arxiv.org/abs/2302.14777v1","updated":"2023-02-28T17:20:40Z","published":"2023-02-28T17:20:40Z","title":"VQA with Cascade of Self- and Co-Attention Blocks","summary":"  The use of complex attention modules has improved the performance of the\nVisual Question Answering (VQA) task. This work aims to learn an improved\nmulti-modal representation through dense interaction of visual and textual\nmodalities. The proposed model has an attention block containing both\nself-attention and co-attention on image and text. The self-attention modules\nprovide the contextual information of objects (for an image) and words (for a\nquestion) that are crucial for inferring an answer. On the other hand,\nco-attention aids the interaction of image and text. Further, fine-grained\ninformation is obtained from two modalities by using a Cascade of Self- and\nCo-Attention blocks (CSCA). This proposal is benchmarked on the widely used\nVQA2.0 and TDIUC datasets. The efficacy of key components of the model and\ncascading of attention modules are demonstrated by experiments involving\nablation analysis.\n","authors":["Aakansha Mishra","Ashish Anand","Prithwijit Guha"],"pdf_url":"https://arxiv.org/pdf/2302.14777v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14772v1","updated":"2023-02-28T17:14:24Z","published":"2023-02-28T17:14:24Z","title":"PA&DA: Jointly Sampling PAth and DAta for Consistent NAS","summary":"  Based on the weight-sharing mechanism, one-shot NAS methods train a supernet\nand then inherit the pre-trained weights to evaluate sub-models, largely\nreducing the search cost. However, several works have pointed out that the\nshared weights suffer from different gradient descent directions during\ntraining. And we further find that large gradient variance occurs during\nsupernet training, which degrades the supernet ranking consistency. To mitigate\nthis issue, we propose to explicitly minimize the gradient variance of the\nsupernet training by jointly optimizing the sampling distributions of PAth and\nDAta (PA&DA). We theoretically derive the relationship between the gradient\nvariance and the sampling distributions, and reveal that the optimal sampling\nprobability is proportional to the normalized gradient norm of path and\ntraining data. Hence, we use the normalized gradient norm as the importance\nindicator for path and training data, and adopt an importance sampling strategy\nfor the supernet training. Our method only requires negligible computation cost\nfor optimizing the sampling distributions of path and data, but achieves lower\ngradient variance during supernet training and better generalization\nperformance for the supernet, resulting in a more consistent NAS. We conduct\ncomprehensive comparisons with other improved approaches in various search\nspaces. Results show that our method surpasses others with more reliable\nranking performance and higher accuracy of searched architectures, showing the\neffectiveness of our method. Code is available at\nhttps://github.com/ShunLu91/PA-DA.\n","authors":["Shun Lu","Yu Hu","Longxing Yang","Zihao Sun","Jilin Mei","Jianchao Tan","Chengru Song"],"pdf_url":"https://arxiv.org/pdf/2302.14772v1.pdf","comment":"To appear in CVPR 2023; we will update the camera-ready version soon"},{"id":"http://arxiv.org/abs/2302.14771v1","updated":"2023-02-28T17:13:14Z","published":"2023-02-28T17:13:14Z","title":"Generic-to-Specific Distillation of Masked Autoencoders","summary":"  Large vision Transformers (ViTs) driven by self-supervised pre-training\nmechanisms achieved unprecedented progress. Lightweight ViT models limited by\nthe model capacity, however, benefit little from those pre-training mechanisms.\nKnowledge distillation defines a paradigm to transfer representations from\nlarge (teacher) models to small (student) ones. However, the conventional\nsingle-stage distillation easily gets stuck on task-specific transfer, failing\nto retain the task-agnostic knowledge crucial for model generalization. In this\nstudy, we propose generic-to-specific distillation (G2SD), to tap the potential\nof small ViT models under the supervision of large models pre-trained by masked\nautoencoders. In generic distillation, decoder of the small model is encouraged\nto align feature predictions with hidden representations of the large model, so\nthat task-agnostic knowledge can be transferred. In specific distillation,\npredictions of the small model are constrained to be consistent with those of\nthe large model, to transfer task-specific features which guarantee task\nperformance. With G2SD, the vanilla ViT-Small model respectively achieves\n98.7%, 98.1% and 99.3% the performance of its teacher (ViT-Base) for image\nclassification, object detection, and semantic segmentation, setting a solid\nbaseline for two-stage vision distillation. Code will be available at\nhttps://github.com/pengzhiliang/G2SD.\n","authors":["Wei Huang","Zhiliang Peng","Li Dong","Furu Wei","Jianbin Jiao","Qixiang Ye"],"pdf_url":"https://arxiv.org/pdf/2302.14771v1.pdf","comment":"Accepted by CVPR2023"},{"id":"http://arxiv.org/abs/2204.05235v2","updated":"2023-02-28T17:12:35Z","published":"2022-04-11T16:32:25Z","title":"Data Splits and Metrics for Method Benchmarking on Surgical Action\n  Triplet Datasets","summary":"  In addition to generating data and annotations, devising sensible data\nsplitting strategies and evaluation metrics is essential for the creation of a\nbenchmark dataset. This practice ensures consensus on the usage of the data,\nhomogeneous assessment, and uniform comparison of research methods on the\ndataset. This study focuses on CholecT50, which is a 50 video surgical dataset\nthat formalizes surgical activities as triplets of <instrument, verb, target>.\nIn this paper, we introduce the standard splits for the CholecT50 and CholecT45\ndatasets and show how they compare with existing use of the dataset. CholecT45\nis the first public release of 45 videos of CholecT50 dataset. We also develop\na metrics library, ivtmetrics, for model evaluation on surgical triplets.\nFurthermore, we conduct a benchmark study by reproducing baseline methods in\nthe most predominantly used deep learning frameworks (PyTorch and TensorFlow)\nto evaluate them using the proposed data splits and metrics and release them\npublicly to support future research. The proposed data splits and evaluation\nmetrics will enable global tracking of research progress on the dataset and\nfacilitate optimal model selection for further deployment.\n","authors":["Chinedu Innocent Nwoye","Nicolas Padoy"],"pdf_url":"https://arxiv.org/pdf/2204.05235v2.pdf","comment":"Official splits for the CholecT50 and CholecT45 datasets, 13 pages, 2\n  figures, 12 tables"},{"id":"http://arxiv.org/abs/2302.14769v1","updated":"2023-02-28T17:10:32Z","published":"2023-02-28T17:10:32Z","title":"Membership Inference Attack for Beluga Whales Discrimination","summary":"  To efficiently monitor the growth and evolution of a particular wildlife\npopulation, one of the main fundamental challenges to address in animal ecology\nis the re-identification of individuals that have been previously encountered\nbut also the discrimination between known and unknown individuals (the\nso-called \"open-set problem\"), which is the first step to realize before\nre-identification. In particular, in this work, we are interested in the\ndiscrimination within digital photos of beluga whales, which are known to be\namong the most challenging marine species to discriminate due to their lack of\ndistinctive features. To tackle this problem, we propose a novel approach based\non the use of Membership Inference Attacks (MIAs), which are normally used to\nassess the privacy risks associated with releasing a particular machine\nlearning model. More precisely, we demonstrate that the problem of\ndiscriminating between known and unknown individuals can be solved efficiently\nusing state-of-the-art approaches for MIAs. Extensive experiments on three\nbenchmark datasets related to whales, two different neural network\narchitectures, and three MIA clearly demonstrate the performance of the\napproach. In addition, we have also designed a novel MIA strategy that we\ncoined as ensemble MIA, which combines the outputs of different MIAs to\nincrease the attack accuracy while diminishing the false positive rate.\nOverall, one of our main objectives is also to show that the research on\nprivacy attacks can also be leveraged \"for good\" by helping to address\npractical challenges encountered in animal ecology.\n","authors":["Voncarlos Marcelo Araújo","Sébastien Gambs","Clément Chion","Robert Michaud","Léo Schneider","Hadrien Lautraite"],"pdf_url":"https://arxiv.org/pdf/2302.14769v1.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2302.14762v1","updated":"2023-02-28T17:02:35Z","published":"2023-02-28T17:02:35Z","title":"Kartezio: Evolutionary Design of Explainable Pipelines for Biomedical\n  Image Analysis","summary":"  An unresolved issue in contemporary biomedicine is the overwhelming number\nand diversity of complex images that require annotation, analysis and\ninterpretation. Recent advances in Deep Learning have revolutionized the field\nof computer vision, creating algorithms that compete with human experts in\nimage segmentation tasks. Crucially however, these frameworks require large\nhuman-annotated datasets for training and the resulting models are difficult to\ninterpret. In this study, we introduce Kartezio, a modular Cartesian Genetic\nProgramming based computational strategy that generates transparent and easily\ninterpretable image processing pipelines by iteratively assembling and\nparameterizing computer vision functions. The pipelines thus generated exhibit\ncomparable precision to state-of-the-art Deep Learning approaches on instance\nsegmentation tasks, while requiring drastically smaller training datasets, a\nfeature which confers tremendous flexibility, speed, and functionality to this\napproach. We also deployed Kartezio to solve semantic and instance segmentation\nproblems in four real-world Use Cases, and showcase its utility in imaging\ncontexts ranging from high-resolution microscopy to clinical pathology. By\nsuccessfully implementing Kartezio on a portfolio of images ranging from\nsubcellular structures to tumoral tissue, we demonstrated the flexibility,\nrobustness and practical utility of this fully explicable evolutionary designer\nfor semantic and instance segmentation.\n","authors":["Kévin Cortacero","Brienne McKenzie","Sabina Müller","Roxana Khazen","Fanny Lafouresse","Gaëlle Corsaut","Nathalie Van Acker","François-Xavier Frenois","Laurence Lamant","Nicolas Meyer","Béatrice Vergier","Dennis G. Wilson","Hervé Luga","Oskar Staufer","Michael L. Dustin","Salvatore Valitutti","Sylvain Cussat-Blanc"],"pdf_url":"https://arxiv.org/pdf/2302.14762v1.pdf","comment":"42 pages, 6 main Figures, 3 Extended Data Figures, 5 Extended Data\n  Tables, 1 Extended Data Movie. The Extended Data Movie is available at the\n  following link:\n  https://drive.google.com/file/d/1eNGhFC8gyu5xjVOhIZve894g3bBKXEgs/view?usp=sharing"},{"id":"http://arxiv.org/abs/2210.10947v2","updated":"2023-02-28T16:54:02Z","published":"2022-10-20T01:32:41Z","title":"Does Learning from Decentralized Non-IID Unlabeled Data Benefit from\n  Self Supervision?","summary":"  Decentralized learning has been advocated and widely deployed to make\nefficient use of distributed datasets, with an extensive focus on supervised\nlearning (SL) problems. Unfortunately, the majority of real-world data are\nunlabeled and can be highly heterogeneous across sources. In this work, we\ncarefully study decentralized learning with unlabeled data through the lens of\nself-supervised learning (SSL), specifically contrastive visual representation\nlearning. We study the effectiveness of a range of contrastive learning\nalgorithms under decentralized learning settings, on relatively large-scale\ndatasets including ImageNet-100, MS-COCO, and a new real-world robotic\nwarehouse dataset. Our experiments show that the decentralized SSL (Dec-SSL)\napproach is robust to the heterogeneity of decentralized datasets, and learns\nuseful representation for object classification, detection, and segmentation\ntasks. This robustness makes it possible to significantly reduce communication\nand reduce the participation ratio of data sources with only minimal drops in\nperformance. Interestingly, using the same amount of data, the representation\nlearned by Dec-SSL can not only perform on par with that learned by centralized\nSSL which requires communication and excessive data storage costs, but also\nsometimes outperform representations extracted from decentralized SL which\nrequires extra knowledge about the data labels. Finally, we provide theoretical\ninsights into understanding why data heterogeneity is less of a concern for\nDec-SSL objectives, and introduce feature alignment and clustering techniques\nto develop a new Dec-SSL algorithm that further improves the performance, in\nthe face of highly non-IID data. Our study presents positive evidence to\nembrace unlabeled data in decentralized learning, and we hope to provide new\ninsights into whether and why decentralized SSL is effective.\n","authors":["Lirui Wang","Kaiqing Zhang","Yunzhu Li","Yonglong Tian","Russ Tedrake"],"pdf_url":"https://arxiv.org/pdf/2210.10947v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14746v1","updated":"2023-02-28T16:45:21Z","published":"2023-02-28T16:45:21Z","title":"Mask3D: Pre-training 2D Vision Transformers by Learning Masked 3D Priors","summary":"  Current popular backbones in computer vision, such as Vision Transformers\n(ViT) and ResNets are trained to perceive the world from 2D images. However, to\nmore effectively understand 3D structural priors in 2D backbones, we propose\nMask3D to leverage existing large-scale RGB-D data in a self-supervised\npre-training to embed these 3D priors into 2D learned feature representations.\nIn contrast to traditional 3D contrastive learning paradigms requiring 3D\nreconstructions or multi-view correspondences, our approach is simple: we\nformulate a pre-text reconstruction task by masking RGB and depth patches in\nindividual RGB-D frames. We demonstrate the Mask3D is particularly effective in\nembedding 3D priors into the powerful 2D ViT backbone, enabling improved\nrepresentation learning for various scene understanding tasks, such as semantic\nsegmentation, instance segmentation and object detection. Experiments show that\nMask3D notably outperforms existing self-supervised 3D pre-training approaches\non ScanNet, NYUv2, and Cityscapes image understanding tasks, with an\nimprovement of +6.5% mIoU against the state-of-the-art Pri3D on ScanNet image\nsemantic segmentation.\n","authors":["Ji Hou","Xiaoliang Dai","Zijian He","Angela Dai","Matthias Nießner"],"pdf_url":"https://arxiv.org/pdf/2302.14746v1.pdf","comment":"accepted to CVPR2023"},{"id":"http://arxiv.org/abs/2302.14736v1","updated":"2023-02-28T16:39:36Z","published":"2023-02-28T16:39:36Z","title":"TextIR: A Simple Framework for Text-based Editable Image Restoration","summary":"  Most existing image restoration methods use neural networks to learn strong\nimage-level priors from huge data to estimate the lost information. However,\nthese works still struggle in cases when images have severe information\ndeficits. Introducing external priors or using reference images to provide\ninformation also have limitations in the application domain. In contrast, text\ninput is more readily available and provides information with higher\nflexibility. In this work, we design an effective framework that allows the\nuser to control the restoration process of degraded images with text\ndescriptions. We use the text-image feature compatibility of the CLIP to\nalleviate the difficulty of fusing text and image features. Our framework can\nbe used for various image restoration tasks, including image inpainting, image\nsuper-resolution, and image colorization. Extensive experiments demonstrate the\neffectiveness of our method.\n","authors":["Yunpeng Bai","Cairong Wang","Shuzhao Xie","Chao Dong","Chun Yuan","Zhi Wang"],"pdf_url":"https://arxiv.org/pdf/2302.14736v1.pdf","comment":"9 pages, 8 figures"},{"id":"http://arxiv.org/abs/2302.14728v1","updated":"2023-02-28T16:34:55Z","published":"2023-02-28T16:34:55Z","title":"Global Context-Aware Person Image Generation","summary":"  We propose a data-driven approach for context-aware person image generation.\nSpecifically, we attempt to generate a person image such that the synthesized\ninstance can blend into a complex scene. In our method, the position, scale,\nand appearance of the generated person are semantically conditioned on the\nexisting persons in the scene. The proposed technique is divided into three\nsequential steps. At first, we employ a Pix2PixHD model to infer a coarse\nsemantic mask that represents the new person's spatial location, scale, and\npotential pose. Next, we use a data-centric approach to select the closest\nrepresentation from a precomputed cluster of fine semantic masks. Finally, we\nadopt a multi-scale, attention-guided architecture to transfer the appearance\nattributes from an exemplar image. The proposed strategy enables us to\nsynthesize semantically coherent realistic persons that can blend into an\nexisting scene without altering the global context. We conclude our findings\nwith relevant qualitative and quantitative evaluations.\n","authors":["Prasun Roy","Saumik Bhattacharya","Subhankar Ghosh","Umapada Pal","Michael Blumenstein"],"pdf_url":"https://arxiv.org/pdf/2302.14728v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2112.04720v2","updated":"2023-02-28T16:21:41Z","published":"2021-12-09T06:16:08Z","title":"Amicable Aid: Perturbing Images to Improve Classification Performance","summary":"  While adversarial perturbation of images to attack deep image classification\nmodels pose serious security concerns in practice, this paper suggests a novel\nparadigm where the concept of image perturbation can benefit classification\nperformance, which we call amicable aid. We show that by taking the opposite\nsearch direction of perturbation, an image can be modified to yield higher\nclassification confidence and even a misclassified image can be made correctly\nclassified. This can be also achieved with a large amount of perturbation by\nwhich the image is made unrecognizable by human eyes. The mechanism of the\namicable aid is explained in the viewpoint of the underlying natural image\nmanifold. Furthermore, we investigate the universal amicable aid, i.e., a fixed\nperturbation can be applied to multiple images to improve their classification\nresults. While it is challenging to find such perturbations, we show that\nmaking the decision boundary as perpendicular to the image manifold as possible\nvia training with modified data is effective to obtain a model for which\nuniversal amicable perturbations are more easily found.\n","authors":["Juyeop Kim","Jun-Ho Choi","Soobeom Jang","Jong-Seok Lee"],"pdf_url":"https://arxiv.org/pdf/2112.04720v2.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2302.14696v1","updated":"2023-02-28T16:09:06Z","published":"2023-02-28T16:09:06Z","title":"Dissolving Is Amplifying: Towards Fine-Grained Anomaly Detection","summary":"  Medical anomalous data normally contains fine-grained instance-wise additive\nfeature patterns (e.g. tumor, hemorrhage), that are oftenly critical but\ninsignificant. Interestingly, apart from the remarkable image generation\nabilities of diffusion models, we observed that diffusion models can dissolve\nimage details for a given image, resulting in generalized feature\nrepresentations. We hereby propose DIA, dissolving is amplifying, that\namplifies fine-grained image features by contrasting an image against its\nfeature dissolved counterpart. In particular, we show that diffusion models can\nserve as semantic preserving feature dissolvers that help learning fine-grained\nanomalous patterns for anomaly detection tasks, especially for medical domains\nwith fine-grained feature differences. As a result, our method yields a novel\nfine-grained anomaly detection method, aims at amplifying instance-level\nfeature patterns, that significantly improves medical anomaly detection\naccuracy in a large margin without any prior knowledge of explicit fine-grained\nanomalous feature patterns.\n","authors":["Jian Shi","Pengyi Zhang","Ni Zhang","Hakim Ghazzai","Yehia Massoud"],"pdf_url":"https://arxiv.org/pdf/2302.14696v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06958v2","updated":"2023-02-28T15:59:30Z","published":"2023-01-17T15:32:59Z","title":"RILS: Masked Visual Reconstruction in Language Semantic Space","summary":"  Both masked image modeling (MIM) and natural language supervision have\nfacilitated the progress of transferable visual pre-training. In this work, we\nseek the synergy between two paradigms and study the emerging properties when\nMIM meets natural language supervision. To this end, we present a novel masked\nvisual Reconstruction In Language semantic Space (RILS) pre-training framework,\nin which sentence representations, encoded by the text encoder, serve as\nprototypes to transform the vision-only signals into patch-sentence\nprobabilities as semantically meaningful MIM reconstruction targets. The vision\nmodels can therefore capture useful components with structured information by\npredicting proper semantic of masked tokens. Better visual representations\ncould, in turn, improve the text encoder via the image-text alignment\nobjective, which is essential for the effective MIM target transformation.\nExtensive experimental results demonstrate that our method not only enjoys the\nbest of previous MIM and CLIP but also achieves further improvements on various\ntasks due to their mutual benefits. RILS exhibits advanced transferability on\ndownstream classification, detection, and segmentation, especially for low-shot\nregimes. Code will be made available at https://github.com/hustvl/RILS.\n","authors":["Shusheng Yang","Yixiao Ge","Kun Yi","Dian Li","Ying Shan","Xiaohu Qie","Xinggang Wang"],"pdf_url":"https://arxiv.org/pdf/2301.06958v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14685v1","updated":"2023-02-28T15:54:47Z","published":"2023-02-28T15:54:47Z","title":"DART: Diversify-Aggregate-Repeat Training Improves Generalization of\n  Neural Networks","summary":"  Generalization of neural networks is crucial for deploying them safely in the\nreal world. Common training strategies to improve generalization involve the\nuse of data augmentations, ensembling and model averaging. In this work, we\nfirst establish a surprisingly simple but strong benchmark for generalization\nwhich utilizes diverse augmentations within a training minibatch, and show that\nthis can learn a more balanced distribution of features. Further, we propose\nDiversify-Aggregate-Repeat Training (DART) strategy that first trains diverse\nmodels using different augmentations (or domains) to explore the loss basin,\nand further Aggregates their weights to combine their expertise and obtain\nimproved generalization. We find that Repeating the step of Aggregation\nthroughout training improves the overall optimization trajectory and also\nensures that the individual models have a sufficiently low loss barrier to\nobtain improved generalization on combining them. We shed light on our approach\nby casting it in the framework proposed by Shen et al. and theoretically show\nthat it indeed generalizes better. In addition to improvements in In- Domain\ngeneralization, we demonstrate SOTA performance on the Domain Generalization\nbenchmarks in the popular DomainBed framework as well. Our method is generic\nand can easily be integrated with several base training algorithms to achieve\nperformance gains.\n","authors":["Samyak Jain","Sravanti Addepalli","Pawan Sahu","Priyam Dey","R. Venkatesh Babu"],"pdf_url":"https://arxiv.org/pdf/2302.14685v1.pdf","comment":"Accepted at CVPR 2023. First two authors contributed equally"},{"id":"http://arxiv.org/abs/2302.14683v1","updated":"2023-02-28T15:51:19Z","published":"2023-02-28T15:51:19Z","title":"IntrinsicNGP: Intrinsic Coordinate based Hash Encoding for Human NeRF","summary":"  Recently, many works have been proposed to utilize the neural radiance field\nfor novel view synthesis of human performers. However, most of these methods\nrequire hours of training, making them difficult for practical use. To address\nthis challenging problem, we propose IntrinsicNGP, which can train from scratch\nand achieve high-fidelity results in few minutes with videos of a human\nperformer. To achieve this target, we introduce a continuous and optimizable\nintrinsic coordinate rather than the original explicit Euclidean coordinate in\nthe hash encoding module of instant-NGP. With this novel intrinsic coordinate,\nIntrinsicNGP can aggregate inter-frame information for dynamic objects with the\nhelp of proxy geometry shapes. Moreover, the results trained with the given\nrough geometry shapes can be further refined with an optimizable offset field\nbased on the intrinsic coordinate.Extensive experimental results on several\ndatasets demonstrate the effectiveness and efficiency of IntrinsicNGP. We also\nillustrate our approach's ability to edit the shape of reconstructed subjects.\n","authors":["Bo Peng","Jun Hu","Jingtao Zhou","Xuan Gao","Juyong Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.14683v1.pdf","comment":"Project page:https://ustc3dv.github.io/IntrinsicNGP/. arXiv admin\n  note: substantial text overlap with arXiv:2210.01651"},{"id":"http://arxiv.org/abs/2107.09559v4","updated":"2023-02-28T15:46:52Z","published":"2021-07-20T15:22:16Z","title":"SynthSeg: Segmentation of brain MRI scans of any contrast and resolution\n  without retraining","summary":"  Despite advances in data augmentation and transfer learning, convolutional\nneural networks (CNNs) difficultly generalise to unseen domains. When\nsegmenting brain scans, CNNs are highly sensitive to changes in resolution and\ncontrast: even within the same MRI modality, performance can decrease across\ndatasets. Here we introduce SynthSeg, the first segmentation CNN robust against\nchanges in contrast and resolution. SynthSeg is trained with synthetic data\nsampled from a generative model conditioned on segmentations. Crucially, we\nadopt a domain randomisation strategy where we fully randomise the contrast and\nresolution of the synthetic training data. Consequently, SynthSeg can segment\nreal scans from a wide range of target domains without retraining or\nfine-tuning, which enables straightforward analysis of huge amounts of\nheterogeneous clinical data. Because SynthSeg only requires segmentations to be\ntrained (no images), it can learn from labels obtained by automated methods on\ndiverse populations (e.g., ageing and diseased), thus achieving robustness to a\nwide range of morphological variability. We demonstrate SynthSeg on 5,000 scans\nof six modalities (including CT) and ten resolutions, where it exhibits\nunparalleled generalisation compared with supervised CNNs, state-of-the-art\ndomain adaptation, and Bayesian segmentation. Finally, we demonstrate the\ngeneralisability of SynthSeg by applying it to cardiac MRI and CT scans.\n","authors":["Benjamin Billot","Douglas N. Greve","Oula Puonti","Axel Thielscher","Koen Van Leemput","Bruce Fischl","Adrian V. Dalca","Juan Eugenio Iglesias"],"pdf_url":"https://arxiv.org/pdf/2107.09559v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14680v1","updated":"2023-02-28T15:45:20Z","published":"2023-02-28T15:45:20Z","title":"Which One Are You Referring To? Multimodal Object Identification in\n  Situated Dialogue","summary":"  The demand for multimodal dialogue systems has been rising in various\ndomains, emphasizing the importance of interpreting multimodal inputs from\nconversational and situational contexts. We explore three methods to tackle\nthis problem and evaluate them on the largest situated dialogue dataset, SIMMC\n2.1. Our best method, scene-dialogue alignment, improves the performance by\n~20% F1-score compared to the SIMMC 2.1 baselines. We provide analysis and\ndiscussion regarding the limitation of our methods and the potential directions\nfor future works. Our code is publicly available at\nhttps://github.com/holylovenia/multimodal-object-identification.\n","authors":["Holy Lovenia","Samuel Cahyawijaya","Pascale Fung"],"pdf_url":"https://arxiv.org/pdf/2302.14680v1.pdf","comment":"Accepted at EACL SRW 2023"},{"id":"http://arxiv.org/abs/2302.14677v1","updated":"2023-02-28T15:39:31Z","published":"2023-02-28T15:39:31Z","title":"Backdoor Attacks Against Deep Image Compression via Adaptive Frequency\n  Trigger","summary":"  Recent deep-learning-based compression methods have achieved superior\nperformance compared with traditional approaches. However, deep learning models\nhave proven to be vulnerable to backdoor attacks, where some specific trigger\npatterns added to the input can lead to malicious behavior of the models. In\nthis paper, we present a novel backdoor attack with multiple triggers against\nlearned image compression models. Motivated by the widely used discrete cosine\ntransform (DCT) in existing compression systems and standards, we propose a\nfrequency-based trigger injection model that adds triggers in the DCT domain.\nIn particular, we design several attack objectives for various attacking\nscenarios, including: 1) attacking compression quality in terms of bit-rate and\nreconstruction quality; 2) attacking task-driven measures, such as down-stream\nface recognition and semantic segmentation. Moreover, a novel simple dynamic\nloss is designed to balance the influence of different loss terms adaptively,\nwhich helps achieve more efficient training. Extensive experiments show that\nwith our trained trigger injection models and simple modification of encoder\nparameters (of the compression model), the proposed attack can successfully\ninject several backdoors with corresponding triggers in a single image\ncompression model.\n","authors":["Yi Yu","Yufei Wang","Wenhan Yang","Shijian Lu","Yap-peng Tan","Alex C. Kot"],"pdf_url":"https://arxiv.org/pdf/2302.14677v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2302.14673v1","updated":"2023-02-28T15:36:17Z","published":"2023-02-28T15:36:17Z","title":"Attention-based Point Cloud Edge Sampling","summary":"  Point cloud sampling is a less explored research topic for this data\nrepresentation. The most common sampling methods nowadays are still classical\nrandom sampling and farthest point sampling. With the development of neural\nnetworks, various methods have been proposed to sample point clouds in a\ntask-based learning manner. However, these methods are mostly generative-based,\nother than selecting points directly with mathematical statistics. Inspired by\nthe Canny edge detection algorithm for images and with the help of the\nattention mechanism, this paper proposes a non-generative Attention-based Point\ncloud Edge Sampling method (APES), which can capture the outline of input point\nclouds. Experimental results show that better performances are achieved with\nour sampling method due to the important outline information it learned.\n","authors":["Chengzhi Wu","Junwei Zheng","Julius Pfrommer","Jürgen Beyerer"],"pdf_url":"https://arxiv.org/pdf/2302.14673v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14670v1","updated":"2023-02-28T15:34:01Z","published":"2023-02-28T15:34:01Z","title":"Double Dynamic Sparse Training for GANs","summary":"  The past decade has witnessed a drastic increase in modern deep neural\nnetworks (DNNs) size, especially for generative adversarial networks (GANs).\nSince GANs usually suffer from high computational complexity, researchers have\nshown an increased interest in applying pruning methods to reduce the training\nand inference costs of GANs. Among different pruning methods invented for\nsupervised learning, dynamic sparse training (DST) has gained increasing\nattention recently as it enjoys excellent training efficiency with comparable\nperformance to post-hoc pruning. Hence, applying DST on GANs, where we train a\nsparse GAN with a fixed parameter count throughout training, seems to be a good\ncandidate for reducing GAN training costs. However, a few challenges, including\nthe degrading training instability, emerge due to the adversarial nature of\nGANs. Hence, we introduce a quantity called balance ratio (BR) to quantify the\nbalance of the generator and the discriminator. We conduct a series of\nexperiments to show the importance of BR in understanding sparse GAN training.\nBuilding upon single dynamic sparse training (SDST), where only the generator\nis adjusted during training, we propose double dynamic sparse training (DDST)\nto control the BR during GAN training. Empirically, DDST automatically\ndetermines the density of the discriminator and greatly boosts the performance\nof sparse GANs on multiple datasets.\n","authors":["Yite Wang","Jing Wu","Naira Hovakimyan","Ruoyu Sun"],"pdf_url":"https://arxiv.org/pdf/2302.14670v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2302.14665v1","updated":"2023-02-28T15:31:23Z","published":"2023-02-28T15:31:23Z","title":"Parametrizing Product Shape Manifolds by Composite Networks","summary":"  Parametrizations of data manifolds in shape spaces can be computed using the\nrich toolbox of Riemannian geometry. This, however, often comes with high\ncomputational costs, which raises the question if one can learn an efficient\nneural network approximation. We show that this is indeed possible for shape\nspaces with a special product structure, namely those smoothly approximable by\na direct sum of low-dimensional manifolds. Our proposed architecture leverages\nthis structure by separately learning approximations for the low-dimensional\nfactors and a subsequent combination. After developing the approach as a\ngeneral framework, we apply it to a shape space of triangular surfaces. Here,\ntypical examples of data manifolds are given through datasets of articulated\nmodels and can be factorized, for example, by a Sparse Principal Geodesic\nAnalysis (SPGA). We demonstrate the effectiveness of our proposed approach with\nexperiments on synthetic data as well as manifolds extracted from data via\nSPGA.\n","authors":["Josua Sassen","Klaus Hildebrandt","Martin Rumpf","Benedikt Wirth"],"pdf_url":"https://arxiv.org/pdf/2302.14665v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03022v2","updated":"2023-02-28T15:09:40Z","published":"2023-02-06T18:57:30Z","title":"SurgT challenge: Benchmark of Soft-Tissue Trackers for Robotic Surgery","summary":"  This paper introduces the \"SurgT: Surgical Tracking\" challenge which was\norganised in conjunction with the 25th International Conference on Medical\nImage Computing and Computer-Assisted Intervention (MICCAI 2022). There were\ntwo purposes for the creation of this challenge: (1) the establishment of the\nfirst standardised benchmark for the research community to assess soft-tissue\ntrackers; and (2) to encourage the development of unsupervised deep learning\nmethods, given the lack of annotated data in surgery. A dataset of 157 stereo\nendoscopic videos from 20 clinical cases, along with stereo camera calibration\nparameters, have been provided. The participants were tasked with the\ndevelopment of algorithms to track a bounding box on stereo endoscopic videos.\nAt the end of the challenge, the developed methods were assessed on a\npreviously hidden test subset. This assessment uses benchmarking metrics that\nwere purposely developed for this challenge and are now available online. The\nteams were ranked according to their Expected Average Overlap (EAO) score,\nwhich is a weighted average of the Intersection over Union (IoU) scores. The\nperformance evaluation study verifies the efficacy of unsupervised deep\nlearning algorithms in tracking soft-tissue. The best-performing method\nachieved an EAO score of 0.583 in the test subset. The dataset and benchmarking\ntool created for this challenge have been made publicly available. This\nchallenge is expected to contribute to the development of autonomous robotic\nsurgery and other digital surgical technologies.\n","authors":["Joao Cartucho","Alistair Weld","Samyakh Tukra","Haozheng Xu","Hiroki Matsuzaki","Taiyo Ishikawa","Minjun Kwon","Yong Eun Jang","Kwang-Ju Kim","Gwang Lee","Bizhe Bai","Lueder Kahrs","Lars Boecking","Simeon Allmendinger","Leopold Muller","Yitong Zhang","Yueming Jin","Bano Sophia","Francisco Vasconcelos","Wolfgang Reiter","Jonas Hajek","Bruno Silva","Lukas R. Buschle","Estevao Lima","Joao L. Vilaca","Sandro Queiros","Stamatia Giannarou"],"pdf_url":"https://arxiv.org/pdf/2302.03022v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14623v1","updated":"2023-02-28T15:03:18Z","published":"2023-02-28T15:03:18Z","title":"Fast as CHITA: Neural Network Pruning with Combinatorial Optimization","summary":"  The sheer size of modern neural networks makes model serving a serious\ncomputational challenge. A popular class of compression techniques overcomes\nthis challenge by pruning or sparsifying the weights of pretrained networks.\nWhile useful, these techniques often face serious tradeoffs between\ncomputational requirements and compression quality. In this work, we propose a\nnovel optimization-based pruning framework that considers the combined effect\nof pruning (and updating) multiple weights subject to a sparsity constraint.\nOur approach, CHITA, extends the classical Optimal Brain Surgeon framework and\nresults in significant improvements in speed, memory, and performance over\nexisting optimization-based approaches for network pruning. CHITA's main\nworkhorse performs combinatorial optimization updates on a memory-friendly\nrepresentation of local quadratic approximation(s) of the loss function. On a\nstandard benchmark of pretrained models and datasets, CHITA leads to\nsignificantly better sparsity-accuracy tradeoffs than competing methods. For\nexample, for MLPNet with only 2% of the weights retained, our approach improves\nthe accuracy by 63% relative to the state of the art. Furthermore, when used in\nconjunction with fine-tuning SGD steps, our method achieves significant\naccuracy gains over the state-of-the-art approaches.\n","authors":["Riade Benbaki","Wenyu Chen","Xiang Meng","Hussein Hazimeh","Natalia Ponomareva","Zhe Zhao","Rahul Mazumder"],"pdf_url":"https://arxiv.org/pdf/2302.14623v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14595v1","updated":"2023-02-28T14:29:22Z","published":"2023-02-28T14:29:22Z","title":"MateRobot: Material Recognition in Wearable Robotics for People with\n  Visual Impairments","summary":"  Wearable robotics can improve the lives of People with Visual Impairments\n(PVI) by providing additional sensory information. Blind people typically\nrecognize objects through haptic perception. However, knowing materials before\ntouching is under-explored in the field of assistive technology. To fill this\ngap, in this work, a wearable robotic system, MateRobot, is established for PVI\nto recognize materials before hand. Specially, the human-centric system can\nperform pixel-wise semantic segmentation of objects and materials. Considering\nboth general object segmentation and material segmentation, an efficient\nMateViT architecture with Learnable Importance Sampling (LIS) and Multi-gate\nMixture-of-Experts (MMoE) is proposed to wearable robots to achieve\ncomplementary gains from different target domains. Our methods achieve\nrespective 40.2% and 51.1% of mIoU on COCOStuff and DMS datasets, surpassing\nprevious method with +5.7% and +7.0% gains. Moreover, on the field test with\nparticipants, our wearable system obtains a score of 28 in NASA-Task Load\nIndex, indicating low cognitive demands and ease of use. Our MateRobot\ndemonstrates the feasibility of recognizing material properties through visual\ncues, and offers a promising step towards improving the functionality of\nwearable robots for PVI. Code will be available at:\nhttps://github.com/JunweiZheng93/MATERobot.\n","authors":["Junwei Zheng","Jiaming Zhang","Kailun Yang","Kunyu Peng","Rainer Stiefelhagen"],"pdf_url":"https://arxiv.org/pdf/2302.14595v1.pdf","comment":"Code will be available at: https://github.com/JunweiZheng93/MATERobot"},{"id":"http://arxiv.org/abs/2302.14589v1","updated":"2023-02-28T14:16:32Z","published":"2023-02-28T14:16:32Z","title":"Focus On Details: Online Multi-object Tracking with Diverse Fine-grained\n  Representation","summary":"  Discriminative representation is essential to keep a unique identifier for\neach target in Multiple object tracking (MOT). Some recent MOT methods extract\nfeatures of the bounding box region or the center point as identity embeddings.\nHowever, when targets are occluded, these coarse-grained global representations\nbecome unreliable. To this end, we propose exploring diverse fine-grained\nrepresentation, which describes appearance comprehensively from global and\nlocal perspectives. This fine-grained representation requires high feature\nresolution and precise semantic information. To effectively alleviate the\nsemantic misalignment caused by indiscriminate contextual information\naggregation, Flow Alignment FPN (FAFPN) is proposed for multi-scale feature\nalignment aggregation. It generates semantic flow among feature maps from\ndifferent resolutions to transform their pixel positions. Furthermore, we\npresent a Multi-head Part Mask Generator (MPMG) to extract fine-grained\nrepresentation based on the aligned feature maps. Multiple parallel branches of\nMPMG allow it to focus on different parts of targets to generate local masks\nwithout label supervision. The diverse details in target masks facilitate\nfine-grained representation. Eventually, benefiting from a Shuffle-Group\nSampling (SGS) training strategy with positive and negative samples balanced,\nwe achieve state-of-the-art performance on MOT17 and MOT20 test sets. Even on\nDanceTrack, where the appearance of targets is extremely similar, our method\nsignificantly outperforms ByteTrack by 5.0% on HOTA and 5.6% on IDF1. Extensive\nexperiments have proved that diverse fine-grained representation makes Re-ID\ngreat again in MOT.\n","authors":["Hao Ren","Shoudong Han","Huilin Ding","Ziwen Zhang","Hongwei Wang","Faquan Wang"],"pdf_url":"https://arxiv.org/pdf/2302.14589v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14581v1","updated":"2023-02-28T14:03:40Z","published":"2023-02-28T14:03:40Z","title":"HopFIR: Hop-wise GraphFormer with Intragroup Joint Refinement for 3D\n  Human Pose Estimation","summary":"  2D-to-3D human pose lifting is fundamental for 3D human pose estimation\n(HPE). Graph Convolutional Network (GCN) has been proven inherently suitable to\nmodel the human skeletal topology. However, current GCN-based 3D HPE methods\nupdate the node features by aggregating their neighbors' information without\nconsidering the interaction of joints in different motion patterns. Although\nsome studies import limb information to learn the movement patterns, the latent\nsynergies among joints, such as maintaining balance in the motion are seldom\ninvestigated. We propose a hop-wise GraphFormer with intragroup joint\nrefinement (HopFIR) to tackle the 3D HPE problem. The HopFIR mainly consists of\na novel Hop-wise GraphFormer(HGF) module and an Intragroup Joint\nRefinement(IJR) module which leverages the prior limb information for\nperipheral joints refinement. The HGF module groups the joints by $k$-hop\nneighbors and utilizes a hop-wise transformer-like attention mechanism among\nthese groups to discover latent joint synergy. Extensive experimental results\nshow that HopFIR outperforms the SOTA methods with a large margin (on the\nHuman3.6M dataset, the mean per joint position error (MPJPE) is 32.67mm).\nFurthermore, it is also demonstrated that previous SOTA GCN-based methods can\nbenefit from the proposed hop-wise attention mechanism efficiently with\nsignificant performance promotion, such as SemGCN and MGCN are improved by 8.9%\nand 4.5%, respectively.\n","authors":["Kai Zhai","Qiang Nie","Bo Ouyang","Xiang Li","ShanLin Yang"],"pdf_url":"https://arxiv.org/pdf/2302.14581v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14578v1","updated":"2023-02-28T14:01:01Z","published":"2023-02-28T14:01:01Z","title":"Interactive Segmentation as Gaussian Process Classification","summary":"  Click-based interactive segmentation (IS) aims to extract the target objects\nunder user interaction. For this task, most of the current deep learning\n(DL)-based methods mainly follow the general pipelines of semantic\nsegmentation. Albeit achieving promising performance, they do not fully and\nexplicitly utilize and propagate the click information, inevitably leading to\nunsatisfactory segmentation results, even at clicked points. Against this\nissue, in this paper, we propose to formulate the IS task as a Gaussian process\n(GP)-based pixel-wise binary classification model on each image. To solve this\nmodel, we utilize amortized variational inference to approximate the\nintractable GP posterior in a data-driven manner and then decouple the\napproximated GP posterior into double space forms for efficient sampling with\nlinear complexity. Then, we correspondingly construct a GP classification\nframework, named GPCIS, which is integrated with the deep kernel learning\nmechanism for more flexibility. The main specificities of the proposed GPCIS\nlie in: 1) Under the explicit guidance of the derived GP posterior, the\ninformation contained in clicks can be finely propagated to the entire image\nand then boost the segmentation; 2) The accuracy of predictions at clicks has\ngood theoretical support. These merits of GPCIS as well as its good generality\nand high efficiency are substantiated by comprehensive experiments on several\nbenchmarks, as compared with representative methods both quantitatively and\nqualitatively.\n","authors":["Minghao Zhou","Hong Wang","Qian Zhao","Yuexiang Li","Yawen Huang","Deyu Meng","Yefeng Zheng"],"pdf_url":"https://arxiv.org/pdf/2302.14578v1.pdf","comment":"To appear in CVPR2023"},{"id":"http://arxiv.org/abs/2211.16761v2","updated":"2023-02-28T13:57:43Z","published":"2022-11-30T05:59:23Z","title":"Improving Cross-Modal Retrieval with Set of Diverse Embeddings","summary":"  Cross-modal retrieval across image and text modalities is a challenging task\ndue to its inherent ambiguity: An image often exhibits various situations, and\na caption can be coupled with diverse images. Set-based embedding has been\nstudied as a solution to this problem. It seeks to encode a sample into a set\nof different embedding vectors that capture different semantics of the sample.\nIn this paper, we present a novel set-based embedding method, which is distinct\nfrom previous work in two aspects. First, we present a new similarity function\ncalled smooth-Chamfer similarity, which is designed to alleviate the side\neffects of existing similarity functions for set-based embedding. Second, we\npropose a novel set prediction module to produce a set of embedding vectors\nthat effectively captures diverse semantics of input by the slot attention\nmechanism. Our method is evaluated on the COCO and Flickr30K datasets across\ndifferent visual backbones, where it outperforms existing methods including\nones that demand substantially larger computation at inference.\n","authors":["Dongwon Kim","Namyup Kim","Suha Kwak"],"pdf_url":"https://arxiv.org/pdf/2211.16761v2.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2302.14574v1","updated":"2023-02-28T13:54:31Z","published":"2023-02-28T13:54:31Z","title":"A Little Bit Attention Is All You Need for Person Re-Identification","summary":"  Person re-identification plays a key role in applications where a mobile\nrobot needs to track its users over a long period of time, even if they are\npartially unobserved for some time, in order to follow them or be available on\ndemand. In this context, deep-learning based real-time feature extraction on a\nmobile robot is often performed on special-purpose devices whose computational\nresources are shared for multiple tasks. Therefore, the inference speed has to\nbe taken into account. In contrast, person re-identification is often improved\nby architectural changes that come at the cost of significantly slowing down\ninference. Attention blocks are one such example. We will show that some\nwell-performing attention blocks used in the state of the art are subject to\ninference costs that are far too high to justify their use for mobile robotic\napplications. As a consequence, we propose an attention block that only\nslightly affects the inference speed while keeping up with much deeper networks\nor more complex attention blocks in terms of re-identification accuracy. We\nperform extensive neural architecture search to derive rules at which locations\nthis attention block should be integrated into the architecture in order to\nachieve the best trade-off between speed and accuracy. Finally, we confirm that\nthe best performing configuration on a re-identification benchmark also\nperforms well on an indoor robotic dataset.\n","authors":["Markus Eisenbach","Jannik Lübberstedt","Dustin Aganian","Horst-Michael Gross"],"pdf_url":"https://arxiv.org/pdf/2302.14574v1.pdf","comment":"IEEE International Conference on Robotics and Automation (ICRA) 2023"},{"id":"http://arxiv.org/abs/2301.07668v2","updated":"2023-02-28T13:53:42Z","published":"2023-01-18T17:24:01Z","title":"Behind the Scenes: Density Fields for Single View Reconstruction","summary":"  Inferring a meaningful geometric scene representation from a single image is\na fundamental problem in computer vision. Approaches based on traditional depth\nmap prediction can only reason about areas that are visible in the image.\nCurrently, neural radiance fields (NeRFs) can capture true 3D including color\nbut are too complex to be generated from a single image. As an alternative, we\nintroduce a neural network that predicts an implicit density field from a\nsingle image. It maps every location in the frustum of the image to volumetric\ndensity. Our network can be trained through self-supervision from only video\ndata. By not storing color in the implicit volume, but directly sampling color\nfrom the available views during training, our scene representation becomes\nsignificantly less complex compared to NeRFs, and we can train neural networks\nto predict it. Thus, we can apply volume rendering to perform both depth\nprediction and novel view synthesis. In our experiments, we show that our\nmethod is able to predict meaningful geometry for regions that are occluded in\nthe input image. Additionally, we demonstrate the potential of our approach on\nthree datasets for depth prediction and novel-view synthesis.\n","authors":["Felix Wimbauer","Nan Yang","Christian Rupprecht","Daniel Cremers"],"pdf_url":"https://arxiv.org/pdf/2301.07668v2.pdf","comment":"Project Page: https://fwmb.github.io/bts/"},{"id":"http://arxiv.org/abs/2206.04656v5","updated":"2023-02-28T13:48:48Z","published":"2022-06-09T17:55:51Z","title":"Simple Cues Lead to a Strong Multi-Object Tracker","summary":"  For a long time, the most common paradigm in Multi-Object Tracking was\ntracking-by-detection (TbD), where objects are first detected and then\nassociated over video frames. For association, most models resourced to motion\nand appearance cues, e.g., re-identification networks. Recent approaches based\non attention propose to learn the cues in a data-driven manner, showing\nimpressive results. In this paper, we ask ourselves whether simple good old TbD\nmethods are also capable of achieving the performance of end-to-end models. To\nthis end, we propose two key ingredients that allow a standard\nre-identification network to excel at appearance-based tracking. We extensively\nanalyse its failure cases, and show that a combination of our appearance\nfeatures with a simple motion model leads to strong tracking results. Our\ntracker generalizes to four public datasets, namely MOT17, MOT20, BDD100k, and\nDanceTrack, achieving state-of-the-art performance. We will release the code\nand models\n","authors":["Jenny Seidenschwarz","Guillem Brasó","Victor Castro Serrano","Ismail Elezi","Laura Leal-Taixé"],"pdf_url":"https://arxiv.org/pdf/2206.04656v5.pdf","comment":"Accepted to CVPR2023!"},{"id":"http://arxiv.org/abs/2302.14557v1","updated":"2023-02-28T13:26:24Z","published":"2023-02-28T13:26:24Z","title":"GRAN: Ghost Residual Attention Network for Single Image Super Resolution","summary":"  Recently, many works have designed wider and deeper networks to achieve\nhigher image super-resolution performance. Despite their outstanding\nperformance, they still suffer from high computational resources, preventing\nthem from directly applying to embedded devices. To reduce the computation\nresources and maintain performance, we propose a novel Ghost Residual Attention\nNetwork (GRAN) for efficient super-resolution. This paper introduces Ghost\nResidual Attention Block (GRAB) groups to overcome the drawbacks of the\nstandard convolutional operation, i.e., redundancy of the intermediate feature.\nGRAB consists of the Ghost Module and Channel and Spatial Attention Module\n(CSAM) to alleviate the generation of redundant features. Specifically, Ghost\nModule can reveal information underlying intrinsic features by employing linear\noperations to replace the standard convolutions. Reducing redundant features by\nthe Ghost Module, our model decreases memory and computing resource\nrequirements in the network. The CSAM pays more comprehensive attention to\nwhere and what the feature extraction is, which is critical to recovering the\nimage details. Experiments conducted on the benchmark datasets demonstrate the\nsuperior performance of our method in both qualitative and quantitative.\nCompared to the baseline models, we achieve higher performance with lower\ncomputational resources, whose parameters and FLOPs have decreased by more than\nten times.\n","authors":["Axi Niu","Pei Wang","Yu Zhu","Jinqiu Sun","Qingsen Yan","Yanning Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.14557v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14554v1","updated":"2023-02-28T13:19:11Z","published":"2023-02-28T13:19:11Z","title":"FPCD: An Open Aerial VHR Dataset for Farm Pond Change Detection","summary":"  Change detection for aerial imagery involves locating and identifying changes\nassociated with the areas of interest between co-registered bi-temporal or\nmulti-temporal images of a geographical location. Farm ponds are man-made\nstructures belonging to the category of minor irrigation structures used to\ncollect surface run-off water for future irrigation purposes. Detection of farm\nponds from aerial imagery and their evolution over time helps in land surveying\nto analyze the agricultural shifts, policy implementation, seasonal effects and\nclimate changes. In this paper, we introduce a publicly available object\ndetection and instance segmentation (OD/IS) dataset for localizing farm ponds\nfrom aerial imagery. We also collected and annotated the bi-temporal data over\na time-span of 14 years across 17 villages, resulting in a binary change\ndetection dataset called \\textbf{F}arm \\textbf{P}ond \\textbf{C}hange\n\\textbf{D}etection Dataset (\\textbf{FPCD}). We have benchmarked and analyzed\nthe performance of various object detection and instance segmentation methods\non our OD/IS dataset and the change detection methods over the FPCD dataset.\nThe datasets are publicly accessible at this page:\n\\textit{\\url{https://huggingface.co/datasets/ctundia/FPCD}}\n","authors":["Chintan Tundia","Rajiv Kumar","Om Damani","G. Sivakumar"],"pdf_url":"https://arxiv.org/pdf/2302.14554v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.06931v4","updated":"2023-02-28T13:09:19Z","published":"2022-01-18T12:49:59Z","title":"Deep Equilibrium Models for Video Snapshot Compressive Imaging","summary":"  The ability of snapshot compressive imaging (SCI) systems to efficiently\ncapture high-dimensional (HD) data has led to an inverse problem, which\nconsists of recovering the HD signal from the compressed and noisy measurement.\nWhile reconstruction algorithms grow fast to solve it with the recent advances\nof deep learning, the fundamental issue of accurate and stable recovery\nremains. To this end, we propose deep equilibrium models (DEQ) for video SCI,\nfusing data-driven regularization and stable convergence in a theoretically\nsound manner. Each equilibrium model implicitly learns a nonexpansive operator\nand analytically computes the fixed point, thus enabling unlimited iterative\nsteps and infinite network depth with only a constant memory requirement in\ntraining and testing. Specifically, we demonstrate how DEQ can be applied to\ntwo existing models for video SCI reconstruction: recurrent neural networks\n(RNN) and Plug-and-Play (PnP) algorithms. On a variety of datasets and real\ndata, both quantitative and qualitative evaluations of our results demonstrate\nthe effectiveness and stability of our proposed method. The code and models are\navailable at: https://github.com/IndigoPurple/DEQSCI .\n","authors":["Yaping Zhao","Siming Zheng","Xin Yuan"],"pdf_url":"https://arxiv.org/pdf/2201.06931v4.pdf","comment":"9 pages, 7 figures"},{"id":"http://arxiv.org/abs/2302.14533v1","updated":"2023-02-28T12:43:52Z","published":"2023-02-28T12:43:52Z","title":"DEff-GAN: Diverse Attribute Transfer for Few-Shot Image Synthesis","summary":"  Requirements of large amounts of data is a difficulty in training many GANs.\nData efficient GANs involve fitting a generators continuous target distribution\nwith a limited discrete set of data samples, which is a difficult task. Single\nimage methods have focused on modeling the internal distribution of a single\nimage and generating its samples. While single image methods can synthesize\nimage samples with diversity, they do not model multiple images or capture the\ninherent relationship possible between two images. Given only a handful of\nimages, we are interested in generating samples and exploiting the\ncommonalities in the input images. In this work, we extend the single-image GAN\nmethod to model multiple images for sample synthesis. We modify the\ndiscriminator with an auxiliary classifier branch, which helps to generate a\nwide variety of samples and to classify the input labels. Our Data-Efficient\nGAN (DEff-GAN) generates excellent results when similarities and\ncorrespondences can be drawn between the input images or classes.\n","authors":["Rajiv Kumar","G. Sivakumar"],"pdf_url":"https://arxiv.org/pdf/2302.14533v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14522v1","updated":"2023-02-28T12:31:31Z","published":"2023-02-28T12:31:31Z","title":"AdaptiveShape: Solving Shape Variability for 3D Object Detection with\n  Geometry Aware Anchor Distributions","summary":"  3D object detection with point clouds and images plays an important role in\nperception tasks such as autonomous driving. Current methods show great\nperformance on detection and pose estimation of standard-shaped vehicles but\nlack behind on more complex shapes as e.g. semi-trailer truck combinations.\nDetermining the shape and motion of those special vehicles accurately is\ncrucial in yard operation and maneuvering and industrial automation\napplications. This work introduces several new methods to improve and measure\nthe performance for such classes. State-of-the-art methods are based on\npredefined anchor grids or heatmaps for ground truth targets. However, the\nunderlying representations do not take the shape of different sized objects\ninto account. Our main contribution, AdaptiveShape, uses shape aware anchor\ndistributions and heatmaps to improve the detection capabilities. For large\nvehicles we achieve +10.9% AP in comparison to current shape agnostic methods.\nFurthermore we introduce a new fast LiDAR-camera fusion. It is based on 2D\nbounding box camera detections which are available in many processing\npipelines. This fusion method does not rely on perfectly calibrated or\ntemporally synchronized systems and is therefore applicable to a broad range of\nrobotic applications. We extend a standard point pillar network to account for\ntemporal data and improve learning of complex object movements. In addition we\nextended a ground truth augmentation to use grouped object pairs to further\nimprove truck AP by +2.2% compared to conventional augmentation.\n","authors":["Benjamin Sick","Michael Walter","Jochen Abhau"],"pdf_url":"https://arxiv.org/pdf/2302.14522v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.09489v5","updated":"2023-02-28T12:15:46Z","published":"2022-09-20T06:02:57Z","title":"Perceptual Quality Assessment for Digital Human Heads","summary":"  Digital humans are attracting more and more research interest during the last\ndecade, the generation, representation, rendering, and animation of which have\nbeen put into large amounts of effort. However, the quality assessment of\ndigital humans has fallen behind. Therefore, to tackle the challenge of digital\nhuman quality assessment issues, we propose the first large-scale quality\nassessment database for three-dimensional (3D) scanned digital human heads\n(DHHs). The constructed database consists of 55 reference DHHs and 1,540\ndistorted DHHs along with the subjective perceptual ratings. Then, a simple yet\neffective full-reference (FR) projection-based method is proposed to evaluate\nthe visual quality of DHHs. The pretrained Swin Transformer tiny is employed\nfor hierarchical feature extraction and the multi-head attention module is\nutilized for feature fusion. The experimental results reveal that the proposed\nmethod exhibits state-of-the-art performance among the mainstream FR metrics.\nThe database is released at https://github.com/zzc-1998/DHHQA.\n","authors":["Zicheng Zhang","Yingjie Zhou","Wei Sun","Xiongkuo Min","Yuzhe Wu","Guangtao Zhai"],"pdf_url":"https://arxiv.org/pdf/2209.09489v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14511v1","updated":"2023-02-28T12:01:16Z","published":"2023-02-28T12:01:16Z","title":"A Unified BEV Model for Joint Learning of 3D Local Features and Overlap\n  Estimation","summary":"  Pairwise point cloud registration is a critical task for many applications,\nwhich heavily depends on finding the right correspondences from the two point\nclouds. However, the low overlap between the input point clouds makes the\nregistration prone to fail, leading to mistaken overlapping and mismatched\ncorrespondences, especially in scenes where non-overlapping regions contain\nsimilar structures. In this paper, we present a unified bird's-eye view (BEV)\nmodel for jointly learning of 3D local features and overlap estimation to\nfulfill the pairwise registration and loop closure. Feature description based\non BEV representation is performed by a sparse UNet-like network, and the 3D\nkeypoints are extracted by a detection head for 2D locations and a regression\nhead for heights, respectively. For overlap detection, a cross-attention module\nis applied for interacting contextual information of the input point clouds,\nfollowed by a classification head to estimate the overlapping region. We\nevaluate our unified model extensively on the KITTI dataset and Apollo-SouthBay\ndataset. The experiments demonstrate that our method significantly outperforms\nexisting methods on overlap prediction, especially in scenes with small\noverlaps. The registration precision also achieves top performance on both\ndatasets in terms of translation and rotation errors. Source codes will be\navailable soon.\n","authors":["Lin Li","Wendong Ding","Yongkun Wen","Yufei Liang","Yong Liu","Guowei Wan"],"pdf_url":"https://arxiv.org/pdf/2302.14511v1.pdf","comment":"8 pages. Accepted by ICRA-2023"},{"id":"http://arxiv.org/abs/2302.14503v1","updated":"2023-02-28T11:34:55Z","published":"2023-02-28T11:34:55Z","title":"Can We Use Diffusion Probabilistic Models for 3D Motion Prediction?","summary":"  After many researchers observed fruitfulness from the recent diffusion\nprobabilistic model, its effectiveness in image generation is actively studied\nthese days. In this paper, our objective is to evaluate the potential of\ndiffusion probabilistic models for 3D human motion-related tasks. To this end,\nthis paper presents a study of employing diffusion probabilistic models to\npredict future 3D human motion(s) from the previously observed motion. Based on\nthe Human 3.6M and HumanEva-I datasets, our results show that diffusion\nprobabilistic models are competitive for both single (deterministic) and\nmultiple (stochastic) 3D motion prediction tasks, after finishing a single\ntraining process. In addition, we find out that diffusion probabilistic models\ncan offer an attractive compromise, since they can strike the right balance\nbetween the likelihood and diversity of the predicted future motions. Our code\nis publicly available on the project website:\nhttps://sites.google.com/view/diffusion-motion-prediction.\n","authors":["Hyemin Ahn","Esteve Valls Mascaro","Dongheui Lee"],"pdf_url":"https://arxiv.org/pdf/2302.14503v1.pdf","comment":"7 pages, 3 figures, ICRA 2023"},{"id":"http://arxiv.org/abs/2112.02500v4","updated":"2023-02-28T11:19:31Z","published":"2021-12-05T07:38:53Z","title":"MovieNet-PS: A Large-Scale Person Search Dataset in the Wild","summary":"  Person search aims to jointly localize and identify a query person from\nnatural, uncropped images, which has been actively studied over the past few\nyears. In this paper, we delve into the rich context information globally and\nlocally surrounding the target person, which we refer to as scene and group\ncontext, respectively. Unlike previous works that treat the two types of\ncontext individually, we exploit them in a unified global-local context network\n(GLCNet) with the intuitive aim of feature enhancement. Specifically, re-ID\nembeddings and context features are simultaneously learned in a multi-stage\nfashion, ultimately leading to enhanced, discriminative features for person\nsearch. We conduct the experiments on two person search benchmarks (i.e.,\nCUHK-SYSU and PRW) as well as extend our approach to a more challenging setting\n(i.e., character search on MovieNet). Extensive experimental results\ndemonstrate the consistent improvement of the proposed GLCNet over the\nstate-of-the-art methods on all three datasets. Our source codes, pre-trained\nmodels, and the new dataset are publicly available at:\nhttps://github.com/ZhengPeng7/GLCNet.\n","authors":["Jie Qin","Peng Zheng","Yichao Yan","Rong Quan","Xiaogang Cheng","Bingbing Ni"],"pdf_url":"https://arxiv.org/pdf/2112.02500v4.pdf","comment":"ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.14490v1","updated":"2023-02-28T11:03:08Z","published":"2023-02-28T11:03:08Z","title":"Estimating Head Motion from MR-Images","summary":"  Head motion is an omnipresent confounder of magnetic resonance image (MRI)\nanalyses as it systematically affects morphometric measurements, even when\nvisual quality control is performed. In order to estimate subtle head motion,\nthat remains undetected by experts, we introduce a deep learning method to\npredict in-scanner head motion directly from T1-weighted (T1w), T2-weighted\n(T2w) and fluid-attenuated inversion recovery (FLAIR) images using motion\nestimates from an in-scanner depth camera as ground truth. Since we work with\ndata from compliant healthy participants of the Rhineland Study, head motion\nand resulting imaging artifacts are less prevalent than in most clinical\ncohorts and more difficult to detect. Our method demonstrates improved\nperformance compared to state-of-the-art motion estimation methods and can\nquantify drift and respiration movement independently. Finally, on unseen data,\nour predictions preserve the known, significant correlation with age.\n","authors":["Clemens Pollak","David Kügler","Martin Reuter"],"pdf_url":"https://arxiv.org/pdf/2302.14490v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14487v1","updated":"2023-02-28T11:00:55Z","published":"2023-02-28T11:00:55Z","title":"Enhancing Classification with Hierarchical Scalable Query on Fusion\n  Transformer","summary":"  Real-world vision based applications require fine-grained classification for\nvarious area of interest like e-commerce, mobile applications, warehouse\nmanagement, etc. where reducing the severity of mistakes and improving the\nclassification accuracy is of utmost importance. This paper proposes a method\nto boost fine-grained classification through a hierarchical approach via\nlearnable independent query embeddings. This is achieved through a\nclassification network that uses coarse class predictions to improve the fine\nclass accuracy in a stage-wise sequential manner. We exploit the idea of\nhierarchy to learn query embeddings that are scalable across all levels, thus\nmaking this a relevant approach even for extreme classification where we have a\nlarge number of classes. The query is initialized with a weighted Eigen image\ncalculated from training samples to best represent and capture the variance of\nthe object. We introduce transformer blocks to fuse intermediate layers at\nwhich query attention happens to enhance the spatial representation of feature\nmaps at different scales. This multi-scale fusion helps improve the accuracy of\nsmall-size objects. We propose a two-fold approach for the unique\nrepresentation of learnable queries. First, at each hierarchical level, we\nleverage cluster based loss that ensures maximum separation between inter-class\nquery embeddings and helps learn a better (query) representation in higher\ndimensional spaces. Second, we fuse coarse level queries with finer level\nqueries weighted by a learned scale factor. We additionally introduce a novel\nblock called Cross Attention on Multi-level queries with Prior (CAMP) Block\nthat helps reduce error propagation from coarse level to finer level, which is\na common problem in all hierarchical classifiers. Our method is able to\noutperform the existing methods with an improvement of ~11% at the fine-grained\nclassification.\n","authors":["Sudeep Kumar Sahoo","Sathish Chalasani","Abhishek Joshi","Kiran Nanjunda Iyer"],"pdf_url":"https://arxiv.org/pdf/2302.14487v1.pdf","comment":"6 pages, 7 figures Published in IEEE ICCE 2023"},{"id":"http://arxiv.org/abs/2302.14486v1","updated":"2023-02-28T11:00:13Z","published":"2023-02-28T11:00:13Z","title":"TrainSim: A Railway Simulation Framework for LiDAR and Camera Dataset\n  Generation","summary":"  The railway industry is searching for new ways to automate a number of\ncomplex train functions, such as object detection, track discrimination, and\naccurate train positioning, which require the artificial perception of the\nrailway environment through different types of sensors, including cameras,\nLiDARs, wheel encoders, and inertial measurement units. A promising approach\nfor processing such sensory data is the use of deep learning models, which\nproved to achieve excellent performance in other application domains, as\nrobotics and self-driving cars. However, testing new algorithms and solutions\nrequires the availability of a large amount of labeled data, acquired in\ndifferent scenarios and operating conditions, which are difficult to obtain in\na real railway setting due to strict regulations and practical constraints in\naccessing the trackside infrastructure and equipping a train with the required\nsensors. To address such difficulties, this paper presents a visual simulation\nframework able to generate realistic railway scenarios in a virtual environment\nand automatically produce inertial data and labeled datasets from emulated\nLiDARs and cameras useful for training deep neural networks or testing\ninnovative algorithms. A set of experimental results are reported to show the\neffectiveness of the proposed approach.\n","authors":["Gianluca D'Amico","Mauro Marinoni","Federico Nesti","Giulio Rossolini","Giorgio Buttazzo","Salvatore Sabina","Gianluigi Lauro"],"pdf_url":"https://arxiv.org/pdf/2302.14486v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2302.14485v1","updated":"2023-02-28T10:58:01Z","published":"2023-02-28T10:58:01Z","title":"Memory-aided Contrastive Consensus Learning for Co-salient Object\n  Detection","summary":"  Co-Salient Object Detection (CoSOD) aims at detecting common salient objects\nwithin a group of relevant source images. Most of the latest works employ the\nattention mechanism for finding common objects. To achieve accurate CoSOD\nresults with high-quality maps and high efficiency, we propose a novel\nMemory-aided Contrastive Consensus Learning (MCCL) framework, which is capable\nof effectively detecting co-salient objects in real time (~110 fps). To learn\nbetter group consensus, we propose the Group Consensus Aggregation Module\n(GCAM) to abstract the common features of each image group; meanwhile, to make\nthe consensus representation more discriminative, we introduce the Memory-based\nContrastive Module (MCM), which saves and updates the consensus of images from\ndifferent groups in a queue of memories. Finally, to improve the quality and\nintegrity of the predicted maps, we develop an Adversarial Integrity Learning\n(AIL) strategy to make the segmented regions more likely composed of complete\nobjects with less surrounding noise. Extensive experiments on all the latest\nCoSOD benchmarks demonstrate that our lite MCCL outperforms 13 cutting-edge\nmodels, achieving the new state of the art (~5.9% and ~6.2% improvement in\nS-measure on CoSOD3k and CoSal2015, respectively). Our source codes, saliency\nmaps, and online demos are publicly available at\nhttps://github.com/ZhengPeng7/MCCL.\n","authors":["Peng Zheng","Jie Qin","Shuo Wang","Tian-Zhu Xiang","Huan Xiong"],"pdf_url":"https://arxiv.org/pdf/2302.14485v1.pdf","comment":"AAAI 2023"},{"id":"http://arxiv.org/abs/2302.14483v1","updated":"2023-02-28T10:54:36Z","published":"2023-02-28T10:54:36Z","title":"RoPAWS: Robust Semi-supervised Representation Learning from Uncurated\n  Data","summary":"  Semi-supervised learning aims to train a model using limited labels.\nState-of-the-art semi-supervised methods for image classification such as PAWS\nrely on self-supervised representations learned with large-scale unlabeled but\ncurated data. However, PAWS is often less effective when using real-world\nunlabeled data that is uncurated, e.g., contains out-of-class data. We propose\nRoPAWS, a robust extension of PAWS that can work with real-world unlabeled\ndata. We first reinterpret PAWS as a generative classifier that models\ndensities using kernel density estimation. From this probabilistic perspective,\nwe calibrate its prediction based on the densities of labeled and unlabeled\ndata, which leads to a simple closed-form solution from the Bayes' rule. We\ndemonstrate that RoPAWS significantly improves PAWS for uncurated Semi-iNat by\n+5.3% and curated ImageNet by +0.4%.\n","authors":["Sangwoo Mo","Jong-Chyi Su","Chih-Yao Ma","Mido Assran","Ishan Misra","Licheng Yu","Sean Bell"],"pdf_url":"https://arxiv.org/pdf/2302.14483v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2209.07734v2","updated":"2023-02-28T10:44:34Z","published":"2022-09-16T06:15:26Z","title":"CenterLineDet: CenterLine Graph Detection for Road Lanes with\n  Vehicle-mounted Sensors by Transformer for HD Map Generation","summary":"  With the fast development of autonomous driving technologies, there is an\nincreasing demand for high-definition (HD) maps, which provide reliable and\nrobust prior information about the static part of the traffic environments. As\none of the important elements in HD maps, road lane centerline is critical for\ndownstream tasks, such as prediction and planning. Manually annotating\ncenterlines for road lanes in HD maps is labor-intensive, expensive and\ninefficient, severely restricting the wide applications of autonomous driving\nsystems. Previous work seldom explores the lane centerline detection problem\ndue to the complicated topology and severe overlapping issues of lane\ncenterlines. In this paper, we propose a novel method named CenterLineDet to\ndetect lane centerlines for automatic HD map generation. Our CenterLineDet is\ntrained by imitation learning and can effectively detect the graph of\ncenterlines with vehicle-mounted sensors (i.e., six cameras and one LiDAR)\nthrough iterations. Due to the use of the DETR-like transformer network,\nCenterLineDet can handle complicated graph topology, such as lane\nintersections. The proposed approach is evaluated on the large-scale public\ndataset NuScenes. The superiority of our CenterLineDet is demonstrated by the\ncomparative results. Our code, supplementary materials, and video\ndemonstrations are available at\n\\href{https://tonyxuqaq.github.io/projects/CenterLineDet/}{https://tonyxuqaq.github.io/projects/CenterLineDet/}.\n","authors":["Zhenhua Xu","Yuxuan Liu","Yuxiang Sun","Ming Liu","Lujia Wang"],"pdf_url":"https://arxiv.org/pdf/2209.07734v2.pdf","comment":"ICRA 2023"},{"id":"http://arxiv.org/abs/2302.14475v1","updated":"2023-02-28T10:34:44Z","published":"2023-02-28T10:34:44Z","title":"Benchmarking Deepart Detection","summary":"  Deepfake technologies have been blurring the boundaries between the real and\nunreal, likely resulting in malicious events. By leveraging newly emerged\ndeepfake technologies, deepfake researchers have been making a great upending\nto create deepfake artworks (deeparts), which are further closing the gap\nbetween reality and fantasy. To address potentially appeared ethics questions,\nthis paper establishes a deepart detection database (DDDB) that consists of a\nset of high-quality conventional art images (conarts) and five sets of deepart\nimages generated by five state-of-the-art deepfake models. This database\nenables us to explore once-for-all deepart detection and continual deepart\ndetection. For the two new problems, we suggest four benchmark evaluations and\nfour families of solutions on the constructed DDDB. The comprehensive study\ndemonstrates the effectiveness of the proposed solutions on the established\nbenchmark dataset, which is capable of paving a way to more interesting\ndirections of deepart detection. The constructed benchmark dataset and the\nsource code will be made publicly available.\n","authors":["Yabin Wang","Zhiwu Huang","Xiaopeng Hong"],"pdf_url":"https://arxiv.org/pdf/2302.14475v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14470v1","updated":"2023-02-28T10:26:02Z","published":"2023-02-28T10:26:02Z","title":"Learning to Estimate Single-View Volumetric Flow Motions without 3D\n  Supervision","summary":"  We address the challenging problem of jointly inferring the 3D flow and\nvolumetric densities moving in a fluid from a monocular input video with a deep\nneural network. Despite the complexity of this task, we show that it is\npossible to train the corresponding networks without requiring any 3D ground\ntruth for training. In the absence of ground truth data we can train our model\nwith observations from real-world capture setups instead of relying on\nsynthetic reconstructions. We make this unsupervised training approach possible\nby first generating an initial prototype volume which is then moved and\ntransported over time without the need for volumetric supervision. Our approach\nrelies purely on image-based losses, an adversarial discriminator network, and\nregularization. Our method can estimate long-term sequences in a stable manner,\nwhile achieving closely matching targets for inputs such as rising smoke\nplumes.\n","authors":["Erik Franz","Barbara Solenthaler","Nils Thuerey"],"pdf_url":"https://arxiv.org/pdf/2302.14470v1.pdf","comment":"ICLR 2023 poster, source code:\n  https://github.com/tum-pbs/Neural-Global-Transport"},{"id":"http://arxiv.org/abs/2302.14460v1","updated":"2023-02-28T10:08:11Z","published":"2023-02-28T10:08:11Z","title":"Interpretable and Intervenable Ultrasonography-based Machine Learning\n  Models for Pediatric Appendicitis","summary":"  Appendicitis is among the most frequent reasons for pediatric abdominal\nsurgeries. With recent advances in machine learning, data-driven decision\nsupport could help clinicians diagnose and manage patients while reducing the\nnumber of non-critical surgeries. Previous decision support systems for\nappendicitis focused on clinical, laboratory, scoring and computed tomography\ndata, mainly ignoring abdominal ultrasound, a noninvasive and readily available\ndiagnostic modality. To this end, we developed and validated interpretable\nmachine learning models for predicting the diagnosis, management and severity\nof suspected appendicitis using ultrasound images. Our models were trained on a\ndataset comprising 579 pediatric patients with 1709 ultrasound images\naccompanied by clinical and laboratory data. Our methodological contribution is\nthe generalization of concept bottleneck models to prediction problems with\nmultiple views and incomplete concept sets. Notably, such models lend\nthemselves to interpretation and interaction via high-level concepts\nunderstandable to clinicians without sacrificing performance or requiring\ntime-consuming image annotation when deployed.\n","authors":["Ričards Marcinkevičs","Patricia Reis Wolfertstetter","Ugne Klimiene","Ece Ozkan","Kieran Chin-Cheong","Alyssia Paschke","Julia Zerres","Markus Denzinger","David Niederberger","Sven Wellmann","Christian Knorr","Julia E. Vogt"],"pdf_url":"https://arxiv.org/pdf/2302.14460v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14452v1","updated":"2023-02-28T09:56:45Z","published":"2023-02-28T09:56:45Z","title":"An Effective Crop-Paste Pipeline for Few-shot Object Detection","summary":"  Few-shot object detection (FSOD) aims to expand an object detector for novel\ncategories given only a few instances for training. However, detecting novel\ncategories with only a few samples usually leads to the problem of\nmisclassification. In FSOD, we notice the false positive (FP) of novel\ncategories is prominent, in which the base categories are often recognized as\nnovel ones. To address this issue, a novel data augmentation pipeline that\nCrops the Novel instances and Pastes them on the selected Base images, called\nCNPB, is proposed. There are two key questions to be answered: (1) How to\nselect useful base images? and (2) How to combine novel and base data? We\ndesign a multi-step selection strategy to find useful base data. Specifically,\nwe first discover the base images which contain the FP of novel categories and\nselect a certain amount of samples from them for the base and novel categories\nbalance. Then the bad cases, such as the base images that have unlabeled ground\ntruth or easily confused base instances, are removed by using CLIP. Finally,\nthe same category strategy is adopted, in which a novel instance with category\nn is pasted on the base image with the FP of n. During combination, a novel\ninstance is cropped and randomly down-sized, and thus pasted at the assigned\noptimal location from the randomly generated candidates in a selected base\nimage. Our method is simple yet effective and can be easy to plug into existing\nFSOD methods, demonstrating significant potential for use. Extensive\nexperiments on PASCAL VOC and MS COCO validate the effectiveness of our method.\n","authors":["Shaobo Lin","Kun Wang","Xingyu Zeng","Rui Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.14452v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.05278v3","updated":"2023-02-28T09:56:20Z","published":"2022-04-11T17:29:36Z","title":"Negligible effect of brain MRI data preprocessing for tumor segmentation","summary":"  Magnetic resonance imaging (MRI) data is heterogeneous due to differences in\ndevice manufacturers, scanning protocols, and inter-subject variability. A\nconventional way to mitigate MR image heterogeneity is to apply preprocessing\ntransformations such as anatomy alignment, voxel resampling, signal intensity\nequalization, image denoising, and localization of regions of interest.\nAlthough a preprocessing pipeline standardizes image appearance, its influence\non the quality of image segmentation and on other downstream tasks in deep\nneural networks has never been rigorously studied.\n  We conduct experiments on three publicly available datasets and evaluate the\neffect of different preprocessing steps in intra- and inter-dataset training\nscenarios. Our results demonstrate that most popular standardization steps add\nno value to the network performance; moreover, preprocessing can hamper model\nperformance. We suggest that image intensity normalization approaches do not\ncontribute to model accuracy because of the reduction of signal variance with\nimage standardization. Finally, we show that the contribution of\nskull-stripping in data preprocessing is almost negligible if measured in terms\nof estimated tumor volume.\n  We show that the only essential transformation for accurate deep learning\nanalysis is the unification of voxel spacing across the dataset. In contrast,\ninter-subjects anatomy alignment in the form of non-rigid atlas registration is\nnot necessary and intensity equalization steps (denoising, bias-field\ncorrection and histogram matching) do not improve models' performance. The\nstudy code is accessible online\n\\footnote{https://github.com/MedImAIR/brain-mri-processing-pipeline}.\n","authors":["Ekaterina Kondrateva","Polina Druzhinina","Alexandra Dalechina","Svetlana Zolotova","Andrey Golanov","Boris Shirokikh","Mikhail Belyaev","Anvar Kurmukov"],"pdf_url":"https://arxiv.org/pdf/2204.05278v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14450v1","updated":"2023-02-28T09:54:53Z","published":"2023-02-28T09:54:53Z","title":"Swin Deformable Attention Hybrid U-Net for Medical Image Segmentation","summary":"  How to harmonize convolution and multi-head self-attention mechanisms has\nrecently emerged as a significant area of research in the field of medical\nimage segmentation. Various combination methods have been proposed. However,\nthere is a common flaw in these works: failed to provide a direct explanation\nfor their hybrid model, which is crucial in clinical scenarios. Deformable\nAttention can improve the segmentation performance and provide an explanation\nbased on the deformation field. Incorporating Deformable Attention into a\nhybrid model could result in a synergistic effect to boost segmentation\nperformance while enhancing the explainability. In this study, we propose the\nincorporation of Swin Deformable Attention with hybrid architecture to improve\nthe segmentation performance while establishing explainability. In the\nexperiment section, our proposed Swin Deformable Attention Hybrid UNet\n(SDAH-UNet) demonstrates state-of-the-art performance on both anatomical and\nlesion segmentation tasks.\n","authors":["Lichao Wang","Jiahao Huang","Guang Yang"],"pdf_url":"https://arxiv.org/pdf/2302.14450v1.pdf","comment":"10 pages, 5 figures, conference"},{"id":"http://arxiv.org/abs/2302.14444v1","updated":"2023-02-28T09:42:39Z","published":"2023-02-28T09:42:39Z","title":"Learning to Estimate Two Dense Depths from LiDAR and Event Data","summary":"  Event cameras do not produce images, but rather a continuous flow of events,\nwhich encode changes of illumination for each pixel independently and\nasynchronously. While they output temporally rich information, they lack any\ndepth information which could facilitate their use with other sensors. LiDARs\ncan provide this depth information, but are by nature very sparse, which makes\nthe depth-to-event association more complex. Furthermore, as events represent\nchanges of illumination, they might also represent changes of depth;\nassociating them with a single depth is therefore inadequate. In this work, we\npropose to address these issues by fusing information from an event camera and\na LiDAR using a learning-based approach to estimate accurate dense depth maps.\nTo solve the \"potential change of depth\" problem, we propose here to estimate\ntwo depth maps at each step: one \"before\" the events happen, and one \"after\"\nthe events happen. We further propose to use this pair of depths to compute a\ndepth difference for each event, to give them more context. We train and\nevaluate our network, ALED, on both synthetic and real driving sequences, and\nshow that it is able to predict dense depths with an error reduction of up to\n61% compared to the current state of the art. We also demonstrate the quality\nof our 2-depths-to-event association, and the usefulness of the depth\ndifference information. Finally, we release SLED, a novel synthetic dataset\ncomprising events, LiDAR point clouds, RGB images, and dense depth maps.\n","authors":["Vincent Brebion","Julien Moreau","Franck Davoine"],"pdf_url":"https://arxiv.org/pdf/2302.14444v1.pdf","comment":"Accepted for SCIA 2023. For the project page, see\n  https://vbrebion.github.io/ALED/"},{"id":"http://arxiv.org/abs/2104.12623v2","updated":"2023-02-28T09:37:59Z","published":"2021-04-26T14:50:59Z","title":"Good Artists Copy, Great Artists Steal: Model Extraction Attacks Against\n  Image Translation Models","summary":"  Machine learning models are typically made available to potential client\nusers via inference APIs. Model extraction attacks occur when a malicious\nclient uses information gleaned from queries to the inference API of a victim\nmodel $F_V$ to build a surrogate model $F_A$ with comparable functionality.\nRecent research has shown successful model extraction of image classification,\nand natural language processing models. In this paper, we show the first model\nextraction attack against real-world generative adversarial network (GAN) image\ntranslation models. We present a framework for conducting such attacks, and\nshow that an adversary can successfully extract functional surrogate models by\nquerying $F_V$ using data from the same domain as the training data for $F_V$.\nThe adversary need not know $F_V$'s architecture or any other information about\nit beyond its intended task. We evaluate the effectiveness of our attacks using\nthree different instances of two popular categories of image translation: (1)\nSelfie-to-Anime and (2) Monet-to-Photo (image style transfer), and (3)\nSuper-Resolution (super resolution). Using standard performance metrics for\nGANs, we show that our attacks are effective. Furthermore, we conducted a large\nscale (125 participants) user study on Selfie-to-Anime and Monet-to-Photo to\nshow that human perception of the images produced by $F_V$ and $F_A$ can be\nconsidered equivalent, within an equivalence bound of Cohen's d = 0.3. Finally,\nwe show that existing defenses against model extraction attacks (watermarking,\nadversarial examples, poisoning) do not extend to image translation models.\n","authors":["Sebastian Szyller","Vasisht Duddu","Tommi Gröndahl","N. Asokan"],"pdf_url":"https://arxiv.org/pdf/2104.12623v2.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2302.14435v1","updated":"2023-02-28T09:25:37Z","published":"2023-02-28T09:25:37Z","title":"ProxyFormer: Proxy Alignment Assisted Point Cloud Completion with\n  Missing Part Sensitive Transformer","summary":"  Problems such as equipment defects or limited viewpoints will lead the\ncaptured point clouds to be incomplete. Therefore, recovering the complete\npoint clouds from the partial ones plays an vital role in many practical tasks,\nand one of the keys lies in the prediction of the missing part. In this paper,\nwe propose a novel point cloud completion approach namely ProxyFormer that\ndivides point clouds into existing (input) and missing (to be predicted) parts\nand each part communicates information through its proxies. Specifically, we\nfuse information into point proxy via feature and position extractor, and\ngenerate features for missing point proxies from the features of existing point\nproxies. Then, in order to better perceive the position of missing points, we\ndesign a missing part sensitive transformer, which converts random normal\ndistribution into reasonable position information, and uses proxy alignment to\nrefine the missing proxies. It makes the predicted point proxies more sensitive\nto the features and positions of the missing part, and thus make these proxies\nmore suitable for subsequent coarse-to-fine processes. Experimental results\nshow that our method outperforms state-of-the-art completion networks on\nseveral benchmark datasets and has the fastest inference speed. Code is\navailable at https://github.com/I2-Multimedia-Lab/ProxyFormer.\n","authors":["Shanshan Li","Pan Gao","Xiaoyang Tan","Mingqiang Wei"],"pdf_url":"https://arxiv.org/pdf/2302.14435v1.pdf","comment":"Accepted by CVPR2023"},{"id":"http://arxiv.org/abs/2302.14434v1","updated":"2023-02-28T09:24:36Z","published":"2023-02-28T09:24:36Z","title":"A Hierarchical Representation Network for Accurate and Detailed Face\n  Reconstruction from In-The-Wild Images","summary":"  Limited by the nature of the low-dimensional representational capacity of\n3DMM, most of the 3DMM-based face reconstruction (FR) methods fail to recover\nhigh-frequency facial details, such as wrinkles, dimples, etc. Some attempt to\nsolve the problem by introducing detail maps or non-linear operations, however,\nthe results are still not vivid. To this end, we in this paper present a novel\nhierarchical representation network (HRN) to achieve accurate and detailed face\nreconstruction from a single image. Specifically, we implement the geometry\ndisentanglement and introduce the hierarchical representation to fulfill\ndetailed face modeling. Meanwhile, 3D priors of facial details are incorporated\nto enhance the accuracy and authenticity of the reconstruction results. We also\npropose a de-retouching module to achieve better decoupling of the geometry and\nappearance. It is noteworthy that our framework can be extended to a multi-view\nfashion by considering detail consistency of different views. Extensive\nexperiments on two single-view and two multi-view FR benchmarks demonstrate\nthat our method outperforms the existing methods in both reconstruction\naccuracy and visual effects. Finally, we introduce a high-quality 3D face\ndataset FaceHD-100 to boost the research of high-fidelity face reconstruction.\n","authors":["Biwen Lei","Jianqiang Ren","Mengyang Feng","Miaomiao Cui","Xuansong Xie"],"pdf_url":"https://arxiv.org/pdf/2302.14434v1.pdf","comment":"Accepted by CVPR2023"},{"id":"http://arxiv.org/abs/2302.14431v1","updated":"2023-02-28T09:21:12Z","published":"2023-02-28T09:21:12Z","title":"Efficient Masked Autoencoders with Self-Consistency","summary":"  Inspired by masked language modeling (MLM) in natural language processing,\nmasked image modeling (MIM) has been recognized as a strong and popular\nself-supervised pre-training method in computer vision. However, its high\nrandom mask ratio would result in two serious problems: 1) the data are not\nefficiently exploited, which brings inefficient pre-training (\\eg, 1600 epochs\nfor MAE $vs.$ 300 epochs for the supervised), and 2) the high uncertainty and\ninconsistency of the pre-trained model, \\ie, the prediction of the same patch\nmay be inconsistent under different mask rounds. To tackle these problems, we\npropose efficient masked autoencoders with self-consistency (EMAE), to improve\nthe pre-training efficiency and increase the consistency of MIM. In particular,\nwe progressively divide the image into K non-overlapping parts, each of which\nis generated by a random mask and has the same mask ratio. Then the MIM task is\nconducted parallelly on all parts in an iteration and generates predictions.\nBesides, we design a self-consistency module to further maintain the\nconsistency of predictions of overlapping masked patches among parts. Overall,\nthe proposed method is able to exploit the data more efficiently and obtains\nreliable representations. Experiments on ImageNet show that EMAE achieves even\nhigher results with only 300 pre-training epochs under ViT-Base than MAE (1600\nepochs). EMAE also consistently obtains state-of-the-art transfer performance\non various downstream tasks, like object detection, and semantic segmentation.\n","authors":["Zhaowen Li","Yousong Zhu","Zhiyang Chen","Wei Li","Chaoyang Zhao","Liwei Wu","Rui Zhao","Ming Tang","Jinqiao Wang"],"pdf_url":"https://arxiv.org/pdf/2302.14431v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14430v1","updated":"2023-02-28T09:18:48Z","published":"2023-02-28T09:18:48Z","title":"Tracking Fast by Learning Slow: An Event-based Speed Adaptive Hand\n  Tracker Leveraging Knowledge in RGB Domain","summary":"  3D hand tracking methods based on monocular RGB videos are easily affected by\nmotion blur, while event camera, a sensor with high temporal resolution and\ndynamic range, is naturally suitable for this task with sparse output and low\npower consumption. However, obtaining 3D annotations of fast-moving hands is\ndifficult for constructing event-based hand-tracking datasets. In this paper,\nwe provided an event-based speed adaptive hand tracker (ESAHT) to solve the\nhand tracking problem based on event camera. We enabled a CNN model trained on\na hand tracking dataset with slow motion, which enabled the model to leverage\nthe knowledge of RGB-based hand tracking solutions, to work on fast hand\ntracking tasks. To realize our solution, we constructed the first 3D hand\ntracking dataset captured by an event camera in a real-world environment,\nfigured out two data augment methods to narrow the domain gap between slow and\nfast motion data, developed a speed adaptive event stream segmentation method\nto handle hand movements in different moving speeds, and introduced a new\nevent-to-frame representation method adaptive to event streams with different\nlengths. Experiments showed that our solution outperformed RGB-based as well as\nprevious event-based solutions in fast hand tracking tasks, and our codes and\ndataset will be publicly available.\n","authors":["Chuanlin Lan","Ziyuan Yin","Arindam Basu","Rosa H. M. Chan"],"pdf_url":"https://arxiv.org/pdf/2302.14430v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08377v2","updated":"2023-02-28T09:00:33Z","published":"2022-12-16T10:05:31Z","title":"PointAvatar: Deformable Point-based Head Avatars from Videos","summary":"  The ability to create realistic, animatable and relightable head avatars from\ncasual video sequences would open up wide ranging applications in communication\nand entertainment. Current methods either build on explicit 3D morphable meshes\n(3DMM) or exploit neural implicit representations. The former are limited by\nfixed topology, while the latter are non-trivial to deform and inefficient to\nrender. Furthermore, existing approaches entangle lighting in the color\nestimation, thus they are limited in re-rendering the avatar in new\nenvironments. In contrast, we propose PointAvatar, a deformable point-based\nrepresentation that disentangles the source color into intrinsic albedo and\nnormal-dependent shading. We demonstrate that PointAvatar bridges the gap\nbetween existing mesh- and implicit representations, combining high-quality\ngeometry and appearance with topological flexibility, ease of deformation and\nrendering efficiency. We show that our method is able to generate animatable 3D\navatars using monocular videos from multiple sources including hand-held\nsmartphones, laptop webcams and internet videos, achieving state-of-the-art\nquality in challenging cases where previous methods fail, e.g., thin hair\nstrands, while being significantly more efficient in training than competing\nmethods.\n","authors":["Yufeng Zheng","Wang Yifan","Gordon Wetzstein","Michael J. Black","Otmar Hilliges"],"pdf_url":"https://arxiv.org/pdf/2212.08377v2.pdf","comment":"Project page: https://zhengyuf.github.io/PointAvatar/ Code base:\n  https://github.com/zhengyuf/pointavatar"},{"id":"http://arxiv.org/abs/2211.15166v2","updated":"2023-02-28T08:57:52Z","published":"2022-11-28T09:21:47Z","title":"Toward Global Sensing Quality Maximization: A Configuration Optimization\n  Scheme for Camera Networks","summary":"  The performance of a camera network monitoring a set of targets depends\ncrucially on the configuration of the cameras. In this paper, we investigate\nthe reconfiguration strategy for the parameterized camera network model, with\nwhich the sensing qualities of the multiple targets can be optimized globally\nand simultaneously. We first propose to use the number of pixels occupied by a\nunit-length object in image as a metric of the sensing quality of the object,\nwhich is determined by the parameters of the camera, such as intrinsic,\nextrinsic, and distortional coefficients. Then, we form a single quantity that\nmeasures the sensing quality of the targets by the camera network. This\nquantity further serves as the objective function of our optimization problem\nto obtain the optimal camera configuration. We verify the effectiveness of our\napproach through extensive simulations and experiments, and the results reveal\nits improved performance on the AprilTag detection tasks. Codes and related\nutilities for this work are open-sourced and available at\nhttps://github.com/sszxc/MultiCam-Simulation.\n","authors":["Xuechao Zhang","Xuda Ding","Yi Ren","Yu Zheng","Chongrong Fang","Jianping He"],"pdf_url":"https://arxiv.org/pdf/2211.15166v2.pdf","comment":"The 2022 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS 2022)"},{"id":"http://arxiv.org/abs/2302.14418v1","updated":"2023-02-28T08:50:17Z","published":"2023-02-28T08:50:17Z","title":"PCR-CG: Point Cloud Registration via Deep Color and Geometry","summary":"  In this paper, we introduce PCR-CG: a novel 3D point cloud registration\nmodule explicitly embedding the color signals into the geometry representation.\nDifferent from previous methods that only use geometry representation, our\nmodule is specifically designed to effectively correlate color into geometry\nfor the point cloud registration task. Our key contribution is a 2D-3D\ncross-modality learning algorithm that embeds the deep features learned from\ncolor signals to the geometry representation. With our designed 2D-3D\nprojection module, the pixel features in a square region centered at\ncorrespondences perceived from images are effectively correlated with point\nclouds. In this way, the overlapped regions can be inferred not only from point\ncloud but also from the texture appearances. Adding color is non-trivial. We\ncompare against a variety of baselines designed for adding color to 3D, such as\nexhaustively adding per-pixel features or RGB values in an implicit manner. We\nleverage Predator [25] as the baseline method and incorporate our proposed\nmodule onto it. To validate the effectiveness of 2D features, we ablate\ndifferent 2D pre-trained networks and show a positive correlation between the\npre-trained weights and the task performance. Our experimental results indicate\na significant improvement of 6.5% registration recall over the baseline method\non the 3DLoMatch benchmark. We additionally evaluate our approach on SOTA\nmethods and observe consistent improvements, such as an improvement of 2.4%\nregistration recall over GeoTransformer as well as 3.5% over CoFiNet. Our study\nreveals a significant advantages of correlating explicit deep color features to\nthe point cloud in the registration task.\n","authors":["Yu Zhang","Junle Yu","Xiaolin Huang","Wenhui Zhou","Ji Hou"],"pdf_url":"https://arxiv.org/pdf/2302.14418v1.pdf","comment":"accepted to ECCV2022; code at https://github.com/Gardlin/PCR-CG"},{"id":"http://arxiv.org/abs/2302.14416v1","updated":"2023-02-28T08:48:45Z","published":"2023-02-28T08:48:45Z","title":"DREAM: Efficient Dataset Distillation by Representative Matching","summary":"  Dataset distillation aims to generate small datasets with little information\nloss as large-scale datasets for reducing storage and training costs. Recent\nstate-of-the-art methods mainly constrain the sample generation process by\nmatching synthetic images and the original ones regarding gradients, embedding\ndistributions, or training trajectories. Although there are various matching\nobjectives, currently the method for selecting original images is limited to\nnaive random sampling. We argue that random sampling inevitably involves\nsamples near the decision boundaries, which may provide large or noisy matching\ntargets. Besides, random sampling cannot guarantee the evenness and diversity\nof the sample distribution. These factors together lead to large optimization\noscillations and degrade the matching efficiency. Accordingly, we propose a\nnovel matching strategy named as \\textbf{D}ataset distillation by\n\\textbf{RE}present\\textbf{A}tive \\textbf{M}atching (DREAM), where only\nrepresentative original images are selected for matching. DREAM is able to be\neasily plugged into popular dataset distillation frameworks and reduce the\nmatching iterations by 10 times without performance drop. Given sufficient\ntraining time, DREAM further provides significant improvements and achieves\nstate-of-the-art performances.\n","authors":["Yanqing Liu","Jianyang Gu","Kai Wang","Zheng Zhu","Wei Jiang","Yang You"],"pdf_url":"https://arxiv.org/pdf/2302.14416v1.pdf","comment":"Efficient matching for dataset distillation"},{"id":"http://arxiv.org/abs/2302.14415v1","updated":"2023-02-28T08:47:53Z","published":"2023-02-28T08:47:53Z","title":"Mesh-SORT: Simple and effective of location-wise tracker","summary":"  Multi-object tracking (MOT) raised much attention in recent years because of\nits wide prospect on traffic and person. We found that in most tracking\nscenarios without camera motion, objects move and lost with a certain location\nspecificity. In this paper simple and effective location-wise method is\nproposed for tracking by detection scheme, the experiment shows its potential\nand improvement on the baseline.\n","authors":["ZongTan Li"],"pdf_url":"https://arxiv.org/pdf/2302.14415v1.pdf","comment":"10 pages 16 figs"},{"id":"http://arxiv.org/abs/2302.14409v1","updated":"2023-02-28T08:44:00Z","published":"2023-02-28T08:44:00Z","title":"An Adaptive Method for Camera Attribution under Complex Radial\n  Distortion Corrections","summary":"  Radial correction distortion, applied by in-camera or out-camera\nsoftware/firmware alters the supporting grid of the image so as to hamper\nPRNU-based camera attribution. Existing solutions to deal with this problem try\nto invert/estimate the correction using radial transformations parameterized\nwith few variables in order to restrain the computational load; however, with\never more prevalent complex distortion corrections their performance is\nunsatisfactory. In this paper we propose an adaptive algorithm that by dividing\nthe image into concentric annuli is able to deal with sophisticated corrections\nlike those applied out-camera by third party software like Adobe Lightroom,\nPhotoshop, Gimp and PT-Lens. We also introduce a statistic called cumulative\npeak of correlation energy (CPCE) that allows for an efficient early stopping\nstrategy. Experiments on a large dataset of in-camera and out-camera radially\ncorrected images show that our solution improves the state of the art in terms\nof both accuracy and computational cost.\n","authors":["Andrea Montibeller","Fernando Pérez-González"],"pdf_url":"https://arxiv.org/pdf/2302.14409v1.pdf","comment":"This paper was submitted to IEEE Transactions on Information\n  Forensics & Security the July 28, 2022"},{"id":"http://arxiv.org/abs/2302.14402v1","updated":"2023-02-28T08:35:50Z","published":"2023-02-28T08:35:50Z","title":"Neural Video Compression with Diverse Contexts","summary":"  For any video codecs, the coding efficiency highly relies on whether the\ncurrent signal to be encoded can find the relevant contexts from the previous\nreconstructed signals. Traditional codec has verified more contexts bring\nsubstantial coding gain, but in a time-consuming manner. However, for the\nemerging neural video codec (NVC), its contexts are still limited, leading to\nlow compression ratio. To boost NVC, this paper proposes increasing the context\ndiversity in both temporal and spatial dimensions. First, we guide the model to\nlearn hierarchical quality patterns across frames, which enriches long-term and\nyet high-quality temporal contexts. Furthermore, to tap the potential of\noptical flow-based coding framework, we introduce a group-based offset\ndiversity where the cross-group interaction is proposed for better context\nmining. In addition, this paper also adopts a quadtree-based partition to\nincrease spatial context diversity when encoding the latent representation in\nparallel. Experiments show that our codec obtains 23.5% bitrate saving over\nprevious SOTA NVC. Better yet, our codec has surpassed the under-developing\nnext generation traditional codec/ECM in both RGB and YUV420 colorspaces, in\nterms of PSNR. The codes are at https://github.com/microsoft/DCVC.\n","authors":["Jiahao Li","Bin Li","Yan Lu"],"pdf_url":"https://arxiv.org/pdf/2302.14402v1.pdf","comment":"Accepted by CVPR 2023. Codes are at https://github.com/microsoft/DCVC"},{"id":"http://arxiv.org/abs/2302.14390v1","updated":"2023-02-28T08:17:50Z","published":"2023-02-28T08:17:50Z","title":"Your time series is worth a binary image: machine vision assisted deep\n  framework for time series forecasting","summary":"  Time series forecasting (TSF) has been a challenging research area, and\nvarious models have been developed to address this task. However, almost all\nthese models are trained with numerical time series data, which is not as\neffectively processed by the neural system as visual information. To address\nthis challenge, this paper proposes a novel machine vision assisted deep time\nseries analysis (MV-DTSA) framework. The MV-DTSA framework operates by\nanalyzing time series data in a novel binary machine vision time series metric\nspace, which includes a mapping and an inverse mapping function from the\nnumerical time series space to the binary machine vision space, and a deep\nmachine vision model designed to address the TSF task in the binary space. A\ncomprehensive computational analysis demonstrates that the proposed MV-DTSA\nframework outperforms state-of-the-art deep TSF models, without requiring\nsophisticated data decomposition or model customization. The code for our\nframework is accessible at https://github.com/IkeYang/\nmachine-vision-assisted-deep-time-series-analysis-MV-DTSA-.\n","authors":["Luoxiao Yang","Xinqi Fan","Zijun Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.14390v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14383v1","updated":"2023-02-28T08:11:56Z","published":"2023-02-28T08:11:56Z","title":"Linear Spaces of Meanings: the Compositional Language of VLMs","summary":"  We investigate compositional structures in vector data embeddings from\npre-trained vision-language models (VLMs). Traditionally, compositionality has\nbeen associated with algebraic operations on embeddings of words from a\npre-existing vocabulary. In contrast, we seek to approximate label\nrepresentations from a text encoder as combinations of a smaller set of vectors\nin the embedding space. These vectors can be seen as \"ideal words\" which can be\nused to generate new concepts in an efficient way. We present a theoretical\nframework for understanding linear compositionality, drawing connections with\nmathematical representation theory and previous definitions of disentanglement.\nWe provide theoretical and empirical evidence that ideal words provide good\ncompositional approximations of composite concepts and can be more effective\nthan token-based decompositions of the same concepts.\n","authors":["Matthew Trager","Pramuditha Perera","Luca Zancato","Alessandro Achille","Parminder Bhatia","Bing Xiang","Stefano Soatto"],"pdf_url":"https://arxiv.org/pdf/2302.14383v1.pdf","comment":"24 pages, 4 figures, 4 tables"},{"id":"http://arxiv.org/abs/2301.08915v3","updated":"2023-02-28T07:54:36Z","published":"2023-01-21T08:30:15Z","title":"Improving Deep Regression with Ordinal Entropy","summary":"  In computer vision, it is often observed that formulating regression problems\nas a classification task often yields better performance. We investigate this\ncurious phenomenon and provide a derivation to show that classification, with\nthe cross-entropy loss, outperforms regression with a mean squared error loss\nin its ability to learn high-entropy feature representations. Based on the\nanalysis, we propose an ordinal entropy loss to encourage higher-entropy\nfeature spaces while maintaining ordinal relationships to improve the\nperformance of regression tasks. Experiments on synthetic and real-world\nregression tasks demonstrate the importance and benefits of increasing entropy\nfor regression.\n","authors":["Shihao Zhang","Linlin Yang","Michael Bi Mi","Xiaoxu Zheng","Angela Yao"],"pdf_url":"https://arxiv.org/pdf/2301.08915v3.pdf","comment":"Accepted to ICLR 2023. Project page:\n  https://github.com/needylove/OrdinalEntropy"},{"id":"http://arxiv.org/abs/2302.14368v1","updated":"2023-02-28T07:43:00Z","published":"2023-02-28T07:43:00Z","title":"Towards Enhanced Controllability of Diffusion Models","summary":"  Denoising Diffusion models have shown remarkable capabilities in generating\nrealistic, high-quality and diverse images. However, the extent of\ncontrollability and editability with diffusion models is underexplored relative\nto GANs. Inspired by techniques based on the latent space of GAN models for\nimage manipulation, we propose to train a diffusion model conditioned on two\nlatent codes, a spatial content mask and a flattened style embedding. We rely\non the inductive bias of the progressive denoising process of diffusion models\nto encode pose/layout information in the spatial structure mask and\nsemantic/style information in the style code. We extend the sampling technique\nfrom composable diffusion models to allow for some dependence between\nconditional inputs. This improves the quality of the generations significantly\nwhile also providing control over the amount of guidance from each latent code\nseparately as well as from their joint distribution. To further enhance\ncontrollability, we vary the level of guidance for structure and style latents\nbased on the denoising timestep. We observe more controllability compared to\nexisting methods and show that without explicit training objectives, diffusion\nmodels can be leveraged for effective image manipulation, reference based image\ntranslation and style transfer.\n","authors":["Wonwoong Cho","Hareesh Ravi","Midhun Harikumar","Vinh Khuc","Krishna Kumar Singh","Jingwan Lu","David I. Inouye","Ajinkya Kale"],"pdf_url":"https://arxiv.org/pdf/2302.14368v1.pdf","comment":"28 pages, 26 figures"},{"id":"http://arxiv.org/abs/2302.14365v1","updated":"2023-02-28T07:37:53Z","published":"2023-02-28T07:37:53Z","title":"RemoteTouch: Enhancing Immersive 3D Video Communication with Hand Touch","summary":"  Recent research advance has significantly improved the visual realism of\nimmersive 3D video communication. In this work we present a method to further\nenhance this immersive experience by adding the hand touch capability (\"remote\nhand clapping\"). In our system, each meeting participant sits in front of a\nlarge screen with haptic feedback. The local participant can reach his hand out\nto the screen and perform hand clapping with the remote participant as if the\ntwo participants were only separated by a virtual glass. A key challenge in\nemulating the remote hand touch is the realistic rendering of the participant's\nhand and arm as the hand touches the screen. When the hand is very close to the\nscreen, the RGBD data required for realistic rendering is no longer available.\nTo tackle this challenge, we present a dual representation of the user's hand.\nOur dual representation not only preserves the high-quality rendering usually\nfound in recent image-based rendering systems but also allows the hand to reach\nthe screen. This is possible because the dual representation includes both an\nimage-based model and a 3D geometry-based model, with the latter driven by a\nhand skeleton tracked by a side view camera. In addition, the dual\nrepresentation provides a distance-based fusion of the image-based and 3D\ngeometry-based models as the hand moves closer to the screen. The result is\nthat the image-based and 3D geometry-based models mutually enhance each other,\nleading to realistic and seamless rendering. Our experiments demonstrate that\nour method provides consistent hand contact experience between remote users and\nimproves the immersive experience of 3D video communication.\n","authors":["Yizhong Zhang","Zhiqi Li","Sicheng Xu","Chong Li","Jiaolong Yang","Xin Tong","Baining Guo"],"pdf_url":"https://arxiv.org/pdf/2302.14365v1.pdf","comment":"IEEE VR 2023"},{"id":"http://arxiv.org/abs/2302.14363v1","updated":"2023-02-28T07:31:48Z","published":"2023-02-28T07:31:48Z","title":"Efficient Implicit Neural Reconstruction Using LiDAR","summary":"  Modeling scene geometry using implicit neural representation has revealed its\nadvantages in accuracy, flexibility, and low memory usage. Previous approaches\nhave demonstrated impressive results using color or depth images but still have\ndifficulty handling poor light conditions and large-scale scenes. Methods\ntaking global point cloud as input require accurate registration and ground\ntruth coordinate labels, which limits their application scenarios. In this\npaper, we propose a new method that uses sparse LiDAR point clouds and rough\nodometry to reconstruct fine-grained implicit occupancy field efficiently\nwithin a few minutes. We introduce a new loss function that supervises directly\nin 3D space without 2D rendering, avoiding information loss. We also manage to\nrefine poses of input frames in an end-to-end manner, creating consistent\ngeometry without global point cloud registration. As far as we know, our method\nis the first to reconstruct implicit scene representation from LiDAR-only\ninput. Experiments on synthetic and real-world datasets, including indoor and\noutdoor scenes, prove that our method is effective, efficient, and accurate,\nobtaining comparable results with existing methods using dense input.\n","authors":["Dongyu Yan","Xiaoyang Lyu","Jieqi Shi","Yi Lin"],"pdf_url":"https://arxiv.org/pdf/2302.14363v1.pdf","comment":"6+2 pages, 8 figures, Accepted for publication at IEEE International\n  Conference on Robotics and Automation (ICRA) 2023"},{"id":"http://arxiv.org/abs/2302.14362v1","updated":"2023-02-28T07:30:36Z","published":"2023-02-28T07:30:36Z","title":"One-Shot Video Inpainting","summary":"  Recently, removing objects from videos and filling in the erased regions\nusing deep video inpainting (VI) algorithms has attracted considerable\nattention. Usually, a video sequence and object segmentation masks for all\nframes are required as the input for this task. However, in real-world\napplications, providing segmentation masks for all frames is quite difficult\nand inefficient. Therefore, we deal with VI in a one-shot manner, which only\ntakes the initial frame's object mask as its input. Although we can achieve\nthat using naive combinations of video object segmentation (VOS) and VI\nmethods, they are sub-optimal and generally cause critical errors. To address\nthat, we propose a unified pipeline for one-shot video inpainting (OSVI). By\njointly learning mask prediction and video completion in an end-to-end manner,\nthe results can be optimal for the entire task instead of each separate module.\nAdditionally, unlike the two stage methods that use the predicted masks as\nground truth cues, our method is more reliable because the predicted masks can\nbe used as the network's internal guidance. On the synthesized datasets for\nOSVI, our proposed method outperforms all others both quantitatively and\nqualitatively.\n","authors":["Sangjin Lee","Suhwan Cho","Sangyoun Lee"],"pdf_url":"https://arxiv.org/pdf/2302.14362v1.pdf","comment":"AAAI2023 submitted"},{"id":"http://arxiv.org/abs/2210.00939v4","updated":"2023-02-28T07:22:39Z","published":"2022-10-03T13:50:58Z","title":"Improving Sample Quality of Diffusion Models Using Self-Attention\n  Guidance","summary":"  Denoising diffusion models (DDMs) have attracted attention due to their\nexceptional sample quality and diversity. This success is largely attributed to\nthe use of class- or text-conditional diffusion guidance methods. In this\npaper, we propose a more comprehensive approach that expands beyond traditional\nguidance methods. By adopting this generalized perspective, we introduce two\nnovel condition-free strategies to enhance the quality of generated images:\nblur guidance and advanced Self-Attention Guidance (SAG). Employing benign\nproperties of Gaussian blur, blur guidance enhances the suitability of\nintermediate samples for fine-scale information and generates higher quality\nsamples with a moderate guidance scale. Improving upon this, SAG utilizes\nintermediate self-attention maps to enhance the stability and efficacy.\nSpecifically, SAG leverages intermediate attention maps of diffusion models at\neach iteration to capture essential information for the generative process and\nguide it accordingly. Our experimental results demonstrate that our zero-shot\nmethod enhances the performance of various diffusion models, including ADM,\nIDDPM, and Stable Diffusion. Furthermore, combining SAG with conventional\nguidance methods, such as classifier-free guidance, results in further\nimprovement.\n","authors":["Susung Hong","Gyuseong Lee","Wooseok Jang","Seungryong Kim"],"pdf_url":"https://arxiv.org/pdf/2210.00939v4.pdf","comment":"Project page: https://ku-cvlab.github.io/Self-Attention-Guidance"},{"id":"http://arxiv.org/abs/2302.14354v1","updated":"2023-02-28T07:14:15Z","published":"2023-02-28T07:14:15Z","title":"Deep Learning for Identifying Iran's Cultural Heritage Buildings in Need\n  of Conservation Using Image Classification and Grad-CAM","summary":"  The cultural heritage buildings (CHB), which are part of mankind's history\nand identity, are in constant danger of damage or in extreme situations total\ndestruction. That being said, it's of utmost importance to preserve them by\nidentifying the existent, or presumptive, defects using novel methods so that\nrenovation processes can be done in a timely manner and with higher accuracy.\nThe main goal of this research is to use new deep learning (DL) methods in the\nprocess of preserving CHBs (situated in Iran); a goal that has been neglected\nespecially in developing countries such as Iran, as these countries still\npreserve their CHBs using manual, and even archaic, methods that need direct\nhuman supervision. Having proven their effectiveness and performance when it\ncomes to processing images, the convolutional neural networks (CNN) are a\nstaple in computer vision (CV) literacy and this paper is not exempt. When\nlacking enough CHB images, training a CNN from scratch would be very difficult\nand prone to overfitting; that's why we opted to use a technique called\ntransfer learning (TL) in which we used pre-trained ResNet, MobileNet, and\nInception networks, for classification. Even more, the Grad-CAM was utilized to\nlocalize the defects to some extent. The final results were very favorable\nbased on those of similar research. The final proposed model can pave the way\nfor moving from manual to unmanned CHB conservation, hence an increase in\naccuracy and a decrease in human-induced errors.\n","authors":["Mahdi Bahrami","Amir Albadvi"],"pdf_url":"https://arxiv.org/pdf/2302.14354v1.pdf","comment":"16 pages, 4745 words, 11 figures, and 5 tables"},{"id":"http://arxiv.org/abs/2107.02450v3","updated":"2023-02-28T06:59:49Z","published":"2021-07-06T07:58:07Z","title":"End-To-End Data-Dependent Routing in Multi-Path Neural Networks","summary":"  Neural networks are known to give better performance with increased depth due\nto their ability to learn more abstract features. Although the deepening of\nnetworks has been well established, there is still room for efficient feature\nextraction within a layer which would reduce the need for mere parameter\nincrement. The conventional widening of networks by having more filters in each\nlayer introduces a quadratic increment of parameters. Having multiple parallel\nconvolutional/dense operations in each layer solves this problem, but without\nany context-dependent allocation of resources among these operations: the\nparallel computations tend to learn similar features making the widening\nprocess less effective. Therefore, we propose the use of multi-path neural\nnetworks with data-dependent resource allocation among parallel computations\nwithin layers, which also lets an input to be routed end-to-end through these\nparallel paths. To do this, we first introduce a cross-prediction based\nalgorithm between parallel tensors of subsequent layers. Second, we further\nreduce the routing overhead by introducing feature-dependent cross-connections\nbetween parallel tensors of successive layers. Our multi-path networks show\nsuperior performance to existing widening and adaptive feature extraction, and\neven ensembles, and deeper networks at similar complexity in the image\nrecognition task.\n","authors":["Dumindu Tissera","Rukshan Wijessinghe","Kasun Vithanage","Alex Xavier","Subha Fernando","Ranga Rodrigo"],"pdf_url":"https://arxiv.org/pdf/2107.02450v3.pdf","comment":"Neural Computing and Applications 2023"},{"id":"http://arxiv.org/abs/2302.14350v1","updated":"2023-02-28T06:59:05Z","published":"2023-02-28T06:59:05Z","title":"Knowledge Augmented Relation Inference for Group Activity Recognition","summary":"  Most existing group activity recognition methods construct spatial-temporal\nrelations merely based on visual representation. Some methods introduce extra\nknowledge, such as action labels, to build semantic relations and use them to\nrefine the visual presentation. However, the knowledge they explored just stay\nat the semantic-level, which is insufficient for pursing notable accuracy. In\nthis paper, we propose to exploit knowledge concretization for the group\nactivity recognition, and develop a novel Knowledge Augmented Relation\nInference framework that can effectively use the concretized knowledge to\nimprove the individual representations. Specifically, the framework consists of\na Visual Representation Module to extract individual appearance features, a\nKnowledge Augmented Semantic Relation Module explore semantic representations\nof individual actions, and a Knowledge-Semantic-Visual Interaction Module aims\nto integrate visual and semantic information by the knowledge. Benefiting from\nthese modules, the proposed framework can utilize knowledge to enhance the\nrelation inference process and the individual representations, thus improving\nthe performance of group activity recognition. Experimental results on two\npublic datasets show that the proposed framework achieves competitive\nperformance compared with state-of-the-art methods.\n","authors":["Xianglong Lang","Zhuming Wang","Zun Li","Meng Tian","Ge Shi","Lifang Wu"],"pdf_url":"https://arxiv.org/pdf/2302.14350v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14348v1","updated":"2023-02-28T06:38:25Z","published":"2023-02-28T06:38:25Z","title":"Im2Hands: Learning Attentive Implicit Representation of Interacting\n  Two-Hand Shapes","summary":"  We present Implicit Two Hands (Im2Hands), the first neural implicit\nrepresentation of two interacting hands. Unlike existing methods on two-hand\nreconstruction that rely on a parametric hand model and/or low-resolution\nmeshes, Im2Hands can produce fine-grained geometry of two hands with high\nhand-to-hand and hand-to-image coherency. To handle the shape complexity and\ninteraction context between two hands, Im2Hands models the occupancy volume of\ntwo hands - conditioned on an RGB image and coarse 3D keypoints - by two novel\nattention-based modules responsible for (1) initial occupancy estimation and\n(2) context-aware occupancy refinement, respectively. Im2Hands first learns\nper-hand neural articulated occupancy in the canonical space designed for each\nhand using query-image attention. It then refines the initial two-hand\noccupancy in the posed space to enhance the coherency between the two hand\nshapes using query-anchor attention. In addition, we introduce an optional\nkeypoint refinement module to enable robust two-hand shape estimation from\npredicted hand keypoints in a single-image reconstruction scenario. We\nexperimentally demonstrate the effectiveness of Im2Hands on two-hand\nreconstruction in comparison to related methods, where ours achieves\nstate-of-the-art results. Our code is publicly available at\nhttps://github.com/jyunlee/Im2Hands.\n","authors":["Jihyun Lee","Minhyuk Sung","Honggyu Choi","Tae-Kyun Kim"],"pdf_url":"https://arxiv.org/pdf/2302.14348v1.pdf","comment":"6 figures, 14 pages, accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2302.03985v5","updated":"2023-02-28T06:31:09Z","published":"2023-02-08T10:50:01Z","title":"Cross-Layer Retrospective Retrieving via Layer Attention","summary":"  More and more evidence has shown that strengthening layer interactions can\nenhance the representation power of a deep neural network, while self-attention\nexcels at learning interdependencies by retrieving query-activated information.\nMotivated by this, we devise a cross-layer attention mechanism, called\nmulti-head recurrent layer attention (MRLA), that sends a query representation\nof the current layer to all previous layers to retrieve query-related\ninformation from different levels of receptive fields. A light-weighted version\nof MRLA is also proposed to reduce the quadratic computation cost. The proposed\nlayer attention mechanism can enrich the representation power of many\nstate-of-the-art vision networks, including CNNs and vision transformers. Its\neffectiveness has been extensively evaluated in image classification, object\ndetection and instance segmentation tasks, where improvements can be\nconsistently observed. For example, our MRLA can improve 1.6% Top-1 accuracy on\nResNet-50, while only introducing 0.16M parameters and 0.07B FLOPs.\nSurprisingly, it can boost the performances by a large margin of 3-4% box AP\nand mask AP in dense prediction tasks. Our code is available at\nhttps://github.com/joyfang1106/MRLA.\n","authors":["Yanwen Fang","Yuxi Cai","Jintai Chen","Jingyu Zhao","Guangjian Tian","Guodong Li"],"pdf_url":"https://arxiv.org/pdf/2302.03985v5.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2302.14340v1","updated":"2023-02-28T06:20:07Z","published":"2023-02-28T06:20:07Z","title":"HelixSurf: A Robust and Efficient Neural Implicit Surface Learning of\n  Indoor Scenes with Iterative Intertwined Regularization","summary":"  Recovery of an underlying scene geometry from multiview images stands as a\nlong-time challenge in computer vision research. The recent promise leverages\nneural implicit surface learning and differentiable volume rendering, and\nachieves both the recovery of scene geometry and synthesis of novel views,\nwhere deep priors of neural models are used as an inductive smoothness bias.\nWhile promising for object-level surfaces, these methods suffer when coping\nwith complex scene surfaces. In the meanwhile, traditional multi-view stereo\ncan recover the geometry of scenes with rich textures, by globally optimizing\nthe local, pixel-wise correspondences across multiple views. We are thus\nmotivated to make use of the complementary benefits from the two strategies,\nand propose a method termed Helix-shaped neural implicit Surface learning or\nHelixSurf; HelixSurf uses the intermediate prediction from one strategy as the\nguidance to regularize the learning of the other one, and conducts such\nintertwined regularization iteratively during the learning process. We also\npropose an efficient scheme for differentiable volume rendering in HelixSurf.\nExperiments on surface reconstruction of indoor scenes show that our method\ncompares favorably with existing methods and is orders of magnitude faster,\neven when some of existing methods are assisted with auxiliary training data.\nThe source code is available at https://github.com/Gorilla-Lab-SCUT/HelixSurf.\n","authors":["Zhihao Liang","Zhangjin Huang","Changxing Ding","Kui Jia"],"pdf_url":"https://arxiv.org/pdf/2302.14340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.08270v2","updated":"2023-02-28T06:17:36Z","published":"2022-08-17T13:02:17Z","title":"On the Privacy Effect of Data Enhancement via the Lens of Memorization","summary":"  Machine learning poses severe privacy concerns as it has been shown that the\nlearned models can reveal sensitive information about their training data. Many\nworks have investigated the effect of widely-adopted data augmentation (DA) and\nadversarial training (AT) techniques, termed data enhancement in the paper, on\nthe privacy leakage of machine learning models. Such privacy effects are often\nmeasured by membership inference attacks (MIAs), which aim to identify whether\na particular example belongs to the training set or not. We propose to\ninvestigate privacy from a new perspective called memorization. Through the\nlens of memorization, we find that previously deployed MIAs produce misleading\nresults as they are less likely to identify samples with higher privacy risks\nas members compared to samples with low privacy risks. To solve this problem,\nwe deploy a recent attack that can capture individual samples' memorization\ndegrees for evaluation. Through extensive experiments, we unveil non-trivial\nfindings about the connections between three essential properties of machine\nlearning models, including privacy, generalization gap, and adversarial\nrobustness. We demonstrate that, unlike existing results, the generalization\ngap is shown not highly correlated with privacy leakage. Moreover, stronger\nadversarial robustness does not necessarily imply that the model is more\nsusceptible to privacy attacks.\n","authors":["Xiao Li","Qiongxiu Li","Zhanhao Hu","Xiaolin Hu"],"pdf_url":"https://arxiv.org/pdf/2208.08270v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14338v1","updated":"2023-02-28T06:06:12Z","published":"2023-02-28T06:06:12Z","title":"Turning a CLIP Model into a Scene Text Detector","summary":"  The recent large-scale Contrastive Language-Image Pretraining (CLIP) model\nhas shown great potential in various downstream tasks via leveraging the\npretrained vision and language knowledge. Scene text, which contains rich\ntextual and visual information, has an inherent connection with a model like\nCLIP. Recently, pretraining approaches based on vision language models have\nmade effective progresses in the field of text detection. In contrast to these\nworks, this paper proposes a new method, termed TCM, focusing on Turning the\nCLIP Model directly for text detection without pretraining process. We\ndemonstrate the advantages of the proposed TCM as follows: (1) The underlying\nprinciple of our framework can be applied to improve existing scene text\ndetector. (2) It facilitates the few-shot training capability of existing\nmethods, e.g., by using 10% of labeled data, we significantly improve the\nperformance of the baseline method with an average of 22% in terms of the\nF-measure on 4 benchmarks. (3) By turning the CLIP model into existing scene\ntext detection methods, we further achieve promising domain adaptation ability.\nThe code will be publicly released.\n","authors":["Wenwen Yu","Yuliang Liu","Wei Hua","Deqiang Jiang","Bo Ren","Xiang Bai"],"pdf_url":"https://arxiv.org/pdf/2302.14338v1.pdf","comment":"CVPR2023"},{"id":"http://arxiv.org/abs/2302.14337v1","updated":"2023-02-28T06:05:43Z","published":"2023-02-28T06:05:43Z","title":"UniFLG: Unified Facial Landmark Generator from Text or Speech","summary":"  Talking face generation has been extensively investigated owing to its wide\napplicability. The two primary frameworks used for talking face generation\ncomprise a text-driven framework, which generates synchronized speech and\ntalking faces from text, and a speech-driven framework, which generates talking\nfaces from speech. To integrate these frameworks, this paper proposes a unified\nfacial landmark generator (UniFLG). The proposed system exploits end-to-end\ntext-to-speech not only for synthesizing speech but also for extracting a\nseries of latent representations that are common to text and speech, and feeds\nit to a landmark decoder to generate facial landmarks. We demonstrate that our\nsystem achieves higher naturalness in both speech synthesis and facial landmark\ngeneration compared to the state-of-the-art text-driven method. We further\ndemonstrate that our system can generate facial landmarks from speech of\nspeakers without facial video data or even speech data.\n","authors":["Kentaro Mitsui","Yukiya Hono","Kei Sawada"],"pdf_url":"https://arxiv.org/pdf/2302.14337v1.pdf","comment":"5 pages, 2 figures, 3 tables"},{"id":"http://arxiv.org/abs/2302.14335v1","updated":"2023-02-28T06:03:42Z","published":"2023-02-28T06:03:42Z","title":"DC-Former: Diverse and Compact Transformer for Person Re-Identification","summary":"  In person re-identification (re-ID) task, it is still challenging to learn\ndiscriminative representation by deep learning, due to limited data. Generally\nspeaking, the model will get better performance when increasing the amount of\ndata. The addition of similar classes strengthens the ability of the classifier\nto identify similar identities, thereby improving the discrimination of\nrepresentation. In this paper, we propose a Diverse and Compact Transformer\n(DC-Former) that can achieve a similar effect by splitting embedding space into\nmultiple diverse and compact subspaces. Compact embedding subspace helps model\nlearn more robust and discriminative embedding to identify similar classes. And\nthe fusion of these diverse embeddings containing more fine-grained information\ncan further improve the effect of re-ID. Specifically, multiple class tokens\nare used in vision transformer to represent multiple embedding spaces. Then, a\nself-diverse constraint (SDC) is applied to these spaces to push them away from\neach other, which makes each embedding space diverse and compact. Further, a\ndynamic weight controller(DWC) is further designed for balancing the relative\nimportance among them during training. The experimental results of our method\nare promising, which surpass previous state-of-the-art methods on several\ncommonly used person re-ID benchmarks.\n","authors":["Wen Li","Cheng Zou","Meng Wang","Furong Xu","Jianan Zhao","Ruobing Zheng","Yuan Cheng","Wei Chu"],"pdf_url":"https://arxiv.org/pdf/2302.14335v1.pdf","comment":"Accepted by AAAI23"},{"id":"http://arxiv.org/abs/2302.14332v1","updated":"2023-02-28T05:55:42Z","published":"2023-02-28T05:55:42Z","title":"Markerless Camera-to-Robot Pose Estimation via Self-supervised\n  Sim-to-Real Transfer","summary":"  Solving the camera-to-robot pose is a fundamental requirement for\nvision-based robot control, and is a process that takes considerable effort and\ncares to make accurate. Traditional approaches require modification of the\nrobot via markers, and subsequent deep learning approaches enabled markerless\nfeature extraction. Mainstream deep learning methods only use synthetic data\nand rely on Domain Randomization to fill the sim-to-real gap, because acquiring\nthe 3D annotation is labor-intensive. In this work, we go beyond the limitation\nof 3D annotations for real-world data. We propose an end-to-end pose estimation\nframework that is capable of online camera-to-robot calibration and a\nself-supervised training method to scale the training to unlabeled real-world\ndata. Our framework combines deep learning and geometric vision for solving the\nrobot pose, and the pipeline is fully differentiable. To train the\nCamera-to-Robot Pose Estimation Network (CtRNet), we leverage foreground\nsegmentation and differentiable rendering for image-level self-supervision. The\npose prediction is visualized through a renderer and the image loss with the\ninput image is back-propagated to train the neural network. Our experimental\nresults on two public real datasets confirm the effectiveness of our approach\nover existing works. We also integrate our framework into a visual servoing\nsystem to demonstrate the promise of real-time precise robot pose estimation\nfor automation tasks.\n","authors":["Jingpei Lu","Florian Richter","Michael C. Yip"],"pdf_url":"https://arxiv.org/pdf/2302.14332v1.pdf","comment":"13 pages, 8 figures"},{"id":"http://arxiv.org/abs/2302.14325v1","updated":"2023-02-28T05:37:45Z","published":"2023-02-28T05:37:45Z","title":"BEVPlace: Learning LiDAR-based Place Recognition using Bird's Eye View\n  Images","summary":"  Place recognition is a key module for long-term SLAM systems. Current\nLiDAR-based place recognition methods are usually based on representations of\npoint clouds such as unordered points or range images. These methods achieve\nhigh recall rates of retrieval, but their performance may degrade in the case\nof view variation or scene changes. In this work, we explore the potential of a\ndifferent representation in place recognition, i.e. bird's eye view (BEV)\nimages. We observe that the structural contents of BEV images are less\ninfluenced by rotations and translations of point clouds. We validate that,\nwithout any delicate design, a simple VGGNet trained on BEV images achieves\ncomparable performance with the state-of-the-art place recognition methods in\nscenes of slight viewpoint changes. For more robust place recognition, we\ndesign a rotation-invariant network called BEVPlace. We use group convolution\nto extract rotation-equivariant local features from the images and NetVLAD for\nglobal feature aggregation. In addition, we observe that the distance between\nBEV features is correlated with the geometry distance of point clouds. Based on\nthe observation, we develop a method to estimate the position of the query\ncloud, extending the usage of place recognition. The experiments conducted on\nlarge-scale public datasets show that our method 1) achieves state-of-the-art\nperformance in terms of recall rates, 2) is robust to view changes, 3) shows\nstrong generalization ability, and 4) can estimate the positions of query point\nclouds. Source code will be made publicly available at\nhttps://github.com/zjuluolun/BEVPlace.\n","authors":["Lun Luo","Shuhang Zheng","Yixuan Li","Yongzhi Fan","Beinan Yu","Siyuan Cao","Huiliang Shen"],"pdf_url":"https://arxiv.org/pdf/2302.14325v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14323v1","updated":"2023-02-28T05:37:04Z","published":"2023-02-28T05:37:04Z","title":"Read Pointer Meters in complex environments based on a Human-like\n  Alignment and Recognition Algorithm","summary":"  Recently, developing an automatic reading system for analog measuring\ninstruments has gained increased attention, as it enables the collection of\nnumerous state of equipment. Nonetheless, two major obstacles still obstruct\nits deployment to real-world applications. The first issue is that they rarely\ntake the entire pipeline's speed into account. The second is that they are\nincapable of dealing with some low-quality images (i.e., meter breakage, blur,\nand uneven scale). In this paper, we propose a human-like alignment and\nrecognition algorithm to overcome these problems. More specifically, a Spatial\nTransformed Module(STM) is proposed to obtain the front view of images in a\nself-autonomous way based on an improved Spatial Transformer Networks(STN).\nMeanwhile, a Value Acquisition Module(VAM) is proposed to infer accurate meter\nvalues by an end-to-end trained framework. In contrast to previous research,\nour model aligns and recognizes meters totally implemented by learnable\nprocessing, which mimics human's behaviours and thus achieves higher\nperformances. Extensive results verify the good robustness of the proposed\nmodel in terms of the accuracy and efficiency.\n","authors":["Yan Shu","Shaohui Liu","Honglei Xu","Feng Jiang"],"pdf_url":"https://arxiv.org/pdf/2302.14323v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.06052v3","updated":"2023-02-28T05:23:51Z","published":"2023-01-15T09:34:42Z","title":"T2M-GPT: Generating Human Motion from Textual Descriptions with Discrete\n  Representations","summary":"  In this work, we investigate a simple and must-known conditional generative\nframework based on Vector Quantised-Variational AutoEncoder (VQ-VAE) and\nGenerative Pre-trained Transformer (GPT) for human motion generation from\ntextural descriptions. We show that a simple CNN-based VQ-VAE with commonly\nused training recipes (EMA and Code Reset) allows us to obtain high-quality\ndiscrete representations. For GPT, we incorporate a simple corruption strategy\nduring the training to alleviate training-testing discrepancy. Despite its\nsimplicity, our T2M-GPT shows better performance than competitive approaches,\nincluding recent diffusion-based approaches. For example, on HumanML3D, which\nis currently the largest dataset, we achieve comparable performance on the\nconsistency between text and generated motion (R-Precision), but with FID 0.116\nlargely outperforming MotionDiffuse of 0.630. Additionally, we conduct analyses\non HumanML3D and observe that the dataset size is a limitation of our approach.\nOur work suggests that VQ-VAE still remains a competitive approach for human\nmotion generation.\n","authors":["Jianrong Zhang","Yangsong Zhang","Xiaodong Cun","Shaoli Huang","Yong Zhang","Hongwei Zhao","Hongtao Lu","Xi Shen"],"pdf_url":"https://arxiv.org/pdf/2301.06052v3.pdf","comment":"Accepted to CVPR 2023. Project page:\n  https://mael-zys.github.io/T2M-GPT/"},{"id":"http://arxiv.org/abs/2209.08772v2","updated":"2023-02-28T05:22:09Z","published":"2022-09-19T05:54:26Z","title":"TANDEM3D: Active Tactile Exploration for 3D Object Recognition","summary":"  Tactile recognition of 3D objects remains a challenging task. Compared to 2D\nshapes, the complex geometry of 3D surfaces requires richer tactile signals,\nmore dexterous actions, and more advanced encoding techniques. In this work, we\npropose TANDEM3D, a method that applies a co-training framework for exploration\nand decision making to 3D object recognition with tactile signals. Starting\nwith our previous work, which introduced a co-training paradigm for 2D\nrecognition problems, we introduce a number of advances that enable us to scale\nup to 3D. TANDEM3D is based on a novel encoder that builds 3D object\nrepresentation from contact positions and normals using PointNet++.\nFurthermore, by enabling 6DOF movement, TANDEM3D explores and collects\ndiscriminative touch information with high efficiency. Our method is trained\nentirely in simulation and validated with real-world experiments. Compared to\nstate-of-the-art baselines, TANDEM3D achieves higher accuracy and a lower\nnumber of actions in recognizing 3D objects and is also shown to be more robust\nto different types and amounts of sensor noise. Video is available at\nhttps://jxu.ai/tandem3d.\n","authors":["Jingxi Xu","Han Lin","Shuran Song","Matei Ciocarlie"],"pdf_url":"https://arxiv.org/pdf/2209.08772v2.pdf","comment":"7 pages. Accepted to International Conference on Robotics and\n  Automation (ICRA) 2023"},{"id":"http://arxiv.org/abs/2205.10706v2","updated":"2023-02-28T05:17:43Z","published":"2022-05-22T02:00:09Z","title":"GL-RG: Global-Local Representation Granularity for Video Captioning","summary":"  Video captioning is a challenging task as it needs to accurately transform\nvisual understanding into natural language description. To date,\nstate-of-the-art methods inadequately model global-local representation across\nvideo frames for caption generation, leaving plenty of room for improvement. In\nthis work, we approach the video captioning task from a new perspective and\npropose a GL-RG framework for video captioning, namely a\n\\textbf{G}lobal-\\textbf{L}ocal \\textbf{R}epresentation \\textbf{G}ranularity.\nOur GL-RG demonstrates three advantages over the prior efforts: 1) we\nexplicitly exploit extensive visual representations from different video ranges\nto improve linguistic expression; 2) we devise a novel global-local encoder to\nproduce rich semantic vocabulary to obtain a descriptive granularity of video\ncontents across frames; 3) we develop an incremental training strategy which\norganizes model learning in an incremental fashion to incur an optimal\ncaptioning behavior. Experimental results on the challenging MSR-VTT and MSVD\ndatasets show that our DL-RG outperforms recent state-of-the-art methods by a\nsignificant margin. Code is available at \\url{https://github.com/ylqi/GL-RG}.\n","authors":["Liqi Yan","Qifan Wang","Yiming Cui","Fuli Feng","Xiaojun Quan","Xiangyu Zhang","Dongfang Liu"],"pdf_url":"https://arxiv.org/pdf/2205.10706v2.pdf","comment":"Accepted to IJCAI 2022"},{"id":"http://arxiv.org/abs/2302.14309v1","updated":"2023-02-28T04:59:23Z","published":"2023-02-28T04:59:23Z","title":"Temporal Coherent Test-Time Optimization for Robust Video Classification","summary":"  Deep neural networks are likely to fail when the test data is corrupted in\nreal-world deployment (e.g., blur, weather, etc.). Test-time optimization is an\neffective way that adapts models to generalize to corrupted data during\ntesting, which has been shown in the image domain. However, the techniques for\nimproving video classification corruption robustness remain few. In this work,\nwe propose a Temporal Coherent Test-time Optimization framework (TeCo) to\nutilize spatio-temporal information in test-time optimization for robust video\nclassification. To exploit information in video with self-supervised learning,\nTeCo uses global content from video clips and optimizes models for entropy\nminimization. TeCo minimizes the entropy of the prediction based on the global\ncontent from video clips. Meanwhile, it also feeds local content to regularize\nthe temporal coherence at the feature level. TeCo retains the generalization\nability of various video classification models and achieves significant\nimprovements in corruption robustness across Mini Kinetics-C and Mini SSV2-C.\nFurthermore, TeCo sets a new baseline in video classification corruption\nrobustness via test-time optimization.\n","authors":["Chenyu Yi","Siyuan Yang","Yufei Wang","Haoliang Li","Yap-Peng Tan","Alex C. Kot"],"pdf_url":"https://arxiv.org/pdf/2302.14309v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2012.12102v4","updated":"2023-02-28T04:56:21Z","published":"2020-12-07T18:16:59Z","title":"Using Persistent Homology Topological Features to Characterize Medical\n  Images: Case Studies on Lung and Brain Cancers","summary":"  Tumor shape is a key factor that affects tumor growth and metastasis. This\npaper proposes a topological feature computed by persistent homology to\ncharacterize tumor progression from digital pathology and radiology images and\nexamines its effect on the time-to-event data. The proposed topological\nfeatures are invariant to scale-preserving transformation and can summarize\nvarious tumor shape patterns. The topological features are represented in\nfunctional space and used as functional predictors in a functional Cox\nproportional hazards model. The proposed model enables interpretable inference\nabout the association between topological shape features and survival risks.\nTwo case studies are conducted using consecutive 133 lung cancer and 77 brain\ntumor patients. The results of both studies show that the topological features\npredict survival prognosis after adjusting clinical variables, and the\npredicted high-risk groups have worse survival outcomes than the low-risk\ngroups. Also, the topological shape features found to be positively associated\nwith survival hazards are irregular and heterogeneous shape patterns, which are\nknown to be related to tumor progression.\n","authors":["Chul Moon","Qiwei Li","Guanghua Xiao"],"pdf_url":"https://arxiv.org/pdf/2012.12102v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14307v1","updated":"2023-02-28T04:45:31Z","published":"2023-02-28T04:45:31Z","title":"GradMA: A Gradient-Memory-based Accelerated Federated Learning with\n  Alleviated Catastrophic Forgetting","summary":"  Federated Learning (FL) has emerged as a de facto machine learning area and\nreceived rapid increasing research interests from the community. However,\ncatastrophic forgetting caused by data heterogeneity and partial participation\nposes distinctive challenges for FL, which are detrimental to the performance.\nTo tackle the problems, we propose a new FL approach (namely GradMA), which\ntakes inspiration from continual learning to simultaneously correct the\nserver-side and worker-side update directions as well as take full advantage of\nserver's rich computing and memory resources. Furthermore, we elaborate a\nmemory reduction strategy to enable GradMA to accommodate FL with a large scale\nof workers. We then analyze convergence of GradMA theoretically under the\nsmooth non-convex setting and show that its convergence rate achieves a linear\nspeed up w.r.t the increasing number of sampled active workers. At last, our\nextensive experiments on various image classification tasks show that GradMA\nachieves significant performance gains in accuracy and communication efficiency\ncompared to SOTA baselines.\n","authors":["Kangyang Luo","Xiang Li","Yunshi Lan","Ming Gao"],"pdf_url":"https://arxiv.org/pdf/2302.14307v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14306v1","updated":"2023-02-28T04:38:52Z","published":"2023-02-28T04:38:52Z","title":"CLR-GAM: Contrastive Point Cloud Learning with Guided Augmentation and\n  Feature Mapping","summary":"  Point cloud data plays an essential role in robotics and self-driving\napplications. Yet, annotating point cloud data is time-consuming and nontrivial\nwhile they enable learning discriminative 3D representations that empower\ndownstream tasks, such as classification and segmentation. Recently,\ncontrastive learning-based frameworks have shown promising results for learning\n3D representations in a self-supervised manner. However, existing contrastive\nlearning methods cannot precisely encode and associate structural features and\nsearch the higher dimensional augmentation space efficiently. In this paper, we\npresent CLR-GAM, a novel contrastive learning-based framework with Guided\nAugmentation (GA) for efficient dynamic exploration strategy and Guided Feature\nMapping (GFM) for similar structural feature association between augmented\npoint clouds. We empirically demonstrate that the proposed approach achieves\nstate-of-the-art performance on both simulated and real-world 3D point cloud\ndatasets for three different downstream tasks, i.e., 3D point cloud\nclassification, few-shot learning, and object part segmentation.\n","authors":["Srikanth Malla","Yi-Ting Chen"],"pdf_url":"https://arxiv.org/pdf/2302.14306v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14302v1","updated":"2023-02-28T04:31:09Z","published":"2023-02-28T04:31:09Z","title":"Improving Model Generalization by On-manifold Adversarial Augmentation\n  in the Frequency Domain","summary":"  Deep neural networks (DNNs) may suffer from significantly degenerated\nperformance when the training and test data are of different underlying\ndistributions. Despite the importance of model generalization to\nout-of-distribution (OOD) data, the accuracy of state-of-the-art (SOTA) models\non OOD data can plummet. Recent work has demonstrated that regular or\noff-manifold adversarial examples, as a special case of data augmentation, can\nbe used to improve OOD generalization. Inspired by this, we theoretically prove\nthat on-manifold adversarial examples can better benefit OOD generalization.\nNevertheless, it is nontrivial to generate on-manifold adversarial examples\nbecause the real manifold is generally complex. To address this issue, we\nproposed a novel method of Augmenting data with Adversarial examples via a\nWavelet module (AdvWavAug), an on-manifold adversarial data augmentation\ntechnique that is simple to implement. In particular, we project a benign image\ninto a wavelet domain. With the assistance of the sparsity characteristic of\nwavelet transformation, we can modify an image on the estimated data manifold.\nWe conduct adversarial augmentation based on AdvProp training framework.\nExtensive experiments on different models and different datasets, including\nImageNet and its distorted versions, demonstrate that our method can improve\nmodel generalization, especially on OOD data. By integrating AdvWavAug into the\ntraining process, we have achieved SOTA results on some recent\ntransformer-based models.\n","authors":["Chang Liu","Wenzhao Xiang","Yuan He","Hui Xue","Shibao Zheng","Hang Su"],"pdf_url":"https://arxiv.org/pdf/2302.14302v1.pdf","comment":"International Journal of Computer Vision (IJCV) [under review]"},{"id":"http://arxiv.org/abs/2302.07116v3","updated":"2023-02-28T04:28:12Z","published":"2023-02-14T15:21:53Z","title":"Team DETR: Guide Queries as a Professional Team in Detection\n  Transformers","summary":"  Recent proposed DETR variants have made tremendous progress in various\nscenarios due to their streamlined processes and remarkable performance.\nHowever, the learned queries usually explore the global context to generate the\nfinal set prediction, resulting in redundant burdens and unfaithful results.\nMore specifically, a query is commonly responsible for objects of different\nscales and positions, which is a challenge for the query itself, and will cause\nspatial resource competition among queries. To alleviate this issue, we propose\nTeam DETR, which leverages query collaboration and position constraints to\nembrace objects of interest more precisely. We also dynamically cater to each\nquery member's prediction preference, offering the query better scale and\nspatial priors. In addition, the proposed Team DETR is flexible enough to be\nadapted to other existing DETR variants without increasing parameters and\ncalculations. Extensive experiments on the COCO dataset show that Team DETR\nachieves remarkable gains, especially for small and large objects. Code is\navailable at \\url{https://github.com/horrible-dong/TeamDETR}.\n","authors":["Tian Qiu","Linyun Zhou","Wenxiang Xu","Lechao Cheng","Zunlei Feng","Mingli Song"],"pdf_url":"https://arxiv.org/pdf/2302.07116v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14301v1","updated":"2023-02-28T04:26:20Z","published":"2023-02-28T04:26:20Z","title":"A Comprehensive Study on Robustness of Image Classification Models:\n  Benchmarking and Rethinking","summary":"  The robustness of deep neural networks is usually lacking under adversarial\nexamples, common corruptions, and distribution shifts, which becomes an\nimportant research problem in the development of deep learning. Although new\ndeep learning methods and robustness improvement techniques have been\nconstantly proposed, the robustness evaluations of existing methods are often\ninadequate due to their rapid development, diverse noise patterns, and simple\nevaluation metrics. Without thorough robustness evaluations, it is hard to\nunderstand the advances in the field and identify the effective methods. In\nthis paper, we establish a comprehensive robustness benchmark called\n\\textbf{ARES-Bench} on the image classification task. In our benchmark, we\nevaluate the robustness of 55 typical deep learning models on ImageNet with\ndiverse architectures (e.g., CNNs, Transformers) and learning algorithms (e.g.,\nnormal supervised training, pre-training, adversarial training) under numerous\nadversarial attacks and out-of-distribution (OOD) datasets. Using robustness\ncurves as the major evaluation criteria, we conduct large-scale experiments and\ndraw several important findings, including: 1) there is an inherent trade-off\nbetween adversarial and natural robustness for the same model architecture; 2)\nadversarial training effectively improves adversarial robustness, especially\nwhen performed on Transformer architectures; 3) pre-training significantly\nimproves natural robustness based on more training data or self-supervised\nlearning. Based on ARES-Bench, we further analyze the training tricks in\nlarge-scale adversarial training on ImageNet. By designing the training\nsettings accordingly, we achieve the new state-of-the-art adversarial\nrobustness. We have made the benchmarking results and code platform publicly\navailable.\n","authors":["Chang Liu","Yinpeng Dong","Wenzhao Xiang","Xiao Yang","Hang Su","Jun Zhu","Yuefeng Chen","Yuan He","Hui Xue","Shibao Zheng"],"pdf_url":"https://arxiv.org/pdf/2302.14301v1.pdf","comment":"International Journal of Computer Vision (IJCV) [under review]"},{"id":"http://arxiv.org/abs/2206.04797v4","updated":"2023-02-28T04:18:22Z","published":"2022-06-06T21:56:11Z","title":"Memory-efficient model-based deep learning with convergence and\n  robustness guarantees","summary":"  Computational imaging has been revolutionized by compressed sensing\nalgorithms, which offer guaranteed uniqueness, convergence, and stability\nproperties. Model-based deep learning methods that combine imaging physics with\nlearned regularization priors have emerged as more powerful alternatives for\nimage recovery. The main focus of this paper is to introduce a memory efficient\nmodel-based algorithm with similar theoretical guarantees as CS methods. The\nproposed iterative algorithm alternates between a gradient descent involving\nthe score function and a conjugate gradient algorithm to encourage data\nconsistency. The score function is modeled as a monotone convolutional neural\nnetwork. Our analysis shows that the monotone constraint is necessary and\nsufficient to enforce the uniqueness of the fixed point in arbitrary inverse\nproblems. In addition, it also guarantees the convergence to a fixed point,\nwhich is robust to input perturbations. We introduce two implementations of the\nproposed MOL framework, which differ in the way the monotone property is\nimposed. The first approach enforces a strict monotone constraint, while the\nsecond one relies on an approximation. The guarantees are not valid for the\nsecond approach in the strict sense. However, our empirical studies show that\nthe convergence and robustness of both approaches are comparable, while the\nless constrained approximate implementation offers better performance. The\nproposed deep equilibrium formulation is significantly more memory efficient\nthan unrolled methods, which allows us to apply it to 3D or 2D+time problems\nthat current unrolled algorithms cannot handle.\n","authors":["Aniket Pramanik","M. Bridget Zimmerman","Mathews Jacob"],"pdf_url":"https://arxiv.org/pdf/2206.04797v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12366v2","updated":"2023-02-28T04:16:53Z","published":"2023-02-23T23:48:20Z","title":"Less is More: Data Pruning for Faster Adversarial Training","summary":"  Deep neural networks (DNNs) are sensitive to adversarial examples, resulting\nin fragile and unreliable performance in the real world. Although adversarial\ntraining (AT) is currently one of the most effective methodologies to robustify\nDNNs, it is computationally very expensive (e.g., 5-10X costlier than standard\ntraining). To address this challenge, existing approaches focus on single-step\nAT, referred to as Fast AT, reducing the overhead of adversarial example\ngeneration. Unfortunately, these approaches are known to fail against stronger\nadversaries. To make AT computationally efficient without compromising\nrobustness, this paper takes a different view of the efficient AT problem.\nSpecifically, we propose to minimize redundancies at the data level by\nleveraging data pruning. Extensive experiments demonstrate that the data\npruning based AT can achieve similar or superior robust (and clean) accuracy as\nits unpruned counterparts while being significantly faster. For instance,\nproposed strategies accelerate CIFAR-10 training up to 3.44X and CIFAR-100\ntraining to 2.02X. Additionally, the data pruning methods can readily be\nreconciled with existing adversarial acceleration tricks to obtain the striking\nspeed-ups of 5.66X and 5.12X on CIFAR-10, 3.67X and 3.07X on CIFAR-100 with\nTRADES and MART, respectively.\n","authors":["Yize Li","Pu Zhao","Xue Lin","Bhavya Kailkhura","Ryan Goldhahn"],"pdf_url":"https://arxiv.org/pdf/2302.12366v2.pdf","comment":"The AAAI-23 Workshop on Artificial Intelligence Safety (SafeAI 2023)"},{"id":"http://arxiv.org/abs/2302.14290v1","updated":"2023-02-28T03:50:56Z","published":"2023-02-28T03:50:56Z","title":"Learning to Retain while Acquiring: Combating Distribution-Shift in\n  Adversarial Data-Free Knowledge Distillation","summary":"  Data-free Knowledge Distillation (DFKD) has gained popularity recently, with\nthe fundamental idea of carrying out knowledge transfer from a Teacher neural\nnetwork to a Student neural network in the absence of training data. However,\nin the Adversarial DFKD framework, the student network's accuracy, suffers due\nto the non-stationary distribution of the pseudo-samples under multiple\ngenerator updates. To this end, at every generator update, we aim to maintain\nthe student's performance on previously encountered examples while acquiring\nknowledge from samples of the current distribution. Thus, we propose a\nmeta-learning inspired framework by treating the task of Knowledge-Acquisition\n(learning from newly generated samples) and Knowledge-Retention (retaining\nknowledge on previously met samples) as meta-train and meta-test, respectively.\nHence, we dub our method as Learning to Retain while Acquiring. Moreover, we\nidentify an implicit aligning factor between the Knowledge-Retention and\nKnowledge-Acquisition tasks indicating that the proposed student update\nstrategy enforces a common gradient direction for both tasks, alleviating\ninterference between the two objectives. Finally, we support our hypothesis by\nexhibiting extensive evaluation and comparison of our method with prior arts on\nmultiple datasets.\n","authors":["Gaurav Patel","Konda Reddy Mopuri","Qiang Qiu"],"pdf_url":"https://arxiv.org/pdf/2302.14290v1.pdf","comment":"Accepted at CVPR 2023"},{"id":"http://arxiv.org/abs/2302.12995v2","updated":"2023-02-28T03:48:03Z","published":"2023-02-25T05:29:45Z","title":"Raw Image Reconstruction with Learned Compact Metadata","summary":"  While raw images exhibit advantages over sRGB images (e.g., linearity and\nfine-grained quantization level), they are not widely used by common users due\nto the large storage requirements. Very recent works propose to compress raw\nimages by designing the sampling masks in the raw image pixel space, leading to\nsuboptimal image representations and redundant metadata. In this paper, we\npropose a novel framework to learn a compact representation in the latent space\nserving as the metadata in an end-to-end manner. Furthermore, we propose a\nnovel sRGB-guided context model with improved entropy estimation strategies,\nwhich leads to better reconstruction quality, smaller size of metadata, and\nfaster speed. We illustrate how the proposed raw image compression scheme can\nadaptively allocate more bits to image regions that are important from a global\nperspective. The experimental results show that the proposed method can achieve\nsuperior raw image reconstruction results using a smaller size of the metadata\non both uncompressed sRGB images and JPEG images.\n","authors":["Yufei Wang","Yi Yu","Wenhan Yang","Lanqing Guo","Lap-Pui Chau","Alex Kot","Bihan Wen"],"pdf_url":"https://arxiv.org/pdf/2302.12995v2.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2302.14284v1","updated":"2023-02-28T03:36:48Z","published":"2023-02-28T03:36:48Z","title":"Rethink Long-tailed Recognition with Vision Transforms","summary":"  In the real world, data tends to follow long-tailed distributions w.r.t.\nclass or attribution, motivating the challenging Long-Tailed Recognition (LTR)\nproblem. In this paper, we revisit recent LTR methods with promising Vision\nTransformers (ViT). We figure out that 1) ViT is hard to train with long-tailed\ndata. 2) ViT learns generalized features in an unsupervised manner, like mask\ngenerative training, either on long-tailed or balanced datasets. Hence, we\npropose to adopt unsupervised learning to utilize long-tailed data.\nFurthermore, we propose the Predictive Distribution Calibration (PDC) as a\nnovel metric for LTR, where the model tends to simply classify inputs into\ncommon classes. Our PDC can measure the model calibration of predictive\npreferences quantitatively. On this basis, we find many LTR approaches\nalleviate it slightly, despite the accuracy improvement. Extensive experiments\non benchmark datasets validate that PDC reflects the model's predictive\npreference precisely, which is consistent with the visualization.\n","authors":["Zhengzhuo Xu","Shuo Yang","Xingjun Wang","Chun Yuan"],"pdf_url":"https://arxiv.org/pdf/2302.14284v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.14277v1","updated":"2023-02-28T03:23:36Z","published":"2023-02-28T03:23:36Z","title":"DECOR-NET: A COVID-19 Lung Infection Segmentation Network Improved by\n  Emphasizing Low-level Features and Decorrelating Features","summary":"  Since 2019, coronavirus Disease 2019 (COVID-19) has been widely spread and\nposed a serious threat to public health. Chest Computed Tomography (CT) holds\ngreat potential for screening and diagnosis of this disease. The segmentation\nof COVID-19 CT imaging can achieves quantitative evaluation of infections and\ntracks disease progression. COVID-19 infections are characterized by high\nheterogeneity and unclear boundaries, so capturing low-level features such as\ntexture and intensity is critical for segmentation. However, segmentation\nnetworks that emphasize low-level features are still lacking. In this work, we\npropose a DECOR-Net capable of capturing more decorrelated low-level features.\nThe channel re-weighting strategy is applied to obtain plenty of low-level\nfeatures and the dependencies between channels are reduced by proposed\ndecorrelation loss. Experiments show that DECOR-Net outperforms other\ncutting-edge methods and surpasses the baseline by 5.1% and 4.9% in terms of\nDice coefficient and intersection over union. Moreover, the proposed\ndecorrelation loss can improve the performance constantly under different\nsettings. The Code is available at https://github.com/jiesihu/DECOR-Net.git.\n","authors":["Jiesi Hu","Yanwu Yang","Xutao Guo","Ting Ma"],"pdf_url":"https://arxiv.org/pdf/2302.14277v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.10792v2","updated":"2023-02-28T03:21:35Z","published":"2022-07-08T05:02:15Z","title":"Test-Time Adaptation via Self-Training with Nearest Neighbor Information","summary":"  Test-time adaptation (TTA) aims to adapt a trained classifier using online\nunlabeled test data only, without any information related to the training\nprocedure. Most existing TTA methods adapt the trained classifier using the\nclassifier's prediction on the test data as pseudo-label. However, under\ntest-time domain shift, accuracy of the pseudo labels cannot be guaranteed, and\nthus the TTA methods often encounter performance degradation at the adapted\nclassifier. To overcome this limitation, we propose a novel test-time\nadaptation method, called Test-time Adaptation via Self-Training with nearest\nneighbor information (TAST), which is composed of the following procedures: (1)\nadds trainable adaptation modules on top of the trained feature extractor; (2)\nnewly defines a pseudo-label distribution for the test data by using the\nnearest neighbor information; (3) trains these modules only a few times during\ntest time to match the nearest neighbor-based pseudo label distribution and a\nprototype-based class distribution for the test data; and (4) predicts the\nlabel of test data using the average predicted class distribution from these\nmodules. The pseudo-label generation is based on the basic intuition that a\ntest data and its nearest neighbor in the embedding space are likely to share\nthe same label under the domain shift. By utilizing multiple randomly\ninitialized adaptation modules, TAST extracts useful information for the\nclassification of the test data under the domain shift, using the nearest\nneighbor information. TAST showed better performance than the state-of-the-art\nTTA methods on two standard benchmark tasks, domain generalization, namely\nVLCS, PACS, OfficeHome, and TerraIncognita, and image corruption, particularly\nCIFAR-10/100C.\n","authors":["Minguk Jang","Sae-Young Chung","Hye Won Chung"],"pdf_url":"https://arxiv.org/pdf/2207.10792v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.06185v2","updated":"2023-02-28T03:19:18Z","published":"2023-02-13T08:42:41Z","title":"PUPS: Point Cloud Unified Panoptic Segmentation","summary":"  Point cloud panoptic segmentation is a challenging task that seeks a holistic\nsolution for both semantic and instance segmentation to predict groupings of\ncoherent points. Previous approaches treat semantic and instance segmentation\nas surrogate tasks, and they either use clustering methods or bounding boxes to\ngather instance groupings with costly computation and hand-crafted designs in\nthe instance segmentation task. In this paper, we propose a simple but\neffective point cloud unified panoptic segmentation (PUPS) framework, which use\na set of point-level classifiers to directly predict semantic and instance\ngroupings in an end-to-end manner. To realize PUPS, we introduce bipartite\nmatching to our training pipeline so that our classifiers are able to\nexclusively predict groupings of instances, getting rid of hand-crafted\ndesigns, e.g. anchors and Non-Maximum Suppression (NMS). In order to achieve\nbetter grouping results, we utilize a transformer decoder to iteratively refine\nthe point classifiers and develop a context-aware CutMix augmentation to\novercome the class imbalance problem. As a result, PUPS achieves 1st place on\nthe leader board of SemanticKITTI panoptic segmentation task and\nstate-of-the-art results on nuScenes.\n","authors":["Shihao Su","Jianyun Xu","Huanyu Wang","Zhenwei Miao","Xin Zhan","Dayang Hao","Xi Li"],"pdf_url":"https://arxiv.org/pdf/2302.06185v2.pdf","comment":"accepted by AAAI2023"},{"id":"http://arxiv.org/abs/2302.14268v1","updated":"2023-02-28T03:02:11Z","published":"2023-02-28T03:02:11Z","title":"Self-Supervised Category-Level Articulated Object Pose Estimation with\n  Part-Level SE(3) Equivariance","summary":"  Category-level articulated object pose estimation aims to estimate a\nhierarchy of articulation-aware object poses of an unseen articulated object\nfrom a known category. To reduce the heavy annotations needed for supervised\nlearning methods, we present a novel self-supervised strategy that solves this\nproblem without any human labels. Our key idea is to factorize canonical shapes\nand articulated object poses from input articulated shapes through part-level\nequivariant shape analysis. Specifically, we first introduce the concept of\npart-level SE(3) equivariance and devise a network to learn features of such\nproperty. Then, through a carefully designed fine-grained pose-shape\ndisentanglement strategy, we expect that canonical spaces to support pose\nestimation could be induced automatically. Thus, we could further predict\narticulated object poses as per-part rigid transformations describing how parts\ntransform from their canonical part spaces to the camera space. Extensive\nexperiments demonstrate the effectiveness of our method on both complete and\npartial point clouds from synthetic and real articulated object datasets.\n","authors":["Xueyi Liu","Ji Zhang","Ruizhen Hu","Haibin Huang","He Wang","Li Yi"],"pdf_url":"https://arxiv.org/pdf/2302.14268v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2206.05751v2","updated":"2023-02-28T03:02:02Z","published":"2022-06-12T14:45:11Z","title":"Consistent Attack: Universal Adversarial Perturbation on Embodied Vision\n  Navigation","summary":"  Embodied agents in vision navigation coupled with deep neural networks have\nattracted increasing attention. However, deep neural networks are vulnerable to\nmalicious adversarial noises, which may potentially cause catastrophic failures\nin Embodied Vision Navigation. Among these adversarial noises, universal\nadversarial perturbations (UAP), i.e., the image-agnostic perturbation applied\non each frame received by the agent, are more critical for Embodied Vision\nNavigation since they are computation-efficient and application-practical\nduring the attack. However, existing UAP methods do not consider the system\ndynamics of Embodied Vision Navigation. For extending UAP in the sequential\ndecision setting, we formulate the disturbed environment under the universal\nnoise $\\delta$, as a $\\delta$-disturbed Markov Decision Process ($\\delta$-MDP).\nBased on the formulation, we analyze the properties of $\\delta$-MDP and propose\ntwo novel Consistent Attack methods for attacking Embodied agents, which first\nconsider the dynamic of the MDP by estimating the disturbed Q function and the\ndisturbed distribution. In spite of victim models, our Consistent Attack can\ncause a significant drop in the performance for the Goalpoint task in habitat.\nExtensive experimental results indicate that there exist potential risks for\napplying Embodied Vision Navigation methods to the real world.\n","authors":["Chengyang Ying","You Qiaoben","Xinning Zhou","Hang Su","Jun Zhu","Bo Zhang"],"pdf_url":"https://arxiv.org/pdf/2206.05751v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14267v1","updated":"2023-02-28T03:01:58Z","published":"2023-02-28T03:01:58Z","title":"Adversarial Attack with Raindrops","summary":"  Deep neural networks (DNNs) are known to be vulnerable to adversarial\nexamples, which are usually designed artificially to fool DNNs, but rarely\nexist in real-world scenarios. In this paper, we study the adversarial examples\ncaused by raindrops, to demonstrate that there exist plenty of natural\nphenomena being able to work as adversarial attackers to DNNs. Moreover, we\npresent a new approach to generate adversarial raindrops, denoted as AdvRD,\nusing the generative adversarial network (GAN) technique to simulate natural\nraindrops. The images crafted by our AdvRD look very similar to the real-world\nraindrop images, statistically close to the distribution of true raindrop\nimages, and more importantly, can perform strong adversarial attack to the\nstate-of-the-art DNN models. On the other side, we show that the adversarial\ntraining using our AdvRD images can significantly improve the robustness of\nDNNs to the real-world raindrop attacks. Extensive experiments are carried out\nto demonstrate that the images crafted by AdvRD are visually and statistically\nclose to the natural raindrop images, can work as strong attackers to DNN\nmodels, and also help improve the robustness of DNNs to raindrop attacks.\n","authors":["Jiyuan Liu","Bingyi Lu","Mingkang Xiong","Tao Zhang","Huilin Xiong"],"pdf_url":"https://arxiv.org/pdf/2302.14267v1.pdf","comment":"10 pages, 7 figures, cvpr2023"},{"id":"http://arxiv.org/abs/2212.02770v2","updated":"2023-02-28T02:49:07Z","published":"2022-12-06T05:44:21Z","title":"CSQ: Growing Mixed-Precision Quantization Scheme with Bi-level\n  Continuous Sparsification","summary":"  Mixed-precision quantization has been widely applied on deep neural networks\n(DNNs) as it leads to significantly better efficiency-accuracy tradeoffs\ncompared to uniform quantization. Meanwhile, determining the exact precision of\neach layer remains challenging. Previous attempts on bit-level regularization\nand pruning-based dynamic precision adjustment during training suffer from\nnoisy gradients and unstable convergence. In this work, we propose Continuous\nSparsification Quantization (CSQ), a bit-level training method to search for\nmixed-precision quantization schemes with improved stability. CSQ stabilizes\nthe bit-level mixed-precision training process with a bi-level gradual\ncontinuous sparsification on both the bit values of the quantized weights and\nthe bit selection in determining the quantization precision of each layer. The\ncontinuous sparsification scheme enables fully-differentiable training without\ngradient approximation while achieving an exact quantized model in the end.A\nbudget-aware regularization of total model size enables the dynamic growth and\npruning of each layer's precision towards a mixed-precision quantization scheme\nof the desired size. Extensive experiments show CSQ achieves better\nefficiency-accuracy tradeoff than previous methods on multiple models and\ndatasets.\n","authors":["Lirui Xiao","Huanrui Yang","Zhen Dong","Kurt Keutzer","Li Du","Shanghang Zhang"],"pdf_url":"https://arxiv.org/pdf/2212.02770v2.pdf","comment":"Published as a conference paper at DAC 2023"},{"id":"http://arxiv.org/abs/2204.10972v2","updated":"2023-02-28T02:46:40Z","published":"2022-04-23T01:40:06Z","title":"GRM: Gradient Rectification Module for Visual Place Retrieval","summary":"  Visual place retrieval aims to search images in the database that depict\nsimilar places as the query image. However, global descriptors encoded by the\nnetwork usually fall into a low dimensional principal space, which is harmful\nto the retrieval performance. We first analyze the cause of this phenomenon,\npointing out that it is due to degraded distribution of the gradients of\ndescriptors. Then, we propose Gradient Rectification Module(GRM) to alleviate\nthis issue. GRM is appended after the final pooling layer and can rectify\ngradients to the complementary space of the principal space. With GRM, the\nnetwork is encouraged to generate descriptors more uniformly in the whole\nspace. At last, we conduct experiments on multiple datasets and generalize our\nmethod to classification task under prototype learning framework.\n","authors":["Boshu Lei","Wenjie Ding","Limeng Qiao","Xi Qiu"],"pdf_url":"https://arxiv.org/pdf/2204.10972v2.pdf","comment":"Accepted to the 2023 International Conference on Robotics and\n  Automation (ICRA 2023)"},{"id":"http://arxiv.org/abs/2302.14264v1","updated":"2023-02-28T02:41:27Z","published":"2023-02-28T02:41:27Z","title":"RGB-D Grasp Detection via Depth Guided Learning with Cross-modal\n  Attention","summary":"  Planar grasp detection is one of the most fundamental tasks to robotic\nmanipulation, and the recent progress of consumer-grade RGB-D sensors enables\ndelivering more comprehensive features from both the texture and shape\nmodalities. However, depth maps are generally of a relatively lower quality\nwith much stronger noise compared to RGB images, making it challenging to\nacquire grasp depth and fuse multi-modal clues. To address the two issues, this\npaper proposes a novel learning based approach to RGB-D grasp detection, namely\nDepth Guided Cross-modal Attention Network (DGCAN). To better leverage the\ngeometry information recorded in the depth channel, a complete 6-dimensional\nrectangle representation is adopted with the grasp depth dedicatedly considered\nin addition to those defined in the common 5-dimensional one. The prediction of\nthe extra grasp depth substantially strengthens feature learning, thereby\nleading to more accurate results. Moreover, to reduce the negative impact\ncaused by the discrepancy of data quality in two modalities, a Local\nCross-modal Attention (LCA) module is designed, where the depth features are\nrefined according to cross-modal relations and concatenated to the RGB ones for\nmore sufficient fusion. Extensive simulation and physical evaluations are\nconducted and the experimental results highlight the superiority of the\nproposed approach.\n","authors":["Ran Qin","Haoxiang Ma","Boyang Gao","Di Huang"],"pdf_url":"https://arxiv.org/pdf/2302.14264v1.pdf","comment":"Accepted at ICRA 2023"},{"id":"http://arxiv.org/abs/2212.08846v3","updated":"2023-02-28T02:30:31Z","published":"2022-12-17T11:00:34Z","title":"Painterly Image Harmonization in Dual Domains","summary":"  Image harmonization aims to produce visually harmonious composite images by\nadjusting the foreground appearance to be compatible with the background. When\nthe composite image has photographic foreground and painterly background, the\ntask is called painterly image harmonization. There are only few works on this\ntask, which are either time-consuming or weak in generating well-harmonized\nresults. In this work, we propose a novel painterly harmonization network\nconsisting of a dual-domain generator and a dual-domain discriminator, which\nharmonizes the composite image in both spatial domain and frequency domain. The\ndual-domain generator performs harmonization by using AdaIN modules in the\nspatial domain and our proposed ResFFT modules in the frequency domain. The\ndual-domain discriminator attempts to distinguish the inharmonious patches\nbased on the spatial feature and frequency feature of each patch, which can\nenhance the ability of generator in an adversarial manner. Extensive\nexperiments on the benchmark dataset show the effectiveness of our method. Our\ncode and model are available at\nhttps://github.com/bcmi/PHDNet-Painterly-Image-Harmonization.\n","authors":["Junyan Cao","Yan Hong","Li Niu"],"pdf_url":"https://arxiv.org/pdf/2212.08846v3.pdf","comment":"Accepted by AAAI2023"},{"id":"http://arxiv.org/abs/2302.14256v1","updated":"2023-02-28T02:27:36Z","published":"2023-02-28T02:27:36Z","title":"Remote Sensing Scene Classification with Masked Image Modeling (MIM)","summary":"  Remote sensing scene classification has been extensively studied for its\ncritical roles in geological survey, oil exploration, traffic management,\nearthquake prediction, wildfire monitoring, and intelligence monitoring. In the\npast, the Machine Learning (ML) methods for performing the task mainly used the\nbackbones pretrained in the manner of supervised learning (SL). As Masked Image\nModeling (MIM), a self-supervised learning (SSL) technique, has been shown as a\nbetter way for learning visual feature representation, it presents a new\nopportunity for improving ML performance on the scene classification task. This\nresearch aims to explore the potential of MIM pretrained backbones on four\nwell-known classification datasets: Merced, AID, NWPU-RESISC45, and Optimal-31.\nCompared to the published benchmarks, we show that the MIM pretrained Vision\nTransformer (ViTs) backbones outperform other alternatives (up to 18% on top 1\naccuracy) and that the MIM technique can learn better feature representation\nthan the supervised learning counterparts (up to 5% on top 1 accuracy).\nMoreover, we show that the general-purpose MIM-pretrained ViTs can achieve\ncompetitive performance as the specially designed yet complicated Transformer\nfor Remote Sensing (TRS) framework. Our experiment results also provide a\nperformance baseline for future studies.\n","authors":["Liya Wang","Alex Tien"],"pdf_url":"https://arxiv.org/pdf/2302.14256v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2301.12058"},{"id":"http://arxiv.org/abs/2302.14250v1","updated":"2023-02-28T02:21:42Z","published":"2023-02-28T02:21:42Z","title":"Foundation Model Drives Weakly Incremental Learning for Semantic\n  Segmentation","summary":"  Modern incremental learning for semantic segmentation methods usually learn\nnew categories based on dense annotations. Although achieve promising results,\npixel-by-pixel labeling is costly and time-consuming. Weakly incremental\nlearning for semantic segmentation (WILSS) is a novel and attractive task,\nwhich aims at learning to segment new classes from cheap and widely available\nimage-level labels. Despite the comparable results, the image-level labels can\nnot provide details to locate each segment, which limits the performance of\nWILSS. This inspires us to think how to improve and effectively utilize the\nsupervision of new classes given image-level labels while avoiding forgetting\nold ones. In this work, we propose a novel and data-efficient framework for\nWILSS, named FMWISS. Specifically, we propose pre-training based\nco-segmentation to distill the knowledge of complementary foundation models for\ngenerating dense pseudo labels. We further optimize the noisy pseudo masks with\na teacher-student architecture, where a plug-in teacher is optimized with a\nproposed dense contrastive loss. Moreover, we introduce memory-based copy-paste\naugmentation to improve the catastrophic forgetting problem of old classes.\nExtensive experiments on Pascal VOC and COCO datasets demonstrate the superior\nperformance of our framework, e.g., FMWISS achieves 70.7% and 73.3% in the 15-5\nVOC setting, outperforming the state-of-the-art method by 3.4% and 6.1%,\nrespectively.\n","authors":["Chaohui Yu","Qiang Zhou","Jingliang Li","Jianlong Yuan","Zhibin Wang","Fan Wang"],"pdf_url":"https://arxiv.org/pdf/2302.14250v1.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2204.05859v2","updated":"2023-02-28T01:46:21Z","published":"2022-04-12T14:59:48Z","title":"DCMS: Motion Forecasting with Dual Consistency and Multi-Pseudo-Target\n  Supervision","summary":"  We present a novel framework for motion forecasting with Dual Consistency\nConstraints and Multi-Pseudo-Target supervision. The motion forecasting task\npredicts future trajectories of vehicles by incorporating spatial and temporal\ninformation from the past. A key design of DCMS is the proposed Dual\nConsistency Constraints that regularize the predicted trajectories under\nspatial and temporal perturbation during the training stage. In addition, we\ndesign a novel self-ensembling scheme to obtain accurate pseudo targets to\nmodel the multi-modality in motion forecasting through supervision with\nmultiple targets explicitly, namely Multi-Pseudo-Target supervision. Our\nexperimental results on the Argoverse motion forecasting benchmark show that\nDCMS significantly outperforms the state-of-the-art methods, achieving 1st\nplace on the leaderboard. We also demonstrate that our proposed strategies can\nbe incorporated into other motion forecasting approaches as general training\nschemes.\n","authors":["Maosheng Ye","Jiamiao Xu","Xunnong Xu","Tengfei Wang","Tongyi Cao","Qifeng Chen"],"pdf_url":"https://arxiv.org/pdf/2204.05859v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14239v1","updated":"2023-02-28T01:44:55Z","published":"2023-02-28T01:44:55Z","title":"Nonlinear Intensity, Scale and Rotation Invariant Matching for\n  Multimodal Images","summary":"  We present an effective method for the matching of multimodal images.\nAccurate image matching is the basis of various applications, such as image\nregistration and structure from motion. Conventional matching methods fail when\nhandling noisy multimodal image pairs with severe scale change, rotation, and\nnonlinear intensity distortion (NID). Toward this need, we introduce an image\npyramid strategy to tackle scale change. We put forward an accurate primary\norientation estimation approach to reduce the effect of image rotation at any\nangle. We utilize multi-scale and multi-orientation image filtering results and\na feature-to-template matching scheme to ensure effective and accurate matching\nunder large NID. Integrating these improvements significantly increases noise,\nscale, rotation, and NID invariant capability. Our experimental results confirm\nthe excellent ability to achieve high-quality matches across various multimodal\nimages. The proposed method outperforms the mainstream multimodal image\nmatching methods in qualitative and quantitative evaluations. Our\nimplementation is available at https://github.com/Zhongli-Fan/NISR.\n","authors":["Zhongli Fan","Li Zhang","Yuxuan Liu"],"pdf_url":"https://arxiv.org/pdf/2302.14239v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14237v1","updated":"2023-02-28T01:39:36Z","published":"2023-02-28T01:39:36Z","title":"Towards Surgical Context Inference and Translation to Gestures","summary":"  Manual labeling of gestures in robot-assisted surgery is labor intensive,\nprone to errors, and requires expertise or training. We propose a method for\nautomated and explainable generation of gesture transcripts that leverages the\nabundance of data for image segmentation to train a surgical scene segmentation\nmodel that provides surgical tool and object masks. Surgical context is\ndetected using segmentation masks by examining the distances and intersections\nbetween the tools and objects. Next, context labels are translated into gesture\ntranscripts using knowledge-based Finite State Machine (FSM) and data-driven\nLong Short Term Memory (LSTM) models. We evaluate the performance of each stage\nof our method by comparing the results with the ground truth segmentation\nmasks, the consensus context labels, and the gesture labels in the JIGSAWS\ndataset. Our results show that our segmentation models achieve state-of-the-art\nperformance in recognizing needle and thread in Suturing and we can\nautomatically detect important surgical states with high agreement with\ncrowd-sourced labels (e.g., contact between graspers and objects in Suturing).\nWe also find that the FSM models are more robust to poor segmentation and\nlabeling performance than LSTMs. Our proposed method can significantly shorten\nthe gesture labeling process (~2.8 times).\n","authors":["Kay Hutchinson","Zongyu Li","Ian Reyes","Homa Alemzadeh"],"pdf_url":"https://arxiv.org/pdf/2302.14237v1.pdf","comment":"accepted for the 2023 International Conference on Robotics and\n  Automation (ICRA)"},{"id":"http://arxiv.org/abs/2205.09949v4","updated":"2023-02-28T01:23:20Z","published":"2022-05-20T03:53:56Z","title":"HCFormer: Unified Image Segmentation with Hierarchical Clustering","summary":"  Hierarchical clustering is an effective and efficient approach widely used\nfor classical image segmentation methods. However, many existing methods using\nneural networks generate segmentation masks directly from per-pixel features,\ncomplicating the architecture design and degrading the interpretability. In\nthis work, we propose a simpler, more interpretable architecture, called\nHCFormer. HCFormer accomplishes image segmentation by bottom-up hierarchical\nclustering and allows us to interpret, visualize, and evaluate the intermediate\nresults as hierarchical clustering results. HCFormer can address semantic,\ninstance, and panoptic segmentation with the same architecture because the\npixel clustering is a common approach for various image segmentation tasks. In\nexperiments, HCFormer achieves comparable or superior segmentation accuracy\ncompared to baseline methods on semantic segmentation (55.5 mIoU on ADE20K),\ninstance segmentation (47.1 AP on COCO), and panoptic segmentation (55.7 PQ on\nCOCO).\n","authors":["Teppei Suzuki"],"pdf_url":"https://arxiv.org/pdf/2205.09949v4.pdf","comment":"Code: https://github.com/DensoITLab/HCFormer"},{"id":"http://arxiv.org/abs/2302.14217v1","updated":"2023-02-28T00:43:13Z","published":"2023-02-28T00:43:13Z","title":"Global Proxy-based Hard Mining for Visual Place Recognition","summary":"  Learning deep representations for visual place recognition is commonly\nperformed using pairwise or triple loss functions that highly depend on the\nhardness of the examples sampled at each training iteration. Existing\ntechniques address this by using computationally and memory expensive offline\nhard mining, which consists of identifying, at each iteration, the hardest\nsamples from the training set. In this paper we introduce a new technique that\nperforms global hard mini-batch sampling based on proxies. To do so, we add a\nnew end-to-end trainable branch to the network, which generates efficient place\ndescriptors (one proxy for each place). These proxy representations are thus\nused to construct a global index that encompasses the similarities between all\nplaces in the dataset, allowing for highly informative mini-batch sampling at\neach training iteration. Our method can be used in combination with all\nexisting pairwise and triplet loss functions with negligible additional memory\nand computation cost. We run extensive ablation studies and show that our\ntechnique brings new state-of-the-art performance on multiple large-scale\nbenchmarks such as Pittsburgh, Mapillary-SLS and SPED. In particular, our\nmethod provides more than 100% relative improvement on the challenging Nordland\ndataset. Our code is available at https://github.com/amaralibey/GPM\n","authors":["Amar Ali-bey","Brahim Chaib-draa","Philippe Giguère"],"pdf_url":"https://arxiv.org/pdf/2302.14217v1.pdf","comment":"Accepted at BMVC 2022"},{"id":"http://arxiv.org/abs/2303.00138v1","updated":"2023-02-28T23:56:31Z","published":"2023-02-28T23:56:31Z","title":"Video Pose Track with Graph-Guided Sparse Motion Estimation","summary":"  In this paper, we propose a novel framework for multi-person pose estimation\nand tracking under occlusions and motion blurs. Specifically, the consistency\nin graph structures from consecutive frames is improved by concentrating on\nvisible body joints and estimating the motion vectors of sparse key-points\nsurrounding visible joints. The proposed framework involves three components:\n(i) A Sparse Key-point Flow Estimating Module (SKFEM) for sampling key-points\nfrom around body joints and estimating the motion vectors of key-points which\ncontribute to the refinement of body joint locations and fine-tuning of pose\nestimators; (ii) A Hierarchical Graph Distance Minimizing Module (HGMM) for\nevaluating the visibility scores of nodes from hierarchical graphs with the\nvisibility score of a node determining the number of samples around that node;\nand (iii) The combination of multiple historical frames for matching\nidentities. Graph matching with HGMM facilitates more accurate tracking even\nunder partial occlusions. The proposed approach not only achieves\nstate-of-the-art performance on the PoseTrack dataset but also contributes to\nsignificant improvements in human-related anomaly detection. Besides a higher\naccuracy, the proposed SKFEM also shows a much higher efficiency than dense\noptical flow estimation.\n","authors":["Yalong Jiang","Wenrui Ding","Hongguang Li","Zheru Chi"],"pdf_url":"https://arxiv.org/pdf/2303.00138v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00137v1","updated":"2023-02-28T23:52:01Z","published":"2023-02-28T23:52:01Z","title":"PixHt-Lab: Pixel Height Based Light Effect Generation for Image\n  Compositing","summary":"  Lighting effects such as shadows or reflections are key in making synthetic\nimages realistic and visually appealing. To generate such effects, traditional\ncomputer graphics uses a physically-based renderer along with 3D geometry. To\ncompensate for the lack of geometry in 2D Image compositing, recent deep\nlearning-based approaches introduced a pixel height representation to generate\nsoft shadows and reflections. However, the lack of geometry limits the quality\nof the generated soft shadows and constrain reflections to pure specular ones.\nWe introduce PixHt-Lab, a system leveraging an explicit mapping from pixel\nheight representation to 3D space. Using this mapping, PixHt-Lab reconstructs\nboth the cutout and background geometry and renders realistic, diverse,\nlighting effects for image compositing. Given a surface with physically-based\nmaterials, we can render reflections with varying glossiness. To generate more\nrealistic soft shadows, we further propose to use 3D-aware buffer channels to\nguide a neural renderer. Both quantitative and qualitative evaluations\ndemonstrate that PixHt-Lab significantly improves soft shadow generation.\n","authors":["Yichen Sheng","Jianming Zhang","Julien Philip","Yannick Hold-Geoffroy","Xin Sun","HE Zhang","Lu Ling","Bedrich Benes"],"pdf_url":"https://arxiv.org/pdf/2303.00137v1.pdf","comment":"11 pages, 10 figures"},{"id":"http://arxiv.org/abs/2212.05032v3","updated":"2023-02-28T23:46:24Z","published":"2022-12-09T18:30:24Z","title":"Training-Free Structured Diffusion Guidance for Compositional\n  Text-to-Image Synthesis","summary":"  Large-scale diffusion models have achieved state-of-the-art results on\ntext-to-image synthesis (T2I) tasks. Despite their ability to generate\nhigh-quality yet creative images, we observe that attribution-binding and\ncompositional capabilities are still considered major challenging issues,\nespecially when involving multiple objects. In this work, we improve the\ncompositional skills of T2I models, specifically more accurate attribute\nbinding and better image compositions. To do this, we incorporate linguistic\nstructures with the diffusion guidance process based on the controllable\nproperties of manipulating cross-attention layers in diffusion-based T2I\nmodels. We observe that keys and values in cross-attention layers have strong\nsemantic meanings associated with object layouts and content. Therefore, we can\nbetter preserve the compositional semantics in the generated image by\nmanipulating the cross-attention representations based on linguistic insights.\nBuilt upon Stable Diffusion, a SOTA T2I model, our structured cross-attention\ndesign is efficient that requires no additional training samples. We achieve\nbetter compositional skills in qualitative and quantitative results, leading to\na 5-8% advantage in head-to-head user comparison studies. Lastly, we conduct an\nin-depth analysis to reveal potential causes of incorrect image compositions\nand justify the properties of cross-attention layers in the generation process.\n","authors":["Weixi Feng","Xuehai He","Tsu-Jui Fu","Varun Jampani","Arjun Akula","Pradyumna Narayana","Sugato Basu","Xin Eric Wang","William Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2212.05032v3.pdf","comment":"ICLR 2023 Camera Ready version"},{"id":"http://arxiv.org/abs/2203.12023v5","updated":"2023-02-28T23:25:05Z","published":"2022-03-22T20:24:21Z","title":"Generative Modeling Helps Weak Supervision (and Vice Versa)","summary":"  Many promising applications of supervised machine learning face hurdles in\nthe acquisition of labeled data in sufficient quantity and quality, creating an\nexpensive bottleneck. To overcome such limitations, techniques that do not\ndepend on ground truth labels have been studied, including weak supervision and\ngenerative modeling. While these techniques would seem to be usable in concert,\nimproving one another, how to build an interface between them is not\nwell-understood. In this work, we propose a model fusing programmatic weak\nsupervision and generative adversarial networks and provide theoretical\njustification motivating this fusion. The proposed approach captures discrete\nlatent variables in the data alongside the weak supervision derived label\nestimate. Alignment of the two allows for better modeling of sample-dependent\naccuracies of the weak supervision sources, improving the estimate of\nunobserved labels. It is the first approach to enable data augmentation through\nweakly supervised synthetic images and pseudolabels. Additionally, its learned\nlatent variables can be inspected qualitatively. The model outperforms baseline\nweak supervision label models on a number of multiclass image classification\ndatasets, improves the quality of generated images, and further improves\nend-model performance through data augmentation with synthetic samples.\n","authors":["Benedikt Boecking","Nicholas Roberts","Willie Neiswanger","Stefano Ermon","Frederic Sala","Artur Dubrawski"],"pdf_url":"https://arxiv.org/pdf/2203.12023v5.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2212.01433v2","updated":"2023-02-28T23:06:09Z","published":"2022-12-02T20:30:59Z","title":"Avoiding spurious correlations via logit correction","summary":"  Empirical studies suggest that machine learning models trained with empirical\nrisk minimization (ERM) often rely on attributes that may be spuriously\ncorrelated with the class labels. Such models typically lead to poor\nperformance during inference for data lacking such correlations. In this work,\nwe explicitly consider a situation where potential spurious correlations are\npresent in the majority of training data. In contrast with existing approaches,\nwhich use the ERM model outputs to detect the samples without spurious\ncorrelations and either heuristically upweight or upsample those samples, we\npropose the logit correction (LC) loss, a simple yet effective improvement on\nthe softmax cross-entropy loss, to correct the sample logit. We demonstrate\nthat minimizing the LC loss is equivalent to maximizing the group-balanced\naccuracy, so the proposed LC could mitigate the negative impacts of spurious\ncorrelations. Our extensive experimental results further reveal that the\nproposed LC loss outperforms state-of-the-art solutions on multiple popular\nbenchmarks by a large margin, an average 5.5\\% absolute improvement, without\naccess to spurious attribute labels. LC is also competitive with oracle methods\nthat make use of the attribute labels. Code is available at\nhttps://github.com/shengliu66/LC.\n","authors":["Sheng Liu","Xu Zhang","Nitesh Sekhar","Yue Wu","Prateek Singhal","Carlos Fernandez-Granda"],"pdf_url":"https://arxiv.org/pdf/2212.01433v2.pdf","comment":"17 pages, 6 figures"},{"id":"http://arxiv.org/abs/2303.00111v1","updated":"2023-02-28T22:26:18Z","published":"2023-02-28T22:26:18Z","title":"PixCUE -- Joint Uncertainty Estimation and Image Reconstruction in MRI\n  using Deep Pixel Classification","summary":"  Deep learning (DL) models are capable of successfully exploiting latent\nrepresentations in MR data and have become state-of-the-art for accelerated MRI\nreconstruction. However, undersampling the measurements in k-space as well as\nthe over- or under-parameterized and non-transparent nature of DL make these\nmodels exposed to uncertainty. Consequently, uncertainty estimation has become\na major issue in DL MRI reconstruction. To estimate uncertainty, Monte Carlo\n(MC) inference techniques have become a common practice where multiple\nreconstructions are utilized to compute the variance in reconstruction as a\nmeasurement of uncertainty. However, these methods demand high computational\ncosts as they require multiple inferences through the DL model. To this end, we\nintroduce a method to estimate uncertainty during MRI reconstruction using a\npixel classification framework. The proposed method, PixCUE (stands for Pixel\nClassification Uncertainty Estimation) produces the reconstructed image along\nwith an uncertainty map during a single forward pass through the DL model. We\ndemonstrate that this approach generates uncertainty maps that highly correlate\nwith the reconstruction errors with respect to various MR imaging sequences and\nunder numerous adversarial conditions. We also show that the estimated\nuncertainties are correlated to that of the conventional MC method. We further\nprovide an empirical relationship between the uncertainty estimations using\nPixCUE and well-established reconstruction metrics such as NMSE, PSNR, and\nSSIM. We conclude that PixCUE is capable of reliably estimating the uncertainty\nin MRI reconstruction with a minimum additional computational cost.\n","authors":["Mevan Ekanayake","Kamlesh Pawar","Gary Egan","Zhaolin Chen"],"pdf_url":"https://arxiv.org/pdf/2303.00111v1.pdf","comment":"19 pages, 7 figures, 1 table"},{"id":"http://arxiv.org/abs/2209.07896v2","updated":"2023-02-28T21:57:49Z","published":"2022-09-16T12:41:43Z","title":"3D VSG: Long-term Semantic Scene Change Prediction through 3D Variable\n  Scene Graphs","summary":"  Numerous applications require robots to operate in environments shared with\nother agents, such as humans or other robots. However, such shared scenes are\ntypically subject to different kinds of long-term semantic scene changes. The\nability to model and predict such changes is thus crucial for robot autonomy.\nIn this work, we formalize the task of semantic scene variability estimation\nand identify three main varieties of semantic scene change: changes in the\nposition of an object, its semantic state, or the composition of a scene as a\nwhole. To represent this variability, we propose the Variable Scene Graph\n(VSG), which augments existing 3D Scene Graph (SG) representations with the\nvariability attribute, representing the likelihood of discrete long-term change\nevents. We present a novel method, DeltaVSG, to estimate the variability of\nVSGs in a supervised fashion. We evaluate our method on the 3RScan long-term\ndataset, showing notable improvements in this novel task over existing\napproaches. Our method DeltaVSG achieves an accuracy of 77.1% and a recall of\n72.3%, often mimicking human intuition about how indoor scenes change over\ntime. We further show the utility of VSG prediction in the task of active\nrobotic change detection, speeding up task completion by 66.0% compared to a\nscene-change-unaware planner. We make our code available as open-source.\n","authors":["Samuel Looper","Javier Rodriguez-Puigvert","Roland Siegwart","Cesar Cadena","Lukas Schmid"],"pdf_url":"https://arxiv.org/pdf/2209.07896v2.pdf","comment":"Accepted for IEEE International Conference on Robotics and Automation\n  (ICRA) 2023. 8 pages, 4 figures, code released at\n  https://github.com/ethz-asl/3d_vsg"},{"id":"http://arxiv.org/abs/2303.00092v1","updated":"2023-02-28T21:32:49Z","published":"2023-02-28T21:32:49Z","title":"A study on the use of perceptual hashing to detect manipulation of\n  embedded messages in images","summary":"  Typically, metadata of images are stored in a specific data segment of the\nimage file. However, to securely detect changes, data can also be embedded\nwithin images. This follows the goal to invisibly and robustly embed as much\ninformation as possible to, ideally, even survive compression.\n  This work searches for embedding principles which allow to distinguish\nbetween unintended changes by lossy image compression and malicious\nmanipulation of the embedded message based on the change of its perceptual or\nrobust hash. Different embedding and compression algorithms are compared.\n  The study shows that embedding a message via integer wavelet transform and\ncompression with Karhunen-Loeve-transform yields the best results. However, it\nwas not possible to distinguish between manipulation and compression in all\ncases.\n","authors":["Sven-Jannik Wöhnert","Kai Hendrik Wöhnert","Eldar Almamedov","Carsten Frank","Volker Skwarek"],"pdf_url":"https://arxiv.org/pdf/2303.00092v1.pdf","comment":"12 pages, 3 figures submitted, accepted and presented at IPCV 2022,\n  subconference of CSCE, https://american-cse.org/csce2022/conferences-IPCV as\n  the publication of the proceedings is delayed, the permission for a\n  (pre-)publication on arxiv was granted\n  https://american-cse.org/csce2022/publisher"},{"id":"http://arxiv.org/abs/2209.08196v2","updated":"2023-02-28T21:30:32Z","published":"2022-09-16T23:29:48Z","title":"Lossless SIMD Compression of LiDAR Range and Attribute Scan Sequences","summary":"  As LiDAR sensors have become ubiquitous, the need for an efficient LiDAR data\ncompression algorithm has increased. Modern LiDARs produce gigabytes of scan\ndata per hour and are often used in applications with limited compute,\nbandwidth, and storage resources.\n  We present a fast, lossless compression algorithm for LiDAR range and\nattribute scan sequences including multiple-return range, signal, reflectivity,\nand ambient infrared. Our algorithm -- dubbed \"Jiffy\" -- achieves substantial\ncompression by exploiting spatiotemporal redundancy and sparsity. Speed is\naccomplished by maximizing use of single-instruction-multiple-data (SIMD)\ninstructions. In autonomous driving, infrastructure monitoring, drone\ninspection, and handheld mapping benchmarks, the Jiffy algorithm consistently\noutcompresses competing lossless codecs while operating at speeds in excess of\n65M points/sec on a single core. In a typical autonomous vehicle use case,\nsingle-threaded Jiffy achieves 6x compression of centimeter-precision range\nscans at 500+ scans per second. To ensure reproducibility and enable adoption,\nthe software is freely available as an open source library.\n","authors":["Jeff Ford","Jordan Ford"],"pdf_url":"https://arxiv.org/pdf/2209.08196v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00086v1","updated":"2023-02-28T21:06:36Z","published":"2023-02-28T21:06:36Z","title":"Applying Plain Transformers to Real-World Point Clouds","summary":"  Due to the lack of inductive bias, transformer-based models usually require a\nlarge amount of training data. The problem is especially concerning in 3D\nvision, as 3D data are harder to acquire and annotate. To overcome this\nproblem, previous works modify the architecture of transformers to incorporate\ninductive biases by applying, e.g., local attention and down-sampling. Although\nthey have achieved promising results, earlier works on transformers for point\nclouds have two issues. First, the power of plain transformers is still\nunder-explored. Second, they focus on simple and small point clouds instead of\ncomplex real-world ones. This work revisits the plain transformers in\nreal-world point cloud understanding. We first take a closer look at some\nfundamental components of plain transformers, e.g., patchifier and positional\nembedding, for both efficiency and performance. To close the performance gap\ndue to the lack of inductive bias and annotated data, we investigate\nself-supervised pre-training with masked autoencoder (MAE). Specifically, we\npropose drop patch, which prevents information leakage and significantly\nimproves the effectiveness of MAE. Our models achieve SOTA results in semantic\nsegmentation on the S3DIS dataset and object detection on the ScanNet dataset\nwith lower computational costs. Our work provides a new baseline for future\nresearch on transformers for point clouds.\n","authors":["Lanxiao Li","Michael Heizmann"],"pdf_url":"https://arxiv.org/pdf/2303.00086v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10859v2","updated":"2023-02-28T20:33:45Z","published":"2023-02-21T18:16:20Z","title":"SF2Former: Amyotrophic Lateral Sclerosis Identification From\n  Multi-center MRI Data Using Spatial and Frequency Fusion Transformer","summary":"  Amyotrophic Lateral Sclerosis (ALS) is a complex neurodegenerative disorder\ninvolving motor neuron degeneration. Significant research has begun to\nestablish brain magnetic resonance imaging (MRI) as a potential biomarker to\ndiagnose and monitor the state of the disease. Deep learning has turned into a\nprominent class of machine learning programs in computer vision and has been\nsuccessfully employed to solve diverse medical image analysis tasks. However,\ndeep learning-based methods applied to neuroimaging have not achieved superior\nperformance in ALS patients classification from healthy controls due to having\ninsignificant structural changes correlated with pathological features.\nTherefore, the critical challenge in deep models is to determine useful\ndiscriminative features with limited training data. By exploiting the\nlong-range relationship of image features, this study introduces a framework\nnamed SF2Former that leverages vision transformer architecture's power to\ndistinguish the ALS subjects from the control group. To further improve the\nnetwork's performance, spatial and frequency domain information are combined\nbecause MRI scans are captured in the frequency domain before being converted\nto the spatial domain. The proposed framework is trained with a set of\nconsecutive coronal 2D slices, which uses the pre-trained weights on ImageNet\nby leveraging transfer learning. Finally, a majority voting scheme has been\nemployed to those coronal slices of a particular subject to produce the final\nclassification decision. Our proposed architecture has been thoroughly assessed\nwith multi-modal neuroimaging data using two well-organized versions of the\nCanadian ALS Neuroimaging Consortium (CALSNIC) multi-center datasets. The\nexperimental results demonstrate the superiority of our proposed strategy in\nterms of classification accuracy compared with several popular deep\nlearning-based techniques.\n","authors":["Rafsanjany Kushol","Collin C. Luk","Avyarthana Dey","Michael Benatar","Hannah Briemberg","Annie Dionne","Nicolas Dupré","Richard Frayne","Angela Genge","Summer Gibson","Simon J. Graham","Lawrence Korngut","Peter Seres","Robert C. Welsh","Alan Wilman","Lorne Zinman","Sanjay Kalra","Yee-Hong Yang"],"pdf_url":"https://arxiv.org/pdf/2302.10859v2.pdf","comment":"17 pages, 8 figures"},{"id":"http://arxiv.org/abs/2203.04450v2","updated":"2023-02-28T20:21:57Z","published":"2022-03-08T23:44:01Z","title":"How to exploit hyperspherical embeddings for out-of-distribution\n  detection?","summary":"  Out-of-distribution (OOD) detection is a critical task for reliable machine\nlearning. Recent advances in representation learning give rise to\ndistance-based OOD detection, where testing samples are detected as OOD if they\nare relatively far away from the centroids or prototypes of in-distribution\n(ID) classes. However, prior methods directly take off-the-shelf contrastive\nlosses that suffice for classifying ID samples, but are not optimally designed\nwhen test inputs contain OOD samples. In this work, we propose CIDER, a novel\nrepresentation learning framework that exploits hyperspherical embeddings for\nOOD detection. CIDER jointly optimizes two losses to promote strong ID-OOD\nseparability: a dispersion loss that promotes large angular distances among\ndifferent class prototypes, and a compactness loss that encourages samples to\nbe close to their class prototypes. We analyze and establish the unexplored\nrelationship between OOD detection performance and the embedding properties in\nthe hyperspherical space, and demonstrate the importance of dispersion and\ncompactness. CIDER establishes superior performance, outperforming the latest\nrival by 19.36% in FPR95. Code is available at\nhttps://github.com/deeplearning-wisc/cider.\n","authors":["Yifei Ming","Yiyou Sun","Ousmane Dia","Yixuan Li"],"pdf_url":"https://arxiv.org/pdf/2203.04450v2.pdf","comment":"Published at ICLR 2023"},{"id":"http://arxiv.org/abs/2212.03516v2","updated":"2023-02-28T19:56:16Z","published":"2022-12-07T08:46:04Z","title":"Site Assessment and Layout Optimization for Rooftop Solar Energy\n  Generation in Worldview-3 Imagery","summary":"  With the growth of residential rooftop PV adoption in recent decades, the\nproblem of effective layout design has become increasingly important in recent\nyears. Although a number of automated methods have been introduced, these tend\nto rely on simplifying assumptions and heuristics to improve computational\ntractability. We demonstrate a fully automated layout design pipeline that\nattempts to solve a more general formulation with greater geometric flexibility\nthat accounts for shading losses. Our approach generates rooftop areas from\nsatellite imagery and uses MINLP optimization to select panel positions,\nazimuth angles and tilt angles on an individual basis rather than imposing any\npredefined layouts. Our results demonstrate that shading plays a critical role\nin automated rooftop PV optimization and significantly changes the resulting\nlayouts. Additionally, they suggest that, although several common heuristics\nare often effective, they may not be universally suitable due to complications\nresulting from geometric restrictions and shading losses. Finally, we evaluate\na few specific heuristics from the literature and propose a potential new rule\nof thumb that may help improve rooftop solar energy potential when shading\neffects are considered.\n","authors":["Zeyad Awwad","Abdulaziz Alharbi","Abdulelah H. Habib","Olivier L. de Weck"],"pdf_url":"https://arxiv.org/pdf/2212.03516v2.pdf","comment":"Final draft"},{"id":"http://arxiv.org/abs/2303.00050v1","updated":"2023-02-28T19:47:30Z","published":"2023-02-28T19:47:30Z","title":"Dynamic Multi-View Scene Reconstruction Using Neural Implicit Surface","summary":"  Reconstructing general dynamic scenes is important for many computer vision\nand graphics applications. Recent works represent the dynamic scene with neural\nradiance fields for photorealistic view synthesis, while their surface geometry\nis under-constrained and noisy. Other works introduce surface constraints to\nthe implicit neural representation to disentangle the ambiguity of geometry and\nappearance field for static scene reconstruction. To bridge the gap between\nrendering dynamic scenes and recovering static surface geometry, we propose a\ntemplate-free method to reconstruct surface geometry and appearance using\nneural implicit representations from multi-view videos. We leverage\ntopology-aware deformation and the signed distance field to learn complex\ndynamic surfaces via differentiable volume rendering without scene-specific\nprior knowledge like template models. Furthermore, we propose a novel\nmask-based ray selection strategy to significantly boost the optimization on\nchallenging time-varying regions. Experiments on different multi-view video\ndatasets demonstrate that our method achieves high-fidelity surface\nreconstruction as well as photorealistic novel view synthesis.\n","authors":["Decai Chen","Haofei Lu","Ingo Feldmann","Oliver Schreer","Peter Eisert"],"pdf_url":"https://arxiv.org/pdf/2303.00050v1.pdf","comment":"5 pages, accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.00040v1","updated":"2023-02-28T19:29:05Z","published":"2023-02-28T19:29:05Z","title":"Towards Generalisable Video Moment Retrieval: Visual-Dynamic Injection\n  to Image-Text Pre-Training","summary":"  The correlation between the vision and text is essential for video moment\nretrieval (VMR), however, existing methods heavily rely on separate\npre-training feature extractors for visual and textual understanding. Without\nsufficient temporal boundary annotations, it is non-trivial to learn universal\nvideo-text alignments. In this work, we explore multi-modal correlations\nderived from large-scale image-text data to facilitate generalisable VMR. To\naddress the limitations of image-text pre-training models on capturing the\nvideo changes, we propose a generic method, referred to as Visual-Dynamic\nInjection (VDI), to empower the model's understanding of video moments. Whilst\nexisting VMR methods are focusing on building temporal-aware video features,\nbeing aware of the text descriptions about the temporal changes is also\ncritical but originally overlooked in pre-training by matching static images\nwith sentences. Therefore, we extract visual context and spatial dynamic\ninformation from video frames and explicitly enforce their alignments with the\nphrases describing video changes (e.g. verb). By doing so, the potentially\nrelevant visual and motion patterns in videos are encoded in the corresponding\ntext embeddings (injected) so to enable more accurate video-text alignments. We\nconduct extensive experiments on two VMR benchmark datasets (Charades-STA and\nActivityNet-Captions) and achieve state-of-the-art performances. Especially,\nVDI yields notable advantages when being tested on the out-of-distribution\nsplits where the testing samples involve novel scenes and vocabulary.\n","authors":["Dezhao Luo","Jiabo Huang","Shaogang Gong","Hailin Jin","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2303.00040v1.pdf","comment":"Accepted by CVPR2023"},{"id":"http://arxiv.org/abs/2302.14835v1","updated":"2023-02-28T18:32:16Z","published":"2023-02-28T18:32:16Z","title":"Novel Machine Learning Approach for Predicting Poverty using Temperature\n  and Remote Sensing Data in Ethiopia","summary":"  In many developing nations, a lack of poverty data prevents critical\nhumanitarian organizations from responding to large-scale crises. Currently,\nsocioeconomic surveys are the only method implemented on a large scale for\norganizations and researchers to measure and track poverty. However, the\ninability to collect survey data efficiently and inexpensively leads to\nsignificant temporal gaps in poverty data; these gaps severely limit the\nability of organizational entities to address poverty at its root cause. We\npropose a transfer learning model based on surface temperature change and\nremote sensing data to extract features useful for predicting poverty rates.\nMachine learning, supported by data sources of poverty indicators, has the\npotential to estimate poverty rates accurately and within strict time\nconstraints. Higher temperatures, as a result of climate change, have caused\nnumerous agricultural obstacles, socioeconomic issues, and environmental\ndisruptions, trapping families in developing countries in cycles of poverty. To\nfind patterns of poverty relating to temperature that have the highest\ninfluence on spatial poverty rates, we use remote sensing data. The two-step\ntransfer model predicts the temperature delta from high resolution satellite\nimagery and then extracts image features useful for predicting poverty. The\nresulting model achieved 80% accuracy on temperature prediction. This method\ntakes advantage of abundant satellite and temperature data to measure poverty\nin a manner comparable to the existing survey methods and exceeds similar\nmodels of poverty prediction.\n","authors":["Om Shah","Krti Tallam"],"pdf_url":"https://arxiv.org/pdf/2302.14835v1.pdf","comment":"12 pages, 3 figures, title page included"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2302.03561v2","updated":"2023-02-28T16:41:22Z","published":"2023-02-07T16:17:25Z","title":"Optimizing Audio Recommendations for the Long-Term: A Reinforcement\n  Learning Perspective","summary":"  We study the problem of optimizing a recommender system for outcomes that\noccur over several weeks or months. We begin by drawing on reinforcement\nlearning to formulate a comprehensive model of users' recurring relationships\nwith a recommender system. Measurement, attribution, and coordination\nchallenges complicate algorithm design. We describe careful modeling --\nincluding a new representation of user state and key conditional independence\nassumptions -- which overcomes these challenges and leads to simple, testable\nrecommender system prototypes. We apply our approach to a podcast recommender\nsystem that makes personalized recommendations to hundreds of millions of\nlisteners. A/B tests demonstrate that purposefully optimizing for long-term\noutcomes leads to large performance gains over conventional approaches that\noptimize for short-term proxies.\n","authors":["Lucas Maystre","Daniel Russo","Yu Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.03561v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14723v1","updated":"2023-02-28T16:32:38Z","published":"2023-02-28T16:32:38Z","title":"Extending English IR methods to multi-lingual IR","summary":"  This paper describes our participation in the 2023 WSDM CUP - MIRACL\nchallenge. Via a combination of i) document translation; ii) multilingual\nSPLADE and Contriever; and iii) multilingual RankT5 and many other models, we\nwere able to get first place in both the known and surprise languages tracks.\nOur strategy mostly revolved around getting the most diverse runs for the first\nstage and then throwing all possible reranking techniques. While this was not a\nfirst for many techniques, we had some things that we believe were never tried\nbefore, for example, we train the first SPLADE model that is effectively\ncapable of working in more than 10 languages. However, a more careful study of\nthe results is needed in order to verify if we were able to get first place\njust due to brute force or if the hybrids we developed really brought\nimprovements over the other team's solutions.\n","authors":["Carlos Lassance"],"pdf_url":"https://arxiv.org/pdf/2302.14723v1.pdf","comment":"Description of the runs that got 1st place on both tasks at WSDM CUP\n  2023 - MIRACL"},{"id":"http://arxiv.org/abs/2302.14640v1","updated":"2023-02-28T15:18:42Z","published":"2023-02-28T15:18:42Z","title":"Meta-Learning with Adaptive Weighted Loss for Imbalanced Cold-Start\n  Recommendation","summary":"  Sequential recommenders have made great strides in capturing a user's\npreferences. Nevertheless, the cold-start recommendation remains a fundamental\nchallenge in which only a few user-item interactions are available for\npersonalization. Gradient-based meta-learning approaches have recently emerged\nin the sequential recommendation field due to their fast adaptation and\neasy-to-integrate abilities. The meta-learning algorithms formulate the\ncold-start recommendation as a few-shot learning problem, where each user is\nrepresented as a task to be adapted. However, while meta-learning algorithms\ngenerally assume that task-wise samples are evenly distributed over classes or\nvalues, user-item interactions are not that way in real-world applications\n(e.g., watching favorite videos multiple times, leaving only good ratings and\nno bad ones). As a result, in the real-world, imbalanced user feedback that\naccounts for most task training data may dominate the user adaptation and\nprevent meta-learning algorithms from learning meaningful meta-knowledge for\npersonalized recommendations. To alleviate this limitation, we propose a novel\nsequential recommendation framework based on gradient-based meta-learning that\ncaptures the imbalance of each user's rating distribution and accordingly\ncomputes adaptive loss for user-specific learning. It is the first work to\ntackle the impact of imbalanced ratings in cold-start sequential recommendation\nscenarios. We design adaptive weighted loss and improve the existing\nmeta-learning algorithms for state-of-the-art sequential recommendation\nmethods. Extensive experiments conducted on real-world datasets demonstrate the\neffectiveness of our framework.\n","authors":["Minchang Kim","Yongjin Yang","Jung Hyun Ryu","Taesup Kim"],"pdf_url":"https://arxiv.org/pdf/2302.14640v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14534v1","updated":"2023-02-28T12:44:10Z","published":"2023-02-28T12:44:10Z","title":"Spacerini: Plug-and-play Search Engines with Pyserini and Hugging Face","summary":"  We present Spacerini, a modular framework for seamless building and\ndeployment of interactive search applications, designed to facilitate the\nqualitative analysis of large scale research datasets. Spacerini integrates\nfeatures from both the Pyserini toolkit and the Hugging Face ecosystem to ease\nthe indexing text collections and deploy them as search engines for ad-hoc\nexploration and to make the retrieval of relevant data points quick and\nefficient. The user-friendly interface enables searching through massive\ndatasets in a no-code fashion, making Spacerini broadly accessible to anyone\nlooking to qualitatively audit their text collections. This is useful both to\nIR~researchers aiming to demonstrate the capabilities of their indexes in a\nsimple and interactive way, and to NLP~researchers looking to better understand\nand audit the failure modes of large language models. The framework is open\nsource and available on GitHub: https://github.com/castorini/hf-spacerini, and\nincludes utilities to load, pre-process, index, and deploy local and web search\napplications. A portfolio of applications created with Spacerini for a\nmultitude of use cases can be found by visiting https://hf.co/spacerini.\n","authors":["Christopher Akiki","Odunayo Ogundepo","Aleksandra Piktus","Xinyu Zhang","Akintunde Oladipo","Jimmy Lin","Martin Potthast"],"pdf_url":"https://arxiv.org/pdf/2302.14534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14532v1","updated":"2023-02-28T12:43:17Z","published":"2023-02-28T12:43:17Z","title":"Rethinking Multi-Interest Learning for Candidate Matching in Recommender\n  Systems","summary":"  Existing research efforts for multi-interest candidate matching in\nrecommender systems mainly focus on improving model architecture or\nincorporating additional information, neglecting the importance of training\nschemes. This work revisits the training framework and uncovers two major\nproblems hindering the expressiveness of learned multi-interest\nrepresentations. First, the current training objective (i.e., uniformly sampled\nsoftmax) fails to effectively train discriminative representations in a\nmulti-interest learning scenario due to the severe increase in easy negative\nsamples. Second, a routing collapse problem is observed where each learned\ninterest may collapse to express information only from a single item, resulting\nin information loss. To address these issues, we propose the REMI framework,\nconsisting of an Interest-aware Hard Negative mining strategy (IHN) and a\nRouting Regularization (RR) method. IHN emphasizes interest-aware hard\nnegatives by proposing an ideal sampling distribution and developing a\nMonte-Carlo strategy for efficient approximation. RR prevents routing collapse\nby introducing a novel regularization term on the item-to-interest routing\nmatrices. These two components enhance the learned multi-interest\nrepresentations from both the optimization objective and the composition\ninformation. REMI is a general framework that can be readily applied to various\nexisting multi-interest candidate matching methods. Experiments on three\nreal-world datasets show our method can significantly improve state-of-the-art\nmethods with easy implementation and negligible computational overhead. The\nsource code will be released.\n","authors":["Yueqi Xie","Jingqi Gao","Peilin Zhou","Qichen Ye","Yining Hua","Jaeboum Kim","Fangzhao Wu","Sunghun Kim"],"pdf_url":"https://arxiv.org/pdf/2302.14532v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10632v3","updated":"2023-02-28T12:13:25Z","published":"2023-02-21T12:44:17Z","title":"Multi-Modal Self-Supervised Learning for Recommendation","summary":"  The online emergence of multi-modal sharing platforms (eg, TikTok, Youtube)\nis powering personalized recommender systems to incorporate various modalities\n(eg, visual, textual and acoustic) into the latent user representations. While\nexisting works on multi-modal recommendation exploit multimedia content\nfeatures in enhancing item embeddings, their model representation capability is\nlimited by heavy label reliance and weak robustness on sparse user behavior\ndata. Inspired by the recent progress of self-supervised learning in\nalleviating label scarcity issue, we explore deriving self-supervision signals\nwith effectively learning of modality-aware user preference and cross-modal\ndependencies. To this end, we propose a new Multi-Modal Self-Supervised\nLearning (MMSSL) method which tackles two key challenges. Specifically, to\ncharacterize the inter-dependency between the user-item collaborative view and\nitem multi-modal semantic view, we design a modality-aware interactive\nstructure learning paradigm via adversarial perturbations for data\naugmentation. In addition, to capture the effects that user's modality-aware\ninteraction pattern would interweave with each other, a cross-modal contrastive\nlearning approach is introduced to jointly preserve the inter-modal semantic\ncommonality and user preference diversity. Experiments on real-world datasets\nverify the superiority of our method in offering great potential for multimedia\nrecommendation over various state-of-the-art baselines. The implementation is\nreleased at: https://github.com/HKUDS/MMSSL.\n","authors":["Wei Wei","Chao Huang","Lianghao Xia","Chuxu Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.10632v3.pdf","comment":"This paper has been published as a full paper at WWW 2023"},{"id":"http://arxiv.org/abs/2210.09957v2","updated":"2023-02-28T10:26:48Z","published":"2022-10-18T16:11:55Z","title":"Contextual bandits with concave rewards, and an application to fair\n  ranking","summary":"  We consider Contextual Bandits with Concave Rewards (CBCR), a multi-objective\nbandit problem where the desired trade-off between the rewards is defined by a\nknown concave objective function, and the reward vector depends on an observed\nstochastic context. We present the first algorithm with provably vanishing\nregret for CBCR without restrictions on the policy space, whereas prior works\nwere restricted to finite policy spaces or tabular representations. Our\nsolution is based on a geometric interpretation of CBCR algorithms as\noptimization algorithms over the convex set of expected rewards spanned by all\nstochastic policies. Building on Frank-Wolfe analyses in constrained convex\noptimization, we derive a novel reduction from the CBCR regret to the regret of\na scalar-reward bandit problem. We illustrate how to apply the reduction\noff-the-shelf to obtain algorithms for CBCR with both linear and general reward\nfunctions, in the case of non-combinatorial actions. Motivated by fairness in\nrecommendation, we describe a special case of CBCR with rankings and\nfairness-aware objectives, leading to the first algorithm with regret\nguarantees for contextual combinatorial bandits with fairness of exposure.\n","authors":["Virginie Do","Elvis Dohmatob","Matteo Pirotta","Alessandro Lazaric","Nicolas Usunier"],"pdf_url":"https://arxiv.org/pdf/2210.09957v2.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2302.14438v1","updated":"2023-02-28T09:30:24Z","published":"2023-02-28T09:30:24Z","title":"Self-Supervised Interest Transfer Network via Prototypical Contrastive\n  Learning for Recommendation","summary":"  Cross-domain recommendation has attracted increasing attention from industry\nand academia recently. However, most existing methods do not exploit the\ninterest invariance between domains, which would yield sub-optimal solutions.\nIn this paper, we propose a cross-domain recommendation method: Self-supervised\nInterest Transfer Network (SITN), which can effectively transfer invariant\nknowledge between domains via prototypical contrastive learning. Specifically,\nwe perform two levels of cross-domain contrastive learning: 1)\ninstance-to-instance contrastive learning, 2) instance-to-cluster contrastive\nlearning. Not only that, we also take into account users' multi-granularity and\nmulti-view interests. With this paradigm, SITN can explicitly learn the\ninvariant knowledge of interest clusters between domains and accurately capture\nusers' intents and preferences. We conducted extensive experiments on a public\ndataset and a large-scale industrial dataset collected from one of the world's\nleading e-commerce corporations. The experimental results indicate that SITN\nachieves significant improvements over state-of-the-art recommendation methods.\nAdditionally, SITN has been deployed on a micro-video recommendation platform,\nand the online A/B testing results further demonstrate its practical value.\nSupplement is available at: https://github.com/fanqieCoffee/SITN-Supplement.\n","authors":["Guoqiang Sun","Yibin Shen","Sijin Zhou","Xiang Chen","Hongyan Liu","Chunming Wu","Chenyi Lei","Xianhui Wei","Fei Fang"],"pdf_url":"https://arxiv.org/pdf/2302.14438v1.pdf","comment":"9 pages, 3 figures, accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2302.14395v1","updated":"2023-02-28T08:23:15Z","published":"2023-02-28T08:23:15Z","title":"Item Cold Start Recommendation via Adversarial Variational Auto-encoder\n  Warm-up","summary":"  The gap between the randomly initialized item ID embedding and the\nwell-trained warm item ID embedding makes the cold items hard to suit the\nrecommendation system, which is trained on the data of historical warm items.\nTo alleviate the performance decline of new items recommendation, the\ndistribution of the new item ID embedding should be close to that of the\nhistorical warm items. To achieve this goal, we propose an Adversarial\nVariational Auto-encoder Warm-up model (AVAEW) to generate warm-up item ID\nembedding for cold items. Specifically, we develop a conditional variational\nauto-encoder model to leverage the side information of items for generating the\nwarm-up item ID embedding. Particularly, we introduce an adversarial module to\nenforce the alignment between warm-up item ID embedding distribution and\nhistorical item ID embedding distribution. We demonstrate the effectiveness and\ncompatibility of the proposed method by extensive offline experiments on public\ndatasets and online A/B tests on a real-world large-scale news recommendation\nplatform.\n","authors":["Shenzheng Zhang","Qi Tan","Xinzhi Zheng","Yi Ren","Xu Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.14395v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.09000v2","updated":"2023-02-28T04:18:29Z","published":"2022-09-19T13:25:38Z","title":"Reweighting Clicks with Dwell Time in Recommendation","summary":"  The click behavior is the most widely-used user positive feedback in\nrecommendation. However, simply considering each click equally in training may\nsuffer from clickbaits and title-content mismatching, and thus fail to\nprecisely capture users' real satisfaction on items. Dwell time could be viewed\nas a high-quality quantitative indicator of user preferences on each click,\nwhile existing recommendation models do not fully explore the modeling of dwell\ntime. In this work, we focus on reweighting clicks with dwell time in\nrecommendation. Precisely, we first define a new behavior named valid read,\nwhich helps to select high-quality click instances for different users and\nitems via dwell time. Next, we propose a normalized dwell time function to\nreweight click signals in training for recommendation. The Click reweighting\nmodel achieves significant improvements on both offline and online evaluations\nin real-world systems.\n","authors":["Ruobing Xie","Lin Ma","Shaoliang Zhang","Feng Xia","Leyu Lin"],"pdf_url":"https://arxiv.org/pdf/2209.09000v2.pdf","comment":"5 pages, accepted by WWW-2023 Companion"},{"id":"http://arxiv.org/abs/2303.00135v1","updated":"2023-02-28T23:40:41Z","published":"2023-02-28T23:40:41Z","title":"Deep learning for COVID-19 topic modelling via Twitter: Alpha, Delta and\n  Omicron","summary":"  Topic modelling with innovative deep learning methods has gained interest for\na wide range of applications that includes COVID-19. Topic modelling can\nprovide, psychological, social and cultural insights for understanding human\nbehaviour in extreme events such as the COVID-19 pandemic. In this paper, we\nuse prominent deep learning-based language models for COVID-19 topic modelling\ntaking into account data from emergence (Alpha) to the Omicron variant. We\napply topic modeling to review the public behaviour across the first, second\nand third waves based on Twitter dataset from India. Our results show that the\ntopics extracted for the subsequent waves had certain overlapping themes such\nas covers governance, vaccination, and pandemic management while novel issues\naroused in political, social and economic situation during COVID-19 pandemic.\nWe also found a strong correlation of the major topics qualitatively to news\nmedia prevalent at the respective time period. Hence, our framework has the\npotential to capture major issues arising during different phases of the\nCOVID-19 pandemic which can be extended to other countries and regions.\n","authors":["Janhavi Lande","Arti Pillay","Rohitash Chandra"],"pdf_url":"https://arxiv.org/pdf/2303.00135v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14757v1","updated":"2023-02-28T16:59:13Z","published":"2023-02-28T16:59:13Z","title":"Audio Retrieval for Multimodal Design Documents: A New Dataset and\n  Algorithms","summary":"  We consider and propose a new problem of retrieving audio files relevant to\nmultimodal design document inputs comprising both textual elements and visual\nimagery, e.g., birthday/greeting cards. In addition to enhancing user\nexperience, integrating audio that matches the theme/style of these inputs also\nhelps improve the accessibility of these documents (e.g., visually impaired\npeople can listen to the audio instead). While recent work in audio retrieval\nexists, these methods and datasets are targeted explicitly towards natural\nimages. However, our problem considers multimodal design documents (created by\nusers using creative software) substantially different from a naturally clicked\nphotograph. To this end, our first contribution is collecting and curating a\nnew large-scale dataset called Melodic-Design (or MELON), comprising design\ndocuments representing various styles, themes, templates, illustrations, etc.,\npaired with music audio. Given our paired image-text-audio dataset, our next\ncontribution is a novel multimodal cross-attention audio retrieval (MMCAR)\nalgorithm that enables training neural networks to learn a common shared\nfeature space across image, text, and audio dimensions. We use these learned\nfeatures to demonstrate that our method outperforms existing state-of-the-art\nmethods and produce a new reference benchmark for the research community on our\nnew dataset.\n","authors":["Prachi Singh","Srikrishna Karanam","Sumit Shekhar"],"pdf_url":"https://arxiv.org/pdf/2302.14757v1.pdf","comment":"5 pages including references"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2302.14853v1","updated":"2023-02-28T18:51:55Z","published":"2023-02-28T18:51:55Z","title":"An Efficient Tester-Learner for Halfspaces","summary":"  We give the first efficient algorithm for learning halfspaces in the testable\nlearning model recently defined by Rubinfeld and Vasilyan (2023). In this\nmodel, a learner certifies that the accuracy of its output hypothesis is near\noptimal whenever the training set passes an associated test, and training sets\ndrawn from some target distribution -- e.g., the Gaussian -- must pass the\ntest. This model is more challenging than distribution-specific agnostic or\nMassart noise models where the learner is allowed to fail arbitrarily if the\ndistributional assumption does not hold.\n  We consider the setting where the target distribution is Gaussian (or more\ngenerally any strongly log-concave distribution) in $d$ dimensions and the\nnoise model is either Massart or adversarial (agnostic). For Massart noise our\ntester-learner runs in polynomial time and outputs a hypothesis with error\n$\\mathsf{opt} + \\epsilon$, which is information-theoretically optimal. For\nadversarial noise our tester-learner has error $\\tilde{O}(\\mathsf{opt}) +\n\\epsilon$ and runs in quasipolynomial time.\n  Prior work on testable learning ignores the labels in the training set and\nchecks that the empirical moments of the covariates are close to the moments of\nthe base distribution. Here we develop new tests of independent interest that\nmake critical use of the labels and combine them with the moment-matching\napproach of Gollakota et al. (2023). This enables us to simulate a variant of\nthe algorithm of Diakonikolas et al. (2020) for learning noisy halfspaces using\nnonconvex SGD but in the testable learning setting.\n","authors":["Aravind Gollakota","Adam R. Klivans","Konstantinos Stavropoulos","Arsen Vasilyan"],"pdf_url":"https://arxiv.org/pdf/2302.14853v1.pdf","comment":"23 pages, 3 figures"},{"id":"http://arxiv.org/abs/2302.10261v2","updated":"2023-02-28T18:50:45Z","published":"2023-02-20T19:47:25Z","title":"Deep Reinforcement Learning for Cost-Effective Medical Diagnosis","summary":"  Dynamic diagnosis is desirable when medical tests are costly or\ntime-consuming. In this work, we use reinforcement learning (RL) to find a\ndynamic policy that selects lab test panels sequentially based on previous\nobservations, ensuring accurate testing at a low cost. Clinical diagnostic data\nare often highly imbalanced; therefore, we aim to maximize the $F_1$ score\ninstead of the error rate. However, optimizing the non-concave $F_1$ score is\nnot a classic RL problem, thus invalidates standard RL methods. To remedy this\nissue, we develop a reward shaping approach, leveraging properties of the $F_1$\nscore and duality of policy optimization, to provably find the set of all\nPareto-optimal policies for budget-constrained $F_1$ score maximization. To\nhandle the combinatorially complex state space, we propose a Semi-Model-based\nDeep Diagnosis Policy Optimization (SM-DDPO) framework that is compatible with\nend-to-end training and online learning. SM-DDPO is tested on diverse clinical\ntasks: ferritin abnormality detection, sepsis mortality prediction, and acute\nkidney injury diagnosis. Experiments with real-world data validate that SM-DDPO\ntrains efficiently and identifies all Pareto-front solutions. Across all tasks,\nSM-DDPO is able to achieve state-of-the-art diagnosis accuracy (in some cases\nhigher than conventional methods) with up to $85\\%$ reduction in testing cost.\nThe code is available at\n[https://github.com/Zheng321/Deep-Reinforcement-Learning-for-Cost-Effective-Medical-Diagnosis].\n","authors":["Zheng Yu","Yikuan Li","Joseph Kim","Kaixuan Huang","Yuan Luo","Mengdi Wang"],"pdf_url":"https://arxiv.org/pdf/2302.10261v2.pdf","comment":"Accepted to ICRL 2023"},{"id":"http://arxiv.org/abs/2302.14843v1","updated":"2023-02-28T18:42:11Z","published":"2023-02-28T18:42:11Z","title":"High Probability Convergence of Stochastic Gradient Methods","summary":"  In this work, we describe a generic approach to show convergence with high\nprobability for both stochastic convex and non-convex optimization with\nsub-Gaussian noise. In previous works for convex optimization, either the\nconvergence is only in expectation or the bound depends on the diameter of the\ndomain. Instead, we show high probability convergence with bounds depending on\nthe initial distance to the optimal solution. The algorithms use step sizes\nanalogous to the standard settings and are universal to Lipschitz functions,\nsmooth functions, and their linear combinations. This method can be applied to\nthe non-convex case. We demonstrate an\n$O((1+\\sigma^{2}\\log(1/\\delta))/T+\\sigma/\\sqrt{T})$ convergence rate when the\nnumber of iterations $T$ is known and an\n$O((1+\\sigma^{2}\\log(T/\\delta))/\\sqrt{T})$ convergence rate when $T$ is unknown\nfor SGD, where $1-\\delta$ is the desired success probability. These bounds\nimprove over existing bounds in the literature. Additionally, we demonstrate\nthat our techniques can be used to obtain high probability bound for\nAdaGrad-Norm (Ward et al., 2019) that removes the bounded gradients assumption\nfrom previous works. Furthermore, our technique for AdaGrad-Norm extends to the\nstandard per-coordinate AdaGrad algorithm (Duchi et al., 2011), providing the\nfirst noise-adapted high probability convergence for AdaGrad.\n","authors":["Zijian Liu","Ta Duy Nguyen","Thien Hang Nguyen","Alina Ene","Huy Lê Nguyen"],"pdf_url":"https://arxiv.org/pdf/2302.14843v1.pdf","comment":"This paper subsumes arXiv paper arxiv:2210.00679"},{"id":"http://arxiv.org/abs/2210.06184v2","updated":"2023-02-28T18:40:52Z","published":"2022-10-07T17:27:50Z","title":"Images as Weight Matrices: Sequential Image Generation Through Synaptic\n  Learning Rules","summary":"  Work on fast weight programmers has demonstrated the effectiveness of\nkey/value outer product-based learning rules for sequentially generating a\nweight matrix (WM) of a neural net (NN) by another NN or itself. However, the\nweight generation steps are typically not visually interpretable by humans,\nbecause the contents stored in the WM of an NN are not. Here we apply the same\nprinciple to generate natural images. The resulting fast weight painters (FPAs)\nlearn to execute sequences of delta learning rules to sequentially generate\nimages as sums of outer products of self-invented keys and values, one rank at\na time, as if each image was a WM of an NN. We train our FPAs in the generative\nadversarial networks framework, and evaluate on various image datasets. We show\nhow these generic learning rules can generate images with respectable visual\nquality without any explicit inductive bias for images. While the performance\nlargely lags behind the one of specialised state-of-the-art image generators,\nour approach allows for visualising how synaptic learning rules iteratively\nproduce complex connection patterns, yielding human-interpretable meaningful\nimages. Finally, we also show that an additional convolutional U-Net (now\npopular in diffusion models) at the output of an FPA can learn one-step\n\"denoising\" of FPA-generated images to enhance their quality. Our code is\npublic.\n","authors":["Kazuki Irie","Jürgen Schmidhuber"],"pdf_url":"https://arxiv.org/pdf/2210.06184v2.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2210.09879v3","updated":"2023-02-28T18:35:23Z","published":"2022-10-18T14:13:20Z","title":"Unsupervised visualization of image datasets using contrastive learning","summary":"  Visualization methods based on the nearest neighbor graph, such as t-SNE or\nUMAP, are widely used for visualizing high-dimensional data. Yet, these\napproaches only produce meaningful results if the nearest neighbors themselves\nare meaningful. For images represented in pixel space this is not the case, as\ndistances in pixel space are often not capturing our sense of similarity and\ntherefore neighbors are not semantically close. This problem can be\ncircumvented by self-supervised approaches based on contrastive learning, such\nas SimCLR, relying on data augmentation to generate implicit neighbors, but\nthese methods do not produce two-dimensional embeddings suitable for\nvisualization. Here, we present a new method, called t-SimCNE, for unsupervised\nvisualization of image data. T-SimCNE combines ideas from contrastive learning\nand neighbor embeddings, and trains a parametric mapping from the\nhigh-dimensional pixel space into two dimensions. We show that the resulting 2D\nembeddings achieve classification accuracy comparable to the state-of-the-art\nhigh-dimensional SimCLR representations, thus faithfully capturing semantic\nrelationships. Using t-SimCNE, we obtain informative visualizations of the\nCIFAR-10 and CIFAR-100 datasets, showing rich cluster structure and\nhighlighting artifacts and outliers.\n","authors":["Jan Niklas Böhm","Philipp Berens","Dmitry Kobak"],"pdf_url":"https://arxiv.org/pdf/2210.09879v3.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2205.00511v2","updated":"2023-02-28T18:33:27Z","published":"2022-05-01T16:42:05Z","title":"An Early Fault Detection Method of Rotating Machines Based on Multiple\n  Feature Fusion with Stacking Architecture","summary":"  Early fault detection (EFD) of rotating machines is important to decrease the\nmaintenance cost and improve the mechanical system stability. One of the key\npoints of EFD is developing a generic model to extract robust and\ndiscriminative features from different equipment for early fault detection.\nMost existing EFD methods focus on learning fault representation by one type of\nfeature. However, a combination of multiple features can capture a more\ncomprehensive representation of system state. In this paper, we propose an EFD\nmethod based on multiple feature fusion with stacking architecture (M2FSA). The\nproposed method can extract generic and discriminiative features to detect\nearly faults by combining time domain (TD), frequency domain (FD), and\ntime-frequency domain (TFD) features. In order to unify the dimensions of the\ndifferent domain features, Stacked Denoising Autoencoder (SDAE) is utilized to\nlearn deep features in three domains. The architecture of the proposed M2FSA\nconsists of two layers. The first layer contains three base models, whose\ncorresponding inputs are different deep features. The outputs of the first\nlayer are concatenated to generate the input to the second layer, which\nconsists of a meta model. The proposed method is tested on three bearing\ndatasets. The results demonstrate that the proposed method is better than\nexisting methods both in sensibility and reliability.\n","authors":["Wenbin Song","Di Wu","Weiming Shen","Benoit Boulet"],"pdf_url":"https://arxiv.org/pdf/2205.00511v2.pdf","comment":"The results require to be updated"},{"id":"http://arxiv.org/abs/2302.14835v1","updated":"2023-02-28T18:32:16Z","published":"2023-02-28T18:32:16Z","title":"Novel Machine Learning Approach for Predicting Poverty using Temperature\n  and Remote Sensing Data in Ethiopia","summary":"  In many developing nations, a lack of poverty data prevents critical\nhumanitarian organizations from responding to large-scale crises. Currently,\nsocioeconomic surveys are the only method implemented on a large scale for\norganizations and researchers to measure and track poverty. However, the\ninability to collect survey data efficiently and inexpensively leads to\nsignificant temporal gaps in poverty data; these gaps severely limit the\nability of organizational entities to address poverty at its root cause. We\npropose a transfer learning model based on surface temperature change and\nremote sensing data to extract features useful for predicting poverty rates.\nMachine learning, supported by data sources of poverty indicators, has the\npotential to estimate poverty rates accurately and within strict time\nconstraints. Higher temperatures, as a result of climate change, have caused\nnumerous agricultural obstacles, socioeconomic issues, and environmental\ndisruptions, trapping families in developing countries in cycles of poverty. To\nfind patterns of poverty relating to temperature that have the highest\ninfluence on spatial poverty rates, we use remote sensing data. The two-step\ntransfer model predicts the temperature delta from high resolution satellite\nimagery and then extracts image features useful for predicting poverty. The\nresulting model achieved 80% accuracy on temperature prediction. This method\ntakes advantage of abundant satellite and temperature data to measure poverty\nin a manner comparable to the existing survey methods and exceeds similar\nmodels of poverty prediction.\n","authors":["Om Shah","Krti Tallam"],"pdf_url":"https://arxiv.org/pdf/2302.14835v1.pdf","comment":"12 pages, 3 figures, title page included"},{"id":"http://arxiv.org/abs/2302.14833v1","updated":"2023-02-28T18:31:07Z","published":"2023-02-28T18:31:07Z","title":"Learning to Control Autonomous Fleets from Observation via Offline\n  Reinforcement Learning","summary":"  Autonomous Mobility-on-Demand (AMoD) systems are a rapidly evolving mode of\ntransportation in which a centrally coordinated fleet of self-driving vehicles\ndynamically serves travel requests. The control of these systems is typically\nformulated as a large network optimization problem, and reinforcement learning\n(RL) has recently emerged as a promising approach to solve the open challenges\nin this space. However, current RL-based approaches exclusively focus on\nlearning from online data, fundamentally ignoring the per-sample-cost of\ninteractions within real-world transportation systems. To address these\nlimitations, we propose to formalize the control of AMoD systems through the\nlens of offline reinforcement learning and learn effective control strategies\nvia solely offline data, thus readily available to current mobility operators.\nWe further investigate design decisions and provide experiments on real-world\nmobility systems showing how offline learning allows to recover AMoD control\npolicies that (i) exhibit performance on par with online methods, (ii)\ndrastically improve data efficiency, and (iii) completely eliminate the need\nfor complex simulated environments. Crucially, this paper demonstrates that\noffline reinforcement learning is a promising paradigm for the application of\nRL-based solutions within economically-critical systems, such as mobility\nsystems.\n","authors":["Carolin Schmidt","Daniele Gammelli","Francisco Camara Pereira","Filipe Rodrigues"],"pdf_url":"https://arxiv.org/pdf/2302.14833v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.00112v2","updated":"2023-02-28T18:30:57Z","published":"2022-10-31T19:35:15Z","title":"Indexability is Not Enough for Whittle: Improved, Near-Optimal\n  Algorithms for Restless Bandits","summary":"  We study the problem of planning restless multi-armed bandits (RMABs) with\nmultiple actions. This is a popular model for multi-agent systems with\napplications like multi-channel communication, monitoring and machine\nmaintenance tasks, and healthcare. Whittle index policies, which are based on\nLagrangian relaxations, are widely used in these settings due to their\nsimplicity and near-optimality under certain conditions. In this work, we first\nshow that Whittle index policies can fail in simple and practically relevant\nRMAB settings, even when the RMABs are indexable. We discuss why the optimality\nguarantees fail and why asymptotic optimality may not translate well to\npractically relevant planning horizons.\n  We then propose an alternate planning algorithm based on the mean-field\nmethod, which can provably and efficiently obtain near-optimal policies with a\nlarge number of arms, without the stringent structural assumptions required by\nthe Whittle index policies. This borrows ideas from existing research with some\nimprovements: our approach is hyper-parameter free, and we provide an improved\nnon-asymptotic analysis which has: (a) no requirement for exogenous\nhyper-parameters and tighter polynomial dependence on known problem parameters;\n(b) high probability bounds which show that the reward of the policy is\nreliable; and (c) matching sub-optimality lower bounds for this algorithm with\nrespect to the number of arms, thus demonstrating the tightness of our bounds.\nOur extensive experimental analysis shows that the mean-field approach matches\nor outperforms other baselines.\n","authors":["Abheek Ghosh","Dheeraj Nagaraj","Manish Jain","Milind Tambe"],"pdf_url":"https://arxiv.org/pdf/2211.00112v2.pdf","comment":"21 pages; AAMAS'23 version with appendix"},{"id":"http://arxiv.org/abs/2302.09956v2","updated":"2023-02-28T18:30:37Z","published":"2023-02-20T12:57:31Z","title":"Because Every Sensor Is Unique, so Is Every Pair: Handling Dynamicity in\n  Traffic Forecasting","summary":"  Traffic forecasting is a critical task to extract values from cyber-physical\ninfrastructures, which is the backbone of smart transportation. However owing\nto external contexts, the dynamics at each sensor are unique. For example, the\nafternoon peaks at sensors near schools are more likely to occur earlier than\nthose near residential areas. In this paper, we first analyze real-world\ntraffic data to show that each sensor has a unique dynamic. Further analysis\nalso shows that each pair of sensors also has a unique dynamic. Then, we\nexplore how node embedding learns the unique dynamics at every sensor location.\nNext, we propose a novel module called Spatial Graph Transformers (SGT) where\nwe use node embedding to leverage the self-attention mechanism to ensure that\nthe information flow between two sensors is adaptive with respect to the unique\ndynamic of each pair. Finally, we present Graph Self-attention WaveNet (G-SWaN)\nto address the complex, non-linear spatiotemporal traffic dynamics. Through\nempirical experiments on four real-world, open datasets, we show that the\nproposed method achieves superior performance on both traffic speed and flow\nforecasting. Code is available at: https://github.com/aprbw/G-SWaN\n","authors":["Arian Prabowo","Wei Shao","Hao Xue","Piotr Koniusz","Flora D. Salim"],"pdf_url":"https://arxiv.org/pdf/2302.09956v2.pdf","comment":"20 pages, IoTDI 2023; Correction on Fig. 4"},{"id":"http://arxiv.org/abs/2302.14831v1","updated":"2023-02-28T18:28:35Z","published":"2023-02-28T18:28:35Z","title":"FacEDiM: A Face Embedding Distribution Model for Few-Shot Biometric\n  Authentication of Cattle","summary":"  This work proposes to solve the problem of few-shot biometric authentication\nby computing the Mahalanobis distance between testing embeddings and a\nmultivariate Gaussian distribution of training embeddings obtained using\npre-trained CNNs. Experimental results show that models pre-trained on the\nImageNet dataset significantly outperform models pre-trained on human faces.\nWith a VGG16 model, we obtain a FRR of 1.18% for a FAR of 1.25% on a dataset of\n20 cattle identities.\n","authors":["Meshia Cédric Oveneke","Rucha Vaishampayan","Deogratias Lukamba Nsadisa","Jenny Ambukiyenyi Onya"],"pdf_url":"https://arxiv.org/pdf/2302.14831v1.pdf","comment":"4 pages, 1 figure, 1 table, paper accepted at Black In AI at the 36th\n  Conference on Neural Information Processing Systems (NeurIPS 2022), New\n  Orleans, USA"},{"id":"http://arxiv.org/abs/2106.11943v2","updated":"2023-02-28T18:24:25Z","published":"2021-06-22T17:29:24Z","title":"Reusing Combinatorial Structure: Faster Iterative Projections over\n  Submodular Base Polytopes","summary":"  Optimization algorithms such as projected Newton's method, FISTA, mirror\ndescent, and its variants enjoy near-optimal regret bounds and convergence\nrates, but suffer from a computational bottleneck of computing ``projections''\nin potentially each iteration (e.g., $O(T^{1/2})$ regret of online mirror\ndescent). On the other hand, conditional gradient variants solve a linear\noptimization in each iteration, but result in suboptimal rates (e.g.,\n$O(T^{3/4})$ regret of online Frank-Wolfe). Motivated by this trade-off in\nruntime v/s convergence rates, we consider iterative projections of close-by\npoints over widely-prevalent submodular base polytopes $B(f)$. We first give\nnecessary and sufficient conditions for when two close points project to the\nsame face of a polytope, and then show that points far away from the polytope\nproject onto its vertices with high probability. We next use this theory and\ndevelop a toolkit to speed up the computation of iterative projections over\nsubmodular polytopes using both discrete and continuous perspectives. We\nsubsequently adapt the away-step Frank-Wolfe algorithm to use this information\nand enable early termination. For the special case of cardinality-based\nsubmodular polytopes, we improve the runtime of computing certain Bregman\nprojections by a factor of $\\Omega(n/\\log(n))$. Our theoretical results show\norders of magnitude reduction in runtime in preliminary computational\nexperiments.\n","authors":["Jai Moondra","Hassan Mortagy","Swati Gupta"],"pdf_url":"https://arxiv.org/pdf/2106.11943v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.09801v2","updated":"2023-02-28T18:00:06Z","published":"2022-11-17T18:59:03Z","title":"Machine Learned Calabi-Yau Metrics and Curvature","summary":"  Finding Ricci-flat (Calabi-Yau) metrics is a long standing problem in\ngeometry with deep implications for string theory and phenomenology. A new\nattack on this problem uses neural networks to engineer approximations to the\nCalabi-Yau metric within a given K\\\"ahler class. In this paper we investigate\nnumerical Ricci-flat metrics over smooth and singular K3 surfaces and\nCalabi-Yau threefolds. Using these Ricci-flat metric approximations for the\nCefal\\'u family of quartic twofolds and the Dwork family of quintic threefolds,\nwe study characteristic forms on these geometries. We observe that the\nnumerical stability of the numerically computed topological characteristic is\nheavily influenced by the choice of the neural network model, in particular, we\nbriefly discuss a different neural network model, namely Spectral networks,\nwhich correctly approximate the topological characteristic of a Calabi-Yau.\nUsing persistent homology, we show that high curvature regions of the manifolds\nform clusters near the singular points. For our neural network approximations,\nwe observe a Bogomolov--Yau type inequality $3c_2 \\geq c_1^2$ and observe an\nidentity when our geometries have isolated $A_1$ type singularities. We sketch\na proof that $\\chi(X~\\smallsetminus~\\mathrm{Sing}\\,{X}) +\n2~|\\mathrm{Sing}\\,{X}| = 24$ also holds for our numerical approximations.\n","authors":["Per Berglund","Giorgi Butbaia","Tristan Hübsch","Vishnu Jejjala","Damián Mayorga Peña","Challenger Mishra","Justin Tan"],"pdf_url":"https://arxiv.org/pdf/2211.09801v2.pdf","comment":"46 pages, 31 figures, 7 tables, 3 appendices: substantially updated\n  with more detailed and improved numerical computations; additional references\n  and discussion"},{"id":"http://arxiv.org/abs/2302.14808v1","updated":"2023-02-28T17:58:54Z","published":"2023-02-28T17:58:54Z","title":"Opto-UNet: Optimized UNet for Segmentation of Varicose Veins in Optical\n  Coherence Tomography","summary":"  Human veins are important for carrying the blood from the body-parts to the\nheart. The improper functioning of the human veins may arise from several\nvenous diseases. Varicose vein is one such disease wherein back flow of blood\ncan occur, often resulting in increased venous pressure or restricted blood\nflow due to changes in the structure of vein. To examine the functional\ncharacteristics of the varicose vein, it is crucial to study the physical and\nbio mechanical properties of the vein. This work proposes a segmentation model\nOpto-UNet, for segmenting the venous wall structure. Optical Coherence\nTomography system is used to acquire images of varicose vein. As the extracted\nvein is not uniform in shape, hence adequate method of segmentation is required\nto segment the venous wall. Opto-UNet model is based on the U-Net architecture\nwherein a new block is integrated into the architecture, employing atrous and\nseparable convolution to extract spatially wide-range and separable features\nmaps for attaining advanced performance. Furthermore, the depth wise separable\nconvolution significantly reduces the complexity of the network by optimizing\nthe number of parameters. The model achieves accuracy of 0.9830, sensitivity of\n0.8425 and specificity of 0.9980 using 8.54 million number of parameters. These\nresults indicate that model is highly adequate in segmenting the varicose vein\nwall without deteriorating the segmentation quality along with reduced\ncomplexity\n","authors":["Maryam Viqar","Violeta Madjarova","Vipul Baghel","Elena Stoykova"],"pdf_url":"https://arxiv.org/pdf/2302.14808v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.03675v3","updated":"2023-02-28T17:56:32Z","published":"2022-10-07T16:33:50Z","title":"Koopman Neural Forecaster for Time Series with Temporal Distribution\n  Shifts","summary":"  Temporal distributional shifts, with underlying dynamics changing over time,\nfrequently occur in real-world time series and pose a fundamental challenge for\ndeep neural networks (DNNs). In this paper, we propose a novel deep sequence\nmodel based on the Koopman theory for time series forecasting: Koopman Neural\nForecaster (KNF) which leverages DNNs to learn the linear Koopman space and the\ncoefficients of chosen measurement functions. KNF imposes appropriate inductive\nbiases for improved robustness against distributional shifts, employing both a\nglobal operator to learn shared characteristics and a local operator to capture\nchanging dynamics, as well as a specially-designed feedback loop to\ncontinuously update the learned operators over time for rapidly varying\nbehaviors. We demonstrate that \\ours{} achieves superior performance compared\nto the alternatives, on multiple time series datasets that are shown to suffer\nfrom distribution shifts.\n","authors":["Rui Wang","Yihe Dong","Sercan Ö. Arik","Rose Yu"],"pdf_url":"https://arxiv.org/pdf/2210.03675v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14806v1","updated":"2023-02-28T17:56:19Z","published":"2023-02-28T17:56:19Z","title":"Framelet Message Passing","summary":"  Graph neural networks (GNNs) have achieved champion in wide applications.\nNeural message passing is a typical key module for feature propagation by\naggregating neighboring features. In this work, we propose a new message\npassing based on multiscale framelet transforms, called Framelet Message\nPassing. Different from traditional spatial methods, it integrates framelet\nrepresentation of neighbor nodes from multiple hops away in node message\nupdate. We also propose a continuous message passing using neural ODE solvers.\nIt turns both discrete and continuous cases can provably achieve network\nstability and limit oversmoothing due to the multiscale property of framelets.\nNumerical experiments on real graph datasets show that the continuous version\nof the framelet message passing significantly outperforms existing methods when\nlearning heterogeneous graphs and achieves state-of-the-art performance on\nclassic node classification tasks with low computational costs.\n","authors":["Xinliang Liu","Bingxin Zhou","Chutian Zhang","Yu Guang Wang"],"pdf_url":"https://arxiv.org/pdf/2302.14806v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.15434v3","updated":"2023-02-28T17:53:00Z","published":"2022-05-30T21:20:30Z","title":"A Game-Theoretic Framework for Managing Risk in Multi-Agent Systems","summary":"  In order for agents in multi-agent systems (MAS) to be safe, they need to\ntake into account the risks posed by the actions of other agents. However, the\ndominant paradigm in game theory (GT) assumes that agents are not affected by\nrisk from other agents and only strive to maximise their expected utility. For\nexample, in hybrid human-AI driving systems, it is necessary to limit large\ndeviations in reward resulting from car crashes. Although there are equilibrium\nconcepts in game theory that take into account risk aversion, they either\nassume that agents are risk-neutral with respect to the uncertainty caused by\nthe actions of other agents, or they are not guaranteed to exist. We introduce\na new GT-based Risk-Averse Equilibrium (RAE) that always produces a solution\nthat minimises the potential variance in reward accounting for the strategy of\nother agents. Theoretically and empirically, we show RAE shares many properties\nwith a Nash Equilibrium (NE), establishing convergence properties and\ngeneralising to risk-dominant NE in certain cases. To tackle large-scale\nproblems, we extend RAE to the PSRO multi-agent reinforcement learning (MARL)\nframework. We empirically demonstrate the minimum reward variance benefits of\nRAE in matrix games with high-risk outcomes. Results on MARL experiments show\nRAE generalises to risk-dominant NE in a trust dilemma game and that it reduces\ninstances of crashing by 7x in an autonomous driving setting versus the best\nperforming baseline.\n","authors":["Oliver Slumbers","David Henry Mguni","Stephen Marcus McAleer","Stefano B. Blumberg","Jun Wang","Yaodong Yang"],"pdf_url":"https://arxiv.org/pdf/2205.15434v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.10445v2","updated":"2023-02-28T17:52:10Z","published":"2022-11-18T14:59:42Z","title":"Building a Subspace of Policies for Scalable Continual Learning","summary":"  The ability to continuously acquire new knowledge and skills is crucial for\nautonomous agents. Existing methods are typically based on either fixed-size\nmodels that struggle to learn a large number of diverse behaviors, or\ngrowing-size models that scale poorly with the number of tasks. In this work,\nwe aim to strike a better balance between an agent's size and performance by\ndesigning a method that grows adaptively depending on the task sequence. We\nintroduce Continual Subspace of Policies (CSP), a new approach that\nincrementally builds a subspace of policies for training a reinforcement\nlearning agent on a sequence of tasks. The subspace's high expressivity allows\nCSP to perform well for many different tasks while growing sublinearly with the\nnumber of tasks. Our method does not suffer from forgetting and displays\npositive transfer to new tasks. CSP outperforms a number of popular baselines\non a wide range of scenarios from two challenging domains, Brax (locomotion)\nand Continual World (manipulation).\n","authors":["Jean-Baptiste Gaya","Thang Doan","Lucas Caccia","Laure Soulier","Ludovic Denoyer","Roberta Raileanu"],"pdf_url":"https://arxiv.org/pdf/2211.10445v2.pdf","comment":"Accepted at ICLR2023 (notable-top-25%)"},{"id":"http://arxiv.org/abs/2302.14803v1","updated":"2023-02-28T17:51:43Z","published":"2023-02-28T17:51:43Z","title":"Learned Risk Metric Maps for Kinodynamic Systems","summary":"  We present Learned Risk Metric Maps (LRMM) for real-time estimation of\ncoherent risk metrics of high dimensional dynamical systems operating in\nunstructured, partially observed environments. LRMM models are simple to design\nand train -- requiring only procedural generation of obstacle sets, state and\ncontrol sampling, and supervised training of a function approximator -- which\nmakes them broadly applicable to arbitrary system dynamics and obstacle sets.\nIn a parallel autonomy setting, we demonstrate the model's ability to rapidly\ninfer collision probabilities of a fast-moving car-like robot driving\nrecklessly in an obstructed environment; allowing the LRMM agent to intervene,\ntake control of the vehicle, and avoid collisions. In this time-critical\nscenario, we show that LRMMs can evaluate risk metrics 20-100x times faster\nthan alternative safety algorithms based on control barrier functions (CBFs)\nand Hamilton-Jacobi reachability (HJ-reach), leading to 5-15\\% fewer obstacle\ncollisions by the LRMM agent than CBFs and HJ-reach. This performance\nimprovement comes in spite of the fact that the LRMM model only has access to\nlocal/partial observation of obstacles, whereas the CBF and HJ-reach agents are\ngranted privileged/global information. We also show that our model can be\nequally well trained on a 12-dimensional quadrotor system operating in an\nobstructed indoor environment. The LRMM codebase is provided at\nhttps://github.com/mit-drl/pyrmm.\n","authors":["Ross Allen","Wei Xiao","Daniela Rus"],"pdf_url":"https://arxiv.org/pdf/2302.14803v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14796v1","updated":"2023-02-28T17:46:32Z","published":"2023-02-28T17:46:32Z","title":"Particle-based Online Bayesian Sampling","summary":"  Online optimization has gained increasing interest due to its capability of\ntracking real-world streaming data. Although online optimization methods have\nbeen widely studied in the setting of frequentist statistics, few works have\nconsidered online optimization with the Bayesian sampling problem. In this\npaper, we study an Online Particle-based Variational Inference (OPVI) algorithm\nthat uses a set of particles to represent the approximating distribution. To\nreduce the gradient error caused by the use of stochastic approximation, we\ninclude a sublinear increasing batch-size method to reduce the variance. To\ntrack the performance of the OPVI algorithm with respect to a sequence of\ndynamically changing target posterior, we provide a detailed theoretical\nanalysis from the perspective of Wasserstein gradient flow with a dynamic\nregret. Synthetic and Bayesian Neural Network experiments show that the\nproposed algorithm achieves better results than naively applying existing\nBayesian sampling methods in the online setting.\n","authors":["Yifan Yang","Chang Liu","Zheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.14796v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03439v3","updated":"2023-02-28T17:33:36Z","published":"2023-02-07T12:51:20Z","title":"Ensemble Value Functions for Efficient Exploration in Multi-Agent\n  Reinforcement Learning","summary":"  Cooperative multi-agent reinforcement learning (MARL) requires agents to\nexplore to learn to cooperate. Existing value-based MARL algorithms commonly\nrely on random exploration, such as $\\epsilon$-greedy, which is inefficient in\ndiscovering multi-agent cooperation. Additionally, the environment in MARL\nappears non-stationary to any individual agent due to the simultaneous training\nof other agents, leading to highly variant and thus unstable optimisation\nsignals. In this work, we propose ensemble value functions for multi-agent\nexploration (EMAX), a general framework to extend any value-based MARL\nalgorithm. EMAX trains ensembles of value functions for each agent to address\nthe key challenges of exploration and non-stationarity: (1) The uncertainty of\nvalue estimates across the ensemble is used in a UCB policy to guide the\nexploration of agents to parts of the environment which require cooperation.\n(2) Average value estimates across the ensemble serve as target values. These\ntargets exhibit lower variance compared to commonly applied target networks and\nwe show that they lead to more stable gradients during the optimisation. We\ninstantiate three value-based MARL algorithms with EMAX, independent DQN, VDN\nand QMIX, and evaluate them in 21 tasks across four environments. Using\nensembles of five value functions, EMAX improves sample efficiency and final\nevaluation returns of these algorithms by 54%, 55%, and 844%, respectively,\naveraged all 21 tasks.\n","authors":["Lukas Schäfer","Oliver Slumbers","Stephen McAleer","Yali Du","Stefano V. Albrecht","David Mguni"],"pdf_url":"https://arxiv.org/pdf/2302.03439v3.pdf","comment":"Preprint. Under review"},{"id":"http://arxiv.org/abs/2206.01816v2","updated":"2023-02-28T17:32:58Z","published":"2022-06-03T20:50:54Z","title":"From $t$-SNE to UMAP with contrastive learning","summary":"  Neighbor embedding methods $t$-SNE and UMAP are the de facto standard for\nvisualizing high-dimensional datasets. Motivated from entirely different\nviewpoints, their loss functions appear to be unrelated. In practice, they\nyield strongly differing embeddings and can suggest conflicting interpretations\nof the same data. The fundamental reasons for this and, more generally, the\nexact relationship between $t$-SNE and UMAP have remained unclear. In this\nwork, we uncover their conceptual connection via a new insight into contrastive\nlearning methods. Noise-contrastive estimation can be used to optimize $t$-SNE,\nwhile UMAP relies on negative sampling, another contrastive method. We find the\nprecise relationship between these two contrastive methods and provide a\nmathematical characterization of the distortion introduced by negative\nsampling. Visually, this distortion results in UMAP generating more compact\nembeddings with tighter clusters compared to $t$-SNE. We exploit this new\nconceptual connection to propose and implement a generalization of negative\nsampling, allowing us to interpolate between (and even extrapolate beyond)\n$t$-SNE and UMAP and their respective embeddings. Moving along this spectrum of\nembeddings leads to a trade-off between discrete / local and continuous /\nglobal structures, mitigating the risk of over-interpreting ostensible features\nof any single embedding. We provide a PyTorch implementation.\n","authors":["Sebastian Damrich","Jan Niklas Böhm","Fred A. Hamprecht","Dmitry Kobak"],"pdf_url":"https://arxiv.org/pdf/2206.01816v2.pdf","comment":"ICLR 2023. 44 pages, 19 figures. Code at\n  https://github.com/hci-unihd/cl-tsne-umap and\n  https://github.com/berenslab/contrastive-ne"},{"id":"http://arxiv.org/abs/2205.13710v2","updated":"2023-02-28T17:32:27Z","published":"2022-05-27T02:09:55Z","title":"Privacy of Noisy Stochastic Gradient Descent: More Iterations without\n  More Privacy Loss","summary":"  A central issue in machine learning is how to train models on sensitive user\ndata. Industry has widely adopted a simple algorithm: Stochastic Gradient\nDescent with noise (a.k.a. Stochastic Gradient Langevin Dynamics). However,\nfoundational theoretical questions about this algorithm's privacy loss remain\nopen -- even in the seemingly simple setting of smooth convex losses over a\nbounded domain. Our main result resolves these questions: for a large range of\nparameters, we characterize the differential privacy up to a constant factor.\nThis result reveals that all previous analyses for this setting have the wrong\nqualitative behavior. Specifically, while previous privacy analyses increase ad\ninfinitum in the number of iterations, we show that after a small burn-in\nperiod, running SGD longer leaks no further privacy.\n  Our analysis departs from previous approaches based on fast mixing, instead\nusing techniques based on optimal transport (namely, Privacy Amplification by\nIteration) and the Sampled Gaussian Mechanism (namely, Privacy Amplification by\nSampling). Our techniques readily extend to other settings, e.g., strongly\nconvex losses, non-uniform stepsizes, arbitrary batch sizes, and random or\ncyclic choice of batches.\n","authors":["Jason M. Altschuler","Kunal Talwar"],"pdf_url":"https://arxiv.org/pdf/2205.13710v2.pdf","comment":"v2: improved exposition, slightly simplified proofs, all results\n  unchanged"},{"id":"http://arxiv.org/abs/2209.15408v2","updated":"2023-02-28T17:30:11Z","published":"2022-09-30T12:10:15Z","title":"Equivariant Energy-Guided SDE for Inverse Molecular Design","summary":"  Inverse molecular design is critical in material science and drug discovery,\nwhere the generated molecules should satisfy certain desirable properties. In\nthis paper, we propose equivariant energy-guided stochastic differential\nequations (EEGSDE), a flexible framework for controllable 3D molecule\ngeneration under the guidance of an energy function in diffusion models.\nFormally, we show that EEGSDE naturally exploits the geometric symmetry in 3D\nmolecular conformation, as long as the energy function is invariant to\northogonal transformations. Empirically, under the guidance of designed energy\nfunctions, EEGSDE significantly improves the baseline on QM9, in inverse\nmolecular design targeted to quantum properties and molecular structures.\nFurthermore, EEGSDE is able to generate molecules with multiple target\nproperties by combining the corresponding energy functions linearly.\n","authors":["Fan Bao","Min Zhao","Zhongkai Hao","Peiyao Li","Chongxuan Li","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2209.15408v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14781v1","updated":"2023-02-28T17:26:27Z","published":"2023-02-28T17:26:27Z","title":"Time Series Anomaly Detection in Smart Homes: A Deep Learning Approach","summary":"  Fixing energy leakage caused by different anomalies can result in significant\nenergy savings and extended appliance life. Further, it assists grid operators\nin scheduling their resources to meet the actual needs of end users, while\nhelping end users reduce their energy costs. In this paper, we analyze the\npatterns pertaining to the power consumption of dishwashers used in two houses\nof the REFIT dataset. Then two autoencoder (AEs) with 1D-CNN and TCN as\nbackbones are trained to differentiate the normal patterns from the abnormal\nones. Our results indicate that TCN outperforms CNN1D in detecting anomalies in\nenergy consumption. Finally, the data from the Fridge_Freezer and the Freezer\nof house No. 3 in REFIT is also used to evaluate our approach.\n","authors":["Somayeh Zamani","Hamed Talebi","Gunnar Stevens"],"pdf_url":"https://arxiv.org/pdf/2302.14781v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14772v1","updated":"2023-02-28T17:14:24Z","published":"2023-02-28T17:14:24Z","title":"PA&DA: Jointly Sampling PAth and DAta for Consistent NAS","summary":"  Based on the weight-sharing mechanism, one-shot NAS methods train a supernet\nand then inherit the pre-trained weights to evaluate sub-models, largely\nreducing the search cost. However, several works have pointed out that the\nshared weights suffer from different gradient descent directions during\ntraining. And we further find that large gradient variance occurs during\nsupernet training, which degrades the supernet ranking consistency. To mitigate\nthis issue, we propose to explicitly minimize the gradient variance of the\nsupernet training by jointly optimizing the sampling distributions of PAth and\nDAta (PA&DA). We theoretically derive the relationship between the gradient\nvariance and the sampling distributions, and reveal that the optimal sampling\nprobability is proportional to the normalized gradient norm of path and\ntraining data. Hence, we use the normalized gradient norm as the importance\nindicator for path and training data, and adopt an importance sampling strategy\nfor the supernet training. Our method only requires negligible computation cost\nfor optimizing the sampling distributions of path and data, but achieves lower\ngradient variance during supernet training and better generalization\nperformance for the supernet, resulting in a more consistent NAS. We conduct\ncomprehensive comparisons with other improved approaches in various search\nspaces. Results show that our method surpasses others with more reliable\nranking performance and higher accuracy of searched architectures, showing the\neffectiveness of our method. Code is available at\nhttps://github.com/ShunLu91/PA-DA.\n","authors":["Shun Lu","Yu Hu","Longxing Yang","Zihao Sun","Jilin Mei","Jianchao Tan","Chengru Song"],"pdf_url":"https://arxiv.org/pdf/2302.14772v1.pdf","comment":"To appear in CVPR 2023; we will update the camera-ready version soon"},{"id":"http://arxiv.org/abs/2302.14770v1","updated":"2023-02-28T17:11:42Z","published":"2023-02-28T17:11:42Z","title":"Completeness of Atomic Structure Representations","summary":"  Achieving a complete and symmetric description of a group of point particles,\nsuch as atoms in a molecule, is a common problem in physics and theoretical\nchemistry. The introduction of machine learning to science has made this issue\neven more critical, as it underpins the ability of a model to reproduce\narbitrary physical relationships, and to do so while being consistent with\nbasic symmetries and conservation laws. However, the descriptors that are\ncommonly used to represent point clouds -- most notably those adopted to\ndescribe matter at the atomic scale -- are unable to distinguish between\nspecial arrangements of particles. This makes it impossible to machine learn\ntheir properties. Frameworks that are provably complete exist, but are only so\nin the limit in which they simultaneously describe the mutual relationship\nbetween all atoms, which is impractical. We introduce, and demonstrate on a\nparticularly insidious class of atomic arrangements, a strategy to build\ndescriptors that rely solely on information on the relative arrangement of\ntriplets of particles, but can be used to construct symmetry-adapted models\nthat have universal approximation power.\n","authors":["Jigyasa Nigam","Sergey N. Pozdnyakov","Kevin K. Huguenin-Dumittan","Michele Ceriotti"],"pdf_url":"https://arxiv.org/pdf/2302.14770v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.07537v2","updated":"2023-02-28T16:57:56Z","published":"2022-02-15T16:13:40Z","title":"Information-Theoretic Analysis of Minimax Excess Risk","summary":"  Two main concepts studied in machine learning theory are generalization gap\n(difference between train and test error) and excess risk (difference between\ntest error and the minimum possible error). While information-theoretic tools\nhave been used extensively to study the generalization gap of learning\nalgorithms, the information-theoretic nature of excess risk has not yet been\nfully investigated. In this paper, some steps are taken toward this goal. We\nconsider the frequentist problem of minimax excess risk as a zero-sum game\nbetween the algorithm designer and the world. Then, we argue that it is\ndesirable to modify this game in a way that the order of play can be swapped.\nWe then prove that, under some regularity conditions, if the world and designer\ncan play randomly the duality gap is zero and the order of play can be changed.\nIn this case, a Bayesian problem surfaces in the dual representation. This\nmakes it possible to utilize recent information-theoretic results on minimum\nexcess risk in Bayesian learning to provide bounds on the minimax excess risk.\nWe demonstrate the applicability of the results by providing information\ntheoretic insight on two important classes of problems: classification when the\nhypothesis space has finite VC-dimension, and regularized least squares.\n","authors":["Hassan Hafez-Kolahi","Behrad Moniri","Shohreh Kasaei"],"pdf_url":"https://arxiv.org/pdf/2202.07537v2.pdf","comment":"Published in the IEEE Transactions on Information Theory"},{"id":"http://arxiv.org/abs/2210.10947v2","updated":"2023-02-28T16:54:02Z","published":"2022-10-20T01:32:41Z","title":"Does Learning from Decentralized Non-IID Unlabeled Data Benefit from\n  Self Supervision?","summary":"  Decentralized learning has been advocated and widely deployed to make\nefficient use of distributed datasets, with an extensive focus on supervised\nlearning (SL) problems. Unfortunately, the majority of real-world data are\nunlabeled and can be highly heterogeneous across sources. In this work, we\ncarefully study decentralized learning with unlabeled data through the lens of\nself-supervised learning (SSL), specifically contrastive visual representation\nlearning. We study the effectiveness of a range of contrastive learning\nalgorithms under decentralized learning settings, on relatively large-scale\ndatasets including ImageNet-100, MS-COCO, and a new real-world robotic\nwarehouse dataset. Our experiments show that the decentralized SSL (Dec-SSL)\napproach is robust to the heterogeneity of decentralized datasets, and learns\nuseful representation for object classification, detection, and segmentation\ntasks. This robustness makes it possible to significantly reduce communication\nand reduce the participation ratio of data sources with only minimal drops in\nperformance. Interestingly, using the same amount of data, the representation\nlearned by Dec-SSL can not only perform on par with that learned by centralized\nSSL which requires communication and excessive data storage costs, but also\nsometimes outperform representations extracted from decentralized SL which\nrequires extra knowledge about the data labels. Finally, we provide theoretical\ninsights into understanding why data heterogeneity is less of a concern for\nDec-SSL objectives, and introduce feature alignment and clustering techniques\nto develop a new Dec-SSL algorithm that further improves the performance, in\nthe face of highly non-IID data. Our study presents positive evidence to\nembrace unlabeled data in decentralized learning, and we hope to provide new\ninsights into whether and why decentralized SSL is effective.\n","authors":["Lirui Wang","Kaiqing Zhang","Yunzhu Li","Yonglong Tian","Russ Tedrake"],"pdf_url":"https://arxiv.org/pdf/2210.10947v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14754v1","updated":"2023-02-28T16:53:54Z","published":"2023-02-28T16:53:54Z","title":"Identifying roadway departure crash patterns on rural two-lane highways\n  under different lighting conditions: association knowledge using data mining\n  approach","summary":"  More than half of all fatalities on U.S. highways occur due to roadway\ndeparture (RwD) each year. Previous research has explored various risk factors\nthat contribute to RwD crashes, however, a comprehensive investigation\nconsidering the effect of lighting conditions has been insufficiently\naddressed. Using the Louisiana Department of Transportation and Development\ncrash database, fatal and injury RwD crashes occurring on rural two-lane (R2L)\nhighways between 2008-2017 were analyzed based on daylight and dark\n(with/without streetlight). This research employed a safe system approach to\nexplore meaningful complex interactions among multidimensional crash risk\nfactors. To accomplish this, an unsupervised data mining algorithm association\nrules mining (ARM) was utilized. Based on the generated rules, the findings\nreveal several interesting crash patterns in the daylight,\ndark-with-streetlight, and dark-no-streetlight, emphasizing the importance of\ninvestigating RwD crash patterns depending on the lighting conditions. In\ndaylight, fatal RwD crashes are associated with cloudy weather conditions,\ndistracted drivers, standing water on the roadway, no seat belt use, and\nconstruction zones. In dark lighting conditions (with/without streetlight), the\nmajority of the RwD crashes are associated with alcohol/drug involvement, young\ndrivers (15-24 years), driver condition (e.g., inattentive, distracted,\nillness/fatigued/asleep) and colliding with animal (s). The findings reveal how\ncertain driver behavior patterns are connected to RwD crashes, such as a strong\nassociation between alcohol/drug intoxication and no seat belt usage in the\ndark-no-streetlight condition. Based on the identified crash patterns and\nbehavioral characteristics under different lighting conditions, the findings\ncould aid researchers and safety specialists in developing the most effective\nRwD crash mitigation strategies.\n","authors":["Ahmed Hossain","Xiaoduan Sun","Shahrin Islam","Shah Alam","Md Mahmud Hossain"],"pdf_url":"https://arxiv.org/pdf/2302.14754v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14753v1","updated":"2023-02-28T16:53:41Z","published":"2023-02-28T16:53:41Z","title":"Learning Hidden Markov Models Using Conditional Samples","summary":"  This paper is concerned with the computational complexity of learning the\nHidden Markov Model (HMM). Although HMMs are some of the most widely used tools\nin sequential and time series modeling, they are cryptographically hard to\nlearn in the standard setting where one has access to i.i.d. samples of\nobservation sequences. In this paper, we depart from this setup and consider an\ninteractive access model, in which the algorithm can query for samples from the\nconditional distributions of the HMMs. We show that interactive access to the\nHMM enables computationally efficient learning algorithms, thereby bypassing\ncryptographic hardness. Specifically, we obtain efficient algorithms for\nlearning HMMs in two settings:\n  (a) An easier setting where we have query access to the exact conditional\nprobabilities. Here our algorithm runs in polynomial time and makes\npolynomially many queries to approximate any HMM in total variation distance.\n  (b) A harder setting where we can only obtain samples from the conditional\ndistributions. Here the performance of the algorithm depends on a new\nparameter, called the fidelity of the HMM. We show that this captures\ncryptographically hard instances and previously known positive results.\n  We also show that these results extend to a broader class of distributions\nwith latent low rank structure. Our algorithms can be viewed as generalizations\nand robustifications of Angluin's $L^*$ algorithm for learning deterministic\nfinite automata from membership queries.\n","authors":["Sham M. Kakade","Akshay Krishnamurthy","Gaurav Mahajan","Cyril Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.14753v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14748v1","updated":"2023-02-28T16:45:42Z","published":"2023-02-28T16:45:42Z","title":"Reducing the Prior Mismatch of Stochastic Differential Equations for\n  Diffusion-based Speech Enhancement","summary":"  Recently, score-based generative models have been successfully employed for\nthe task of speech enhancement. A stochastic differential equation is used to\nmodel the iterative forward process, where at each step environmental noise and\nwhite Gaussian noise are added to the clean speech signal. While in limit the\nmean of the forward process ends at the noisy mixture, in practice it stops\nearlier and thus only at an approximation of the noisy mixture. This results in\na discrepancy between the terminating distribution of the forward process and\nthe prior used for solving the reverse process at inference. In this paper, we\naddress this discrepancy. To this end, we propose a forward process based on a\nBrownian bridge and show that such a process leads to a reduction of the\nmismatch compared to previous diffusion processes. More importantly, we show\nthat our approach improves in objective metrics over the baseline process with\nonly half of the iteration steps and having one hyperparameter less to tune.\n","authors":["Bunlong Lay","Simon Welker","Julius Richter","Timo Gerkmann"],"pdf_url":"https://arxiv.org/pdf/2302.14748v1.pdf","comment":"5 pages, 3 figures"},{"id":"http://arxiv.org/abs/2302.14744v1","updated":"2023-02-28T16:44:10Z","published":"2023-02-28T16:44:10Z","title":"Tightness of prescriptive tree-based mixed-integer optimization\n  formulations","summary":"  We focus on modeling the relationship between an input feature vector and the\npredicted outcome of a trained decision tree using mixed-integer optimization.\nThis can be used in many practical applications where a decision tree or tree\nensemble is incorporated into an optimization problem to model the predicted\noutcomes of a decision. We propose tighter mixed-integer optimization\nformulations than those previously introduced. Existing formulations can be\nshown to have linear relaxations that have fractional extreme points, even for\nthe simple case of modeling a single decision tree. A formulation we propose,\nbased on a projected union of polyhedra approach, is ideal for a single\ndecision tree. While the formulation is generally not ideal for tree ensembles\nor if additional constraints are added, it generally has fewer extreme points,\nleading to a faster time to solve, particularly if the formulation has\nrelatively few trees. However, previous work has shown that formulations based\non a binary representation of the feature vector perform well computationally\nand hence are attractive for use in practical applications. We present multiple\napproaches to tighten existing formulations with binary vectors, and show that\nfractional extreme points are removed when there are multiple splits on the\nsame feature. At an extreme, we prove that this results in ideal formulations\nfor tree ensembles modeling a one-dimensional feature vector. Building on this\nresult, we also show via numerical simulations that these additional\nconstraints result in significantly tighter linear relaxations when the feature\nvector is low dimensional. We also present instances where the time to solve to\noptimality is significantly improved using these formulations.\n","authors":["Max Biggs","Georgia Perakis"],"pdf_url":"https://arxiv.org/pdf/2302.14744v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14740v1","updated":"2023-02-28T16:42:07Z","published":"2023-02-28T16:42:07Z","title":"Fusion of ML with numerical simulation for optimized propeller design","summary":"  In computer-aided engineering design, the goal of a designer is to find an\noptimal design on a given requirement using the numerical simulator in loop\nwith an optimization method. In this design optimization process, a good design\noptimization process is one that can reduce the time from inception to design.\nIn this work, we take a class of design problem, that is computationally cheap\nto evaluate but has high dimensional design space. In such cases, traditional\nsurrogate-based optimization does not offer any benefits. In this work, we\npropose an alternative way to use ML model to surrogate the design process that\nformulates the search problem as an inverse problem and can save time by\nfinding the optimal design or at least a good initial seed design for\noptimization. By using this trained surrogate model with the traditional\noptimization method, we can get the best of both worlds. We call this as\nSurrogate Assisted Optimization (SAO)- a hybrid approach by mixing ML surrogate\nwith the traditional optimization method. Empirical evaluations of propeller\ndesign problems show that a better efficient design can be found in fewer\nevaluations using SAO.\n","authors":["Harsh Vardhan","Peter Volgyesi","Janos Sztipanovits"],"pdf_url":"https://arxiv.org/pdf/2302.14740v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14739v1","updated":"2023-02-28T16:41:24Z","published":"2023-02-28T16:41:24Z","title":"Deep Learning for Mean Field Optimal Transport","summary":"  Mean field control (MFC) problems have been introduced to study social optima\nin very large populations of strategic agents. The main idea is to consider an\ninfinite population and to simplify the analysis by using a mean field\napproximation. These problems can also be viewed as optimal control problems\nfor McKean-Vlasov dynamics. They have found applications in a wide range of\nfields, from economics and finance to social sciences and engineering. Usually,\nthe goal for the agents is to minimize a total cost which consists in the\nintegral of a running cost plus a terminal cost. In this work, we consider MFC\nproblems in which there is no terminal cost but, instead, the terminal\ndistribution is prescribed. We call such problems mean field optimal transport\nproblems since they can be viewed as a generalization of classical optimal\ntransport problems when mean field interactions occur in the dynamics or the\nrunning cost function. We propose three numerical methods based on neural\nnetworks. The first one is based on directly learning an optimal control. The\nsecond one amounts to solve a forward-backward PDE system characterizing the\nsolution. The third one relies on a primal-dual approach. We illustrate these\nmethods with numerical experiments conducted on two families of examples.\n","authors":["Sebastian Baudelet","Brieuc Frénais","Mathieu Laurière","Amal Machtalay","Yuchen Zhu"],"pdf_url":"https://arxiv.org/pdf/2302.14739v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03561v2","updated":"2023-02-28T16:41:22Z","published":"2023-02-07T16:17:25Z","title":"Optimizing Audio Recommendations for the Long-Term: A Reinforcement\n  Learning Perspective","summary":"  We study the problem of optimizing a recommender system for outcomes that\noccur over several weeks or months. We begin by drawing on reinforcement\nlearning to formulate a comprehensive model of users' recurring relationships\nwith a recommender system. Measurement, attribution, and coordination\nchallenges complicate algorithm design. We describe careful modeling --\nincluding a new representation of user state and key conditional independence\nassumptions -- which overcomes these challenges and leads to simple, testable\nrecommender system prototypes. We apply our approach to a podcast recommender\nsystem that makes personalized recommendations to hundreds of millions of\nlisteners. A/B tests demonstrate that purposefully optimizing for long-term\noutcomes leads to large performance gains over conventional approaches that\noptimize for short-term proxies.\n","authors":["Lucas Maystre","Daniel Russo","Yu Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.03561v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14732v1","updated":"2023-02-28T16:36:26Z","published":"2023-02-28T16:36:26Z","title":"Constrained Bayesian Optimization for Automatic Underwater Vehicle Hull\n  Design","summary":"  Automatic underwater vehicle hull Design optimization is a complex\nengineering process for generating a UUV hull with optimized properties on a\ngiven requirement. First, it involves the integration of involved\ncomputationally complex engineering simulation tools. Second, it needs\nintegration of a sample efficient optimization framework with the integrated\ntoolchain. To this end, we integrated the CAD tool called FreeCAD with CFD tool\nopenFoam for automatic design evaluation. For optimization, we chose Bayesian\noptimization (BO), which is a well-known technique developed for optimizing\ntime-consuming expensive engineering simulations and has proven to be very\nsample efficient in a variety of problems, including hyper-parameter tuning and\nexperimental design. During the optimization process, we can handle infeasible\ndesign as constraints integrated into the optimization process. By integrating\ndomain-specific toolchain with AI-based optimization, we executed the automatic\ndesign optimization of underwater vehicle hull design. For empirical\nevaluation, we took two different use cases of real-world underwater vehicle\ndesign to validate the execution of our tool.\n","authors":["Harsh Vardhan","Peter Volgyesi","Janos Sztipanovits"],"pdf_url":"https://arxiv.org/pdf/2302.14732v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14719v1","updated":"2023-02-28T16:31:17Z","published":"2023-02-28T16:31:17Z","title":"Self-training through Classifier Disagreement for Cross-Domain Opinion\n  Target Extraction","summary":"  Opinion target extraction (OTE) or aspect extraction (AE) is a fundamental\ntask in opinion mining that aims to extract the targets (or aspects) on which\nopinions have been expressed. Recent work focus on cross-domain OTE, which is\ntypically encountered in real-world scenarios, where the testing and training\ndistributions differ. Most methods use domain adversarial neural networks that\naim to reduce the domain gap between the labelled source and unlabelled target\ndomains to improve target domain performance. However, this approach only\naligns feature distributions and does not account for class-wise feature\nalignment, leading to suboptimal results. Semi-supervised learning (SSL) has\nbeen explored as a solution, but is limited by the quality of pseudo-labels\ngenerated by the model. Inspired by the theoretical foundations in domain\nadaptation [2], we propose a new SSL approach that opts for selecting target\nsamples whose model output from a domain-specific teacher and student network\ndisagree on the unlabelled target data, in an effort to boost the target domain\nperformance. Extensive experiments on benchmark cross-domain OTE datasets show\nthat this approach is effective and performs consistently well in settings with\nlarge domain shifts.\n","authors":["Kai Sun","Richong Zhang","Samuel Mensah","Nikolaos Aletras","Yongyi Mao","Xudong Liu"],"pdf_url":"https://arxiv.org/pdf/2302.14719v1.pdf","comment":"Accepted at TheWebConf 2023"},{"id":"http://arxiv.org/abs/2302.14714v1","updated":"2023-02-28T16:26:23Z","published":"2023-02-28T16:26:23Z","title":"Minimizing the Outage Probability in a Markov Decision Process","summary":"  Standard Markov decision process (MDP) and reinforcement learning algorithms\noptimize the policy with respect to the expected gain. We propose an algorithm\nwhich enables to optimize an alternative objective: the probability that the\ngain is greater than a given value. The algorithm can be seen as an extension\nof the value iteration algorithm. We also show how the proposed algorithm could\nbe generalized to use neural networks, similarly to the deep Q learning\nextension of Q learning.\n","authors":["Vincent Corlay","Jean-Christophe Sibel"],"pdf_url":"https://arxiv.org/pdf/2302.14714v1.pdf","comment":"Accepted at the Information Theory Workshop (ITW) 2023"},{"id":"http://arxiv.org/abs/2302.14712v1","updated":"2023-02-28T16:23:18Z","published":"2023-02-28T16:23:18Z","title":"Generating Accurate Virtual Examples For Lifelong Machine Learning","summary":"  Lifelong machine learning (LML) is an area of machine learning research\nconcerned with human-like persistent and cumulative nature of learning. LML\nsystem's objective is consolidating new information into an existing machine\nlearning model without catastrophically disrupting the prior information. Our\nresearch addresses this LML retention problem for creating a knowledge\nconsolidation network through task rehearsal without retaining the prior task's\ntraining examples. We discovered that the training data reconstruction error\nfrom a trained Restricted Boltzmann Machine can be successfully used to\ngenerate accurate virtual examples from the reconstructed set of a uniform\nrandom set of examples given to the trained model. We also defined a measure\nfor comparing the probability distributions of two datasets given to a trained\nnetwork model based on their reconstruction mean square errors.\n","authors":["Sazia Mahfuz"],"pdf_url":"https://arxiv.org/pdf/2302.14712v1.pdf","comment":"4 pages, Canadian AI GSS 2019"},{"id":"http://arxiv.org/abs/2112.04720v2","updated":"2023-02-28T16:21:41Z","published":"2021-12-09T06:16:08Z","title":"Amicable Aid: Perturbing Images to Improve Classification Performance","summary":"  While adversarial perturbation of images to attack deep image classification\nmodels pose serious security concerns in practice, this paper suggests a novel\nparadigm where the concept of image perturbation can benefit classification\nperformance, which we call amicable aid. We show that by taking the opposite\nsearch direction of perturbation, an image can be modified to yield higher\nclassification confidence and even a misclassified image can be made correctly\nclassified. This can be also achieved with a large amount of perturbation by\nwhich the image is made unrecognizable by human eyes. The mechanism of the\namicable aid is explained in the viewpoint of the underlying natural image\nmanifold. Furthermore, we investigate the universal amicable aid, i.e., a fixed\nperturbation can be applied to multiple images to improve their classification\nresults. While it is challenging to find such perturbations, we show that\nmaking the decision boundary as perpendicular to the image manifold as possible\nvia training with modified data is effective to obtain a model for which\nuniversal amicable perturbations are more easily found.\n","authors":["Juyeop Kim","Jun-Ho Choi","Soobeom Jang","Jong-Seok Lee"],"pdf_url":"https://arxiv.org/pdf/2112.04720v2.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2302.14705v1","updated":"2023-02-28T16:17:23Z","published":"2023-02-28T16:17:23Z","title":"AccelTran: A Sparsity-Aware Accelerator for Dynamic Inference with\n  Transformers","summary":"  Self-attention-based transformer models have achieved tremendous success in\nthe domain of natural language processing. Despite their efficacy, accelerating\nthe transformer is challenging due to its quadratic computational complexity\nand large activation sizes. Existing transformer accelerators attempt to prune\nits tokens to reduce memory access, albeit with high compute overheads.\nMoreover, previous works directly operate on large matrices involved in the\nattention operation, which limits hardware utilization. In order to address\nthese challenges, this work proposes a novel dynamic inference scheme,\nDynaTran, which prunes activations at runtime with low overhead, substantially\nreducing the number of ineffectual operations. This improves the throughput of\ntransformer inference. We further propose tiling the matrices in transformer\noperations along with diverse dataflows to improve data reuse, thus enabling\nhigher energy efficiency. To effectively implement these methods, we propose\nAccelTran, a novel accelerator architecture for transformers. Extensive\nexperiments with different models and benchmarks demonstrate that DynaTran\nachieves higher accuracy than the state-of-the-art top-k hardware-aware pruning\nstrategy while attaining up to 1.2$\\times$ higher sparsity. One of our proposed\naccelerators, AccelTran-Edge, achieves 330K$\\times$ higher throughput with\n93K$\\times$ lower energy requirement when compared to a Raspberry Pi device. On\nthe other hand, AccelTran-Server achieves 5.73$\\times$ higher throughput and\n3.69$\\times$ lower energy consumption compared to the state-of-the-art\ntransformer co-processor, Energon.\n","authors":["Shikhar Tuli","Niraj K. Jha"],"pdf_url":"https://arxiv.org/pdf/2302.14705v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14703v1","updated":"2023-02-28T16:16:45Z","published":"2023-02-28T16:16:45Z","title":"Improving Expert Specialization in Mixture of Experts","summary":"  Mixture of experts (MoE), introduced over 20 years ago, is the simplest gated\nmodular neural network architecture. There is renewed interest in MoE because\nthe conditional computation allows only parts of the network to be used during\neach inference, as was recently demonstrated in large scale natural language\nprocessing models. MoE is also of potential interest for continual learning, as\nexperts may be reused for new tasks, and new experts introduced. The gate in\nthe MoE architecture learns task decompositions and individual experts learn\nsimpler functions appropriate to the gate's decomposition. In this paper: (1)\nwe show that the original MoE architecture and its training method do not\nguarantee intuitive task decompositions and good expert utilization, indeed\nthey can fail spectacularly even for simple data such as MNIST and\nFashionMNIST; (2) we introduce a novel gating architecture, similar to\nattention, that improves performance and results in a lower entropy task\ndecomposition; and (3) we introduce a novel data-driven regularization that\nimproves expert specialization. We empirically validate our methods on MNIST,\nFashionMNIST and CIFAR-100 datasets.\n","authors":["Yamuna Krishnamurthy","Chris Watkins","Thomas Gaertner"],"pdf_url":"https://arxiv.org/pdf/2302.14703v1.pdf","comment":"14 pages including appendix"},{"id":"http://arxiv.org/abs/2302.14698v1","updated":"2023-02-28T16:11:08Z","published":"2023-02-28T16:11:08Z","title":"Heuristic Modularity Maximization Algorithms for Community Detection\n  Rarely Return an Optimal Partition or Anything Similar","summary":"  Community detection is a classic problem in network science with extensive\napplications in various fields. The most commonly used methods are the\nalgorithms designed to maximize modularity over different partitions of the\nnetwork nodes into communities. Using 80 real and random networks from a wide\nrange of contexts, we investigate the extent to which current heuristic\nmodularity maximization algorithms succeed in returning modularity-maximum\n(optimal) partitions. We evaluate (1) the ratio of their output modularity to\nthe maximum modularity for each input graph and (2) the maximum similarity\nbetween their output partition and any optimal partition of that graph. Our\ncomputational experiments involve eight existing heuristic algorithms which we\ncompare against an exact integer programming method that globally maximizes\nmodularity. The average modularity-based heuristic algorithm returns optimal\npartitions for only 16.9% of the 80 graphs considered. Results on adjusted\nmutual information show considerable dissimilarity between the sub-optimal\npartitions and any optimal partitions of the graphs in our experiments. More\nimportantly, our results show that near-optimal partitions tend to be\ndisproportionally dissimilar to any optimal partition. Taken together, our\nanalysis points to a crucial limitation of commonly used modularity-based\nalgorithms for discovering communities: they rarely return an optimal partition\nor a partition resembling an optimal partition. Given this finding, developing\nan exact or approximate algorithm for modularity maximization is recommendable\nfor a more methodologically sound usage of modularity in community detection.\n","authors":["Samin Aref","Mahdi Mostajabdaveh","Hriday Chheda"],"pdf_url":"https://arxiv.org/pdf/2302.14698v1.pdf","comment":"15 pages, 3 figures. arXiv admin note: text overlap with\n  arXiv:2209.04562"},{"id":"http://arxiv.org/abs/2211.04772v2","updated":"2023-02-28T16:08:45Z","published":"2022-11-09T09:58:22Z","title":"Efficient Large-scale Audio Tagging via Transformer-to-CNN Knowledge\n  Distillation","summary":"  Audio Spectrogram Transformer models rule the field of Audio Tagging,\noutrunning previously dominating Convolutional Neural Networks (CNNs). Their\nsuperiority is based on the ability to scale up and exploit large-scale\ndatasets such as AudioSet. However, Transformers are demanding in terms of\nmodel size and computational requirements compared to CNNs. We propose a\ntraining procedure for efficient CNNs based on offline Knowledge Distillation\n(KD) from high-performing yet complex transformers. The proposed training\nschema and the efficient CNN design based on MobileNetV3 results in models\noutperforming previous solutions in terms of parameter and computational\nefficiency and prediction performance. We provide models of different\ncomplexity levels, scaling from low-complexity models up to a new\nstate-of-the-art performance of .483 mAP on AudioSet. Source Code available at:\nhttps://github.com/fschmid56/EfficientAT\n","authors":["Florian Schmid","Khaled Koutini","Gerhard Widmer"],"pdf_url":"https://arxiv.org/pdf/2211.04772v2.pdf","comment":"To appear in IEEE International Conference on Acoustics, Speech and\n  Signal Processing (ICASSP) 2023. Source Code available at:\n  https://github.com/fschmid56/EfficientAT"},{"id":"http://arxiv.org/abs/2302.14695v1","updated":"2023-02-28T16:08:12Z","published":"2023-02-28T16:08:12Z","title":"Pushing One Pair of Labels Apart Each Time in Multi-Label Learning: From\n  Single Positive to Full Labels","summary":"  In Multi-Label Learning (MLL), it is extremely challenging to accurately\nannotate every appearing object due to expensive costs and limited knowledge.\nWhen facing such a challenge, a more practical and cheaper alternative should\nbe Single Positive Multi-Label Learning (SPMLL), where only one positive label\nneeds to be provided per sample. Existing SPMLL methods usually assume unknown\nlabels as negatives, which inevitably introduces false negatives as noisy\nlabels. More seriously, Binary Cross Entropy (BCE) loss is often used for\ntraining, which is notoriously not robust to noisy labels. To mitigate this\nissue, we customize an objective function for SPMLL by pushing only one pair of\nlabels apart each time to prevent the domination of negative labels, which is\nthe main culprit of fitting noisy labels in SPMLL. To further combat such noisy\nlabels, we explore the high-rankness of label matrix, which can also push apart\ndifferent labels. By directly extending from SPMLL to MLL with full labels, a\nunified loss applicable to both settings is derived. Experiments on real\ndatasets demonstrate that the proposed loss not only performs more robustly to\nnoisy labels for SPMLL but also works well for full labels. Besides, we\nempirically discover that high-rankness can mitigate the dramatic performance\ndrop in SPMLL. Most surprisingly, even without any regularization or fine-tuned\nlabel correction, only adopting our loss defeats state-of-the-art SPMLL methods\non CUB, a dataset that severely lacks labels.\n","authors":["Xiang Li","Xinrui Wang","Songcan Chen"],"pdf_url":"https://arxiv.org/pdf/2302.14695v1.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2302.14690v1","updated":"2023-02-28T16:01:38Z","published":"2023-02-28T16:01:38Z","title":"On the existence of minimizers in shallow residual ReLU neural network\n  optimization landscapes","summary":"  Many mathematical convergence results for gradient descent (GD) based\nalgorithms employ the assumption that the GD process is (almost surely) bounded\nand, also in concrete numerical simulations, divergence of the GD process may\nslow down, or even completely rule out, convergence of the error function. In\npractical relevant learning problems, it thus seems to be advisable to design\nthe ANN architectures in a way so that GD optimization processes remain\nbounded. The property of the boundedness of GD processes for a given learning\nproblem seems, however, to be closely related to the existence of minimizers in\nthe optimization landscape and, in particular, GD trajectories may escape to\ninfinity if the infimum of the error function (objective function) is not\nattained in the optimization landscape. This naturally raises the question of\nthe existence of minimizers in the optimization landscape and, in the situation\nof shallow residual ANNs with multi-dimensional input layers and\nmulti-dimensional hidden layers with the ReLU activation, the main result of\nthis work answers this question affirmatively for a general class of loss\nfunctions and all continuous target functions. In our proof of this statement,\nwe propose a kind of closure of the search space, where the limits are called\ngeneralized responses, and, thereafter, we provide sufficient criteria for the\nloss function and the underlying probability distribution which ensure that all\nadditional artificial generalized responses are suboptimal which finally allows\nus to conclude the existence of minimizers in the optimization landscape.\n","authors":["Steffen Dereich","Arnulf Jentzen","Sebastian Kassing"],"pdf_url":"https://arxiv.org/pdf/2302.14690v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.16114v4","updated":"2023-02-28T16:00:34Z","published":"2022-10-28T13:21:28Z","title":"Towards Reliable Neural Specifications","summary":"  Having reliable specifications is an unavoidable challenge in achieving\nverifiable correctness, robustness, and interpretability of AI systems.\nExisting specifications for neural networks are in the paradigm of data as\nspecification. That is, the local neighborhood centering around a reference\ninput is considered to be correct (or robust). While existing specifications\ncontribute to verifying adversarial robustness, a significant problem in many\nresearch domains, our empirical study shows that those verified regions are\nsomewhat tight, and thus fail to allow verification of test set inputs, making\nthem impractical for some real-world applications. To this end, we propose a\nnew family of specifications called neural representation as specification,\nwhich uses the intrinsic information of neural networks - neural activation\npatterns (NAPs), rather than input data to specify the correctness and/or\nrobustness of neural network predictions. We present a simple statistical\napproach to mining neural activation patterns. To show the effectiveness of\ndiscovered NAPs, we formally verify several important properties, such as\nvarious types of misclassifications will never happen for a given NAP, and\nthere is no ambiguity between different NAPs. We show that by using NAP, we can\nverify a significant region of the input space, while still recalling 84% of\nthe data on MNIST. Moreover, we can push the verifiable bound to 10 times\nlarger on the CIFAR10 benchmark. Thus, we argue that NAPs can potentially be\nused as a more reliable and extensible specification for neural network\nverification.\n","authors":["Chuqin Geng","Nham Le","Xiaojie Xu","Zhaoyue Wang","Arie Gurfinkel","Xujie Si"],"pdf_url":"https://arxiv.org/pdf/2210.16114v4.pdf","comment":"19 pages, 16 figures"},{"id":"http://arxiv.org/abs/2302.14686v1","updated":"2023-02-28T15:55:52Z","published":"2023-02-28T15:55:52Z","title":"Approximately Stationary Bandits with Knapsacks","summary":"  Bandits with Knapsacks (BwK), the generalization of the Multi-Armed Bandits\nunder budget constraints, has received a lot of attention in recent years. It\nhas numerous applications, including dynamic pricing, repeated auctions, etc.\nPrevious work has focused on one of the two extremes: Stochastic BwK where the\nrewards and consumptions of the resources each round are sampled from an i.i.d.\ndistribution, and Adversarial BwK where these values are picked by an\nadversary. Achievable guarantees in the two cases exhibit a massive gap:\nNo-regret learning is achievable in Stochastic BwK, but in Adversarial BwK,\nonly competitive ratio style guarantees are achievable, where the competitive\nratio depends on the budget. What makes this gap so vast is that in Adversarial\nBwK the guarantees get worse in the typical case when the budget is more\nbinding. While ``best-of-both-worlds'' type algorithms are known (algorithms\nthat provide the best achievable guarantee in both extreme cases), their\nguarantees degrade to the adversarial case as soon as the environment is not\nfully stochastic.\n  Our work aims to bridge this gap, offering guarantees for a workload that is\nnot exactly stochastic but is also not worst-case. We define a condition,\nApproximately Stationary BwK, that parameterizes how close to stochastic or\nadversarial an instance is. Based on these parameters, we explore what is the\nbest competitive ratio attainable in BwK. We explore two algorithms that are\noblivious to the values of the parameters but guarantee competitive ratios that\nsmoothly transition between the best possible guarantees in the two extreme\ncases, depending on the values of the parameters. Our guarantees offer great\nimprovement over the adversarial guarantee, especially when the available\nbudget is small. We also prove bounds on the achievable guarantee, showing that\nour results are approximately tight when the budget is small.\n","authors":["Giannis Fikioris","Éva Tardos"],"pdf_url":"https://arxiv.org/pdf/2302.14686v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14685v1","updated":"2023-02-28T15:54:47Z","published":"2023-02-28T15:54:47Z","title":"DART: Diversify-Aggregate-Repeat Training Improves Generalization of\n  Neural Networks","summary":"  Generalization of neural networks is crucial for deploying them safely in the\nreal world. Common training strategies to improve generalization involve the\nuse of data augmentations, ensembling and model averaging. In this work, we\nfirst establish a surprisingly simple but strong benchmark for generalization\nwhich utilizes diverse augmentations within a training minibatch, and show that\nthis can learn a more balanced distribution of features. Further, we propose\nDiversify-Aggregate-Repeat Training (DART) strategy that first trains diverse\nmodels using different augmentations (or domains) to explore the loss basin,\nand further Aggregates their weights to combine their expertise and obtain\nimproved generalization. We find that Repeating the step of Aggregation\nthroughout training improves the overall optimization trajectory and also\nensures that the individual models have a sufficiently low loss barrier to\nobtain improved generalization on combining them. We shed light on our approach\nby casting it in the framework proposed by Shen et al. and theoretically show\nthat it indeed generalizes better. In addition to improvements in In- Domain\ngeneralization, we demonstrate SOTA performance on the Domain Generalization\nbenchmarks in the popular DomainBed framework as well. Our method is generic\nand can easily be integrated with several base training algorithms to achieve\nperformance gains.\n","authors":["Samyak Jain","Sravanti Addepalli","Pawan Sahu","Priyam Dey","R. Venkatesh Babu"],"pdf_url":"https://arxiv.org/pdf/2302.14685v1.pdf","comment":"Accepted at CVPR 2023. First two authors contributed equally"},{"id":"http://arxiv.org/abs/2206.14507v3","updated":"2023-02-28T15:53:18Z","published":"2022-06-29T09:56:59Z","title":"Variational Quantum Approximate Support Vector Machine with Inference\n  Transfer","summary":"  A kernel-based quantum classifier is the most practical and influential\nquantum machine learning technique for the hyper-linear classification of\ncomplex data. We propose a Variational Quantum Approximate Support Vector\nMachine (VQASVM) algorithm that demonstrates empirical sub-quadratic run-time\ncomplexity with quantum operations feasible even in NISQ computers. We\nexperimented our algorithm with toy example dataset on cloud-based NISQ\nmachines as a proof of concept. We also numerically investigated its\nperformance on the standard Iris flower and MNIST datasets to confirm the\npracticality and scalability.\n","authors":["Siheon Park","Daniel K. Park","June-Koo Kevin Rhee"],"pdf_url":"https://arxiv.org/pdf/2206.14507v3.pdf","comment":"16 pages, 4 figures"},{"id":"http://arxiv.org/abs/2110.01960v3","updated":"2023-02-28T15:48:17Z","published":"2021-10-05T11:42:36Z","title":"Energy-based survival modelling using harmoniums","summary":"  Survival analysis concerns the study of timeline data where the event of\ninterest may remain unobserved (i.e., censored). Studies commonly record more\nthan one type of event, but conventional survival techniques focus on a single\nevent type. We set out to integrate both multiple independently censored\ntime-to-event variables as well as missing observations. An energy-based\napproach is taken with a bi-partite structure between latent and visible\nstates, known as harmoniums (or restricted Boltzmann machines). The present\nharmonium is shown, both theoretically and experimentally, to capture\nnon-linearly separable patterns between distinct time recordings. We illustrate\non real world data that, for a single time-to-event variable, our model is on\npar with established methods. In addition, we demonstrate that discriminative\npredictions improve by leveraging an extra time-to-event variable. In\nconclusion, multiple time-to-event variables can be successfully captured\nwithin the harmonium paradigm.\n","authors":["Hylke C. Donker","Harry J. M. Groen"],"pdf_url":"https://arxiv.org/pdf/2110.01960v3.pdf","comment":"11 + 9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2302.14679v1","updated":"2023-02-28T15:42:30Z","published":"2023-02-28T15:42:30Z","title":"Synthesizing Mixed-type Electronic Health Records using Diffusion Models","summary":"  Electronic Health Records (EHRs) contain sensitive patient information, which\npresents privacy concerns when sharing such data. Synthetic data generation is\na promising solution to mitigate these risks, often relying on deep generative\nmodels such as Generative Adversarial Networks (GANs). However, recent studies\nhave shown that diffusion models offer several advantages over GANs, such as\ngeneration of more realistic synthetic data and stable training in generating\ndata modalities, including image, text, and sound. In this work, we investigate\nthe potential of diffusion models for generating realistic mixed-type tabular\nEHRs, comparing TabDDPM model with existing methods on four datasets in terms\nof data quality, utility, privacy, and augmentation. Our experiments\ndemonstrate that TabDDPM outperforms the state-of-the-art models across all\nevaluation metrics, except for privacy, which confirms the trade-off between\nprivacy and utility.\n","authors":["Taha Ceritli","Ghadeer O. Ghosheh","Vinod Kumar Chauhan","Tingting Zhu","Andrew P. Creagh","David A. Clifton"],"pdf_url":"https://arxiv.org/pdf/2302.14679v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14678v1","updated":"2023-02-28T15:39:42Z","published":"2023-02-28T15:39:42Z","title":"Graph Reinforcement Learning for Operator Selection in the ALNS\n  Metaheuristic","summary":"  ALNS is a popular metaheuristic with renowned efficiency in solving\ncombinatorial optimisation problems. However, despite 16 years of intensive\nresearch into ALNS, whether the embedded adaptive layer can efficiently select\noperators to improve the incumbent remains an open question. In this work, we\nformulate the choice of operators as a Markov Decision Process, and propose a\npractical approach based on Deep Reinforcement Learning and Graph Neural\nNetworks. The results show that our proposed method achieves better performance\nthan the classic ALNS adaptive layer due to the choice of operator being\nconditioned on the current solution. We also discuss important considerations\nsuch as the size of the operator portfolio and the impact of the choice of\noperator scales. Notably, our approach can also save significant time and\nlabour costs for handcrafting problem-specific operator portfolios.\n","authors":["Syu-Ning Johnn","Victor-Alexandru Darvariu","Julia Handl","Joerg Kalcsics"],"pdf_url":"https://arxiv.org/pdf/2302.14678v1.pdf","comment":"To appear in Proceedings of The International Conference in\n  Optimization and Learning (OLA2023)"},{"id":"http://arxiv.org/abs/2302.14670v1","updated":"2023-02-28T15:34:01Z","published":"2023-02-28T15:34:01Z","title":"Double Dynamic Sparse Training for GANs","summary":"  The past decade has witnessed a drastic increase in modern deep neural\nnetworks (DNNs) size, especially for generative adversarial networks (GANs).\nSince GANs usually suffer from high computational complexity, researchers have\nshown an increased interest in applying pruning methods to reduce the training\nand inference costs of GANs. Among different pruning methods invented for\nsupervised learning, dynamic sparse training (DST) has gained increasing\nattention recently as it enjoys excellent training efficiency with comparable\nperformance to post-hoc pruning. Hence, applying DST on GANs, where we train a\nsparse GAN with a fixed parameter count throughout training, seems to be a good\ncandidate for reducing GAN training costs. However, a few challenges, including\nthe degrading training instability, emerge due to the adversarial nature of\nGANs. Hence, we introduce a quantity called balance ratio (BR) to quantify the\nbalance of the generator and the discriminator. We conduct a series of\nexperiments to show the importance of BR in understanding sparse GAN training.\nBuilding upon single dynamic sparse training (SDST), where only the generator\nis adjusted during training, we propose double dynamic sparse training (DDST)\nto control the BR during GAN training. Empirically, DDST automatically\ndetermines the density of the discriminator and greatly boosts the performance\nof sparse GANs on multiple datasets.\n","authors":["Yite Wang","Jing Wu","Naira Hovakimyan","Ruoyu Sun"],"pdf_url":"https://arxiv.org/pdf/2302.14670v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2302.14665v1","updated":"2023-02-28T15:31:23Z","published":"2023-02-28T15:31:23Z","title":"Parametrizing Product Shape Manifolds by Composite Networks","summary":"  Parametrizations of data manifolds in shape spaces can be computed using the\nrich toolbox of Riemannian geometry. This, however, often comes with high\ncomputational costs, which raises the question if one can learn an efficient\nneural network approximation. We show that this is indeed possible for shape\nspaces with a special product structure, namely those smoothly approximable by\na direct sum of low-dimensional manifolds. Our proposed architecture leverages\nthis structure by separately learning approximations for the low-dimensional\nfactors and a subsequent combination. After developing the approach as a\ngeneral framework, we apply it to a shape space of triangular surfaces. Here,\ntypical examples of data manifolds are given through datasets of articulated\nmodels and can be factorized, for example, by a Sparse Principal Geodesic\nAnalysis (SPGA). We demonstrate the effectiveness of our proposed approach with\nexperiments on synthetic data as well as manifolds extracted from data via\nSPGA.\n","authors":["Josua Sassen","Klaus Hildebrandt","Martin Rumpf","Benedikt Wirth"],"pdf_url":"https://arxiv.org/pdf/2302.14665v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.13248v4","updated":"2023-02-28T15:19:57Z","published":"2022-02-26T23:00:34Z","title":"Automated Data Augmentations for Graph Classification","summary":"  Data augmentations are effective in improving the invariance of learning\nmachines. We argue that the core challenge of data augmentations lies in\ndesigning data transformations that preserve labels. This is relatively\nstraightforward for images, but much more challenging for graphs. In this work,\nwe propose GraphAug, a novel automated data augmentation method aiming at\ncomputing label-invariant augmentations for graph classification. Instead of\nusing uniform transformations as in existing studies, GraphAug uses an\nautomated augmentation model to avoid compromising critical label-related\ninformation of the graph, thereby producing label-invariant augmentations at\nmost times. To ensure label-invariance, we develop a training method based on\nreinforcement learning to maximize an estimated label-invariance probability.\nExperiments show that GraphAug outperforms previous graph augmentation methods\non various graph classification tasks.\n","authors":["Youzhi Luo","Michael McThrow","Wing Yee Au","Tao Komikado","Kanji Uchino","Koji Maruhashi","Shuiwang Ji"],"pdf_url":"https://arxiv.org/pdf/2202.13248v4.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2302.14640v1","updated":"2023-02-28T15:18:42Z","published":"2023-02-28T15:18:42Z","title":"Meta-Learning with Adaptive Weighted Loss for Imbalanced Cold-Start\n  Recommendation","summary":"  Sequential recommenders have made great strides in capturing a user's\npreferences. Nevertheless, the cold-start recommendation remains a fundamental\nchallenge in which only a few user-item interactions are available for\npersonalization. Gradient-based meta-learning approaches have recently emerged\nin the sequential recommendation field due to their fast adaptation and\neasy-to-integrate abilities. The meta-learning algorithms formulate the\ncold-start recommendation as a few-shot learning problem, where each user is\nrepresented as a task to be adapted. However, while meta-learning algorithms\ngenerally assume that task-wise samples are evenly distributed over classes or\nvalues, user-item interactions are not that way in real-world applications\n(e.g., watching favorite videos multiple times, leaving only good ratings and\nno bad ones). As a result, in the real-world, imbalanced user feedback that\naccounts for most task training data may dominate the user adaptation and\nprevent meta-learning algorithms from learning meaningful meta-knowledge for\npersonalized recommendations. To alleviate this limitation, we propose a novel\nsequential recommendation framework based on gradient-based meta-learning that\ncaptures the imbalance of each user's rating distribution and accordingly\ncomputes adaptive loss for user-specific learning. It is the first work to\ntackle the impact of imbalanced ratings in cold-start sequential recommendation\nscenarios. We design adaptive weighted loss and improve the existing\nmeta-learning algorithms for state-of-the-art sequential recommendation\nmethods. Extensive experiments conducted on real-world datasets demonstrate the\neffectiveness of our framework.\n","authors":["Minchang Kim","Yongjin Yang","Jung Hyun Ryu","Taesup Kim"],"pdf_url":"https://arxiv.org/pdf/2302.14640v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14625v1","updated":"2023-02-28T15:06:03Z","published":"2023-02-28T15:06:03Z","title":"mmSense: Detecting Concealed Weapons with a Miniature Radar Sensor","summary":"  For widespread adoption, public security and surveillance systems must be\naccurate, portable, compact, and real-time, without impeding the privacy of the\nindividuals being observed. Current systems broadly fall into two categories --\nimage-based which are accurate, but lack privacy, and RF signal-based, which\npreserve privacy but lack portability, compactness and accuracy. Our paper\nproposes mmSense, an end-to-end portable miniaturised real-time system that can\naccurately detect the presence of concealed metallic objects on persons in a\ndiscrete, privacy-preserving modality. mmSense features millimeter wave radar\ntechnology, provided by Google's Soli sensor for its data acquisition, and\nTransDope, our real-time neural network, capable of processing a single radar\ndata frame in 19 ms. mmSense achieves high recognition rates on a diverse set\nof challenging scenes while running on standard laptop hardware, demonstrating\na significant advancement towards creating portable, cost-effective real-time\nradar based surveillance systems.\n","authors":["Kevin Mitchell","Khaled Kassem","Chaitanya Kaul","Valentin Kapitany","Philip Binner","Andrew Ramsay","Roderick Murray-Smith","Daniele Faccio"],"pdf_url":"https://arxiv.org/pdf/2302.14625v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.14624v1","updated":"2023-02-28T15:05:33Z","published":"2023-02-28T15:05:33Z","title":"The 2022 NIST Language Recognition Evaluation","summary":"  In 2022, the U.S. National Institute of Standards and Technology (NIST)\nconducted the latest Language Recognition Evaluation (LRE) in an ongoing series\nadministered by NIST since 1996 to foster research in language recognition and\nto measure state-of-the-art technology. Similar to previous LREs, LRE22 focused\non conversational telephone speech (CTS) and broadcast narrowband speech (BNBS)\ndata. LRE22 also introduced new evaluation features, such as an emphasis on\nAfrican languages, including low resource languages, and a test set consisting\nof segments containing between 3s and 35s of speech randomly sampled and\nextracted from longer recordings. A total of 21 research organizations, forming\n16 teams, participated in this 3-month long evaluation and made a total of 65\nvalid system submissions to be evaluated. This paper presents an overview of\nLRE22 and an analysis of system performance over different evaluation\nconditions. The evaluation results suggest that Oromo and Tigrinya are easier\nto detect while Xhosa and Zulu are more challenging. A greater confusability is\nseen for some language pairs. When speech duration increased, system\nperformance significantly increased up to a certain duration, and then a\ndiminishing return on system performance is observed afterward.\n","authors":["Yooyoung Lee","Craig Greenberg","Eliot Godard","Asad A. Butt","Elliot Singer","Trang Nguyen","Lisa Mason","Douglas Reynolds"],"pdf_url":"https://arxiv.org/pdf/2302.14624v1.pdf","comment":"5 pages, 10 figures"},{"id":"http://arxiv.org/abs/2302.14623v1","updated":"2023-02-28T15:03:18Z","published":"2023-02-28T15:03:18Z","title":"Fast as CHITA: Neural Network Pruning with Combinatorial Optimization","summary":"  The sheer size of modern neural networks makes model serving a serious\ncomputational challenge. A popular class of compression techniques overcomes\nthis challenge by pruning or sparsifying the weights of pretrained networks.\nWhile useful, these techniques often face serious tradeoffs between\ncomputational requirements and compression quality. In this work, we propose a\nnovel optimization-based pruning framework that considers the combined effect\nof pruning (and updating) multiple weights subject to a sparsity constraint.\nOur approach, CHITA, extends the classical Optimal Brain Surgeon framework and\nresults in significant improvements in speed, memory, and performance over\nexisting optimization-based approaches for network pruning. CHITA's main\nworkhorse performs combinatorial optimization updates on a memory-friendly\nrepresentation of local quadratic approximation(s) of the loss function. On a\nstandard benchmark of pretrained models and datasets, CHITA leads to\nsignificantly better sparsity-accuracy tradeoffs than competing methods. For\nexample, for MLPNet with only 2% of the weights retained, our approach improves\nthe accuracy by 63% relative to the state of the art. Furthermore, when used in\nconjunction with fine-tuning SGD steps, our method achieves significant\naccuracy gains over the state-of-the-art approaches.\n","authors":["Riade Benbaki","Wenyu Chen","Xiang Meng","Hussein Hazimeh","Natalia Ponomareva","Zhe Zhao","Rahul Mazumder"],"pdf_url":"https://arxiv.org/pdf/2302.14623v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09709v2","updated":"2023-02-28T14:57:32Z","published":"2023-01-23T20:32:41Z","title":"On The Convergence Of Policy Iteration-Based Reinforcement Learning With\n  Monte Carlo Policy Evaluation","summary":"  A common technique in reinforcement learning is to evaluate the value\nfunction from Monte Carlo simulations of a given policy, and use the estimated\nvalue function to obtain a new policy which is greedy with respect to the\nestimated value function. A well-known longstanding open problem in this\ncontext is to prove the convergence of such a scheme when the value function of\na policy is estimated from data collected from a single sample path obtained\nfrom implementing the policy (see page 99 of [Sutton and Barto, 2018], page 8\nof [Tsitsiklis, 2002]). We present a solution to the open problem by showing\nthat a first-visit version of such a policy iteration scheme indeed converges\nto the optimal policy provided that the policy improvement step uses lookahead\n[Silver et al., 2016, Mnih et al., 2016, Silver et al., 2017b] rather than a\nsimple greedy policy improvement. We provide results both for the original open\nproblem in the tabular setting and also present extensions to the function\napproximation setting, where we show that the policy resulting from the\nalgorithm performs close to the optimal policy within a function approximation\nerror.\n","authors":["Anna Winnicki","R. Srikant"],"pdf_url":"https://arxiv.org/pdf/2301.09709v2.pdf","comment":"27 pages"},{"id":"http://arxiv.org/abs/2302.14616v1","updated":"2023-02-28T14:55:57Z","published":"2023-02-28T14:55:57Z","title":"Metric Learning Improves the Ability of Combinatorial Coverage Metrics\n  to Anticipate Classification Error","summary":"  Machine learning models are increasingly used in practice. However, many\nmachine learning methods are sensitive to test or operational data that is\ndissimilar to training data. Out-of-distribution (OOD) data is known to\nincrease the probability of error and research into metrics that identify what\ndissimilarities in data affect model performance is on-going. Recently,\ncombinatorial coverage metrics have been explored in the literature as an\nalternative to distribution-based metrics. Results show that coverage metrics\ncan correlate with classification error. However, other results show that the\nutility of coverage metrics is highly dataset-dependent. In this paper, we show\nthat this dataset-dependence can be alleviated with metric learning, a machine\nlearning technique for learning latent spaces where data from different classes\nis further apart. In a study of 6 open-source datasets, we find that metric\nlearning increased the difference between set-difference coverage metrics\n(SDCCMs) calculated on correctly and incorrectly classified data, thereby\ndemonstrating that metric learning improves the ability of SDCCMs to anticipate\nclassification error. Paired t-tests validate the statistical significance of\nour findings. Overall, we conclude that metric learning improves the ability of\ncoverage metrics to anticipate classifier error and identify when OOD data is\nlikely to degrade model performance.\n","authors":["Tyler Cody","Laura Freeman"],"pdf_url":"https://arxiv.org/pdf/2302.14616v1.pdf","comment":"Accepted 2022 IEEE International Conference on Software Testing\n  International Workshop on Combinatorial Testing (IEEE ICST IWCT)"},{"id":"http://arxiv.org/abs/2302.14604v1","updated":"2023-02-28T14:44:29Z","published":"2023-02-28T14:44:29Z","title":"IQ-Flow: Mechanism Design for Inducing Cooperative Behavior to\n  Self-Interested Agents in Sequential Social Dilemmas","summary":"  Achieving and maintaining cooperation between agents to accomplish a common\nobjective is one of the central goals of Multi-Agent Reinforcement Learning\n(MARL). Nevertheless in many real-world scenarios, separately trained and\nspecialized agents are deployed into a shared environment, or the environment\nrequires multiple objectives to be achieved by different coexisting parties.\nThese variations among specialties and objectives are likely to cause mixed\nmotives that eventually result in a social dilemma where all the parties are at\na loss. In order to resolve this issue, we propose the Incentive Q-Flow\n(IQ-Flow) algorithm, which modifies the system's reward setup with an incentive\nregulator agent such that the cooperative policy also corresponds to the\nself-interested policy for the agents. Unlike the existing methods that learn\nto incentivize self-interested agents, IQ-Flow does not make any assumptions\nabout agents' policies or learning algorithms, which enables the generalization\nof the developed framework to a wider array of applications. IQ-Flow performs\nan offline evaluation of the optimality of the learned policies using the data\nprovided by other agents to determine cooperative and self-interested policies.\nNext, IQ-Flow uses meta-gradient learning to estimate how policy evaluation\nchanges according to given incentives and modifies the incentive such that the\ngreedy policy for cooperative objective and self-interested objective yield the\nsame actions. We present the operational characteristics of IQ-Flow in Iterated\nMatrix Games. We demonstrate that IQ-Flow outperforms the state-of-the-art\nincentive design algorithm in Escape Room and 2-Player Cleanup environments. We\nfurther demonstrate that the pretrained IQ-Flow mechanism significantly\noutperforms the performance of the shared reward setup in the 2-Player Cleanup\nenvironment.\n","authors":["Bengisu Guresti","Abdullah Vanlioglu","Nazim Kemal Ure"],"pdf_url":"https://arxiv.org/pdf/2302.14604v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14599v1","updated":"2023-02-28T14:39:18Z","published":"2023-02-28T14:39:18Z","title":"Scalable Clustering: Large Scale Unsupervised Learning of Gaussian\n  Mixture Models with Outliers","summary":"  Clustering is a widely used technique with a long and rich history in a\nvariety of areas. However, most existing algorithms do not scale well to large\ndatasets, or are missing theoretical guarantees of convergence. This paper\nintroduces a provably robust clustering algorithm based on loss minimization\nthat performs well on Gaussian mixture models with outliers. It provides\ntheoretical guarantees that the algorithm obtains high accuracy with high\nprobability under certain assumptions. Moreover, it can also be used as an\ninitialization strategy for $k$-means clustering. Experiments on real-world\nlarge-scale datasets demonstrate the effectiveness of the algorithm when\nclustering a large number of clusters, and a $k$-means algorithm initialized by\nthe algorithm outperforms many of the classic clustering methods in both speed\nand accuracy, while scaling well to large datasets such as ImageNet.\n","authors":["Yijia Zhou","Kyle A. Gallivan","Adrian Barbu"],"pdf_url":"https://arxiv.org/pdf/2302.14599v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.07124v2","updated":"2023-02-28T14:21:09Z","published":"2022-09-15T08:13:40Z","title":"The Cost of Training Machine Learning Models over Distributed Data\n  Sources","summary":"  Federated learning is one of the most appealing alternatives to the standard\ncentralized learning paradigm, allowing a heterogeneous set of devices to train\na machine learning model without sharing their raw data. However, it requires a\ncentral server to coordinate the learning process, thus introducing potential\nscalability and security issues. In the literature, server-less federated\nlearning approaches like gossip federated learning and blockchain-enabled\nfederated learning have been proposed to mitigate these issues. In this work,\nwe propose a complete overview of these three techniques proposing a comparison\naccording to an integral set of performance indicators, including model\naccuracy, time complexity, communication overhead, convergence time, and energy\nconsumption. An extensive simulation campaign permits to draw a quantitative\nanalysis considering both feedforward and convolutional neural network models.\nResults show that gossip federated learning and standard federated solution are\nable to reach a similar level of accuracy, and their energy consumption is\ninfluenced by the machine learning model adopted, the software library, and the\nhardware used. Differently, blockchain-enabled federated learning represents a\nviable solution for implementing decentralized learning with a higher level of\nsecurity, at the cost of an extra energy usage and data sharing. Finally, we\nidentify open issues on the two decentralized federated learning\nimplementations and provide insights on potential extensions and possible\nresearch directions in this new research field.\n","authors":["Elia Guerra","Francesc Wilhelmi","Marco Miozzo","Paolo Dini"],"pdf_url":"https://arxiv.org/pdf/2209.07124v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2002.11021v2","updated":"2023-02-28T14:09:29Z","published":"2020-02-23T05:39:54Z","title":"SNIFF: Reverse Engineering of Neural Networks with Fault Attacks","summary":"  Neural networks have been shown to be vulnerable against fault injection\nattacks. These attacks change the physical behavior of the device during the\ncomputation, resulting in a change of value that is currently being computed.\nThey can be realized by various fault injection techniques, ranging from\nclock/voltage glitching to application of lasers to rowhammer. In this paper we\nexplore the possibility to reverse engineer neural networks with the usage of\nfault attacks. SNIFF stands for sign bit flip fault, which enables the reverse\nengineering by changing the sign of intermediate values. We develop the first\nexact extraction method on deep-layer feature extractor networks that provably\nallows the recovery of the model parameters. Our experiments with Keras library\nshow that the precision error for the parameter recovery for the tested\nnetworks is less than $10^{-13}$ with the usage of 64-bit floats, which\nimproves the current state of the art by 6 orders of magnitude. Additionally,\nwe discuss the protection techniques against fault injection attacks that can\nbe applied to enhance the fault resistance.\n","authors":["Jakub Breier","Dirmanto Jap","Xiaolu Hou","Shivam Bhasin","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2002.11021v2.pdf","comment":"Published in IEEE Transactions on Reliability"},{"id":"http://arxiv.org/abs/2302.14576v1","updated":"2023-02-28T13:55:19Z","published":"2023-02-28T13:55:19Z","title":"Co-Design of Approximate Multilayer Perceptron for Ultra-Resource\n  Constrained Printed Circuits","summary":"  Printed Electronics (PE) exhibits on-demand, extremely low-cost hardware due\nto its additive manufacturing process, enabling machine learning (ML)\napplications for domains that feature ultra-low cost, conformity, and\nnon-toxicity requirements that silicon-based systems cannot deliver.\nNevertheless, large feature sizes in PE prohibit the realization of complex\nprinted ML circuits. In this work, we present, for the first time, an automated\nprinted-aware software/hardware co-design framework that exploits approximate\ncomputing principles to enable ultra-resource constrained printed multilayer\nperceptrons (MLPs). Our evaluation demonstrates that, compared to the\nstate-of-the-art baseline, our circuits feature on average 6x (5.7x) lower area\n(power) and less than 1% accuracy loss.\n","authors":["Giorgos Armeniakos","Georgios Zervakis","Dimitrios Soudris","Mehdi B. Tahoori","Jörg Henkel"],"pdf_url":"https://arxiv.org/pdf/2302.14576v1.pdf","comment":"Accepted for publication by IEEE Transactions on Computers, February\n  2023"},{"id":"http://arxiv.org/abs/2302.14567v1","updated":"2023-02-28T13:43:23Z","published":"2023-02-28T13:43:23Z","title":"Active Learning with Combinatorial Coverage","summary":"  Active learning is a practical field of machine learning that automates the\nprocess of selecting which data to label. Current methods are effective in\nreducing the burden of data labeling but are heavily model-reliant. This has\nled to the inability of sampled data to be transferred to new models as well as\nissues with sampling bias. Both issues are of crucial concern in machine\nlearning deployment. We propose active learning methods utilizing combinatorial\ncoverage to overcome these issues. The proposed methods are data-centric, as\nopposed to model-centric, and through our experiments we show that the\ninclusion of coverage in active learning leads to sampling data that tends to\nbe the best in transferring to better performing models and has a competitive\nsampling bias compared to benchmark methods.\n","authors":["Sai Prathyush Katragadda","Tyler Cody","Peter Beling","Laura Freeman"],"pdf_url":"https://arxiv.org/pdf/2302.14567v1.pdf","comment":"Accepted 2022 IEEE International Conference on Machine Learning and\n  Applications (IEEE ICMLA)"},{"id":"http://arxiv.org/abs/2302.03662v2","updated":"2023-02-28T13:27:32Z","published":"2023-02-07T18:26:07Z","title":"Federated Learning with Regularized Client Participation","summary":"  Federated Learning (FL) is a distributed machine learning approach where\nmultiple clients work together to solve a machine learning task. One of the key\nchallenges in FL is the issue of partial participation, which occurs when a\nlarge number of clients are involved in the training process. The traditional\nmethod to address this problem is randomly selecting a subset of clients at\neach communication round. In our research, we propose a new technique and\ndesign a novel regularized client participation scheme. Under this scheme, each\nclient joins the learning process every $R$ communication rounds, which we\nrefer to as a meta epoch. We have found that this participation scheme leads to\na reduction in the variance caused by client sampling. Combined with the\npopular FedAvg algorithm (McMahan et al., 2017), it results in superior rates\nunder standard assumptions. For instance, the optimization term in our main\nconvergence bound decreases linearly with the product of the number of\ncommunication rounds and the size of the local dataset of each client, and the\nstatistical term scales with step size quadratically instead of linearly (the\ncase for client sampling with replacement), leading to better convergence rate\n$\\mathcal{O}\\left(\\frac{1}{T^2}\\right)$ compared to\n$\\mathcal{O}\\left(\\frac{1}{T}\\right)$, where $T$ is the total number of\ncommunication rounds. Furthermore, our results permit arbitrary client\navailability as long as each client is available for training once per each\nmeta epoch.\n","authors":["Grigory Malinovsky","Samuel Horváth","Konstantin Burlachenko","Peter Richtárik"],"pdf_url":"https://arxiv.org/pdf/2302.03662v2.pdf","comment":"33 pages, 10 figures,1 algorithm, 3 theorems"},{"id":"http://arxiv.org/abs/2207.02098v3","updated":"2023-02-28T13:22:17Z","published":"2022-07-05T15:06:11Z","title":"Neural Networks and the Chomsky Hierarchy","summary":"  Reliable generalization lies at the heart of safe ML and AI. However,\nunderstanding when and how neural networks generalize remains one of the most\nimportant unsolved problems in the field. In this work, we conduct an extensive\nempirical study (20'910 models, 15 tasks) to investigate whether insights from\nthe theory of computation can predict the limits of neural network\ngeneralization in practice. We demonstrate that grouping tasks according to the\nChomsky hierarchy allows us to forecast whether certain architectures will be\nable to generalize to out-of-distribution inputs. This includes negative\nresults where even extensive amounts of data and training time never lead to\nany non-trivial generalization, despite models having sufficient capacity to\nfit the training data perfectly. Our results show that, for our subset of\ntasks, RNNs and Transformers fail to generalize on non-regular tasks, LSTMs can\nsolve regular and counter-language tasks, and only networks augmented with\nstructured memory (such as a stack or memory tape) can successfully generalize\non context-free and context-sensitive tasks.\n","authors":["Grégoire Delétang","Anian Ruoss","Jordi Grau-Moya","Tim Genewein","Li Kevin Wenliang","Elliot Catt","Chris Cundy","Marcus Hutter","Shane Legg","Joel Veness","Pedro A. Ortega"],"pdf_url":"https://arxiv.org/pdf/2207.02098v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14552v1","updated":"2023-02-28T13:17:56Z","published":"2023-02-28T13:17:56Z","title":"Toward Robust Uncertainty Estimation with Random Activation Functions","summary":"  Deep neural networks are in the limelight of machine learning with their\nexcellent performance in many data-driven applications. However, they can lead\nto inaccurate predictions when queried in out-of-distribution data points,\nwhich can have detrimental effects especially in sensitive domains, such as\nhealthcare and transportation, where erroneous predictions can be very costly\nand/or dangerous. Subsequently, quantifying the uncertainty of the output of a\nneural network is often leveraged to evaluate the confidence of its\npredictions, and ensemble models have proved to be effective in measuring the\nuncertainty by utilizing the variance of predictions over a pool of models. In\nthis paper, we propose a novel approach for uncertainty quantification via\nensembles, called Random Activation Functions (RAFs) Ensemble, that aims at\nimproving the ensemble diversity toward a more robust estimation, by\naccommodating each neural network with a different (random) activation\nfunction. Extensive empirical study demonstrates that RAFs Ensemble outperforms\nstate-of-the-art ensemble uncertainty quantification methods on both synthetic\nand real-world datasets in a series of regression tasks.\n","authors":["Yana Stoyanova","Soroush Ghandi","Maryam Tavakol"],"pdf_url":"https://arxiv.org/pdf/2302.14552v1.pdf","comment":"Published at AAAI 2023, the Thirty-Seventh AAAI Conference on\n  Artificial Intelligence"},{"id":"http://arxiv.org/abs/2302.14548v1","updated":"2023-02-28T13:14:07Z","published":"2023-02-28T13:14:07Z","title":"Safe-DS: A Domain Specific Language to Make Data Science Safe","summary":"  Due to the long runtime of Data Science (DS) pipelines, even small\nprogramming mistakes can be very costly, if they are not detected statically.\nHowever, even basic static type checking of DS pipelines is difficult because\nmost are written in Python. Static typing is available in Python only via\nexternal linters. These require static type annotations for parameters or\nresults of functions, which many DS libraries do not provide. In this paper, we\nshow how the wealth of Python DS libraries can be used in a statically safe way\nvia Safe-DS, a domain specific language (DSL) for DS. Safe-DS catches\nconventional type errors plus errors related to range restrictions, data\nmanipulation, and call order of functions, going well beyond the abilities of\ncurrent Python linters. Python libraries are integrated into Safe-DS via a stub\nlanguage for specifying the interface of its declarations, and an API-Editor\nthat is able to extract type information from the code and documentation of\nPython libraries, and automatically generate suitable stubs.\n  Moreover, Safe-DS complements textual DS pipelines with a graphical\nrepresentation that eases safe development by preventing syntax errors. The\nseamless synchronization of textual and graphic view lets developers always\nchoose the one best suited for their skills and current task. We think that\nSafe-DS can make DS development easier, faster, and more reliable,\nsignificantly reducing development costs.\n","authors":["Lars Reimann","Günter Kniesel-Wünsche"],"pdf_url":"https://arxiv.org/pdf/2302.14548v1.pdf","comment":"Accepted for the NIER Track of the 45th International Conference on\n  Software Engineering (ICSE 2023)"},{"id":"http://arxiv.org/abs/2211.12005v2","updated":"2023-02-28T13:11:00Z","published":"2022-11-22T04:54:20Z","title":"Self-Ensemble Protection: Training Checkpoints Are Good Data Protectors","summary":"  As data becomes increasingly vital, a company would be very cautious about\nreleasing data, because the competitors could use it to train high-performance\nmodels, thereby posing a tremendous threat to the company's commercial\ncompetence. To prevent training good models on the data, we could add\nimperceptible perturbations to it. Since such perturbations aim at hurting the\nentire training process, they should reflect the vulnerability of DNN training,\nrather than that of a single model. Based on this new idea, we seek perturbed\nexamples that are always unrecognized (never correctly classified) in training.\nIn this paper, we uncover them by model checkpoints' gradients, forming the\nproposed self-ensemble protection (SEP), which is very effective because (1)\nlearning on examples ignored during normal training tends to yield DNNs\nignoring normal examples; (2) checkpoints' cross-model gradients are close to\northogonal, meaning that they are as diverse as DNNs with different\narchitectures. That is, our amazing performance of ensemble only requires the\ncomputation of training one model. By extensive experiments with 9 baselines on\n3 datasets and 5 architectures, SEP is verified to be a new state-of-the-art,\ne.g., our small $\\ell_\\infty=2/255$ perturbations reduce the accuracy of a\nCIFAR-10 ResNet18 from 94.56% to 14.68%, compared to 41.35% by the best-known\nmethod. Code is available at https://github.com/Sizhe-Chen/SEP.\n","authors":["Sizhe Chen","Geng Yuan","Xinwen Cheng","Yifan Gong","Minghai Qin","Yanzhi Wang","Xiaolin Huang"],"pdf_url":"https://arxiv.org/pdf/2211.12005v2.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2302.14545v1","updated":"2023-02-28T13:10:04Z","published":"2023-02-28T13:10:04Z","title":"Modern Bayesian Experimental Design","summary":"  Bayesian experimental design (BED) provides a powerful and general framework\nfor optimizing the design of experiments. However, its deployment often poses\nsubstantial computational challenges that can undermine its practical use. In\nthis review, we outline how recent advances have transformed our ability to\novercome these challenges and thus utilize BED effectively, before discussing\nsome key areas for future development in the field.\n","authors":["Tom Rainforth","Adam Foster","Desi R Ivanova","Freddie Bickford Smith"],"pdf_url":"https://arxiv.org/pdf/2302.14545v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.13531v2","updated":"2023-02-28T13:06:52Z","published":"2022-05-26T17:50:55Z","title":"Learning ReLU networks to high uniform accuracy is intractable","summary":"  Statistical learning theory provides bounds on the necessary number of\ntraining samples needed to reach a prescribed accuracy in a learning problem\nformulated over a given target class. This accuracy is typically measured in\nterms of a generalization error, that is, an expected value of a given loss\nfunction. However, for several applications -- for example in a\nsecurity-critical context or for problems in the computational sciences --\naccuracy in this sense is not sufficient. In such cases, one would like to have\nguarantees for high accuracy on every input value, that is, with respect to the\nuniform norm. In this paper we precisely quantify the number of training\nsamples needed for any conceivable training algorithm to guarantee a given\nuniform accuracy on any learning problem formulated over target classes\ncontaining (or consisting of) ReLU neural networks of a prescribed\narchitecture. We prove that, under very general assumptions, the minimal number\nof training samples for this task scales exponentially both in the depth and\nthe input dimension of the network architecture.\n","authors":["Julius Berner","Philipp Grohs","Felix Voigtlaender"],"pdf_url":"https://arxiv.org/pdf/2205.13531v2.pdf","comment":"Accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2203.01629v4","updated":"2023-02-28T12:47:28Z","published":"2022-03-03T10:44:50Z","title":"Learning Group Importance using the Differentiable Hypergeometric\n  Distribution","summary":"  Partitioning a set of elements into subsets of a priori unknown sizes is\nessential in many applications. These subset sizes are rarely explicitly\nlearned - be it the cluster sizes in clustering applications or the number of\nshared versus independent generative latent factors in weakly-supervised\nlearning. Probability distributions over correct combinations of subset sizes\nare non-differentiable due to hard constraints, which prohibit gradient-based\noptimization. In this work, we propose the differentiable hypergeometric\ndistribution. The hypergeometric distribution models the probability of\ndifferent group sizes based on their relative importance. We introduce\nreparameterizable gradients to learn the importance between groups and\nhighlight the advantage of explicitly learning the size of subsets in two\ntypical applications: weakly-supervised learning and clustering. In both\napplications, we outperform previous approaches, which rely on suboptimal\nheuristics to model the unknown size of groups.\n","authors":["Thomas M. Sutter","Laura Manduchi","Alain Ryser","Julia E. Vogt"],"pdf_url":"https://arxiv.org/pdf/2203.01629v4.pdf","comment":"ICLR 2023 (Spotlight)"},{"id":"http://arxiv.org/abs/2302.11716v2","updated":"2023-02-28T12:21:42Z","published":"2023-02-23T00:45:14Z","title":"VRA: Out-of-Distribution Detection with variational rectified\n  activations","summary":"  Detecting out-of-distribution (OOD) data is critical to building reliable\nmachine learning systems in the open world. Among the existing OOD detection\nmethods, ReAct is famous for its simplicity and efficiency, and has good\ntheoretical analysis. The gap between ID data and OOD data is enlarged by\nclipping the larger activation value. But the question is, is this operation\noptimal? Is there a better way to expand the spacing between ID samples and OOD\nsamples in theory? Driven by these questions, we propose the Variational\nRecified Acitvations method. To verify the effectiveness of our method, we\nconduct experiments on many benchmark datasets. Experimental results\ndemonstrate that our method outperforms existing state-of-the-art approaches.\nMeanwhile, our method is easy to implement and does not require additional OOD\ndata or fine-tuning process. We can realize OOD detection in only one forward\npass.\n","authors":["Mingyu Xu","Zheng Lian"],"pdf_url":"https://arxiv.org/pdf/2302.11716v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14518v1","updated":"2023-02-28T12:13:57Z","published":"2023-02-28T12:13:57Z","title":"Asymptotically Optimal Generalization Error Bounds for Noisy, Iterative\n  Algorithms","summary":"  We adopt an information-theoretic framework to analyze the generalization\nbehavior of the class of iterative, noisy learning algorithms. This class is\nparticularly suitable for study under information-theoretic metrics as the\nalgorithms are inherently randomized, and it includes commonly used algorithms\nsuch as Stochastic Gradient Langevin Dynamics (SGLD). Herein, we use the\nmaximal leakage (equivalently, the Sibson mutual information of order infinity)\nmetric, as it is simple to analyze, and it implies both bounds on the\nprobability of having a large generalization error and on its expected value.\nWe show that, if the update function (e.g., gradient) is bounded in $L_2$-norm,\nthen adding isotropic Gaussian noise leads to optimal generalization bounds:\nindeed, the input and output of the learning algorithm in this case are\nasymptotically statistically independent. Furthermore, we demonstrate how the\nassumptions on the update function affect the optimal (in the sense of\nminimizing the induced maximal leakage) choice of the noise. Finally, we\ncompute explicit tight upper bounds on the induced maximal leakage for several\nscenarios of interest.\n","authors":["Ibrahim Issa","Amedeo Roberto Esposito","Michael Gastpar"],"pdf_url":"https://arxiv.org/pdf/2302.14518v1.pdf","comment":"Submitted to COLT 2023"},{"id":"http://arxiv.org/abs/2302.14517v1","updated":"2023-02-28T12:13:43Z","published":"2023-02-28T12:13:43Z","title":"Arbitrary Decisions are a Hidden Cost of Differentially-Private Training","summary":"  Mechanisms used in privacy-preserving machine learning often aim to guarantee\ndifferential privacy (DP) during model training. Practical DP-ensuring training\nmethods use randomization when fitting model parameters to privacy-sensitive\ndata (e.g., adding Gaussian noise to clipped gradients). We demonstrate that\nsuch randomization incurs predictive multiplicity: for a given input example,\nthe output predicted by equally-private models depends on the randomness used\nin training. Thus, for a given input, the predicted output can vary drastically\nif a model is re-trained, even if the same training dataset is used. The\npredictive-multiplicity cost of DP training has not been studied, and is\ncurrently neither audited for nor communicated to model designers and\nstakeholders. We derive a bound on the number of re-trainings required to\nestimate predictive multiplicity reliably. We analyze -- both theoretically and\nthrough extensive experiments -- the predictive-multiplicity cost of three\nDP-ensuring algorithms: output perturbation, objective perturbation, and\nDP-SGD. We demonstrate that the degree of predictive multiplicity rises as the\nlevel of privacy increases, and is unevenly distributed across individuals and\ndemographic groups in the data. Because randomness used to ensure DP during\ntraining explains predictions for some examples, our results highlight a\nfundamental challenge to the justifiability of decisions supported by\ndifferentially-private models in high-stakes settings. We conclude that\npractitioners should audit the predictive multiplicity of their DP-ensuring\nalgorithms before deploying them in applications of individual-level\nconsequence.\n","authors":["Bogdan Kulynych","Hsiang Hsu","Carmela Troncoso","Flavio P. Calmon"],"pdf_url":"https://arxiv.org/pdf/2302.14517v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14514v1","updated":"2023-02-28T12:07:27Z","published":"2023-02-28T12:07:27Z","title":"Differentially Private Distributed Convex Optimization","summary":"  This paper considers distributed optimization (DO) where multiple agents\ncooperate to minimize a global objective function, expressed as a sum of local\nobjectives, subject to some constraints. In DO, each agent iteratively solves a\nlocal optimization model constructed by its own data and communicates some\ninformation (e.g., a local solution) with its neighbors until a global solution\nis obtained. Even though locally stored data are not shared with other agents,\nit is still possible to reconstruct the data from the information communicated\namong agents, which could limit the practical usage of DO in applications with\nsensitive data. To address this issue, we propose a privacy-preserving DO\nalgorithm for constrained convex optimization models, which provides a\nstatistical guarantee of data privacy, known as differential privacy, and a\nsequence of iterates that converges to an optimal solution in expectation. The\nproposed algorithm generalizes a linearized alternating direction method of\nmultipliers by introducing a multiple local updates technique to reduce\ncommunication costs and incorporating an objective perturbation method in the\nlocal optimization models to compute and communicate randomized feasible local\nsolutions that cannot be utilized to reconstruct the local data, thus\npreserving data privacy. Under the existence of convex constraints, we show\nthat, while both algorithms provide the same level of data privacy, the\nobjective perturbation used in the proposed algorithm can provide better\nsolutions than does the widely adopted output perturbation method that\nrandomizes the local solutions by adding some noise. We present the details of\nprivacy and convergence analyses and numerically demonstrate the effectiveness\nof the proposed algorithm by applying it in two different applications, namely,\ndistributed control of power flow and federated learning, where data privacy is\nof concern.\n","authors":["Minseok Ryu","Kibaek Kim"],"pdf_url":"https://arxiv.org/pdf/2302.14514v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2202.09409"},{"id":"http://arxiv.org/abs/2302.14510v1","updated":"2023-02-28T12:00:21Z","published":"2023-02-28T12:00:21Z","title":"Bayesian Kernelized Tensor Factorization as Surrogate for Bayesian\n  Optimization","summary":"  Bayesian optimization (BO) primarily uses Gaussian processes (GP) as the key\nsurrogate model, mostly with a simple stationary and separable kernel function\nsuch as the widely used squared-exponential kernel with automatic relevance\ndetermination (SE-ARD). However, such simple kernel specifications are\ndeficient in learning functions with complex features, such as being\nnonstationary, nonseparable, and multimodal. Approximating such functions using\na local GP, even in a low-dimensional space, will require a large number of\nsamples, not to mention in a high-dimensional setting. In this paper, we\npropose to use Bayesian Kernelized Tensor Factorization (BKTF) -- as a new\nsurrogate model -- for BO in a D-dimensional Cartesian product space. Our key\nidea is to approximate the underlying D-dimensional solid with a fully Bayesian\nlow-rank tensor CP decomposition, in which we place GP priors on the latent\nbasis functions for each dimension to encode local consistency and smoothness.\nWith this formulation, information from each sample can be shared not only with\nneighbors but also across dimensions. Although BKTF no longer has an analytical\nposterior, we can still efficiently approximate the posterior distribution\nthrough Markov chain Monte Carlo (MCMC) and obtain prediction and full\nuncertainty quantification (UQ). We conduct numerical experiments on both\nstandard BO testing problems and machine learning hyperparameter tuning\nproblems, and our results confirm the superiority of BKTF in terms of sample\nefficiency.\n","authors":["Mengying Lei","Lijun Sun"],"pdf_url":"https://arxiv.org/pdf/2302.14510v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14509v1","updated":"2023-02-28T11:58:39Z","published":"2023-02-28T11:58:39Z","title":"Policy Dispersion in Non-Markovian Environment","summary":"  Markov Decision Process (MDP) presents a mathematical framework to formulate\nthe learning processes of agents in reinforcement learning. MDP is limited by\nthe Markovian assumption that a reward only depends on the immediate state and\naction. However, a reward sometimes depends on the history of states and\nactions, which may result in the decision process in a non-Markovian\nenvironment. In such environments, agents receive rewards via\ntemporally-extended behaviors sparsely, and the learned policies may be\nsimilar. This leads the agents acquired with similar policies generally overfit\nto the given task and can not quickly adapt to perturbations of environments.\nTo resolve this problem, this paper tries to learn the diverse policies from\nthe history of state-action pairs under a non-Markovian environment, in which a\npolicy dispersion scheme is designed for seeking diverse policy representation.\nSpecifically, we first adopt a transformer-based method to learn policy\nembeddings. Then, we stack the policy embeddings to construct a dispersion\nmatrix to induce a set of diverse policies. Finally, we prove that if the\ndispersion matrix is positive definite, the dispersed embeddings can\neffectively enlarge the disagreements across policies, yielding a diverse\nexpression for the original policy embedding distribution. Experimental results\nshow that this dispersion scheme can obtain more expressive diverse policies,\nwhich then derive more robust performance than recent learning baselines under\nvarious learning environments.\n","authors":["Bohao Qu","Xiaofeng Cao","Jielong Yang","Hechang Chen","Chang Yi","Ivor W. Tsang","Yew-Soon Ong"],"pdf_url":"https://arxiv.org/pdf/2302.14509v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.10598v2","updated":"2023-02-28T11:54:43Z","published":"2022-06-18T06:33:06Z","title":"A deep inverse reinforcement learning approach to route choice modeling\n  with context-dependent rewards","summary":"  Route choice modeling is a fundamental task in transportation planning and\ndemand forecasting. Classical methods generally adopt the discrete choice model\n(DCM) framework with linear utility functions and high-level route\ncharacteristics. While several recent studies have started to explore the\napplicability of deep learning for route choice modeling, they are limited to\npath-based models with relatively simple model architectures and relying on\npredefined choice sets. Existing link-based models can capture the dynamic\nnature of link choices within the trip without the need for choice set\ngeneration, but still assume linear relationships and link-additive features.\nTo address these issues, this study proposes a general deep inverse\nreinforcement learning (IRL) framework for link-based route choice modeling,\nwhich is capable of incorporating diverse features (of the state, action and\ntrip context) and capturing complex relationships. Specifically, we adapt an\nadversarial IRL model to the route choice problem for efficient estimation of\ncontext-dependent reward functions without value iteration. Experiment results\nbased on taxi GPS data from Shanghai, China validate the superior prediction\nperformance of the proposed model over conventional DCMs and other imitation\nlearning baselines, even for destinations unseen in the training data. Further\nanalysis show that the model exhibits competitive computational efficiency and\nreasonable interpretability. The proposed methodology provides a new direction\nfor future development of route choice models. It is general and can be\nadaptable to other route choice problems across different modes and networks.\n","authors":["Zhan Zhao","Yuebing Liang"],"pdf_url":"https://arxiv.org/pdf/2206.10598v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.03834v2","updated":"2023-02-28T11:31:18Z","published":"2022-01-11T08:35:18Z","title":"STIR$^2$: Reward Relabelling for combined Reinforcement and Imitation\n  Learning on sparse-reward tasks","summary":"  In the search for more sample-efficient reinforcement-learning (RL)\nalgorithms, a promising direction is to leverage as much external off-policy\ndata as possible. For instance, expert demonstrations. In the past, multiple\nideas have been proposed to make good use of the demonstrations added to the\nreplay buffer, such as pretraining on demonstrations only or minimizing\nadditional cost functions. We present a new method, able to leverage both\ndemonstrations and episodes collected online in any sparse-reward environment\nwith any off-policy algorithm. Our method is based on a reward bonus given to\ndemonstrations and successful episodes (via relabeling), encouraging expert\nimitation and self-imitation. Our experiments focus on several\nrobotic-manipulation tasks across two different simulation environments. We\nshow that our method based on reward relabeling improves the performance of the\nbase algorithm (SAC and DDPG) on these tasks. Finally, our best algorithm\nSTIR$^2$ (Self and Teacher Imitation by Reward Relabeling), which integrates\ninto our method multiple improvements from previous works, is more\ndata-efficient than all baselines.\n","authors":["Jesus Bujalance Martin","Fabien Moutarde"],"pdf_url":"https://arxiv.org/pdf/2201.03834v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2110.14464"},{"id":"http://arxiv.org/abs/2302.14483v1","updated":"2023-02-28T10:54:36Z","published":"2023-02-28T10:54:36Z","title":"RoPAWS: Robust Semi-supervised Representation Learning from Uncurated\n  Data","summary":"  Semi-supervised learning aims to train a model using limited labels.\nState-of-the-art semi-supervised methods for image classification such as PAWS\nrely on self-supervised representations learned with large-scale unlabeled but\ncurated data. However, PAWS is often less effective when using real-world\nunlabeled data that is uncurated, e.g., contains out-of-class data. We propose\nRoPAWS, a robust extension of PAWS that can work with real-world unlabeled\ndata. We first reinterpret PAWS as a generative classifier that models\ndensities using kernel density estimation. From this probabilistic perspective,\nwe calibrate its prediction based on the densities of labeled and unlabeled\ndata, which leads to a simple closed-form solution from the Bayes' rule. We\ndemonstrate that RoPAWS significantly improves PAWS for uncurated Semi-iNat by\n+5.3% and curated ImageNet by +0.4%.\n","authors":["Sangwoo Mo","Jong-Chyi Su","Chih-Yao Ma","Mido Assran","Ishan Misra","Licheng Yu","Sean Bell"],"pdf_url":"https://arxiv.org/pdf/2302.14483v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2203.07893v3","updated":"2023-02-28T10:50:17Z","published":"2022-03-15T13:40:22Z","title":"Gold Doesn't Always Glitter: Spectral Removal of Linear and Nonlinear\n  Guarded Attribute Information","summary":"  We describe a simple and effective method (Spectral Attribute removaL; SAL)\nto remove private or guarded information from neural representations. Our\nmethod uses matrix decomposition to project the input representations into\ndirections with reduced covariance with the guarded information rather than\nmaximal covariance as factorization methods normally use. We begin with linear\ninformation removal and proceed to generalize our algorithm to the case of\nnonlinear information removal using kernels. Our experiments demonstrate that\nour algorithm retains better main task performance after removing the guarded\ninformation compared to previous work. In addition, our experiments demonstrate\nthat we need a relatively small amount of guarded attribute data to remove\ninformation about these attributes, which lowers the exposure to sensitive data\nand is more suitable for low-resource scenarios. Code is available at\nhttps://github.com/jasonshaoshun/SAL.\n","authors":["Shun Shao","Yftah Ziser","Shay B. Cohen"],"pdf_url":"https://arxiv.org/pdf/2203.07893v3.pdf","comment":"Accepted to the Conference of the European Chapter of the Association\n  for Computational Linguistics (EACL), 2023; 12 pages"},{"id":"http://arxiv.org/abs/2302.14475v1","updated":"2023-02-28T10:34:44Z","published":"2023-02-28T10:34:44Z","title":"Benchmarking Deepart Detection","summary":"  Deepfake technologies have been blurring the boundaries between the real and\nunreal, likely resulting in malicious events. By leveraging newly emerged\ndeepfake technologies, deepfake researchers have been making a great upending\nto create deepfake artworks (deeparts), which are further closing the gap\nbetween reality and fantasy. To address potentially appeared ethics questions,\nthis paper establishes a deepart detection database (DDDB) that consists of a\nset of high-quality conventional art images (conarts) and five sets of deepart\nimages generated by five state-of-the-art deepfake models. This database\nenables us to explore once-for-all deepart detection and continual deepart\ndetection. For the two new problems, we suggest four benchmark evaluations and\nfour families of solutions on the constructed DDDB. The comprehensive study\ndemonstrates the effectiveness of the proposed solutions on the established\nbenchmark dataset, which is capable of paving a way to more interesting\ndirections of deepart detection. The constructed benchmark dataset and the\nsource code will be made publicly available.\n","authors":["Yabin Wang","Zhiwu Huang","Xiaopeng Hong"],"pdf_url":"https://arxiv.org/pdf/2302.14475v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14473v1","updated":"2023-02-28T10:32:17Z","published":"2023-02-28T10:32:17Z","title":"Implicit Bilevel Optimization: Differentiating through Bilevel\n  Optimization Programming","summary":"  Bilevel Optimization Programming is used to model complex and conflicting\ninteractions between agents, for example in Robust AI or Privacy-preserving AI.\nIntegrating bilevel mathematical programming within deep learning is thus an\nessential objective for the Machine Learning community. Previously proposed\napproaches only consider single-level programming. In this paper, we extend\nexisting single-level optimization programming approaches and thus propose\nDifferentiating through Bilevel Optimization Programming (BiGrad) for\nend-to-end learning of models that use Bilevel Programming as a layer. BiGrad\nhas wide applicability and can be used in modern machine learning frameworks.\nBiGrad is applicable to both continuous and combinatorial Bilevel optimization\nproblems. We describe a class of gradient estimators for the combinatorial case\nwhich reduces the requirements in terms of computation complexity; for the case\nof the continuous variable, the gradient computation takes advantage of the\npush-back approach (i.e. vector-jacobian product) for an efficient\nimplementation. Experiments show that the BiGrad successfully extends existing\nsingle-level approaches to Bilevel Programming.\n","authors":["Francesco Alesiani"],"pdf_url":"https://arxiv.org/pdf/2302.14473v1.pdf","comment":"Accepted for presentation at AAAI23; code will be submitted at\n  https://github.com/falesiani/bigrad"},{"id":"http://arxiv.org/abs/2212.01133v4","updated":"2023-02-28T10:31:40Z","published":"2022-12-02T12:26:00Z","title":"RIPPLE: Concept-Based Interpretation for Raw Time Series Models in\n  Education","summary":"  Time series is the most prevalent form of input data for educational\nprediction tasks. The vast majority of research using time series data focuses\non hand-crafted features, designed by experts for predictive performance and\ninterpretability. However, extracting these features is labor-intensive for\nhumans and computers. In this paper, we propose an approach that utilizes\nirregular multivariate time series modeling with graph neural networks to\nachieve comparable or better accuracy with raw time series clickstreams in\ncomparison to hand-crafted features. Furthermore, we extend concept activation\nvectors for interpretability in raw time series models. We analyze these\nadvances in the education domain, addressing the task of early student\nperformance prediction for downstream targeted interventions and instructional\nsupport. Our experimental analysis on 23 MOOCs with millions of combined\ninteractions over six behavioral dimensions show that models designed with our\napproach can (i) beat state-of-the-art educational time series baselines with\nno feature extraction and (ii) provide interpretable insights for personalized\ninterventions. Source code: https://github.com/epfl-ml4ed/ripple/.\n","authors":["Mohammad Asadi","Vinitra Swamy","Jibril Frej","Julien Vignoud","Mirko Marras","Tanja Käser"],"pdf_url":"https://arxiv.org/pdf/2212.01133v4.pdf","comment":"Accepted as a full paper at AAAI 2023: 37th AAAI Conference on\n  Artificial Intelligence (EAAI: AI for Education Special Track), 7-14 of\n  February 2023, Washington DC, USA"},{"id":"http://arxiv.org/abs/2302.14471v1","updated":"2023-02-28T10:29:42Z","published":"2023-02-28T10:29:42Z","title":"Safe peeling for l0-regularized least-squares with supplementary\n  material","summary":"  We introduce a new methodology dubbed ``safe peeling'' to accelerate the\nresolution of l0-regularized least-squares problems via a Branch-and-Bound\n(BnB) method. Our procedure enables to tighten the convex relaxation considered\nat each node of the BnB decision tree and therefore potentially allows for more\naggressive pruning. Numerical simulations show that our proposed methodology\nleads to significant gains in terms of number of nodes explored and overall\nsolving time.\n","authors":["Théo Guyard","Gilles Monnoyer","Clément Elvira","Cédric Herzet"],"pdf_url":"https://arxiv.org/pdf/2302.14471v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.09957v2","updated":"2023-02-28T10:26:48Z","published":"2022-10-18T16:11:55Z","title":"Contextual bandits with concave rewards, and an application to fair\n  ranking","summary":"  We consider Contextual Bandits with Concave Rewards (CBCR), a multi-objective\nbandit problem where the desired trade-off between the rewards is defined by a\nknown concave objective function, and the reward vector depends on an observed\nstochastic context. We present the first algorithm with provably vanishing\nregret for CBCR without restrictions on the policy space, whereas prior works\nwere restricted to finite policy spaces or tabular representations. Our\nsolution is based on a geometric interpretation of CBCR algorithms as\noptimization algorithms over the convex set of expected rewards spanned by all\nstochastic policies. Building on Frank-Wolfe analyses in constrained convex\noptimization, we derive a novel reduction from the CBCR regret to the regret of\na scalar-reward bandit problem. We illustrate how to apply the reduction\noff-the-shelf to obtain algorithms for CBCR with both linear and general reward\nfunctions, in the case of non-combinatorial actions. Motivated by fairness in\nrecommendation, we describe a special case of CBCR with rankings and\nfairness-aware objectives, leading to the first algorithm with regret\nguarantees for contextual combinatorial bandits with fairness of exposure.\n","authors":["Virginie Do","Elvis Dohmatob","Matteo Pirotta","Alessandro Lazaric","Nicolas Usunier"],"pdf_url":"https://arxiv.org/pdf/2210.09957v2.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2302.14470v1","updated":"2023-02-28T10:26:02Z","published":"2023-02-28T10:26:02Z","title":"Learning to Estimate Single-View Volumetric Flow Motions without 3D\n  Supervision","summary":"  We address the challenging problem of jointly inferring the 3D flow and\nvolumetric densities moving in a fluid from a monocular input video with a deep\nneural network. Despite the complexity of this task, we show that it is\npossible to train the corresponding networks without requiring any 3D ground\ntruth for training. In the absence of ground truth data we can train our model\nwith observations from real-world capture setups instead of relying on\nsynthetic reconstructions. We make this unsupervised training approach possible\nby first generating an initial prototype volume which is then moved and\ntransported over time without the need for volumetric supervision. Our approach\nrelies purely on image-based losses, an adversarial discriminator network, and\nregularization. Our method can estimate long-term sequences in a stable manner,\nwhile achieving closely matching targets for inputs such as rising smoke\nplumes.\n","authors":["Erik Franz","Barbara Solenthaler","Nils Thuerey"],"pdf_url":"https://arxiv.org/pdf/2302.14470v1.pdf","comment":"ICLR 2023 poster, source code:\n  https://github.com/tum-pbs/Neural-Global-Transport"},{"id":"http://arxiv.org/abs/2302.14460v1","updated":"2023-02-28T10:08:11Z","published":"2023-02-28T10:08:11Z","title":"Interpretable and Intervenable Ultrasonography-based Machine Learning\n  Models for Pediatric Appendicitis","summary":"  Appendicitis is among the most frequent reasons for pediatric abdominal\nsurgeries. With recent advances in machine learning, data-driven decision\nsupport could help clinicians diagnose and manage patients while reducing the\nnumber of non-critical surgeries. Previous decision support systems for\nappendicitis focused on clinical, laboratory, scoring and computed tomography\ndata, mainly ignoring abdominal ultrasound, a noninvasive and readily available\ndiagnostic modality. To this end, we developed and validated interpretable\nmachine learning models for predicting the diagnosis, management and severity\nof suspected appendicitis using ultrasound images. Our models were trained on a\ndataset comprising 579 pediatric patients with 1709 ultrasound images\naccompanied by clinical and laboratory data. Our methodological contribution is\nthe generalization of concept bottleneck models to prediction problems with\nmultiple views and incomplete concept sets. Notably, such models lend\nthemselves to interpretation and interaction via high-level concepts\nunderstandable to clinicians without sacrificing performance or requiring\ntime-consuming image annotation when deployed.\n","authors":["Ričards Marcinkevičs","Patricia Reis Wolfertstetter","Ugne Klimiene","Ece Ozkan","Kieran Chin-Cheong","Alyssia Paschke","Julia Zerres","Markus Denzinger","David Niederberger","Sven Wellmann","Christian Knorr","Julia E. Vogt"],"pdf_url":"https://arxiv.org/pdf/2302.14460v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13696v2","updated":"2023-02-28T10:07:47Z","published":"2023-02-27T11:55:24Z","title":"Moderate Adaptive Linear Units (MoLU)","summary":"  We propose a new high-performance activation function, Moderate Adaptive\nLinear Units (MoLU), for the deep neural network. The MoLU is a simple,\nbeautiful and powerful activation function that can be a good main activation\nfunction among hundreds of activation functions. Because the MoLU is made up of\nthe elementary functions, not only it is a infinite diffeomorphism (i.e. smooth\nand infinitely differentiable over whole domains), but also it decreases\ntraining time.\n","authors":["Hankyul Koh","Joon-hyuk Ko","Wonho Jhe"],"pdf_url":"https://arxiv.org/pdf/2302.13696v2.pdf","comment":"4 pages, 5 figures"},{"id":"http://arxiv.org/abs/2302.14458v1","updated":"2023-02-28T10:05:45Z","published":"2023-02-28T10:05:45Z","title":"Ultra-low Precision Multiplication-free Training for Deep Neural\n  Networks","summary":"  The training for deep neural networks (DNNs) demands immense energy\nconsumption, which restricts the development of deep learning as well as\nincreases carbon emissions. Thus, the study of energy-efficient training for\nDNNs is essential. In training, the linear layers consume the most energy\nbecause of the intense use of energy-consuming full-precision (FP32)\nmultiplication in multiply-accumulate (MAC). The energy-efficient works try to\ndecrease the precision of multiplication or replace the multiplication with\nenergy-efficient operations such as addition or bitwise shift, to reduce the\nenergy consumption of FP32 multiplications. However, the existing\nenergy-efficient works cannot replace all of the FP32 multiplications during\nboth forward and backward propagation with low-precision energy-efficient\noperations. In this work, we propose an Adaptive Layer-wise Scaling PoT\nQuantization (ALS-POTQ) method and a Multiplication-Free MAC (MF-MAC) to\nreplace all of the FP32 multiplications with the INT4 additions and 1-bit XOR\noperations. In addition, we propose Weight Bias Correction and Parameterized\nRatio Clipping techniques for stable training and improving accuracy. In our\ntraining scheme, all of the above methods do not introduce extra\nmultiplications, so we reduce up to 95.8% of the energy consumption in linear\nlayers during training. Experimentally, we achieve an accuracy degradation of\nless than 1% for CNN models on ImageNet and Transformer model on the WMT En-De\ntask. In summary, we significantly outperform the existing methods for both\nenergy efficiency and accuracy.\n","authors":["Chang Liu","Rui Zhang","Xishan Zhang","Yifan Hao","Zidong Du","Xing Hu","Ling Li","Qi Guo"],"pdf_url":"https://arxiv.org/pdf/2302.14458v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14451v1","updated":"2023-02-28T09:56:36Z","published":"2023-02-28T09:56:36Z","title":"Hierarchical Reinforcement Learning in Complex 3D Environments","summary":"  Hierarchical Reinforcement Learning (HRL) agents have the potential to\ndemonstrate appealing capabilities such as planning and exploration with\nabstraction, transfer, and skill reuse. Recent successes with HRL across\ndifferent domains provide evidence that practical, effective HRL agents are\npossible, even if existing agents do not yet fully realize the potential of\nHRL. Despite these successes, visually complex partially observable 3D\nenvironments remained a challenge for HRL agents. We address this issue with\nHierarchical Hybrid Offline-Online (H2O2), a hierarchical deep reinforcement\nlearning agent that discovers and learns to use options from scratch using its\nown experience. We show that H2O2 is competitive with a strong non-hierarchical\nMuesli baseline in the DeepMind Hard Eight tasks and we shed new light on the\nproblem of learning hierarchical agents in complex environments. Our empirical\nstudy of H2O2 reveals previously unnoticed practical challenges and brings new\nperspective to the current understanding of hierarchical agents in complex\ndomains.\n","authors":["Bernardo Avila Pires","Feryal Behbahani","Hubert Soyer","Kyriacos Nikiforou","Thomas Keck","Satinder Singh"],"pdf_url":"https://arxiv.org/pdf/2302.14451v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.02501v2","updated":"2023-02-28T09:50:50Z","published":"2022-11-04T15:03:41Z","title":"Weisfeiler and Leman go Hyperbolic: Learning Distance Preserving Node\n  Representations","summary":"  In recent years, graph neural networks (GNNs) have emerged as a promising\ntool for solving machine learning problems on graphs. Most GNNs are members of\nthe family of message passing neural networks (MPNNs). There is a close\nconnection between these models and the Weisfeiler-Leman (WL) test of\nisomorphism, an algorithm that can successfully test isomorphism for a broad\nclass of graphs. Recently, much research has focused on measuring the\nexpressive power of GNNs. For instance, it has been shown that standard MPNNs\nare at most as powerful as WL in terms of distinguishing non-isomorphic graphs.\nHowever, these studies have largely ignored the distances between the\nrepresentations of nodes/graphs which are of paramount importance for learning\ntasks. In this paper, we define a distance function between nodes which is\nbased on the hierarchy produced by the WL algorithm, and propose a model that\nlearns representations which preserve those distances between nodes. Since the\nemerging hierarchy corresponds to a tree, to learn these representations, we\ncapitalize on recent advances in the field of hyperbolic neural networks. We\nempirically evaluate the proposed model on standard node and graph\nclassification datasets where it achieves competitive performance with\nstate-of-the-art models.\n","authors":["Giannis Nikolentzos","Michail Chatzianastasis","Michalis Vazirgiannis"],"pdf_url":"https://arxiv.org/pdf/2211.02501v2.pdf","comment":"Accepted at AISTATS 2023"},{"id":"http://arxiv.org/abs/2302.14446v1","updated":"2023-02-28T09:46:44Z","published":"2023-02-28T09:46:44Z","title":"Reproducing kernel Hilbert spaces in the mean field limit","summary":"  Kernel methods, being supported by a well-developed theory and coming with\nefficient algorithms, are among the most popular and successful machine\nlearning techniques. From a mathematical point of view, these methods rest on\nthe concept of kernels and function spaces generated by kernels, so called\nreproducing kernel Hilbert spaces. Motivated by recent developments of learning\napproaches in the context of interacting particle systems, we investigate\nkernel methods acting on data with many measurement variables. We show the\nrigorous mean field limit of kernels and provide a detailed analysis of the\nlimiting reproducing kernel Hilbert space. Furthermore, several examples of\nkernels, that allow a rigorous mean field limit, are presented.\n","authors":["Christian Fiedler","Michael Herty","Michael Rom","Chiara Segala","Sebastian Trimpe"],"pdf_url":"https://arxiv.org/pdf/2302.14446v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2104.12623v2","updated":"2023-02-28T09:37:59Z","published":"2021-04-26T14:50:59Z","title":"Good Artists Copy, Great Artists Steal: Model Extraction Attacks Against\n  Image Translation Models","summary":"  Machine learning models are typically made available to potential client\nusers via inference APIs. Model extraction attacks occur when a malicious\nclient uses information gleaned from queries to the inference API of a victim\nmodel $F_V$ to build a surrogate model $F_A$ with comparable functionality.\nRecent research has shown successful model extraction of image classification,\nand natural language processing models. In this paper, we show the first model\nextraction attack against real-world generative adversarial network (GAN) image\ntranslation models. We present a framework for conducting such attacks, and\nshow that an adversary can successfully extract functional surrogate models by\nquerying $F_V$ using data from the same domain as the training data for $F_V$.\nThe adversary need not know $F_V$'s architecture or any other information about\nit beyond its intended task. We evaluate the effectiveness of our attacks using\nthree different instances of two popular categories of image translation: (1)\nSelfie-to-Anime and (2) Monet-to-Photo (image style transfer), and (3)\nSuper-Resolution (super resolution). Using standard performance metrics for\nGANs, we show that our attacks are effective. Furthermore, we conducted a large\nscale (125 participants) user study on Selfie-to-Anime and Monet-to-Photo to\nshow that human perception of the images produced by $F_V$ and $F_A$ can be\nconsidered equivalent, within an equivalence bound of Cohen's d = 0.3. Finally,\nwe show that existing defenses against model extraction attacks (watermarking,\nadversarial examples, poisoning) do not extend to image translation models.\n","authors":["Sebastian Szyller","Vasisht Duddu","Tommi Gröndahl","N. Asokan"],"pdf_url":"https://arxiv.org/pdf/2104.12623v2.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2302.14438v1","updated":"2023-02-28T09:30:24Z","published":"2023-02-28T09:30:24Z","title":"Self-Supervised Interest Transfer Network via Prototypical Contrastive\n  Learning for Recommendation","summary":"  Cross-domain recommendation has attracted increasing attention from industry\nand academia recently. However, most existing methods do not exploit the\ninterest invariance between domains, which would yield sub-optimal solutions.\nIn this paper, we propose a cross-domain recommendation method: Self-supervised\nInterest Transfer Network (SITN), which can effectively transfer invariant\nknowledge between domains via prototypical contrastive learning. Specifically,\nwe perform two levels of cross-domain contrastive learning: 1)\ninstance-to-instance contrastive learning, 2) instance-to-cluster contrastive\nlearning. Not only that, we also take into account users' multi-granularity and\nmulti-view interests. With this paradigm, SITN can explicitly learn the\ninvariant knowledge of interest clusters between domains and accurately capture\nusers' intents and preferences. We conducted extensive experiments on a public\ndataset and a large-scale industrial dataset collected from one of the world's\nleading e-commerce corporations. The experimental results indicate that SITN\nachieves significant improvements over state-of-the-art recommendation methods.\nAdditionally, SITN has been deployed on a micro-video recommendation platform,\nand the online A/B testing results further demonstrate its practical value.\nSupplement is available at: https://github.com/fanqieCoffee/SITN-Supplement.\n","authors":["Guoqiang Sun","Yibin Shen","Sijin Zhou","Xiang Chen","Hongyan Liu","Chunming Wu","Chenyi Lei","Xianhui Wei","Fei Fang"],"pdf_url":"https://arxiv.org/pdf/2302.14438v1.pdf","comment":"9 pages, 3 figures, accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2302.14428v1","updated":"2023-02-28T09:18:00Z","published":"2023-02-28T09:18:00Z","title":"Stochastic Gradient Descent under Markovian Sampling Schemes","summary":"  We study a variation of vanilla stochastic gradient descent where the\noptimizer only has access to a Markovian sampling scheme. These schemes\nencompass applications that range from decentralized optimization with a random\nwalker (token algorithms), to RL and online system identification problems. We\nfocus on obtaining rates of convergence under the least restrictive assumptions\npossible on the underlying Markov chain and on the functions optimized. We\nfirst unveil the theoretical lower bound for methods that sample stochastic\ngradients along the path of a Markov chain, making appear a dependency in the\nhitting time of the underlying Markov chain. We then study Markov chain SGD\n(MC-SGD) under much milder regularity assumptions than prior works. We finally\nintroduce MC-SAG, an alternative to MC-SGD with variance reduction, that only\ndepends on the hitting time of the Markov chain, therefore obtaining a\ncommunication-efficient token algorithm.\n","authors":["Mathieu Even"],"pdf_url":"https://arxiv.org/pdf/2302.14428v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.00702v6","updated":"2023-02-28T09:17:29Z","published":"2022-06-01T18:28:23Z","title":"Fast and Precise: Adjusting Planning Horizon with Adaptive Subgoal\n  Search","summary":"  Complex reasoning problems contain states that vary in the computational cost\nrequired to determine a good action plan. Taking advantage of this property, we\npropose Adaptive Subgoal Search (AdaSubS), a search method that adaptively\nadjusts the planning horizon. To this end, AdaSubS generates diverse sets of\nsubgoals at different distances. A verification mechanism is employed to filter\nout unreachable subgoals swiftly, allowing to focus on feasible further\nsubgoals. In this way, AdaSubS benefits from the efficiency of planning with\nlonger subgoals and the fine control with the shorter ones, and thus scales\nwell to difficult planning problems. We show that AdaSubS significantly\nsurpasses hierarchical planning algorithms on three complex reasoning tasks:\nSokoban, the Rubik's Cube, and inequality proving benchmark INT.\n","authors":["Michał Zawalski","Michał Tyrolski","Konrad Czechowski","Damian Stachura","Piotr Piękos","Tomasz Odrzygóźdź","Yuhuai Wu","Łukasz Kuciński","Piotr Miłoś"],"pdf_url":"https://arxiv.org/pdf/2206.00702v6.pdf","comment":"ICLR 2023 (oral)"},{"id":"http://arxiv.org/abs/2302.14427v1","updated":"2023-02-28T09:15:41Z","published":"2023-02-28T09:15:41Z","title":"Federated Covariate Shift Adaptation for Missing Target Output Values","summary":"  The most recent multi-source covariate shift algorithm is an efficient\nhyperparameter optimization algorithm for missing target output. In this paper,\nwe extend this algorithm to the framework of federated learning. For data\nislands in federated learning and covariate shift adaptation, we propose the\nfederated domain adaptation estimate of the target risk which is asymptotically\nunbiased with a desirable asymptotic variance property. We construct a weighted\nmodel for the target task and propose the federated covariate shift adaptation\nalgorithm which works preferably in our setting. The efficacy of our method is\njustified both theoretically and empirically.\n","authors":["Yaqian Xu","Wenquan Cui","Jianjun Xu","Haoyang Cheng"],"pdf_url":"https://arxiv.org/pdf/2302.14427v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.13200v2","updated":"2023-02-28T08:47:14Z","published":"2021-06-24T17:27:22Z","title":"Software for Dataset-wide XAI: From Local Explanations to Global\n  Insights with Zennit, CoRelAy, and ViRelAy","summary":"  Deep Neural Networks (DNNs) are known to be strong predictors, but their\nprediction strategies can rarely be understood. With recent advances in\nExplainable Artificial Intelligence (XAI), approaches are available to explore\nthe reasoning behind those complex models' predictions. Among post-hoc\nattribution methods, Layer-wise Relevance Propagation (LRP) shows high\nperformance. For deeper quantitative analysis, manual approaches exist, but\nwithout the right tools they are unnecessarily labor intensive. In this\nsoftware paper, we introduce three software packages targeted at scientists to\nexplore model reasoning using attribution approaches and beyond: (1) Zennit - a\nhighly customizable and intuitive attribution framework implementing LRP and\nrelated approaches in PyTorch, (2) CoRelAy - a framework to easily and quickly\nconstruct quantitative analysis pipelines for dataset-wide analyses of\nexplanations, and (3) ViRelAy - a web-application to interactively explore\ndata, attributions, and analysis results. With this, we provide a standardized\nimplementation solution for XAI, to contribute towards more reproducibility in\nour field.\n","authors":["Christopher J. Anders","David Neumann","Wojciech Samek","Klaus-Robert Müller","Sebastian Lapuschkin"],"pdf_url":"https://arxiv.org/pdf/2106.13200v2.pdf","comment":"20 pages, 6 figures, 2 listings, 1 table"},{"id":"http://arxiv.org/abs/2302.14412v1","updated":"2023-02-28T08:46:51Z","published":"2023-02-28T08:46:51Z","title":"An Algorithm and Complexity Results for Causal Unit Selection","summary":"  The unit selection problem aims to identify objects, called units, that are\nmost likely to exhibit a desired mode of behavior when subjected to stimuli\n(e.g., customers who are about to churn but would change their mind if\nencouraged). Unit selection with counterfactual objective functions was\nintroduced relatively recently with existing work focusing on bounding a\nspecific class of objective functions, called the benefit functions, based on\nobservational and interventional data -- assuming a fully specified model is\nnot available to evaluate these functions. We complement this line of work by\nproposing the first exact algorithm for finding optimal units given a broad\nclass of causal objective functions and a fully specified structural causal\nmodel (SCM). We show that unit selection under this class of objective\nfunctions is $\\text{NP}^\\text{PP}$-complete but is $\\text{NP}$-complete when\nunit variables correspond to all exogenous variables in the SCM. We also\nprovide treewidth-based complexity bounds on our proposed algorithm while\nrelating it to a well-known algorithm for Maximum a Posteriori (MAP) inference.\n","authors":["Haiying Huang","Adnan Darwiche"],"pdf_url":"https://arxiv.org/pdf/2302.14412v1.pdf","comment":"To be published in the 2nd Conference on Causal Learning and\n  Reasoning (CLeaR 2023)"},{"id":"http://arxiv.org/abs/2302.13152v2","updated":"2023-02-28T08:43:40Z","published":"2023-02-25T20:36:41Z","title":"On Bellman's principle of optimality and Reinforcement learning for\n  safety-constrained Markov decision process","summary":"  We study optimality for the safety-constrained Markov decision process which\nis the underlying framework for safe reinforcement learning. Specifically, we\nconsider a constrained Markov decision process (with finite states and finite\nactions) where the goal of the decision maker is to reach a target set while\navoiding an unsafe set(s) with certain probabilistic guarantees. Therefore the\nunderlying Markov chain for any control policy will be multichain since by\ndefinition there exists a target set and an unsafe set. The decision maker also\nhas to be optimal (with respect to a cost function) while navigating to the\ntarget set. This gives rise to a multi-objective optimization problem. We\nhighlight the fact that Bellman's principle of optimality may not hold for\nconstrained Markov decision problems with an underlying multichain structure\n(as shown by the counterexample). We resolve the counterexample by formulating\nthe aforementioned multi-objective optimization problem as a zero-sum game and\nthereafter construct an asynchronous value iteration scheme for the Lagrangian\n(similar to Shapley's algorithm. Finally, we consider the reinforcement\nlearning problem for the same and construct a modified Q-learning algorithm for\nlearning the Lagrangian from data. We also provide a lower bound on the number\nof iterations required for learning the Lagrangian and corresponding error\nbounds.\n","authors":["Rahul Misra","Rafał Wisniewski","Carsten Skovmose Kallesøe"],"pdf_url":"https://arxiv.org/pdf/2302.13152v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14407v1","updated":"2023-02-28T08:42:42Z","published":"2023-02-28T08:42:42Z","title":"Asymptotically Optimal Thompson Sampling Based Policy for the Uniform\n  Bandits and the Gaussian Bandits","summary":"  Thompson sampling (TS) for the parametric stochastic multi-armed bandits has\nbeen well studied under the one-dimensional parametric models. It is often\nreported that TS is fairly insensitive to the choice of the prior when it comes\nto regret bounds. However, this property is not necessarily true when\nmultiparameter models are considered, e.g., a Gaussian model with unknown mean\nand variance parameters. In this paper, we first extend the regret analysis of\nTS to the model of uniform distributions with unknown supports. Specifically,\nwe show that a switch of noninformative priors drastically affects the regret\nin expectation. Through our analysis, the uniform prior is proven to be the\noptimal choice in terms of the expected regret, while the reference prior and\nthe Jeffreys prior are found to be suboptimal, which is consistent with\nprevious findings in the model of Gaussian distributions. However, the uniform\nprior is specific to the parameterization of the distributions, meaning that if\nan agent considers different parameterizations of the same model, the agent\nwith the uniform prior might not always achieve the optimal performance. In\nlight of this limitation, we propose a slightly modified TS-based policy,\ncalled TS with Truncation (TS-T), which can achieve the asymptotic optimality\nfor the Gaussian distributions and the uniform distributions by using the\nreference prior and the Jeffreys prior that are invariant under one-to-one\nreparameterizations. The pre-processig of the posterior distribution is the key\nto TS-T, where we add an adaptive truncation procedure on the parameter space\nof the posterior distributions. Simulation results support our analysis, where\nTS-T shows the best performance in a finite-time horizon compared to other\nknown optimal policies, while TS with the invariant priors performs poorly.\n","authors":["Jongyeong Lee","Chao-Kai Chiang","Masashi Sugiyama"],"pdf_url":"https://arxiv.org/pdf/2302.14407v1.pdf","comment":"47 pages, preprint"},{"id":"http://arxiv.org/abs/2302.12388v2","updated":"2023-02-28T08:41:46Z","published":"2023-02-24T01:29:21Z","title":"TrafFormer: A Transformer Model for Predicting Long-term Traffic","summary":"  Traffic prediction is a flourishing research field due to its importance in\nhuman mobility in the urban space. Despite this, existing studies only focus on\nshort-term prediction of up to few hours in advance, with most being up to one\nhour only. Long-term traffic prediction can enable more comprehensive,\ninformed, and proactive measures against traffic congestion and is therefore an\nimportant task to explore. In this paper, we explore the task of long-term\ntraffic prediction; where we predict traffic up to 24 hours in advance. We note\nthe weaknesses of existing models--which are based on recurrent structures--for\nlong-term traffic prediction and propose a modified Transformer model\n``TrafFormer\". Experiments comparing our model with existing hybrid neural\nnetwork models show the superiority of our model.\n","authors":["David Alexander Tedjopurnomo","Farhana M. Choudhury","A. K. Qin"],"pdf_url":"https://arxiv.org/pdf/2302.12388v2.pdf","comment":"14 pages, 6 figures"},{"id":"http://arxiv.org/abs/2302.01029v2","updated":"2023-02-28T08:38:39Z","published":"2023-02-02T11:46:23Z","title":"On Suppressing Range of Adaptive Stepsizes of Adam to Improve\n  Generalisation Performance","summary":"  A number of recent adaptive optimizers improve the generalisation performance\nof Adam by essentially reducing the variance of adaptive stepsizes to get\ncloser to SGD with momentum. Following the above motivation, we suppress the\nrange of the adaptive stepsizes of Adam by exploiting the layerwise gradient\nstatistics. In particular, at each iteration, we propose to perform three\nconsecutive operations on the second momentum v_t before using it to update a\nDNN model: (1): down-scaling, (2): epsilon-embedding, and (3):\ndown-translating. The resulting algorithm is referred to as SET-Adam, where SET\nis a brief notation of the three operations. The down-scaling operation on v_t\nis performed layerwise by making use of the angles between the layerwise\nsubvectors of v_t and the corresponding all-one subvectors. Extensive\nexperimental results show that SET-Adam outperforms eight adaptive optimizers\nwhen training transformers and LSTMs for NLP, and VGG and ResNet for image\nclassification over CIAF10 and CIFAR100 while matching the best performance of\nthe eight adaptive methods when training WGAN-GP models for image generation\ntasks. Furthermore, SET-Adam produces higher validation accuracies than Adam\nand AdaBelief for training ResNet18 over ImageNet.\n","authors":["Guoqiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.01029v2.pdf","comment":"12 pages. arXiv admin note: substantial text overlap with\n  arXiv:2203.13273"},{"id":"http://arxiv.org/abs/2302.14395v1","updated":"2023-02-28T08:23:15Z","published":"2023-02-28T08:23:15Z","title":"Item Cold Start Recommendation via Adversarial Variational Auto-encoder\n  Warm-up","summary":"  The gap between the randomly initialized item ID embedding and the\nwell-trained warm item ID embedding makes the cold items hard to suit the\nrecommendation system, which is trained on the data of historical warm items.\nTo alleviate the performance decline of new items recommendation, the\ndistribution of the new item ID embedding should be close to that of the\nhistorical warm items. To achieve this goal, we propose an Adversarial\nVariational Auto-encoder Warm-up model (AVAEW) to generate warm-up item ID\nembedding for cold items. Specifically, we develop a conditional variational\nauto-encoder model to leverage the side information of items for generating the\nwarm-up item ID embedding. Particularly, we introduce an adversarial module to\nenforce the alignment between warm-up item ID embedding distribution and\nhistorical item ID embedding distribution. We demonstrate the effectiveness and\ncompatibility of the proposed method by extensive offline experiments on public\ndatasets and online A/B tests on a real-world large-scale news recommendation\nplatform.\n","authors":["Shenzheng Zhang","Qi Tan","Xinzhi Zheng","Yi Ren","Xu Zhao"],"pdf_url":"https://arxiv.org/pdf/2302.14395v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.15771v3","updated":"2023-02-28T08:18:32Z","published":"2021-10-29T13:39:14Z","title":"Collaborative Pure Exploration in Kernel Bandit","summary":"  In this paper, we formulate a Collaborative Pure Exploration in Kernel Bandit\nproblem (CoPE-KB), which provides a novel model for multi-agent multi-task\ndecision making under limited communication and general reward functions, and\nis applicable to many online learning tasks, e.g., recommendation systems and\nnetwork scheduling. We consider two settings of CoPE-KB, i.e., Fixed-Confidence\n(FC) and Fixed-Budget (FB), and design two optimal algorithms CoopKernelFC (for\nFC) and CoopKernelFB (for FB). Our algorithms are equipped with innovative and\nefficient kernelized estimators to simultaneously achieve computation and\ncommunication efficiency. Matching upper and lower bounds under both the\nstatistical and communication metrics are established to demonstrate the\noptimality of our algorithms. The theoretical bounds successfully quantify the\ninfluences of task similarities on learning acceleration and only depend on the\neffective dimension of the kernelized feature space. Our analytical techniques,\nincluding data dimension decomposition, linear structured instance\ntransformation and (communication) round-speedup induction, are novel and\napplicable to other bandit problems. Empirical evaluations are provided to\nvalidate our theoretical results and demonstrate the performance superiority of\nour algorithms.\n","authors":["Yihan Du","Wei Chen","Yuko Kuroki","Longbo Huang"],"pdf_url":"https://arxiv.org/pdf/2110.15771v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14390v1","updated":"2023-02-28T08:17:50Z","published":"2023-02-28T08:17:50Z","title":"Your time series is worth a binary image: machine vision assisted deep\n  framework for time series forecasting","summary":"  Time series forecasting (TSF) has been a challenging research area, and\nvarious models have been developed to address this task. However, almost all\nthese models are trained with numerical time series data, which is not as\neffectively processed by the neural system as visual information. To address\nthis challenge, this paper proposes a novel machine vision assisted deep time\nseries analysis (MV-DTSA) framework. The MV-DTSA framework operates by\nanalyzing time series data in a novel binary machine vision time series metric\nspace, which includes a mapping and an inverse mapping function from the\nnumerical time series space to the binary machine vision space, and a deep\nmachine vision model designed to address the TSF task in the binary space. A\ncomprehensive computational analysis demonstrates that the proposed MV-DTSA\nframework outperforms state-of-the-art deep TSF models, without requiring\nsophisticated data decomposition or model customization. The code for our\nframework is accessible at https://github.com/IkeYang/\nmachine-vision-assisted-deep-time-series-analysis-MV-DTSA-.\n","authors":["Luoxiao Yang","Xinqi Fan","Zijun Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.14390v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14386v1","updated":"2023-02-28T08:15:49Z","published":"2023-02-28T08:15:49Z","title":"Practical Algorithms for Orientations of Partially Directed Graphical\n  Models","summary":"  In observational studies, the true causal model is typically unknown and\nneeds to be estimated from available observational and limited experimental\ndata. In such cases, the learned causal model is commonly represented as a\npartially directed acyclic graph (PDAG), which contains both directed and\nundirected edges indicating uncertainty of causal relations between random\nvariables. The main focus of this paper is on the maximal orientation task,\nwhich, for a given PDAG, aims to orient the undirected edges maximally such\nthat the resulting graph represents the same Markov equivalent DAGs as the\ninput PDAG. This task is a subroutine used frequently in causal discovery, e.\ng., as the final step of the celebrated PC algorithm. Utilizing connections to\nthe problem of finding a consistent DAG extension of a PDAG, we derive faster\nalgorithms for computing the maximal orientation by proposing two novel\napproaches for extending PDAGs, both constructed with an emphasis on simplicity\nand practical effectiveness.\n","authors":["Malte Luttermann","Marcel Wienöbst","Maciej Liśkiewicz"],"pdf_url":"https://arxiv.org/pdf/2302.14386v1.pdf","comment":"Accepted to the Proceedings of the 2nd Conference on Causal Learning\n  and Reasoning (CLeaR-23)"},{"id":"http://arxiv.org/abs/2302.14383v1","updated":"2023-02-28T08:11:56Z","published":"2023-02-28T08:11:56Z","title":"Linear Spaces of Meanings: the Compositional Language of VLMs","summary":"  We investigate compositional structures in vector data embeddings from\npre-trained vision-language models (VLMs). Traditionally, compositionality has\nbeen associated with algebraic operations on embeddings of words from a\npre-existing vocabulary. In contrast, we seek to approximate label\nrepresentations from a text encoder as combinations of a smaller set of vectors\nin the embedding space. These vectors can be seen as \"ideal words\" which can be\nused to generate new concepts in an efficient way. We present a theoretical\nframework for understanding linear compositionality, drawing connections with\nmathematical representation theory and previous definitions of disentanglement.\nWe provide theoretical and empirical evidence that ideal words provide good\ncompositional approximations of composite concepts and can be more effective\nthan token-based decompositions of the same concepts.\n","authors":["Matthew Trager","Pramuditha Perera","Luca Zancato","Alessandro Achille","Parminder Bhatia","Bing Xiang","Stefano Soatto"],"pdf_url":"https://arxiv.org/pdf/2302.14383v1.pdf","comment":"24 pages, 4 figures, 4 tables"},{"id":"http://arxiv.org/abs/2302.12578v2","updated":"2023-02-28T08:08:29Z","published":"2023-02-24T11:25:50Z","title":"Fairness in Language Models Beyond English: Gaps and Challenges","summary":"  With language models becoming increasingly ubiquitous, it has become\nessential to address their inequitable treatment of diverse demographic groups\nand factors. Most research on evaluating and mitigating fairness harms has been\nconcentrated on English, while multilingual models and non-English languages\nhave received comparatively little attention. This paper presents a survey of\nfairness in multilingual and non-English contexts, highlighting the\nshortcomings of current research and the difficulties faced by methods designed\nfor English. We contend that the multitude of diverse cultures and languages\nacross the world makes it infeasible to achieve comprehensive coverage in terms\nof constructing fairness datasets. Thus, the measurement and mitigation of\nbiases must evolve beyond the current dataset-driven practices that are\nnarrowly focused on specific dimensions and types of biases and, therefore,\nimpossible to scale across languages and cultures.\n","authors":["Krithika Ramesh","Sunayana Sitaram","Monojit Choudhury"],"pdf_url":"https://arxiv.org/pdf/2302.12578v2.pdf","comment":"Accepted to EACL 2023 (Findings)"},{"id":"http://arxiv.org/abs/2111.14039v3","updated":"2023-02-28T08:07:02Z","published":"2021-11-28T03:22:22Z","title":"Generalization Performance of Empirical Risk Minimization on\n  Over-parameterized Deep ReLU Nets","summary":"  In this paper, we study the generalization performance of global minima for\nimplementing empirical risk minimization (ERM) on over-parameterized deep ReLU\nnets. Using a novel deepening scheme for deep ReLU nets, we rigorously prove\nthat there exist perfect global minima achieving almost optimal generalization\nerror bounds for numerous types of data under mild conditions. Since\nover-parameterization is crucial to guarantee that the global minima of ERM on\ndeep ReLU nets can be realized by the widely used stochastic gradient descent\n(SGD) algorithm, our results indeed fill a gap between optimization and\ngeneralization.\n","authors":["Shao-Bo Lin","Yao Wang","Ding-Xuan Zhou"],"pdf_url":"https://arxiv.org/pdf/2111.14039v3.pdf","comment":"15 pages, 3 figures"},{"id":"http://arxiv.org/abs/2302.14376v1","updated":"2023-02-28T07:58:49Z","published":"2023-02-28T07:58:49Z","title":"GNOT: A General Neural Operator Transformer for Operator Learning","summary":"  Learning partial differential equations' (PDEs) solution operators is an\nessential problem in machine learning. However, there are several challenges\nfor learning operators in practical applications like the irregular mesh,\nmultiple input functions, and complexity of the PDEs' solution. To address\nthese challenges, we propose a general neural operator transformer (GNOT), a\nscalable and effective transformer-based framework for learning operators. By\ndesigning a novel heterogeneous normalized attention layer, our model is highly\nflexible to handle multiple input functions and irregular mesh. Besides, we\nintroduce a geometric gating mechanism which could be viewed as a soft domain\ndecomposition to solve the multi-scale problems. The large model capacity of\ntransformer architecture grants our model the possibility to scale to large\ndatasets and practical problems. We conduct extensive experiments on multiple\nchallenging datasets from different domains and achieve a remarkable\nimprovement compared with alternative methods.\n","authors":["Zhongkai Hao","Chengyang Ying","Zhengyi Wang","Hang Su","Yinpeng Dong","Songming Liu","Ze Cheng","Jun Zhu","Jian Song"],"pdf_url":"https://arxiv.org/pdf/2302.14376v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.04553v4","updated":"2023-02-28T07:55:21Z","published":"2021-12-08T19:55:26Z","title":"Recent Advances in Reinforcement Learning in Finance","summary":"  The rapid changes in the finance industry due to the increasing amount of\ndata have revolutionized the techniques on data processing and data analysis\nand brought new theoretical and computational challenges. In contrast to\nclassical stochastic control theory and other analytical approaches for solving\nfinancial decision-making problems that heavily reply on model assumptions, new\ndevelopments from reinforcement learning (RL) are able to make full use of the\nlarge amount of financial data with fewer model assumptions and to improve\ndecisions in complex financial environments. This survey paper aims to review\nthe recent developments and use of RL approaches in finance. We give an\nintroduction to Markov decision processes, which is the setting for many of the\ncommonly used RL approaches. Various algorithms are then introduced with a\nfocus on value and policy based methods that do not require any model\nassumptions. Connections are made with neural networks to extend the framework\nto encompass deep RL algorithms. Our survey concludes by discussing the\napplication of these RL algorithms in a variety of decision-making problems in\nfinance, including optimal execution, portfolio optimization, option pricing\nand hedging, market making, smart order routing, and robo-advising.\n","authors":["Ben Hambly","Renyuan Xu","Huining Yang"],"pdf_url":"https://arxiv.org/pdf/2112.04553v4.pdf","comment":"60 pages, 1 figure"},{"id":"http://arxiv.org/abs/2302.14372v1","updated":"2023-02-28T07:55:02Z","published":"2023-02-28T07:55:02Z","title":"The In-Sample Softmax for Offline Reinforcement Learning","summary":"  Reinforcement learning (RL) agents can leverage batches of previously\ncollected data to extract a reasonable control policy. An emerging issue in\nthis offline RL setting, however, is that the bootstrapping update underlying\nmany of our methods suffers from insufficient action-coverage: standard max\noperator may select a maximal action that has not been seen in the dataset.\nBootstrapping from these inaccurate values can lead to overestimation and even\ndivergence. There are a growing number of methods that attempt to approximate\nan \\emph{in-sample} max, that only uses actions well-covered by the dataset. We\nhighlight a simple fact: it is more straightforward to approximate an in-sample\n\\emph{softmax} using only actions in the dataset. We show that policy iteration\nbased on the in-sample softmax converges, and that for decreasing temperatures\nit approaches the in-sample max. We derive an In-Sample Actor-Critic (AC),\nusing this in-sample softmax, and show that it is consistently better or\ncomparable to existing offline RL methods, and is also well-suited to\nfine-tuning.\n","authors":["Chenjun Xiao","Han Wang","Yangchen Pan","Adam White","Martha White"],"pdf_url":"https://arxiv.org/pdf/2302.14372v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08915v3","updated":"2023-02-28T07:54:36Z","published":"2023-01-21T08:30:15Z","title":"Improving Deep Regression with Ordinal Entropy","summary":"  In computer vision, it is often observed that formulating regression problems\nas a classification task often yields better performance. We investigate this\ncurious phenomenon and provide a derivation to show that classification, with\nthe cross-entropy loss, outperforms regression with a mean squared error loss\nin its ability to learn high-entropy feature representations. Based on the\nanalysis, we propose an ordinal entropy loss to encourage higher-entropy\nfeature spaces while maintaining ordinal relationships to improve the\nperformance of regression tasks. Experiments on synthetic and real-world\nregression tasks demonstrate the importance and benefits of increasing entropy\nfor regression.\n","authors":["Shihao Zhang","Linlin Yang","Michael Bi Mi","Xiaoxu Zheng","Angela Yao"],"pdf_url":"https://arxiv.org/pdf/2301.08915v3.pdf","comment":"Accepted to ICLR 2023. Project page:\n  https://github.com/needylove/OrdinalEntropy"},{"id":"http://arxiv.org/abs/2207.12884v2","updated":"2023-02-28T07:53:10Z","published":"2022-07-26T13:17:28Z","title":"CFLIT: Coexisting Federated Learning and Information Transfer","summary":"  Future wireless networks are expected to support diverse mobile services,\nincluding artificial intelligence (AI) services and ubiquitous data\ntransmissions. Federated learning (FL), as a revolutionary learning approach,\nenables collaborative AI model training across distributed mobile edge devices.\nBy exploiting the superposition property of multiple-access channels,\nover-the-air computation allows concurrent model uploading from massive devices\nover the same radio resources, and thus significantly reduces the communication\ncost of FL. In this paper, we study the coexistence of over-the-air FL and\ntraditional information transfer (IT) in a mobile edge network. We propose a\ncoexisting federated learning and information transfer (CFLIT) communication\nframework, where the FL and IT devices share the wireless spectrum in an OFDM\nsystem. Under this framework, we aim to maximize the IT data rate and guarantee\na given FL convergence performance by optimizing the long-term radio resource\nallocation. A key challenge that limits the spectrum efficiency of the\ncoexisting system lies in the large overhead incurred by frequent communication\nbetween the server and edge devices for FL model aggregation. To address the\nchallenge, we rigorously analyze the impact of the computation-to-communication\nratio on the convergence of over-the-air FL in wireless fading channels. The\nanalysis reveals the existence of an optimal computation-to-communication ratio\nthat minimizes the amount of radio resources needed for over-the-air FL to\nconverge to a given error tolerance. Based on the analysis, we propose a\nlow-complexity online algorithm to jointly optimize the radio resource\nallocation for both the FL devices and IT devices. Extensive numerical\nsimulations verify the superior performance of the proposed design for the\ncoexistence of FL and IT devices in wireless cellular systems.\n","authors":["Zehong Lin","Hang Liu","Ying-Jun Angela Zhang"],"pdf_url":"https://arxiv.org/pdf/2207.12884v2.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2212.00328v2","updated":"2023-02-28T07:47:30Z","published":"2022-12-01T07:26:49Z","title":"Differentially Private Learning with Per-Sample Adaptive Clipping","summary":"  Privacy in AI remains a topic that draws attention from researchers and the\ngeneral public in recent years. As one way to implement privacy-preserving AI,\ndifferentially private learning is a framework that enables AI models to use\ndifferential privacy (DP). To achieve DP in the learning process, existing\nalgorithms typically limit the magnitude of gradients with a constant clipping,\nwhich requires carefully tuned due to its significant impact on model\nperformance. As a solution to this issue, latest works NSGD and Auto-S\ninnovatively propose to use normalization instead of clipping to avoid\nhyperparameter tuning. However, normalization-based approaches like NSGD and\nAuto-S rely on a monotonic weight function, which imposes excessive weight on\nsmall gradient samples and introduces extra deviation to the update. In this\npaper, we propose a Differentially Private Per-Sample Adaptive Clipping\n(DP-PSAC) algorithm based on a non-monotonic adaptive weight function, which\nguarantees privacy without the typical hyperparameter tuning process of using a\nconstant clipping while significantly reducing the deviation between the update\nand true batch-averaged gradient. We provide a rigorous theoretical convergence\nanalysis and show that with convergence rate at the same order, the proposed\nalgorithm achieves a lower non-vanishing bound, which is maintained over\ntraining iterations, compared with NSGD/Auto-S. In addition, through extensive\nexperimental evaluation, we show that DP-PSAC outperforms or matches the\nstate-of-the-art methods on multiple main-stream vision and language tasks.\n","authors":["Tianyu Xia","Shuheng Shen","Su Yao","Xinyi Fu","Ke Xu","Xiaolong Xu","Xing Fu","Weiqiang Wang"],"pdf_url":"https://arxiv.org/pdf/2212.00328v2.pdf","comment":"To appear in AAAI 2023, Revised acknowledgments and citations"},{"id":"http://arxiv.org/abs/2302.14367v1","updated":"2023-02-28T07:40:37Z","published":"2023-02-28T07:40:37Z","title":"BrainBERT: Self-supervised representation learning for intracranial\n  recordings","summary":"  We create a reusable Transformer, BrainBERT, for intracranial recordings\nbringing modern representation learning approaches to neuroscience. Much like\nin NLP and speech recognition, this Transformer enables classifying complex\nconcepts, i.e., decoding neural data, with higher accuracy and with much less\ndata by being pretrained in an unsupervised manner on a large corpus of\nunannotated neural recordings. Our approach generalizes to new subjects with\nelectrodes in new positions and to unrelated tasks showing that the\nrepresentations robustly disentangle the neural signal. Just like in NLP where\none can study language by investigating what a language model learns, this\napproach opens the door to investigating the brain by what a model of the brain\nlearns. As a first step along this path, we demonstrate a new analysis of the\nintrinsic dimensionality of the computations in different areas of the brain.\nTo construct these representations, we combine a technique for producing\nsuper-resolution spectrograms of neural data with an approach designed for\ngenerating contextual representations of audio by masking. In the future, far\nmore concepts will be decodable from neural recordings by using representation\nlearning, potentially unlocking the brain like language models unlocked\nlanguage.\n","authors":["Christopher Wang","Vighnesh Subramaniam","Adam Uri Yaari","Gabriel Kreiman","Boris Katz","Ignacio Cases","Andrei Barbu"],"pdf_url":"https://arxiv.org/pdf/2302.14367v1.pdf","comment":"9 pages, 6 figures, ICLR 2023"},{"id":"http://arxiv.org/abs/2209.07075v2","updated":"2023-02-28T07:35:57Z","published":"2022-09-15T06:21:24Z","title":"Bi-level Physics-Informed Neural Networks for PDE Constrained\n  Optimization using Broyden's Hypergradients","summary":"  Deep learning based approaches like Physics-informed neural networks (PINNs)\nand DeepONets have shown promise on solving PDE constrained optimization\n(PDECO) problems. However, existing methods are insufficient to handle those\nPDE constraints that have a complicated or nonlinear dependency on optimization\ntargets. In this paper, we present a novel bi-level optimization framework to\nresolve the challenge by decoupling the optimization of the targets and\nconstraints. For the inner loop optimization, we adopt PINNs to solve the PDE\nconstraints only. For the outer loop, we design a novel method by using\nBroyden's method based on the Implicit Function Theorem (IFT), which is\nefficient and accurate for approximating hypergradients. We further present\ntheoretical explanations and error analysis of the hypergradients computation.\nExtensive experiments on multiple large-scale and nonlinear PDE constrained\noptimization problems demonstrate that our method achieves state-of-the-art\nresults compared with strong baselines.\n","authors":["Zhongkai Hao","Chengyang Ying","Hang Su","Jun Zhu","Jian Song","Ze Cheng"],"pdf_url":"https://arxiv.org/pdf/2209.07075v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.11836v2","updated":"2023-02-28T07:35:33Z","published":"2023-02-23T07:52:31Z","title":"Sharpness-Aware Minimization: An Implicit Regularization Perspective","summary":"  Sharpness-Aware Minimization (SAM) is a recent optimization framework aiming\nto improve the deep neural network generalization, through obtaining flatter\n(i.e. less sharp) solutions. As SAM has been numerically successful, recent\npapers have studied the theoretical aspects of the framework. In this work, we\nstudy SAM through an implicit regularization lens, and present a new\ntheoretical explanation of why SAM generalizes well. To this end, we study the\nleast-squares linear regression problem and show a bias-variance trade-off for\nSAM's error over the course of the algorithm. We show SAM has lower bias\ncompared to Gradient Descent (GD), while having higher variance. This shows SAM\ncan outperform GD, specially if the algorithm is \\emph{stopped early}, which is\noften the case when training large neural networks due to the prohibitive\ncomputational cost. We extend our results to kernel regression, as well as\nstochastic optimization and discuss how implicit regularization of SAM can\nimprove upon vanilla training.\n","authors":["Kayhan Behdin","Rahul Mazumder"],"pdf_url":"https://arxiv.org/pdf/2302.11836v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00939v4","updated":"2023-02-28T07:22:39Z","published":"2022-10-03T13:50:58Z","title":"Improving Sample Quality of Diffusion Models Using Self-Attention\n  Guidance","summary":"  Denoising diffusion models (DDMs) have attracted attention due to their\nexceptional sample quality and diversity. This success is largely attributed to\nthe use of class- or text-conditional diffusion guidance methods. In this\npaper, we propose a more comprehensive approach that expands beyond traditional\nguidance methods. By adopting this generalized perspective, we introduce two\nnovel condition-free strategies to enhance the quality of generated images:\nblur guidance and advanced Self-Attention Guidance (SAG). Employing benign\nproperties of Gaussian blur, blur guidance enhances the suitability of\nintermediate samples for fine-scale information and generates higher quality\nsamples with a moderate guidance scale. Improving upon this, SAG utilizes\nintermediate self-attention maps to enhance the stability and efficacy.\nSpecifically, SAG leverages intermediate attention maps of diffusion models at\neach iteration to capture essential information for the generative process and\nguide it accordingly. Our experimental results demonstrate that our zero-shot\nmethod enhances the performance of various diffusion models, including ADM,\nIDDPM, and Stable Diffusion. Furthermore, combining SAG with conventional\nguidance methods, such as classifier-free guidance, results in further\nimprovement.\n","authors":["Susung Hong","Gyuseong Lee","Wooseok Jang","Seungryong Kim"],"pdf_url":"https://arxiv.org/pdf/2210.00939v4.pdf","comment":"Project page: https://ku-cvlab.github.io/Self-Attention-Guidance"},{"id":"http://arxiv.org/abs/2302.14358v1","updated":"2023-02-28T07:22:30Z","published":"2023-02-28T07:22:30Z","title":"A Unified Representation Framework for Rideshare Marketplace Equilibrium\n  and Efficiency","summary":"  Ridesharing platforms are a type of two-sided marketplace where\n``supply-demand balance'' is critical for market efficiency and yet is complex\nto define and analyze. We present a unified analytical framework based on the\ngraph-based equilibrium metric (GEM) for quantifying the supply-demand\nspatiotemporal state and efficiency of a ridesharing marketplace. GEM was\ndeveloped as a generalized Wasserstein distance between the supply and demand\ndistributions in a ridesharing market and has been used as an evaluation metric\nfor algorithms expected to improve supply-demand alignment. Building upon GEM,\nwe develop SD-GEM, a dual-perspective (supply- and demand-side) representation\nof rideshare market equilibrium. We show that there are often disparities\nbetween the two views and examine how this dual-view leads to the notion of\nmarket efficiency, in which we propose novel statistical tests for capturing\nimprovement and explaining the underlying driving factors.\n","authors":["Alex Chin","Zhiwei Qin"],"pdf_url":"https://arxiv.org/pdf/2302.14358v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14357v1","updated":"2023-02-28T07:20:49Z","published":"2023-02-28T07:20:49Z","title":"A Token-Wise Beam Search Algorithm for RNN-T","summary":"  Standard Recurrent Neural Network Transducers (RNN-T) decoding algorithms for\nspeech recognition are iterating over the time axis, such that one time step is\ndecoded before moving on to the next time step. Those algorithms result in a\nlarge number of calls to the joint network, that were shown in previous work to\nbe an important factor that reduces decoding speed. We present a decoding beam\nsearch algorithm that batches the joint network calls across a segment of time\nsteps, which results in 40%-70% decoding speedups, consistently across all\nmodels and settings experimented with. In addition, aggregating emission\nprobabilities over a segment may be seen as a better approximation to finding\nthe most likely model output, causing our algorithm to improve oracle word\nerror rate by up to 10% relative as the segment size increases, and to slightly\nimprove general word error rate.\n","authors":["Gil Keren"],"pdf_url":"https://arxiv.org/pdf/2302.14357v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14353v1","updated":"2023-02-28T07:11:55Z","published":"2023-02-28T07:11:55Z","title":"A semantic backdoor attack against Graph Convolutional Networks","summary":"  Graph Convolutional Networks (GCNs) have been very effective in addressing\nthe issue of various graph-structured related tasks, such as node\nclassification and graph classification. However, extensive research has shown\nthat GCNs are vulnerable to adversarial attacks. One of the security threats\nfacing GCNs is the backdoor attack, which hides incorrect classification rules\nin models and activates only when the model encounters specific inputs\ncontaining special features (e.g., fixed patterns like subgraphs, called\ntriggers), thus outputting incorrect classification results, while the model\nbehaves normally on benign samples. The semantic backdoor attack is a type of\nthe backdoor attack where the trigger is a semantic part of the sample; i.e.,\nthe trigger exists naturally in the original dataset and the attacker can pick\na naturally occurring feature as the backdoor trigger, which causes the model\nto misclassify even unmodified inputs. Meanwhile, it is difficult to detect\neven if the attacker modifies the input samples in the inference phase as they\ndo not have any anomaly compared to normal samples. Thus, semantic backdoor\nattacks are more imperceptible than non-semantic ones. However, existed\nresearch on semantic backdoor attacks has only focused on image and text\ndomains, which have not been well explored against GCNs. In this work, we\npropose a black-box Semantic Backdoor Attack (SBA) against GCNs. We assign the\ntrigger as a certain class of nodes in the dataset and our trigger is semantic.\nThrough evaluation on several real-world benchmark graph datasets, the\nexperimental results demonstrate that our proposed SBA can achieve almost 100%\nattack success rate under the poisoning rate less than 5% while having no\nimpact on normal predictive accuracy.\n","authors":["Jiazhu Dai","Zhipeng Xiong"],"pdf_url":"https://arxiv.org/pdf/2302.14353v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.02710v2","updated":"2023-02-28T06:50:59Z","published":"2022-02-06T05:25:22Z","title":"Spectrally Adapted Physics-Informed Neural Networks for Solving\n  Unbounded Domain Problems","summary":"  Solving analytically intractable partial differential equations (PDEs) that\ninvolve at least one variable defined on an unbounded domain arises in numerous\nphysical applications. Accurately solving unbounded domain PDEs requires\nefficient numerical methods that can resolve the dependence of the PDE on the\nunbounded variable over at least several orders of magnitude. We propose a\nsolution to such problems by combining two classes of numerical methods: (i)\nadaptive spectral methods and (ii) physics-informed neural networks (PINNs).\nThe numerical approach that we develop takes advantage of the ability of\nphysics-informed neural networks to easily implement high-order numerical\nschemes to efficiently solve PDEs and extrapolate numerical solutions at any\npoint in space and time. We then show how recently introduced adaptive\ntechniques for spectral methods can be integrated into PINN-based PDE solvers\nto obtain numerical solutions of unbounded domain problems that cannot be\nefficiently approximated by standard PINNs. Through a number of examples, we\ndemonstrate the advantages of the proposed spectrally adapted PINNs in solving\nPDEs and estimating model parameters from noisy observations in unbounded\ndomains.\n","authors":["Mingtao Xia","Lucas Böttcher","Tom Chou"],"pdf_url":"https://arxiv.org/pdf/2202.02710v2.pdf","comment":"29 pages, 8 figures"},{"id":"http://arxiv.org/abs/2206.09670v2","updated":"2023-02-28T06:45:07Z","published":"2022-06-20T09:22:20Z","title":"Benchmarking Constraint Inference in Inverse Reinforcement Learning","summary":"  When deploying Reinforcement Learning (RL) agents into a physical system, we\nmust ensure that these agents are well aware of the underlying constraints. In\nmany real-world problems, however, the constraints are often hard to specify\nmathematically and unknown to the RL agents. To tackle these issues, Inverse\nConstrained Reinforcement Learning (ICRL) empirically estimates constraints\nfrom expert demonstrations. As an emerging research topic, ICRL does not have\ncommon benchmarks, and previous works tested algorithms under hand-crafted\nenvironments with manually-generated expert demonstrations. In this paper, we\nconstruct an ICRL benchmark in the context of RL application domains, including\nrobot control, and autonomous driving. For each environment, we design relevant\nconstraints and train expert agents to generate demonstration data. Besides,\nunlike existing baselines that learn a deterministic constraint, we propose a\nvariational ICRL method to model a posterior distribution of candidate\nconstraints. We conduct extensive experiments on these algorithms under our\nbenchmark and show how they can facilitate studying important research\nchallenges for ICRL. The benchmark, including the instructions for reproducing\nICRL algorithms, is available at\nhttps://github.com/Guiliang/ICRL-benchmarks-public.\n","authors":["Guiliang Liu","Yudong Luo","Ashish Gaurav","Kasra Rezaee","Pascal Poupart"],"pdf_url":"https://arxiv.org/pdf/2206.09670v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14346v1","updated":"2023-02-28T06:38:05Z","published":"2023-02-28T06:38:05Z","title":"Sampled Transformer for Point Sets","summary":"  The sparse transformer can reduce the computational complexity of the\nself-attention layers to $O(n)$, whilst still being a universal approximator of\ncontinuous sequence-to-sequence functions. However, this permutation variant\noperation is not appropriate for direct application to sets. In this paper, we\nproposed an $O(n)$ complexity sampled transformer that can process point set\nelements directly without any additional inductive bias. Our sampled\ntransformer introduces random element sampling, which randomly splits point\nsets into subsets, followed by applying a shared Hamiltonian self-attention\nmechanism to each subset. The overall attention mechanism can be viewed as a\nHamiltonian cycle in the complete attention graph, and the permutation of point\nset elements is equivalent to randomly sampling Hamiltonian cycles. This\nmechanism implements a Monte Carlo simulation of the $O(n^2)$ dense attention\nconnections. We show that it is a universal approximator for continuous\nset-to-set functions. Experimental results on point-clouds show comparable or\nbetter accuracy with significantly reduced computational complexity compared to\nthe dense transformer or alternative sparse attention schemes.\n","authors":["Shidi Li","Christian Walder","Alexander Soen","Lexing Xie","Miaomiao Liu"],"pdf_url":"https://arxiv.org/pdf/2302.14346v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13939v2","updated":"2023-02-28T06:28:43Z","published":"2023-02-27T16:43:04Z","title":"SpikeGPT: Generative Pre-trained Language Model with Spiking Neural\n  Networks","summary":"  As the size of large language models continue to scale, so does the\ncomputational resources required to run it. Spiking neural networks (SNNs) have\nemerged as an energy-efficient approach to deep learning that leverage sparse\nand event-driven activations to reduce the computational overhead associated\nwith model inference. While they have become competitive with non-spiking\nmodels on many computer vision tasks, SNNs have also proven to be more\nchallenging to train. As a result, their performance lags behind modern deep\nlearning, and we are yet to see the effectiveness of SNNs in language\ngeneration. In this paper, inspired by the RWKV language model, we successfully\nimplement `SpikeGPT', a generative language model with pure binary,\nevent-driven spiking activation units. We train the proposed model on three\nmodel variants: 45M, 125M and 260M parameters. To the best of our knowledge,\nthis is 4x larger than any functional backprop-trained SNN to date. We achieve\nthis by modifying the transformer block to replace multi-head self attention to\nreduce quadratic computational complexity to linear with increasing sequence\nlength. Input tokens are instead streamed in sequentially to our attention\nmechanism (as with typical SNNs). Our preliminary experiments show that\nSpikeGPT remains competitive with non-spiking models on tested benchmarks,\nwhile maintaining 5x less energy consumption when processed on neuromorphic\nhardware that can leverage sparse, event-driven activations. Our code\nimplementation is available at https://github.com/ridgerchu/SpikeGPT.\n","authors":["Rui-Jie Zhu","Qihang Zhao","Jason K. Eshraghian"],"pdf_url":"https://arxiv.org/pdf/2302.13939v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.08270v2","updated":"2023-02-28T06:17:36Z","published":"2022-08-17T13:02:17Z","title":"On the Privacy Effect of Data Enhancement via the Lens of Memorization","summary":"  Machine learning poses severe privacy concerns as it has been shown that the\nlearned models can reveal sensitive information about their training data. Many\nworks have investigated the effect of widely-adopted data augmentation (DA) and\nadversarial training (AT) techniques, termed data enhancement in the paper, on\nthe privacy leakage of machine learning models. Such privacy effects are often\nmeasured by membership inference attacks (MIAs), which aim to identify whether\na particular example belongs to the training set or not. We propose to\ninvestigate privacy from a new perspective called memorization. Through the\nlens of memorization, we find that previously deployed MIAs produce misleading\nresults as they are less likely to identify samples with higher privacy risks\nas members compared to samples with low privacy risks. To solve this problem,\nwe deploy a recent attack that can capture individual samples' memorization\ndegrees for evaluation. Through extensive experiments, we unveil non-trivial\nfindings about the connections between three essential properties of machine\nlearning models, including privacy, generalization gap, and adversarial\nrobustness. We demonstrate that, unlike existing results, the generalization\ngap is shown not highly correlated with privacy leakage. Moreover, stronger\nadversarial robustness does not necessarily imply that the model is more\nsusceptible to privacy attacks.\n","authors":["Xiao Li","Qiongxiu Li","Zhanhao Hu","Xiaolin Hu"],"pdf_url":"https://arxiv.org/pdf/2208.08270v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2001.09887v5","updated":"2023-02-28T06:07:24Z","published":"2020-01-27T16:22:05Z","title":"Estimating heterogeneous treatment effects with right-censored data via\n  causal survival forests","summary":"  Forest-based methods have recently gained in popularity for non-parametric\ntreatment effect estimation. Building on this line of work, we introduce causal\nsurvival forests, which can be used to estimate heterogeneous treatment effects\nin a survival and observational setting where outcomes may be right-censored.\nOur approach relies on orthogonal estimating equations to robustly adjust for\nboth censoring and selection effects under unconfoundedness. In our\nexperiments, we find our approach to perform well relative to a number of\nbaselines.\n","authors":["Yifan Cui","Michael R. Kosorok","Erik Sverdrup","Stefan Wager","Ruoqing Zhu"],"pdf_url":"https://arxiv.org/pdf/2001.09887v5.pdf","comment":"To appear in the Journal of the Royal Statistical Society, Series B"},{"id":"http://arxiv.org/abs/2302.13582v2","updated":"2023-02-28T06:02:56Z","published":"2023-02-27T08:40:45Z","title":"Neural Graph Revealers","summary":"  Sparse graph recovery methods work well where the data follows their\nassumptions but often they are not designed for doing downstream probabilistic\nqueries. This limits their adoption to only identifying connections among the\ninput variables. On the other hand, the Probabilistic Graphical Models (PGMs)\nassume an underlying base graph between variables and learns a distribution\nover them. PGM design choices are carefully made such that the inference \\&\nsampling algorithms are efficient. This brings in certain restrictions and\noften simplifying assumptions. In this work, we propose Neural Graph Revealers\n(NGRs), that are an attempt to efficiently merge the sparse graph recovery\nmethods with PGMs into a single flow. The problem setting consists of an input\ndata X with D features and M samples and the task is to recover a sparse graph\nshowing connection between the features and learn a probability distribution\nover the D at the same time. NGRs view the neural networks as a `glass box' or\nmore specifically as a multitask learning framework. We introduce\n`Graph-constrained path norm' that NGRs leverage to learn a graphical model\nthat captures complex non-linear functional dependencies between the features\nin the form of an undirected sparse graph. Furthermore, NGRs can handle\nmultimodal inputs like images, text, categorical data, embeddings etc. which is\nnot straightforward to incorporate in the existing methods. We show\nexperimental results of doing sparse graph recovery and probabilistic inference\non data from Gaussian graphical models and a multimodal infant mortality\ndataset by Centers for Disease Control and Prevention.\n","authors":["Harsh Shrivastava","Urszula Chajewska"],"pdf_url":"https://arxiv.org/pdf/2302.13582v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10959v2","updated":"2023-02-28T05:58:25Z","published":"2023-02-21T19:35:47Z","title":"Dealing with Collinearity in Large-Scale Linear System Identification\n  Using Gaussian Regression","summary":"  Many problems arising in control require the determination of a mathematical\nmodel of the application. This has often to be performed starting from\ninput-output data, leading to a task known as system identification in the\nengineering literature. One emerging topic in this field is estimation of\nnetworks consisting of several interconnected dynamic systems. We consider the\nlinear setting assuming that system outputs are the result of many correlated\ninputs, hence making system identification severely ill-conditioned. This is a\nscenario often encountered when modeling complex cybernetics systems composed\nby many sub-units with feedback and algebraic loops. We develop a strategy cast\nin a Bayesian regularization framework where any impulse response is seen as\nrealization of a zero-mean Gaussian process. Any covariance is defined by the\nso called stable spline kernel which includes information on smooth exponential\ndecay. We design a novel Markov chain Monte Carlo scheme able to reconstruct\nthe impulse responses posterior by efficiently dealing with collinearity. Our\nscheme relies on a variation of the Gibbs sampling technique: beyond\nconsidering blocks forming a partition of the parameter space, some other\n(overlapping) blocks are also updated on the basis of the level of collinearity\nof the system inputs. Theoretical properties of the algorithm are studied\nobtaining its convergence rate. Numerical experiments are included using\nsystems containing hundreds of impulse responses and highly correlated inputs.\n","authors":["Wenqi Cao","Gianluigi Pillonetto"],"pdf_url":"https://arxiv.org/pdf/2302.10959v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2203.13633"},{"id":"http://arxiv.org/abs/2302.14329v1","updated":"2023-02-28T05:45:05Z","published":"2023-02-28T05:45:05Z","title":"Towards Personalized Preprocessing Pipeline Search","summary":"  Feature preprocessing, which transforms raw input features into numerical\nrepresentations, is a crucial step in automated machine learning (AutoML)\nsystems. However, the existing systems often have a very small search space for\nfeature preprocessing with the same preprocessing pipeline applied to all the\nnumerical features. This may result in sub-optimal performance since different\ndatasets often have various feature characteristics, and features within a\ndataset may also have their own preprocessing preferences. To bridge this gap,\nwe explore personalized preprocessing pipeline search, where the search\nalgorithm is allowed to adopt a different preprocessing pipeline for each\nfeature. This is a challenging task because the search space grows\nexponentially with more features. To tackle this challenge, we propose\nClusterP3S, a novel framework for Personalized Preprocessing Pipeline Search\nvia Clustering. The key idea is to learn feature clusters such that the search\nspace can be significantly reduced by using the same preprocessing pipeline for\nthe features within a cluster. To this end, we propose a hierarchical search\nstrategy to jointly learn the clusters and search for the optimal pipelines,\nwhere the upper-level search optimizes the feature clustering to enable better\npipelines built upon the clusters, and the lower-level search optimizes the\npipeline given a specific cluster assignment. We instantiate this idea with a\ndeep clustering network that is trained with reinforcement learning at the\nupper level, and random search at the lower level. Experiments on benchmark\nclassification datasets demonstrate the effectiveness of enabling feature-wise\npreprocessing pipeline search.\n","authors":["Diego Martinez","Daochen Zha","Qiaoyu Tan","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2302.14329v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14320v1","updated":"2023-02-28T05:22:54Z","published":"2023-02-28T05:22:54Z","title":"Towards Addressing GAN Training Instabilities: Dual-objective GANs with\n  Tunable Parameters","summary":"  In an effort to address the training instabilities of GANs, we introduce a\nclass of dual-objective GANs with different value functions (objectives) for\nthe generator (G) and discriminator (D). In particular, we model each objective\nusing $\\alpha$-loss, a tunable classification loss, to obtain\n$(\\alpha_D,\\alpha_G)$-GANs, parameterized by $(\\alpha_D,\\alpha_G)\\in\n[0,\\infty)^2$. For sufficiently large number of samples and capacities for G\nand D, we show that the resulting non-zero sum game simplifies to minimizing an\n$f$-divergence under appropriate conditions on $(\\alpha_D,\\alpha_G)$. In the\nfinite sample and capacity setting, we define estimation error to quantify the\ngap in the generator's performance relative to the optimal setting with\ninfinite samples and obtain upper bounds on this error, showing it to be order\noptimal under certain conditions. Finally, we highlight the value of tuning\n$(\\alpha_D,\\alpha_G)$ in alleviating training instabilities for the synthetic\n2D Gaussian mixture ring and the Stacked MNIST datasets.\n","authors":["Monica Welfert","Kyle Otstot","Gowtham R. Kurri","Lalitha Sankar"],"pdf_url":"https://arxiv.org/pdf/2302.14320v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.08772v2","updated":"2023-02-28T05:22:09Z","published":"2022-09-19T05:54:26Z","title":"TANDEM3D: Active Tactile Exploration for 3D Object Recognition","summary":"  Tactile recognition of 3D objects remains a challenging task. Compared to 2D\nshapes, the complex geometry of 3D surfaces requires richer tactile signals,\nmore dexterous actions, and more advanced encoding techniques. In this work, we\npropose TANDEM3D, a method that applies a co-training framework for exploration\nand decision making to 3D object recognition with tactile signals. Starting\nwith our previous work, which introduced a co-training paradigm for 2D\nrecognition problems, we introduce a number of advances that enable us to scale\nup to 3D. TANDEM3D is based on a novel encoder that builds 3D object\nrepresentation from contact positions and normals using PointNet++.\nFurthermore, by enabling 6DOF movement, TANDEM3D explores and collects\ndiscriminative touch information with high efficiency. Our method is trained\nentirely in simulation and validated with real-world experiments. Compared to\nstate-of-the-art baselines, TANDEM3D achieves higher accuracy and a lower\nnumber of actions in recognizing 3D objects and is also shown to be more robust\nto different types and amounts of sensor noise. Video is available at\nhttps://jxu.ai/tandem3d.\n","authors":["Jingxi Xu","Han Lin","Shuran Song","Matei Ciocarlie"],"pdf_url":"https://arxiv.org/pdf/2209.08772v2.pdf","comment":"7 pages. Accepted to International Conference on Robotics and\n  Automation (ICRA) 2023"},{"id":"http://arxiv.org/abs/2302.14311v1","updated":"2023-02-28T05:01:01Z","published":"2023-02-28T05:01:01Z","title":"Towards Memory- and Time-Efficient Backpropagation for Training Spiking\n  Neural Networks","summary":"  Spiking Neural Networks (SNNs) are promising energy-efficient models for\nneuromorphic computing. For training the non-differentiable SNN models, the\nbackpropagation through time (BPTT) with surrogate gradients (SG) method has\nachieved high performance. However, this method suffers from considerable\nmemory cost and training time during training. In this paper, we propose the\nSpatial Learning Through Time (SLTT) method that can achieve high performance\nwhile greatly improving training efficiency compared with BPTT. First, we show\nthat the backpropagation of SNNs through the temporal domain contributes just a\nlittle to the final calculated gradients. Thus, we propose to ignore the\nunimportant routes in the computational graph during backpropagation. The\nproposed method reduces the number of scalar multiplications and achieves a\nsmall memory occupation that is independent of the total time steps.\nFurthermore, we propose a variant of SLTT, called SLTT-K, that allows\nbackpropagation only at K time steps, then the required number of scalar\nmultiplications is further reduced and is independent of the total time steps.\nExperiments on both static and neuromorphic datasets demonstrate superior\ntraining efficiency and performance of our SLTT. In particular, our method\nachieves state-of-the-art accuracy on ImageNet, while the memory cost and\ntraining time are reduced by more than 70% and 50%, respectively, compared with\nBPTT.\n","authors":["Qingyan Meng","Mingqing Xiao","Shen Yan","Yisen Wang","Zhouchen Lin","Zhi-Quan Luo"],"pdf_url":"https://arxiv.org/pdf/2302.14311v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14307v1","updated":"2023-02-28T04:45:31Z","published":"2023-02-28T04:45:31Z","title":"GradMA: A Gradient-Memory-based Accelerated Federated Learning with\n  Alleviated Catastrophic Forgetting","summary":"  Federated Learning (FL) has emerged as a de facto machine learning area and\nreceived rapid increasing research interests from the community. However,\ncatastrophic forgetting caused by data heterogeneity and partial participation\nposes distinctive challenges for FL, which are detrimental to the performance.\nTo tackle the problems, we propose a new FL approach (namely GradMA), which\ntakes inspiration from continual learning to simultaneously correct the\nserver-side and worker-side update directions as well as take full advantage of\nserver's rich computing and memory resources. Furthermore, we elaborate a\nmemory reduction strategy to enable GradMA to accommodate FL with a large scale\nof workers. We then analyze convergence of GradMA theoretically under the\nsmooth non-convex setting and show that its convergence rate achieves a linear\nspeed up w.r.t the increasing number of sampled active workers. At last, our\nextensive experiments on various image classification tasks show that GradMA\nachieves significant performance gains in accuracy and communication efficiency\ncompared to SOTA baselines.\n","authors":["Kangyang Luo","Xiang Li","Yunshi Lan","Ming Gao"],"pdf_url":"https://arxiv.org/pdf/2302.14307v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14306v1","updated":"2023-02-28T04:38:52Z","published":"2023-02-28T04:38:52Z","title":"CLR-GAM: Contrastive Point Cloud Learning with Guided Augmentation and\n  Feature Mapping","summary":"  Point cloud data plays an essential role in robotics and self-driving\napplications. Yet, annotating point cloud data is time-consuming and nontrivial\nwhile they enable learning discriminative 3D representations that empower\ndownstream tasks, such as classification and segmentation. Recently,\ncontrastive learning-based frameworks have shown promising results for learning\n3D representations in a self-supervised manner. However, existing contrastive\nlearning methods cannot precisely encode and associate structural features and\nsearch the higher dimensional augmentation space efficiently. In this paper, we\npresent CLR-GAM, a novel contrastive learning-based framework with Guided\nAugmentation (GA) for efficient dynamic exploration strategy and Guided Feature\nMapping (GFM) for similar structural feature association between augmented\npoint clouds. We empirically demonstrate that the proposed approach achieves\nstate-of-the-art performance on both simulated and real-world 3D point cloud\ndatasets for three different downstream tasks, i.e., 3D point cloud\nclassification, few-shot learning, and object part segmentation.\n","authors":["Srikanth Malla","Yi-Ting Chen"],"pdf_url":"https://arxiv.org/pdf/2302.14306v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.14548v2","updated":"2023-02-28T04:19:48Z","published":"2022-09-29T04:36:23Z","title":"Offline Reinforcement Learning via High-Fidelity Generative Behavior\n  Modeling","summary":"  In offline reinforcement learning, weighted regression is a common method to\nensure the learned policy stays close to the behavior policy and to prevent\nselecting out-of-sample actions. In this work, we show that due to the limited\ndistributional expressivity of policy models, previous methods might still\nselect unseen actions during training, which deviates from their initial\nmotivation. To address this problem, we adopt a generative approach by\ndecoupling the learned policy into two parts: an expressive generative behavior\nmodel and an action evaluation model. The key insight is that such decoupling\navoids learning an explicitly parameterized policy model with a closed-form\nexpression. Directly learning the behavior policy allows us to leverage\nexisting advances in generative modeling, such as diffusion-based methods, to\nmodel diverse behaviors. As for action evaluation, we combine our method with\nan in-sample planning technique to further avoid selecting out-of-sample\nactions and increase computational efficiency. Experimental results on D4RL\ndatasets show that our proposed method achieves competitive or superior\nperformance compared with state-of-the-art offline RL methods, especially in\ncomplex tasks such as AntMaze. We also empirically demonstrate that our method\ncan successfully learn from a heterogeneous dataset containing multiple\ndistinctive but similarly successful strategies, whereas previous unimodal\npolicies fail.\n","authors":["Huayu Chen","Cheng Lu","Chengyang Ying","Hang Su","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2209.14548v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.04797v4","updated":"2023-02-28T04:18:22Z","published":"2022-06-06T21:56:11Z","title":"Memory-efficient model-based deep learning with convergence and\n  robustness guarantees","summary":"  Computational imaging has been revolutionized by compressed sensing\nalgorithms, which offer guaranteed uniqueness, convergence, and stability\nproperties. Model-based deep learning methods that combine imaging physics with\nlearned regularization priors have emerged as more powerful alternatives for\nimage recovery. The main focus of this paper is to introduce a memory efficient\nmodel-based algorithm with similar theoretical guarantees as CS methods. The\nproposed iterative algorithm alternates between a gradient descent involving\nthe score function and a conjugate gradient algorithm to encourage data\nconsistency. The score function is modeled as a monotone convolutional neural\nnetwork. Our analysis shows that the monotone constraint is necessary and\nsufficient to enforce the uniqueness of the fixed point in arbitrary inverse\nproblems. In addition, it also guarantees the convergence to a fixed point,\nwhich is robust to input perturbations. We introduce two implementations of the\nproposed MOL framework, which differ in the way the monotone property is\nimposed. The first approach enforces a strict monotone constraint, while the\nsecond one relies on an approximation. The guarantees are not valid for the\nsecond approach in the strict sense. However, our empirical studies show that\nthe convergence and robustness of both approaches are comparable, while the\nless constrained approximate implementation offers better performance. The\nproposed deep equilibrium formulation is significantly more memory efficient\nthan unrolled methods, which allows us to apply it to 3D or 2D+time problems\nthat current unrolled algorithms cannot handle.\n","authors":["Aniket Pramanik","M. Bridget Zimmerman","Mathews Jacob"],"pdf_url":"https://arxiv.org/pdf/2206.04797v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12366v2","updated":"2023-02-28T04:16:53Z","published":"2023-02-23T23:48:20Z","title":"Less is More: Data Pruning for Faster Adversarial Training","summary":"  Deep neural networks (DNNs) are sensitive to adversarial examples, resulting\nin fragile and unreliable performance in the real world. Although adversarial\ntraining (AT) is currently one of the most effective methodologies to robustify\nDNNs, it is computationally very expensive (e.g., 5-10X costlier than standard\ntraining). To address this challenge, existing approaches focus on single-step\nAT, referred to as Fast AT, reducing the overhead of adversarial example\ngeneration. Unfortunately, these approaches are known to fail against stronger\nadversaries. To make AT computationally efficient without compromising\nrobustness, this paper takes a different view of the efficient AT problem.\nSpecifically, we propose to minimize redundancies at the data level by\nleveraging data pruning. Extensive experiments demonstrate that the data\npruning based AT can achieve similar or superior robust (and clean) accuracy as\nits unpruned counterparts while being significantly faster. For instance,\nproposed strategies accelerate CIFAR-10 training up to 3.44X and CIFAR-100\ntraining to 2.02X. Additionally, the data pruning methods can readily be\nreconciled with existing adversarial acceleration tricks to obtain the striking\nspeed-ups of 5.66X and 5.12X on CIFAR-10, 3.67X and 3.07X on CIFAR-100 with\nTRADES and MART, respectively.\n","authors":["Yize Li","Pu Zhao","Xue Lin","Bhavya Kailkhura","Ryan Goldhahn"],"pdf_url":"https://arxiv.org/pdf/2302.12366v2.pdf","comment":"The AAAI-23 Workshop on Artificial Intelligence Safety (SafeAI 2023)"},{"id":"http://arxiv.org/abs/2302.14299v1","updated":"2023-02-28T04:16:42Z","published":"2023-02-28T04:16:42Z","title":"Gradient-Boosted Based Structured and Unstructured Learning","summary":"  We propose two frameworks to deal with problem settings in which both\nstructured and unstructured data are available. Structured data problems are\nbest solved by traditional machine learning models such as boosting and\ntree-based algorithms, whereas deep learning has been widely applied to\nproblems dealing with images, text, audio, and other unstructured data sources.\nHowever, for the setting in which both structured and unstructured data are\naccessible, it is not obvious what the best modeling approach is to enhance\nperformance on both data sources simultaneously. Our proposed frameworks allow\njoint learning on both kinds of data by integrating the paradigms of boosting\nmodels and deep neural networks. The first framework, the\nboosted-feature-vector deep learning network, learns features from the\nstructured data using gradient boosting and combines them with embeddings from\nunstructured data via a two-branch deep neural network. Secondly, the\ntwo-weak-learner boosting framework extends the boosting paradigm to the\nsetting with two input data sources. We present and compare first- and\nsecond-order methods of this framework. Our experimental results on both public\nand real-world datasets show performance gains achieved by the frameworks over\nselected baselines by magnitudes of 0.1% - 4.7%.\n","authors":["Andrea Treviño Gavito","Diego Klabjan","Jean Utke"],"pdf_url":"https://arxiv.org/pdf/2302.14299v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.14148v2","updated":"2023-02-28T04:16:04Z","published":"2022-09-28T14:58:41Z","title":"Guiding Safe Exploration with Weakest Preconditions","summary":"  In reinforcement learning for safety-critical settings, it is often desirable\nfor the agent to obey safety constraints at all points in time, including\nduring training. We present a novel neurosymbolic approach called SPICE to\nsolve this safe exploration problem. SPICE uses an online shielding layer based\non symbolic weakest preconditions to achieve a more precise safety analysis\nthan existing tools without unduly impacting the training process. We evaluate\nthe approach on a suite of continuous control benchmarks and show that it can\nachieve comparable performance to existing safe learning techniques while\nincurring fewer safety violations. Additionally, we present theoretical results\nshowing that SPICE converges to the optimal safe policy under reasonable\nassumptions.\n","authors":["Greg Anderson","Swarat Chaudhuri","Isil Dillig"],"pdf_url":"https://arxiv.org/pdf/2209.14148v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14290v1","updated":"2023-02-28T03:50:56Z","published":"2023-02-28T03:50:56Z","title":"Learning to Retain while Acquiring: Combating Distribution-Shift in\n  Adversarial Data-Free Knowledge Distillation","summary":"  Data-free Knowledge Distillation (DFKD) has gained popularity recently, with\nthe fundamental idea of carrying out knowledge transfer from a Teacher neural\nnetwork to a Student neural network in the absence of training data. However,\nin the Adversarial DFKD framework, the student network's accuracy, suffers due\nto the non-stationary distribution of the pseudo-samples under multiple\ngenerator updates. To this end, at every generator update, we aim to maintain\nthe student's performance on previously encountered examples while acquiring\nknowledge from samples of the current distribution. Thus, we propose a\nmeta-learning inspired framework by treating the task of Knowledge-Acquisition\n(learning from newly generated samples) and Knowledge-Retention (retaining\nknowledge on previously met samples) as meta-train and meta-test, respectively.\nHence, we dub our method as Learning to Retain while Acquiring. Moreover, we\nidentify an implicit aligning factor between the Knowledge-Retention and\nKnowledge-Acquisition tasks indicating that the proposed student update\nstrategy enforces a common gradient direction for both tasks, alleviating\ninterference between the two objectives. Finally, we support our hypothesis by\nexhibiting extensive evaluation and comparison of our method with prior arts on\nmultiple datasets.\n","authors":["Gaurav Patel","Konda Reddy Mopuri","Qiang Qiu"],"pdf_url":"https://arxiv.org/pdf/2302.14290v1.pdf","comment":"Accepted at CVPR 2023"},{"id":"http://arxiv.org/abs/2303.00135v1","updated":"2023-02-28T23:40:41Z","published":"2023-02-28T23:40:41Z","title":"Deep learning for COVID-19 topic modelling via Twitter: Alpha, Delta and\n  Omicron","summary":"  Topic modelling with innovative deep learning methods has gained interest for\na wide range of applications that includes COVID-19. Topic modelling can\nprovide, psychological, social and cultural insights for understanding human\nbehaviour in extreme events such as the COVID-19 pandemic. In this paper, we\nuse prominent deep learning-based language models for COVID-19 topic modelling\ntaking into account data from emergence (Alpha) to the Omicron variant. We\napply topic modeling to review the public behaviour across the first, second\nand third waves based on Twitter dataset from India. Our results show that the\ntopics extracted for the subsequent waves had certain overlapping themes such\nas covers governance, vaccination, and pandemic management while novel issues\naroused in political, social and economic situation during COVID-19 pandemic.\nWe also found a strong correlation of the major topics qualitatively to news\nmedia prevalent at the respective time period. Hence, our framework has the\npotential to capture major issues arising during different phases of the\nCOVID-19 pandemic which can be extended to other countries and regions.\n","authors":["Janhavi Lande","Arti Pillay","Rohitash Chandra"],"pdf_url":"https://arxiv.org/pdf/2303.00135v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.08639v2","updated":"2023-02-28T23:32:08Z","published":"2023-02-17T01:04:51Z","title":"Improving Transformer-based Networks With Locality For Automatic Speaker\n  Verification","summary":"  Recently, Transformer-based architectures have been explored for speaker\nembedding extraction. Although the Transformer employs the self-attention\nmechanism to efficiently model the global interaction between token embeddings,\nit is inadequate for capturing short-range local context, which is essential\nfor the accurate extraction of speaker information. In this study, we enhance\nthe Transformer with the enhanced locality modeling in two directions. First,\nwe propose the Locality-Enhanced Conformer (LE-Confomer) by introducing\ndepth-wise convolution and channel-wise attention into the Conformer blocks.\nSecond, we present the Speaker Swin Transformer (SST) by adapting the Swin\nTransformer, originally proposed for vision tasks, into speaker embedding\nnetwork. We evaluate the proposed approaches on the VoxCeleb datasets and a\nlarge-scale Microsoft internal multilingual (MS-internal) dataset. The proposed\nmodels achieve 0.75% EER on VoxCeleb 1 test set, outperforming the previously\nproposed Transformer-based models and CNN-based models, such as ResNet34 and\nECAPA-TDNN. When trained on the MS-internal dataset, the proposed models\nachieve promising results with 14.6% relative reduction in EER over the\nRes2Net50 model.\n","authors":["Mufan Sang","Yong Zhao","Gang Liu","John H. L. Hansen","Jian Wu"],"pdf_url":"https://arxiv.org/pdf/2302.08639v2.pdf","comment":"Accepted to ICASSP 2023"}],"Multimedia":[{"id":"http://arxiv.org/abs/2302.14757v1","updated":"2023-02-28T16:59:13Z","published":"2023-02-28T16:59:13Z","title":"Audio Retrieval for Multimodal Design Documents: A New Dataset and\n  Algorithms","summary":"  We consider and propose a new problem of retrieving audio files relevant to\nmultimodal design document inputs comprising both textual elements and visual\nimagery, e.g., birthday/greeting cards. In addition to enhancing user\nexperience, integrating audio that matches the theme/style of these inputs also\nhelps improve the accessibility of these documents (e.g., visually impaired\npeople can listen to the audio instead). While recent work in audio retrieval\nexists, these methods and datasets are targeted explicitly towards natural\nimages. However, our problem considers multimodal design documents (created by\nusers using creative software) substantially different from a naturally clicked\nphotograph. To this end, our first contribution is collecting and curating a\nnew large-scale dataset called Melodic-Design (or MELON), comprising design\ndocuments representing various styles, themes, templates, illustrations, etc.,\npaired with music audio. Given our paired image-text-audio dataset, our next\ncontribution is a novel multimodal cross-attention audio retrieval (MMCAR)\nalgorithm that enables training neural networks to learn a common shared\nfeature space across image, text, and audio dimensions. We use these learned\nfeatures to demonstrate that our method outperforms existing state-of-the-art\nmethods and produce a new reference benchmark for the research community on our\nnew dataset.\n","authors":["Prachi Singh","Srikrishna Karanam","Sumit Shekhar"],"pdf_url":"https://arxiv.org/pdf/2302.14757v1.pdf","comment":"5 pages including references"},{"id":"http://arxiv.org/abs/2302.14728v1","updated":"2023-02-28T16:34:55Z","published":"2023-02-28T16:34:55Z","title":"Global Context-Aware Person Image Generation","summary":"  We propose a data-driven approach for context-aware person image generation.\nSpecifically, we attempt to generate a person image such that the synthesized\ninstance can blend into a complex scene. In our method, the position, scale,\nand appearance of the generated person are semantically conditioned on the\nexisting persons in the scene. The proposed technique is divided into three\nsequential steps. At first, we employ a Pix2PixHD model to infer a coarse\nsemantic mask that represents the new person's spatial location, scale, and\npotential pose. Next, we use a data-centric approach to select the closest\nrepresentation from a precomputed cluster of fine semantic masks. Finally, we\nadopt a multi-scale, attention-guided architecture to transfer the appearance\nattributes from an exemplar image. The proposed strategy enables us to\nsynthesize semantically coherent realistic persons that can blend into an\nexisting scene without altering the global context. We conclude our findings\nwith relevant qualitative and quantitative evaluations.\n","authors":["Prasun Roy","Saumik Bhattacharya","Subhankar Ghosh","Umapada Pal","Michael Blumenstein"],"pdf_url":"https://arxiv.org/pdf/2302.14728v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2302.14472v1","updated":"2023-02-28T10:30:16Z","published":"2023-02-28T10:30:16Z","title":"TV-watching Companion Robot Powered by Open-domain Chatbot \"KACTUS\"","summary":"  Watching TV not only provides news information but also gives an opportunity\nfor different generations to communicate. With the proliferation of\nsmartphones, PC, and the Internet, increase the opportunities for communication\nin front of the television is also likely to diminish. This has led to some\nproblems further from face-to-face such as a lack of self-control and\ninsufficient development of communication skills. This paper proposes a\nTV-watching companion robot with open-domain chat ability. The robot contains\ntwo modes: TV-watching mode and conversation mode. In TV-watching mode, the\nrobot first extracts keywords from the TV program and then generates the\ndisclosure utterances based on the extracted keywords as if enjoying the TV\nprogram. In the conversation mode, the robot generates question utterances with\nkeywords in the same way and then employs a topics-based dialog management\nmethod consisting of multiple dialog engines for rich conversations related to\nthe TV program. We conduct the initial experiments and the result shows that\nall participants from the three groups enjoyed talking with the robot, and the\nquestion about their interests in the robot was rated 6.5/7-levels. This\nindicates that the proposed conversational features of TV-watching Companion\nRobot have the potential to make our daily lives more enjoyable. Under the\nanalysis of the initial experiments, we achieve further experiments with more\nparticipants by dividing them into two groups: a control group without a robot\nand an intervention group with a robot. The results show that people prefer to\ntalk to robots because the robot will bring more enjoyable, relaxed, and\ninteresting.\n","authors":["Donghuo Zeng","Jianming Wu","Gen Hattori","Yasuhiro Takishima"],"pdf_url":"https://arxiv.org/pdf/2302.14472v1.pdf","comment":"15 pages, 3 figures, 11 tables"},{"id":"http://arxiv.org/abs/2302.14465v1","updated":"2023-02-28T10:14:28Z","published":"2023-02-28T10:14:28Z","title":"Video Quality Assessment with Texture Information Fusion for Streaming\n  Applications","summary":"  The rise of video streaming applications has increased the demand for Video\nQuality Assessment (VQA). In 2016, Netflix introduced VMAF, a full reference\nVQA metric that strongly correlates with perceptual quality, but its\ncomputation is time-intensive. This paper proposes a Discrete Cosine Transform\n(DCT)-energy-based VQA with texture information fusion (VQ-TIF ) model for\nvideo streaming applications that predicts VMAF for the reconstructed video\ncompared to the original video. VQ-TIF extracts Structural Similarity (SSIM)\nand spatio-temporal features of the frames from the original and reconstructed\nvideos, fuses them using a Long Short-Term Memory (LSTM)-based model to\nestimate VMAF. Experimental results show that VQ-TIF estimates VMAF with a\nPearson Correlation Coefficient (PCC) of 0.96 and a Mean Absolute Error (MAE)\nof 2.71, on average, compared to the ground truth VMAF scores. Additionally,\nVQ-TIF estimates VMAF at a rate of 9.14 times faster than the state-of-the-art\nVMAF implementation and a 89.44% reduction in the energy consumption, assuming\nan Ultra HD (2160p) display resolution.\n","authors":["Vignesh V Menon","Prajit T Rajendran","Reza Farahani","Klaus Schoeffmann","Christian Timmerer"],"pdf_url":"https://arxiv.org/pdf/2302.14465v1.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2302.14409v1","updated":"2023-02-28T08:44:00Z","published":"2023-02-28T08:44:00Z","title":"An Adaptive Method for Camera Attribution under Complex Radial\n  Distortion Corrections","summary":"  Radial correction distortion, applied by in-camera or out-camera\nsoftware/firmware alters the supporting grid of the image so as to hamper\nPRNU-based camera attribution. Existing solutions to deal with this problem try\nto invert/estimate the correction using radial transformations parameterized\nwith few variables in order to restrain the computational load; however, with\never more prevalent complex distortion corrections their performance is\nunsatisfactory. In this paper we propose an adaptive algorithm that by dividing\nthe image into concentric annuli is able to deal with sophisticated corrections\nlike those applied out-camera by third party software like Adobe Lightroom,\nPhotoshop, Gimp and PT-Lens. We also introduce a statistic called cumulative\npeak of correlation energy (CPCE) that allows for an efficient early stopping\nstrategy. Experiments on a large dataset of in-camera and out-camera radially\ncorrected images show that our solution improves the state of the art in terms\nof both accuracy and computational cost.\n","authors":["Andrea Montibeller","Fernando Pérez-González"],"pdf_url":"https://arxiv.org/pdf/2302.14409v1.pdf","comment":"This paper was submitted to IEEE Transactions on Information\n  Forensics & Security the July 28, 2022"},{"id":"http://arxiv.org/abs/2302.14402v1","updated":"2023-02-28T08:35:50Z","published":"2023-02-28T08:35:50Z","title":"Neural Video Compression with Diverse Contexts","summary":"  For any video codecs, the coding efficiency highly relies on whether the\ncurrent signal to be encoded can find the relevant contexts from the previous\nreconstructed signals. Traditional codec has verified more contexts bring\nsubstantial coding gain, but in a time-consuming manner. However, for the\nemerging neural video codec (NVC), its contexts are still limited, leading to\nlow compression ratio. To boost NVC, this paper proposes increasing the context\ndiversity in both temporal and spatial dimensions. First, we guide the model to\nlearn hierarchical quality patterns across frames, which enriches long-term and\nyet high-quality temporal contexts. Furthermore, to tap the potential of\noptical flow-based coding framework, we introduce a group-based offset\ndiversity where the cross-group interaction is proposed for better context\nmining. In addition, this paper also adopts a quadtree-based partition to\nincrease spatial context diversity when encoding the latent representation in\nparallel. Experiments show that our codec obtains 23.5% bitrate saving over\nprevious SOTA NVC. Better yet, our codec has surpassed the under-developing\nnext generation traditional codec/ECM in both RGB and YUV420 colorspaces, in\nterms of PSNR. The codes are at https://github.com/microsoft/DCVC.\n","authors":["Jiahao Li","Bin Li","Yan Lu"],"pdf_url":"https://arxiv.org/pdf/2302.14402v1.pdf","comment":"Accepted by CVPR 2023. Codes are at https://github.com/microsoft/DCVC"},{"id":"http://arxiv.org/abs/2303.00520v1","updated":"2023-02-28T05:43:25Z","published":"2023-02-28T05:43:25Z","title":"Valid Information Guidance Network for Compressed Video Quality\n  Enhancement","summary":"  In recent years deep learning methods have shown great superiority in\ncompressed video quality enhancement tasks. Existing methods generally take the\nraw video as the ground truth and extract practical information from\nconsecutive frames containing various artifacts. However, they do not fully\nexploit the valid information of compressed and raw videos to guide the quality\nenhancement for compressed videos. In this paper, we propose a unique Valid\nInformation Guidance scheme (VIG) to enhance the quality of compressed videos\nby mining valid information from both compressed videos and raw videos.\nSpecifically, we propose an efficient framework, Compressed Redundancy\nFiltering (CRF) network, to balance speed and enhancement. After removing the\nredundancy by filtering the information, CRF can use the valid information of\nthe compressed video to reconstruct the texture. Furthermore, we propose a\nprogressive Truth Guidance Distillation (TGD) strategy, which does not need to\ndesign additional teacher models and distillation loss functions. By only using\nthe ground truth as input to guide the model to aggregate the correct\nspatio-temporal correspondence across the raw frames, TGD can significantly\nimprove the enhancement effect without increasing the extra training cost.\nExtensive experiments show that our method achieves the state-of-the-art\nperformance of compressed video quality enhancement in terms of accuracy and\nefficiency.\n","authors":["Xuan Sun","Ziyue Zhang","Guannan Chen","Dan Zhu"],"pdf_url":"https://arxiv.org/pdf/2303.00520v1.pdf","comment":null}]},"2023-03-01T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2210.12587v3","updated":"2023-03-01T18:56:01Z","published":"2022-10-23T01:33:16Z","title":"Model ensemble instead of prompt fusion: a sample-specific knowledge\n  transfer method for few-shot prompt tuning","summary":"  Prompt tuning approaches, which learn task-specific soft prompts for a\ndownstream task conditioning on frozen pre-trained models, have attracted\ngrowing interest due to its parameter efficiency. With large language models\nand sufficient training data, prompt tuning performs comparably to full-model\ntuning. However, with limited training samples in few-shot settings, prompt\ntuning fails to match the performance of full-model fine-tuning. In this work,\nwe focus on improving the few-shot performance of prompt tuning by transferring\nknowledge from soft prompts of source tasks. Recognizing the good\ngeneralization capabilities of ensemble methods in low-data regime, we first\nexperiment and show that a simple ensemble of model predictions based on\ndifferent source prompts, outperforms existing multi-prompt knowledge transfer\napproaches such as source prompt fusion in the few-shot setting. Motivated by\nthis observation, we further investigate model ensembles and propose\nSample-specific Ensemble of Source Models (SESoM). SESoM learns to adjust the\ncontribution of each source model for each target sample separately when\nensembling source model outputs. Through this way, SESoM inherits the superior\ngeneralization of model ensemble approaches and simultaneously captures the\nsample-specific competence of each source prompt. We conduct experiments across\na diverse set of eight NLP tasks using models of different scales (T5-{base,\nlarge, XL}) and find that SESoM consistently outperforms the existing models of\nthe same as well as larger parametric scale by a large margin.\n","authors":["Xiangyu Peng","Chen Xing","Prafulla Kumar Choubey","Chien-Sheng Wu","Caiming Xiong"],"pdf_url":"https://arxiv.org/pdf/2210.12587v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00733v1","updated":"2023-03-01T18:47:41Z","published":"2023-03-01T18:47:41Z","title":"SpeechPrompt v2: Prompt Tuning for Speech Classification Tasks","summary":"  Prompt tuning is a technology that tunes a small set of parameters to steer a\npre-trained language model (LM) to directly generate the output for downstream\ntasks. Recently, prompt tuning has demonstrated its storage and computation\nefficiency in both natural language processing (NLP) and speech processing\nfields. These advantages have also revealed prompt tuning as a candidate\napproach to serving pre-trained LM for multiple tasks in a unified manner. For\nspeech processing, SpeechPrompt shows its high parameter efficiency and\ncompetitive performance on a few speech classification tasks. However, whether\nSpeechPrompt is capable of serving a large number of tasks is unanswered. In\nthis work, we propose SpeechPrompt v2, a prompt tuning framework capable of\nperforming a wide variety of speech classification tasks, covering multiple\nlanguages and prosody-related tasks. The experiment result shows that\nSpeechPrompt v2 achieves performance on par with prior works with less than\n0.15M trainable parameters in a unified framework.\n","authors":["Kai-Wei Chang","Yu-Kai Wang","Hua Shen","Iu-thing Kang","Wei-Cheng Tseng","Shang-Wen Li","Hung-yi Lee"],"pdf_url":"https://arxiv.org/pdf/2303.00733v1.pdf","comment":"Project website: https://ga642381.github.io/SpeechPrompt"},{"id":"http://arxiv.org/abs/2303.00722v1","updated":"2023-03-01T18:26:47Z","published":"2023-03-01T18:26:47Z","title":"A Systematic Analysis of Vocabulary and BPE Settings for Optimal\n  Fine-tuning of NMT: A Case Study of In-domain Translation","summary":"  The effectiveness of Neural Machine Translation (NMT) models largely depends\non the vocabulary used at training; small vocabularies can lead to\nout-of-vocabulary problems -- large ones, to memory issues. Subword (SW)\ntokenization has been successfully employed to mitigate these issues. The\nchoice of vocabulary and SW tokenization has a significant impact on both\ntraining and fine-tuning an NMT model. Fine-tuning is a common practice in\noptimizing an MT model with respect to new data. However, new data potentially\nintroduces new words (or tokens), which, if not taken into consideration, may\nlead to suboptimal performance. In addition, the distribution of tokens in the\nnew data can differ from the distribution of the original data. As such, the\noriginal SW tokenization model could be less suitable for the new data. Through\na systematic empirical evaluation, in this work we compare different strategies\nfor SW tokenization and vocabulary generation with the ultimate goal to uncover\nan optimal setting for fine-tuning a domain-specific model. Furthermore, we\ndeveloped several (in-domain) models, the best of which achieves 6 BLEU points\nimprovement over the baseline.\n","authors":["J. Pourmostafa Roshan Sharami","D. Shterionov","P. Spronck"],"pdf_url":"https://arxiv.org/pdf/2303.00722v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.04717v2","updated":"2023-03-01T17:59:06Z","published":"2022-11-09T07:23:15Z","title":"Improving Noisy Student Training on Non-target Domain Data for Automatic\n  Speech Recognition","summary":"  Noisy Student Training (NST) has recently demonstrated extremely strong\nperformance in Automatic Speech Recognition(ASR). In this paper, we propose a\ndata selection strategy named LM Filter to improve the performance of NST on\nnon-target domain data in ASR tasks. Hypotheses with and without a Language\nModel are generated and the CER differences between them are utilized as a\nfilter threshold. Results reveal that significant improvements of 10.4%\ncompared with no data filtering baselines. We can achieve 3.31% CER in\nAISHELL-1 test set, which is best result from our knowledge without any other\nsupervised data. We also perform evaluations on the supervised 1000 hour\nAISHELL-2 dataset and competitive results of 4.73% CER can be achieved.\n","authors":["Yu Chen","Wen Ding","Junjie Lai"],"pdf_url":"https://arxiv.org/pdf/2211.04717v2.pdf","comment":"This paper is accepted by the ICASSP 2023 conference"},{"id":"http://arxiv.org/abs/2302.12813v2","updated":"2023-03-01T17:21:48Z","published":"2023-02-24T18:48:43Z","title":"Check Your Facts and Try Again: Improving Large Language Models with\n  External Knowledge and Automated Feedback","summary":"  Large language models (LLMs), such as ChatGPT, are able to generate\nhuman-like, fluent responses for many downstream tasks, e.g., task-oriented\ndialog and question answering. However, applying LLMs to real-world,\nmission-critical applications remains challenging mainly due to their tendency\nto generate hallucinations and inability to use external knowledge.This paper\nproposes a LLM-Augmenter system, which augments a black-box LLM with a set of\nplug-and-play modules. Our system makes the LLM generate responses grounded in\nconsolidated external knowledge, e.g., stored in task-specific databases. It\nalso iteratively revises LLM prompts to improve model responses using feedback\ngenerated by utility functions, e.g., the factuality score of a LLM-generated\nresponse. The effectiveness of LLM-Augmenter is empirically validated on two\ntypes of mission-critical scenarios, task-oriented dialog and open-domain\nquestion answering. LLM-Augmenter significantly reduces ChatGPT's\nhallucinations without sacrificing the fluency and informativeness of its\nresponses. We make the source code and models publicly available.\n","authors":["Baolin Peng","Michel Galley","Pengcheng He","Hao Cheng","Yujia Xie","Yu Hu","Qiuyuan Huang","Lars Liden","Zhou Yu","Weizhu Chen","Jianfeng Gao"],"pdf_url":"https://arxiv.org/pdf/2302.12813v2.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2303.00628v1","updated":"2023-03-01T16:31:01Z","published":"2023-03-01T16:31:01Z","title":"MuAViC: A Multilingual Audio-Visual Corpus for Robust Speech Recognition\n  and Robust Speech-to-Text Translation","summary":"  We introduce MuAViC, a multilingual audio-visual corpus for robust speech\nrecognition and robust speech-to-text translation providing 1200 hours of\naudio-visual speech in 9 languages. It is fully transcribed and covers 6\nEnglish-to-X translation as well as 6 X-to-English translation directions. To\nthe best of our knowledge, this is the first open benchmark for audio-visual\nspeech-to-text translation and the largest open benchmark for multilingual\naudio-visual speech recognition. Our baseline results show that MuAViC is\neffective for building noise-robust speech recognition and translation models.\nWe make the corpus available at https://github.com/facebookresearch/muavic.\n","authors":["Mohamed Anwar","Bowen Shi","Vedanuj Goswami","Wei-Ning Hsu","Juan Pino","Changhan Wang"],"pdf_url":"https://arxiv.org/pdf/2303.00628v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00595v1","updated":"2023-03-01T15:35:32Z","published":"2023-03-01T15:35:32Z","title":"A Universal Question-Answering Platform for Knowledge Graphs","summary":"  Knowledge from diverse application domains is organized as knowledge graphs\n(KGs) that are stored in RDF engines accessible in the web via SPARQL\nendpoints. Expressing a well-formed SPARQL query requires information about the\ngraph structure and the exact URIs of its components, which is impractical for\nthe average user. Question answering (QA) systems assist by translating natural\nlanguage questions to SPARQL. Existing QA systems are typically based on\napplication-specific human-curated rules, or require prior information,\nexpensive pre-processing and model adaptation for each targeted KG. Therefore,\nthey are hard to generalize to a broad set of applications and KGs.\n  In this paper, we propose KGQAn, a universal QA system that does not need to\nbe tailored to each target KG. Instead of curated rules, KGQAn introduces a\nnovel formalization of question understanding as a text generation problem to\nconvert a question into an intermediate abstract representation via a neural\nsequence-to-sequence model. We also develop a just-in-time linker that maps at\nquery time the abstract representation to a SPARQL query for a specific KG,\nusing only the publicly accessible APIs and the existing indices of the RDF\nstore, without requiring any pre-processing. Our experiments with several real\nKGs demonstrate that KGQAn is easily deployed and outperforms by a large margin\nthe state-of-the-art in terms of quality of answers and processing time,\nespecially for arbitrary KGs, unseen during the training.\n","authors":["Reham Omar","Ishika Dhall","Panos Kalnis","Essam Mansour"],"pdf_url":"https://arxiv.org/pdf/2303.00595v1.pdf","comment":"The paper is accepted to SIGMOD 2023"},{"id":"http://arxiv.org/abs/2301.12711v2","updated":"2023-03-01T14:31:12Z","published":"2023-01-30T07:40:45Z","title":"UzbekTagger: The rule-based POS tagger for Uzbek language","summary":"  This research paper presents a part-of-speech (POS) annotated dataset and\ntagger tool for the low-resource Uzbek language. The dataset includes 12 tags,\nwhich were used to develop a rule-based POS-tagger tool. The corpus text used\nin the annotation process was made sure to be balanced over 20 different fields\nin order to ensure its representativeness. Uzbek being an agglutinative\nlanguage so the most of the words in an Uzbek sentence are formed by adding\nsuffixes. This nature of it makes the POS-tagging task difficult to find the\nstems of words and the right part-of-speech they belong to. The methodology\nproposed in this research is the stemming of the words with an affix/suffix\nstripping approach including database of the stem forms of the words in the\nUzbek language. The tagger tool was tested on the annotated dataset and showed\nhigh accuracy in identifying and tagging parts of speech in Uzbek text. This\nnewly presented dataset and tagger tool can be used for a variety of natural\nlanguage processing tasks such as language modeling, machine translation, and\ntext-to-speech synthesis. The presented dataset is the first of its kind to be\nmade publicly available for Uzbek, and the POS-tagger tool created can also be\nused as a pivot to use as a base for other closely-related Turkic languages.\n","authors":["Maksud Sharipov","Elmurod Kuriyozov","Ollabergan Yuldashev","Ogabek Sobirov"],"pdf_url":"https://arxiv.org/pdf/2301.12711v2.pdf","comment":"Preprint of the accepted paper to The 10th Language & Technology\n  Conference: Human Language Technologies as a Challenge for Computer Science\n  and Linguistics, April 21-23, 2023, Poznan, Poland"},{"id":"http://arxiv.org/abs/2303.00534v1","updated":"2023-03-01T14:21:19Z","published":"2023-03-01T14:21:19Z","title":"RAMM: Retrieval-augmented Biomedical Visual Question Answering with\n  Multi-modal Pre-training","summary":"  Vision-and-language multi-modal pretraining and fine-tuning have shown great\nsuccess in visual question answering (VQA). Compared to general domain VQA, the\nperformance of biomedical VQA suffers from limited data. In this paper, we\npropose a retrieval-augmented pretrain-and-finetune paradigm named RAMM for\nbiomedical VQA to overcome the data limitation issue. Specifically, we collect\na new biomedical dataset named PMCPM which offers patient-based image-text\npairs containing diverse patient situations from PubMed. Then, we pretrain the\nbiomedical multi-modal model to learn visual and textual representation for\nimage-text pairs and align these representations with image-text contrastive\nobjective (ITC). Finally, we propose a retrieval-augmented method to better use\nthe limited data. We propose to retrieve similar image-text pairs based on ITC\nfrom pretraining datasets and introduce a novel retrieval-attention module to\nfuse the representation of the image and the question with the retrieved images\nand texts. Experiments demonstrate that our retrieval-augmented\npretrain-and-finetune paradigm obtains state-of-the-art performance on\nMed-VQA2019, Med-VQA2021, VQARAD, and SLAKE datasets. Further analysis shows\nthat the proposed RAMM and PMCPM can enhance biomedical VQA performance\ncompared with previous resources and methods. We will open-source our dataset,\ncodes, and pretrained model.\n","authors":["Zheng Yuan","Qiao Jin","Chuanqi Tan","Zhengyun Zhao","Hongyi Yuan","Fei Huang","Songfang Huang"],"pdf_url":"https://arxiv.org/pdf/2303.00534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00465v1","updated":"2023-03-01T12:46:00Z","published":"2023-03-01T12:46:00Z","title":"Uzbek text's correspondence with the educational potential of pupils: a\n  case study of the School corpus","summary":"  One of the major challenges of an educational system is choosing appropriate\ncontent considering pupils' age and intellectual potential. In this article the\nexperiment of primary school grades (from 1st to 4th grades) is considered for\nautomatically determining the correspondence of an educational materials\nrecommended for pupils by using the School corpus where it includes the dataset\nof 25 school textbooks confirmed by the Ministry of preschool and school\neducation of the Republic of Uzbekistan. In this case, TF-IDF scores of the\ntexts are determined, they are converted into a vector representation, and the\ngiven educational materials are compared with the corresponding class of the\nSchool corpus using the cosine similarity algorithm. Based on the results of\nthe calculation, it is determined whether the given educational material is\nappropriate or not appropriate for the pupils' educational potential.\n","authors":["Khabibulla Madatov","Sanatbek Matlatipov","Mersaid Aripov"],"pdf_url":"https://arxiv.org/pdf/2303.00465v1.pdf","comment":"Preprint of the paper accepted to The 10th Language & Technology\n  Conference: Human Language Technologies as a Challenge for Computer Science\n  and Linguistics. April 21-23, 2023, Poznan, Poland"},{"id":"http://arxiv.org/abs/2303.00461v1","updated":"2023-03-01T12:39:46Z","published":"2023-03-01T12:39:46Z","title":"Uzbek text summarization based on TF-IDF","summary":"  The volume of information is increasing at an incredible rate with the rapid\ndevelopment of the Internet and electronic information services. Due to time\nconstraints, we don't have the opportunity to read all this information. Even\nthe task of analyzing textual data related to one field requires a lot of work.\nThe text summarization task helps to solve these problems. This article\npresents an experiment on summarization task for Uzbek language, the\nmethodology was based on text abstracting based on TF-IDF algorithm. Using this\ndensity function, semantically important parts of the text are extracted. We\nsummarize the given text by applying the n-gram method to important parts of\nthe whole text. The authors used a specially handcrafted corpus called \"School\ncorpus\" to evaluate the performance of the proposed method. The results show\nthat the proposed approach is effective in extracting summaries from Uzbek\nlanguage text and can potentially be used in various applications such as\ninformation retrieval and natural language processing. Overall, this research\ncontributes to the growing body of work on text summarization in\nunder-resourced languages.\n","authors":["Khabibulla Madatov","Shukurla Bekchanov","Jernej Vičič"],"pdf_url":"https://arxiv.org/pdf/2303.00461v1.pdf","comment":"Preprint of the paper accepted to The 10th Language & Technology\n  Conference: Human Language Technologies as a Challenge for Computer Science\n  and Linguistics. April 21-23, 2023, Poznan, Poland"},{"id":"http://arxiv.org/abs/2303.00456v1","updated":"2023-03-01T12:32:34Z","published":"2023-03-01T12:32:34Z","title":"N-best T5: Robust ASR Error Correction using Multiple Input Hypotheses\n  and Constrained Decoding Space","summary":"  Error correction models form an important part of Automatic Speech\nRecognition (ASR) post-processing to improve the readability and quality of\ntranscriptions. Most prior works use the 1-best ASR hypothesis as input and\ntherefore can only perform correction by leveraging the context within one\nsentence. In this work, we propose a novel N-best T5 model for this task, which\nis fine-tuned from a T5 model and utilizes ASR N-best lists as model input. By\ntransferring knowledge from the pre-trained language model and obtaining richer\ninformation from the ASR decoding space, the proposed approach outperforms a\nstrong Conformer-Transducer baseline. Another issue with standard error\ncorrection is that the generation process is not well-guided. To address this a\nconstrained decoding process, either based on the N-best list or an ASR\nlattice, is used which allows additional information to be propagated.\n","authors":["Rao Ma","Mark J F Gales","Kate Knill","Mengjie Qian"],"pdf_url":"https://arxiv.org/pdf/2303.00456v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.11703v3","updated":"2023-03-01T11:58:21Z","published":"2022-11-21T18:24:34Z","title":"Towards continually learning new languages","summary":"  Multilingual speech recognition with neural networks is often implemented\nwith batch-learning, when all of the languages are available before training.\nAn ability to add new languages after the prior training sessions can be\neconomically beneficial, but the main challenge is catastrophic forgetting. In\nthis work, we combine the qualities of weight factorization and elastic weight\nconsolidation in order to counter catastrophic forgetting and facilitate\nlearning new languages quickly. Such combination allowed us to eliminate\ncatastrophic forgetting while still achieving performance for the new languages\ncomparable with having all languages at once, in experiments of learning from\nan initial 10 languages to achieve 26 languages without catastrophic forgetting\nand a reasonable performance compared to training all languages from scratch.\n","authors":["Ngoc-Quan Pham","Jan Niehues","Alexander Waibel"],"pdf_url":"https://arxiv.org/pdf/2211.11703v3.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2302.14045v2","updated":"2023-03-01T11:04:51Z","published":"2023-02-27T18:55:27Z","title":"Language Is Not All You Need: Aligning Perception with Language Models","summary":"  A big convergence of language, multimodal perception, action, and world\nmodeling is a key step toward artificial general intelligence. In this work, we\nintroduce Kosmos-1, a Multimodal Large Language Model (MLLM) that can perceive\ngeneral modalities, learn in context (i.e., few-shot), and follow instructions\n(i.e., zero-shot). Specifically, we train Kosmos-1 from scratch on web-scale\nmultimodal corpora, including arbitrarily interleaved text and images,\nimage-caption pairs, and text data. We evaluate various settings, including\nzero-shot, few-shot, and multimodal chain-of-thought prompting, on a wide range\nof tasks without any gradient updates or finetuning. Experimental results show\nthat Kosmos-1 achieves impressive performance on (i) language understanding,\ngeneration, and even OCR-free NLP (directly fed with document images), (ii)\nperception-language tasks, including multimodal dialogue, image captioning,\nvisual question answering, and (iii) vision tasks, such as image recognition\nwith descriptions (specifying classification via text instructions). We also\nshow that MLLMs can benefit from cross-modal transfer, i.e., transfer knowledge\nfrom language to multimodal, and from multimodal to language. In addition, we\nintroduce a dataset of Raven IQ test, which diagnoses the nonverbal reasoning\ncapability of MLLMs.\n","authors":["Shaohan Huang","Li Dong","Wenhui Wang","Yaru Hao","Saksham Singhal","Shuming Ma","Tengchao Lv","Lei Cui","Owais Khan Mohammed","Barun Patra","Qiang Liu","Kriti Aggarwal","Zewen Chi","Johan Bjorck","Vishrav Chaudhary","Subhojit Som","Xia Song","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2302.14045v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00408v1","updated":"2023-03-01T10:57:21Z","published":"2023-03-01T10:57:21Z","title":"A Persian Benchmark for Joint Intent Detection and Slot Filling","summary":"  Natural Language Understanding (NLU) is important in today's technology as it\nenables machines to comprehend and process human language, leading to improved\nhuman-computer interactions and advancements in fields such as virtual\nassistants, chatbots, and language-based AI systems. This paper highlights the\nsignificance of advancing the field of NLU for low-resource languages. With\nintent detection and slot filling being crucial tasks in NLU, the widely used\ndatasets ATIS and SNIPS have been utilized in the past. However, these datasets\nonly cater to the English language and do not support other languages. In this\nwork, we aim to address this gap by creating a Persian benchmark for joint\nintent detection and slot filling based on the ATIS dataset. To evaluate the\neffectiveness of our benchmark, we employ state-of-the-art methods for intent\ndetection and slot filling.\n","authors":["Masoud Akbari","Amir Hossein Karimi","Tayyebeh Saeedi","Zeinab Saeidi","Kiana Ghezelbash","Fatemeh Shamsezat","Mohammad Akbari","Ali Mohades"],"pdf_url":"https://arxiv.org/pdf/2303.00408v1.pdf","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2203.00162v3","updated":"2023-03-01T10:01:16Z","published":"2022-02-19T09:56:38Z","title":"Do Transformers know symbolic rules, and would we know if they did?","summary":"  To improve the explainability of leading Transformer networks used in NLP, it\nis important to tease apart genuine symbolic rules from merely associative\ninput-output patterns. However, we identify several inconsistencies in how\n``symbolicity'' has been construed in recent NLP literature. To mitigate this\nproblem, we propose two criteria to be the most relevant, one pertaining to a\nsystem's internal architecture and the other to the dissociation between\nabstract rules and specific input identities. From this perspective, we\ncritically examine prior work on the symbolic capacities of Transformers, and\ndeem the results to be fundamentally inconclusive for reasons inherent in\nexperiment design. We further maintain that there is no simple fix to this\nproblem, since it arises -- to an extent -- in all end-to-end settings.\nNonetheless, we emphasize the need for more robust evaluation of whether\nnon-symbolic explanations exist for success in seemingly symbolic tasks. To\nfacilitate this, we experiment on four sequence modelling tasks on the T5\nTransformer in two experiment settings: zero-shot generalization, and\ngeneralization across class-specific vocabularies flipped between the training\nand test set. We observe that T5's generalization is markedly stronger in\nsequence-to-sequence tasks than in comparable classification tasks. Based on\nthis, we propose a thus far overlooked analysis, where the Transformer itself\ndoes not need to be symbolic to be part of a symbolic architecture as the\nprocessor, operating on the input and output as external memory components.\n","authors":["Tommi Gröndahl","Yujia Guo","N. Asokan"],"pdf_url":"https://arxiv.org/pdf/2203.00162v3.pdf","comment":"15 pages, 1 figure"},{"id":"http://arxiv.org/abs/2301.00591v3","updated":"2023-03-01T09:59:54Z","published":"2023-01-02T10:36:40Z","title":"Analysing Discrete Self Supervised Speech Representation for Spoken\n  Language Modeling","summary":"  This work profoundly analyzes discrete self-supervised speech representations\n(units) through the eyes of Generative Spoken Language Modeling (GSLM).\nFollowing the findings of such an analysis, we propose practical improvements\nto the discrete unit for the GSLM. First, we start comprehending these units by\nanalyzing them in three axes: interpretation, visualization, and resynthesis.\nOur analysis finds a high correlation between the speech units to phonemes and\nphoneme families, while their correlation with speaker or gender is weaker.\nAdditionally, we found redundancies in the extracted units and claim that one\nreason may be the units' context. Following this analysis, we propose a new,\nunsupervised metric to measure unit redundancies. Finally, we use this metric\nto develop new methods that improve the robustness of units' clustering and\nshow significant improvement considering zero-resource speech metrics such as\nABX. Code and analysis tools are available under the following link:\nhttps://github.com/slp-rl/SLM-Discrete-Representations\n","authors":["Amitay Sicherman","Yossi Adi"],"pdf_url":"https://arxiv.org/pdf/2301.00591v3.pdf","comment":"Accepted at ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.00344v1","updated":"2023-03-01T09:11:07Z","published":"2023-03-01T09:11:07Z","title":"Inline Citation Classification using Peripheral Context and\n  Time-evolving Augmentation","summary":"  Citation plays a pivotal role in determining the associations among research\narticles. It portrays essential information in indicative, supportive, or\ncontrastive studies. The task of inline citation classification aids in\nextrapolating these relationships; However, existing studies are still immature\nand demand further scrutiny. Current datasets and methods used for inline\ncitation classification only use citation-marked sentences constraining the\nmodel to turn a blind eye to domain knowledge and neighboring contextual\nsentences. In this paper, we propose a new dataset, named 3Cext, which along\nwith the cited sentences, provides discourse information using the vicinal\nsentences to analyze the contrasting and entailing relationships as well as\ndomain information. We propose PeriCite, a Transformer-based deep neural\nnetwork that fuses peripheral sentences and domain knowledge. Our model\nachieves the state-of-the-art on the 3Cext dataset by +0.09 F1 against the best\nbaseline. We conduct extensive ablations to analyze the efficacy of the\nproposed dataset and model fusion methods.\n","authors":["Priyanshi Gupta","Yash Kumar Atri","Apurva Nagvenkar","Sourish Dasgupta","Tanmoy Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2303.00344v1.pdf","comment":"accepted to PAKDD 2023"},{"id":"http://arxiv.org/abs/2303.00333v1","updated":"2023-03-01T08:53:36Z","published":"2023-03-01T08:53:36Z","title":"Competence-Based Analysis of Language Models","summary":"  Despite the recent success of large pretrained language models (LMs) on a\nvariety of prompting tasks, these models can be alarmingly brittle to small\nchanges in inputs or application contexts. To better understand such behavior\nand motivate the design of more robust LMs, we propose a general experimental\nframework, CALM (Competence-based Analysis of Language Models), where targeted\ncausal interventions are utilized to damage an LM's internal representation of\nvarious linguistic properties in order to evaluate its use of each\nrepresentation in performing a given task. We implement these interventions as\ngradient-based adversarial attacks, which (in contrast to prior causal probing\nmethodologies) are able to target arbitrarily-encoded representations of\nrelational properties, and carry out a case study of this approach to analyze\nhow BERT-like LMs use representations of several relational properties in\nperforming associated relation prompting tasks. We find that, while the\nrepresentations LMs leverage in performing each task are highly entangled, they\nmay be meaningfully interpreted in terms of the tasks where they are most\nutilized; and more broadly, that CALM enables an expanded scope of inquiry in\nLM analysis that may be useful in predicting and explaining weaknesses of\nexisting LMs.\n","authors":["Adam Davies","Jize Jiang","ChengXiang Zhai"],"pdf_url":"https://arxiv.org/pdf/2303.00333v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12840v2","updated":"2023-03-01T08:43:13Z","published":"2023-02-24T18:17:38Z","title":"HULAT at SemEval-2023 Task 10: Data augmentation for pre-trained\n  transformers applied to the detection of sexism in social media","summary":"  This paper describes our participation in SemEval-2023 Task 10, whose goal is\nthe detection of sexism in social media. We explore some of the most popular\ntransformer models such as BERT, DistilBERT, RoBERTa, and XLNet. We also study\ndifferent data augmentation techniques to increase the training dataset. During\nthe development phase, our best results were obtained by using RoBERTa and data\naugmentation for tasks B and C. However, the use of synthetic data does not\nimprove the results for task C. We participated in the three subtasks. Our\napproach still has much room for improvement, especially in the two\nfine-grained classifications. All our code is available in the repository\nhttps://github.com/isegura/hulat_edos.\n","authors":["Isabel Segura-Bedmar"],"pdf_url":"https://arxiv.org/pdf/2302.12840v2.pdf","comment":"The experiments are not reproducible because I did not use a seed for\n  replicability"},{"id":"http://arxiv.org/abs/2303.00311v1","updated":"2023-03-01T08:15:48Z","published":"2023-03-01T08:15:48Z","title":"Modeling Multiple User Interests using Hierarchical Knowledge for\n  Conversational Recommender System","summary":"  A conversational recommender system (CRS) is a practical application for item\nrecommendation through natural language conversation. Such a system estimates\nuser interests for appropriate personalized recommendations. Users sometimes\nhave various interests in different categories or genres, but existing studies\nassume a unique user interest that can be covered by closely related items. In\nthis work, we propose to model such multiple user interests in CRS. We\ninvestigated its effects in experiments using the ReDial dataset and found that\nthe proposed method can recommend a wider variety of items than that of the\nbaseline CR-Walker.\n","authors":["Yuka Okuda","Katsuhito Sudoh","Seitaro Shinagawa","Satoshi Nakamura"],"pdf_url":"https://arxiv.org/pdf/2303.00311v1.pdf","comment":"Accepted as a conference paper at IWSDS 2023"},{"id":"http://arxiv.org/abs/2212.00959v2","updated":"2023-03-01T07:48:46Z","published":"2022-12-02T04:08:09Z","title":"UniKGQA: Unified Retrieval and Reasoning for Solving Multi-hop Question\n  Answering Over Knowledge Graph","summary":"  Multi-hop Question Answering over Knowledge Graph~(KGQA) aims to find the\nanswer entities that are multiple hops away from the topic entities mentioned\nin a natural language question on a large-scale Knowledge Graph (KG). To cope\nwith the vast search space, existing work usually adopts a two-stage approach:\nit first retrieves a relatively small subgraph related to the question and then\nperforms the reasoning on the subgraph to find the answer entities accurately.\nAlthough these two stages are highly related, previous work employs very\ndifferent technical solutions for developing the retrieval and reasoning\nmodels, neglecting their relatedness in task essence. In this paper, we propose\nUniKGQA, a novel approach for multi-hop KGQA task, by unifying retrieval and\nreasoning in both model architecture and parameter learning. For model\narchitecture, UniKGQA consists of a semantic matching module based on a\npre-trained language model~(PLM) for question-relation semantic matching, and a\nmatching information propagation module to propagate the matching information\nalong the directed edges on KGs. For parameter learning, we design a shared\npre-training task based on question-relation matching for both retrieval and\nreasoning models, and then propose retrieval- and reasoning-oriented\nfine-tuning strategies. Compared with previous studies, our approach is more\nunified, tightly relating the retrieval and reasoning stages. Extensive\nexperiments on three benchmark datasets have demonstrated the effectiveness of\nour method on the multi-hop KGQA task. Our codes and data are publicly\navailable at~\\url{https://github.com/RUCAIBox/UniKGQA}.\n","authors":["Jinhao Jiang","Kun Zhou","Wayne Xin Zhao","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2212.00959v2.pdf","comment":"Camera-ready of ICLR 2023"},{"id":"http://arxiv.org/abs/2303.00293v1","updated":"2023-03-01T07:39:01Z","published":"2023-03-01T07:39:01Z","title":"How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language\n  Understanding Tasks","summary":"  The GPT-3.5 models have demonstrated impressive performance in various\nNatural Language Processing (NLP) tasks, showcasing their strong understanding\nand reasoning capabilities. However, their robustness and abilities to handle\nvarious complexities of the open world have yet to be explored, which is\nespecially crucial in assessing the stability of models and is a key aspect of\ntrustworthy AI. In this study, we perform a comprehensive experimental analysis\nof GPT-3.5, exploring its robustness using 21 datasets (about 116K test\nsamples) with 66 text transformations from TextFlint that cover 9 popular\nNatural Language Understanding (NLU) tasks. Our findings indicate that while\nGPT-3.5 outperforms existing fine-tuned models on some tasks, it still\nencounters significant robustness degradation, such as its average performance\ndropping by up to 35.74\\% and 43.59\\% in natural language inference and\nsentiment analysis tasks, respectively. We also show that GPT-3.5 faces some\nspecific robustness challenges, including robustness instability, prompt\nsensitivity, and number sensitivity. These insights are valuable for\nunderstanding its limitations and guiding future research in addressing these\nchallenges to enhance GPT-3.5's overall performance and generalization\nabilities.\n","authors":["Xuanting Chen","Junjie Ye","Can Zu","Nuo Xu","Rui Zheng","Minlong Peng","Jie Zhou","Tao Gui","Qi Zhang","Xuanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2303.00293v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00279v1","updated":"2023-03-01T07:01:29Z","published":"2023-03-01T07:01:29Z","title":"Coarse-to-Fine Covid-19 Segmentation via Vision-Language Alignment","summary":"  Segmentation of COVID-19 lesions can assist physicians in better diagnosis\nand treatment of COVID-19. However, there are few relevant studies due to the\nlack of detailed information and high-quality annotation in the COVID-19\ndataset. To solve the above problem, we propose C2FVL, a Coarse-to-Fine\nsegmentation framework via Vision-Language alignment to merge text information\ncontaining the number of lesions and specific locations of image information.\nThe introduction of text information allows the network to achieve better\nprediction results on challenging datasets. We conduct extensive experiments on\ntwo COVID-19 datasets including chest X-ray and CT, and the results demonstrate\nthat our proposed method outperforms other state-of-the-art segmentation\nmethods.\n","authors":["Dandan Shan","Zihan Li","Wentao Chen","Qingde Li","Jie Tian","Qingqi Hong"],"pdf_url":"https://arxiv.org/pdf/2303.00279v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.00257v1","updated":"2023-03-01T06:28:33Z","published":"2023-03-01T06:28:33Z","title":"Hidden Markov Transformer for Simultaneous Machine Translation","summary":"  Simultaneous machine translation (SiMT) outputs the target sequence while\nreceiving the source sequence, and hence learning when to start translating\neach target token is the core challenge for SiMT task. However, it is\nnon-trivial to learn the optimal moment among many possible moments of starting\ntranslating, as the moments of starting translating always hide inside the\nmodel and can only be supervised with the observed target sequence. In this\npaper, we propose a Hidden Markov Transformer (HMT), which treats the moments\nof starting translating as hidden events and the target sequence as the\ncorresponding observed events, thereby organizing them as a hidden Markov\nmodel. HMT explicitly models multiple moments of starting translating as the\ncandidate hidden events, and then selects one to generate the target token.\nDuring training, by maximizing the marginal likelihood of the target sequence\nover multiple moments of starting translating, HMT learns to start translating\nat the moments that target tokens can be generated more accurately. Experiments\non multiple SiMT benchmarks show that HMT outperforms strong baselines and\nachieves state-of-the-art performance.\n","authors":["Shaolei Zhang","Yang Feng"],"pdf_url":"https://arxiv.org/pdf/2303.00257v1.pdf","comment":"Accepted to ICLR 2023 Spotlight"},{"id":"http://arxiv.org/abs/2303.00242v1","updated":"2023-03-01T05:45:48Z","published":"2023-03-01T05:45:48Z","title":"DIFFQG: Generating Questions to Summarize Factual Changes","summary":"  Identifying the difference between two versions of the same article is useful\nto update knowledge bases and to understand how articles evolve. Paired texts\noccur naturally in diverse situations: reporters write similar news stories and\nmaintainers of authoritative websites must keep their information up to date.\nWe propose representing factual changes between paired documents as\nquestion-answer pairs, where the answer to the same question differs between\ntwo versions. We find that question-answer pairs can flexibly and concisely\ncapture the updated contents. Provided with paired documents, annotators\nidentify questions that are answered by one passage but answered differently or\ncannot be answered by the other. We release DIFFQG which consists of 759 QA\npairs and 1153 examples of paired passages with no factual change. These\nquestions are intended to be both unambiguous and information-seeking and\ninvolve complex edits, pushing beyond the capabilities of current question\ngeneration and factual change detection systems. Our dataset summarizes the\nchanges between two versions of the document as questions and answers, studying\nautomatic update summarization in a novel way.\n","authors":["Jeremy R. Cole","Palak Jain","Julian Martin Eisenschlos","Michael J. Q. Zhang","Eunsol Choi","Bhuwan Dhingra"],"pdf_url":"https://arxiv.org/pdf/2303.00242v1.pdf","comment":"14 pages. Accepted at EACL 2023 (main, long)"},{"id":"http://arxiv.org/abs/2302.10186v3","updated":"2023-03-01T04:42:53Z","published":"2023-02-16T21:45:35Z","title":"E2E Spoken Entity Extraction for Virtual Agents","summary":"  This paper reimagines some aspects of speech processing using speech\nencoders, specifically about extracting entities directly from speech, with no\nintermediate textual representation. In human-computer conversations,\nextracting entities such as names, postal addresses and email addresses from\nspeech is a challenging task. In this paper, we study the impact of fine-tuning\npre-trained speech encoders on extracting spoken entities in human-readable\nform directly from speech without the need for text transcription. We\nillustrate that such a direct approach optimizes the encoder to transcribe only\nthe entity relevant portions of speech, ignoring the superfluous portions such\nas carrier phrases and spellings of entities. In the context of dialogs from an\nenterprise virtual agent, we demonstrate that the 1-step approach outperforms\nthe typical 2-step cascade of first generating lexical transcriptions followed\nby text-based entity extraction for identifying spoken entities.\n","authors":["Karan Singla","Yeon-Jun Kim","Ryan Price","Shahab Jalalvand","Srinivas Bangalore"],"pdf_url":"https://arxiv.org/pdf/2302.10186v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.02875v2","updated":"2023-03-01T03:21:40Z","published":"2022-10-06T12:55:17Z","title":"Binding Language Models in Symbolic Languages","summary":"  Though end-to-end neural approaches have recently been dominating NLP tasks\nin both performance and ease-of-use, they lack interpretability and robustness.\nWe propose Binder, a training-free neural-symbolic framework that maps the task\ninput to a program, which (1) allows binding a unified API of language model\n(LM) functionalities to a programming language (e.g., SQL, Python) to extend\nits grammar coverage and thus tackle more diverse questions, (2) adopts an LM\nas both the program parser and the underlying model called by the API during\nexecution, and (3) requires only a few in-context exemplar annotations.\nSpecifically, we employ GPT-3 Codex as the LM. In the parsing stage, with only\na few in-context exemplars, Codex is able to identify the part of the task\ninput that cannot be answerable by the original programming language, correctly\ngenerate API calls to prompt Codex to solve the unanswerable part, and identify\nwhere to place the API calls while being compatible with the original grammar.\nIn the execution stage, Codex can perform versatile functionalities (e.g.,\ncommonsense QA, information extraction) given proper prompts in the API calls.\nBinder achieves state-of-the-art results on WikiTableQuestions and TabFact\ndatasets, with explicit output programs that benefit human debugging. Note that\nprevious best systems are all finetuned on tens of thousands of task-specific\nsamples, while Binder only uses dozens of annotations as in-context exemplars\nwithout any training. Our code is available at https://github.com/HKUNLP/Binder .\n","authors":["Zhoujun Cheng","Tianbao Xie","Peng Shi","Chengzu Li","Rahul Nadkarni","Yushi Hu","Caiming Xiong","Dragomir Radev","Mari Ostendorf","Luke Zettlemoyer","Noah A. Smith","Tao Yu"],"pdf_url":"https://arxiv.org/pdf/2210.02875v2.pdf","comment":"ICLR 2023 camera ready, 27 pages, 10 figures"},{"id":"http://arxiv.org/abs/2212.10898v2","updated":"2023-03-01T03:20:08Z","published":"2022-12-21T10:15:19Z","title":"Training language models to summarize narratives improves brain\n  alignment","summary":"  Building systems that achieve a deeper understanding of language is one of\nthe central goals of natural language processing (NLP). Towards this goal,\nrecent works have begun to train language models on narrative datasets which\nrequire extracting the most critical information by integrating across long\ncontexts. However, it is still an open question whether these models are\nlearning a deeper understanding of the text, or if the models are simply\nlearning a heuristic to complete the task. This work investigates this further\nby turning to the one language processing system that truly understands complex\nlanguage: the human brain. We show that training language models for deeper\nnarrative understanding results in richer representations that have improved\nalignment to human brain activity. We further find that the improvements in\nbrain alignment are larger for character names than for other discourse\nfeatures, which indicates that these models are learning important narrative\nelements. Taken together, these results suggest that this type of training can\nindeed lead to deeper language understanding. These findings have consequences\nboth for cognitive neuroscience by revealing some of the significant factors\nbehind brain-NLP alignment, and for NLP by highlighting that understanding of\nlong-range context can be improved beyond language modeling.\n","authors":["Khai Loong Aw","Mariya Toneva"],"pdf_url":"https://arxiv.org/pdf/2212.10898v2.pdf","comment":"ICLR 2023 (notable top 25%)"},{"id":"http://arxiv.org/abs/2210.00312v4","updated":"2023-03-01T02:51:12Z","published":"2022-10-01T16:24:15Z","title":"Multimodal Analogical Reasoning over Knowledge Graphs","summary":"  Analogical reasoning is fundamental to human cognition and holds an important\nplace in various fields. However, previous studies mainly focus on single-modal\nanalogical reasoning and ignore taking advantage of structure knowledge.\nNotably, the research in cognitive psychology has demonstrated that information\nfrom multimodal sources always brings more powerful cognitive transfer than\nsingle modality sources. To this end, we introduce the new task of multimodal\nanalogical reasoning over knowledge graphs, which requires multimodal reasoning\nability with the help of background knowledge. Specifically, we construct a\nMultimodal Analogical Reasoning dataSet (MARS) and a multimodal knowledge graph\nMarKG. We evaluate with multimodal knowledge graph embedding and pre-trained\nTransformer baselines, illustrating the potential challenges of the proposed\ntask. We further propose a novel model-agnostic Multimodal analogical reasoning\nframework with Transformer (MarT) motivated by the structure mapping theory,\nwhich can obtain better performance. Code and datasets are available in\nhttps://github.com/zjunlp/MKG_Analogy.\n","authors":["Ningyu Zhang","Lei Li","Xiang Chen","Xiaozhuan Liang","Shumin Deng","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2210.00312v4.pdf","comment":"Accepted by ICLR 2023. The project website is\n  https://zjunlp.github.io/project/MKG_Analogy/introduction.html"},{"id":"http://arxiv.org/abs/2210.01241v3","updated":"2023-03-01T01:31:17Z","published":"2022-10-03T21:38:29Z","title":"Is Reinforcement Learning (Not) for Natural Language Processing:\n  Benchmarks, Baselines, and Building Blocks for Natural Language Policy\n  Optimization","summary":"  We tackle the problem of aligning pre-trained large language models (LMs)\nwith human preferences. If we view text generation as a sequential\ndecision-making problem, reinforcement learning (RL) appears to be a natural\nconceptual framework. However, using RL for LM-based generation faces empirical\nchallenges, including training instability due to the combinatorial action\nspace, as well as a lack of open-source libraries and benchmarks customized for\nLM alignment. Thus, a question rises in the research community: is RL a\npractical paradigm for NLP?\n  To help answer this, we first introduce an open-source modular library,\nRL4LMs (Reinforcement Learning for Language Models), for optimizing language\ngenerators with RL. The library consists of on-policy RL algorithms that can be\nused to train any encoder or encoder-decoder LM in the HuggingFace library\n(Wolf et al. 2020) with an arbitrary reward function. Next, we present the GRUE\n(General Reinforced-language Understanding Evaluation) benchmark, a set of 6\nlanguage generation tasks which are supervised not by target strings, but by\nreward functions which capture automated measures of human preference.GRUE is\nthe first leaderboard-style evaluation of RL algorithms for NLP tasks. Finally,\nwe introduce an easy-to-use, performant RL algorithm, NLPO (Natural Language\nPolicy Optimization)} that learns to effectively reduce the combinatorial\naction space in language generation. We show 1) that RL techniques are\ngenerally better than supervised methods at aligning LMs to human preferences;\nand 2) that NLPO exhibits greater stability and performance than previous\npolicy gradient methods (e.g., PPO (Schulman et al. 2017)), based on both\nautomatic and human evaluations.\n","authors":["Rajkumar Ramamurthy","Prithviraj Ammanabrolu","Kianté Brantley","Jack Hessel","Rafet Sifa","Christian Bauckhage","Hannaneh Hajishirzi","Yejin Choi"],"pdf_url":"https://arxiv.org/pdf/2210.01241v3.pdf","comment":"In Proceedings of ICLR 2023. Code found at\n  https://github.com/allenai/rl4lms and Project website at\n  https://rl4lms.apps.allenai.org/"},{"id":"http://arxiv.org/abs/2208.04202v2","updated":"2023-03-01T00:18:33Z","published":"2022-08-08T15:08:40Z","title":"Analog Bits: Generating Discrete Data using Diffusion Models with\n  Self-Conditioning","summary":"  We present Bit Diffusion: a simple and generic approach for generating\ndiscrete data with continuous state and continuous time diffusion models. The\nmain idea behind our approach is to first represent the discrete data as binary\nbits, and then train a continuous diffusion model to model these bits as real\nnumbers which we call analog bits. To generate samples, the model first\ngenerates the analog bits, which are then thresholded to obtain the bits that\nrepresent the discrete variables. We further propose two simple techniques,\nnamely Self-Conditioning and Asymmetric Time Intervals, which lead to a\nsignificant improvement in sample quality. Despite its simplicity, the proposed\napproach can achieve strong performance in both discrete image generation and\nimage captioning tasks. For discrete image generation, we significantly improve\nprevious state-of-the-art on both CIFAR-10 (which has 3K discrete 8-bit tokens)\nand ImageNet-64x64 (which has 12K discrete 8-bit tokens), outperforming the\nbest autoregressive model in both sample quality (measured by FID) and\nefficiency. For image captioning on MS-COCO dataset, our approach achieves\ncompetitive results compared to autoregressive models.\n","authors":["Ting Chen","Ruixiang Zhang","Geoffrey Hinton"],"pdf_url":"https://arxiv.org/pdf/2208.04202v2.pdf","comment":"ICLR'23"},{"id":"http://arxiv.org/abs/2303.00855v1","updated":"2023-03-01T22:58:50Z","published":"2023-03-01T22:58:50Z","title":"Grounded Decoding: Guiding Text Generation with Grounded Models for\n  Robot Control","summary":"  Recent progress in large language models (LLMs) has demonstrated the ability\nto learn and leverage Internet-scale knowledge through pre-training with\nautoregressive models. Unfortunately, applying such models to settings with\nembodied agents, such as robots, is challenging due to their lack of experience\nwith the physical world, inability to parse non-language observations, and\nignorance of rewards or safety constraints that robots may require. On the\nother hand, language-conditioned robotic policies that learn from interaction\ndata can provide the necessary grounding that allows the agent to be correctly\nsituated in the real world, but such policies are limited by the lack of\nhigh-level semantic understanding due to the limited breadth of the interaction\ndata available for training them. Thus, if we want to make use of the semantic\nknowledge in a language model while still situating it in an embodied setting,\nwe must construct an action sequence that is both likely according to the\nlanguage model and also realizable according to grounded models of the\nenvironment. We frame this as a problem similar to probabilistic filtering:\ndecode a sequence that both has high probability under the language model and\nhigh probability under a set of grounded model objectives. We demonstrate this\nguided decoding strategy is able to solve complex, long-horizon embodiment\ntasks in a robotic setting by leveraging the knowledge of both models. The\nproject's website can be found at grounded-decoding.github.io.\n","authors":["Wenlong Huang","Fei Xia","Dhruv Shah","Danny Driess","Andy Zeng","Yao Lu","Pete Florence","Igor Mordatch","Sergey Levine","Karol Hausman","Brian Ichter"],"pdf_url":"https://arxiv.org/pdf/2303.00855v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00815v1","updated":"2023-03-01T20:33:37Z","published":"2023-03-01T20:33:37Z","title":"Soft Prompt Guided Joint Learning for Cross-Domain Sentiment Analysis","summary":"  Aspect term extraction is a fundamental task in fine-grained sentiment\nanalysis, which aims at detecting customer's opinion targets from reviews on\nproduct or service. The traditional supervised models can achieve promising\nresults with annotated datasets, however, the performance dramatically\ndecreases when they are applied to the task of cross-domain aspect term\nextraction. Existing cross-domain transfer learning methods either directly\ninject linguistic features into Language models, making it difficult to\ntransfer linguistic knowledge to target domain, or rely on the fixed predefined\nprompts, which is time-consuming to construct the prompts over all potential\naspect term spans. To resolve the limitations, we propose a soft prompt-based\njoint learning method for cross domain aspect term extraction in this paper.\nSpecifically, by incorporating external linguistic features, the proposed\nmethod learn domain-invariant representations between source and target domains\nvia multiple objectives, which bridges the gap between domains with varied\ndistributions of aspect terms. Further, the proposed method interpolates a set\nof transferable soft prompts consisted of multiple learnable vectors that are\nbeneficial to detect aspect terms in target domain. Extensive experiments are\nconducted on the benchmark datasets and the experimental results demonstrate\nthe effectiveness of the proposed method for cross-domain aspect terms\nextraction.\n","authors":["Jingli Shi","Weihua Li","Quan Bai","Yi Yang","Jianhua Jiang"],"pdf_url":"https://arxiv.org/pdf/2303.00815v1.pdf","comment":"22 pages"},{"id":"http://arxiv.org/abs/2302.12126v2","updated":"2023-03-01T20:32:01Z","published":"2023-02-23T16:09:42Z","title":"KHAN: Knowledge-Aware Hierarchical Attention Networks for Accurate\n  Political Stance Prediction","summary":"  The political stance prediction for news articles has been widely studied to\nmitigate the echo chamber effect -- people fall into their thoughts and\nreinforce their pre-existing beliefs. The previous works for the political\nstance problem focus on (1) identifying political factors that could reflect\nthe political stance of a news article and (2) capturing those factors\neffectively. Despite their empirical successes, they are not sufficiently\njustified in terms of how effective their identified factors are in the\npolitical stance prediction. Motivated by this, in this work, we conduct a user\nstudy to investigate important factors in political stance prediction, and\nobserve that the context and tone of a news article (implicit) and external\nknowledge for real-world entities appearing in the article (explicit) are\nimportant in determining its political stance. Based on this observation, we\npropose a novel knowledge-aware approach to political stance prediction (KHAN),\nemploying (1) hierarchical attention networks (HAN) to learn the relationships\namong words and sentences in three different levels and (2) knowledge encoding\n(KE) to incorporate external knowledge for real-world entities into the process\nof political stance prediction. Also, to take into account the subtle and\nimportant difference between opposite political stances, we build two\nindependent political knowledge graphs (KG) (i.e., KG-lib and KG-con) by\nourselves and learn to fuse the different political knowledge. Through\nextensive evaluations on three real-world datasets, we demonstrate the\nsuperiority of DASH in terms of (1) accuracy, (2) efficiency, and (3)\neffectiveness.\n","authors":["Yunyong Ko","Seongeun Ryu","Soeun Han","Yeongseung Jeon","Jaehoon Kim","Sohyun Park","Kyungsik Han","Hanghang Tong","Sang-Wook Kim"],"pdf_url":"https://arxiv.org/pdf/2302.12126v2.pdf","comment":"12 pages, 5 figures, 10 tables, the Web Conference 2023 (WWW)"},{"id":"http://arxiv.org/abs/2303.00807v1","updated":"2023-03-01T20:21:23Z","published":"2023-03-01T20:21:23Z","title":"UDAPDR: Unsupervised Domain Adaptation via LLM Prompting and\n  Distillation of Rerankers","summary":"  Many information retrieval tasks require large labeled datasets for\nfine-tuning. However, such datasets are often unavailable, and their utility\nfor real-world applications can diminish quickly due to domain shifts. To\naddress this challenge, we develop and motivate a method for using large\nlanguage models (LLMs) to generate large numbers of synthetic queries cheaply.\nThe method begins by generating a small number of synthetic queries using an\nexpensive LLM. After that, a much less expensive one is used to create large\nnumbers of synthetic queries, which are used to fine-tune a family of reranker\nmodels. These rerankers are then distilled into a single efficient retriever\nfor use in the target domain. We show that this technique boosts zero-shot\naccuracy in long-tail domains, even where only 2K synthetic queries are used\nfor fine-tuning, and that it achieves substantially lower latency than standard\nreranking methods. We make our end-to-end approach, including our synthetic\ndatasets and replication code, publicly available on Github.\n","authors":["Jon Saad-Falcon","Omar Khattab","Keshav Santhanam","Radu Florian","Martin Franz","Salim Roukos","Avirup Sil","Md Arafat Sultan","Christopher Potts"],"pdf_url":"https://arxiv.org/pdf/2303.00807v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12112v2","updated":"2023-03-01T20:18:25Z","published":"2023-01-28T07:05:15Z","title":"On Pre-trained Language Models for Antibody","summary":"  Antibodies are vital proteins offering robust protection for the human body\nfrom pathogens. The development of general protein and antibody-specific\npre-trained language models both facilitate antibody prediction tasks. However,\nthere have been limited studies that comprehensively explore the representation\ncapability of distinct pre-trained language models on different antibody tasks.\nTo investigate the problem, we aim to answer several key questions in this\npaper, such as how pre-trained language models perform in antibody tasks with\ndifferent specificity and how introducing specific biological mechanisms to the\npre-training process can benefit the model. Additionally, we evaluate if the\nlearned antibody pre-trained representations can be applied to real-world\nantibody problems, like drug discovery and immune process understanding.\nPreviously, no benchmark available largely hindered the study to answer these\nquestions. To aid in our investigation, we provide an AnTibody Understanding\nEvaluation (ATUE) benchmark. We comprehensively evaluate the performance of\nprotein pre-trained language models by empirical study along with conclusions\nand new insights. Our ATUE and code are released at\nhttps://github.com/dqwang122/EATLM.\n","authors":["Danqing Wang","Fei Ye","Hao Zhou"],"pdf_url":"https://arxiv.org/pdf/2301.12112v2.pdf","comment":"Accepted in ICLR 2023"},{"id":"http://arxiv.org/abs/2109.11034v3","updated":"2023-03-01T20:15:51Z","published":"2021-09-22T20:49:16Z","title":"Conditional Poisson Stochastic Beam Search","summary":"  Beam search is the default decoding strategy for many sequence generation\ntasks in NLP. The set of approximate K-best items returned by the algorithm is\na useful summary of the distribution for many applications; however, the\ncandidates typically exhibit high overlap and may give a highly biased estimate\nfor expectations under our model. These problems can be addressed by instead\nusing stochastic decoding strategies. In this work, we propose a new method for\nturning beam search into a stochastic process: Conditional Poisson stochastic\nbeam search. Rather than taking the maximizing set at each iteration, we sample\nK candidates without replacement according to the conditional Poisson sampling\ndesign. We view this as a more natural alternative to Kool et. al. 2019's\nstochastic beam search (SBS). Furthermore, we show how samples generated under\nthe CPSBS design can be used to build consistent estimators and sample diverse\nsets from sequence models. In our experiments, we observe CPSBS produces lower\nvariance and more efficient estimators than SBS, even showing improvements in\nhigh entropy settings.\n","authors":["Clara Meister","Afra Amini","Tim Vieira","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2109.11034v3.pdf","comment":"Proceedings of EMNLP 2021"},{"id":"http://arxiv.org/abs/2303.00802v1","updated":"2023-03-01T20:05:19Z","published":"2023-03-01T20:05:19Z","title":"Synthetic Cross-accent Data Augmentation for Automatic Speech\n  Recognition","summary":"  The awareness for biased ASR datasets or models has increased notably in\nrecent years. Even for English, despite a vast amount of available training\ndata, systems perform worse for non-native speakers. In this work, we improve\nan accent-conversion model (ACM) which transforms native US-English speech into\naccented pronunciation. We include phonetic knowledge in the ACM training to\nprovide accurate feedback about how well certain pronunciation patterns were\nrecovered in the synthesized waveform. Furthermore, we investigate the\nfeasibility of learned accent representations instead of static embeddings.\nGenerated data was then used to train two state-of-the-art ASR systems. We\nevaluated our approach on native and non-native English datasets and found that\nsynthetically accented data helped the ASR to better understand speech from\nseen accents. This observation did not translate to unseen accents, and it was\nnot observed for a model that had been pre-trained exclusively with native\nspeech.\n","authors":["Philipp Klumpp","Pooja Chitkara","Leda Sarı","Prashant Serai","Jilong Wu","Irina-Elena Veliche","Rongqing Huang","Qing He"],"pdf_url":"https://arxiv.org/pdf/2303.00802v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.03787v4","updated":"2023-03-01T19:47:33Z","published":"2022-09-08T12:59:14Z","title":"Goodness of Pronunciation Pipelines for OOV Problem","summary":"  In the following report we propose pipelines for Goodness of Pronunciation\n(GoP) computation solving OOV problem at testing time using Vocab/Lexicon\nexpansion techniques. The pipeline uses different components of ASR system to\nquantify accent and automatically evaluate them as scores. We use the\nposteriors of an ASR model trained on native English speech, along with the\nphone level boundaries to obtain phone level pronunciation scores. We used this\nas a baseline pipeline and implemented methods to remove UNK and SPN phonemes\nin the GoP output by building three pipelines. The Online, Offline and Hybrid\npipeline which returns the scores but also can prevent unknown words in the\nfinal output. The Online method is based per utterance, Offline method\npre-incorporates a set of OOV words for a given data set and the Hybrid method\ncombines the above two ideas to expand the lexicon as well work per utterance.\nWe further provide utilities such as the Phoneme to posterior mappings, GoP\nscores of each utterance as a vector, and Word boundaries used in the GoP\npipeline for use in future research.\n","authors":["Ankit Grover"],"pdf_url":"https://arxiv.org/pdf/2209.03787v4.pdf","comment":"47 pages, 24 Figures, 1 Table"},{"id":"http://arxiv.org/abs/2108.00480v2","updated":"2023-03-01T19:47:21Z","published":"2021-08-01T15:43:57Z","title":"Realised Volatility Forecasting: Machine Learning via Financial Word\n  Embedding","summary":"  This study develops FinText, a financial word embedding compiled from 15\nyears of business news archives. The results show that FinText produces\nsubstantially more accurate results than general word embeddings based on the\ngold-standard financial benchmark we introduced. In contrast to well-known\neconometric models, and over the sample period from 27 July 2007 to 27 January\n2022 for 23 NASDAQ stocks, using stock-related news, our simple natural\nlanguage processing model supported by different word embeddings improves\nrealised volatility forecasts on high volatility days. This improvement in\nrealised volatility forecasting performance switches to normal volatility days\nwhen general hot news is used. By utilising SHAP, an Explainable AI method, we\nalso identify and classify key phrases in stock-related and general hot news\nthat moved volatility.\n","authors":["Eghbal Rahimikia","Stefan Zohren","Ser-Huang Poon"],"pdf_url":"https://arxiv.org/pdf/2108.00480v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00786v1","updated":"2023-03-01T19:20:01Z","published":"2023-03-01T19:20:01Z","title":"Building High-accuracy Multilingual ASR with Gated Language Experts and\n  Curriculum Training","summary":"  We propose gated language experts to improve multilingual transformer\ntransducer models without any language identification (LID) input from users\nduring inference. We define gating mechanism and LID loss to let transformer\nencoders learn language-dependent information, construct the multilingual\ntransformer block with gated transformer experts and shared transformer layers\nfor compact models, and apply linear experts on joint network output to better\nregularize speech acoustic and token label joint information. Furthermore, a\ncurriculum training scheme is proposed to let LID guide the gated language\nexperts for better serving their corresponding languages. Evaluated on the\nEnglish and Spanish bilingual task, our methods achieve average 12.5% and 7.3%\nrelative word error reductions over the baseline bilingual model and\nmonolingual models, respectively, obtaining similar results to the upper bound\nmodel trained and inferred with oracle LID. We further explore our method on\ntrilingual, quadrilingual, and pentalingual models, and observe similar\nadvantages as in the bilingual models, which demonstrates the easy extension to\nmore languages.\n","authors":["Eric Sun","Jinyu Li","Yuxuan Hu","Yimeng Zhu","Long Zhou","Jian Xue","Peidong Wang","Linquan Liu","Shujie Liu","Edward Lin","Yifan Gong"],"pdf_url":"https://arxiv.org/pdf/2303.00786v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01261v1","updated":"2023-03-01T17:23:12Z","published":"2023-03-01T17:23:12Z","title":"ParrotTTS: Text-to-Speech synthesis by exploiting self-supervised\n  representations","summary":"  Text-to-speech (TTS) systems are modelled as mel-synthesizers followed by\nspeech-vocoders since the era of statistical TTS that is carried forward into\nneural designs. We propose an alternative approach to TTS modelling referred to\nas ParrotTTS borrowing from self-supervised learning (SSL) methods. ParrotTTS\ntakes a two-step approach by initially training a speech-to-speech model on\nunlabelled data that is abundantly available, followed by a text-to-embedding\nmodel that leverages speech with aligned transcriptions to extend it to TTS.\nParrotTTS achieves competitive mean opinion scores on naturalness compared to\ntraditional TTS models but significantly improves over the latter's data\nefficiency of transcribed pairs and speaker adaptation without transcriptions.\nThis further paves the path to training TTS models on generically trained SSL\nspeech models.\n","authors":["Saiteja Kosgi","Neil Kumar Shah","Vishal Tambrahalli","Neha Sherin","Vineet Gandhi"],"pdf_url":"https://arxiv.org/pdf/2303.01261v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01258v1","updated":"2023-03-01T09:48:39Z","published":"2023-03-01T09:48:39Z","title":"Domain-adapted large language models for classifying nuclear medicine\n  reports","summary":"  With the growing use of transformer-based language models in medicine, it is\nunclear how well these models generalize to nuclear medicine which has\ndomain-specific vocabulary and unique reporting styles. In this study, we\nevaluated the value of domain adaptation in nuclear medicine by adapting\nlanguage models for the purpose of 5-point Deauville score prediction based on\nclinical 18F-fluorodeoxyglucose (FDG) PET/CT reports. We retrospectively\nretrieved 4542 text reports and 1664 images for FDG PET/CT lymphoma exams from\n2008-2018 in our clinical imaging database. Deauville scores were removed from\nthe reports and then the remaining text in the reports was used as the model\ninput. Multiple general-purpose transformer language models were used to\nclassify the reports into Deauville scores 1-5. We then adapted the models to\nthe nuclear medicine domain using masked language modeling and assessed its\nimpact on classification performance. The language models were compared against\nvision models, a multimodal vision language model, and a nuclear medicine\nphysician with seven-fold Monte Carlo cross validation, reported are the mean\nand standard deviations. Domain adaption improved all language models. For\nexample, BERT improved from 61.3% five-class accuracy to 65.7% following domain\nadaptation. The best performing model (domain-adapted RoBERTa) achieved a\nfive-class accuracy of 77.4%, which was better than the physician's performance\n(66%), the best vision model's performance (48.1), and was similar to the\nmultimodal model's performance (77.2). Domain adaptation improved the\nperformance of large language models in interpreting nuclear medicine text\nreports.\n","authors":["Zachary Huemann","Changhee Lee","Junjie Hu","Steve Y. Cho","Tyler Bradshaw"],"pdf_url":"https://arxiv.org/pdf/2303.01258v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01248v1","updated":"2023-03-01T06:16:14Z","published":"2023-03-01T06:16:14Z","title":"Can ChatGPT Assess Human Personalities? A General Evaluation Framework","summary":"  Large Language Models (LLMs) especially ChatGPT have produced impressive\nresults in various areas, but their potential human-like psychology is still\nlargely unexplored. Existing works study the virtual personalities of LLMs but\nrarely explore the possibility of analyzing human personalities via LLMs. This\npaper presents a generic evaluation framework for LLMs to assess human\npersonalities based on Myers Briggs Type Indicator (MBTI) tests. Specifically,\nwe first devise unbiased prompts by randomly permuting options in MBTI\nquestions and adopt the average testing result to encourage more impartial\nanswer generation. Then, we propose to replace the subject in question\nstatements to enable flexible queries and assessments on different subjects\nfrom LLMs. Finally, we re-formulate the question instructions in a manner of\ncorrectness evaluation to facilitate LLMs to generate clearer responses. The\nproposed framework enables LLMs to flexibly assess personalities of different\ngroups of people. We further propose three evaluation metrics to measure the\nconsistency, robustness, and fairness of assessment results from\nstate-of-the-art LLMs including ChatGPT and InstructGPT. Our experiments reveal\nChatGPT's ability to assess human personalities, and the average results\ndemonstrate that it can achieve more consistent and fairer assessments in spite\nof lower robustness against prompt biases compared with InstructGPT.\n","authors":["Haocong Rao","Cyril Leung","Chunyan Miao"],"pdf_url":"https://arxiv.org/pdf/2303.01248v1.pdf","comment":"Our codes are available at https://github.com/Kali-Hac/ChatGPT-MBTI"},{"id":"http://arxiv.org/abs/2303.01234v1","updated":"2023-03-01T06:04:25Z","published":"2023-03-01T06:04:25Z","title":"Frauds Bargain Attack: Generating Adversarial Text Samples via Word\n  Manipulation Process","summary":"  Recent studies on adversarial examples expose vulnerabilities of natural\nlanguage processing (NLP) models. Existing techniques for generating\nadversarial examples are typically driven by deterministic heuristic rules that\nare agnostic to the optimal adversarial examples, a strategy that often results\nin attack failures. To this end, this research proposes Fraud's Bargain Attack\n(FBA) which utilizes a novel randomization mechanism to enlarge the search\nspace and enables high-quality adversarial examples to be generated with high\nprobabilities. FBA applies the Metropolis-Hasting sampler, a member of Markov\nChain Monte Carlo samplers, to enhance the selection of adversarial examples\nfrom all candidates proposed by a customized stochastic process that we call\nthe Word Manipulation Process (WMP). WMP perturbs one word at a time via\ninsertion, removal or substitution in a contextual-aware manner. Extensive\nexperiments demonstrate that FBA outperforms the state-of-the-art methods in\nterms of both attack success rate and imperceptibility.\n","authors":["Mingze Ni","Zhensu Sun","Wei Liu"],"pdf_url":"https://arxiv.org/pdf/2303.01234v1.pdf","comment":"21 pages, 9 tables, 3 figures"},{"id":"http://arxiv.org/abs/2303.01229v1","updated":"2023-03-01T02:30:11Z","published":"2023-03-01T02:30:11Z","title":"Almanac: Knowledge-Grounded Language Models for Clinical Medicine","summary":"  Large-language models have recently demonstrated impressive zero-shot\ncapabilities in a variety of natural language tasks such as summarization,\ndialogue generation, and question-answering. Despite many promising\napplications in clinical medicine (e.g. medical record documentation, treatment\nguideline-lookup), adoption of these models in real-world settings has been\nlargely limited by their tendency to generate factually incorrect and sometimes\neven toxic statements. In this paper we explore the ability of large-language\nmodels to facilitate and streamline medical guidelines and recommendation\nreferencing: by enabling these model to access external point-of-care tools in\nresponse to physician queries, we demonstrate significantly improved factual\ngrounding, helpfulness, and safety in a variety of clinical scenarios.\n","authors":["Cyril Zakka","Akash Chaurasia","Rohan Shad","William Hiesinger"],"pdf_url":"https://arxiv.org/pdf/2303.01229v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2303.00750v1","updated":"2023-03-01T18:59:33Z","published":"2023-03-01T18:59:33Z","title":"StraIT: Non-autoregressive Generation with Stratified Image Transformer","summary":"  We propose Stratified Image Transformer(StraIT), a pure\nnon-autoregressive(NAR) generative model that demonstrates superiority in\nhigh-quality image synthesis over existing autoregressive(AR) and diffusion\nmodels(DMs). In contrast to the under-exploitation of visual characteristics in\nexisting vision tokenizer, we leverage the hierarchical nature of images to\nencode visual tokens into stratified levels with emergent properties. Through\nthe proposed image stratification that obtains an interlinked token pair, we\nalleviate the modeling difficulty and lift the generative power of NAR models.\nOur experiments demonstrate that StraIT significantly improves NAR generation\nand out-performs existing DMs and AR methods while being order-of-magnitude\nfaster, achieving FID scores of 3.96 at 256*256 resolution on ImageNet without\nleveraging any guidance in sampling or auxiliary image classifiers. When\nequipped with classifier-free guidance, our method achieves an FID of 3.36 and\nIS of 259.3. In addition, we illustrate the decoupled modeling process of\nStraIT generation, showing its compelling properties on applications including\ndomain transfer.\n","authors":["Shengju Qian","Huiwen Chang","Yuanzhen Li","Zizhao Zhang","Jiaya Jia","Han Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.00750v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00749v1","updated":"2023-03-01T18:59:30Z","published":"2023-03-01T18:59:30Z","title":"S-NeRF: Neural Radiance Fields for Street Views","summary":"  Neural Radiance Fields (NeRFs) aim to synthesize novel views of objects and\nscenes, given the object-centric camera views with large overlaps. However, we\nconjugate that this paradigm does not fit the nature of the street views that\nare collected by many self-driving cars from the large-scale unbounded scenes.\nAlso, the onboard cameras perceive scenes without much overlapping. Thus,\nexisting NeRFs often produce blurs, 'floaters' and other artifacts on\nstreet-view synthesis. In this paper, we propose a new street-view NeRF\n(S-NeRF) that considers novel view synthesis of both the large-scale background\nscenes and the foreground moving vehicles jointly. Specifically, we improve the\nscene parameterization function and the camera poses for learning better neural\nrepresentations from street views. We also use the the noisy and sparse LiDAR\npoints to boost the training and learn a robust geometry and reprojection based\nconfidence to address the depth outliers. Moreover, we extend our S-NeRF for\nreconstructing moving vehicles that is impracticable for conventional NeRFs.\nThorough experiments on the large-scale driving datasets (e.g., nuScenes and\nWaymo) demonstrate that our method beats the state-of-the-art rivals by\nreducing 7% to 40% of the mean-squared error in the street-view synthesis and a\n45% PSNR gain for the moving vehicles rendering.\n","authors":["Ziyang Xie","Junge Zhang","Wenye Li","Feihu Zhang","Li Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.00749v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.00748v1","updated":"2023-03-01T18:59:29Z","published":"2023-03-01T18:59:29Z","title":"Efficient and Explicit Modelling of Image Hierarchies for Image\n  Restoration","summary":"  The aim of this paper is to propose a mechanism to efficiently and explicitly\nmodel image hierarchies in the global, regional, and local range for image\nrestoration. To achieve that, we start by analyzing two important properties of\nnatural images including cross-scale similarity and anisotropic image features.\nInspired by that, we propose the anchored stripe self-attention which achieves\na good balance between the space and time complexity of self-attention and the\nmodelling capacity beyond the regional range. Then we propose a new network\narchitecture dubbed GRL to explicitly model image hierarchies in the Global,\nRegional, and Local range via anchored stripe self-attention, window\nself-attention, and channel attention enhanced convolution. Finally, the\nproposed network is applied to 7 image restoration types, covering both real\nand synthetic settings. The proposed method sets the new state-of-the-art for\nseveral of those. Code will be available at\nhttps://github.com/ofsoundof/GRL-Image-Restoration.git.\n","authors":["Yawei Li","Yuchen Fan","Xiaoyu Xiang","Denis Demandolx","Rakesh Ranjan","Radu Timofte","Luc Van Gool"],"pdf_url":"https://arxiv.org/pdf/2303.00748v1.pdf","comment":"Accepted by CVPR 2023. 12 pages, 7 figures, 11 tables"},{"id":"http://arxiv.org/abs/2303.00744v1","updated":"2023-03-01T18:56:43Z","published":"2023-03-01T18:56:43Z","title":"READ Avatars: Realistic Emotion-controllable Audio Driven Avatars","summary":"  We present READ Avatars, a 3D-based approach for generating 2D avatars that\nare driven by audio input with direct and granular control over the emotion.\nPrevious methods are unable to achieve realistic animation due to the\nmany-to-many nature of audio to expression mappings. We alleviate this issue by\nintroducing an adversarial loss in the audio-to-expression generation process.\nThis removes the smoothing effect of regression-based models and helps to\nimprove the realism and expressiveness of the generated avatars. We note\nfurthermore, that audio should be directly utilized when generating mouth\ninteriors and that other 3D-based methods do not attempt this. We address this\nwith audio-conditioned neural textures, which are resolution-independent. To\nevaluate the performance of our method, we perform quantitative and qualitative\nexperiments, including a user study. We also propose a new metric for comparing\nhow well an actor's emotion is reconstructed in the generated avatar. Our\nresults show that our approach outperforms state of the art audio-driven avatar\ngeneration methods across several metrics. A demo video can be found at\n\\url{https://youtu.be/QSyMl3vV0pA}\n","authors":["Jack Saunders","Vinay Namboodiri"],"pdf_url":"https://arxiv.org/pdf/2303.00744v1.pdf","comment":"13 Pages, 8 Figures For demo video see https://youtu.be/QSyMl3vV0pA"},{"id":"http://arxiv.org/abs/2303.00725v1","updated":"2023-03-01T18:34:10Z","published":"2023-03-01T18:34:10Z","title":"OSRE: Object-to-Spot Rotation Estimation for Bike Parking Assessment","summary":"  Current deep models provide remarkable object detection in terms of object\nclassification and localization. However, estimating object rotation with\nrespect to other visual objects in the visual context of an input image still\nlacks deep studies due to the unavailability of object datasets with rotation\nannotations.\n  This paper tackles these two challenges to solve the rotation estimation of a\nparked bike with respect to its parking area. First, we leverage the power of\n3D graphics to build a camera-agnostic well-annotated Synthetic Bike Rotation\nDataset (SynthBRSet). Then, we propose an object-to-spot rotation estimator\n(OSRE) by extending the object detection task to further regress the bike\nrotations in two axes. Since our model is purely trained on synthetic data, we\nadopt image smoothing techniques when deploying it on real-world images. The\nproposed OSRE is evaluated on synthetic and real-world data providing promising\nresults. Our data and code are available at\n\\href{https://github.com/saghiralfasly/OSRE-Project}{https://github.com/saghiralfasly/OSRE-Project}.\n","authors":["Saghir Alfasly","Zaid Al-huda","Saifullah Bello","Ahmed Elazab","Jian Lu","Chen Xu"],"pdf_url":"https://arxiv.org/pdf/2303.00725v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13371v2","updated":"2023-03-01T18:32:04Z","published":"2023-01-31T02:31:18Z","title":"Demystifying Disagreement-on-the-Line in High Dimensions","summary":"  Evaluating the performance of machine learning models under distribution\nshift is challenging, especially when we only have unlabeled data from the\nshifted (target) domain, along with labeled data from the original (source)\ndomain. Recent work suggests that the notion of disagreement, the degree to\nwhich two models trained with different randomness differ on the same input, is\na key to tackle this problem. Experimentally, disagreement and prediction error\nhave been shown to be strongly connected, which has been used to estimate model\nperformance. Experiments have led to the discovery of the\ndisagreement-on-the-line phenomenon, whereby the classification error under the\ntarget domain is often a linear function of the classification error under the\nsource domain; and whenever this property holds, disagreement under the source\nand target domain follow the same linear relation. In this work, we develop a\ntheoretical foundation for analyzing disagreement in high-dimensional random\nfeatures regression; and study under what conditions the\ndisagreement-on-the-line phenomenon occurs in our setting. Experiments on\nCIFAR-10-C, Tiny ImageNet-C, and Camelyon17 are consistent with our theory and\nsupport the universality of the theoretical findings.\n","authors":["Donghwan Lee","Behrad Moniri","Xinmeng Huang","Edgar Dobriban","Hamed Hassani"],"pdf_url":"https://arxiv.org/pdf/2301.13371v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00716v1","updated":"2023-03-01T18:20:24Z","published":"2023-03-01T18:20:24Z","title":"Aligning benchmark datasets for table structure recognition","summary":"  Benchmark datasets for table structure recognition (TSR) must be carefully\nprocessed to ensure they are annotated consistently. However, even if a\ndataset's annotations are self-consistent, there may be significant\ninconsistency across datasets, which can harm the performance of models trained\nand evaluated on them. In this work, we show that aligning these\nbenchmarks$\\unicode{x2014}$removing both errors and inconsistency between\nthem$\\unicode{x2014}$improves model performance significantly. We demonstrate\nthis through a data-centric approach where we adopt a single model\narchitecture, the Table Transformer (TATR), that we hold fixed throughout.\nBaseline exact match accuracy for TATR evaluated on the ICDAR-2013 benchmark is\n65% when trained on PubTables-1M, 42% when trained on FinTabNet, and 69%\ncombined. After reducing annotation mistakes and inter-dataset inconsistency,\nperformance of TATR evaluated on ICDAR-2013 increases substantially to 75% when\ntrained on PubTables-1M, 65% when trained on FinTabNet, and 81% combined. We\nshow through ablations over the modification steps that canonicalization of the\ntable annotations has a significantly positive effect on performance, while\nother choices balance necessary trade-offs that arise when deciding a benchmark\ndataset's final composition. Overall we believe our work has significant\nimplications for benchmark design for TSR and potentially other tasks as well.\nAll dataset processing and training code will be released.\n","authors":["Brandon Smock","Rohith Pesala","Robin Abraham"],"pdf_url":"https://arxiv.org/pdf/2303.00716v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00714v1","updated":"2023-03-01T18:19:10Z","published":"2023-03-01T18:19:10Z","title":"A Complementarity-Based Switch-Fuse System for Improved Visual Place\n  Recognition","summary":"  Recently several fusion and switching based approaches have been presented to\nsolve the problem of Visual Place Recognition. In spite of these systems\ndemonstrating significant boost in VPR performance they each have their own set\nof limitations. The multi-process fusion systems usually involve employing\nbrute force and running all available VPR techniques simultaneously while the\nswitching method attempts to negate this practise by only selecting the best\nsuited VPR technique for given query image. But switching does fail at times\nwhen no available suitable technique can be identified. An innovative solution\nwould be an amalgamation of the two otherwise discrete approaches to combine\ntheir competitive advantages while negating their shortcomings. The proposed,\nSwitch-Fuse system, is an interesting way to combine both the robustness of\nswitching VPR techniques based on complementarity and the force of fusing the\ncarefully selected techniques to significantly improve performance. Our system\nholds a structure superior to the basic fusion methods as instead of simply\nfusing all or any random techniques, it is structured to first select the best\npossible VPR techniques for fusion, according to the query image. The system\ncombines two significant processes, switching and fusing VPR techniques, which\ntogether as a hybrid model substantially improve performance on all major VPR\ndata sets illustrated using PR curves.\n","authors":["Maria Waheed","Sania Waheed","Michael Milford","Klaus McDonald-Maier","Shoaib Ehsan"],"pdf_url":"https://arxiv.org/pdf/2303.00714v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2203.00591"},{"id":"http://arxiv.org/abs/2303.00703v1","updated":"2023-03-01T17:57:09Z","published":"2023-03-01T17:57:09Z","title":"Nearest Neighbors Meet Deep Neural Networks for Point Cloud Analysis","summary":"  Performances on standard 3D point cloud benchmarks have plateaued, resulting\nin oversized models and complex network design to make a fractional\nimprovement. We present an alternative to enhance existing deep neural networks\nwithout any redesigning or extra parameters, termed as Spatial-Neighbor Adapter\n(SN-Adapter). Building on any trained 3D network, we utilize its learned\nencoding capability to extract features of the training dataset and summarize\nthem as prototypical spatial knowledge. For a test point cloud, the SN-Adapter\nretrieves k nearest neighbors (k-NN) from the pre-constructed spatial\nprototypes and linearly interpolates the k-NN prediction with that of the\noriginal 3D network. By providing complementary characteristics, the proposed\nSN-Adapter serves as a plug-and-play module to economically improve performance\nin a non-parametric manner. More importantly, our SN-Adapter can be effectively\ngeneralized to various 3D tasks, including shape classification, part\nsegmentation, and 3D object detection, demonstrating its superiority and\nrobustness. We hope our approach could show a new perspective for point cloud\nanalysis and facilitate future research.\n","authors":["Renrui Zhang","Liuhui Wang","Ziyu Guo","Jianbo Shi"],"pdf_url":"https://arxiv.org/pdf/2303.00703v1.pdf","comment":"Accepted by WACV 2023"},{"id":"http://arxiv.org/abs/2303.00693v1","updated":"2023-03-01T17:41:36Z","published":"2023-03-01T17:41:36Z","title":"PE-GAN: Prior Embedding GAN for PXD images at Belle II","summary":"  The pixel vertex detector (PXD) is an essential part of the Belle II detector\nrecording particle positions. Data from the PXD and other sensors allow us to\nreconstruct particle tracks and decay vertices. The effect of background hits\non track reconstruction is simulated by adding measured or simulated background\nhit patterns to the hits produced by simulated signal particles. This model\nrequires a large set of statistically independent PXD background noise samples\nto avoid a systematic bias of reconstructed tracks. However, data from the\nfine-grained PXD requires a substantial amount of storage. As an efficient way\nof producing background noise, we explore the idea of an on-demand PXD\nbackground generator using conditional Generative Adversarial Networks (GANs)\nwith contrastive learning, adapted by the number of PXD sensors in order to\nboth increase the image fidelity and produce sensor-dependent PXD hitmaps.\n","authors":["Hosein Hashemi","Nikolai Hartmann","Thomas Kuhr","Martin Ritter","Matej srebre"],"pdf_url":"https://arxiv.org/pdf/2303.00693v1.pdf","comment":"25th International Conference on Computing in High Energy and Nuclear\n  Physics (CHEP 2021)"},{"id":"http://arxiv.org/abs/2303.00691v1","updated":"2023-03-01T17:39:08Z","published":"2023-03-01T17:39:08Z","title":"On the Importance of Feature Representation for Flood Mapping using\n  Classical Machine Learning Approaches","summary":"  Climate change has increased the severity and frequency of weather disasters\nall around the world. Flood inundation mapping based on earth observation data\ncan help in this context, by providing cheap and accurate maps depicting the\narea affected by a flood event to emergency-relief units in near-real-time.\nBuilding upon the recent development of the Sen1Floods11 dataset, which\nprovides a limited amount of hand-labeled high-quality training data, this\npaper evaluates the potential of five traditional machine learning approaches\nsuch as gradient boosted decision trees, support vector machines or quadratic\ndiscriminant analysis. By performing a grid-search-based hyperparameter\noptimization on 23 feature spaces we can show that all considered classifiers\nare capable of outperforming the current state-of-the-art neural network-based\napproaches in terms of total IoU on their best-performing feature spaces. With\ntotal and mean IoU values of 0.8751 and 0.7031 compared to 0.70 and 0.5873 as\nthe previous best-reported results, we show that a simple gradient boosting\nclassifier can significantly improve over deep neural network based approaches,\ndespite using less training data. Furthermore, an analysis of the regional\ndistribution of the Sen1Floods11 dataset reveals a problem of spatial\nimbalance. We show that traditional machine learning models can learn this bias\nand argue that modified metric evaluations are required to counter artifacts\ndue to spatial imbalance. Lastly, a qualitative analysis shows that this\npixel-wise classifier provides highly-precise surface water classifications\nindicating that a good choice of a feature space and pixel-wise classification\ncan generate high-quality flood maps using optical and SAR data. We make our\ncode publicly available at:\nhttps://github.com/DFKI-Earth-And-Space-Applications/Flood_Mapping_Feature_Space_Importance\n","authors":["Kevin Iselborn","Marco Stricker","Takashi Miyamoto","Marlon Nuske","Andreas Dengel"],"pdf_url":"https://arxiv.org/pdf/2303.00691v1.pdf","comment":"24 pages, 9 figures, submitted to Remote Sensing of Environment and\n  code is available at\n  https://github.com/DFKI-Earth-And-Space-Applications/Flood_Mapping_Feature_Space_Importance"},{"id":"http://arxiv.org/abs/2303.00690v1","updated":"2023-03-01T17:38:03Z","published":"2023-03-01T17:38:03Z","title":"Rethinking Efficient Tuning Methods from a Unified Perspective","summary":"  Parameter-efficient transfer learning (PETL) based on large-scale pre-trained\nfoundation models has achieved great success in various downstream\napplications. Existing tuning methods, such as prompt, prefix, and adapter,\nperform task-specific lightweight adjustments to different parts of the\noriginal architecture. However, they take effect on only some parts of the\npre-trained models, i.e., only the feed-forward layers or the self-attention\nlayers, which leaves the remaining frozen structures unable to adapt to the\ndata distributions of downstream tasks. Further, the existing structures are\nstrongly coupled with the Transformers, hindering parameter-efficient\ndeployment as well as the design flexibility for new approaches. In this paper,\nwe revisit the design paradigm of PETL and derive a unified framework U-Tuning\nfor parameter-efficient transfer learning, which is composed of an operation\nwith frozen parameters and a unified tuner that adapts the operation for\ndownstream applications. The U-Tuning framework can simultaneously encompass\nexisting methods and derive new approaches for parameter-efficient transfer\nlearning, which prove to achieve on-par or better performances on CIFAR-100 and\nFGVC datasets when compared with existing PETL methods.\n","authors":["Zeyinzi Jiang","Chaojie Mao","Ziyuan Huang","Yiliang Lv","Deli Zhao","Jingren Zhou"],"pdf_url":"https://arxiv.org/pdf/2303.00690v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00616v1","updated":"2023-03-01T16:12:47Z","published":"2023-03-01T16:12:47Z","title":"Prediction of SLAM ATE Using an Ensemble Learning Regression Model and\n  1-D Global Pooling of Data Characterization","summary":"  Robustness and resilience of simultaneous localization and mapping (SLAM) are\ncritical requirements for modern autonomous robotic systems. One of the\nessential steps to achieve robustness and resilience is the ability of SLAM to\nhave an integrity measure for its localization estimates, and thus, have\ninternal fault tolerance mechanisms to deal with performance degradation. In\nthis work, we introduce a novel method for predicting SLAM localization error\nbased on the characterization of raw sensor inputs. The proposed method relies\non using a random forest regression model trained on 1-D global pooled features\nthat are generated from characterized raw sensor data. The model is validated\nby using it to predict the performance of ORB-SLAM3 on three different datasets\nrunning on four different operating modes, resulting in an average prediction\naccuracy of up to 94.7\\%. The paper also studies the impact of 12 different 1-D\nglobal pooling functions on regression quality, and the superiority of 1-D\nglobal averaging is quantitatively proven. Finally, the paper studies the\nquality of prediction with limited training data, and proves that we are able\nto maintain proper prediction quality when only 20 \\% of the training examples\nare used for training, which highlights how the proposed model can optimize the\nevaluation footprint of SLAM systems.\n","authors":["Islam Ali"," Bingqing"," Wan","Hong Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.00616v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.06316v2","updated":"2023-03-01T16:10:00Z","published":"2022-09-13T21:47:18Z","title":"Optimizing SLAM Evaluation Footprint Through Dynamic Range Coverage\n  Analysis of Datasets","summary":"  Simultaneous Localization and Mapping (SLAM) is considered an ever-evolving\nproblem due to its usage in many applications. Evaluation of SLAM is done\ntypically using publicly available datasets which are increasing in number and\nthe level of difficulty. Each dataset provides a certain level of dynamic range\ncoverage that is a key aspect of measuring the robustness and resilience of\nSLAM. In this paper, we provide a systematic analysis of the dynamic range\ncoverage of datasets based on a number of characterization metrics, and our\nanalysis shows a huge level of redundancy within and between datasets.\nSubsequently, we propose a dynamic programming (DP) algorithm for eliminating\nthe redundancy in the evaluation process of SLAM by selecting a subset of\nsequences that matches a single or multiple dynamic range coverage objectives.\nIt is shown that, with the help of dataset characterization and DP selection\nalgorithm, a reduction in the evaluation effort can be achieved while\nmaintaining the same level of coverage. We also study how the evaluation\nprocess of a real-world SLAM system can be optimized utilizing the method\nproposed.\n","authors":["Islam Ali","Hong Zhang"],"pdf_url":"https://arxiv.org/pdf/2209.06316v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00612v1","updated":"2023-03-01T16:09:11Z","published":"2023-03-01T16:09:11Z","title":"Has the Virtualization of the Face Changed Facial Perception? A Study of\n  the Impact of Augmented Reality on Facial Perception","summary":"  Augmented reality and other photo editing filters are popular methods used to\nmodify images, especially images of faces, posted online. Considering the\nimportant role of human facial perception in social communication, how does\nexposure to an increasing number of modified faces online affect human facial\nperception? In this paper we present the results of six surveys designed to\nmeasure familiarity with different styles of facial filters, perceived\nstrangeness of faces edited with different facial filters, and ability to\ndiscern whether images are filtered or not. Our results indicate that faces\nfiltered with photo editing filters that change the image color tones, modify\nfacial structure, or add facial beautification tend to be perceived similarly\nto unmodified faces; however, faces filtered with augmented reality filters\n(\\textit{i.e.,} filters that overlay digital objects) are perceived differently\nfrom unmodified faces. We also found that responses differed based on different\nsurvey question phrasings, indicating that the shift in facial perception due\nto the prevalence of filtered images is noisy to detect. A better understanding\nof shifts in facial perception caused by facial filters will help us build\nonline spaces more responsibly and could inform the training of more accurate\nand equitable facial recognition models, especially those trained with human\npsychophysical annotations.\n","authors":["Louisa Conwill","Samuel Anthony","Walter Scheirer"],"pdf_url":"https://arxiv.org/pdf/2303.00612v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00609v1","updated":"2023-03-01T16:03:25Z","published":"2023-03-01T16:03:25Z","title":"Unsupervised Pathology Detection: A Deep Dive Into the State of the Art","summary":"  Deep unsupervised approaches are gathering increased attention for\napplications such as pathology detection and segmentation in medical images\nsince they promise to alleviate the need for large labeled datasets and are\nmore generalizable than their supervised counterparts in detecting any kind of\nrare pathology. As the Unsupervised Anomaly Detection (UAD) literature\ncontinuously grows and new paradigms emerge, it is vital to continuously\nevaluate and benchmark new methods in a common framework, in order to reassess\nthe state-of-the-art (SOTA) and identify promising research directions. To this\nend, we evaluate a diverse selection of cutting-edge UAD methods on multiple\nmedical datasets, comparing them against the established SOTA in UAD for brain\nMRI. Our experiments demonstrate that newly developed feature-modeling methods\nfrom the industrial and medical literature achieve increased performance\ncompared to previous work and set the new SOTA in a variety of modalities and\ndatasets. Additionally, we show that such methods are capable of benefiting\nfrom recently developed self-supervised pre-training algorithms, further\nincreasing their performance. Finally, we perform a series of experiments in\norder to gain further insights into some unique characteristics of selected\nmodels and datasets. Our code can be found under\nhttps://github.com/iolag/UPD_study/.\n","authors":["Ioannis Lagogiannis","Felix Meissen","Georgios Kaissis","Daniel Rueckert"],"pdf_url":"https://arxiv.org/pdf/2303.00609v1.pdf","comment":"12 pages, 4 figures, under review for IEEE Transactions on Medical\n  Imaging"},{"id":"http://arxiv.org/abs/2303.00608v1","updated":"2023-03-01T16:01:46Z","published":"2023-03-01T16:01:46Z","title":"Level Up the Deepfake Detection: a Method to Effectively Discriminate\n  Images Generated by GAN Architectures and Diffusion Models","summary":"  The image deepfake detection task has been greatly addressed by the\nscientific community to discriminate real images from those generated by\nArtificial Intelligence (AI) models: a binary classification task. In this\nwork, the deepfake detection and recognition task was investigated by\ncollecting a dedicated dataset of pristine images and fake ones generated by 9\ndifferent Generative Adversarial Network (GAN) architectures and by 4\nadditional Diffusion Models (DM). A hierarchical multi-level approach was then\nintroduced to solve three different deepfake detection and recognition tasks:\n(i) Real Vs AI generated; (ii) GANs Vs DMs; (iii) AI specific architecture\nrecognition. Experimental results demonstrated, in each case, more than 97%\nclassification accuracy, outperforming state-of-the-art methods.\n","authors":["Luca Guarnera","Oliver Giudice","Sebastiano Battiato"],"pdf_url":"https://arxiv.org/pdf/2303.00608v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00601v1","updated":"2023-03-01T15:48:27Z","published":"2023-03-01T15:48:27Z","title":"Multimodal Industrial Anomaly Detection via Hybrid Fusion","summary":"  2D-based Industrial Anomaly Detection has been widely discussed, however,\nmultimodal industrial anomaly detection based on 3D point clouds and RGB images\nstill has many untouched fields. Existing multimodal industrial anomaly\ndetection methods directly concatenate the multimodal features, which leads to\na strong disturbance between features and harms the detection performance. In\nthis paper, we propose Multi-3D-Memory (M3DM), a novel multimodal anomaly\ndetection method with hybrid fusion scheme: firstly, we design an unsupervised\nfeature fusion with patch-wise contrastive learning to encourage the\ninteraction of different modal features; secondly, we use a decision layer\nfusion with multiple memory banks to avoid loss of information and additional\nnovelty classifiers to make the final decision. We further propose a point\nfeature alignment operation to better align the point cloud and RGB features.\nExtensive experiments show that our multimodal industrial anomaly detection\nmodel outperforms the state-of-the-art (SOTA) methods on both detection and\nsegmentation precision on MVTec-3D AD dataset. Code is available at\nhttps://github.com/nomewang/M3DM.\n","authors":["Yue Wang","Jinlong Peng","Jiangning Zhang","Ran Yi","Yabiao Wang","Chengjie Wang"],"pdf_url":"https://arxiv.org/pdf/2303.00601v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2201.12240v3","updated":"2023-03-01T15:38:54Z","published":"2022-01-28T16:51:54Z","title":"Continuous Deep Equilibrium Models: Training Neural ODEs faster by\n  integrating them to Infinity","summary":"  Implicit models separate the definition of a layer from the description of\nits solution process. While implicit layers allow features such as depth to\nadapt to new scenarios and inputs automatically, this adaptivity makes its\ncomputational expense challenging to predict. In this manuscript, we\n\\textit{increase the ``implicitness\" of the DEQ by redefining the method in\nterms of an infinite time neural ODE}, which paradoxically decreases the\ntraining cost over a standard neural ODE by $\\mathit{2} - \\mathit{4 \\times}$.\nAdditionally, we address the question: \\textit{is there a way to simultaneously\nachieve the robustness of implicit layers while allowing the reduced\ncomputational expense of an explicit layer?} To solve this, we develop Skip and\nSkip Reg. DEQ, an implicit-explicit (IMEX) layer that simultaneously trains an\nexplicit prediction followed by an implicit correction. We show that training\nthis explicit predictor is free and even decreases the training time by\n$\\mathit{1.11} - \\mathit{3.19 \\times}$. Together, this manuscript shows how\nbridging the dichotomy of implicit and explicit deep learning can combine the\nadvantages of both techniques.\n","authors":["Avik Pal","Alan Edelman","Christopher Rackauckas"],"pdf_url":"https://arxiv.org/pdf/2201.12240v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00586v1","updated":"2023-03-01T15:28:26Z","published":"2023-03-01T15:28:26Z","title":"FAIR-Ensemble: When Fairness Naturally Emerges From Deep Ensembling","summary":"  Ensembling independent deep neural networks (DNNs) is a simple and effective\nway to improve top-line metrics and to outperform larger single models. In this\nwork, we go beyond top-line metrics and instead explore the impact of\nensembling on subgroup performances. Surprisingly, even with a simple\nhomogenous ensemble -- all the individual models share the same training set,\narchitecture, and design choices -- we find compelling and powerful gains in\nworst-k and minority group performance, i.e. fairness naturally emerges from\nensembling. We show that the gains in performance from ensembling for the\nminority group continue for far longer than for the majority group as more\nmodels are added. Our work establishes that simple DNN ensembles can be a\npowerful tool for alleviating disparate impact from DNN classifiers, thus\ncurbing algorithmic harm. We also explore why this is the case. We find that\neven in homogeneous ensembles, varying the sources of stochasticity through\nparameter initialization, mini-batch sampling, and the data-augmentation\nrealizations, results in different fairness outcomes.\n","authors":["Wei-Yin Ko","Daniel D'souza","Karina Nguyen","Randall Balestriero","Sara Hooker"],"pdf_url":"https://arxiv.org/pdf/2303.00586v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.13036v2","updated":"2023-03-01T15:27:29Z","published":"2022-09-26T21:29:50Z","title":"MonoGraspNet: 6-DoF Grasping with a Single RGB Image","summary":"  6-DoF robotic grasping is a long-lasting but unsolved problem. Recent methods\nutilize strong 3D networks to extract geometric grasping representations from\ndepth sensors, demonstrating superior accuracy on common objects but perform\nunsatisfactorily on photometrically challenging objects, e.g., objects in\ntransparent or reflective materials. The bottleneck lies in that the surface of\nthese objects can not reflect back accurate depth due to the absorption or\nrefraction of light. In this paper, in contrast to exploiting the inaccurate\ndepth data, we propose the first RGB-only 6-DoF grasping pipeline called\nMonoGraspNet that utilizes stable 2D features to simultaneously handle\narbitrary object grasping and overcome the problems induced by photometrically\nchallenging objects. MonoGraspNet leverages keypoint heatmap and normal map to\nrecover the 6-DoF grasping poses represented by our novel representation\nparameterized with 2D keypoints with corresponding depth, grasping direction,\ngrasping width, and angle. Extensive experiments in real scenes demonstrate\nthat our method can achieve competitive results in grasping common objects and\nsurpass the depth-based competitor by a large margin in grasping\nphotometrically challenging objects. To further stimulate robotic manipulation\nresearch, we additionally annotate and open-source a multi-view and multi-scene\nreal-world grasping dataset, containing 120 objects of mixed photometric\ncomplexity with 20M accurate grasping labels.\n","authors":["Guangyao Zhai","Dianye Huang","Shun-Cheng Wu","Hyunjun Jung","Yan Di","Fabian Manhardt","Federico Tombari","Nassir Navab","Benjamin Busam"],"pdf_url":"https://arxiv.org/pdf/2209.13036v2.pdf","comment":"ICRA 2023 accepted. Project website:\n  https://sites.google.com/view/monograsp"},{"id":"http://arxiv.org/abs/2303.00575v1","updated":"2023-03-01T15:16:56Z","published":"2023-03-01T15:16:56Z","title":"IPCC-TP: Utilizing Incremental Pearson Correlation Coefficient for Joint\n  Multi-Agent Trajectory Prediction","summary":"  Reliable multi-agent trajectory prediction is crucial for the safe planning\nand control of autonomous systems. Compared with single-agent cases, the major\nchallenge in simultaneously processing multiple agents lies in modeling complex\nsocial interactions caused by various driving intentions and road conditions.\nPrevious methods typically leverage graph-based message propagation or\nattention mechanism to encapsulate such interactions in the format of marginal\nprobabilistic distributions. However, it is inherently sub-optimal. In this\npaper, we propose IPCC-TP, a novel relevance-aware module based on Incremental\nPearson Correlation Coefficient to improve multi-agent interaction modeling.\nIPCC-TP learns pairwise joint Gaussian Distributions through the\ntightly-coupled estimation of the means and covariances according to\ninteractive incremental movements. Our module can be conveniently embedded into\nexisting multi-agent prediction methods to extend original motion distribution\ndecoders. Extensive experiments on nuScenes and Argoverse 2 datasets\ndemonstrate that IPCC-TP improves the performance of baselines by a large\nmargin.\n","authors":["Dekai Zhu","Guangyao Zhai","Yan Di","Fabian Manhardt","Hendrik Berkemeyer","Tuan Tran","Nassir Navab","Federico Tombari","Benjamin Busam"],"pdf_url":"https://arxiv.org/pdf/2303.00575v1.pdf","comment":"CVPR 2023 accepted. More details are coming soon"},{"id":"http://arxiv.org/abs/2303.00566v1","updated":"2023-03-01T15:12:55Z","published":"2023-03-01T15:12:55Z","title":"Structured Pruning for Deep Convolutional Neural Networks: A survey","summary":"  The remarkable performance of deep Convolutional neural networks (CNNs) is\ngenerally attributed to their deeper and wider architectures, which can come\nwith significant computational costs. Pruning neural networks has thus gained\ninterest since it effectively lowers storage and computational costs. In\ncontrast to weight pruning, which results in unstructured models, structured\npruning provides the benefit of realistic acceleration by producing models that\nare friendly to hardware implementation. The special requirements of structured\npruning have led to the discovery of numerous new challenges and the\ndevelopment of innovative solutions. This article surveys the recent progress\ntowards structured pruning of deep CNNs. We summarize and compare the\nstate-of-the-art structured pruning techniques with respect to filter ranking\nmethods, regularization methods, dynamic execution, neural architecture search,\nthe lottery ticket hypothesis, and the applications of pruning. While\ndiscussing structured pruning algorithms, we briefly introduce the unstructured\npruning counterpart to emphasize their differences. Furthermore, we provide\ninsights into potential research opportunities in the field of structured\npruning. A curated list of neural network pruning papers can be found at\nhttps://github.com/he-y/Awesome-Pruning\n","authors":["Yang He","Lingao Xiao"],"pdf_url":"https://arxiv.org/pdf/2303.00566v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2303.00563v1","updated":"2023-03-01T15:09:45Z","published":"2023-03-01T15:09:45Z","title":"ROCO: A Roundabout Traffic Conflict Dataset","summary":"  Traffic conflicts have been studied by the transportation research community\nas a surrogate safety measure for decades. However, due to the rarity of\ntraffic conflicts, collecting large-scale real-world traffic conflict data\nbecomes extremely challenging. In this paper, we introduce and analyze ROCO - a\nreal-world roundabout traffic conflict dataset. The data is collected at a\ntwo-lane roundabout at the intersection of State St. and W. Ellsworth Rd. in\nAnn Arbor, Michigan. We use raw video dataflow captured from four fisheye\ncameras installed at the roundabout as our input data source. We adopt a\nlearning-based conflict identification algorithm from video to find potential\ntraffic conflicts, and then manually label them for dataset collection and\nannotation. In total 557 traffic conflicts and 17 traffic crashes are collected\nfrom August 2021 to October 2021. We provide trajectory data of the traffic\nconflict scenes extracted using our roadside perception system. Taxonomy based\non traffic conflict severity, reason for the traffic conflict, and its effect\non the traffic flow is provided. With the traffic conflict data collected, we\ndiscover that failure to yield to circulating vehicles when entering the\nroundabout is the largest contributing reason for traffic conflicts. ROCO\ndataset will be made public in the short future.\n","authors":["Depu Meng","Owen Sayer","Rusheng Zhang","Shengyin Shen","Houqiang Li","Henry X. Liu"],"pdf_url":"https://arxiv.org/pdf/2303.00563v1.pdf","comment":"Accepted by TRBAM 2023 presentation"},{"id":"http://arxiv.org/abs/2302.10763v2","updated":"2023-03-01T14:58:09Z","published":"2023-02-12T12:19:57Z","title":"Contrastive Learning and the Emergence of Attributes Associations","summary":"  In response to an object presentation, supervised learning schemes generally\nrespond with a parsimonious label. Upon a similar presentation we humans\nrespond again with a label, but are flooded, in addition, by a myriad of\nassociations. A significant portion of these consist of the presented object\nattributes. Contrastive learning is a semi-supervised learning scheme based on\nthe application of identity preserving transformations on the object input\nrepresentations. It is conjectured in this work that these same applied\ntransformations preserve, in addition to the identity of the presented object,\nalso the identity of its semantically meaningful attributes. The corollary of\nthis is that the output representations of such a contrastive learning scheme\ncontain valuable information not only for the classification of the presented\nobject, but also for the presence or absence decision of any attribute of\ninterest. Simulation results which demonstrate this idea and the feasibility of\nthis conjecture are presented.\n","authors":["Daniel N. Nissani"],"pdf_url":"https://arxiv.org/pdf/2302.10763v2.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2302.13838v2","updated":"2023-03-01T14:50:41Z","published":"2023-02-27T14:39:50Z","title":"Cross-modal Face- and Voice-style Transfer","summary":"  Image-to-image translation and voice conversion enable the generation of a\nnew facial image and voice while maintaining some of the semantics such as a\npose in an image and linguistic content in audio, respectively. They can aid in\nthe content-creation process in many applications. However, as they are limited\nto the conversion within each modality, matching the impression of the\ngenerated face and voice remains an open question. We propose a cross-modal\nstyle transfer framework called XFaVoT that jointly learns four tasks: image\ntranslation and voice conversion tasks with audio or image guidance, which\nenables the generation of ``face that matches given voice\" and ``voice that\nmatches given face\", and intra-modality translation tasks with a single\nframework. Experimental results on multiple datasets show that XFaVoT achieves\ncross-modal style translation of image and voice, outperforming baselines in\nterms of quality, diversity, and face-voice correspondence.\n","authors":["Naoya Takahashi","Mayank K. Singh","Yuki Mitsufuji"],"pdf_url":"https://arxiv.org/pdf/2302.13838v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00542v1","updated":"2023-03-01T14:36:19Z","published":"2023-03-01T14:36:19Z","title":"D2Q-DETR: Decoupling and Dynamic Queries for Oriented Object Detection\n  with Transformers","summary":"  Despite the promising results, existing oriented object detection methods\nusually involve heuristically designed rules, e.g., RRoI generation, rotated\nNMS. In this paper, we propose an end-to-end framework for oriented object\ndetection, which simplifies the model pipeline and obtains superior\nperformance. Our framework is based on DETR, with the box regression head\nreplaced with a points prediction head. The learning of points is more\nflexible, and the distribution of points can reflect the angle and size of the\ntarget rotated box. We further propose to decouple the query features into\nclassification and regression features, which significantly improves the model\nprecision. Aerial images usually contain thousands of instances. To better\nbalance model precision and efficiency, we propose a novel dynamic query\ndesign, which reduces the number of object queries in stacked decoder layers\nwithout sacrificing model performance. Finally, we rethink the label assignment\nstrategy of existing DETR-like detectors and propose an effective label\nre-assignment strategy for improved performance. We name our method D2Q-DETR.\nExperiments on the largest and challenging DOTA-v1.0 and DOTA-v1.5 datasets\nshow that D2Q-DETR outperforms existing NMS-based and NMS-free oriented object\ndetection methods and achieves the new state-of-the-art.\n","authors":["Qiang Zhou","Chaohui Yu","Zhibin Wang","Fan Wang"],"pdf_url":"https://arxiv.org/pdf/2303.00542v1.pdf","comment":"5 figures"},{"id":"http://arxiv.org/abs/2303.00534v1","updated":"2023-03-01T14:21:19Z","published":"2023-03-01T14:21:19Z","title":"RAMM: Retrieval-augmented Biomedical Visual Question Answering with\n  Multi-modal Pre-training","summary":"  Vision-and-language multi-modal pretraining and fine-tuning have shown great\nsuccess in visual question answering (VQA). Compared to general domain VQA, the\nperformance of biomedical VQA suffers from limited data. In this paper, we\npropose a retrieval-augmented pretrain-and-finetune paradigm named RAMM for\nbiomedical VQA to overcome the data limitation issue. Specifically, we collect\na new biomedical dataset named PMCPM which offers patient-based image-text\npairs containing diverse patient situations from PubMed. Then, we pretrain the\nbiomedical multi-modal model to learn visual and textual representation for\nimage-text pairs and align these representations with image-text contrastive\nobjective (ITC). Finally, we propose a retrieval-augmented method to better use\nthe limited data. We propose to retrieve similar image-text pairs based on ITC\nfrom pretraining datasets and introduce a novel retrieval-attention module to\nfuse the representation of the image and the question with the retrieved images\nand texts. Experiments demonstrate that our retrieval-augmented\npretrain-and-finetune paradigm obtains state-of-the-art performance on\nMed-VQA2019, Med-VQA2021, VQARAD, and SLAKE datasets. Further analysis shows\nthat the proposed RAMM and PMCPM can enhance biomedical VQA performance\ncompared with previous resources and methods. We will open-source our dataset,\ncodes, and pretrained model.\n","authors":["Zheng Yuan","Qiao Jin","Chuanqi Tan","Zhengyun Zhao","Hongyi Yuan","Fei Huang","Songfang Huang"],"pdf_url":"https://arxiv.org/pdf/2303.00534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00521v1","updated":"2023-03-01T13:52:40Z","published":"2023-03-01T13:52:40Z","title":"Quality-aware Pre-trained Models for Blind Image Quality Assessment","summary":"  Blind image quality assessment (BIQA) aims to automatically evaluate the\nperceived quality of a single image, whose performance has been improved by\ndeep learning-based methods in recent years. However, the paucity of labeled\ndata somewhat restrains deep learning-based BIQA methods from unleashing their\nfull potential. In this paper, we propose to solve the problem by a pretext\ntask customized for BIQA in a self-supervised learning manner, which enables\nlearning representations from orders of magnitude more data. To constrain the\nlearning process, we propose a quality-aware contrastive loss based on a simple\nassumption: the quality of patches from a distorted image should be similar,\nbut vary from patches from the same image with different degradations and\npatches from different images. Further, we improve the existing degradation\nprocess and form a degradation space with the size of roughly $2\\times10^7$.\nAfter pre-trained on ImageNet using our method, models are more sensitive to\nimage quality and perform significantly better on downstream BIQA tasks.\nExperimental results show that our method obtains remarkable improvements on\npopular BIQA datasets.\n","authors":["Kai Zhao","Kun Yuan","Ming Sun","Mading Li","Xing Wen"],"pdf_url":"https://arxiv.org/pdf/2303.00521v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2302.13602v2","updated":"2023-03-01T13:48:55Z","published":"2023-02-27T09:10:08Z","title":"The Role of Pre-training Data in Transfer Learning","summary":"  The transfer learning paradigm of model pre-training and subsequent\nfine-tuning produces high-accuracy models. While most studies recommend scaling\nthe pre-training size to benefit most from transfer learning, a question\nremains: what data and method should be used for pre-training? We investigate\nthe impact of pre-training data distribution on the few-shot and full\nfine-tuning performance using 3 pre-training methods (supervised, contrastive\nlanguage-image and image-image), 7 pre-training datasets, and 9 downstream\ndatasets. Through extensive controlled experiments, we find that the choice of\nthe pre-training data source is essential for the few-shot transfer, but its\nrole decreases as more data is made available for fine-tuning. Additionally, we\nexplore the role of data curation and examine the trade-offs between label\nnoise and the size of the pre-training dataset. We find that using 2000X more\npre-training data from LAION can match the performance of supervised ImageNet\npre-training. Furthermore, we investigate the effect of pre-training methods,\ncomparing language-image contrastive vs. image-image contrastive, and find that\nthe latter leads to better downstream accuracy\n","authors":["Rahim Entezari","Mitchell Wortsman","Olga Saukh","M. Moein Shariatnia","Hanie Sedghi","Ludwig Schmidt"],"pdf_url":"https://arxiv.org/pdf/2302.13602v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00502v1","updated":"2023-03-01T13:35:35Z","published":"2023-03-01T13:35:35Z","title":"On the Audio-visual Synchronization for Lip-to-Speech Synthesis","summary":"  Most lip-to-speech (LTS) synthesis models are trained and evaluated under the\nassumption that the audio-video pairs in the dataset are perfectly\nsynchronized. In this work, we show that the commonly used audio-visual\ndatasets, such as GRID, TCD-TIMIT, and Lip2Wav, can have data asynchrony\nissues. Training lip-to-speech with such datasets may further cause the model\nasynchrony issue -- that is, the generated speech and the input video are out\nof sync. To address these asynchrony issues, we propose a synchronized\nlip-to-speech (SLTS) model with an automatic synchronization mechanism (ASM) to\ncorrect data asynchrony and penalize model asynchrony. We further demonstrate\nthe limitation of the commonly adopted evaluation metrics for LTS with\nasynchronous test data and introduce an audio alignment frontend before the\nmetrics sensitive to time alignment for better evaluation. We compare our\nmethod with state-of-the-art approaches on conventional and time-aligned\nmetrics to show the benefits of synchronization training.\n","authors":["Zhe Niu","Brian Mak"],"pdf_url":"https://arxiv.org/pdf/2303.00502v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00500v1","updated":"2023-03-01T13:32:55Z","published":"2023-03-01T13:32:55Z","title":"Inherently Interpretable Multi-Label Classification Using Class-Specific\n  Counterfactuals","summary":"  Interpretability is essential for machine learning algorithms in high-stakes\napplication fields such as medical image analysis. However, high-performing\nblack-box neural networks do not provide explanations for their predictions,\nwhich can lead to mistrust and suboptimal human-ML collaboration. Post-hoc\nexplanation techniques, which are widely used in practice, have been shown to\nsuffer from severe conceptual problems. Furthermore, as we show in this paper,\ncurrent explanation techniques do not perform adequately in the multi-label\nscenario, in which multiple medical findings may co-occur in a single image. We\npropose Attri-Net, an inherently interpretable model for multi-label\nclassification. Attri-Net is a powerful classifier that provides transparent,\ntrustworthy, and human-understandable explanations. The model first generates\nclass-specific attribution maps based on counterfactuals to identify which\nimage regions correspond to certain medical findings. Then a simple logistic\nregression classifier is used to make predictions based solely on these\nattribution maps. We compare Attri-Net to five post-hoc explanation techniques\nand one inherently interpretable classifier on three chest X-ray datasets. We\nfind that Attri-Net produces high-quality multi-label explanations consistent\nwith clinical knowledge and has comparable classification performance to\nstate-of-the-art classification models.\n","authors":["Susu Sun","Stefano Woerner","Andreas Maier","Lisa M. Koch","Christian F. Baumgartner"],"pdf_url":"https://arxiv.org/pdf/2303.00500v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00491v1","updated":"2023-03-01T13:26:39Z","published":"2023-03-01T13:26:39Z","title":"Pose Impact Estimation on Face Recognition using 3D-Aware Synthetic Data\n  with Application to Quality Assessment","summary":"  Evaluating the quality of facial images is essential for operating face\nrecognition systems with sufficient accuracy. The recent advances in face\nquality standardisation (ISO/IEC WD 29794-5) recommend the usage of component\nquality measures for breaking down face quality into its individual factors,\nhence providing valuable feedback for operators to re-capture low-quality\nimages. In light of recent advances in 3D-aware generative adversarial\nnetworks, we propose a novel dataset, \"Syn-YawPitch\", comprising 1,000\nidentities with varying yaw-pitch angle combinations. Utilizing this dataset,\nwe demonstrate that pitch angles beyond 30 degrees have a significant impact on\nthe biometric performance of current face recognition systems. Furthermore, we\npropose a lightweight and efficient pose quality predictor that adheres to the\nstandards of ISO/IEC WD 29794-5 and is freely available for use at\nhttps://github.com/datasciencegrimmer/Syn-YawPitch/.\n","authors":["Marcel Grimmer","Christian Rathgeb","Christoph Busch"],"pdf_url":"https://arxiv.org/pdf/2303.00491v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09617v2","updated":"2023-03-01T13:25:59Z","published":"2023-01-23T18:33:38Z","title":"Fully transformer-based biomarker prediction from colorectal cancer\n  histology: a large-scale multicentric study","summary":"  Background: Deep learning (DL) can extract predictive and prognostic\nbiomarkers from routine pathology slides in colorectal cancer. For example, a\nDL test for the diagnosis of microsatellite instability (MSI) in CRC has been\napproved in 2022. Current approaches rely on convolutional neural networks\n(CNNs). Transformer networks are outperforming CNNs and are replacing them in\nmany applications, but have not been used for biomarker prediction in cancer at\na large scale. In addition, most DL approaches have been trained on small\npatient cohorts, which limits their clinical utility. Methods: In this study,\nwe developed a new fully transformer-based pipeline for end-to-end biomarker\nprediction from pathology slides. We combine a pre-trained transformer encoder\nand a transformer network for patch aggregation, capable of yielding single and\nmulti-target prediction at patient level. We train our pipeline on over 9,000\npatients from 10 colorectal cancer cohorts. Results: A fully transformer-based\napproach massively improves the performance, generalizability, data efficiency,\nand interpretability as compared with current state-of-the-art algorithms.\nAfter training on a large multicenter cohort, we achieve a sensitivity of 0.97\nwith a negative predictive value of 0.99 for MSI prediction on surgical\nresection specimens. We demonstrate for the first time that resection\nspecimen-only training reaches clinical-grade performance on endoscopic biopsy\ntissue, solving a long-standing diagnostic problem. Interpretation: A fully\ntransformer-based end-to-end pipeline trained on thousands of pathology slides\nyields clinical-grade performance for biomarker prediction on surgical\nresections and biopsies. Our new methods are freely available under an open\nsource license.\n","authors":["Sophia J. Wagner","Daniel Reisenbüchler","Nicholas P. West","Jan Moritz Niehues","Gregory Patrick Veldhuizen","Philip Quirke","Heike I. Grabsch","Piet A. van den Brandt","Gordon G. A. Hutchins","Susan D. Richman","Tanwei Yuan","Rupert Langer","Josien Christina Anna Jenniskens","Kelly Offermans","Wolfram Mueller","Richard Gray","Stephen B. Gruber","Joel K. Greenson","Gad Rennert","Joseph D. Bonner","Daniel Schmolze","Jacqueline A. James","Maurice B. Loughrey","Manuel Salto-Tellez","Hermann Brenner","Michael Hoffmeister","Daniel Truhn","Julia A. Schnabel","Melanie Boxberg","Tingying Peng","Jakob Nikolas Kather"],"pdf_url":"https://arxiv.org/pdf/2301.09617v2.pdf","comment":"Updated Figure 2 and Table A.5"},{"id":"http://arxiv.org/abs/2209.08343v2","updated":"2023-03-01T13:13:47Z","published":"2022-09-17T14:46:28Z","title":"Data Efficient Visual Place Recognition Using Extremely JPEG-Compressed\n  Images","summary":"  Visual Place Recognition (VPR) is the ability of a robotic platform to\ncorrectly interpret visual stimuli from its on-board cameras in order to\ndetermine whether it is currently located in a previously visited place,\ndespite different viewpoint, illumination and appearance changes. JPEG is a\nwidely used image compression standard that is capable of significantly\nreducing the size of an image at the cost of image clarity. For applications\nwhere several robotic platforms are simultaneously deployed, the visual data\ngathered must be transmitted remotely between each robot. Hence, JPEG\ncompression can be employed to drastically reduce the amount of data\ntransmitted over a communication channel, as working with limited bandwidth for\nVPR can be proven to be a challenging task. However, the effects of JPEG\ncompression on the performance of current VPR techniques have not been\npreviously studied. For this reason, this paper presents an in-depth study of\nJPEG compression in VPR related scenarios. We use a selection of\nwell-established VPR techniques on well-established benchmark datasets with\nvarious amounts of compression applied. We show that by introducing\ncompression, the VPR performance is drastically reduced, especially in the\nhigher spectrum of compression. Moreover, this paper demonstrates how\nfine-tuning a CNN can be utilised as an optimisation method for JPEG compressed\ndata to perform more consistently with the image transformations detected in\nextremely JPEG compressed images.\n","authors":["Mihnea-Alexandru Tomita","Bruno Ferrarini","Michael Milford","Klaus McDonald-Maier","Shoaib Ehsan"],"pdf_url":"https://arxiv.org/pdf/2209.08343v2.pdf","comment":"The paper is currently under-review. 8 pages, 8 figures"},{"id":"http://arxiv.org/abs/2303.00477v1","updated":"2023-03-01T13:04:45Z","published":"2023-03-01T13:04:45Z","title":"ORCHNet: A Robust Global Feature Aggregation approach for 3D LiDAR-based\n  Place recognition in Orchards","summary":"  Robust and reliable place recognition and loop closure detection in\nagricultural environments is still an open problem. In particular, orchards are\na difficult case study due to structural similarity across the entire field. In\nthis work, we address the place recognition problem in orchards resorting to 3D\nLiDAR data, which is considered a key modality for robustness. Hence, we\npropose ORCHNet, a deep-learning-based approach that maps 3D-LiDAR scans to\nglobal descriptors. Specifically, this work proposes a new global feature\naggregation approach, which fuses multiple aggregation methods into a robust\nglobal descriptor. ORCHNet is evaluated on real-world data collected in\norchards, comprising data from the summer and autumn seasons. To assess the\nrobustness, We compare ORCHNet with state-of-the-art aggregation approaches on\ndata from the same season and across seasons. Moreover, we additionally\nevaluate the proposed approach as part of a localization framework, where\nORCHNet is used as a loop closure detector. The empirical results indicate\nthat, on the place recognition task, ORCHNet outperforms the remaining\napproaches, and is also more robust across seasons. As for the localization,\nthe edge cases where the path goes through the trees are solved when\nintegrating ORCHNet as a loop detector, showing the potential applicability of\nthe proposed approach in this task. The code and dataset will be publicly\navailable at:\\url{https://github.com/Cybonic/ORCHNet.git}\n","authors":["T. Barros","L. Garrote","P. Conde","M. J. Coombes","C. Liu","C. Premebida","U. J. Nunes"],"pdf_url":"https://arxiv.org/pdf/2303.00477v1.pdf","comment":"This preprint has been submitted to IEEE Robotics & Automation\n  Magazine"},{"id":"http://arxiv.org/abs/2209.09359v3","updated":"2023-03-01T12:52:16Z","published":"2022-09-19T21:40:32Z","title":"E-VFIA : Event-Based Video Frame Interpolation with Attention","summary":"  Video frame interpolation (VFI) is a fundamental vision task that aims to\nsynthesize several frames between two consecutive original video images. Most\nalgorithms aim to accomplish VFI by using only keyframes, which is an ill-posed\nproblem since the keyframes usually do not yield any accurate precision about\nthe trajectories of the objects in the scene. On the other hand, event-based\ncameras provide more precise information between the keyframes of a video. Some\nrecent state-of-the-art event-based methods approach this problem by utilizing\nevent data for better optical flow estimation to interpolate for video frame by\nwarping. Nonetheless, those methods heavily suffer from the ghosting effect. On\nthe other hand, some of kernel-based VFI methods that only use frames as input,\nhave shown that deformable convolutions, when backed up with transformers, can\nbe a reliable way of dealing with long-range dependencies. We propose\nevent-based video frame interpolation with attention (E-VFIA), as a lightweight\nkernel-based method. E-VFIA fuses event information with standard video frames\nby deformable convolutions to generate high quality interpolated frames. The\nproposed method represents events with high temporal resolution and uses a\nmulti-head self-attention mechanism to better encode event-based information,\nwhile being less vulnerable to blurring and ghosting artifacts; thus,\ngenerating crispier frames. The simulation results show that the proposed\ntechnique outperforms current state-of-the-art methods (both frame and\nevent-based) with a significantly smaller model size.\n","authors":["Onur Selim Kılıç","Ahmet Akman","A. Aydın Alatan"],"pdf_url":"https://arxiv.org/pdf/2209.09359v3.pdf","comment":"Accepted to 2023 IEEE International Conference on Robotics and\n  Automation (ICRA 2023)"},{"id":"http://arxiv.org/abs/2301.01970v2","updated":"2023-03-01T12:42:10Z","published":"2023-01-05T09:11:16Z","title":"CAT: LoCalization and IdentificAtion Cascade Detection Transformer for\n  Open-World Object Detection","summary":"  Open-world object detection (OWOD), as a more general and challenging goal,\nrequires the model trained from data on known objects to detect both known and\nunknown objects and incrementally learn to identify these unknown objects. The\nexisting works which employ standard detection framework and fixed\npseudo-labelling mechanism (PLM) have the following problems: (i) The inclusion\nof detecting unknown objects substantially reduces the model's ability to\ndetect known ones. (ii) The PLM does not adequately utilize the priori\nknowledge of inputs. (iii) The fixed selection manner of PLM cannot guarantee\nthat the model is trained in the right direction. We observe that humans\nsubconsciously prefer to focus on all foreground objects and then identify each\none in detail, rather than localize and identify a single object\nsimultaneously, for alleviating the confusion. This motivates us to propose a\nnovel solution called CAT: LoCalization and IdentificAtion Cascade Detection\nTransformer which decouples the detection process via the shared decoder in the\ncascade decoding way. In the meanwhile, we propose the self-adaptive\npseudo-labelling mechanism which combines the model-driven with input-driven\nPLM and self-adaptively generates robust pseudo-labels for unknown objects,\nsignificantly improving the ability of CAT to retrieve unknown objects.\nComprehensive experiments on two benchmark datasets, i.e., MS-COCO and PASCAL\nVOC, show that our model outperforms the state-of-the-art in terms of all\nmetrics in the task of OWOD, incremental object detection (IOD) and open-set\ndetection.\n","authors":["Shuailei Ma","Yuefeng Wang","Jiaqi Fan","Ying Wei","Thomas H. Li","Hongli Liu","Fanbing Lv"],"pdf_url":"https://arxiv.org/pdf/2301.01970v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00462v1","updated":"2023-03-01T12:41:12Z","published":"2023-03-01T12:41:12Z","title":"Hidden Gems: 4D Radar Scene Flow Learning Using Cross-Modal Supervision","summary":"  This work proposes a novel approach to 4D radar-based scene flow estimation\nvia cross-modal learning. Our approach is motivated by the co-located sensing\nredundancy in modern autonomous vehicles. Such redundancy implicitly provides\nvarious forms of supervision cues to the radar scene flow estimation.\nSpecifically, we introduce a multi-task model architecture for the identified\ncross-modal learning problem and propose loss functions to opportunistically\nengage scene flow estimation using multiple cross-modal constraints for\neffective model training. Extensive experiments show the state-of-the-art\nperformance of our method and demonstrate the effectiveness of cross-modal\nsupervised learning to infer more accurate 4D radar scene flow. We also show\nits usefulness to two subtasks - motion segmentation and ego-motion estimation.\nOur source code will be available on \\url{https://github.com/Toytiny/CMFlow.}\n","authors":["Fangqiang Ding","Andras Palffy","Dariu M. Gavrila","Chris Xiaoxuan Lu"],"pdf_url":"https://arxiv.org/pdf/2303.00462v1.pdf","comment":"10 pages, 7 figures. Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2302.14340v2","updated":"2023-03-01T12:24:02Z","published":"2023-02-28T06:20:07Z","title":"HelixSurf: A Robust and Efficient Neural Implicit Surface Learning of\n  Indoor Scenes with Iterative Intertwined Regularization","summary":"  Recovery of an underlying scene geometry from multiview images stands as a\nlong-time challenge in computer vision research. The recent promise leverages\nneural implicit surface learning and differentiable volume rendering, and\nachieves both the recovery of scene geometry and synthesis of novel views,\nwhere deep priors of neural models are used as an inductive smoothness bias.\nWhile promising for object-level surfaces, these methods suffer when coping\nwith complex scene surfaces. In the meanwhile, traditional multi-view stereo\ncan recover the geometry of scenes with rich textures, by globally optimizing\nthe local, pixel-wise correspondences across multiple views. We are thus\nmotivated to make use of the complementary benefits from the two strategies,\nand propose a method termed Helix-shaped neural implicit Surface learning or\nHelixSurf; HelixSurf uses the intermediate prediction from one strategy as the\nguidance to regularize the learning of the other one, and conducts such\nintertwined regularization iteratively during the learning process. We also\npropose an efficient scheme for differentiable volume rendering in HelixSurf.\nExperiments on surface reconstruction of indoor scenes show that our method\ncompares favorably with existing methods and is orders of magnitude faster,\neven when some of existing methods are assisted with auxiliary training data.\nThe source code is available at https://github.com/Gorilla-Lab-SCUT/HelixSurf.\n","authors":["Zhihao Liang","Zhangjin Huang","Changxing Ding","Kui Jia"],"pdf_url":"https://arxiv.org/pdf/2302.14340v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00449v1","updated":"2023-03-01T12:18:03Z","published":"2023-03-01T12:18:03Z","title":"Motion Compensation via Epipolar Consistency for In-Vivo X-Ray\n  Microscopy","summary":"  Intravital X-ray microscopy (XRM) in preclinical mouse models is of vital\nimportance for the identification of microscopic structural pathological\nchanges in the bone which are characteristic of osteoporosis. The complexity of\nthis method stems from the requirement for high-quality 3D reconstructions of\nthe murine bones. However, respiratory motion and muscle relaxation lead to\ninconsistencies in the projection data which result in artifacts in\nuncompensated reconstructions. Motion compensation using epipolar consistency\nconditions (ECC) has previously shown good performance in clinical CT settings.\nHere, we explore whether such algorithms are suitable for correcting\nmotion-corrupted XRM data. Different rigid motion patterns are simulated and\nthe quality of the motion-compensated reconstructions is assessed. The method\nis able to restore microscopic features for out-of-plane motion, but artifacts\nremain for more realistic motion patterns including all six degrees of freedom\nof rigid motion. Therefore, ECC is valuable for the initial alignment of the\nprojection data followed by further fine-tuning of motion parameters using a\nreconstruction-based method\n","authors":["Mareike Thies","Fabian Wagner","Mingxuan Gu","Yixing Huang","Sabrina Pechmann","Oliver Aust","Daniela Weidner","Georgiana Neag","Stefan Uderhardt","Georg Schett","Silke Christiansen","Andreas Maier"],"pdf_url":"https://arxiv.org/pdf/2303.00449v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00448v1","updated":"2023-03-01T12:17:33Z","published":"2023-03-01T12:17:33Z","title":"The style transformer with common knowledge optimization for image-text\n  retrieval","summary":"  Image-text retrieval which associates different modalities has drawn broad\nattention due to its excellent research value and broad real-world application.\nWhile the algorithms keep updated, most of them haven't taken the high-level\nsemantic relationships (\"style embedding\") and common knowledge from\nmulti-modalities into full consideration. To this end, we propose a novel style\ntransformer network with common knowledge optimization (CKSTN) for image-text\nretrieval. The main module is the common knowledge adaptor (CKA) with both the\nstyle embedding extractor (SEE) and the common knowledge optimization (CKO)\nmodules. Specifically, the SEE is designed to effectively extract high-level\nfeatures. The CKO module is introduced to dynamically capture the latent\nconcepts of common knowledge from different modalities. Together, they could\nassist in the formation of item representations in lightweight transformers.\nBesides, to get generalized temporal common knowledge, we propose a sequential\nupdate strategy to effectively integrate the features of different layers in\nSEE with previous common feature units. CKSTN outperforms the results of\nstate-of-the-art methods in image-text retrieval on MSCOCO and Flickr30K\ndatasets. Moreover, CKSTN is more convenient and practical for the application\nof real scenes, due to the better performance and lower parameters.\n","authors":["Wenrui Li","Zhengyu Ma","Xiaopeng Fan"],"pdf_url":"https://arxiv.org/pdf/2303.00448v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01540v3","updated":"2023-03-01T12:02:21Z","published":"2023-02-03T04:31:13Z","title":"DEVICE: DEpth and VIsual ConcEpts Aware Transformer for TextCaps","summary":"  Text-based image captioning is an important but under-explored task, aiming\nto generate descriptions containing visual objects and scene text. Recent\nstudies have made encouraging progress, but they are still suffering from a\nlack of overall understanding of scenes and generating inaccurate captions. One\npossible reason is that current studies mainly focus on constructing the\nplane-level geometric relationship of scene text without depth information.\nThis leads to insufficient scene text relational reasoning so that models may\ndescribe scene text inaccurately. The other possible reason is that existing\nmethods fail to generate fine-grained descriptions of some visual objects. In\naddition, they may ignore essential visual objects, leading to the scene text\nbelonging to these ignored objects not being utilized. To address the above\nissues, we propose a DEpth and VIsual ConcEpts Aware Transformer (DEVICE) for\nTextCaps. Concretely, to construct three-dimensional geometric relations, we\nintroduce depth information and propose a depth-enhanced feature updating\nmodule to ameliorate OCR token features. To generate more precise and\ncomprehensive captions, we introduce semantic features of detected visual\nobject concepts as auxiliary information. Our DEVICE is capable of generalizing\nscenes more comprehensively and boosting the accuracy of described visual\nentities. Sufficient experiments demonstrate the effectiveness of our proposed\nDEVICE, which outperforms state-of-the-art models on the TextCaps test set. Our\ncode will be publicly available.\n","authors":["Dongsheng Xu","Qingbao Huang","Feng Shuang","Yi Cai"],"pdf_url":"https://arxiv.org/pdf/2302.01540v3.pdf","comment":"11pages, 7figures. This work has been submitted to the IEEE for\n  possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2303.00440v1","updated":"2023-03-01T12:00:15Z","published":"2023-03-01T12:00:15Z","title":"Extracting Motion and Appearance via Inter-Frame Attention for Efficient\n  Video Frame Interpolation","summary":"  Effectively extracting inter-frame motion and appearance information is\nimportant for video frame interpolation (VFI). Previous works either extract\nboth types of information in a mixed way or elaborate separate modules for each\ntype of information, which lead to representation ambiguity and low efficiency.\nIn this paper, we propose a novel module to explicitly extract motion and\nappearance information via a unifying operation. Specifically, we rethink the\ninformation process in inter-frame attention and reuse its attention map for\nboth appearance feature enhancement and motion information extraction.\nFurthermore, for efficient VFI, our proposed module could be seamlessly\nintegrated into a hybrid CNN and Transformer architecture. This hybrid pipeline\ncan alleviate the computational complexity of inter-frame attention as well as\npreserve detailed low-level structure information. Experimental results\ndemonstrate that, for both fixed- and arbitrary-timestep interpolation, our\nmethod achieves state-of-the-art performance on various datasets. Meanwhile,\nour approach enjoys a lighter computation overhead over models with close\nperformance. The source code and models are available at\nhttps://github.com/MCG-NJU/EMA-VFI.\n","authors":["Guozhen Zhang","Yuhan Zhu","Haonan Wang","Youxin Chen","Gangshan Wu","Limin Wang"],"pdf_url":"https://arxiv.org/pdf/2303.00440v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2303.00431v1","updated":"2023-03-01T11:39:54Z","published":"2023-03-01T11:39:54Z","title":"OliVaR: Improving Olive Variety Recognition using Deep Neural Networks","summary":"  The easy and accurate identification of varieties is fundamental in\nagriculture, especially in the olive sector, where more than 1200 olive\nvarieties are currently known worldwide. Varietal misidentification leads to\nmany potential problems for all the actors in the sector: farmers and nursery\nworkers may establish the wrong variety, leading to its maladaptation in the\nfield; olive oil and table olive producers may label and sell a non-authentic\nproduct; consumers may be misled; and breeders may commit errors during\ntargeted crossings between different varieties. To date, the standard for\nvarietal identification and certification consists of two methods:\nmorphological classification and genetic analysis. The morphological\nclassification consists of the visual pairwise comparison of different organs\nof the olive tree, where the most important organ is considered to be the\nendocarp. In contrast, different methods for genetic classification exist\n(RAPDs, SSR, and SNP). Both classification methods present advantages and\ndisadvantages. Visual morphological classification requires highly specialized\npersonnel and is prone to human error. Genetic identification methods are more\naccurate but incur a high cost and are difficult to implement. This paper\nintroduces OliVaR, a novel approach to olive varietal identification. OliVaR\nuses a teacher-student deep learning architecture to learn the defining\ncharacteristics of the endocarp of each specific olive variety and perform\nclassification. We construct what is, to the best of our knowledge, the largest\nolive variety dataset to date, comprising image data for 131 varieties from the\nMediterranean basin. We thoroughly test OliVaR on this dataset and show that it\ncorrectly predicts olive varieties with over 86% accuracy.\n","authors":["Hristofor Miho","Giulio Pagnotta","Dorjan Hitaj","Fabio De Gaspari","Luigi V. Mancini","Georgios Koubouris","Gianluca Godino","Mehmet Hakan","Concepcion Muñoz Diez"],"pdf_url":"https://arxiv.org/pdf/2303.00431v1.pdf","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2302.14045v2","updated":"2023-03-01T11:04:51Z","published":"2023-02-27T18:55:27Z","title":"Language Is Not All You Need: Aligning Perception with Language Models","summary":"  A big convergence of language, multimodal perception, action, and world\nmodeling is a key step toward artificial general intelligence. In this work, we\nintroduce Kosmos-1, a Multimodal Large Language Model (MLLM) that can perceive\ngeneral modalities, learn in context (i.e., few-shot), and follow instructions\n(i.e., zero-shot). Specifically, we train Kosmos-1 from scratch on web-scale\nmultimodal corpora, including arbitrarily interleaved text and images,\nimage-caption pairs, and text data. We evaluate various settings, including\nzero-shot, few-shot, and multimodal chain-of-thought prompting, on a wide range\nof tasks without any gradient updates or finetuning. Experimental results show\nthat Kosmos-1 achieves impressive performance on (i) language understanding,\ngeneration, and even OCR-free NLP (directly fed with document images), (ii)\nperception-language tasks, including multimodal dialogue, image captioning,\nvisual question answering, and (iii) vision tasks, such as image recognition\nwith descriptions (specifying classification via text instructions). We also\nshow that MLLMs can benefit from cross-modal transfer, i.e., transfer knowledge\nfrom language to multimodal, and from multimodal to language. In addition, we\nintroduce a dataset of Raven IQ test, which diagnoses the nonverbal reasoning\ncapability of MLLMs.\n","authors":["Shaohan Huang","Li Dong","Wenhui Wang","Yaru Hao","Saksham Singhal","Shuming Ma","Tengchao Lv","Lei Cui","Owais Khan Mohammed","Barun Patra","Qiang Liu","Kriti Aggarwal","Zewen Chi","Johan Bjorck","Vishrav Chaudhary","Subhojit Som","Xia Song","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2302.14045v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00404v1","updated":"2023-03-01T10:52:20Z","published":"2023-03-01T10:52:20Z","title":"Distilled Reverse Attention Network for Open-world Compositional\n  Zero-Shot Learning","summary":"  Open-World Compositional Zero-Shot Learning (OW-CZSL) aims to recognize new\ncompositions of seen attributes and objects. In OW-CZSL, methods built on the\nconventional closed-world setting degrade severely due to the unconstrained OW\ntest space. While previous works alleviate the issue by pruning compositions\naccording to external knowledge or correlations in seen pairs, they introduce\nbiases that harm the generalization. Some methods thus predict state and object\nwith independently constructed and trained classifiers, ignoring that\nattributes are highly context-dependent and visually entangled with objects. In\nthis paper, we propose a novel Distilled Reverse Attention Network to address\nthe challenges. We also model attributes and objects separately but with\ndifferent motivations, capturing contextuality and locality, respectively. We\nfurther design a reverse-and-distill strategy that learns disentangled\nrepresentations of elementary components in training data supervised by reverse\nattention and knowledge distillation. We conduct experiments on three datasets\nand consistently achieve state-of-the-art (SOTA) performance.\n","authors":["Yun Li","Zhe Liu","Saurav Jha","Sally Cripps","Lina Yao"],"pdf_url":"https://arxiv.org/pdf/2303.00404v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00403v1","updated":"2023-03-01T10:51:27Z","published":"2023-03-01T10:51:27Z","title":"Can representation learning for multimodal image registration be\n  improved by supervision of intermediate layers?","summary":"  Multimodal imaging and correlative analysis typically require image\nalignment. Contrastive learning can generate representations of multimodal\nimages, reducing the challenging task of multimodal image registration to a\nmonomodal one. Previously, additional supervision on intermediate layers in\ncontrastive learning has improved biomedical image classification. We evaluate\nif a similar approach improves representations learned for registration to\nboost registration performance. We explore three approaches to add contrastive\nsupervision to the latent features of the bottleneck layer in the U-Nets\nencoding the multimodal images and evaluate three different critic functions.\nOur results show that representations learned without additional supervision on\nlatent features perform best in the downstream task of registration on two\npublic biomedical datasets. We investigate the performance drop by exploiting\nrecent insights in contrastive learning in classification and self-supervised\nlearning. We visualize the spatial relations of the learned representations by\nmeans of multidimensional scaling, and show that additional supervision on the\nbottleneck layer can lead to partial dimensional collapse of the intermediate\nembedding space.\n","authors":["Elisabeth Wetzer","Joakim Lindblad","Nataša Sladoje"],"pdf_url":"https://arxiv.org/pdf/2303.00403v1.pdf","comment":"15 Pages + 9 Pages Appendix, 10 Figures"},{"id":"http://arxiv.org/abs/2303.00396v1","updated":"2023-03-01T10:33:02Z","published":"2023-03-01T10:33:02Z","title":"Controlling Class Layout for Deep Ordinal Classification via Constrained\n  Proxies Learning","summary":"  For deep ordinal classification, learning a well-structured feature space\nspecific to ordinal classification is helpful to properly capture the ordinal\nnature among classes. Intuitively, when Euclidean distance metric is used, an\nideal ordinal layout in feature space would be that the sample clusters are\narranged in class order along a straight line in space. However, enforcing\nsamples to conform to a specific layout in the feature space is a challenging\nproblem. To address this problem, in this paper, we propose a novel Constrained\nProxies Learning (CPL) method, which can learn a proxy for each ordinal class\nand then adjusts the global layout of classes by constraining these proxies.\nSpecifically, we propose two kinds of strategies: hard layout constraint and\nsoft layout constraint. The hard layout constraint is realized by directly\ncontrolling the generation of proxies to force them to be placed in a strict\nlinear layout or semicircular layout (i.e., two instantiations of strict\nordinal layout). The soft layout constraint is realized by constraining that\nthe proxy layout should always produce unimodal proxy-to-proxies similarity\ndistribution for each proxy (i.e., to be a relaxed ordinal layout). Experiments\nshow that the proposed CPL method outperforms previous deep ordinal\nclassification methods under the same setting of feature extractor.\n","authors":["Cong Wang","Zhiwei Jiang","Yafeng Yin","Zifeng Cheng","Shiping Ge","Qing Gu"],"pdf_url":"https://arxiv.org/pdf/2303.00396v1.pdf","comment":"Accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2303.00377v1","updated":"2023-03-01T10:02:12Z","published":"2023-03-01T10:02:12Z","title":"Few-shots Portrait Generation with Style Enhancement and Identity\n  Preservation","summary":"  Nowadays, the wide application of virtual digital human promotes the\ncomprehensive prosperity and development of digital culture supported by\ndigital economy. The personalized portrait automatically generated by AI\ntechnology needs both the natural artistic style and human sentiment. In this\npaper, we propose a novel StyleIdentityGAN model, which can ensure the identity\nand artistry of the generated portrait at the same time. Specifically, the\nstyle-enhanced module focuses on artistic style features decoupling and\ntransferring to improve the artistry of generated virtual face images.\nMeanwhile, the identity-enhanced module preserves the significant features\nextracted from the input photo. Furthermore, the proposed method requires a\nsmall number of reference style data. Experiments demonstrate the superiority\nof StyleIdentityGAN over state-of-art methods in artistry and identity effects,\nwith comparisons done qualitatively, quantitatively and through a perceptual\nuser study. Code has been released on Github3.\n","authors":["Runchuan Zhu","Naye Ji","Youbing Zhao","Fan Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.00377v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00369v1","updated":"2023-03-01T09:50:39Z","published":"2023-03-01T09:50:39Z","title":"Indescribable Multi-modal Spatial Evaluator","summary":"  Multi-modal image registration spatially aligns two images with different\ndistributions. One of its major challenges is that images acquired from\ndifferent imaging machines have different imaging distributions, making it\ndifficult to focus only on the spatial aspect of the images and ignore\ndifferences in distributions. In this study, we developed a self-supervised\napproach, Indescribable Multi-model Spatial Evaluator (IMSE), to address\nmulti-modal image registration. IMSE creates an accurate multi-modal spatial\nevaluator to measure spatial differences between two images, and then optimizes\nregistration by minimizing the error predicted of the evaluator. To optimize\nIMSE performance, we also proposed a new style enhancement method called\nShuffle Remap which randomizes the image distribution into multiple segments,\nand then randomly disorders and remaps these segments, so that the distribution\nof the original image is changed. Shuffle Remap can help IMSE to predict the\ndifference in spatial location from unseen target distributions. Our results\nshow that IMSE outperformed the existing methods for registration using T1-T2\nand CT-MRI datasets. IMSE also can be easily integrated into the traditional\nregistration process, and can provide a convenient way to evaluate and\nvisualize registration results. IMSE also has the potential to be used as a new\nparadigm for image-to-image translation. Our code is available at\nhttps://github.com/Kid-Liet/IMSE.\n","authors":["Lingke Kong","X. Sharon Qi","Qijin Shen","Jiacheng Wang","Jingyi Zhang","Yanle Hu","Qichao Zhou"],"pdf_url":"https://arxiv.org/pdf/2303.00369v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00364v1","updated":"2023-03-01T09:45:17Z","published":"2023-03-01T09:45:17Z","title":"Lessons Learned Report: Super-Resolution for Detection Tasks in\n  Engineering Problem-Solving","summary":"  We describe the lessons learned from targeting agricultural detection\nproblem-solving, when subject to low resolution input maps, by means of Machine\nLearning-based super-resolution approaches. The underlying domain is the\nso-called agro-detection class of problems, and the specific objective is to\nlearn a complementary ensemble of sporadic input maps. While super-resolution\nalgorithms are branded with the capacity to enhance various attractive features\nin generic photography, we argue that they must meet certain requirements, and\nmore importantly, that their outcome does not necessarily guarantee an\nimprovement in engineering detection problem-solving (unlike so-called\naesthetics/artistic super-resolution in ImageNet-like datasets). By presenting\nspecific data-driven case studies, we outline a set of limitations and\nrecommendations for deploying super-resolution algorithms for agro-detection\nproblems. Another conclusion states that super-resolution algorithms can be\nused for learning missing spectral channels, and that their usage may result in\nsome desired side-effects such as channels' synchronization.\n","authors":["Martin Feder","Michal Horovitz","Assaf Chen","Raphael Linker","Ofer M. Shir"],"pdf_url":"https://arxiv.org/pdf/2303.00364v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00355v1","updated":"2023-03-01T09:33:49Z","published":"2023-03-01T09:33:49Z","title":"Progressive Scale-aware Network for Remote sensing Image Change\n  Captioning","summary":"  Remote sensing (RS) images contain numerous objects of different scales,\nwhich poses significant challenges for the RS image change captioning (RSICC)\ntask to identify visual changes of interest in complex scenes and describe them\nvia language. However, current methods still have some weaknesses in\nsufficiently extracting and utilizing multi-scale information. In this paper,\nwe propose a progressive scale-aware network (PSNet) to address the problem.\nPSNet is a pure Transformer-based model. To sufficiently extract multi-scale\nvisual features, multiple progressive difference perception (PDP) layers are\nstacked to progressively exploit the differencing features of bitemporal\nfeatures. To sufficiently utilize the extracted multi-scale features for\ncaptioning, we propose a scale-aware reinforcement (SR) module and combine it\nwith the Transformer decoding layer to progressively utilize the features from\ndifferent PDP layers. Experiments show that the PDP layer and SR module are\neffective and our PSNet outperforms previous methods.\n","authors":["Chenyang Liu","Jiajun Yang","Zipeng Qi","Zhengxia Zou","Zhenwei Shi"],"pdf_url":"https://arxiv.org/pdf/2303.00355v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00354v1","updated":"2023-03-01T09:30:48Z","published":"2023-03-01T09:30:48Z","title":"Unlimited-Size Diffusion Restoration","summary":"  Recently, using diffusion models for zero-shot image restoration (IR) has\nbecome a new hot paradigm. This type of method only needs to use the\npre-trained off-the-shelf diffusion models, without any finetuning, and can\ndirectly handle various IR tasks. The upper limit of the restoration\nperformance depends on the pre-trained diffusion models, which are in rapid\nevolution. However, current methods only discuss how to deal with fixed-size\nimages, but dealing with images of arbitrary sizes is very important for\npractical applications. This paper focuses on how to use those diffusion-based\nzero-shot IR methods to deal with any size while maintaining the excellent\ncharacteristics of zero-shot. A simple way to solve arbitrary size is to divide\nit into fixed-size patches and solve each patch independently. But this may\nyield significant artifacts since it neither considers the global semantics of\nall patches nor the local information of adjacent patches. Inspired by the\nRange-Null space Decomposition, we propose the Mask-Shift Restoration to\naddress local incoherence and propose the Hierarchical Restoration to alleviate\nout-of-domain issues. Our simple, parameter-free approaches can be used not\nonly for image restoration but also for image generation of unlimited sizes,\nwith the potential to be a general tool for diffusion models. Code:\nhttps://github.com/wyhuai/DDNM/tree/main/hq_demo\n","authors":["Yinhuai Wang","Jiwen Yu","Runyi Yu","Jian Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.00354v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00351v1","updated":"2023-03-01T09:27:08Z","published":"2023-03-01T09:27:08Z","title":"An end-to-end SE(3)-equivariant segmentation network","summary":"  Convolutional neural networks (CNNs) allow for parameter sharing and\ntranslational equivariance by using convolutional kernels in their linear\nlayers. By restricting these kernels to be SO(3)-steerable, CNNs can further\nimprove parameter sharing and equivariance. These equivariant convolutional\nlayers have several advantages over standard convolutional layers, including\nincreased robustness to unseen poses, smaller network size, and improved sample\nefficiency. Despite this, most segmentation networks used in medical image\nanalysis continue to rely on standard convolutional kernels. In this paper, we\npresent a new family of segmentation networks that use equivariant voxel\nconvolutions based on spherical harmonics, as well as equivariant pooling and\nnormalization operations. These SE(3)-equivariant volumetric segmentation\nnetworks, which are robust to data poses not seen during training, do not\nrequire rotation-based data augmentation during training. In addition, we\ndemonstrate improved segmentation performance in MRI brain tumor and healthy\nbrain structure segmentation tasks, with enhanced robustness to reduced amounts\nof training data and improved parameter efficiency. Code to reproduce our\nresults, and to implement the equivariant segmentation networks for other tasks\nis available at~\\url{http://github.com/SCAN-NRAD/e3nn_Unet}.\n","authors":["Ivan Diaz","Mario Geiger","Richard Iain McKinley"],"pdf_url":"https://arxiv.org/pdf/2303.00351v1.pdf","comment":"19 pages, 10 figures, submitted to the Journal of Machine Learning\n  for Biomedical Imaging"},{"id":"http://arxiv.org/abs/2209.00588v2","updated":"2023-03-01T09:21:14Z","published":"2022-09-01T17:03:07Z","title":"Transformers are Sample-Efficient World Models","summary":"  Deep reinforcement learning agents are notoriously sample inefficient, which\nconsiderably limits their application to real-world problems. Recently, many\nmodel-based methods have been designed to address this issue, with learning in\nthe imagination of a world model being one of the most prominent approaches.\nHowever, while virtually unlimited interaction with a simulated environment\nsounds appealing, the world model has to be accurate over extended periods of\ntime. Motivated by the success of Transformers in sequence modeling tasks, we\nintroduce IRIS, a data-efficient agent that learns in a world model composed of\na discrete autoencoder and an autoregressive Transformer. With the equivalent\nof only two hours of gameplay in the Atari 100k benchmark, IRIS achieves a mean\nhuman normalized score of 1.046, and outperforms humans on 10 out of 26 games,\nsetting a new state of the art for methods without lookahead search. To foster\nfuture research on Transformers and world models for sample-efficient\nreinforcement learning, we release our code and models at\nhttps://github.com/eloialonso/iris.\n","authors":["Vincent Micheli","Eloi Alonso","François Fleuret"],"pdf_url":"https://arxiv.org/pdf/2209.00588v2.pdf","comment":"ICLR 2023 (notable top 5%)"},{"id":"http://arxiv.org/abs/2303.00340v1","updated":"2023-03-01T09:07:27Z","published":"2023-03-01T09:07:27Z","title":"A Practical Upper Bound for the Worst-Case Attribution Deviations","summary":"  Model attribution is a critical component of deep neural networks (DNNs) for\nits interpretability to complex models. Recent studies bring up attention to\nthe security of attribution methods as they are vulnerable to attribution\nattacks that generate similar images with dramatically different attributions.\nExisting works have been investigating empirically improving the robustness of\nDNNs against those attacks; however, none of them explicitly quantifies the\nactual deviations of attributions. In this work, for the first time, a\nconstrained optimization problem is formulated to derive an upper bound that\nmeasures the largest dissimilarity of attributions after the samples are\nperturbed by any noises within a certain region while the classification\nresults remain the same. Based on the formulation, different practical\napproaches are introduced to bound the attributions above using Euclidean\ndistance and cosine similarity under both $\\ell_2$ and $\\ell_\\infty$-norm\nperturbations constraints. The bounds developed by our theoretical study are\nvalidated on various datasets and two different types of attacks (PGD attack\nand IFIA attribution attack). Over 10 million attacks in the experiments\nindicate that the proposed upper bounds effectively quantify the robustness of\nmodels based on the worst-case attribution dissimilarities.\n","authors":["Fan Wang","Adams Wai-Kin Kong"],"pdf_url":"https://arxiv.org/pdf/2303.00340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14415v2","updated":"2023-03-01T09:07:01Z","published":"2023-02-28T08:47:53Z","title":"Mesh-SORT: Simple and effective of location-wise tracker","summary":"  In recent years, Multi-Object Tracking (MOT) has gained increased attention\ndue to its potential applications in traffic and person detection. We have\nobserved that in most tracking scenarios, objects tend to move and be lost\nwithin specific locations. To address this, we propose different strategies for\ntracking and association that can identify and target these regions.\nAdditionally, we note that tracking by detection may be impacted by errors in\nthe detector, such as an imprecise bounding box. To counter this, we present a\nrobust strategy for dealing with lost objects, as well as a location-wise\nmethod for tracking by detection that includes three improvements in lost\ntracklet management. Resulting Mesh-SORT, it gives mesh division for the\noriginal frame, and applying strategies for differentiation. Experiments\ndemonstrate the potential of our approach and the improvements it provides over\nthe baseline.\n","authors":["ZongTan Li"],"pdf_url":"https://arxiv.org/pdf/2302.14415v2.pdf","comment":"10 pages 16 figs"},{"id":"http://arxiv.org/abs/2303.00337v1","updated":"2023-03-01T09:03:44Z","published":"2023-03-01T09:03:44Z","title":"TAU: A Framework for Video-Based Traffic Analytics Leveraging Artificial\n  Intelligence and Unmanned Aerial Systems","summary":"  Smart traffic engineering and intelligent transportation services are in\nincreasing demand from governmental authorities to optimize traffic performance\nand thus reduce energy costs, increase the drivers' safety and comfort, ensure\ntraffic laws enforcement, and detect traffic violations. In this paper, we\naddress this challenge, and we leverage the use of Artificial Intelligence (AI)\nand Unmanned Aerial Vehicles (UAVs) to develop an AI-integrated video analytics\nframework, called TAU (Traffic Analysis from UAVs), for automated traffic\nanalytics and understanding. Unlike previous works on traffic video analytics,\nwe propose an automated object detection and tracking pipeline from video\nprocessing to advanced traffic understanding using high-resolution UAV images.\nTAU combines six main contributions. First, it proposes a pre-processing\nalgorithm to adapt the high-resolution UAV image as input to the object\ndetector without lowering the resolution. This ensures an excellent detection\naccuracy from high-quality features, particularly the small size of detected\nobjects from UAV images. Second, it introduces an algorithm for recalibrating\nthe vehicle coordinates to ensure that vehicles are uniquely identified and\ntracked across the multiple crops of the same frame. Third, it presents a speed\ncalculation algorithm based on accumulating information from successive frames.\nFourth, TAU counts the number of vehicles per traffic zone based on the Ray\nTracing algorithm. Fifth, TAU has a fully independent algorithm for crossroad\narbitration based on the data gathered from the different zones surrounding it.\nSixth, TAU introduces a set of algorithms for extracting twenty-four types of\ninsights from the raw data collected. The code is shared here:\nhttps://github.com/bilel-bj/TAU. Video demonstrations are provided here:\nhttps://youtu.be/wXJV0H7LviU and here: https://youtu.be/kGv0gmtVEbI.\n","authors":["Bilel Benjdira","Anis Koubaa","Ahmad Taher Azar","Zahid Khan","Adel Ammar","Wadii Boulila"],"pdf_url":"https://arxiv.org/pdf/2303.00337v1.pdf","comment":"This is the final proofread version submitted to Elsevier EAAI:\n  please see the published version at:\n  https://doi.org/10.1016/j.engappai.2022.105095"},{"id":"http://arxiv.org/abs/2303.00334v1","updated":"2023-03-01T08:54:56Z","published":"2023-03-01T08:54:56Z","title":"Online Video Streaming Super-Resolution with Adaptive Look-Up Table\n  Fusion","summary":"  This paper focuses on Super-resolution for online video streaming data.\nApplying existing super-resolution methods to video streaming data is\nnon-trivial for two reasons. First, to support application with constant\ninteractions, video streaming has a high requirement for latency that most\nexisting methods are less applicable, especially on low-end devices. Second,\nexisting video streaming protocols (e.g., WebRTC) dynamically adapt the video\nquality to the network condition, thus video streaming in the wild varies\ngreatly under different network bandwidths, which leads to diverse and dynamic\ndegradations. To tackle the above two challenges, we proposed a novel video\nsuper-resolution method for online video streaming. First, we incorporate\nLook-Up Table (LUT) to lightweight convolution modules to achieve real-time\nlatency. Second, for variant degradations, we propose a pixel-level LUT fusion\nstrategy, where a set of LUT bases are built upon state-of-the-art SR networks\npre-trained on different degraded data, and those LUT bases are combined with\nextracted weights from lightweight convolution modules to adaptively handle\ndynamic degradations. Extensive experiments are conducted on a newly proposed\nonline video streaming dataset named LDV-WebRTC. All the results show that our\nmethod significantly outperforms existing LUT-based methods and offers\ncompetitive SR performance with faster speed compared to efficient CNN-based\nmethods. Accelerated with our parallel LUT inference, our proposed method can\neven support online 720P video SR around 100 FPS.\n","authors":["Guanghao Yin","Xinyang Jiang","Shan Jiang","Zhenhua Han","Ningxin Zheng","Huan Yang","Donglin Bai","Haisheng Tan","Shouqian Sun","Yuqing Yang","Dongsheng Li","Lili Qiu"],"pdf_url":"https://arxiv.org/pdf/2303.00334v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00326v1","updated":"2023-03-01T08:43:05Z","published":"2023-03-01T08:43:05Z","title":"Empowering Networks With Scale and Rotation Equivariance Using A\n  Similarity Convolution","summary":"  The translational equivariant nature of Convolutional Neural Networks (CNNs)\nis a reason for its great success in computer vision. However, networks do not\nenjoy more general equivariance properties such as rotation or scaling,\nultimately limiting their generalization performance. To address this\nlimitation, we devise a method that endows CNNs with simultaneous equivariance\nwith respect to translation, rotation, and scaling. Our approach defines a\nconvolution-like operation and ensures equivariance based on our proposed\nscalable Fourier-Argand representation. The method maintains similar efficiency\nas a traditional network and hardly introduces any additional learnable\nparameters, since it does not face the computational issue that often occurs in\ngroup-convolution operators. We validate the efficacy of our approach in the\nimage classification task, demonstrating its robustness and the generalization\nability to both scaled and rotated inputs.\n","authors":["Zikai Sun","Thierry Blu"],"pdf_url":"https://arxiv.org/pdf/2303.00326v1.pdf","comment":"Accepted for ICLR 2023"},{"id":"http://arxiv.org/abs/2303.00319v1","updated":"2023-03-01T08:32:44Z","published":"2023-03-01T08:32:44Z","title":"RIFT2: Speeding-up RIFT with A New Rotation-Invariance Technique","summary":"  Multimodal image matching is an important prerequisite for multisource image\ninformation fusion. Compared with the traditional matching problem, multimodal\nfeature matching is more challenging due to the severe nonlinear radiation\ndistortion (NRD). Radiation-variation insensitive feature transform\n(RIFT)~\\cite{li2019rift} has shown very good robustness to NRD and become a\nbaseline method in multimodal feature matching. However, the high computational\ncost for rotation invariance largely limits its usage in practice. In this\npaper, we propose an improved RIFT method, called RIFT2. We develop a new\nrotation invariance technique based on dominant index value, which avoids the\nconstruction process of convolution sequence ring. Hence, it can speed up the\nrunning time and reduce the memory consumption of the original RIFT by almost 3\ntimes in theory. Extensive experiments show that RIFT2 achieves similar\nmatching performance to RIFT while being much faster and having less memory\nconsumption. The source code will be made publicly available in\n\\url{https://github.com/LJY-RS/RIFT2-multimodal-matching-rotation}\n","authors":["Jiayuan Li","Pengcheng Shi","Qingwu Hu","Yongjun Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.00319v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.00372v2","updated":"2023-03-01T08:20:17Z","published":"2021-07-01T11:16:44Z","title":"Egocentric Image Captioning for Privacy-Preserved Passive Dietary Intake\n  Monitoring","summary":"  Camera-based passive dietary intake monitoring is able to continuously\ncapture the eating episodes of a subject, recording rich visual information,\nsuch as the type and volume of food being consumed, as well as the eating\nbehaviours of the subject. However, there currently is no method that is able\nto incorporate these visual clues and provide a comprehensive context of\ndietary intake from passive recording (e.g., is the subject sharing food with\nothers, what food the subject is eating, and how much food is left in the\nbowl). On the other hand, privacy is a major concern while egocentric wearable\ncameras are used for capturing. In this paper, we propose a privacy-preserved\nsecure solution (i.e., egocentric image captioning) for dietary assessment with\npassive monitoring, which unifies food recognition, volume estimation, and\nscene understanding. By converting images into rich text descriptions,\nnutritionists can assess individual dietary intake based on the captions\ninstead of the original images, reducing the risk of privacy leakage from\nimages. To this end, an egocentric dietary image captioning dataset has been\nbuilt, which consists of in-the-wild images captured by head-worn and\nchest-worn cameras in field studies in Ghana. A novel transformer-based\narchitecture is designed to caption egocentric dietary images. Comprehensive\nexperiments have been conducted to evaluate the effectiveness and to justify\nthe design of the proposed architecture for egocentric dietary image\ncaptioning. To the best of our knowledge, this is the first work that applies\nimage captioning for dietary intake assessment in real life settings.\n","authors":["Jianing Qiu","Frank P. -W. Lo","Xiao Gu","Modou L. Jobarteh","Wenyan Jia","Tom Baranowski","Matilda Steiner-Asiedu","Alex K. Anderson","Megan A McCrory","Edward Sazonov","Mingui Sun","Gary Frost","Benny Lo"],"pdf_url":"https://arxiv.org/pdf/2107.00372v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.12886v2","updated":"2023-03-01T08:18:42Z","published":"2022-11-23T11:44:35Z","title":"OReX: Object Reconstruction from Planar Cross-sections Using Neural\n  Fields","summary":"  Reconstructing 3D shapes from planar cross-sections is a challenge inspired\nby downstream applications like medical imaging and geographic informatics. The\ninput is an in/out indicator function fully defined on a sparse collection of\nplanes in space, and the output is an interpolation of the indicator function\nto the entire volume. Previous works addressing this sparse and ill-posed\nproblem either produce low quality results, or rely on additional priors such\nas target topology, appearance information, or input normal directions. In this\npaper, we present OReX, a method for 3D shape reconstruction from slices alone,\nfeaturing a Neural Field as the interpolation prior. A simple neural network is\ntrained on the input planes to receive a 3D coordinate and return an\ninside/outside estimate for the query point. This prior is powerful in inducing\nsmoothness and self-similarities. The main challenge for this approach is\nhigh-frequency details, as the neural prior is overly smoothing. To alleviate\nthis, we offer an iterative estimation architecture and a hierarchical input\nsampling scheme that encourage coarse-to-fine training, allowing focusing on\nhigh frequencies at later stages. In addition, we identify and analyze a common\nripple-like effect stemming from the mesh extraction step. We mitigate it by\nregularizing the spatial gradients of the indicator function around input\nin/out boundaries, cutting the problem at the root.\n  Through extensive qualitative and quantitative experimentation, we\ndemonstrate our method is robust, accurate, and scales well with the size of\nthe input. We report state-of-the-art results compared to previous approaches\nand recent potential solutions, and demonstrate the benefit of our individual\ncontributions through analysis and ablation studies.\n","authors":["Haim Sawdayee","Amir Vaxman","Amit H. Bermano"],"pdf_url":"https://arxiv.org/pdf/2211.12886v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00308v1","updated":"2023-03-01T08:13:26Z","published":"2023-03-01T08:13:26Z","title":"Event Fusion Photometric Stereo Network","summary":"  We introduce a novel method to estimate surface normal of an object in an\nambient light environment using RGB and event cameras. Modern photometric\nstereo methods rely on RGB cameras in a darkroom to avoid ambient illumination.\nTo alleviate the limitations of using an RGB camera in a darkroom setting, we\nutilize an event camera with high dynamic range and low latency by capturing\nessential light information. This is the first study to use event cameras for\nphotometric stereo in continuous light sources and ambient light environments.\nAdditionally, we curate a new photometric stereo dataset captured by RGB and\nevent cameras under various ambient lights. Our proposed framework, Event\nFusion Photometric Stereo Network (EFPS-Net), estimates surface normals using\nRGB frames and event signals. EFPS-Net outperforms state-of-the-art methods on\na real-world dataset with ambient lights, demonstrating the effectiveness of\nincorporating additional modalities to alleviate limitations caused by ambient\nillumination.\n","authors":["Wonjeong Ryoo","Giljoo Nam","Jae-Sang Hyun","Sangpil Kim"],"pdf_url":"https://arxiv.org/pdf/2303.00308v1.pdf","comment":"35 pages, 11 figures"},{"id":"http://arxiv.org/abs/2302.14350v2","updated":"2023-03-01T08:12:08Z","published":"2023-02-28T06:59:05Z","title":"Knowledge Augmented Relation Inference for Group Activity Recognition","summary":"  Most existing group activity recognition methods construct spatial-temporal\nrelations merely based on visual representation. Some methods introduce extra\nknowledge, such as action labels, to build semantic relations and use them to\nrefine the visual presentation. However, the knowledge they explored just stay\nat the semantic-level, which is insufficient for pursing notable accuracy. In\nthis paper, we propose to exploit knowledge concretization for the group\nactivity recognition, and develop a novel Knowledge Augmented Relation\nInference framework that can effectively use the concretized knowledge to\nimprove the individual representations. Specifically, the framework consists of\na Visual Representation Module to extract individual appearance features, a\nKnowledge Augmented Semantic Relation Module explore semantic representations\nof individual actions, and a Knowledge-Semantic-Visual Interaction Module aims\nto integrate visual and semantic information by the knowledge. Benefiting from\nthese modules, the proposed framework can utilize knowledge to enhance the\nrelation inference process and the individual representations, thus improving\nthe performance of group activity recognition. Experimental results on two\npublic datasets show that the proposed framework achieves competitive\nperformance compared with state-of-the-art methods.\n","authors":["Xianglong Lang","Zhuming Wang","Zun Li","Meng Tian","Ge Shi","Lifang Wu","Liang Wang"],"pdf_url":"https://arxiv.org/pdf/2302.14350v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.12428v3","updated":"2023-03-01T08:05:18Z","published":"2022-08-26T03:53:04Z","title":"Robust Prototypical Few-Shot Organ Segmentation with Regularized\n  Neural-ODEs","summary":"  Despite the tremendous progress made by deep learning models in image\nsemantic segmentation, they typically require large annotated examples, and\nincreasing attention is being diverted to problem settings like Few-Shot\nLearning (FSL) where only a small amount of annotation is needed for\ngeneralisation to novel classes. This is especially seen in medical domains\nwhere dense pixel-level annotations are expensive to obtain. In this paper, we\npropose Regularized Prototypical Neural Ordinary Differential Equation\n(R-PNODE), a method that leverages intrinsic properties of Neural-ODEs,\nassisted and enhanced by additional cluster and consistency losses to perform\nFew-Shot Segmentation (FSS) of organs. R-PNODE constrains support and query\nfeatures from the same classes to lie closer in the representation space\nthereby improving the performance over the existing Convolutional Neural\nNetwork (CNN) based FSS methods. We further demonstrate that while many\nexisting Deep CNN based methods tend to be extremely vulnerable to adversarial\nattacks, R-PNODE exhibits increased adversarial robustness for a wide array of\nthese attacks. We experiment with three publicly available multi-organ\nsegmentation datasets in both in-domain and cross-domain FSS settings to\ndemonstrate the efficacy of our method. In addition, we perform experiments\nwith seven commonly used adversarial attacks in various settings to demonstrate\nR-PNODE's robustness. R-PNODE outperforms the baselines for FSS by significant\nmargins and also shows superior performance for a wide array of attacks varying\nin intensity and design.\n","authors":["Prashant Pandey","Mustafa Chasmai","Tanuj Sur","Brejesh Lall"],"pdf_url":"https://arxiv.org/pdf/2208.12428v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00304v1","updated":"2023-03-01T08:00:46Z","published":"2023-03-01T08:00:46Z","title":"Renderable Neural Radiance Map for Visual Navigation","summary":"  We propose a novel type of map for visual navigation, a renderable neural\nradiance map (RNR-Map), which is designed to contain the overall visual\ninformation of a 3D environment. The RNR-Map has a grid form and consists of\nlatent codes at each pixel. These latent codes are embedded from image\nobservations, and can be converted to the neural radiance field which enables\nimage rendering given a camera pose. The recorded latent codes implicitly\ncontain visual information about the environment, which makes the RNR-Map\nvisually descriptive. This visual information in RNR-Map can be a useful\nguideline for visual localization and navigation. We develop localization and\nnavigation frameworks that can effectively utilize the RNR-Map. We evaluate the\nproposed frameworks on camera tracking, visual localization, and image-goal\nnavigation. Experimental results show that the RNR-Map-based localization\nframework can find the target location based on a single query image with fast\nspeed and competitive accuracy compared to other baselines. Also, this\nlocalization framework is robust to environmental changes, and even finds the\nmost visually similar places when a query image from a different environment is\ngiven. The proposed navigation framework outperforms the existing image-goal\nnavigation methods in difficult scenarios, under odometry and actuation noises.\nThe navigation framework shows 65.7% success rate in curved scenarios of the\nNRNS dataset, which is an improvement of 18.6% over the current\nstate-of-the-art.\n","authors":["Obin Kwon","Jeongho Park","Songhwai Oh"],"pdf_url":"https://arxiv.org/pdf/2303.00304v1.pdf","comment":"Preprint version, CVPR 2023 accepted. Supplementary Video:\n  https://youtu.be/DHlcKbVDt5A. This will be replaced by a camera-ready version\n  with some minor revisions"},{"id":"http://arxiv.org/abs/2303.00300v1","updated":"2023-03-01T07:50:34Z","published":"2023-03-01T07:50:34Z","title":"BiSVP: Building Footprint Extraction via Bidirectional Serialized Vertex\n  Prediction","summary":"  Extracting building footprints from remote sensing images has been attracting\nextensive attention recently. Dominant approaches address this challenging\nproblem by generating vectorized building masks with cumbersome refinement\nstages, which limits the application of such methods. In this paper, we\nintroduce a new refinement-free and end-to-end building footprint extraction\nmethod, which is conceptually intuitive, simple, and effective. Our method,\ntermed as BiSVP, represents a building instance with ordered vertices and\nformulates the building footprint extraction as predicting the serialized\nvertices directly in a bidirectional fashion. Moreover, we propose a\ncross-scale feature fusion (CSFF) module to facilitate high resolution and rich\nsemantic feature learning, which is essential for the dense building vertex\nprediction task. Without bells and whistles, our BiSVP outperforms\nstate-of-the-art methods by considerable margins on three building instance\nsegmentation benchmarks, clearly demonstrating its superiority. The code and\ndatasets will be made public available.\n","authors":["Mingming Zhang","Ye Du","Zhenghui Hu","Qingjie Liu","Yunhong Wang"],"pdf_url":"https://arxiv.org/pdf/2303.00300v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14348v2","updated":"2023-03-01T07:50:20Z","published":"2023-02-28T06:38:25Z","title":"Im2Hands: Learning Attentive Implicit Representation of Interacting\n  Two-Hand Shapes","summary":"  We present Implicit Two Hands (Im2Hands), the first neural implicit\nrepresentation of two interacting hands. Unlike existing methods on two-hand\nreconstruction that rely on a parametric hand model and/or low-resolution\nmeshes, Im2Hands can produce fine-grained geometry of two hands with high\nhand-to-hand and hand-to-image coherency. To handle the shape complexity and\ninteraction context between two hands, Im2Hands models the occupancy volume of\ntwo hands - conditioned on an RGB image and coarse 3D keypoints - by two novel\nattention-based modules responsible for (1) initial occupancy estimation and\n(2) context-aware occupancy refinement, respectively. Im2Hands first learns\nper-hand neural articulated occupancy in the canonical space designed for each\nhand using query-image attention. It then refines the initial two-hand\noccupancy in the posed space to enhance the coherency between the two hand\nshapes using query-anchor attention. In addition, we introduce an optional\nkeypoint refinement module to enable robust two-hand shape estimation from\npredicted hand keypoints in a single-image reconstruction scenario. We\nexperimentally demonstrate the effectiveness of Im2Hands on two-hand\nreconstruction in comparison to related methods, where ours achieves\nstate-of-the-art results. Our code is publicly available at\nhttps://github.com/jyunlee/Im2Hands.\n","authors":["Jihyun Lee","Minhyuk Sung","Honggyu Choi","Tae-Kyun Kim"],"pdf_url":"https://arxiv.org/pdf/2302.14348v2.pdf","comment":"6 figures, 14 pages, accepted to CVPR 2023, project page:\n  https://jyunlee.github.io/projects/implicit-two-hands/"},{"id":"http://arxiv.org/abs/2303.00298v1","updated":"2023-03-01T07:48:01Z","published":"2023-03-01T07:48:01Z","title":"Capturing the motion of every joint: 3D human pose and shape estimation\n  with independent tokens","summary":"  In this paper we present a novel method to estimate 3D human pose and shape\nfrom monocular videos. This task requires directly recovering pixel-alignment\n3D human pose and body shape from monocular images or videos, which is\nchallenging due to its inherent ambiguity. To improve precision, existing\nmethods highly rely on the initialized mean pose and shape as prior estimates\nand parameter regression with an iterative error feedback manner. In addition,\nvideo-based approaches model the overall change over the image-level features\nto temporally enhance the single-frame feature, but fail to capture the\nrotational motion at the joint level, and cannot guarantee local temporal\nconsistency. To address these issues, we propose a novel Transformer-based\nmodel with a design of independent tokens. First, we introduce three types of\ntokens independent of the image feature: \\textit{joint rotation tokens, shape\ntoken, and camera token}. By progressively interacting with image features\nthrough Transformer layers, these tokens learn to encode the prior knowledge of\nhuman 3D joint rotations, body shape, and position information from large-scale\ndata, and are updated to estimate SMPL parameters conditioned on a given image.\nSecond, benefiting from the proposed token-based representation, we further use\na temporal model to focus on capturing the rotational temporal information of\neach joint, which is empirically conducive to preventing large jitters in local\nparts. Despite being conceptually simple, the proposed method attains superior\nperformances on the 3DPW and Human3.6M datasets. Using ResNet-50 and\nTransformer architectures, it obtains 42.0 mm error on the PA-MPJPE metric of\nthe challenging 3DPW, outperforming state-of-the-art counterparts by a large\nmargin. Code will be publicly available at\nhttps://github.com/yangsenius/INT_HMR_Model\n","authors":["Sen Yang","Wen Heng","Gang Liu","Guozhong Luo","Wankou Yang","Gang Yu"],"pdf_url":"https://arxiv.org/pdf/2303.00298v1.pdf","comment":"17 pages, 12 figures. ICLR 2023 (spotlight)"},{"id":"http://arxiv.org/abs/2207.12988v2","updated":"2023-03-01T07:41:59Z","published":"2022-07-26T15:48:46Z","title":"Monocular 3D Object Detection with Depth from Motion","summary":"  Perceiving 3D objects from monocular inputs is crucial for robotic systems,\ngiven its economy compared to multi-sensor settings. It is notably difficult as\na single image can not provide any clues for predicting absolute depth values.\nMotivated by binocular methods for 3D object detection, we take advantage of\nthe strong geometry structure provided by camera ego-motion for accurate object\ndepth estimation and detection. We first make a theoretical analysis on this\ngeneral two-view case and notice two challenges: 1) Cumulative errors from\nmultiple estimations that make the direct prediction intractable; 2) Inherent\ndilemmas caused by static cameras and matching ambiguity. Accordingly, we\nestablish the stereo correspondence with a geometry-aware cost volume as the\nalternative for depth estimation and further compensate it with monocular\nunderstanding to address the second problem. Our framework, named Depth from\nMotion (DfM), then uses the established geometry to lift 2D image features to\nthe 3D space and detects 3D objects thereon. We also present a pose-free DfM to\nmake it usable when the camera pose is unavailable. Our framework outperforms\nstate-of-the-art methods by a large margin on the KITTI benchmark. Detailed\nquantitative and qualitative analyses also validate our theoretical\nconclusions. The code will be released at\nhttps://github.com/Tai-Wang/Depth-from-Motion.\n","authors":["Tai Wang","Jiangmiao Pang","Dahua Lin"],"pdf_url":"https://arxiv.org/pdf/2207.12988v2.pdf","comment":"ECCV 2022 Oral"},{"id":"http://arxiv.org/abs/2012.08950v5","updated":"2023-03-01T07:35:43Z","published":"2020-12-16T13:48:48Z","title":"Revocable Deep Reinforcement Learning with Affinity Regularization for\n  Outlier-Robust Graph Matching","summary":"  Graph matching (GM) has been a building block in various areas including\ncomputer vision and pattern recognition. Despite recent impressive progress,\nexisting deep GM methods often have obvious difficulty in handling outliers,\nwhich are ubiquitous in practice. We propose a deep reinforcement learning\nbased approach RGM, whose sequential node matching scheme naturally fits the\nstrategy for selective inlier matching against outliers. A revocable action\nframework is devised to improve the agent's flexibility against the complex\nconstrained GM. Moreover, we propose a quadratic approximation technique to\nregularize the affinity score, in the presence of outliers. As such, the agent\ncan finish inlier matching timely when the affinity score stops growing, for\nwhich otherwise an additional parameter i.e. the number of inliers is needed to\navoid matching outliers. In this paper, we focus on learning the back-end\nsolver under the most general form of GM: the Lawler's QAP, whose input is the\naffinity matrix. Especially, our approach can also boost existing GM methods\nthat use such input. Experiments on multiple real-world datasets demonstrate\nits performance regarding both accuracy and robustness.\n","authors":["Chang Liu","Zetian Jiang","Runzhong Wang","Junchi Yan","Lingxiao Huang","Pinyan Lu"],"pdf_url":"https://arxiv.org/pdf/2012.08950v5.pdf","comment":"Proceedings of The Eleventh International Conference on Learning\n  Representations (ICLR 2023)"},{"id":"http://arxiv.org/abs/2303.00289v1","updated":"2023-03-01T07:32:51Z","published":"2023-03-01T07:32:51Z","title":"StrucTexTv2: Masked Visual-Textual Prediction for Document Image\n  Pre-training","summary":"  In this paper, we present StrucTexTv2, an effective document image\npre-training framework, by performing masked visual-textual prediction. It\nconsists of two self-supervised pre-training tasks: masked image modeling and\nmasked language modeling, based on text region-level image masking. The\nproposed method randomly masks some image regions according to the bounding box\ncoordinates of text words. The objectives of our pre-training tasks are\nreconstructing the pixels of masked image regions and the corresponding masked\ntokens simultaneously. Hence the pre-trained encoder can capture more textual\nsemantics in comparison to the masked image modeling that usually predicts the\nmasked image patches. Compared to the masked multi-modal modeling methods for\ndocument image understanding that rely on both the image and text modalities,\nStrucTexTv2 models image-only input and potentially deals with more application\nscenarios free from OCR pre-processing. Extensive experiments on mainstream\nbenchmarks of document image understanding demonstrate the effectiveness of\nStrucTexTv2. It achieves competitive or even new state-of-the-art performance\nin various downstream tasks such as image classification, layout analysis,\ntable structure recognition, document OCR, and information extraction under the\nend-to-end scenario.\n","authors":["Yuechen Yu","Yulin Li","Chengquan Zhang","Xiaoqiang Zhang","Zengyuan Guo","Xiameng Qin","Kun Yao","Junyu Han","Errui Ding","Jingdong Wang"],"pdf_url":"https://arxiv.org/pdf/2303.00289v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.00284v1","updated":"2023-03-01T07:22:39Z","published":"2023-03-01T07:22:39Z","title":"To Make Yourself Invisible with Adversarial Semantic Contours","summary":"  Modern object detectors are vulnerable to adversarial examples, which may\nbring risks to real-world applications. The sparse attack is an important task\nwhich, compared with the popular adversarial perturbation on the whole image,\nneeds to select the potential pixels that is generally regularized by an\n$\\ell_0$-norm constraint, and simultaneously optimize the corresponding\ntexture. The non-differentiability of $\\ell_0$ norm brings challenges and many\nworks on attacking object detection adopted manually-designed patterns to\naddress them, which are meaningless and independent of objects, and therefore\nlead to relatively poor attack performance.\n  In this paper, we propose Adversarial Semantic Contour (ASC), an MAP estimate\nof a Bayesian formulation of sparse attack with a deceived prior of object\ncontour. The object contour prior effectively reduces the search space of pixel\nselection and improves the attack by introducing more semantic bias. Extensive\nexperiments demonstrate that ASC can corrupt the prediction of 9 modern\ndetectors with different architectures (\\e.g., one-stage, two-stage and\nTransformer) by modifying fewer than 5\\% of the pixels of the object area in\nCOCO in white-box scenario and around 10\\% of those in black-box scenario. We\nfurther extend the attack to datasets for autonomous driving systems to verify\nthe effectiveness. We conclude with cautions about contour being the common\nweakness of object detectors with various architecture and the care needed in\napplying them in safety-sensitive scenarios.\n","authors":["Yichi Zhang","Zijian Zhu","Hang Su","Jun Zhu","Shibao Zheng","Yuan He","Hui Xue"],"pdf_url":"https://arxiv.org/pdf/2303.00284v1.pdf","comment":"11 pages, 7 figures, published in Computer Vision and Image\n  Understanding in 2023"},{"id":"http://arxiv.org/abs/2302.12172v3","updated":"2023-03-01T07:11:16Z","published":"2023-02-23T17:13:25Z","title":"Unified Chest X-ray and Radiology Report Generation Model with\n  Multi-view Chest X-rays","summary":"  Generated synthetic data in medical research can substitute privacy and\nsecurity-sensitive data with a large-scale curated dataset, reducing data\ncollection and annotation costs. As part of this effort, we propose UniXGen, a\nunified chest X-ray and report generation model, with the following\ncontributions. First, we design a unified model for bidirectional chest X-ray\nand report generation by adopting a vector quantization method to discretize\nchest X-rays into discrete visual tokens and formulating both tasks as sequence\ngeneration tasks. Second, we introduce several special tokens to generate chest\nX-rays with specific views that can be useful when the desired views are\nunavailable. Furthermore, UniXGen can flexibly take various inputs from single\nto multiple views to take advantage of the additional findings available in\nother X-ray views. We adopt an efficient transformer for computational and\nmemory efficiency to handle the long-range input sequence of multi-view chest\nX-rays with high resolution and long paragraph reports. In extensive\nexperiments, we show that our unified model has a synergistic effect on both\ngeneration tasks, as opposed to training only the task-specific models. We also\nfind that view-specific special tokens can distinguish between different views\nand properly generate specific views even if they do not exist in the dataset,\nand utilizing multi-view chest X-rays can faithfully capture the abnormal\nfindings in the additional X-rays. The source code is publicly available at:\nhttps://github.com/ttumyche/UniXGen.\n","authors":["Hyungyung Lee","Da Young Lee","Wonjae Kim","Jin-Hwa Kim","Tackeun Kim","Jihang Kim","Leonard Sunwoo","Edward Choi"],"pdf_url":"https://arxiv.org/pdf/2302.12172v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.03741v3","updated":"2023-03-01T07:09:41Z","published":"2022-12-07T16:10:08Z","title":"Magic: Multi Art Genre Intelligent Choreography Dataset and Network for\n  3D Dance Generation","summary":"  Achieving multiple genres and long-term choreography sequences from given\nmusic is a challenging task, due to the lack of a multi-genre dataset. To\ntackle this problem,we propose a Multi Art Genre Intelligent Choreography\nDataset (MagicDance). The data of MagicDance is captured from professional\ndancers assisted by motion capture technicians. It has a total of 8 hours 3D\nmotioncapture human dances with paired music, and 16 different dance genres. To\nthe best of our knowledge, MagicDance is the 3D dance dataset with the most\ngenres. In addition, we find that the existing two types of methods\n(generation-based method and synthesis-based method) can only satisfy one of\nthe diversity and duration, but they can complement to some extent. Based on\nthis observation, we also propose a generation-synthesis choreography network\n(MagicNet), which cascades a Diffusion-based 3D Diverse Dance fragments\nGeneration Network (3DGNet) and a Genre&Coherent aware Retrieval Module (GCRM).\nThe former can generate various dance fragments from only one music clip. The\nlatter is utilized to select the best dance fragment generated by 3DGNet and\nswitch them into a complete dance according to the genre and coherent matching\nscore. Quantitative and qualitative experiments demonstrate the quality of\nMagicDance, and the state-of-the-art performance of MagicNet.\n","authors":["Ronghui Li","Junfan Zhao","Yachao Zhang","Mingyang Su","Zeping Ren","Han Zhang","Xiu Li"],"pdf_url":"https://arxiv.org/pdf/2212.03741v3.pdf","comment":"We realize that there are methods and experiments that better support\n  our conclusions, so we decide to withdraw this release and investigate this\n  further in future work"},{"id":"http://arxiv.org/abs/2303.00279v1","updated":"2023-03-01T07:01:29Z","published":"2023-03-01T07:01:29Z","title":"Coarse-to-Fine Covid-19 Segmentation via Vision-Language Alignment","summary":"  Segmentation of COVID-19 lesions can assist physicians in better diagnosis\nand treatment of COVID-19. However, there are few relevant studies due to the\nlack of detailed information and high-quality annotation in the COVID-19\ndataset. To solve the above problem, we propose C2FVL, a Coarse-to-Fine\nsegmentation framework via Vision-Language alignment to merge text information\ncontaining the number of lesions and specific locations of image information.\nThe introduction of text information allows the network to achieve better\nprediction results on challenging datasets. We conduct extensive experiments on\ntwo COVID-19 datasets including chest X-ray and CT, and the results demonstrate\nthat our proposed method outperforms other state-of-the-art segmentation\nmethods.\n","authors":["Dandan Shan","Zihan Li","Wentao Chen","Qingde Li","Jie Tian","Qingqi Hong"],"pdf_url":"https://arxiv.org/pdf/2303.00279v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.00262v1","updated":"2023-03-01T06:35:42Z","published":"2023-03-01T06:35:42Z","title":"Collage Diffusion","summary":"  Text-conditional diffusion models generate high-quality, diverse images.\nHowever, text is often an ambiguous specification for a desired target image,\ncreating the need for additional user-friendly controls for diffusion-based\nimage generation. We focus on having precise control over image output for\nscenes with several objects. Users control image generation by defining a\ncollage: a text prompt paired with an ordered sequence of layers, where each\nlayer is an RGBA image and a corresponding text prompt. We introduce Collage\nDiffusion, a collage-conditional diffusion algorithm that allows users to\ncontrol both the spatial arrangement and visual attributes of objects in the\nscene, and also enables users to edit individual components of generated\nimages. To ensure that different parts of the input text correspond to the\nvarious locations specified in the input collage layers, Collage Diffusion\nmodifies text-image cross-attention with the layers' alpha masks. To maintain\ncharacteristics of individual collage layers that are not specified in text,\nCollage Diffusion learns specialized text representations per layer. Collage\ninput also enables layer-based controls that provide fine-grained control over\nthe final output: users can control image harmonization on a layer-by-layer\nbasis, and they can edit individual objects in generated images while keeping\nother objects fixed. Collage-conditional image generation requires harmonizing\nthe input collage to make objects fit together--the key challenge involves\nminimizing changes in the positions and key visual attributes of objects in the\ninput collage while allowing other attributes of the collage to change in the\nharmonization process. By leveraging the rich information present in layer\ninput, Collage Diffusion generates globally harmonized images that maintain\ndesired object locations and visual characteristics better than prior\napproaches.\n","authors":["Vishnu Sarukkai","Linden Li","Arden Ma","Christopher Ré","Kayvon Fatahalian"],"pdf_url":"https://arxiv.org/pdf/2303.00262v1.pdf","comment":"26 pages, 20 figures"},{"id":"http://arxiv.org/abs/2303.00261v1","updated":"2023-03-01T06:35:29Z","published":"2023-03-01T06:35:29Z","title":"Speeding Up EfficientNet: Selecting Update Blocks of Convolutional\n  Neural Networks using Genetic Algorithm in Transfer Learning","summary":"  The performance of convolutional neural networks (CNN) depends heavily on\ntheir architectures. Transfer learning performance of a CNN relies quite\nstrongly on selection of its trainable layers. Selecting the most effective\nupdate layers for a certain target dataset often requires expert knowledge on\nCNN architecture which many practitioners do not posses. General users prefer\nto use an available architecture (e.g. GoogleNet, ResNet, EfficientNet etc.)\nthat is developed by domain experts. With the ever-growing number of layers, it\nis increasingly becoming quite difficult and cumbersome to handpick the update\nlayers. Therefore, in this paper we explore the application of genetic\nalgorithm to mitigate this problem. The convolutional layers of popular\npretrained networks are often grouped into modules that constitute their\nbuilding blocks. We devise a genetic algorithm to select blocks of layers for\nupdating the parameters. By experimenting with EfficientNetB0 pre-trained on\nImageNet and using Food-101, CIFAR-100 and MangoLeafBD as target datasets, we\nshow that our algorithm yields similar or better results than the baseline in\nterms of accuracy, and requires lower training and evaluation time due to\nlearning less number of parameters. We also devise a metric called block\nimportance to measure efficacy of each block as update block and analyze the\nimportance of the blocks selected by our algorithm.\n","authors":["Md. Mehedi Hasana","Muhammad Ibrahim","Md. Sawkat Ali"],"pdf_url":"https://arxiv.org/pdf/2303.00261v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2209.06954v2","updated":"2023-03-01T06:28:54Z","published":"2022-09-14T22:04:10Z","title":"Correlation Information Bottleneck: Towards Adapting Pretrained\n  Multimodal Models for Robust Visual Question Answering","summary":"  Benefiting from large-scale pretrained vision language models (VLMs), the\nperformance of Visual Question Answering (VQA) has approached human oracle\nperformance. However, finetuning large-scale pretrained VLMs with limited data\nusually suffers from overfitting and poor generalization issues, leading to a\nlack of model robustness. In this paper, we aim to improve the input\nrobustness, \\ie the ability of models to defend against visual and linguistic\ninput variations as well as shortcut learning involved in inputs, from the\nperspective of Information Bottleneck when adapting pretrained VLMs to the\ndownstream VQA task. Generally, internal representations obtained by pretrained\nVLMs inevitably contain irrelevant and redundant information for a specific\ndownstream task, resulting in statistically spurious correlations and\ninsensitivity to input variations. To encourage the obtained representations to\nconverge to a minimal sufficient statistic in vision-language learning, we\npropose the Correlation Information Bottleneck (CIB) principle, which seeks a\ntradeoff between representation compression and redundancy by minimizing the\nmutual information (MI) between inputs and internal representations while\nmaximizing the MI between outputs and the representations. Furthermore, CIB\nmeasures the internal correlations among visual and linguistic inputs and\nrepresentations via a symmetrized joint MI estimation. Extensive experiments on\nfive VQA datasets of input robustness demonstrate the effectiveness and\nsuperiority of the proposed CIB in terms of robustness and accuracy.\n","authors":["Jingjing Jiang","Ziyi Liu","Nanning Zheng"],"pdf_url":"https://arxiv.org/pdf/2209.06954v2.pdf","comment":"17 pages, 4 figures, 11 tables"},{"id":"http://arxiv.org/abs/2303.00246v1","updated":"2023-03-01T06:06:28Z","published":"2023-03-01T06:06:28Z","title":"ISBNet: a 3D Point Cloud Instance Segmentation Network with\n  Instance-aware Sampling and Box-aware Dynamic Convolution","summary":"  Existing 3D instance segmentation methods are predominated by the bottom-up\ndesign -- manually fine-tuned algorithm to group points into clusters followed\nby a refinement network. However, by relying on the quality of the clusters,\nthese methods generate susceptible results when (1) nearby objects with the\nsame semantic class are packed together, or (2) large objects with loosely\nconnected regions. To address these limitations, we introduce ISBNet, a novel\ncluster-free method that represents instances as kernels and decodes instance\nmasks via dynamic convolution. To efficiently generate high-recall and\ndiscriminative kernels, we propose a simple strategy named Instance-aware\nFarthest Point Sampling to sample candidates and leverage the local aggregation\nlayer inspired by PointNet++ to encode candidate features. Moreover, we show\nthat predicting and leveraging the 3D axis-aligned bounding boxes in the\ndynamic convolution further boosts performance. Our method set new\nstate-of-the-art results on ScanNetV2 (55.9), S3DIS (60.8), and STPLS3D (49.2)\nin terms of AP and retains fast inference time (237ms per scene on ScanNetV2).\n","authors":["Tuan Duc Ngo","Binh-Son Hua","Khoi Nguyen"],"pdf_url":"https://arxiv.org/pdf/2303.00246v1.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2210.01302v2","updated":"2023-03-01T06:00:47Z","published":"2022-10-04T01:40:31Z","title":"Nuisances via Negativa: Adjusting for Spurious Correlations via Data\n  Augmentation","summary":"  In prediction tasks, there exist features that are related to the label in\nthe same way across different settings for that task; these are semantic\nfeatures or semantics. Features with varying relationships to the label are\nnuisances. For example, in detecting cows from natural images, the shape of the\nhead is a semantic but because images of cows often have grass backgrounds but\nnot always, the background is a nuisance. Relationships between a nuisance and\nthe label are unstable across settings and, consequently, models that exploit\nnuisance-label relationships face performance degradation when these\nrelationships change. Direct knowledge of a nuisance helps build models that\nare robust to such changes, but requires extra annotations beyond labels and\ncovariates. In this paper, we develop an alternative way to produce robust\nmodels by data augmentation. These data augmentations corrupt semantic\ninformation to produce models that identify and adjust for where nuisances\ndrive predictions. We study semantic corruptions in powering different\nspurious-correlation avoiding methods on multiple out-of distribution (OOD)\ntasks like classifying waterbirds, natural language inference (NLI), and\ndetecting cardiomegaly in chest X-rays.\n","authors":["Aahlad Puli","Nitish Joshi","He He","Rajesh Ranganath"],"pdf_url":"https://arxiv.org/pdf/2210.01302v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00244v1","updated":"2023-03-01T05:54:52Z","published":"2023-03-01T05:54:52Z","title":"SUNY: A Visual Interpretation Framework for Convolutional Neural\n  Networks from a Necessary and Sufficient Perspective","summary":"  Researchers have proposed various methods for visually interpreting the\nConvolutional Neural Network (CNN) via saliency maps, which include\nClass-Activation-Map (CAM) based approaches as a leading family. However, in\nterms of the internal design logic, existing CAM-based approaches often\noverlook the causal perspective that answers the core \"why\" question to help\nhumans understand the explanation. Additionally, current CNN explanations lack\nthe consideration of both necessity and sufficiency, two complementary sides of\na desirable explanation. This paper presents a causality-driven framework,\nSUNY, designed to rationalize the explanations toward better human\nunderstanding. Using the CNN model's input features or internal filters as\nhypothetical causes, SUNY generates explanations by bi-directional\nquantifications on both the necessary and sufficient perspectives. Extensive\nevaluations justify that SUNY not only produces more informative and convincing\nexplanations from the angles of necessity and sufficiency, but also achieves\nperformances competitive to other approaches across different CNN architectures\nover large-scale datasets, including ILSVRC2012 and CUB-200-2011.\n","authors":["Xiwei Xuan","Ziquan Deng","Hsuan-Tien Lin","Zhaodan Kong","Kwan-Liu Ma"],"pdf_url":"https://arxiv.org/pdf/2303.00244v1.pdf","comment":"10 pages, 6 figures. This manuscript is currently under review"},{"id":"http://arxiv.org/abs/2209.14499v2","updated":"2023-03-01T05:45:02Z","published":"2022-09-29T01:30:34Z","title":"NVRadarNet: Real-Time Radar Obstacle and Free Space Detection for\n  Autonomous Driving","summary":"  Detecting obstacles is crucial for safe and efficient autonomous driving. To\nthis end, we present NVRadarNet, a deep neural network (DNN) that detects\ndynamic obstacles and drivable free space using automotive RADAR sensors. The\nnetwork utilizes temporally accumulated data from multiple RADAR sensors to\ndetect dynamic obstacles and compute their orientation in a top-down bird's-eye\nview (BEV). The network also regresses drivable free space to detect\nunclassified obstacles. Our DNN is the first of its kind to utilize sparse\nRADAR signals in order to perform obstacle and free space detection in real\ntime from RADAR data only. The network has been successfully used for\nperception on our autonomous vehicles in real self-driving scenarios. The\nnetwork runs faster than real time on an embedded GPU and shows good\ngeneralization across geographic regions.\n","authors":["Alexander Popov","Patrik Gebhardt","Ke Chen","Ryan Oldja","Heeseok Lee","Shane Murray","Ruchi Bhargava","Nikolai Smolyanskiy"],"pdf_url":"https://arxiv.org/pdf/2209.14499v2.pdf","comment":"7 pages, 6 figures, ICRA 2023 conference, for associated video file,\n  see https://youtu.be/WlwJJMltoJY"},{"id":"http://arxiv.org/abs/2303.00236v1","updated":"2023-03-01T05:07:48Z","published":"2023-03-01T05:07:48Z","title":"P$^2$SDF for Neural Indoor Scene Reconstruction","summary":"  Given only a set of images, neural implicit surface representation has shown\nits capability in 3D surface reconstruction. However, as the nature of\nper-scene optimization is based on the volumetric rendering of color, previous\nneural implicit surface reconstruction methods usually fail in low-textured\nregions, including the floors, walls, etc., which commonly exist for indoor\nscenes. Being aware of the fact that these low-textured regions usually\ncorrespond to planes, without introducing additional ground-truth supervisory\nsignals or making additional assumptions about the room layout, we propose to\nleverage a novel Pseudo Plane-regularized Signed Distance Field (P$^2$SDF) for\nindoor scene reconstruction. Specifically, we consider adjacent pixels with\nsimilar colors to be on the same pseudo planes. The plane parameters are then\nestimated on the fly during training by an efficient and effective two-step\nscheme. Then the signed distances of the points on the planes are regularized\nby the estimated plane parameters in the training phase. As the unsupervised\nplane segments are usually noisy and inaccurate, we propose to assign different\nweights to the sampled points on the plane in plane estimation as well as the\nregularization loss. The weights come by fusing the plane segments from\ndifferent views. As the sampled rays in the planar regions are redundant,\nleading to inefficient training, we further propose a keypoint-guided rays\nsampling strategy that attends to the informative textured regions with large\ncolor variations, and the implicit network gets a better reconstruction,\ncompared with the original uniform ray sampling strategy. Experiments show that\nour P$^2$SDF achieves competitive reconstruction performance in Manhattan\nscenes. Further, as we do not introduce any additional room layout assumption,\nour P$^2$SDF generalizes well to the reconstruction of non-Manhattan scenes.\n","authors":["Jing Li","Jinpeng Yu","Ruoyu Wang","Zhengxin Li","Zhengyu Zhang","Lina Cao","Shenghua Gao"],"pdf_url":"https://arxiv.org/pdf/2303.00236v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00232v1","updated":"2023-03-01T04:52:49Z","published":"2023-03-01T04:52:49Z","title":"Towards more precise automatic analysis: a comprehensive survey of deep\n  learning-based multi-organ segmentation","summary":"  Accurate segmentation of multiple organs of the head, neck, chest, and\nabdomen from medical images is an essential step in computer-aided diagnosis,\nsurgical navigation, and radiation therapy. In the past few years, with a\ndata-driven feature extraction approach and end-to-end training, automatic deep\nlearning-based multi-organ segmentation method has far outperformed traditional\nmethods and become a new research topic. This review systematically summarizes\nthe latest research in this field. For the first time, from the perspective of\nfull and imperfect annotation, we comprehensively compile 161 studies on deep\nlearning-based multi-organ segmentation in multiple regions such as the head\nand neck, chest, and abdomen, containing a total of 214 related references. The\nmethod based on full annotation summarizes the existing methods from four\naspects: network architecture, network dimension, network dedicated modules,\nand network loss function. The method based on imperfect annotation summarizes\nthe existing methods from two aspects: weak annotation-based methods and semi\nannotation-based methods. We also summarize frequently used datasets for\nmulti-organ segmentation and discuss new challenges and new research trends in\nthis field.\n","authors":["Xiaoyu Liu","Linhao Qu","Ziyue Xie","Jiayue Zhao","Yonghong Shi","Zhijian Song"],"pdf_url":"https://arxiv.org/pdf/2303.00232v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13473v2","updated":"2023-03-01T04:41:51Z","published":"2023-01-31T08:41:18Z","title":"CRC-RL: A Novel Visual Feature Representation Architecture for\n  Unsupervised Reinforcement Learning","summary":"  This paper addresses the problem of visual feature representation learning\nwith an aim to improve the performance of end-to-end reinforcement learning\n(RL) models. Specifically, a novel architecture is proposed that uses a\nheterogeneous loss function, called CRC loss, to learn improved visual features\nwhich can then be used for policy learning in RL. The CRC-loss function is a\ncombination of three individual loss functions, namely, contrastive,\nreconstruction and consistency loss. The feature representation is learned in\nparallel to the policy learning while sharing the weight updates through a\nSiamese Twin encoder model. This encoder model is augmented with a decoder\nnetwork and a feature projection network to facilitate computation of the above\nloss components. Through empirical analysis involving latent feature\nvisualization, an attempt is made to provide an insight into the role played by\nthis loss function in learning new action-dependent features and how they are\nlinked to the complexity of the problems being solved. The proposed\narchitecture, called CRC-RL, is shown to outperform the existing\nstate-of-the-art methods on the challenging Deep mind control suite\nenvironments by a significant margin thereby creating a new benchmark in this\nfield.\n","authors":["Darshita Jain","Anima Majumder","Samrat Dutta","Swagat Kumar"],"pdf_url":"https://arxiv.org/pdf/2301.13473v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.05833v2","updated":"2023-03-01T04:40:21Z","published":"2022-07-12T20:52:26Z","title":"Earthformer: Exploring Space-Time Transformers for Earth System\n  Forecasting","summary":"  Conventionally, Earth system (e.g., weather and climate) forecasting relies\non numerical simulation with complex physical models and are hence both\nexpensive in computation and demanding on domain expertise. With the explosive\ngrowth of the spatiotemporal Earth observation data in the past decade,\ndata-driven models that apply Deep Learning (DL) are demonstrating impressive\npotential for various Earth system forecasting tasks. The Transformer as an\nemerging DL architecture, despite its broad success in other domains, has\nlimited adoption in this area. In this paper, we propose Earthformer, a\nspace-time Transformer for Earth system forecasting. Earthformer is based on a\ngeneric, flexible and efficient space-time attention block, named Cuboid\nAttention. The idea is to decompose the data into cuboids and apply\ncuboid-level self-attention in parallel. These cuboids are further connected\nwith a collection of global vectors. We conduct experiments on the MovingMNIST\ndataset and a newly proposed chaotic N-body MNIST dataset to verify the\neffectiveness of cuboid attention and figure out the best design of\nEarthformer. Experiments on two real-world benchmarks about precipitation\nnowcasting and El Nino/Southern Oscillation (ENSO) forecasting show Earthformer\nachieves state-of-the-art performance. Code is available:\nhttps://github.com/amazon-science/earth-forecasting-transformer .\n","authors":["Zhihan Gao","Xingjian Shi","Hao Wang","Yi Zhu","Yuyang Wang","Mu Li","Dit-Yan Yeung"],"pdf_url":"https://arxiv.org/pdf/2207.05833v2.pdf","comment":"Published at NeurIPS 2022. Camera-ready version"},{"id":"http://arxiv.org/abs/2302.14338v2","updated":"2023-03-01T04:36:26Z","published":"2023-02-28T06:06:12Z","title":"Turning a CLIP Model into a Scene Text Detector","summary":"  The recent large-scale Contrastive Language-Image Pretraining (CLIP) model\nhas shown great potential in various downstream tasks via leveraging the\npretrained vision and language knowledge. Scene text, which contains rich\ntextual and visual information, has an inherent connection with a model like\nCLIP. Recently, pretraining approaches based on vision language models have\nmade effective progresses in the field of text detection. In contrast to these\nworks, this paper proposes a new method, termed TCM, focusing on Turning the\nCLIP Model directly for text detection without pretraining process. We\ndemonstrate the advantages of the proposed TCM as follows: (1) The underlying\nprinciple of our framework can be applied to improve existing scene text\ndetector. (2) It facilitates the few-shot training capability of existing\nmethods, e.g., by using 10% of labeled data, we significantly improve the\nperformance of the baseline method with an average of 22% in terms of the\nF-measure on 4 benchmarks. (3) By turning the CLIP model into existing scene\ntext detection methods, we further achieve promising domain adaptation ability.\nThe code will be publicly released at https://github.com/wenwenyu/TCM.\n","authors":["Wenwen Yu","Yuliang Liu","Wei Hua","Deqiang Jiang","Bo Ren","Xiang Bai"],"pdf_url":"https://arxiv.org/pdf/2302.14338v2.pdf","comment":"CVPR2023"},{"id":"http://arxiv.org/abs/2212.12990v3","updated":"2023-03-01T04:35:39Z","published":"2022-12-26T02:37:38Z","title":"Unsupervised Representation Learning from Pre-trained Diffusion\n  Probabilistic Models","summary":"  Diffusion Probabilistic Models (DPMs) have shown a powerful capacity of\ngenerating high-quality image samples. Recently, diffusion autoencoders\n(Diff-AE) have been proposed to explore DPMs for representation learning via\nautoencoding. Their key idea is to jointly train an encoder for discovering\nmeaningful representations from images and a conditional DPM as the decoder for\nreconstructing images. Considering that training DPMs from scratch will take a\nlong time and there have existed numerous pre-trained DPMs, we propose\n\\textbf{P}re-trained \\textbf{D}PM \\textbf{A}uto\\textbf{E}ncoding\n(\\textbf{PDAE}), a general method to adapt existing pre-trained DPMs to the\ndecoders for image reconstruction, with better training efficiency and\nperformance than Diff-AE. Specifically, we find that the reason that\npre-trained DPMs fail to reconstruct an image from its latent variables is due\nto the information loss of forward process, which causes a gap between their\npredicted posterior mean and the true one. From this perspective, the\nclassifier-guided sampling method can be explained as computing an extra mean\nshift to fill the gap, reconstructing the lost class information in samples.\nThese imply that the gap corresponds to the lost information of the image, and\nwe can reconstruct the image by filling the gap. Drawing inspiration from this,\nwe employ a trainable model to predict a mean shift according to encoded\nrepresentation and train it to fill as much gap as possible, in this way, the\nencoder is forced to learn as much information as possible from images to help\nthe filling. By reusing a part of network of pre-trained DPMs and redesigning\nthe weighting scheme of diffusion loss, PDAE can learn meaningful\nrepresentations from images efficiently. Extensive experiments demonstrate the\neffectiveness, efficiency and flexibility of PDAE.\n","authors":["Zijian Zhang","Zhou Zhao","Zhijie Lin"],"pdf_url":"https://arxiv.org/pdf/2212.12990v3.pdf","comment":"Accepted by NeurIPS 2022 Conference"},{"id":"http://arxiv.org/abs/2302.09369v2","updated":"2023-03-01T03:48:17Z","published":"2023-02-18T15:53:55Z","title":"Calibrating the Rigged Lottery: Making All Tickets Reliable","summary":"  Although sparse training has been successfully used in various\nresource-limited deep learning tasks to save memory, accelerate training, and\nreduce inference time, the reliability of the produced sparse models remains\nunexplored. Previous research has shown that deep neural networks tend to be\nover-confident, and we find that sparse training exacerbates this problem.\nTherefore, calibrating the sparse models is crucial for reliable prediction and\ndecision-making. In this paper, we propose a new sparse training method to\nproduce sparse models with improved confidence calibration. In contrast to\nprevious research that uses only one mask to control the sparse topology, our\nmethod utilizes two masks, including a deterministic mask and a random mask.\nThe former efficiently searches and activates important weights by exploiting\nthe magnitude of weights and gradients. While the latter brings better\nexploration and finds more appropriate weight values by random updates.\nTheoretically, we prove our method can be viewed as a hierarchical variational\napproximation of a probabilistic deep Gaussian process. Extensive experiments\non multiple datasets, model architectures, and sparsities show that our method\nreduces ECE values by up to 47.8\\% and simultaneously maintains or even\nimproves accuracy with only a slight increase in computation and storage\nburden.\n","authors":["Bowen Lei","Ruqi Zhang","Dongkuan Xu","Bani Mallick"],"pdf_url":"https://arxiv.org/pdf/2302.09369v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13130v2","updated":"2023-03-01T03:46:43Z","published":"2023-02-25T18:12:37Z","title":"Point Cloud Forecasting as a Proxy for 4D Occupancy Forecasting","summary":"  Predicting how the world can evolve in the future is crucial for motion\nplanning in autonomous systems. Classical methods are limited because they rely\non costly human annotations in the form of semantic class labels, bounding\nboxes, and tracks or HD maps of cities to plan their motion and thus are\ndifficult to scale to large unlabeled datasets. One promising self-supervised\ntask is 3D point cloud forecasting from unannotated LiDAR sequences. We show\nthat this task requires algorithms to implicitly capture (1) sensor extrinsics\n(i.e., the egomotion of the autonomous vehicle), (2) sensor intrinsics (i.e.,\nthe sampling pattern specific to the particular LiDAR sensor), and (3) the\nshape and motion of other objects in the scene. But autonomous systems should\nmake predictions about the world and not their sensors. To this end, we factor\nout (1) and (2) by recasting the task as one of spacetime (4D) occupancy\nforecasting. But because it is expensive to obtain ground-truth 4D occupancy,\nwe render point cloud data from 4D occupancy predictions given sensor\nextrinsics and intrinsics, allowing one to train and test occupancy algorithms\nwith unannotated LiDAR sequences. This also allows one to evaluate and compare\npoint cloud forecasting algorithms across diverse datasets, sensors, and\nvehicles.\n","authors":["Tarasha Khurana","Peiyun Hu","David Held","Deva Ramanan"],"pdf_url":"https://arxiv.org/pdf/2302.13130v2.pdf","comment":"CVPR 2023. Project page:\n  https://www.cs.cmu.edu/~tkhurana/ff4d/index.html; Code:\n  https://github.com/tarashakhurana/4d-occ-forecasting"},{"id":"http://arxiv.org/abs/2303.00215v1","updated":"2023-03-01T03:37:42Z","published":"2023-03-01T03:37:42Z","title":"Single Image Backdoor Inversion via Robust Smoothed Classifiers","summary":"  Backdoor inversion, the process of finding a backdoor trigger inserted into a\nmachine learning model, has become the pillar of many backdoor detection and\ndefense methods. Previous works on backdoor inversion often recover the\nbackdoor through an optimization process to flip a support set of clean images\ninto the target class. However, it is rarely studied and understood how large\nthis support set should be to recover a successful backdoor. In this work, we\nshow that one can reliably recover the backdoor trigger with as few as a single\nimage. Specifically, we propose the SmoothInv method, which first constructs a\nrobust smoothed version of the backdoored classifier and then performs guided\nimage synthesis towards the target class to reveal the backdoor pattern.\nSmoothInv requires neither an explicit modeling of the backdoor via a mask\nvariable, nor any complex regularization schemes, which has become the standard\npractice in backdoor inversion methods. We perform both quantitaive and\nqualitative study on backdoored classifiers from previous published backdoor\nattacks. We demonstrate that compared to existing methods, SmoothInv is able to\nrecover successful backdoors from single images, while maintaining high\nfidelity to the original backdoor. We also show how we identify the target\nbackdoored class from the backdoored classifier. Last, we propose and analyze\ntwo countermeasures to our approach and show that SmoothInv remains robust in\nthe face of an adaptive attacker. Our code is available at\nhttps://github.com/locuslab/smoothinv .\n","authors":["Mingjie Sun","Zico Kolter"],"pdf_url":"https://arxiv.org/pdf/2303.00215v1.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2303.00212v1","updated":"2023-03-01T03:33:12Z","published":"2023-03-01T03:33:12Z","title":"A task-specific deep-learning-based denoising approach for myocardial\n  perfusion SPECT","summary":"  Deep-learning (DL)-based methods have shown significant promise in denoising\nmyocardial perfusion SPECT images acquired at low dose. For clinical\napplication of these methods, evaluation on clinical tasks is crucial.\nTypically, these methods are designed to minimize some fidelity-based criterion\nbetween the predicted denoised image and some reference normal-dose image.\nHowever, while promising, studies have shown that these methods may have\nlimited impact on the performance of clinical tasks in SPECT. To address this\nissue, we use concepts from the literature on model observers and our\nunderstanding of the human visual system to propose a DL-based denoising\napproach designed to preserve observer-related information for detection tasks.\nThe proposed method was objectively evaluated on the task of detecting\nperfusion defect in myocardial perfusion SPECT images using a retrospective\nstudy with anonymized clinical data. Our results demonstrate that the proposed\nmethod yields improved performance on this detection task compared to using\nlow-dose images. The results show that by preserving task-specific information,\nDL may provide a mechanism to improve observer performance in low-dose\nmyocardial perfusion SPECT.\n","authors":["Md Ashequr Rahman","Zitong Yu","Barry A. Siegel","Abhinav K. Jha"],"pdf_url":"https://arxiv.org/pdf/2303.00212v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00205v1","updated":"2023-03-01T03:15:31Z","published":"2023-03-01T03:15:31Z","title":"RECIST Weakly Supervised Lesion Segmentation via Label-Space Co-Training","summary":"  As an essential indicator for cancer progression and treatment response,\ntumor size is often measured following the response evaluation criteria in\nsolid tumors (RECIST) guideline in CT slices. By marking each lesion with its\nlongest axis and the longest perpendicular one, laborious pixel-wise manual\nannotation can be avoided. However, such a coarse substitute cannot provide a\nrich and accurate base to allow versatile quantitative analysis of lesions. To\nthis end, we propose a novel weakly supervised framework to exploit the\nexisting rich RECIST annotations for pixel-wise lesion segmentation.\nSpecifically, a pair of under- and over-segmenting masks are constructed for\neach lesion based on its RECIST annotation and served as the label for\nco-training a pair of subnets, respectively, along with the proposed\nlabel-space perturbation induced consistency loss to bridge the gap between the\ntwo subnets and enable effective co-training. Extensive experiments are\nconducted on a public dataset to demonstrate the superiority of the proposed\nframework regarding the RECIST-based weakly supervised segmentation task and\nits universal applicability to various backbone networks.\n","authors":["Lianyu Zhou","Dong Wei","Donghuan Lu","Wei Xue","Liansheng Wang","Yefeng Zheng"],"pdf_url":"https://arxiv.org/pdf/2303.00205v1.pdf","comment":"ISBI 2023"},{"id":"http://arxiv.org/abs/2303.00200v1","updated":"2023-03-01T03:08:40Z","published":"2023-03-01T03:08:40Z","title":"Feature Extraction Matters More: Universal Deepfake Disruption through\n  Attacking Ensemble Feature Extractors","summary":"  Adversarial example is a rising way of protecting facial privacy security\nfrom deepfake modification. To prevent massive facial images from being\nillegally modified by various deepfake models, it is essential to design a\nuniversal deepfake disruptor. However, existing works treat deepfake disruption\nas an End-to-End process, ignoring the functional difference between feature\nextraction and image reconstruction, which makes it difficult to generate a\ncross-model universal disruptor. In this work, we propose a novel\nFeature-Output ensemble UNiversal Disruptor (FOUND) against deepfake networks,\nwhich explores a new opinion that considers attacking feature extractors as the\nmore critical and general task in deepfake disruption. We conduct an effective\ntwo-stage disruption process. We first disrupt multi-model feature extractors\nthrough multi-feature aggregation and individual-feature maintenance, and then\ndevelop a gradient-ensemble algorithm to enhance the disruption effect by\nsimplifying the complex optimization problem of disrupting multiple End-to-End\nmodels. Extensive experiments demonstrate that FOUND can significantly boost\nthe disruption effect against ensemble deepfake benchmark models. Besides, our\nmethod can fast obtain a cross-attribute, cross-image, and cross-model\nuniversal deepfake disruptor with only a few training images, surpassing\nstate-of-the-art universal disruptors in both success rate and efficiency.\n","authors":["Long Tang","Dengpan Ye","Zhenhao Lu","Yunming Zhang","Shengshan Hu","Yue Xu","Chuanxi Chen"],"pdf_url":"https://arxiv.org/pdf/2303.00200v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00199v1","updated":"2023-03-01T03:08:30Z","published":"2023-03-01T03:08:30Z","title":"DMSA: Dynamic Multi-scale Unsupervised Semantic Segmentation Based on\n  Adaptive Affinity","summary":"  The proposed method in this paper proposes an end-to-end unsupervised\nsemantic segmentation architecture DMSA based on four loss functions. The\nframework uses Atrous Spatial Pyramid Pooling (ASPP) module to enhance feature\nextraction. At the same time, a dynamic dilation strategy is designed to better\ncapture multi-scale context information. Secondly, a Pixel-Adaptive Refinement\n(PAR) module is introduced, which can adaptively refine the initial pseudo\nlabels after feature fusion to obtain high quality pseudo labels. Experiments\nshow that the proposed DSMA framework is superior to the existing methods on\nthe saliency dataset. On the COCO 80 dataset, the MIoU is improved by 2.0, and\nthe accuracy is improved by 5.39. On the Pascal VOC 2012 Augmented dataset, the\nMIoU is improved by 4.9, and the accuracy is improved by 3.4. In addition, the\nconvergence speed of the model is also greatly improved after the introduction\nof the PAR module.\n","authors":["Kun Yang","Jun Lu"],"pdf_url":"https://arxiv.org/pdf/2303.00199v1.pdf","comment":"5 pages,4 figures"},{"id":"http://arxiv.org/abs/2303.00198v1","updated":"2023-03-01T03:06:29Z","published":"2023-03-01T03:06:29Z","title":"Self-Supervised Convolutional Visual Prompts","summary":"  Machine learning models often fail on out-of-distribution (OOD) samples.\nVisual prompts emerge as a light-weight adaptation method in input space for\nlarge-scale vision models. Existing vision prompts optimize a high-dimensional\nadditive vector and require labeled data on training. However, we find this\nparadigm fails on test-time adaptation when labeled data is unavailable, where\nthe high-dimensional visual prompt overfits to the self-supervised objective.\nWe present convolutional visual prompts for test-time adaptation without\nlabels. Our convolutional prompt is structured and requires fewer trainable\nparameters (less than 1 % parameters of standard visual prompts). Extensive\nexperiments on a wide variety of OOD recognition tasks show that our approach\nis effective, improving robustness by up to 5.87 % over a number of large-scale\nmodel architectures.\n","authors":["Yun-Yun Tsai","Chengzhi Mao","Yow-Kuan Lin","Junfeng Yang"],"pdf_url":"https://arxiv.org/pdf/2303.00198v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00193v1","updated":"2023-03-01T02:59:55Z","published":"2023-03-01T02:59:55Z","title":"CLIPER: A Unified Vision-Language Framework for In-the-Wild Facial\n  Expression Recognition","summary":"  Facial expression recognition (FER) is an essential task for understanding\nhuman behaviors. As one of the most informative behaviors of humans, facial\nexpressions are often compound and variable, which is manifested by the fact\nthat different people may express the same expression in very different ways.\nHowever, most FER methods still use one-hot or soft labels as the supervision,\nwhich lack sufficient semantic descriptions of facial expressions and are less\ninterpretable. Recently, contrastive vision-language pre-training (VLP) models\n(e.g., CLIP) use text as supervision and have injected new vitality into\nvarious computer vision tasks, benefiting from the rich semantics in text.\nTherefore, in this work, we propose CLIPER, a unified framework for both static\nand dynamic facial Expression Recognition based on CLIP. Besides, we introduce\nmultiple expression text descriptors (METD) to learn fine-grained expression\nrepresentations that make CLIPER more interpretable. We conduct extensive\nexperiments on several popular FER benchmarks and achieve state-of-the-art\nperformance, which demonstrates the effectiveness of CLIPER.\n","authors":["Hanting Li","Hongjing Niu","Zhaoqing Zhu","Feng Zhao"],"pdf_url":"https://arxiv.org/pdf/2303.00193v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00312v4","updated":"2023-03-01T02:51:12Z","published":"2022-10-01T16:24:15Z","title":"Multimodal Analogical Reasoning over Knowledge Graphs","summary":"  Analogical reasoning is fundamental to human cognition and holds an important\nplace in various fields. However, previous studies mainly focus on single-modal\nanalogical reasoning and ignore taking advantage of structure knowledge.\nNotably, the research in cognitive psychology has demonstrated that information\nfrom multimodal sources always brings more powerful cognitive transfer than\nsingle modality sources. To this end, we introduce the new task of multimodal\nanalogical reasoning over knowledge graphs, which requires multimodal reasoning\nability with the help of background knowledge. Specifically, we construct a\nMultimodal Analogical Reasoning dataSet (MARS) and a multimodal knowledge graph\nMarKG. We evaluate with multimodal knowledge graph embedding and pre-trained\nTransformer baselines, illustrating the potential challenges of the proposed\ntask. We further propose a novel model-agnostic Multimodal analogical reasoning\nframework with Transformer (MarT) motivated by the structure mapping theory,\nwhich can obtain better performance. Code and datasets are available in\nhttps://github.com/zjunlp/MKG_Analogy.\n","authors":["Ningyu Zhang","Lei Li","Xiang Chen","Xiaozhuan Liang","Shumin Deng","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2210.00312v4.pdf","comment":"Accepted by ICLR 2023. The project website is\n  https://zjunlp.github.io/project/MKG_Analogy/introduction.html"},{"id":"http://arxiv.org/abs/2303.00181v1","updated":"2023-03-01T02:15:07Z","published":"2023-03-01T02:15:07Z","title":"Selectively Hard Negative Mining for Alleviating Gradient Vanishing in\n  Image-Text Matching","summary":"  Recently, a series of Image-Text Matching (ITM) methods achieve impressive\nperformance. However, we observe that most existing ITM models suffer from\ngradients vanishing at the beginning of training, which makes these models\nprone to falling into local minima. Most ITM models adopt triplet loss with\nHard Negative mining (HN) as the optimization objective. We find that\noptimizing an ITM model using only the hard negative samples can easily lead to\ngradient vanishing. In this paper, we derive the condition under which the\ngradient vanishes during training. When the difference between the positive\npair similarity and the negative pair similarity is close to 0, the gradients\non both the image and text encoders will approach 0. To alleviate the gradient\nvanishing problem, we propose a Selectively Hard Negative Mining (SelHN)\nstrategy, which chooses whether to mine hard negative samples according to the\ngradient vanishing condition. SelHN can be plug-and-play applied to existing\nITM models to give them better training behavior. To further ensure the\nback-propagation of gradients, we construct a Residual Visual Semantic\nEmbedding model with SelHN, denoted as RVSE++. Extensive experiments on two ITM\nbenchmarks demonstrate the strength of RVSE++, achieving state-of-the-art\nperformance.\n","authors":["Zheng Li","Caili Guo","Xin Wang","Zerun Feng","Zhongtian Du"],"pdf_url":"https://arxiv.org/pdf/2303.00181v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00180v1","updated":"2023-03-01T02:14:20Z","published":"2023-03-01T02:14:20Z","title":"FaceRNET: a Facial Expression Intensity Estimation Network","summary":"  This paper presents our approach for Facial Expression Intensity Estimation\nfrom videos. It includes two components: i) a representation extractor network\nthat extracts various emotion descriptors (valence-arousal, action units and\nbasic expressions) from each videoframe; ii) a RNN that captures temporal\ninformation in the data, followed by a mask layer which enables handling\nvarying input video lengths through dynamic routing. This approach has been\ntested on the Hume-Reaction dataset yielding excellent results.\n","authors":["Dimitrios Kollias","Andreas Psaroudakis","Anastasios Arsenos","Paraskeui Theofilou"],"pdf_url":"https://arxiv.org/pdf/2303.00180v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00175v1","updated":"2023-03-01T02:07:48Z","published":"2023-03-01T02:07:48Z","title":"A Deep Neural Architecture for Harmonizing 3-D Input Data Analysis and\n  Decision Making in Medical Imaging","summary":"  Harmonizing the analysis of data, especially of 3-D image volumes, consisting\nof different number of slices and annotated per volume, is a significant\nproblem in training and using deep neural networks in various applications,\nincluding medical imaging. Moreover, unifying the decision making of the\nnetworks over different input datasets is crucial for the generation of rich\ndata-driven knowledge and for trusted usage in the applications. This paper\npresents a new deep neural architecture, named RACNet, which includes routing\nand feature alignment steps and effectively handles different input lengths and\nsingle annotations of the 3-D image inputs, whilst providing highly accurate\ndecisions. In addition, through latent variable extraction from the trained\nRACNet, a set of anchors are generated providing further insight on the\nnetwork's decision making. These can be used to enrich and unify data-driven\nknowledge extracted from different datasets. An extensive experimental study\nillustrates the above developments, focusing on COVID-19 diagnosis through\nanalysis of 3-D chest CT scans from databases generated in different countries\nand medical centers.\n","authors":["Dimitrios Kollias","Anastasios Arsenos","Stefanos Kollias"],"pdf_url":"https://arxiv.org/pdf/2303.00175v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.15274v2","updated":"2023-03-01T02:06:06Z","published":"2022-10-27T09:08:40Z","title":"Improved Feature Distillation via Projector Ensemble","summary":"  In knowledge distillation, previous feature distillation methods mainly focus\non the design of loss functions and the selection of the distilled layers,\nwhile the effect of the feature projector between the student and the teacher\nremains under-explored. In this paper, we first discuss a plausible mechanism\nof the projector with empirical evidence and then propose a new feature\ndistillation method based on a projector ensemble for further performance\nimprovement. We observe that the student network benefits from a projector even\nif the feature dimensions of the student and the teacher are the same. Training\na student backbone without a projector can be considered as a multi-task\nlearning process, namely achieving discriminative feature extraction for\nclassification and feature matching between the student and the teacher for\ndistillation at the same time. We hypothesize and empirically verify that\nwithout a projector, the student network tends to overfit the teacher's feature\ndistributions despite having different architecture and weights initialization.\nThis leads to degradation on the quality of the student's deep features that\nare eventually used in classification. Adding a projector, on the other hand,\ndisentangles the two learning tasks and helps the student network to focus\nbetter on the main feature extraction task while still being able to utilize\nteacher features as a guidance through the projector. Motivated by the positive\neffect of the projector in feature distillation, we propose an ensemble of\nprojectors to further improve the quality of student features. Experimental\nresults on different datasets with a series of teacher-student pairs illustrate\nthe effectiveness of the proposed method.\n","authors":["Yudong Chen","Sen Wang","Jiajun Liu","Xuwei Xu","Frank de Hoog","Zi Huang"],"pdf_url":"https://arxiv.org/pdf/2210.15274v2.pdf","comment":"NeurIPS 2022"},{"id":"http://arxiv.org/abs/2303.00167v1","updated":"2023-03-01T01:45:28Z","published":"2023-03-01T01:45:28Z","title":"Sketch2Cloth: Sketch-based 3D Garment Generation with Unsigned Distance\n  Fields","summary":"  3D model reconstruction from a single image has achieved great progress with\nthe recent deep generative models. However, the conventional reconstruction\napproaches with template mesh deformation and implicit fields have difficulty\nin reconstructing non-watertight 3D mesh models, such as garments. In contrast\nto image-based modeling, the sketch-based approach can help users generate 3D\nmodels to meet the design intentions from hand-drawn sketches. In this study,\nwe propose Sketch2Cloth, a sketch-based 3D garment generation system using the\nunsigned distance fields from the user's sketch input. Sketch2Cloth first\nestimates the unsigned distance function of the target 3D model from the sketch\ninput, and extracts the mesh from the estimated field with Marching Cubes. We\nalso provide the model editing function to modify the generated mesh. We\nverified the proposed Sketch2Cloth with quantitative evaluations on garment\ngeneration and editing with a state-of-the-art approach.\n","authors":["Yi He","Haoran Xie","Kazunori Miyata"],"pdf_url":"https://arxiv.org/pdf/2303.00167v1.pdf","comment":"8 pages, 9 figures, video is here https://youtu.be/miisvVTpqj8"},{"id":"http://arxiv.org/abs/2303.00165v1","updated":"2023-03-01T01:37:24Z","published":"2023-03-01T01:37:24Z","title":"Diffusion Probabilistic Fields","summary":"  Diffusion probabilistic models have quickly become a major approach for\ngenerative modeling of images, 3D geometry, video and other domains. However,\nto adapt diffusion generative modeling to these domains the denoising network\nneeds to be carefully designed for each domain independently, oftentimes under\nthe assumption that data lives in a Euclidean grid. In this paper we introduce\nDiffusion Probabilistic Fields (DPF), a diffusion model that can learn\ndistributions over continuous functions defined over metric spaces, commonly\nknown as fields. We extend the formulation of diffusion probabilistic models to\ndeal with this field parametrization in an explicit way, enabling us to define\nan end-to-end learning algorithm that side-steps the requirement of\nrepresenting fields with latent vectors as in previous approaches (Dupont et\nal., 2022a; Du et al., 2021). We empirically show that, while using the same\ndenoising network, DPF effectively deals with different modalities like 2D\nimages and 3D geometry, in addition to modeling distributions over fields\ndefined on non-Euclidean metric spaces.\n","authors":["Peiye Zhuang","Samira Abnar","Jiatao Gu","Alex Schwing","Joshua M. Susskind","Miguel Ángel Bautista"],"pdf_url":"https://arxiv.org/pdf/2303.00165v1.pdf","comment":"Accepted to ICLR 2023. 20 pages, 17 figures"},{"id":"http://arxiv.org/abs/2210.10992v3","updated":"2023-03-01T01:30:41Z","published":"2022-10-20T03:35:05Z","title":"NIFT: Neural Interaction Field and Template for Object Manipulation","summary":"  We introduce NIFT, Neural Interaction Field and Template, a descriptive and\nrobust interaction representation of object manipulations to facilitate\nimitation learning. Given a few object manipulation demos, NIFT guides the\ngeneration of the interaction imitation for a new object instance by matching\nthe Neural Interaction Template (NIT) extracted from the demos in the target\nNeural Interaction Field (NIF) defined for the new object. Specifically, the\nNIF is a neural field that encodes the relationship between each spatial point\nand a given object, where the relative position is defined by a spherical\ndistance function rather than occupancies or signed distances, which are\ncommonly adopted by conventional neural fields but less informative. For a\ngiven demo interaction, the corresponding NIT is defined by a set of spatial\npoints sampled in the demo NIF with associated neural features. To better\ncapture the interaction, the points are sampled on the Interaction Bisector\nSurface (IBS), which consists of points that are equidistant to the two\ninteracting objects and has been used extensively for interaction\nrepresentation. With both point selection and pointwise features defined for\nbetter interaction encoding, NIT effectively guides the feature matching in the\nNIFs of the new object instances such that the relative poses are optimized to\nrealize the manipulation while imitating the demo interactions. Experiments\nshow that our NIFT solution outperforms state-of-the-art imitation learning\nmethods for object manipulation and generalizes better to objects from new\ncategories.\n","authors":["Zeyu Huang","Juzhan Xu","Sisi Dai","Kai Xu","Hao Zhang","Hui Huang","Ruizhen Hu"],"pdf_url":"https://arxiv.org/pdf/2210.10992v3.pdf","comment":"ICRA 2023"},{"id":"http://arxiv.org/abs/2303.00157v1","updated":"2023-03-01T01:09:01Z","published":"2023-03-01T01:09:01Z","title":"Semi-supervised Parametric Real-world Image Harmonization","summary":"  Learning-based image harmonization techniques are usually trained to undo\nsynthetic random global transformations applied to a masked foreground in a\nsingle ground truth photo. This simulated data does not model many of the\nimportant appearance mismatches (illumination, object boundaries, etc.) between\nforeground and background in real composites, leading to models that do not\ngeneralize well and cannot model complex local changes. We propose a new\nsemi-supervised training strategy that addresses this problem and lets us learn\ncomplex local appearance harmonization from unpaired real composites, where\nforeground and background come from different images. Our model is fully\nparametric. It uses RGB curves to correct the global colors and tone and a\nshading map to model local variations. Our method outperforms previous work on\nestablished benchmarks and real composites, as shown in a user study, and\nprocesses high-resolution images interactively.\n","authors":["Ke Wang","Michaël Gharbi","He Zhang","Zhihao Xia","Eli Shechtman"],"pdf_url":"https://arxiv.org/pdf/2303.00157v1.pdf","comment":"19 pages, 16 figures, 5 tables"},{"id":"http://arxiv.org/abs/2303.00154v1","updated":"2023-03-01T00:56:39Z","published":"2023-03-01T00:56:39Z","title":"Neural inverse procedural modeling of knitting yarns from images","summary":"  We investigate the capabilities of neural inverse procedural modeling to\ninfer high-quality procedural yarn models with fiber-level details from single\nimages of depicted yarn samples. While directly inferring all parameters of the\nunderlying yarn model based on a single neural network may seem an intuitive\nchoice, we show that the complexity of yarn structures in terms of twisting and\nmigration characteristics of the involved fibers can be better encountered in\nterms of ensembles of networks that focus on individual characteristics. We\nanalyze the effect of different loss functions including a parameter loss to\npenalize the deviation of inferred parameters to ground truth annotations, a\nreconstruction loss to enforce similar statistics of the image generated for\nthe estimated parameters in comparison to training images as well as an\nadditional regularization term to explicitly penalize deviations between latent\ncodes of synthetic images and the average latent code of real images in the\nlatent space of the encoder. We demonstrate that the combination of a carefully\ndesigned parametric, procedural yarn model with respective network ensembles as\nwell as loss functions even allows robust parameter inference when solely\ntrained on synthetic data. Since our approach relies on the availability of a\nyarn database with parameter annotations and we are not aware of such a\nrespectively available dataset, we additionally provide, to the best of our\nknowledge, the first dataset of yarn images with annotations regarding the\nrespective yarn parameters. For this purpose, we use a novel yarn generator\nthat improves the realism of the produced results over previous approaches.\n","authors":["Elena Trunz","Jonathan Klein","Jan Müller","Lukas Bode","Ralf Sarlette","Michael Weinmann","Reinhard Klein"],"pdf_url":"https://arxiv.org/pdf/2303.00154v1.pdf","comment":"23 pages, 16 figures"},{"id":"http://arxiv.org/abs/2208.04202v2","updated":"2023-03-01T00:18:33Z","published":"2022-08-08T15:08:40Z","title":"Analog Bits: Generating Discrete Data using Diffusion Models with\n  Self-Conditioning","summary":"  We present Bit Diffusion: a simple and generic approach for generating\ndiscrete data with continuous state and continuous time diffusion models. The\nmain idea behind our approach is to first represent the discrete data as binary\nbits, and then train a continuous diffusion model to model these bits as real\nnumbers which we call analog bits. To generate samples, the model first\ngenerates the analog bits, which are then thresholded to obtain the bits that\nrepresent the discrete variables. We further propose two simple techniques,\nnamely Self-Conditioning and Asymmetric Time Intervals, which lead to a\nsignificant improvement in sample quality. Despite its simplicity, the proposed\napproach can achieve strong performance in both discrete image generation and\nimage captioning tasks. For discrete image generation, we significantly improve\nprevious state-of-the-art on both CIFAR-10 (which has 3K discrete 8-bit tokens)\nand ImageNet-64x64 (which has 12K discrete 8-bit tokens), outperforming the\nbest autoregressive model in both sample quality (measured by FID) and\nefficiency. For image captioning on MS-COCO dataset, our approach achieves\ncompetitive results compared to autoregressive models.\n","authors":["Ting Chen","Ruixiang Zhang","Geoffrey Hinton"],"pdf_url":"https://arxiv.org/pdf/2208.04202v2.pdf","comment":"ICLR'23"},{"id":"http://arxiv.org/abs/2209.07725v3","updated":"2023-03-01T23:49:35Z","published":"2022-09-16T05:14:08Z","title":"VINet: Visual and Inertial-based Terrain Classification and Adaptive\n  Navigation over Unknown Terrain","summary":"  We present a visual and inertial-based terrain classification network (VINet)\nfor robotic navigation over different traversable surfaces. We use a novel\nnavigation-based labeling scheme for terrain classification and generalization\non unknown surfaces. Our proposed perception method and adaptive scheduling\ncontrol framework can make predictions according to terrain navigation\nproperties and lead to better performance on both terrain classification and\nnavigation control on known and unknown surfaces. Our VINet can achieve 98.37%\nin terms of accuracy under supervised setting on known terrains and improve the\naccuracy by 8.51% on unknown terrains compared to previous methods. We deploy\nVINet on a mobile tracked robot for trajectory following and navigation on\ndifferent terrains, and we demonstrate an improvement of 10.3% compared to a\nbaseline controller in terms of RMSE.\n","authors":["Tianrui Guan","Ruitao Song","Zhixian Ye","Liangjun Zhang"],"pdf_url":"https://arxiv.org/pdf/2209.07725v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00865v1","updated":"2023-03-01T23:37:45Z","published":"2023-03-01T23:37:45Z","title":"AMIGO: Sparse Multi-Modal Graph Transformer with Shared-Context\n  Processing for Representation Learning of Giga-pixel Images","summary":"  Processing giga-pixel whole slide histopathology images (WSI) is a\ncomputationally expensive task. Multiple instance learning (MIL) has become the\nconventional approach to process WSIs, in which these images are split into\nsmaller patches for further processing. However, MIL-based techniques ignore\nexplicit information about the individual cells within a patch. In this paper,\nby defining the novel concept of shared-context processing, we designed a\nmulti-modal Graph Transformer (AMIGO) that uses the celluar graph within the\ntissue to provide a single representation for a patient while taking advantage\nof the hierarchical structure of the tissue, enabling a dynamic focus between\ncell-level and tissue-level information. We benchmarked the performance of our\nmodel against multiple state-of-the-art methods in survival prediction and\nshowed that ours can significantly outperform all of them including\nhierarchical Vision Transformer (ViT). More importantly, we show that our model\nis strongly robust to missing information to an extent that it can achieve the\nsame performance with as low as 20% of the data. Finally, in two different\ncancer datasets, we demonstrated that our model was able to stratify the\npatients into low-risk and high-risk groups while other state-of-the-art\nmethods failed to achieve this goal. We also publish a large dataset of\nimmunohistochemistry images (InUIT) containing 1,600 tissue microarray (TMA)\ncores from 188 patients along with their survival information, making it one of\nthe largest publicly available datasets in this context.\n","authors":["Ramin Nakhli","Puria Azadi Moghadam","Haoyang Mi","Hossein Farahani","Alexander Baras","Blake Gilks","Ali Bashashati"],"pdf_url":"https://arxiv.org/pdf/2303.00865v1.pdf","comment":"Accepted at CVPR 2023"},{"id":"http://arxiv.org/abs/2303.00855v1","updated":"2023-03-01T22:58:50Z","published":"2023-03-01T22:58:50Z","title":"Grounded Decoding: Guiding Text Generation with Grounded Models for\n  Robot Control","summary":"  Recent progress in large language models (LLMs) has demonstrated the ability\nto learn and leverage Internet-scale knowledge through pre-training with\nautoregressive models. Unfortunately, applying such models to settings with\nembodied agents, such as robots, is challenging due to their lack of experience\nwith the physical world, inability to parse non-language observations, and\nignorance of rewards or safety constraints that robots may require. On the\nother hand, language-conditioned robotic policies that learn from interaction\ndata can provide the necessary grounding that allows the agent to be correctly\nsituated in the real world, but such policies are limited by the lack of\nhigh-level semantic understanding due to the limited breadth of the interaction\ndata available for training them. Thus, if we want to make use of the semantic\nknowledge in a language model while still situating it in an embodied setting,\nwe must construct an action sequence that is both likely according to the\nlanguage model and also realizable according to grounded models of the\nenvironment. We frame this as a problem similar to probabilistic filtering:\ndecode a sequence that both has high probability under the language model and\nhigh probability under a set of grounded model objectives. We demonstrate this\nguided decoding strategy is able to solve complex, long-horizon embodiment\ntasks in a robotic setting by leveraging the knowledge of both models. The\nproject's website can be found at grounded-decoding.github.io.\n","authors":["Wenlong Huang","Fei Xia","Dhruv Shah","Danny Driess","Andy Zeng","Yao Lu","Pete Florence","Igor Mordatch","Sergey Levine","Karol Hausman","Brian Ichter"],"pdf_url":"https://arxiv.org/pdf/2303.00855v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.13443v2","updated":"2023-03-01T21:02:26Z","published":"2021-12-26T19:31:34Z","title":"Sinogram upsampling using Primal-Dual UNet for undersampled CT and\n  radial MRI reconstruction","summary":"  Computed tomography and magnetic resonance imaging are two widely used\nclinical imaging modalities for non-invasive diagnosis. However, both of these\nmodalities come with certain problems. CT uses harmful ionising radiation, and\nMRI suffers from slow acquisition speed. Both problems can be tackled by\nundersampling, such as sparse sampling. However, such undersampled data leads\nto lower resolution and introduces artefacts. Several techniques, including\ndeep learning based methods, have been proposed to reconstruct such data.\nHowever, the undersampled reconstruction problem for these two modalities was\nalways considered as two different problems and tackled separately by different\nresearch works. This paper proposes a unified solution for both sparse CT and\nundersampled radial MRI reconstruction, achieved by applying Fourier\ntransform-based pre-processing on the radial MRI and then finally\nreconstructing both modalities using sinogram upsampling combined with filtered\nback-projection. The Primal-Dual network is a deep learning based method for\nreconstructing sparsely-sampled CT data. This paper introduces Primal-Dual\nUNet, which improves the Primal-Dual network in terms of accuracy and\nreconstruction speed. The proposed method resulted in an average SSIM of\n0.932\\textpm0.021 while performing sparse CT reconstruction for fan-beam\ngeometry with a sparsity level of 16, achieving a statistically significant\nimprovement over the previous model, which resulted in 0.919\\textpm0.016.\nFurthermore, the proposed model resulted in 0.903\\textpm0.019 and\n0.957\\textpm0.023 average SSIM while reconstructing undersampled brain and\nabdominal MRI data with an acceleration factor of 16, respectively -\nstatistically significant improvements over the original model, which resulted\nin 0.867\\textpm0.025 and 0.949\\textpm0.025.\n","authors":["Philipp Ernst","Soumick Chatterjee","Georg Rose","Oliver Speck","Andreas Nürnberger"],"pdf_url":"https://arxiv.org/pdf/2112.13443v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.06725v2","updated":"2023-03-01T20:50:07Z","published":"2022-06-14T10:16:54Z","title":"Automated SSIM Regression for Detection and Quantification of Motion\n  Artefacts in Brain MR Images","summary":"  Motion artefacts in magnetic resonance brain images can have a strong impact\non diagnostic confidence. The assessment of MR image quality is fundamental\nbefore proceeding with the clinical diagnosis. Motion artefacts can alter the\ndelineation of structures such as the brain, lesions or tumours and may require\na repeat scan. Otherwise, an inaccurate (e.g. correct pathology but wrong\nseverity) or incorrect diagnosis (e.g. wrong pathology) may occur.\n\"\\textit{Image quality assessment}\" as a fast, automated step right after\nscanning can assist in deciding if the acquired images are diagnostically\nsufficient. An automated image quality assessment based on the structural\nsimilarity index (SSIM) regression through a residual neural network is\nproposed in this work. Additionally, a classification into different groups -\nby subdividing with SSIM ranges - is evaluated. Importantly, this method\npredicts SSIM values of an input image in the absence of a reference ground\ntruth image. The networks were able to detect motion artefacts, and the best\nperformance for the regression and classification task has always been achieved\nwith ResNet-18 with contrast augmentation. The mean and standard deviation of\nresiduals' distribution were $\\mu=-0.0009$ and $\\sigma=0.0139$, respectively.\nWhilst for the classification task in 3, 5 and 10 classes, the best accuracies\nwere 97, 95 and 89\\%, respectively. The results show that the proposed method\ncould be a tool for supporting neuro-radiologists and radiographers in\nevaluating image quality quickly.\n","authors":["Alessandro Sciarra","Soumick Chatterjee","Max Dünnwald","Giuseppe Placidi","Andreas Nürnberger","Oliver Speck","Steffen Oeltze-Jafra"],"pdf_url":"https://arxiv.org/pdf/2206.06725v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00818v1","updated":"2023-03-01T20:39:46Z","published":"2023-03-01T20:39:46Z","title":"Improving Model's Focus Improves Performance of Deep Learning-Based\n  Synthetic Face Detectors","summary":"  Deep learning-based models generalize better to unknown data samples after\nbeing guided \"where to look\" by incorporating human perception into training\nstrategies. We made an observation that the entropy of the model's salience\ntrained in that way is lower when compared to salience entropy computed for\nmodels training without human perceptual intelligence. Thus the question: does\nfurther increase of model's focus, by lowering the entropy of model's class\nactivation map, help in further increasing the performance? In this paper we\npropose and evaluate several entropy-based new loss function components\ncontrolling the model's focus, covering the full range of the level of such\ncontrol, from none to its \"aggressive\" minimization. We show, using a problem\nof synthetic face detection, that improving the model's focus, through lowering\nentropy, leads to models that perform better in an open-set scenario, in which\nthe test samples are synthesized by unknown generative models. We also show\nthat optimal performance is obtained when the model's loss function blends\nthree aspects: regular classification, low-entropy of the model's focus, and\nhuman-guided saliency.\n","authors":["Jacob Piland","Adam Czajka","Christopher Sweet"],"pdf_url":"https://arxiv.org/pdf/2303.00818v1.pdf","comment":"15 pages, 7 figures"},{"id":"http://arxiv.org/abs/2206.09034v4","updated":"2023-03-01T20:36:43Z","published":"2022-06-17T22:23:11Z","title":"Towards Better Selective Classification","summary":"  We tackle the problem of Selective Classification where the objective is to\nachieve the best performance on a predetermined ratio (coverage) of the\ndataset. Recent state-of-the-art selective methods come with architectural\nchanges either via introducing a separate selection head or an extra abstention\nlogit. In this paper, we challenge the aforementioned methods. The results\nsuggest that the superior performance of state-of-the-art methods is owed to\ntraining a more generalizable classifier rather than their proposed selection\nmechanisms. We argue that the best performing selection mechanism should\ninstead be rooted in the classifier itself. Our proposed selection strategy\nuses the classification scores and achieves better results by a significant\nmargin, consistently, across all coverages and all datasets, without any added\ncompute cost. Furthermore, inspired by semi-supervised learning, we propose an\nentropy-based regularizer that improves the performance of selective\nclassification methods. Our proposed selection mechanism with the proposed\nentropy-based regularizer achieves new state-of-the-art results.\n","authors":["Leo Feng","Mohamed Osama Ahmed","Hossein Hajimirsadeghi","Amir Abdi"],"pdf_url":"https://arxiv.org/pdf/2206.09034v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.05282v3","updated":"2023-03-01T20:24:58Z","published":"2022-06-10T07:09:28Z","title":"Learning to Estimate Shapley Values with Vision Transformers","summary":"  Transformers have become a default architecture in computer vision, but\nunderstanding what drives their predictions remains a challenging problem.\nCurrent explanation approaches rely on attention values or input gradients, but\nthese provide a limited view of a model's dependencies. Shapley values offer a\ntheoretically sound alternative, but their computational cost makes them\nimpractical for large, high-dimensional models. In this work, we aim to make\nShapley values practical for vision transformers (ViTs). To do so, we first\nleverage an attention masking approach to evaluate ViTs with partial\ninformation, and we then develop a procedure to generate Shapley value\nexplanations via a separate, learned explainer model. Our experiments compare\nShapley values to many baseline methods (e.g., attention rollout, GradCAM,\nLRP), and we find that our approach provides more accurate explanations than\nexisting methods for ViTs.\n","authors":["Ian Covert","Chanwoo Kim","Su-In Lee"],"pdf_url":"https://arxiv.org/pdf/2206.05282v3.pdf","comment":"ICLR 2023 camera-ready"},{"id":"http://arxiv.org/abs/2210.11924v2","updated":"2023-03-01T19:58:01Z","published":"2022-10-21T12:50:15Z","title":"Men Also Do Laundry: Multi-Attribute Bias Amplification","summary":"  As computer vision systems become more widely deployed, there is increasing\nconcern from both the research community and the public that these systems are\nnot only reproducing but amplifying harmful social biases. The phenomenon of\nbias amplification, which is the focus of this work, refers to models\namplifying inherent training set biases at test time. Existing metrics measure\nbias amplification with respect to single annotated attributes (e.g.,\n$\\texttt{computer}$). However, several visual datasets consist of images with\nmultiple attribute annotations. We show models can learn to exploit\ncorrelations with respect to multiple attributes (e.g., {$\\texttt{computer}$,\n$\\texttt{keyboard}$}), which are not accounted for by current metrics. In\naddition, we show current metrics can give the erroneous impression that\nminimal or no bias amplification has occurred as they involve aggregating over\npositive and negative values. Further, these metrics lack a clear desired\nvalue, making them difficult to interpret. To address these shortcomings, we\npropose a new metric: Multi-Attribute Bias Amplification. We validate our\nproposed metric through an analysis of gender bias amplification on the COCO\nand imSitu datasets. Finally, we benchmark bias mitigation methods using our\nproposed metric, suggesting possible avenues for future bias mitigation\n","authors":["Dora Zhao","Jerone T. A. Andrews","Alice Xiang"],"pdf_url":"https://arxiv.org/pdf/2210.11924v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.13224v2","updated":"2023-03-01T19:54:06Z","published":"2022-08-28T13:58:54Z","title":"Deep learning for automatic head and neck lymph node level delineation\n  provides expert-level accuracy","summary":"  Background: Deep learning (DL)-based head and neck lymph node level (HN_LNL)\nautodelineation is of high relevance to radiotherapy research and clinical\ntreatment planning but still underinvestigated in academic literature. Methods:\nAn expert-delineated cohort of 35 planning CTs was used for training of an\nnnU-net 3D-fullres/2D-ensemble model for autosegmentation of 20 different\nHN_LNL. A second cohort acquired at the same institution later in time served\nas the test set (n=20). In a completely blinded evaluation, 3 clinical experts\nrated the quality of DL autosegmentations in a head-to-head comparison with\nexpert-created contours. For a subgroup of 10 cases, intraobserver variability\nwas compared to the average DL autosegmentation accuracy on the original and\nrecontoured set of expert segmentations. A postprocessing step to adjust\ncraniocaudal boundaries of level autosegmentations to the CT slice plane was\nintroduced and the effect on geometric accuracy and expert rating was\ninvestigated. Results: Blinded expert ratings for DL segmentations and\nexpert-created contours were not significantly different. DL segmentations with\nslice plane adjustment were rated numerically higher (mean, 81.0 vs.\n79.6,p=0.185) and DL segmentations without slice plane adjustment were rated\nnumerically lower (77.2 vs. 79.6,p=0.167) than manually drawn contours. DL\nsegmentations with CT slice plane adjustment were rated significantly better\nthan DL contours without slice plane adjustment (81.0 vs. 77.2,p=0.004).\nGeometric accuracy of DL segmentations was not different from intraobserver\nvariability (mean, 0.76 vs. 0.77, p=0.307). Conclusions: We show that a nnU-net\n3D-fullres/2D-ensemble model can be used for highly accurate autodelineation of\nHN_LNL using only a limited training dataset that is ideally suited for\nlarge-scale standardized autodelineation of HN_LNL in the research setting.\n","authors":["Thomas Weissmann","Yixing Huang","Stefan Fischer","Johannes Roesch","Sina Mansoorian","Horacio Ayala Gaona","Antoniu-Oreste Gostian","Markus Hecht","Sebastian Lettmaier","Lisa Deloch","Benjamin Frey","Udo S. Gaipl","Luitpold V. Distel","Andreas Maier","Heinrich Iro","Sabine Semrau","Christoph Bert","Rainer Fietkau","Florian Putz"],"pdf_url":"https://arxiv.org/pdf/2208.13224v2.pdf","comment":"14 pages, 6 figures, published in Frontiers in Oncology"},{"id":"http://arxiv.org/abs/2303.00795v1","updated":"2023-03-01T19:48:45Z","published":"2023-03-01T19:48:45Z","title":"Improved Segmentation of Deep Sulci in Cortical Gray Matter Using a Deep\n  Learning Framework Incorporating Laplace's Equation","summary":"  When developing tools for automated cortical segmentation, the ability to\nproduce topologically correct segmentations is important in order to compute\ngeometrically valid morphometry measures. In practice, accurate cortical\nsegmentation is challenged by image artifacts and the highly convoluted anatomy\nof the cortex itself. To address this, we propose a novel deep learning-based\ncortical segmentation method in which prior knowledge about the geometry of the\ncortex is incorporated into the network during the training process. We design\na loss function which uses the theory of Laplace's equation applied to the\ncortex to locally penalize unresolved boundaries between tightly folded sulci.\nUsing an ex vivo MRI dataset of human medial temporal lobe specimens, we\ndemonstrate that our approach outperforms baseline segmentation networks, both\nquantitatively and qualitatively.\n","authors":["Sadhana Ravikumar","Ranjit Itttyerah","Sydney Lim","Long Xie","Sandhitsu Das","Pulkit Khandelwal","Laura E. M. Wisse","Madigan L. Bedard","John L. Robinson","Terry Schuck","Murray Grossman","John Q. Trojanowski","Edward B. Lee","M. Dylan Tisdall","Karthik Prabhakaran","John A. Detre","David J. Irwin","Winifred Trotman","Gabor Mizsei","Emilio Artacho-Pérula","Maria Mercedes Iñiguez de Onzono Martin","Maria del Mar Arroyo Jiménez","Monica Muñoz","Francisco Javier Molina Romero","Maria del Pilar Marcos Rabal","Sandra Cebada-Sánchez","José Carlos Delgado González","Carlos de la Rosa-Prieto","Marta Córcoles Parada","David A. Wolk","Ricardo Insausti","Paul A. Yushkevich"],"pdf_url":"https://arxiv.org/pdf/2303.00795v1.pdf","comment":"Accepted at the 28th biennial international conference on Information\n  Processing in Medical Imaging (IPMI 2023)"},{"id":"http://arxiv.org/abs/2210.09461v3","updated":"2023-03-01T19:45:11Z","published":"2022-10-17T22:23:40Z","title":"Token Merging: Your ViT But Faster","summary":"  We introduce Token Merging (ToMe), a simple method to increase the throughput\nof existing ViT models without needing to train. ToMe gradually combines\nsimilar tokens in a transformer using a general and light-weight matching\nalgorithm that is as fast as pruning while being more accurate. Off-the-shelf,\nToMe can 2x the throughput of state-of-the-art ViT-L @ 512 and ViT-H @ 518\nmodels on images and 2.2x the throughput of ViT-L on video with only a 0.2-0.3%\naccuracy drop in each case. ToMe can also easily be applied during training,\nimproving in practice training speed up to 2x for MAE fine-tuning on video.\nTraining with ToMe further minimizes accuracy drop, leading to 2x the\nthroughput of ViT-B on audio for only a 0.4% mAP drop. Qualitatively, we find\nthat ToMe merges object parts into one token, even over multiple frames of\nvideo. Overall, ToMe's accuracy and speed are competitive with state-of-the-art\non images, video, and audio.\n","authors":["Daniel Bolya","Cheng-Yang Fu","Xiaoliang Dai","Peizhao Zhang","Christoph Feichtenhofer","Judy Hoffman"],"pdf_url":"https://arxiv.org/pdf/2210.09461v3.pdf","comment":"Accepted ICLR 2023 Oral (top 5%) [final v2]. This version includes\n  stable diffusion experiments. See code at\n  https://github.com/facebookresearch/ToMe"},{"id":"http://arxiv.org/abs/2210.07998v2","updated":"2023-03-01T19:03:18Z","published":"2022-10-14T17:54:01Z","title":"$Λ$-DARTS: Mitigating Performance Collapse by Harmonizing\n  Operation Selection among Cells","summary":"  Differentiable neural architecture search (DARTS) is a popular method for\nneural architecture search (NAS), which performs cell-search and utilizes\ncontinuous relaxation to improve the search efficiency via gradient-based\noptimization. The main shortcoming of DARTS is performance collapse, where the\ndiscovered architecture suffers from a pattern of declining quality during\nsearch. Performance collapse has become an important topic of research, with\nmany methods trying to solve the issue through either regularization or\nfundamental changes to DARTS. However, the weight-sharing framework used for\ncell-search in DARTS and the convergence of architecture parameters has not\nbeen analyzed yet. In this paper, we provide a thorough and novel theoretical\nand empirical analysis on DARTS and its point of convergence. We show that\nDARTS suffers from a specific structural flaw due to its weight-sharing\nframework that limits the convergence of DARTS to saturation points of the\nsoftmax function. This point of convergence gives an unfair advantage to layers\ncloser to the output in choosing the optimal architecture, causing performance\ncollapse. We then propose two new regularization terms that aim to prevent\nperformance collapse by harmonizing operation selection via aligning gradients\nof layers. Experimental results on six different search spaces and three\ndifferent datasets show that our method ($\\Lambda$-DARTS) does indeed prevent\nperformance collapse, providing justification for our theoretical analysis and\nthe proposed remedy.\n","authors":["Sajad Movahedi","Melika Adabinejad","Ayyoob Imani","Arezou Keshavarz","Mostafa Dehghani","Azadeh Shakery","Babak N. Araabi"],"pdf_url":"https://arxiv.org/pdf/2210.07998v2.pdf","comment":"Published as a conference paper at ICLR 2023"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2303.00720v1","updated":"2023-03-01T18:26:14Z","published":"2023-03-01T18:26:14Z","title":"Cross-Modal Entity Matching for Visually Rich Documents","summary":"  Visually rich documents (VRD) are physical/digital documents that utilize\nvisual cues to augment their semantics. The information contained in these\ndocuments are often incomplete. Existing works that enable automated querying\non VRDs do not take this aspect into account. Consequently, they support a\nlimited set of queries. In this paper, we describe Juno -- a multimodal\nframework that identifies a set of tuples from a relational database to augment\nan incomplete VRD with supplementary information. Our main contribution in this\nis an end-to-end-trainable neural network with bi-directional attention that\nexecutes this cross-modal entity matching task without any prior knowledge\nabout the document type or the underlying database-schema. Exhaustive\nexperiments on two heteroegeneous datasets show that Juno outperforms\nstate-of-the-art baselines by more than 6% in F1-score, while reducing the\namount of human-effort in its workflow by more than 80%. To the best of our\nknowledge, ours is the first work that investigates the incompleteness of VRDs\nand proposes a robust framework to address it in a seamless way.\n","authors":["Ritesh Sarkhel","Arnab Nandi"],"pdf_url":"https://arxiv.org/pdf/2303.00720v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12000v2","updated":"2023-03-01T12:43:16Z","published":"2023-02-22T12:02:23Z","title":"Graph Construction using Principal Axis Trees for Simple Graph\n  Convolution","summary":"  Graph Neural Networks (GNNs) are increasingly becoming the favorite method\nfor graph learning. They exploit the semi-supervised nature of deep learning,\nand they bypass computational bottlenecks associated with traditional graph\nlearning methods. In addition to the feature matrix $X$, GNNs need an adjacency\nmatrix $A$ to perform feature propagation. In many cases the adjacency matrix\n$A$ is missing. We introduce a graph construction scheme that construct the\nadjacency matrix $A$ using unsupervised and supervised information.\nUnsupervised information characterize the neighborhood around points. We used\nPrincipal Axis trees (PA-trees) as a source of unsupervised information, where\nwe create edges between points falling onto the same leaf node. For supervised\ninformation, we used the concept of penalty and intrinsic graphs. A penalty\ngraph connects points with different class labels, whereas intrinsic graph\nconnects points with the same class label. We used the penalty and intrinsic\ngraphs to remove or add edges to the graph constructed via PA-tree. This graph\nconstruction scheme was tested on two well-known GNNs: 1) Graph Convolutional\nNetwork (GCN) and 2) Simple Graph Convolution (SGC). The experiments show that\nit is better to use SGC because it is faster and delivers better or the same\nresults as GCN. We also test the effect of oversmoothing on both GCN and SGC.\nWe found out that the level of smoothing has to be selected carefully for SGC\nto avoid oversmoothing.\n","authors":["Mashaan Alshammari","John Stavrakakis","Adel F. Ahmed","Masahiro Takatsuka"],"pdf_url":"https://arxiv.org/pdf/2302.12000v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00400v1","updated":"2023-03-01T10:39:58Z","published":"2023-03-01T10:39:58Z","title":"A Study on Accuracy, Miscalibration, and Popularity Bias in\n  Recommendations","summary":"  Recent research has suggested different metrics to measure the inconsistency\nof recommendation performance, including the accuracy difference between user\ngroups, miscalibration, and popularity lift. However, a study that relates\nmiscalibration and popularity lift to recommendation accuracy across different\nuser groups is still missing. Additionally, it is unclear if particular genres\ncontribute to the emergence of inconsistency in recommendation performance\nacross user groups. In this paper, we present an analysis of these three\naspects of five well-known recommendation algorithms for user groups that\ndiffer in their preference for popular content. Additionally, we study how\ndifferent genres affect the inconsistency of recommendation performance, and\nhow this is aligned with the popularity of the genres. Using data from LastFm,\nMovieLens, and MyAnimeList, we present two key findings. First, we find that\nusers with little interest in popular content receive the worst recommendation\naccuracy, and that this is aligned with miscalibration and popularity lift.\nSecond, our experiments show that particular genres contribute to a different\nextent to the inconsistency of recommendation performance, especially in terms\nof miscalibration in the case of the MyAnimeList dataset.\n","authors":["Dominik Kowald","Gregor Mayr","Markus Schedl","Elisabeth Lex"],"pdf_url":"https://arxiv.org/pdf/2303.00400v1.pdf","comment":"Accepted at BIAS@ECIR WS 2023"},{"id":"http://arxiv.org/abs/2303.00386v1","updated":"2023-03-01T10:11:50Z","published":"2023-03-01T10:11:50Z","title":"Authorship Conflicts in Academia: an International Cross-Discipline\n  Survey","summary":"  Collaboration among scholars has emerged as a significant characteristic of\ncontemporary science. As a result, the number of authors listed in publications\ncontinues to rise steadily. Unfortunately, determining the authors to be\nincluded in the byline and their respective order entails multiple difficulties\nwhich often lead to conflicts. Despite the large volume of literature about\nconflicts in academia, it remains unclear how exactly it is distributed over\nthe main socio-demographic properties, as well as the different types of\ninteractions academics experience. To address this gap, we conducted an\ninternational and cross-disciplinary survey answered by 752 academics from 41\nfields of research and 93 countries that statistically well-represent the\noverall academic workforce. Our findings are concerning and suggest that\nauthorship credit conflicts arise very early in one's academic career, even at\nthe level of Master and Ph.D., and become increasingly common over time.\n","authors":["Elizaveta Savchenko","Teddy Lazebnik","Ariel Rosenfeld"],"pdf_url":"https://arxiv.org/pdf/2303.00386v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.02817v2","updated":"2023-03-01T09:58:16Z","published":"2023-01-07T09:36:35Z","title":"Cost-optimal Seeding Strategy During a Botanical Pandemic in\n  Domesticated Fields","summary":"  Context: Botanical pandemics cause enormous economic damage and food shortage\naround the globe. However, since botanical pandemics are here to stay in the\nshort-medium term, domesticated field owners can strategically seed their\nfields to optimize each session's economic profit. Objective: Given the\npathogen's epidemiological properties, we aim to find an economically optimal\ngrid-based seeding strategy for field owners and policymakers. Methods: We\npropose a novel epidemiological-economic mathematical model that describes the\neconomic profit from a field of plants during a botanical pandemic. We describe\nthe epidemiological dynamics using a spatio-temporal extended\nSusceptible-Infected-Recovered epidemiological model with a non-linear output\nepidemiological model. Results and Conclusions: We provide an algorithm to\nobtain an optimal grid-formed seeding strategy to maximize economic profit,\ngiven field and pathogen properties. In addition, we implement the proposed\nmodel in realistic settings, analyzing the sensitivity of the economic profit\nas a function of several epidemiological and economic properties. We show that\nthe recovery and basic infection rates have a similar economic influence.\nUnintuitively, we show that in the context of a botanic pandemic, a larger farm\ndoes not promise higher economic profit. Significance: Our results demonstrate\na significant benefit of using the proposed seeding strategy and shed more\nlight on the dynamics of the botanical pandemic in domesticated fields.\n","authors":["Teddy Lazebnik"],"pdf_url":"https://arxiv.org/pdf/2301.02817v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00311v1","updated":"2023-03-01T08:15:48Z","published":"2023-03-01T08:15:48Z","title":"Modeling Multiple User Interests using Hierarchical Knowledge for\n  Conversational Recommender System","summary":"  A conversational recommender system (CRS) is a practical application for item\nrecommendation through natural language conversation. Such a system estimates\nuser interests for appropriate personalized recommendations. Users sometimes\nhave various interests in different categories or genres, but existing studies\nassume a unique user interest that can be covered by closely related items. In\nthis work, we propose to model such multiple user interests in CRS. We\ninvestigated its effects in experiments using the ReDial dataset and found that\nthe proposed method can recommend a wider variety of items than that of the\nbaseline CR-Walker.\n","authors":["Yuka Okuda","Katsuhito Sudoh","Seitaro Shinagawa","Satoshi Nakamura"],"pdf_url":"https://arxiv.org/pdf/2303.00311v1.pdf","comment":"Accepted as a conference paper at IWSDS 2023"},{"id":"http://arxiv.org/abs/2303.00279v1","updated":"2023-03-01T07:01:29Z","published":"2023-03-01T07:01:29Z","title":"Coarse-to-Fine Covid-19 Segmentation via Vision-Language Alignment","summary":"  Segmentation of COVID-19 lesions can assist physicians in better diagnosis\nand treatment of COVID-19. However, there are few relevant studies due to the\nlack of detailed information and high-quality annotation in the COVID-19\ndataset. To solve the above problem, we propose C2FVL, a Coarse-to-Fine\nsegmentation framework via Vision-Language alignment to merge text information\ncontaining the number of lesions and specific locations of image information.\nThe introduction of text information allows the network to achieve better\nprediction results on challenging datasets. We conduct extensive experiments on\ntwo COVID-19 datasets including chest X-ray and CT, and the results demonstrate\nthat our proposed method outperforms other state-of-the-art segmentation\nmethods.\n","authors":["Dandan Shan","Zihan Li","Wentao Chen","Qingde Li","Jie Tian","Qingqi Hong"],"pdf_url":"https://arxiv.org/pdf/2303.00279v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.00276v1","updated":"2023-03-01T06:55:43Z","published":"2023-03-01T06:55:43Z","title":"Entire Space Learning Framework: Unbias Conversion Rate Prediction in\n  Full Stages of Recommender System","summary":"  Recommender system is an essential part of online services, especially for\ne-commerce platform. Conversion Rate (CVR) prediction in RS plays a significant\nrole in optimizing Gross Merchandise Volume (GMV) goal of e-commerce. However,\nCVR suffers from well-known Sample Selection Bias (SSB) and Data Sparsity (DS)\nproblems. Although existing methods ESMM and ESM2 train with all impression\nsamples over the entire space by modeling user behavior paths, SSB and DS\nproblems still exist. In real practice, the online inference space are samples\nfrom previous stage of RS process, rather than the impression space modeled by\nexisting methods. Moreover, existing methods solve the DS problem mainly by\nbuilding behavior paths of their own specific scene, ignoring the behaviors in\nvarious scenes of e-commerce platform. In this paper, we propose Entire Space\nLearning Framework: Unbias Conversion Rate Prediction in Full Stages of\nRecommender System, solving SSB and DS problems by reformulating GMV goal in a\nnovel manner. Specifically, we rebuild the CVR on the entire data space with\nsamples from previous stage of RS process, unifying training and online\ninference space. Moreover, we explicitly introduce purchase samples from other\nscenes of e-commerce platform in model learning process. Online A/B test and\noffline experiments show the superiority of our framework. Our framework has\nbeen deployed in rank stage of Taobao recommendation, providing recommendation\nservice for hundreds of millions of consumers everyday.\n","authors":["Shanshan Lyu","Qiwei Chen","Tao Zhuang","Junfeng Ge"],"pdf_url":"https://arxiv.org/pdf/2303.00276v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00243v1","updated":"2023-03-01T05:46:36Z","published":"2023-03-01T05:46:36Z","title":"GUESR: A Global Unsupervised Data-Enhancement with Bucket-Cluster\n  Sampling for Sequential Recommendation","summary":"  Sequential Recommendation is a widely studied paradigm for learning users'\ndynamic interests from historical interactions for predicting the next\npotential item. Although lots of research work has achieved remarkable\nprogress, they are still plagued by the common issues: data sparsity of limited\nsupervised signals and data noise of accidentally clicking. To this end,\nseveral works have attempted to address these issues, which ignored the complex\nassociation of items across several sequences. Along this line, with the aim of\nlearning representative item embedding to alleviate this dilemma, we propose\nGUESR, from the view of graph contrastive learning. Specifically, we first\nconstruct the Global Item Relationship Graph (GIRG) from all interaction\nsequences and present the Bucket-Cluster Sampling (BCS) method to conduct the\nsub-graphs. Then, graph contrastive learning on this reduced graph is developed\nto enhance item representations with complex associations from the global view.\nWe subsequently extend the CapsNet module with the elaborately introduced\ntarget-attention mechanism to derive users' dynamic preferences. Extensive\nexperimental results have demonstrated our proposed GUESR could not only\nachieve significant improvements but also could be regarded as a general\nenhancement strategy to improve the performance in combination with other\nsequential recommendation methods.\n","authors":["Yongqiang Han","Likang Wu","Hao Wang","Guifeng Wang","Mengdi Zhang","Zhi Li","Defu Lian","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2303.00243v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00168v1","updated":"2023-03-01T01:46:52Z","published":"2023-03-01T01:46:52Z","title":"REASONER: An Explainable Recommendation Dataset with Multi-aspect Real\n  User Labeled Ground Truths Towards more Measurable Explainable Recommendation","summary":"  Explainable recommendation has attracted much attention from the industry and\nacademic communities. It has shown great potential for improving the\nrecommendation persuasiveness, informativeness and user satisfaction. Despite a\nlot of promising explainable recommender models have been proposed in the past\nfew years, the evaluation strategies of these models suffer from several\nlimitations. For example, the explanation ground truths are not labeled by real\nusers, the explanations are mostly evaluated based on only one aspect and the\nevaluation strategies can be hard to unify. To alleviate the above problems, we\npropose to build an explainable recommendation dataset with multi-aspect real\nuser labeled ground truths. In specific, we firstly develop a video\nrecommendation platform, where a series of questions around the recommendation\nexplainability are carefully designed. Then, we recruit about 3000 users with\ndifferent backgrounds to use the system, and collect their behaviors and\nfeedback to our questions. In this paper, we detail the construction process of\nour dataset and also provide extensive analysis on its characteristics. In\naddition, we develop a library, where ten well-known explainable recommender\nmodels are implemented in a unified framework. Based on this library, we build\nseveral benchmarks for different explainable recommendation tasks. At last, we\npresent many new opportunities brought by our dataset, which are expected to\nshed some new lights to the explainable recommendation field. Our dataset,\nlibrary and the related documents have been released at\nhttps://reasoner2023.github.io/.\n","authors":["Xu Chen","Jingsen Zhang","Lei Wang","Quanyu Dai","Zhenhua Dong","Ruiming Tang","Rui Zhang","Li Chen","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2303.00168v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00807v1","updated":"2023-03-01T20:21:23Z","published":"2023-03-01T20:21:23Z","title":"UDAPDR: Unsupervised Domain Adaptation via LLM Prompting and\n  Distillation of Rerankers","summary":"  Many information retrieval tasks require large labeled datasets for\nfine-tuning. However, such datasets are often unavailable, and their utility\nfor real-world applications can diminish quickly due to domain shifts. To\naddress this challenge, we develop and motivate a method for using large\nlanguage models (LLMs) to generate large numbers of synthetic queries cheaply.\nThe method begins by generating a small number of synthetic queries using an\nexpensive LLM. After that, a much less expensive one is used to create large\nnumbers of synthetic queries, which are used to fine-tune a family of reranker\nmodels. These rerankers are then distilled into a single efficient retriever\nfor use in the target domain. We show that this technique boosts zero-shot\naccuracy in long-tail domains, even where only 2K synthetic queries are used\nfor fine-tuning, and that it achieves substantially lower latency than standard\nreranking methods. We make our end-to-end approach, including our synthetic\ndatasets and replication code, publicly available on Github.\n","authors":["Jon Saad-Falcon","Omar Khattab","Keshav Santhanam","Radu Florian","Martin Franz","Salim Roukos","Avirup Sil","Md Arafat Sultan","Christopher Potts"],"pdf_url":"https://arxiv.org/pdf/2303.00807v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2301.07605v2","updated":"2023-03-01T18:53:22Z","published":"2023-01-18T15:37:11Z","title":"Strong inductive biases provably prevent harmless interpolation","summary":"  Classical wisdom suggests that estimators should avoid fitting noise to\nachieve good generalization. In contrast, modern overparameterized models can\nyield small test error despite interpolating noise -- a phenomenon often called\n\"benign overfitting\" or \"harmless interpolation\". This paper argues that the\ndegree to which interpolation is harmless hinges upon the strength of an\nestimator's inductive bias, i.e., how heavily the estimator favors solutions\nwith a certain structure: while strong inductive biases prevent harmless\ninterpolation, weak inductive biases can even require fitting noise to\ngeneralize well. Our main theoretical result establishes tight non-asymptotic\nbounds for high-dimensional kernel regression that reflect this phenomenon for\nconvolutional kernels, where the filter size regulates the strength of the\ninductive bias. We further provide empirical evidence of the same behavior for\ndeep neural networks with varying filter sizes and rotational invariance.\n","authors":["Michael Aerni","Marco Milanta","Konstantin Donhauser","Fanny Yang"],"pdf_url":"https://arxiv.org/pdf/2301.07605v2.pdf","comment":"Accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.00735v1","updated":"2023-03-01T18:50:59Z","published":"2023-03-01T18:50:59Z","title":"DOTE: Rethinking (Predictive) WAN Traffic Engineering","summary":"  We explore a new design point for traffic engineering on wide-area networks\n(WANs): directly optimizing traffic flow on the WAN using only historical data\nabout traffic demands. Doing so obviates the need to explicitly estimate, or\npredict, future demands. Our method, which utilizes stochastic optimization,\nprovably converges to the global optimum in well-studied theoretical models. We\nemploy deep learning to scale to large WANs and real-world traffic. Our\nextensive empirical evaluation on real-world traffic and network topologies\nestablishes that our approach's TE quality almost matches that of an\n(infeasible) omniscient oracle, outperforming previously proposed approaches,\nand also substantially lowers runtimes.\n","authors":["Yarin Perry","Felipe Vieira Frujeri","Chaim Hoch","Srikanth Kandula","Ishai Menache","Michael Schapira","Aviv Tamar"],"pdf_url":"https://arxiv.org/pdf/2303.00735v1.pdf","comment":"To appear at NSDI 2023"},{"id":"http://arxiv.org/abs/2303.00733v1","updated":"2023-03-01T18:47:41Z","published":"2023-03-01T18:47:41Z","title":"SpeechPrompt v2: Prompt Tuning for Speech Classification Tasks","summary":"  Prompt tuning is a technology that tunes a small set of parameters to steer a\npre-trained language model (LM) to directly generate the output for downstream\ntasks. Recently, prompt tuning has demonstrated its storage and computation\nefficiency in both natural language processing (NLP) and speech processing\nfields. These advantages have also revealed prompt tuning as a candidate\napproach to serving pre-trained LM for multiple tasks in a unified manner. For\nspeech processing, SpeechPrompt shows its high parameter efficiency and\ncompetitive performance on a few speech classification tasks. However, whether\nSpeechPrompt is capable of serving a large number of tasks is unanswered. In\nthis work, we propose SpeechPrompt v2, a prompt tuning framework capable of\nperforming a wide variety of speech classification tasks, covering multiple\nlanguages and prosody-related tasks. The experiment result shows that\nSpeechPrompt v2 achieves performance on par with prior works with less than\n0.15M trainable parameters in a unified framework.\n","authors":["Kai-Wei Chang","Yu-Kai Wang","Hua Shen","Iu-thing Kang","Wei-Cheng Tseng","Shang-Wen Li","Hung-yi Lee"],"pdf_url":"https://arxiv.org/pdf/2303.00733v1.pdf","comment":"Project website: https://ga642381.github.io/SpeechPrompt"},{"id":"http://arxiv.org/abs/2303.00732v1","updated":"2023-03-01T18:46:40Z","published":"2023-03-01T18:46:40Z","title":"R-U-SURE? Uncertainty-Aware Code Suggestions By Maximizing Utility\n  Across Random User Intents","summary":"  Large language models show impressive results at predicting structured text\nsuch as code, but also commonly introduce errors and hallucinations in their\noutput. When used to assist software developers, these models may make mistakes\nthat users must go back and fix, or worse, introduce subtle bugs that users may\nmiss entirely. We propose Randomized Utility-driven Synthesis of Uncertain\nREgions (R-U-SURE), an approach for building uncertainty-aware suggestions\nbased on a decision-theoretic model of goal-conditioned utility, using random\nsamples from a generative model as a proxy for the unobserved possible intents\nof the end user. Our technique combines minimum-Bayes-risk decoding, dual\ndecomposition, and decision diagrams in order to efficiently produce structured\nuncertainty summaries, given only sample access to an arbitrary generative\nmodel of code and an optional AST parser. We demonstrate R-U-SURE on three\ndeveloper-assistance tasks, and show that it can be applied different user\ninteraction patterns without retraining the model and leads to more accurate\nuncertainty estimates than token-probability baselines.\n","authors":["Daniel D. Johnson","Daniel Tarlow","Christian Walder"],"pdf_url":"https://arxiv.org/pdf/2303.00732v1.pdf","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2303.00728v1","updated":"2023-03-01T18:42:14Z","published":"2023-03-01T18:42:14Z","title":"On the universality of $S_n$-equivariant $k$-body gates","summary":"  The importance of symmetries has recently been recognized in quantum machine\nlearning from the simple motto: if a task exhibits a symmetry (given by a group\n$\\mathfrak{G}$), the learning model should respect said symmetry. This can be\ninstantiated via $\\mathfrak{G}$-equivariant Quantum Neural Networks (QNNs),\ni.e., parametrized quantum circuits whose gates are generated by operators\ncommuting with a given representation of $\\mathfrak{G}$. In practice, however,\nthere might be additional restrictions to the types of gates one can use, such\nas being able to act on at most $k$ qubits. In this work we study how the\ninterplay between symmetry and $k$-bodyness in the QNN generators affect its\nexpressiveness for the special case of $\\mathfrak{G}=S_n$, the symmetric group.\nOur results show that if the QNN is generated by one- and two-body\n$S_n$-equivariant gates, the QNN is semi-universal but not universal. That is,\nthe QNN can generate any arbitrary special unitary matrix in the invariant\nsubspaces, but has no control over the relative phases between them. Then, we\nshow that in order to reach universality one needs to include $n$-body\ngenerators (if $n$ is even) or $(n-1)$-body generators (if $n$ is odd). As\nsuch, our results brings us a step closer to better understanding the\ncapabilities and limitations of equivariant QNNs.\n","authors":["Sujay Kazi","Martin Larocca","M. Cerezo"],"pdf_url":"https://arxiv.org/pdf/2303.00728v1.pdf","comment":"8+14 pages, 3+5 figures"},{"id":"http://arxiv.org/abs/2302.00695v2","updated":"2023-03-01T18:38:26Z","published":"2023-02-01T19:00:10Z","title":"Versatile Energy-Based Models for High Energy Physics","summary":"  Energy-based models have the natural advantage of flexibility in the form of\nthe energy function. Recently, energy-based models have achieved great success\nin modeling high-dimensional data in computer vision and natural language\nprocessing. In accordance with these signs of progress, we build a versatile\nenergy-based model for High Energy Physics events at the Large Hadron Collider.\nThis framework builds on a powerful generative model and describes higher-order\ninter-particle interactions. It suits different encoding architectures and\nbuilds on implicit generation. As for applicational aspects, it can serve as a\npowerful parameterized event generator, a generic anomalous signal detector,\nand an augmented event classifier.\n","authors":["Taoli Cheng","Aaron Courville"],"pdf_url":"https://arxiv.org/pdf/2302.00695v2.pdf","comment":"17 pages, 8 figures"},{"id":"http://arxiv.org/abs/2301.13371v2","updated":"2023-03-01T18:32:04Z","published":"2023-01-31T02:31:18Z","title":"Demystifying Disagreement-on-the-Line in High Dimensions","summary":"  Evaluating the performance of machine learning models under distribution\nshift is challenging, especially when we only have unlabeled data from the\nshifted (target) domain, along with labeled data from the original (source)\ndomain. Recent work suggests that the notion of disagreement, the degree to\nwhich two models trained with different randomness differ on the same input, is\na key to tackle this problem. Experimentally, disagreement and prediction error\nhave been shown to be strongly connected, which has been used to estimate model\nperformance. Experiments have led to the discovery of the\ndisagreement-on-the-line phenomenon, whereby the classification error under the\ntarget domain is often a linear function of the classification error under the\nsource domain; and whenever this property holds, disagreement under the source\nand target domain follow the same linear relation. In this work, we develop a\ntheoretical foundation for analyzing disagreement in high-dimensional random\nfeatures regression; and study under what conditions the\ndisagreement-on-the-line phenomenon occurs in our setting. Experiments on\nCIFAR-10-C, Tiny ImageNet-C, and Camelyon17 are consistent with our theory and\nsupport the universality of the theoretical findings.\n","authors":["Donghwan Lee","Behrad Moniri","Xinmeng Huang","Edgar Dobriban","Hamed Hassani"],"pdf_url":"https://arxiv.org/pdf/2301.13371v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12360v2","updated":"2023-03-01T18:28:36Z","published":"2023-02-23T22:53:02Z","title":"Practical Knowledge Distillation: Using DNNs to Beat DNNs","summary":"  For tabular data sets, we explore data and model distillation, as well as\ndata denoising. These techniques improve both gradient-boosting models and a\nspecialized DNN architecture. While gradient boosting is known to outperform\nDNNs on tabular data, we close the gap for datasets with 100K+ rows and give\nDNNs an advantage on small data sets. We extend these results with input-data\ndistillation and optimized ensembling to help DNN performance match or exceed\nthat of gradient boosting. As a theoretical justification of our practical\nmethod, we prove its equivalence to classical cross-entropy knowledge\ndistillation. We also qualitatively explain the superiority of DNN ensembles\nover XGBoost on small data sets. For an industry end-to-end real-time ML\nplatform with 4M production inferences per second, we develop a model-training\nworkflow based on data sampling that distills ensembles of models into a single\ngradient-boosting model favored for high-performance real-time inference,\nwithout performance loss. Empirical evaluation shows that the proposed\ncombination of methods consistently improves model accuracy over prior best\nmodels across several production applications deployed worldwide.\n","authors":["Chung-Wei Lee","Pavlos Athanasios Apostolopulos","Igor L. Markov"],"pdf_url":"https://arxiv.org/pdf/2302.12360v2.pdf","comment":"11 pages, 1 figure, 17 tables"},{"id":"http://arxiv.org/abs/2303.00721v1","updated":"2023-03-01T18:26:44Z","published":"2023-03-01T18:26:44Z","title":"Bootstrapping Parallel Anchors for Relative Representations","summary":"  The use of relative representations for latent embeddings has shown potential\nin enabling latent space communication and zero-shot model stitching across a\nwide range of applications. Nevertheless, relative representations rely on a\ncertain amount of parallel anchors to be given as input, which can be\nimpractical to obtain in certain scenarios. To overcome this limitation, we\npropose an optimization-based method to discover new parallel anchors from a\nlimited number of seeds. Our approach can be used to find semantic\ncorrespondence between different domains, align their relative spaces, and\nachieve competitive results in several tasks.\n","authors":["Irene Cannistraci","Luca Moschella","Valentino Maiorca","Marco Fumero","Antonio Norelli","Emanuele Rodolà"],"pdf_url":"https://arxiv.org/pdf/2303.00721v1.pdf","comment":"9 pages, 7 tables"},{"id":"http://arxiv.org/abs/2303.00720v1","updated":"2023-03-01T18:26:14Z","published":"2023-03-01T18:26:14Z","title":"Cross-Modal Entity Matching for Visually Rich Documents","summary":"  Visually rich documents (VRD) are physical/digital documents that utilize\nvisual cues to augment their semantics. The information contained in these\ndocuments are often incomplete. Existing works that enable automated querying\non VRDs do not take this aspect into account. Consequently, they support a\nlimited set of queries. In this paper, we describe Juno -- a multimodal\nframework that identifies a set of tuples from a relational database to augment\nan incomplete VRD with supplementary information. Our main contribution in this\nis an end-to-end-trainable neural network with bi-directional attention that\nexecutes this cross-modal entity matching task without any prior knowledge\nabout the document type or the underlying database-schema. Exhaustive\nexperiments on two heteroegeneous datasets show that Juno outperforms\nstate-of-the-art baselines by more than 6% in F1-score, while reducing the\namount of human-effort in its workflow by more than 80%. To the best of our\nknowledge, ours is the first work that investigates the incompleteness of VRDs\nand proposes a robust framework to address it in a seamless way.\n","authors":["Ritesh Sarkhel","Arnab Nandi"],"pdf_url":"https://arxiv.org/pdf/2303.00720v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.02912v2","updated":"2023-03-01T18:22:47Z","published":"2022-10-06T13:30:16Z","title":"CANIFE: Crafting Canaries for Empirical Privacy Measurement in Federated\n  Learning","summary":"  Federated Learning (FL) is a setting for training machine learning models in\ndistributed environments where the clients do not share their raw data but\ninstead send model updates to a server. However, model updates can be subject\nto attacks and leak private information. Differential Privacy (DP) is a leading\nmitigation strategy which involves adding noise to clipped model updates,\ntrading off performance for strong theoretical privacy guarantees. Previous\nwork has shown that the threat model of DP is conservative and that the\nobtained guarantees may be vacuous or may overestimate information leakage in\npractice. In this paper, we aim to achieve a tighter measurement of the model\nexposure by considering a realistic threat model. We propose a novel method,\nCANIFE, that uses canaries - carefully crafted samples by a strong adversary to\nevaluate the empirical privacy of a training round. We apply this attack to\nvision models trained on CIFAR-10 and CelebA and to language models trained on\nSent140 and Shakespeare. In particular, in realistic FL scenarios, we\ndemonstrate that the empirical per-round epsilon obtained with CANIFE is 4-5x\nlower than the theoretical bound.\n","authors":["Samuel Maddock","Alexandre Sablayrolles","Pierre Stock"],"pdf_url":"https://arxiv.org/pdf/2210.02912v2.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2303.00716v1","updated":"2023-03-01T18:20:24Z","published":"2023-03-01T18:20:24Z","title":"Aligning benchmark datasets for table structure recognition","summary":"  Benchmark datasets for table structure recognition (TSR) must be carefully\nprocessed to ensure they are annotated consistently. However, even if a\ndataset's annotations are self-consistent, there may be significant\ninconsistency across datasets, which can harm the performance of models trained\nand evaluated on them. In this work, we show that aligning these\nbenchmarks$\\unicode{x2014}$removing both errors and inconsistency between\nthem$\\unicode{x2014}$improves model performance significantly. We demonstrate\nthis through a data-centric approach where we adopt a single model\narchitecture, the Table Transformer (TATR), that we hold fixed throughout.\nBaseline exact match accuracy for TATR evaluated on the ICDAR-2013 benchmark is\n65% when trained on PubTables-1M, 42% when trained on FinTabNet, and 69%\ncombined. After reducing annotation mistakes and inter-dataset inconsistency,\nperformance of TATR evaluated on ICDAR-2013 increases substantially to 75% when\ntrained on PubTables-1M, 65% when trained on FinTabNet, and 81% combined. We\nshow through ablations over the modification steps that canonicalization of the\ntable annotations has a significantly positive effect on performance, while\nother choices balance necessary trade-offs that arise when deciding a benchmark\ndataset's final composition. Overall we believe our work has significant\nimplications for benchmark design for TSR and potentially other tasks as well.\nAll dataset processing and training code will be released.\n","authors":["Brandon Smock","Rohith Pesala","Robin Abraham"],"pdf_url":"https://arxiv.org/pdf/2303.00716v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.02742v6","updated":"2023-03-01T18:19:45Z","published":"2022-12-06T04:15:24Z","title":"A Learning Based Hypothesis Test for Harmful Covariate Shift","summary":"  The ability to quickly and accurately identify covariate shift at test time\nis a critical and often overlooked component of safe machine learning systems\ndeployed in high-risk domains. While methods exist for detecting when\npredictions should not be made on out-of-distribution test examples,\nidentifying distributional level differences between training and test time can\nhelp determine when a model should be removed from the deployment setting and\nretrained. In this work, we define harmful covariate shift (HCS) as a change in\ndistribution that may weaken the generalization of a predictive model. To\ndetect HCS, we use the discordance between an ensemble of classifiers trained\nto agree on training data and disagree on test data. We derive a loss function\nfor training this ensemble and show that the disagreement rate and entropy\nrepresent powerful discriminative statistics for HCS. Empirically, we\ndemonstrate the ability of our method to detect harmful covariate shift with\nstatistical certainty on a variety of high-dimensional datasets. Across\nnumerous domains and modalities, we show state-of-the-art performance compared\nto existing methods, particularly when the number of observed test samples is\nsmall.\n","authors":["Tom Ginsberg","Zhongyuan Liang","Rahul G. Krishnan"],"pdf_url":"https://arxiv.org/pdf/2212.02742v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.09329v2","updated":"2023-03-01T18:06:44Z","published":"2022-09-19T20:13:29Z","title":"MAN: Multi-Action Networks Learning","summary":"  Learning control policies with large discrete action spaces is a challenging\nproblem in the field of reinforcement learning due to present inefficiencies in\nexploration. With high dimensional action spaces, there are a large number of\npotential actions in each individual dimension over which policies would be\nlearned. In this work, we introduce a Deep Reinforcement Learning (DRL)\nalgorithm call Multi-Action Networks (MAN) Learning that addresses the\nchallenge of high-dimensional large discrete action spaces. We propose\nfactorizing the N-dimension action space into N 1-dimensional components, known\nas sub-actions, creating a Value Neural Network for each sub-action. Then, MAN\nuses temporal-difference learning to train the networks synchronously, which is\nsimpler than training a single network with a large action output directly. To\nevaluate the proposed method, we test MAN on three scenarios: an n-dimension\nmaze task, a block stacking task, and then extend MAN to handle 12 games from\nthe Atari Arcade Learning environment with 18 action spaces. Our results\nindicate that MAN learns faster than both Deep Q-Learning and Double Deep\nQ-Learning, implying our method is a better performing synchronous temporal\ndifference algorithm than those currently available for large discrete action\nspaces.\n","authors":["Keqin Wang","Alison Bartsch","Amir Barati Farimani"],"pdf_url":"https://arxiv.org/pdf/2209.09329v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.14935v2","updated":"2023-03-01T18:01:09Z","published":"2022-09-29T16:54:05Z","title":"Does Zero-Shot Reinforcement Learning Exist?","summary":"  A zero-shot RL agent is an agent that can solve any RL task in a given\nenvironment, instantly with no additional planning or learning, after an\ninitial reward-free learning phase. This marks a shift from the reward-centric\nRL paradigm towards \"controllable\" agents that can follow arbitrary\ninstructions in an environment. Current RL agents can solve families of related\ntasks at best, or require planning anew for each task. Strategies for\napproximate zero-shot RL ave been suggested using successor features (SFs)\n[BBQ+ 18] or forward-backward (FB) representations [TO21], but testing has been\nlimited.\n  After clarifying the relationships between these schemes, we introduce\nimproved losses and new SF models, and test the viability of zero-shot RL\nschemes systematically on tasks from the Unsupervised RL benchmark [LYL+21]. To\ndisentangle universal representation learning from exploration, we work in an\noffline setting and repeat the tests on several existing replay buffers.\n  SFs appear to suffer from the choice of the elementary state features. SFs\nwith Laplacian eigenfunctions do well, while SFs based on auto-encoders,\ninverse curiosity, transition models, low-rank transition matrix, contrastive\nlearning, or diversity (APS), perform unconsistently. In contrast, FB\nrepresentations jointly learn the elementary and successor features from a\nsingle, principled criterion. They perform best and consistently across the\nboard, reaching 85% of supervised RL performance with a good replay buffer, in\na zero-shot manner.\n","authors":["Ahmed Touati","Jérémy Rapin","Yann Ollivier"],"pdf_url":"https://arxiv.org/pdf/2209.14935v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.04368v2","updated":"2023-03-01T17:51:40Z","published":"2023-01-11T09:26:16Z","title":"On the functional form of the radial acceleration relation","summary":"  We apply a new method for learning equations from data -- Exhaustive Symbolic\nRegression (ESR) -- to late-type galaxy dynamics as encapsulated in the radial\nacceleration relation (RAR). Relating the centripetal acceleration due to\nbaryons, $g_\\text{bar}$, to the total dynamical acceleration, $g_\\text{obs}$,\nthe RAR has been claimed to manifest a new law of nature due to its regularity\nand tightness, in agreement with Modified Newtonian Dynamics (MOND). Fits to\nthis relation have been restricted by prior expectations to particular\nfunctional forms, while ESR affords an exhaustive and nearly prior-free search\nthrough functional parameter space to identify the equations optimally trading\naccuracy with simplicity. Working with the SPARC data, we find the best\nfunctions typically satisfy $g_\\text{obs} \\propto g_\\text{bar}$ at high\n$g_\\text{bar}$, although the coefficient of proportionality is not clearly\nunity and the deep-MOND limit $g_\\text{obs} \\propto \\sqrt{g_\\text{bar}}$ as\n$g_\\text{bar} \\to 0$ is little evident at all. By generating mock data\naccording to MOND with or without the external field effect, we find that\nsymbolic regression would not be expected to identify the generating function\nor reconstruct successfully the asymptotic slopes. We conclude that the limited\ndynamical range and significant uncertainties of the SPARC RAR preclude a\ndefinitive statement of its functional form, and hence that this data alone can\nneither demonstrate nor rule out law-like gravitational behaviour.\n","authors":["Harry Desmond","Deaglan J. Bartlett","Pedro G. Ferreira"],"pdf_url":"https://arxiv.org/pdf/2301.04368v2.pdf","comment":"12+4 pages, 4 figures, 3 tables; minor revision to match MNRAS\n  published version"},{"id":"http://arxiv.org/abs/2303.00694v1","updated":"2023-03-01T17:42:26Z","published":"2023-03-01T17:42:26Z","title":"The Virtues of Laziness in Model-based RL: A Unified Objective and\n  Algorithms","summary":"  We propose a novel approach to addressing two fundamental challenges in\nModel-based Reinforcement Learning (MBRL): the computational expense of\nrepeatedly finding a good policy in the learned model, and the objective\nmismatch between model fitting and policy computation. Our \"lazy\" method\nleverages a novel unified objective, Performance Difference via Advantage in\nModel, to capture the performance difference between the learned policy and\nexpert policy under the true dynamics. This objective demonstrates that\noptimizing the expected policy advantage in the learned model under an\nexploration distribution is sufficient for policy computation, resulting in a\nsignificant boost in computational efficiency compared to traditional planning\nmethods. Additionally, the unified objective uses a value moment matching term\nfor model fitting, which is aligned with the model's usage during policy\ncomputation. We present two no-regret algorithms to optimize the proposed\nobjective, and demonstrate their statistical and computational gains compared\nto existing MBRL methods through simulated benchmarks.\n","authors":["Anirudh Vemula","Yuda Song","Aarti Singh","J. Andrew Bagnell","Sanjiban Choudhury"],"pdf_url":"https://arxiv.org/pdf/2303.00694v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.17028v2","updated":"2023-03-01T17:41:25Z","published":"2022-10-31T03:00:11Z","title":"Improved Learning-augmented Algorithms for k-means and k-medians\n  Clustering","summary":"  We consider the problem of clustering in the learning-augmented setting,\nwhere we are given a data set in $d$-dimensional Euclidean space, and a label\nfor each data point given by an oracle indicating what subsets of points should\nbe clustered together. This setting captures situations where we have access to\nsome auxiliary information about the data set relevant for our clustering\nobjective, for instance the labels output by a neural network. Following prior\nwork, we assume that there are at most an $\\alpha \\in (0,c)$ for some $c<1$\nfraction of false positives and false negatives in each predicted cluster, in\nthe absence of which the labels would attain the optimal clustering cost\n$\\mathrm{OPT}$.\n  For a dataset of size $m$, we propose a deterministic $k$-means algorithm\nthat produces centers with improved bound on clustering cost compared to the\nprevious randomized algorithm while preserving the $O( d m \\log m)$ runtime.\nFurthermore, our algorithm works even when the predictions are not very\naccurate, i.e. our bound holds for $\\alpha$ up to $1/2$, an improvement over\n$\\alpha$ being at most $1/7$ in the previous work. For the $k$-medians problem\nwe improve upon prior work by achieving a biquadratic improvement in the\ndependence of the approximation factor on the accuracy parameter $\\alpha$ to\nget a cost of $(1+O(\\alpha))\\mathrm{OPT}$, while requiring essentially just\n$O(md \\log^3 m/\\alpha)$ runtime.\n","authors":["Thy Nguyen","Anamay Chaturvedi","Huy Lê Nguyen"],"pdf_url":"https://arxiv.org/pdf/2210.17028v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00691v1","updated":"2023-03-01T17:39:08Z","published":"2023-03-01T17:39:08Z","title":"On the Importance of Feature Representation for Flood Mapping using\n  Classical Machine Learning Approaches","summary":"  Climate change has increased the severity and frequency of weather disasters\nall around the world. Flood inundation mapping based on earth observation data\ncan help in this context, by providing cheap and accurate maps depicting the\narea affected by a flood event to emergency-relief units in near-real-time.\nBuilding upon the recent development of the Sen1Floods11 dataset, which\nprovides a limited amount of hand-labeled high-quality training data, this\npaper evaluates the potential of five traditional machine learning approaches\nsuch as gradient boosted decision trees, support vector machines or quadratic\ndiscriminant analysis. By performing a grid-search-based hyperparameter\noptimization on 23 feature spaces we can show that all considered classifiers\nare capable of outperforming the current state-of-the-art neural network-based\napproaches in terms of total IoU on their best-performing feature spaces. With\ntotal and mean IoU values of 0.8751 and 0.7031 compared to 0.70 and 0.5873 as\nthe previous best-reported results, we show that a simple gradient boosting\nclassifier can significantly improve over deep neural network based approaches,\ndespite using less training data. Furthermore, an analysis of the regional\ndistribution of the Sen1Floods11 dataset reveals a problem of spatial\nimbalance. We show that traditional machine learning models can learn this bias\nand argue that modified metric evaluations are required to counter artifacts\ndue to spatial imbalance. Lastly, a qualitative analysis shows that this\npixel-wise classifier provides highly-precise surface water classifications\nindicating that a good choice of a feature space and pixel-wise classification\ncan generate high-quality flood maps using optical and SAR data. We make our\ncode publicly available at:\nhttps://github.com/DFKI-Earth-And-Space-Applications/Flood_Mapping_Feature_Space_Importance\n","authors":["Kevin Iselborn","Marco Stricker","Takashi Miyamoto","Marlon Nuske","Andreas Dengel"],"pdf_url":"https://arxiv.org/pdf/2303.00691v1.pdf","comment":"24 pages, 9 figures, submitted to Remote Sensing of Environment and\n  code is available at\n  https://github.com/DFKI-Earth-And-Space-Applications/Flood_Mapping_Feature_Space_Importance"},{"id":"http://arxiv.org/abs/2303.00673v1","updated":"2023-03-01T17:12:49Z","published":"2023-03-01T17:12:49Z","title":"Fairness Evaluation in Text Classification: Machine Learning\n  Practitioner Perspectives of Individual and Group Fairness","summary":"  Mitigating algorithmic bias is a critical task in the development and\ndeployment of machine learning models. While several toolkits exist to aid\nmachine learning practitioners in addressing fairness issues, little is known\nabout the strategies practitioners employ to evaluate model fairness and what\nfactors influence their assessment, particularly in the context of text\nclassification. Two common approaches of evaluating the fairness of a model are\ngroup fairness and individual fairness. We run a study with Machine Learning\npractitioners (n=24) to understand the strategies used to evaluate models.\nMetrics presented to practitioners (group vs. individual fairness) impact which\nmodels they consider fair. Participants focused on risks associated with\nunderpredicting/overpredicting and model sensitivity relative to identity token\nmanipulations. We discover fairness assessment strategies involving personal\nexperiences or how users form groups of identity tokens to test model fairness.\nWe provide recommendations for interactive tools for evaluating fairness in\ntext classification.\n","authors":["Zahra Ashktorab","Benjamin Hoover","Mayank Agarwal","Casey Dugan","Werner Geyer","Hao Bang Yang","Mikhail Yurochkin"],"pdf_url":"https://arxiv.org/pdf/2303.00673v1.pdf","comment":"To appear in Proceedings of the 2023 CHI Conference on Human Factors\n  in Computing Systems (CHI '23)"},{"id":"http://arxiv.org/abs/2303.00654v1","updated":"2023-03-01T16:56:39Z","published":"2023-03-01T16:56:39Z","title":"How to DP-fy ML: A Practical Guide to Machine Learning with Differential\n  Privacy","summary":"  ML models are ubiquitous in real world applications and are a constant focus\nof research. At the same time, the community has started to realize the\nimportance of protecting the privacy of ML training data.\n  Differential Privacy (DP) has become a gold standard for making formal\nstatements about data anonymization. However, while some adoption of DP has\nhappened in industry, attempts to apply DP to real world complex ML models are\nstill few and far between. The adoption of DP is hindered by limited practical\nguidance of what DP protection entails, what privacy guarantees to aim for, and\nthe difficulty of achieving good privacy-utility-computation trade-offs for ML\nmodels. Tricks for tuning and maximizing performance are scattered among papers\nor stored in the heads of practitioners. Furthermore, the literature seems to\npresent conflicting evidence on how and whether to apply architectural\nadjustments and which components are ``safe'' to use with DP.\n  This work is a self-contained guide that gives an in-depth overview of the\nfield of DP ML and presents information about achieving the best possible DP ML\nmodel with rigorous privacy guarantees. Our target audience is both researchers\nand practitioners. Researchers interested in DP for ML will benefit from a\nclear overview of current advances and areas for improvement. We include\ntheory-focused sections that highlight important topics such as privacy\naccounting and its assumptions, and convergence. For a practitioner, we provide\na background in DP theory and a clear step-by-step guide for choosing an\nappropriate privacy definition and approach, implementing DP training,\npotentially updating the model architecture, and tuning hyperparameters. For\nboth researchers and practitioners, consistently and fully reporting privacy\nguarantees is critical, and so we propose a set of specific best practices for\nstating guarantees.\n","authors":["Natalia Ponomareva","Hussein Hazimeh","Alex Kurakin","Zheng Xu","Carson Denison","H. Brendan McMahan","Sergei Vassilvitskii","Steve Chien","Abhradeep Thakurta"],"pdf_url":"https://arxiv.org/pdf/2303.00654v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00652v1","updated":"2023-03-01T16:54:48Z","published":"2023-03-01T16:54:48Z","title":"Finding the right XAI method -- A Guide for the Evaluation and Ranking\n  of Explainable AI Methods in Climate Science","summary":"  Explainable artificial intelligence (XAI) methods shed light on the\npredictions of deep neural networks (DNNs). Several different approaches exist\nand have partly already been successfully applied in climate science. However,\nthe often missing ground truth explanations complicate their evaluation and\nvalidation, subsequently compounding the choice of the XAI method. Therefore,\nin this work, we introduce XAI evaluation in the context of climate research\nand assess different desired explanation properties, namely, robustness,\nfaithfulness, randomization, complexity, and localization. To this end we build\nupon previous work and train a multi-layer perceptron (MLP) and a convolutional\nneural network (CNN) to predict the decade based on annual-mean temperature\nmaps. Next, multiple local XAI methods are applied and their performance is\nquantified for each evaluation property and compared against a baseline test.\nIndependent of the network type, we find that the XAI methods Integrated\nGradients, Layer-wise relevance propagation, and InputGradients exhibit\nconsiderable robustness, faithfulness, and complexity while sacrificing\nrandomization. The opposite is true for Gradient, SmoothGrad, NoiseGrad, and\nFusionGrad. Notably, explanations using input perturbations, such as SmoothGrad\nand Integrated Gradients, do not improve robustness and faithfulness, contrary\nto previous claims. Overall, our experiments offer a comprehensive overview of\ndifferent properties of explanation methods in the climate science context and\nsupports users in the selection of a suitable XAI method.\n","authors":["Philine Bommer","Marlene Kretschmer","Anna Hedström","Dilyara Bareeva","Marina M. -C. Höhne"],"pdf_url":"https://arxiv.org/pdf/2303.00652v1.pdf","comment":"17 pages, 8 figure, under review"},{"id":"http://arxiv.org/abs/2302.08973v2","updated":"2023-03-01T16:47:49Z","published":"2023-02-17T16:19:26Z","title":"Measuring Equality in Machine Learning Security Defenses","summary":"  The machine learning security community has developed myriad defenses for\nevasion attacks over the past decade. An understudied question in that\ncommunity is: for whom do these defenses defend? In this work, we consider some\ncommon approaches to defending learned systems and whether those approaches may\noffer unexpected performance inequities when used by different sub-populations.\nWe outline simple parity metrics and a framework for analysis that can begin to\nanswer this question through empirical results of the fairness implications of\nmachine learning security methods. Many methods have been proposed that can\ncause direct harm, which we describe as biased vulnerability and biased\nrejection. Our framework and metric can be applied to robustly trained models,\npreprocessing-based methods, and rejection methods to capture behavior over\nsecurity budgets. We identify a realistic dataset with a reasonable\ncomputational cost suitable for measuring the equality of defenses. Through a\ncase study in speech command recognition, we show how such defenses do not\noffer equal protection for social subgroups and how to perform such analyses\nfor robustness training, and we present a comparison of fairness between two\nrejection-based defenses: randomized smoothing and neural rejection. We offer\nfurther analysis of factors that correlate to equitable defenses to stimulate\nthe future investigation of how to assist in building such defenses. To the\nbest of our knowledge, this is the first work that examines the fairness\ndisparity in the accuracy-robustness trade-off in speech data and addresses\nfairness evaluation for rejection-based defenses.\n","authors":["Luke E. Richards","Edward Raff","Cynthia Matuszek"],"pdf_url":"https://arxiv.org/pdf/2302.08973v2.pdf","comment":"In Submission"},{"id":"http://arxiv.org/abs/2112.07110v9","updated":"2023-03-01T16:44:09Z","published":"2021-12-14T02:25:43Z","title":"Non-Asymptotic Analysis of Online Multiplicative Stochastic Gradient\n  Descent","summary":"  Past research has indicated that the covariance of the Stochastic Gradient\nDescent (SGD) error done via minibatching plays a critical role in determining\nits regularization and escape from low potential points. Motivated by some new\nresearch in this area, we prove universality results by showing that noise\nclasses that have the same mean and covariance structure of SGD via\nminibatching have similar properties. We mainly consider the Multiplicative\nStochastic Gradient Descent (M-SGD) algorithm as introduced in previous work,\nwhich has a much more general noise class than the SGD algorithm done via\nminibatching. We establish non asymptotic bounds for the M-SGD algorithm in the\nWasserstein distance. We also show that the M-SGD error is approximately a\nscaled Gaussian distribution with mean $0$ at any fixed point of the M-SGD\nalgorithm.\n","authors":["Riddhiman Bhattacharya","Tiefeng Jiang"],"pdf_url":"https://arxiv.org/pdf/2112.07110v9.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00638v1","updated":"2023-03-01T16:40:54Z","published":"2023-03-01T16:40:54Z","title":"MEGA-DAgger: Imitation Learning with Multiple Imperfect Experts","summary":"  Imitation learning has been widely applied to various autonomous systems\nthanks to recent development in interactive algorithms that address covariate\nshift and compounding errors induced by traditional approaches like behavior\ncloning. However, existing interactive imitation learning methods assume access\nto one perfect expert. Whereas in reality, it is more likely to have multiple\nimperfect experts instead. In this paper, we propose MEGA-DAgger, a new DAgger\nvariant that is suitable for interactive learning with multiple imperfect\nexperts. First, unsafe demonstrations are filtered while aggregating the\ntraining data, so the imperfect demonstrations have little influence when\ntraining the novice policy. Next, experts are evaluated and compared on\nscenarios-specific metrics to resolve the conflicted labels among experts.\nThrough experiments in autonomous racing scenarios, we demonstrate that policy\nlearned using MEGA-DAgger can outperform both experts and policies learned\nusing the state-of-the-art interactive imitation learning algorithm. The\nsupplementary video can be found at https://youtu.be/pYQiPSHk6dU.\n","authors":["Xiatao Sun","Shuo Yang","Rahul Mangharam"],"pdf_url":"https://arxiv.org/pdf/2303.00638v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.15466v6","updated":"2023-03-01T16:31:13Z","published":"2022-05-30T23:44:09Z","title":"Data Banzhaf: A Robust Data Valuation Framework for Machine Learning","summary":"  Data valuation has wide use cases in machine learning, including improving\ndata quality and creating economic incentives for data sharing. This paper\nstudies the robustness of data valuation to noisy model performance scores.\nParticularly, we find that the inherent randomness of the widely used\nstochastic gradient descent can cause existing data value notions (e.g., the\nShapley value and the Leave-one-out error) to produce inconsistent data value\nrankings across different runs. To address this challenge, we introduce the\nconcept of safety margin, which measures the robustness of a data value notion.\nWe show that the Banzhaf value, a famous value notion that originated from\ncooperative game theory literature, achieves the largest safety margin among\nall semivalues (a class of value notions that satisfy crucial properties\nentailed by ML applications and include the famous Shapley value and\nLeave-one-out error). We propose an algorithm to efficiently estimate the\nBanzhaf value based on the Maximum Sample Reuse (MSR) principle. Our evaluation\ndemonstrates that the Banzhaf value outperforms the existing semivalue-based\ndata value notions on several ML tasks such as learning with weighted samples\nand noisy label detection. Overall, our study suggests that when the underlying\nML algorithm is stochastic, the Banzhaf value is a promising alternative to the\nother semivalue-based data value schemes given its computational advantage and\nability to robustly differentiate data quality.\n","authors":["Jiachen T. Wang","Ruoxi Jia"],"pdf_url":"https://arxiv.org/pdf/2205.15466v6.pdf","comment":"AISTATS 2023 Oral"},{"id":"http://arxiv.org/abs/2211.02093v2","updated":"2023-03-01T16:31:04Z","published":"2022-11-03T18:49:38Z","title":"Domain Adaptation under Missingness Shift","summary":"  Rates of missing data often depend on record-keeping policies and thus may\nchange across times and locations, even when the underlying features are\ncomparatively stable. In this paper, we introduce the problem of Domain\nAdaptation under Missingness Shift (DAMS). Here, (labeled) source data and\n(unlabeled) target data would be exchangeable but for different missing data\nmechanisms. We show that if missing data indicators are available, DAMS reduces\nto covariate shift. Addressing cases where such indicators are absent, we\nestablish the following theoretical results for underreporting completely at\nrandom: (i) covariate shift is violated (adaptation is required); (ii) the\noptimal linear source predictor can perform arbitrarily worse on the target\ndomain than always predicting the mean; (iii) the optimal target predictor can\nbe identified, even when the missingness rates themselves are not; and (iv) for\nlinear models, a simple analytic adjustment yields consistent estimates of the\noptimal target parameters. In experiments on synthetic and semi-synthetic data,\nwe demonstrate the promise of our methods when assumptions hold. Finally, we\ndiscuss a rich family of future extensions.\n","authors":["Helen Zhou","Sivaraman Balakrishnan","Zachary C. Lipton"],"pdf_url":"https://arxiv.org/pdf/2211.02093v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00620v1","updated":"2023-03-01T16:22:22Z","published":"2023-03-01T16:22:22Z","title":"Multi-Armed Bandits with Generalized Temporally-Partitioned Rewards","summary":"  Decision-making problems of sequential nature, where decisions made in the\npast may have an impact on the future, are used to model many practically\nimportant applications. In some real-world applications, feedback about a\ndecision is delayed and may arrive via partial rewards that are observed with\ndifferent delays. Motivated by such scenarios, we propose a novel problem\nformulation called multi-armed bandits with generalized temporally-partitioned\nrewards. To formalize how feedback about a decision is partitioned across\nseveral time steps, we introduce $\\beta$-spread property. We derive a lower\nbound on the performance of any uniformly efficient algorithm for the\nconsidered problem. Moreover, we provide an algorithm called TP-UCB-FR-G and\nprove an upper bound on its performance measure. In some scenarios, our upper\nbound improves upon the state of the art. We provide experimental results\nvalidating the proposed algorithm and our theoretical results.\n","authors":["Ronald C. van den Broek","Rik Litjens","Tobias Sagis","Luc Siecker","Nina Verbeeke","Pratik Gajane"],"pdf_url":"https://arxiv.org/pdf/2303.00620v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13259v2","updated":"2023-03-01T16:18:34Z","published":"2023-02-26T08:12:28Z","title":"Dodging the Double Descent in Deep Neural Networks","summary":"  Finding the optimal size of deep learning models is very actual and of broad\nimpact, especially in energy-saving schemes. Very recently, an unexpected\nphenomenon, the ``double descent'', has caught the attention of the deep\nlearning community. As the model's size grows, the performance gets first\nworse, and then goes back to improving. It raises serious questions about the\noptimal model's size to maintain high generalization: the model needs to be\nsufficiently over-parametrized, but adding too many parameters wastes training\nresources. Is it possible to find, in an efficient way, the best trade-off? Our\nwork shows that the double descent phenomenon is potentially avoidable with\nproper conditioning of the learning problem, but a final answer is yet to be\nfound. We empirically observe that there is hope to dodge the double descent in\ncomplex scenarios with proper regularization, as a simple $\\ell_2$\nregularization is already positively contributing to such a perspective.\n","authors":["Victor Quétu","Enzo Tartaglione"],"pdf_url":"https://arxiv.org/pdf/2302.13259v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11300v2","updated":"2023-03-01T16:13:33Z","published":"2023-01-26T18:38:56Z","title":"ZiCo: Zero-shot NAS via Inverse Coefficient of Variation on Gradients","summary":"  Neural Architecture Search (NAS) is widely used to automatically obtain the\nneural network with the best performance among a large number of candidate\narchitectures. To reduce the search time, zero-shot NAS aims at designing\ntraining-free proxies that can predict the test performance of a given\narchitecture. However, as shown recently, none of the zero-shot proxies\nproposed to date can actually work consistently better than a naive proxy,\nnamely, the number of network parameters (#Params). To improve this state of\naffairs, as the main theoretical contribution, we first reveal how some\nspecific gradient properties across different samples impact the convergence\nrate and generalization capacity of neural networks. Based on this theoretical\nanalysis, we propose a new zero-shot proxy, ZiCo, the first proxy that works\nconsistently better than #Params. We demonstrate that ZiCo works better than\nState-Of-The-Art (SOTA) proxies on several popular NAS-Benchmarks (NASBench101,\nNATSBench-SSS/TSS, TransNASBench-101) for multiple applications (e.g., image\nclassification/reconstruction and pixel-level prediction). Finally, we\ndemonstrate that the optimal architectures found via ZiCo are as competitive as\nthe ones found by one-shot and multi-shot NAS methods, but with much less\nsearch time. For example, ZiCo-based NAS can find optimal architectures with\n78.1%, 79.4%, and 80.4% test accuracy under inference budgets of 450M, 600M,\nand 1000M FLOPs, respectively, on ImageNet within 0.4 GPU days. Our code is\navailable at https://github.com/SLDGroup/ZiCo.\n","authors":["Guihong Li","Yuedong Yang","Kartikeya Bhardwaj","Radu Marculescu"],"pdf_url":"https://arxiv.org/pdf/2301.11300v2.pdf","comment":"ICLR 2023 Spotlight"},{"id":"http://arxiv.org/abs/2303.00613v1","updated":"2023-03-01T16:11:05Z","published":"2023-03-01T16:11:05Z","title":"Diffusing Graph Attention","summary":"  The dominant paradigm for machine learning on graphs uses Message Passing\nGraph Neural Networks (MP-GNNs), in which node representations are updated by\naggregating information in their local neighborhood. Recently, there have been\nincreasingly more attempts to adapt the Transformer architecture to graphs in\nan effort to solve some known limitations of MP-GNN. A challenging aspect of\ndesigning Graph Transformers is integrating the arbitrary graph structure into\nthe architecture. We propose Graph Diffuser (GD) to address this challenge. GD\nlearns to extract structural and positional relationships between distant nodes\nin the graph, which it then uses to direct the Transformer's attention and node\nrepresentation. We demonstrate that existing GNNs and Graph Transformers\nstruggle to capture long-range interactions and how Graph Diffuser does so\nwhile admitting intuitive visualizations. Experiments on eight benchmarks show\nGraph Diffuser to be a highly competitive model, outperforming the\nstate-of-the-art in a diverse set of domains.\n","authors":["Daniel Glickman","Eran Yahav"],"pdf_url":"https://arxiv.org/pdf/2303.00613v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00609v1","updated":"2023-03-01T16:03:25Z","published":"2023-03-01T16:03:25Z","title":"Unsupervised Pathology Detection: A Deep Dive Into the State of the Art","summary":"  Deep unsupervised approaches are gathering increased attention for\napplications such as pathology detection and segmentation in medical images\nsince they promise to alleviate the need for large labeled datasets and are\nmore generalizable than their supervised counterparts in detecting any kind of\nrare pathology. As the Unsupervised Anomaly Detection (UAD) literature\ncontinuously grows and new paradigms emerge, it is vital to continuously\nevaluate and benchmark new methods in a common framework, in order to reassess\nthe state-of-the-art (SOTA) and identify promising research directions. To this\nend, we evaluate a diverse selection of cutting-edge UAD methods on multiple\nmedical datasets, comparing them against the established SOTA in UAD for brain\nMRI. Our experiments demonstrate that newly developed feature-modeling methods\nfrom the industrial and medical literature achieve increased performance\ncompared to previous work and set the new SOTA in a variety of modalities and\ndatasets. Additionally, we show that such methods are capable of benefiting\nfrom recently developed self-supervised pre-training algorithms, further\nincreasing their performance. Finally, we perform a series of experiments in\norder to gain further insights into some unique characteristics of selected\nmodels and datasets. Our code can be found under\nhttps://github.com/iolag/UPD_study/.\n","authors":["Ioannis Lagogiannis","Felix Meissen","Georgios Kaissis","Daniel Rueckert"],"pdf_url":"https://arxiv.org/pdf/2303.00609v1.pdf","comment":"12 pages, 4 figures, under review for IEEE Transactions on Medical\n  Imaging"},{"id":"http://arxiv.org/abs/2303.00599v1","updated":"2023-03-01T15:46:12Z","published":"2023-03-01T15:46:12Z","title":"LS-IQ: Implicit Reward Regularization for Inverse Reinforcement Learning","summary":"  Recent methods for imitation learning directly learn a $Q$-function using an\nimplicit reward formulation rather than an explicit reward function. However,\nthese methods generally require implicit reward regularization to improve\nstability and often mistreat absorbing states. Previous works show that a\nsquared norm regularization on the implicit reward function is effective, but\ndo not provide a theoretical analysis of the resulting properties of the\nalgorithms. In this work, we show that using this regularizer under a mixture\ndistribution of the policy and the expert provides a particularly illuminating\nperspective: the original objective can be understood as squared Bellman error\nminimization, and the corresponding optimization problem minimizes a bounded\n$\\chi^2$-Divergence between the expert and the mixture distribution. This\nperspective allows us to address instabilities and properly treat absorbing\nstates. We show that our method, Least Squares Inverse Q-Learning (LS-IQ),\noutperforms state-of-the-art algorithms, particularly in environments with\nabsorbing states. Finally, we propose to use an inverse dynamics model to learn\nfrom observations only. Using this approach, we retain performance in settings\nwhere no expert actions are available.\n","authors":["Firas Al-Hafez","Davide Tateo","Oleg Arenz","Guoping Zhao","Jan Peters"],"pdf_url":"https://arxiv.org/pdf/2303.00599v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.12240v3","updated":"2023-03-01T15:38:54Z","published":"2022-01-28T16:51:54Z","title":"Continuous Deep Equilibrium Models: Training Neural ODEs faster by\n  integrating them to Infinity","summary":"  Implicit models separate the definition of a layer from the description of\nits solution process. While implicit layers allow features such as depth to\nadapt to new scenarios and inputs automatically, this adaptivity makes its\ncomputational expense challenging to predict. In this manuscript, we\n\\textit{increase the ``implicitness\" of the DEQ by redefining the method in\nterms of an infinite time neural ODE}, which paradoxically decreases the\ntraining cost over a standard neural ODE by $\\mathit{2} - \\mathit{4 \\times}$.\nAdditionally, we address the question: \\textit{is there a way to simultaneously\nachieve the robustness of implicit layers while allowing the reduced\ncomputational expense of an explicit layer?} To solve this, we develop Skip and\nSkip Reg. DEQ, an implicit-explicit (IMEX) layer that simultaneously trains an\nexplicit prediction followed by an implicit correction. We show that training\nthis explicit predictor is free and even decreases the training time by\n$\\mathit{1.11} - \\mathit{3.19 \\times}$. Together, this manuscript shows how\nbridging the dichotomy of implicit and explicit deep learning can combine the\nadvantages of both techniques.\n","authors":["Avik Pal","Alan Edelman","Christopher Rackauckas"],"pdf_url":"https://arxiv.org/pdf/2201.12240v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00589v1","updated":"2023-03-01T15:30:29Z","published":"2023-03-01T15:30:29Z","title":"Composite Optimization Algorithms for Sigmoid Networks","summary":"  In this paper, we use composite optimization algorithms to solve sigmoid\nnetworks. We equivalently transfer the sigmoid networks to a convex composite\noptimization and propose the composite optimization algorithms based on the\nlinearized proximal algorithms and the alternating direction method of\nmultipliers. Under the assumptions of the weak sharp minima and the regularity\ncondition, the algorithm is guaranteed to converge to a globally optimal\nsolution of the objective function even in the case of non-convex and\nnon-smooth problems. Furthermore, the convergence results can be directly\nrelated to the amount of training data and provide a general guide for setting\nthe size of sigmoid networks. Numerical experiments on Franke's function\nfitting and handwritten digit recognition show that the proposed algorithms\nperform satisfactorily and robustly.\n","authors":["Huixiong Chen","Qi Ye"],"pdf_url":"https://arxiv.org/pdf/2303.00589v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00586v1","updated":"2023-03-01T15:28:26Z","published":"2023-03-01T15:28:26Z","title":"FAIR-Ensemble: When Fairness Naturally Emerges From Deep Ensembling","summary":"  Ensembling independent deep neural networks (DNNs) is a simple and effective\nway to improve top-line metrics and to outperform larger single models. In this\nwork, we go beyond top-line metrics and instead explore the impact of\nensembling on subgroup performances. Surprisingly, even with a simple\nhomogenous ensemble -- all the individual models share the same training set,\narchitecture, and design choices -- we find compelling and powerful gains in\nworst-k and minority group performance, i.e. fairness naturally emerges from\nensembling. We show that the gains in performance from ensembling for the\nminority group continue for far longer than for the majority group as more\nmodels are added. Our work establishes that simple DNN ensembles can be a\npowerful tool for alleviating disparate impact from DNN classifiers, thus\ncurbing algorithmic harm. We also explore why this is the case. We find that\neven in homogeneous ensembles, varying the sources of stochasticity through\nparameter initialization, mini-batch sampling, and the data-augmentation\nrealizations, results in different fairness outcomes.\n","authors":["Wei-Yin Ko","Daniel D'souza","Karina Nguyen","Randall Balestriero","Sara Hooker"],"pdf_url":"https://arxiv.org/pdf/2303.00586v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00120v2","updated":"2023-03-01T15:23:49Z","published":"2022-09-30T22:34:54Z","title":"NTFields: Neural Time Fields for Physics-Informed Robot Motion Planning","summary":"  Neural Motion Planners (NMPs) have emerged as a promising tool for solving\nrobot navigation tasks in complex environments. However, these methods often\nrequire expert data for learning, which limits their application to scenarios\nwhere data generation is time-consuming. Recent developments have also led to\nphysics-informed deep neural models capable of representing complex dynamical\nPartial Differential Equations (PDEs). Inspired by these developments, we\npropose Neural Time Fields (NTFields) for robot motion planning in cluttered\nscenarios. Our framework represents a wave propagation model generating\ncontinuous arrival time to find path solutions informed by a nonlinear\nfirst-order PDE called Eikonal Equation. We evaluate our method in various\ncluttered 3D environments, including the Gibson dataset, and demonstrate its\nability to solve motion planning problems for 4-DOF and 6-DOF robot\nmanipulators where the traditional grid-based Eikonal planners often face the\ncurse of dimensionality. Furthermore, the results show that our method exhibits\nhigh success rates and significantly lower computational times than the\nstate-of-the-art methods, including NMPs that require training data from\nclassical planners.\n","authors":["Ruiqi Ni","Ahmed H. Qureshi"],"pdf_url":"https://arxiv.org/pdf/2210.00120v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.00858v2","updated":"2023-03-01T15:22:56Z","published":"2023-01-02T19:51:55Z","title":"Robust Average-Reward Markov Decision Processes","summary":"  In robust Markov decision processes (MDPs), the uncertainty in the transition\nkernel is addressed by finding a policy that optimizes the worst-case\nperformance over an uncertainty set of MDPs. While much of the literature has\nfocused on discounted MDPs, robust average-reward MDPs remain largely\nunexplored. In this paper, we focus on robust average-reward MDPs, where the\ngoal is to find a policy that optimizes the worst-case average reward over an\nuncertainty set. We first take an approach that approximates average-reward\nMDPs using discounted MDPs. We prove that the robust discounted value function\nconverges to the robust average-reward as the discount factor $\\gamma$ goes to\n$1$, and moreover, when $\\gamma$ is large, any optimal policy of the robust\ndiscounted MDP is also an optimal policy of the robust average-reward. We\nfurther design a robust dynamic programming approach, and theoretically\ncharacterize its convergence to the optimum. Then, we investigate robust\naverage-reward MDPs directly without using discounted MDPs as an intermediate\nstep. We derive the robust Bellman equation for robust average-reward MDPs,\nprove that the optimal policy can be derived from its solution, and further\ndesign a robust relative value iteration algorithm that provably finds its\nsolution, or equivalently, the optimal robust policy.\n","authors":["Yue Wang","Alvaro Velasquez","George Atia","Ashley Prater-Bennette","Shaofeng Zou"],"pdf_url":"https://arxiv.org/pdf/2301.00858v2.pdf","comment":"AAAI 2023"},{"id":"http://arxiv.org/abs/2303.00579v1","updated":"2023-03-01T15:22:40Z","published":"2023-03-01T15:22:40Z","title":"Are More Layers Beneficial to Graph Transformers?","summary":"  Despite that going deep has proven successful in many neural architectures,\nthe existing graph transformers are relatively shallow. In this work, we\nexplore whether more layers are beneficial to graph transformers, and find that\ncurrent graph transformers suffer from the bottleneck of improving performance\nby increasing depth. Our further analysis reveals the reason is that deep graph\ntransformers are limited by the vanishing capacity of global attention,\nrestricting the graph transformer from focusing on the critical substructure\nand obtaining expressive features. To this end, we propose a novel graph\ntransformer model named DeepGraph that explicitly employs substructure tokens\nin the encoded representation, and applies local attention on related nodes to\nobtain substructure based attention encoding. Our model enhances the ability of\nthe global attention to focus on substructures and promotes the expressiveness\nof the representations, addressing the limitation of self-attention as the\ngraph transformer deepens. Experiments show that our method unblocks the depth\nlimitation of graph transformers and results in state-of-the-art performance\nacross various graph benchmarks with deeper models.\n","authors":["Haiteng Zhao","Shuming Ma","Dongdong Zhang","Zhi-Hong Deng","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2303.00579v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.00573v1","updated":"2023-03-01T15:16:27Z","published":"2023-03-01T15:16:27Z","title":"Dimension-reduced KRnet maps for high-dimensional inverse problems","summary":"  We present a dimension-reduced KRnet map approach (DR-KRnet) for\nhigh-dimensional inverse problems, which is based on an explicit construction\nof a map that pushes forward the prior measure to the posterior measure in the\nlatent space. Our approach consists of two main components: data-driven VAE\nprior and density approximation of the posterior of the latent variable. In\nreality, it may not be trivial to initialize a prior distribution that is\nconsistent with available prior data; in other words, the complex prior\ninformation is often beyond simple hand-crafted priors. We employ variational\nautoencoder (VAE) to approximate the underlying distribution of the prior\ndataset, which is achieved through a latent variable and a decoder. Using the\ndecoder provided by the VAE prior, we reformulate the problem in a\nlow-dimensional latent space. In particular, we seek an invertible transport\nmap given by KRnet to approximate the posterior distribution of the latent\nvariable. Moreover, an efficient physics-constrained surrogate model without\nany labeled data is constructed to reduce the computational cost of solving\nboth forward and adjoint problems involved in likelihood computation. Numerical\nexperiments are implemented to demonstrate the validity, accuracy, and\nefficiency of DR-KRnet.\n","authors":["Yani Feng","Kejun Tang","Xiaoliang Wan","Qifeng Liao"],"pdf_url":"https://arxiv.org/pdf/2303.00573v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.06605v2","updated":"2023-03-01T15:16:15Z","published":"2022-11-12T08:03:57Z","title":"Comprehensive Analysis of Over-smoothing in Graph Neural Networks from\n  Markov Chains Perspective","summary":"  The over-smoothing problem is an obstacle of developing deep graph neural\nnetwork (GNN). Although many approaches to improve the over-smoothing problem\nhave been proposed, there is still a lack of comprehensive understanding and\nconclusion of this problem. In this work, we analyze the over-smoothing problem\nfrom the Markov chain perspective. We focus on message passing of GNN and first\nestablish a connection between GNNs and Markov chains on the graph. GNNs are\ndivided into two classes of operator-consistent and operator-inconsistent based\non whether the corresponding Markov chains are time-homogeneous. Next we\nattribute the over-smoothing problem to the convergence of an arbitrary initial\ndistribution to a stationary distribution. Based on this, we prove that\nalthough the previously proposed methods can alleviate over-smoothing, but\nthese methods cannot avoid the over-smoothing problem. In addition, we give the\nconclusion of the over-smoothing problem in two types of GNNs in the Markovian\nsense. On the one hand, operator-consistent GNN cannot avoid over-smoothing at\nan exponential rate. On the other hand, operator-inconsistent GNN is not always\nover-smoothing. Further, we investigate the existence of the limiting\ndistribution of the time-inhomogeneous Markov chain, from which we derive a\nsufficient condition for operator-inconsistent GNN to avoid over-smoothing.\nFinally, we design experiments to verify our findings. Results show that our\nproposed sufficient condition can effectively improve over-smoothing problem in\noperator-inconsistent GNN and enhance the performance of the model.\n","authors":["Weichen Zhao","Chenguang Wang","Congying Han","Tiande Guo"],"pdf_url":"https://arxiv.org/pdf/2211.06605v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00565v1","updated":"2023-03-01T15:12:42Z","published":"2023-03-01T15:12:42Z","title":"AdaSAM: Boosting Sharpness-Aware Minimization with Adaptive Learning\n  Rate and Momentum for Training Deep Neural Networks","summary":"  Sharpness aware minimization (SAM) optimizer has been extensively explored as\nit can generalize better for training deep neural networks via introducing\nextra perturbation steps to flatten the landscape of deep learning models.\nIntegrating SAM with adaptive learning rate and momentum acceleration, dubbed\nAdaSAM, has already been explored empirically to train large-scale deep neural\nnetworks without theoretical guarantee due to the triple difficulties in\nanalyzing the coupled perturbation step, adaptive learning rate and momentum\nstep. In this paper, we try to analyze the convergence rate of AdaSAM in the\nstochastic non-convex setting. We theoretically show that AdaSAM admits a\n$\\mathcal{O}(1/\\sqrt{bT})$ convergence rate, which achieves linear speedup\nproperty with respect to mini-batch size $b$. Specifically, to decouple the\nstochastic gradient steps with the adaptive learning rate and perturbed\ngradient, we introduce the delayed second-order momentum term to decompose them\nto make them independent while taking an expectation during the analysis. Then\nwe bound them by showing the adaptive learning rate has a limited range, which\nmakes our analysis feasible. To the best of our knowledge, we are the first to\nprovide the non-trivial convergence rate of SAM with an adaptive learning rate\nand momentum acceleration. At last, we conduct several experiments on several\nNLP tasks, which show that AdaSAM could achieve superior performance compared\nwith SGD, AMSGrad, and SAM optimizers.\n","authors":["Hao Sun","Li Shen","Qihuang Zhong","Liang Ding","Shixiang Chen","Jingwei Sun","Jing Li","Guangzhong Sun","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2303.00565v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2303.00564v1","updated":"2023-03-01T15:11:23Z","published":"2023-03-01T15:11:23Z","title":"Learning curves for deep structured Gaussian feature models","summary":"  In recent years, significant attention in deep learning theory has been\ndevoted to analyzing the generalization performance of models with multiple\nlayers of Gaussian random features. However, few works have considered the\neffect of feature anisotropy; most assume that features are generated using\nindependent and identically distributed Gaussian weights. Here, we derive\nlearning curves for models with many layers of structured Gaussian features. We\nshow that allowing correlations between the rows of the first layer of features\ncan aid generalization, while structure in later layers is generally\ndetrimental. Our results shed light on how weight structure affects\ngeneralization in a simple class of solvable models.\n","authors":["Jacob A. Zavatone-Veth","Cengiz Pehlevan"],"pdf_url":"https://arxiv.org/pdf/2303.00564v1.pdf","comment":"9+12 pages, 3 figures"},{"id":"http://arxiv.org/abs/2302.10763v2","updated":"2023-03-01T14:58:09Z","published":"2023-02-12T12:19:57Z","title":"Contrastive Learning and the Emergence of Attributes Associations","summary":"  In response to an object presentation, supervised learning schemes generally\nrespond with a parsimonious label. Upon a similar presentation we humans\nrespond again with a label, but are flooded, in addition, by a myriad of\nassociations. A significant portion of these consist of the presented object\nattributes. Contrastive learning is a semi-supervised learning scheme based on\nthe application of identity preserving transformations on the object input\nrepresentations. It is conjectured in this work that these same applied\ntransformations preserve, in addition to the identity of the presented object,\nalso the identity of its semantically meaningful attributes. The corollary of\nthis is that the output representations of such a contrastive learning scheme\ncontain valuable information not only for the classification of the presented\nobject, but also for the presence or absence decision of any attribute of\ninterest. Simulation results which demonstrate this idea and the feasibility of\nthis conjecture are presented.\n","authors":["Daniel N. Nissani"],"pdf_url":"https://arxiv.org/pdf/2302.10763v2.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2112.02089v3","updated":"2023-03-01T14:49:01Z","published":"2021-12-03T18:55:50Z","title":"Regularized Newton Method with Global $O(1/k^2)$ Convergence","summary":"  We present a Newton-type method that converges fast from any initialization\nand for arbitrary convex objectives with Lipschitz Hessians. We achieve this by\nmerging the ideas of cubic regularization with a certain adaptive\nLevenberg--Marquardt penalty. In particular, we show that the iterates given by\n$x^{k+1}=x^k - \\bigl(\\nabla^2 f(x^k) + \\sqrt{H\\|\\nabla f(x^k)\\|}\n\\mathbf{I}\\bigr)^{-1}\\nabla f(x^k)$, where $H>0$ is a constant, converge\nglobally with a $\\mathcal{O}(\\frac{1}{k^2})$ rate. Our method is the first\nvariant of Newton's method that has both cheap iterations and provably fast\nglobal convergence. Moreover, we prove that locally our method converges\nsuperlinearly when the objective is strongly convex. To boost the method's\nperformance, we present a line search procedure that does not need prior\nknowledge of $H$ and is provably efficient.\n","authors":["Konstantin Mishchenko"],"pdf_url":"https://arxiv.org/pdf/2112.02089v3.pdf","comment":"Accepted for publication at SIOPT. 22 pages, 2 figures"},{"id":"http://arxiv.org/abs/2211.15612v2","updated":"2023-03-01T14:48:03Z","published":"2022-11-28T18:11:26Z","title":"Learning from Good Trajectories in Offline Multi-Agent Reinforcement\n  Learning","summary":"  Offline multi-agent reinforcement learning (MARL) aims to learn effective\nmulti-agent policies from pre-collected datasets, which is an important step\ntoward the deployment of multi-agent systems in real-world applications.\nHowever, in practice, each individual behavior policy that generates\nmulti-agent joint trajectories usually has a different level of how well it\nperforms. e.g., an agent is a random policy while other agents are medium\npolicies. In the cooperative game with global reward, one agent learned by\nexisting offline MARL often inherits this random policy, jeopardizing the\nperformance of the entire team. In this paper, we investigate offline MARL with\nexplicit consideration on the diversity of agent-wise trajectories and propose\na novel framework called Shared Individual Trajectories (SIT) to address this\nproblem. Specifically, an attention-based reward decomposition network assigns\nthe credit to each agent through a differentiable key-value memory mechanism in\nan offline manner. These decomposed credits are then used to reconstruct the\njoint offline datasets into prioritized experience replay with individual\ntrajectories, thereafter agents can share their good trajectories and\nconservatively train their policies with a graph attention network (GAT) based\ncritic. We evaluate our method in both discrete control (i.e., StarCraft II and\nmulti-agent particle environment) and continuous control (i.e, multi-agent\nmujoco). The results indicate that our method achieves significantly better\nresults in complex and mixed offline multi-agent datasets, especially when the\ndifference of data quality between individual trajectories is large.\n","authors":["Qi Tian","Kun Kuang","Furui Liu","Baoxiang Wang"],"pdf_url":"https://arxiv.org/pdf/2211.15612v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.15987v2","updated":"2023-03-01T14:39:06Z","published":"2022-10-28T08:37:13Z","title":"NNSVS: A Neural Network-Based Singing Voice Synthesis Toolkit","summary":"  This paper describes the design of NNSVS, an open-source software for neural\nnetwork-based singing voice synthesis research. NNSVS is inspired by Sinsy, an\nopen-source pioneer in singing voice synthesis research, and provides many\nadditional features such as multi-stream models, autoregressive fundamental\nfrequency models, and neural vocoders. Furthermore, NNSVS provides extensive\ndocumentation and numerous scripts to build complete singing voice synthesis\nsystems. Experimental results demonstrate that our best system significantly\noutperforms our reproduction of Sinsy and other baseline systems. The toolkit\nis available at https://github.com/nnsvs/nnsvs.\n","authors":["Ryuichi Yamamoto","Reo Yoneyama","Tomoki Toda"],"pdf_url":"https://arxiv.org/pdf/2210.15987v2.pdf","comment":"Accepted to ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.03459v2","updated":"2023-03-01T14:36:30Z","published":"2023-02-07T13:29:06Z","title":"On the relationship between multivariate splines and infinitely-wide\n  neural networks","summary":"  We consider multivariate splines and show that they have a random feature\nexpansion as infinitely wide neural networks with one-hidden layer and a\nhomogeneous activation function which is the power of the rectified linear\nunit. We show that the associated function space is a Sobolev space on a\nEuclidean ball, with an explicit bound on the norms of derivatives. This link\nprovides a new random feature expansion for multivariate splines that allow\nefficient algorithms. This random feature expansion is numerically better\nbehaved than usual random Fourier features, both in theory and practice. In\nparticular, in dimension one, we compare the associated leverage scores to\ncompare the two random expansions and show a better scaling for the neural\nnetwork expansion.\n","authors":["Francis Bach"],"pdf_url":"https://arxiv.org/pdf/2302.03459v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13754v2","updated":"2023-03-01T14:29:48Z","published":"2023-02-27T13:32:47Z","title":"Combining Slow and Fast: Complementary Filtering for Dynamics Learning","summary":"  Modeling an unknown dynamical system is crucial in order to predict the\nfuture behavior of the system. A standard approach is training recurrent models\non measurement data. While these models typically provide exact short-term\npredictions, accumulating errors yield deteriorated long-term behavior. In\ncontrast, models with reliable long-term predictions can often be obtained,\neither by training a robust but less detailed model, or by leveraging\nphysics-based simulations. In both cases, inaccuracies in the models yield a\nlack of short-time details. Thus, different models with contrastive properties\non different time horizons are available. This observation immediately raises\nthe question: Can we obtain predictions that combine the best of both worlds?\nInspired by sensor fusion tasks, we interpret the problem in the frequency\ndomain and leverage classical methods from signal processing, in particular\ncomplementary filters. This filtering technique combines two signals by\napplying a high-pass filter to one signal, and low-pass filtering the other.\nEssentially, the high-pass filter extracts high-frequencies, whereas the\nlow-pass filter extracts low frequencies. Applying this concept to dynamics\nmodel learning enables the construction of models that yield accurate long- and\nshort-term predictions. Here, we propose two methods, one being purely\nlearning-based and the other one being a hybrid model that requires an\nadditional physics-based simulator.\n","authors":["Katharina Ensinger","Sebastian Ziesche","Barbara Rakitsch","Michael Tiemann","Sebastian Trimpe"],"pdf_url":"https://arxiv.org/pdf/2302.13754v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00529v1","updated":"2023-03-01T14:10:21Z","published":"2023-03-01T14:10:21Z","title":"Extending DNN-based Multiplicative Masking to Deep Subband Filtering for\n  Improved Dereverberation","summary":"  In this paper, we present a scheme for extending deep neural network-based\nmultiplicative maskers to deep subband filters for speech restoration in the\ntime-frequency domain. The resulting method can be generically applied to any\ndeep neural network providing masks in the time-frequency domain, while\nrequiring only few more trainable parameters and a computational overhead that\nis negligible for state-of-the-art neural networks. We demonstrate that the\nresulting deep subband filtering scheme outperforms multiplicative masking for\ndereverberation, while leaving the denoising performance virtually the same. We\nargue that this is because deep subband filtering in the time-frequency domain\nfits the subband approximation often assumed in the dereverberation literature,\nwhereas multiplicative masking corresponds to the narrowband approximation\ngenerally employed in denoising.\n","authors":["Jean-Marie Lemercier","Julian Tobergte","Timo Gerkmann"],"pdf_url":"https://arxiv.org/pdf/2303.00529v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.14709v2","updated":"2023-03-01T14:09:04Z","published":"2022-10-26T13:40:57Z","title":"Learning on Large-scale Text-attributed Graphs via Variational Inference","summary":"  This paper studies learning on text-attributed graphs (TAGs), where each node\nis associated with a text description. An ideal solution for such a problem\nwould be integrating both the text and graph structure information with large\nlanguage models and graph neural networks (GNNs). However, the problem becomes\nvery challenging when graphs are large due to the high computational complexity\nbrought by training large language models and GNNs together. In this paper, we\npropose an efficient and effective solution to learning on large\ntext-attributed graphs by fusing graph structure and language learning with a\nvariational Expectation-Maximization (EM) framework, called GLEM. Instead of\nsimultaneously training large language models and GNNs on big graphs, GLEM\nproposes to alternatively update the two modules in the E-step and M-step. Such\na procedure allows training the two modules separately while simultaneously\nallowing the two modules to interact and mutually enhance each other. Extensive\nexperiments on multiple data sets demonstrate the efficiency and effectiveness\nof the proposed approach.\n","authors":["Jianan Zhao","Meng Qu","Chaozhuo Li","Hao Yan","Qian Liu","Rui Li","Xing Xie","Jian Tang"],"pdf_url":"https://arxiv.org/pdf/2210.14709v2.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2211.05641v2","updated":"2023-03-01T13:50:09Z","published":"2022-11-10T15:13:23Z","title":"Regression as Classification: Influence of Task Formulation on Neural\n  Network Features","summary":"  Neural networks can be trained to solve regression problems by using\ngradient-based methods to minimize the square loss. However, practitioners\noften prefer to reformulate regression as a classification problem, observing\nthat training on the cross entropy loss results in better performance. By\nfocusing on two-layer ReLU networks, which can be fully characterized by\nmeasures over their feature space, we explore how the implicit bias induced by\ngradient-based optimization could partly explain the above phenomenon. We\nprovide theoretical evidence that the regression formulation yields a measure\nwhose support can differ greatly from that for classification, in the case of\none-dimensional data. Our proposed optimal supports correspond directly to the\nfeatures learned by the input layer of the network. The different nature of\nthese supports sheds light on possible optimization difficulties the square\nloss could encounter during training, and we present empirical results\nillustrating this phenomenon.\n","authors":["Lawrence Stewart","Francis Bach","Quentin Berthet","Jean-Philippe Vert"],"pdf_url":"https://arxiv.org/pdf/2211.05641v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13602v2","updated":"2023-03-01T13:48:55Z","published":"2023-02-27T09:10:08Z","title":"The Role of Pre-training Data in Transfer Learning","summary":"  The transfer learning paradigm of model pre-training and subsequent\nfine-tuning produces high-accuracy models. While most studies recommend scaling\nthe pre-training size to benefit most from transfer learning, a question\nremains: what data and method should be used for pre-training? We investigate\nthe impact of pre-training data distribution on the few-shot and full\nfine-tuning performance using 3 pre-training methods (supervised, contrastive\nlanguage-image and image-image), 7 pre-training datasets, and 9 downstream\ndatasets. Through extensive controlled experiments, we find that the choice of\nthe pre-training data source is essential for the few-shot transfer, but its\nrole decreases as more data is made available for fine-tuning. Additionally, we\nexplore the role of data curation and examine the trade-offs between label\nnoise and the size of the pre-training dataset. We find that using 2000X more\npre-training data from LAION can match the performance of supervised ImageNet\npre-training. Furthermore, we investigate the effect of pre-training methods,\ncomparing language-image contrastive vs. image-image contrastive, and find that\nthe latter leads to better downstream accuracy\n","authors":["Rahim Entezari","Mitchell Wortsman","Olga Saukh","M. Moein Shariatnia","Hanie Sedghi","Ludwig Schmidt"],"pdf_url":"https://arxiv.org/pdf/2302.13602v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.15269v2","updated":"2023-03-01T13:46:20Z","published":"2022-05-30T17:26:06Z","title":"Kernel Neural Optimal Transport","summary":"  We study the Neural Optimal Transport (NOT) algorithm which uses the general\noptimal transport formulation and learns stochastic transport plans. We show\nthat NOT with the weak quadratic cost might learn fake plans which are not\noptimal. To resolve this issue, we introduce kernel weak quadratic costs. We\nshow that they provide improved theoretical guarantees and practical\nperformance. We test NOT with kernel costs on the unpaired image-to-image\ntranslation task.\n","authors":["Alexander Korotin","Daniil Selikhanovych","Evgeny Burnaev"],"pdf_url":"https://arxiv.org/pdf/2205.15269v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.01130v3","updated":"2023-03-01T13:43:18Z","published":"2022-12-02T12:19:12Z","title":"Improving Pareto Front Learning via Multi-Sample Hypernetworks","summary":"  Pareto Front Learning (PFL) was recently introduced as an effective approach\nto obtain a mapping function from a given trade-off vector to a solution on the\nPareto front, which solves the multi-objective optimization (MOO) problem. Due\nto the inherent trade-off between conflicting objectives, PFL offers a flexible\napproach in many scenarios in which the decision makers can not specify the\npreference of one Pareto solution over another, and must switch between them\ndepending on the situation. However, existing PFL methods ignore the\nrelationship between the solutions during the optimization process, which\nhinders the quality of the obtained front. To overcome this issue, we propose a\nnovel PFL framework namely PHN-HVI, which employs a hypernetwork to generate\nmultiple solutions from a set of diverse trade-off preferences and enhance the\nquality of the Pareto front by maximizing the Hypervolume indicator defined by\nthese solutions. The experimental results on several MOO machine learning tasks\nshow that the proposed framework significantly outperforms the baselines in\nproducing the trade-off Pareto front.\n","authors":["Long P. Hoang","Dung D. Le","Tran Anh Tuan","Tran Ngoc Thang"],"pdf_url":"https://arxiv.org/pdf/2212.01130v3.pdf","comment":"Accepted to AAAI-23"},{"id":"http://arxiv.org/abs/2201.12220v3","updated":"2023-03-01T13:38:35Z","published":"2022-01-28T16:24:13Z","title":"Neural Optimal Transport","summary":"  We present a novel neural-networks-based algorithm to compute optimal\ntransport maps and plans for strong and weak transport costs. To justify the\nusage of neural networks, we prove that they are universal approximators of\ntransport plans between probability distributions. We evaluate the performance\nof our optimal transport algorithm on toy examples and on the unpaired\nimage-to-image translation.\n","authors":["Alexander Korotin","Daniil Selikhanovych","Evgeny Burnaev"],"pdf_url":"https://arxiv.org/pdf/2201.12220v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.15512v2","updated":"2023-03-01T13:37:28Z","published":"2022-05-31T02:50:17Z","title":"Nearly Minimax Optimal Offline Reinforcement Learning with Linear\n  Function Approximation: Single-Agent MDP and Markov Game","summary":"  Offline reinforcement learning (RL) aims at learning an optimal strategy\nusing a pre-collected dataset without further interactions with the\nenvironment. While various algorithms have been proposed for offline RL in the\nprevious literature, the minimax optimality has only been (nearly) established\nfor tabular Markov decision processes (MDPs). In this paper, we focus on\noffline RL with linear function approximation and propose a new pessimism-based\nalgorithm for offline linear MDP. At the core of our algorithm is the\nuncertainty decomposition via a reference function, which is new in the\nliterature of offline RL under linear function approximation. Theoretical\nanalysis demonstrates that our algorithm can match the performance lower bound\nup to logarithmic factors. We also extend our techniques to the two-player\nzero-sum Markov games (MGs), and establish a new performance lower bound for\nMGs, which tightens the existing result, and verifies the nearly minimax\noptimality of the proposed algorithm. To the best of our knowledge, these are\nthe first computationally efficient and nearly minimax optimal algorithms for\noffline single-agent MDPs and MGs with linear function approximation.\n","authors":["Wei Xiong","Han Zhong","Chengshuai Shi","Cong Shen","Liwei Wang","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2205.15512v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00501v1","updated":"2023-03-01T13:35:22Z","published":"2023-03-01T13:35:22Z","title":"OmniForce: On Human-Centered, Large Model Empowered and Cloud-Edge\n  Collaborative AutoML System","summary":"  Automated machine learning (AutoML) seeks to build ML models with minimal\nhuman effort. While considerable research has been conducted in the area of\nAutoML in general, aiming to take humans out of the loop when building\nartificial intelligence (AI) applications, scant literature has focused on how\nAutoML works well in open-environment scenarios such as the process of training\nand updating large models, industrial supply chains or the industrial\nmetaverse, where people often face open-loop problems during the search\nprocess: they must continuously collect data, update data and models, satisfy\nthe requirements of the development and deployment environment, support massive\ndevices, modify evaluation metrics, etc. Addressing the open-environment issue\nwith pure data-driven approaches requires considerable data, computing\nresources, and effort from dedicated data engineers, making current AutoML\nsystems and platforms inefficient and computationally intractable.\nHuman-computer interaction is a practical and feasible way to tackle the\nproblem of open-environment AI. In this paper, we introduce OmniForce, a\nhuman-centered AutoML (HAML) system that yields both human-assisted ML and\nML-assisted human techniques, to put an AutoML system into practice and build\nadaptive AI in open-environment scenarios. Specifically, we present OmniForce\nin terms of ML version management; pipeline-driven development and deployment\ncollaborations; a flexible search strategy framework; and widely provisioned\nand crowdsourced application algorithms, including large models. Furthermore,\nthe (large) models constructed by OmniForce can be automatically turned into\nremote services in a few minutes; this process is dubbed model as a service\n(MaaS). Experimental results obtained in multiple search spaces and real-world\nuse cases demonstrate the efficacy and efficiency of OmniForce.\n","authors":["Chao Xue","Wei Liu","Shuai Xie","Zhenfang Wang","Jiaxing Li","Xuyang Peng","Liang Ding","Shanshan Zhao","Qiong Cao","Yibo Yang","Fengxiang He","Bohua Cai","Rongcheng Bian","Yiyan Zhao","Heliang Zheng","Xiangyang Liu","Dongkai Liu","Daqing Liu","Li Shen","Chang Li","Shijin Zhang","Yukang Zhang","Guanpu Chen","Shixiang Chen","Yibing Zhan","Jing Zhang","Chaoyue Wang","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2303.00501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00500v1","updated":"2023-03-01T13:32:55Z","published":"2023-03-01T13:32:55Z","title":"Inherently Interpretable Multi-Label Classification Using Class-Specific\n  Counterfactuals","summary":"  Interpretability is essential for machine learning algorithms in high-stakes\napplication fields such as medical image analysis. However, high-performing\nblack-box neural networks do not provide explanations for their predictions,\nwhich can lead to mistrust and suboptimal human-ML collaboration. Post-hoc\nexplanation techniques, which are widely used in practice, have been shown to\nsuffer from severe conceptual problems. Furthermore, as we show in this paper,\ncurrent explanation techniques do not perform adequately in the multi-label\nscenario, in which multiple medical findings may co-occur in a single image. We\npropose Attri-Net, an inherently interpretable model for multi-label\nclassification. Attri-Net is a powerful classifier that provides transparent,\ntrustworthy, and human-understandable explanations. The model first generates\nclass-specific attribution maps based on counterfactuals to identify which\nimage regions correspond to certain medical findings. Then a simple logistic\nregression classifier is used to make predictions based solely on these\nattribution maps. We compare Attri-Net to five post-hoc explanation techniques\nand one inherently interpretable classifier on three chest X-ray datasets. We\nfind that Attri-Net produces high-quality multi-label explanations consistent\nwith clinical knowledge and has comparable classification performance to\nstate-of-the-art classification models.\n","authors":["Susu Sun","Stefano Woerner","Andreas Maier","Lisa M. Koch","Christian F. Baumgartner"],"pdf_url":"https://arxiv.org/pdf/2303.00500v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.13308v2","updated":"2023-03-01T13:27:24Z","published":"2022-09-27T11:23:49Z","title":"Safe Reinforcement Learning of Dynamic High-Dimensional Robotic Tasks:\n  Navigation, Manipulation, Interaction","summary":"  Safety is a crucial property of every robotic platform: any control policy\nshould always comply with actuator limits and avoid collisions with the\nenvironment and humans. In reinforcement learning, safety is even more\nfundamental for exploring an environment without causing any damage. While\nthere are many proposed solutions to the safe exploration problem, only a few\nof them can deal with the complexity of the real world. This paper introduces a\nnew formulation of safe exploration for reinforcement learning of various\nrobotic tasks. Our approach applies to a wide class of robotic platforms and\nenforces safety even under complex collision constraints learned from data by\nexploring the tangent space of the constraint manifold. Our proposed approach\nachieves state-of-the-art performance in simulated high-dimensional and dynamic\ntasks while avoiding collisions with the environment. We show safe real-world\ndeployment of our learned controller on a TIAGo++ robot, achieving remarkable\nperformance in manipulation and human-robot interaction tasks.\n","authors":["Puze Liu","Kuo Zhang","Davide Tateo","Snehal Jauhri","Zhiyuan Hu","Jan Peters","Georgia Chalvatzaki"],"pdf_url":"https://arxiv.org/pdf/2209.13308v2.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2303.00492v1","updated":"2023-03-01T13:27:06Z","published":"2023-03-01T13:27:06Z","title":"Lumos: Heterogeneity-aware Federated Graph Learning over Decentralized\n  Devices","summary":"  Graph neural networks (GNN) have been widely deployed in real-world networked\napplications and systems due to their capability to handle graph-structured\ndata. However, the growing awareness of data privacy severely challenges the\ntraditional centralized model training paradigm, where a server holds all the\ngraph information. Federated learning is an emerging collaborative computing\nparadigm that allows model training without data centralization. Existing\nfederated GNN studies mainly focus on systems where clients hold distinctive\ngraphs or sub-graphs. The practical node-level federated situation, where each\nclient is only aware of its direct neighbors, has yet to be studied. In this\npaper, we propose the first federated GNN framework called Lumos that supports\nsupervised and unsupervised learning with feature and degree protection on\nnode-level federated graphs. We first design a tree constructor to improve the\nrepresentation capability given the limited structural information. We further\npresent a Monte Carlo Markov Chain-based algorithm to mitigate the workload\nimbalance caused by degree heterogeneity with theoretically-guaranteed\nperformance. Based on the constructed tree for each client, a decentralized\ntree-based GNN trainer is proposed to support versatile training. Extensive\nexperiments demonstrate that Lumos outperforms the baseline with significantly\nhigher accuracy and greatly reduced communication cost and training time.\n","authors":["Qiying Pan","Yifei Zhu","Lingyang Chu"],"pdf_url":"https://arxiv.org/pdf/2303.00492v1.pdf","comment":"13 pages, 7 figures, to be published in the Proceedings of the 39th\n  IEEE International Conference on Data Engineering (ICDE 2023)"},{"id":"http://arxiv.org/abs/1910.02684v4","updated":"2023-03-01T13:12:23Z","published":"2019-10-07T09:21:49Z","title":"Effective Stabilized Self-Training on Few-Labeled Graph Data","summary":"  Graph neural networks (GNNs) are designed for semi-supervised node\nclassification on graphs where only a subset of nodes have class labels.\nHowever, under extreme cases when very few labels are available (e.g., 1\nlabeled node per class), GNNs suffer from severe performance degradation.\nSpecifically, we observe that existing GNNs suffer from unstable training\nprocess on few-labeled graphs, resulting to inferior performance on node\nclassification. Therefore, we propose an effective framework, Stabilized\nSelf-Training (SST), which is applicable to existing GNNs to handle the\nscarcity of labeled data, and consequently, boost classification accuracy. We\nconduct thorough empirical and theoretical analysis to support our findings and\nmotivate the algorithmic designs in SST. We apply SST to two popular GNN models\nGCN and DAGNN, to get SSTGCN and SSTDA methods respectively, and evaluate the\ntwo methods against 10 competitors over 5 benchmarking datasets. Extensive\nexperiments show that the proposed SST framework is highly effective,\nespecially when few labeled data are available. Our methods achieve superior\nperformance under almost all settings over all datasets. For instance, on a\nCora dataset with only 1 labeled node per class, the accuracy of SSTGCN is\n62.5%, 17.9% higher than GCN, and the accuracy of SSTDA is 66.4%, which\noutperforms DAGNN by 6.6%.\n","authors":["Ziang Zhou","Jieming Shi","Shengzhong Zhang","Zengfeng Huang","Qing Li"],"pdf_url":"https://arxiv.org/pdf/1910.02684v4.pdf","comment":"34 pages"},{"id":"http://arxiv.org/abs/2102.10343v4","updated":"2023-03-01T13:05:43Z","published":"2021-02-20T13:19:31Z","title":"Measuring the Transferability of $\\ell_\\infty$ Attacks by the $\\ell_2$\n  Norm","summary":"  Deep neural networks could be fooled by adversarial examples with trivial\ndifferences to original samples. To keep the difference imperceptible in human\neyes, researchers bound the adversarial perturbations by the $\\ell_\\infty$\nnorm, which is now commonly served as the standard to align the strength of\ndifferent attacks for a fair comparison. However, we propose that using the\n$\\ell_\\infty$ norm alone is not sufficient in measuring the attack strength,\nbecause even with a fixed $\\ell_\\infty$ distance, the $\\ell_2$ distance also\ngreatly affects the attack transferability between models. Through the\ndiscovery, we reach more in-depth understandings towards the attack mechanism,\ni.e., several existing methods attack black-box models better partly because\nthey craft perturbations with 70% to 130% larger $\\ell_2$ distances. Since\nlarger perturbations naturally lead to better transferability, we thereby\nadvocate that the strength of attacks should be simultaneously measured by both\nthe $\\ell_\\infty$ and $\\ell_2$ norm. Our proposal is firmly supported by\nextensive experiments on ImageNet dataset from 7 attacks, 4 white-box models,\nand 9 black-box models.\n","authors":["Sizhe Chen","Qinghua Tao","Zhixing Ye","Xiaolin Huang"],"pdf_url":"https://arxiv.org/pdf/2102.10343v4.pdf","comment":"ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.00466v1","updated":"2023-03-01T12:47:14Z","published":"2023-03-01T12:47:14Z","title":"ASP: Learn a Universal Neural Solver!","summary":"  Applying machine learning to combinatorial optimization problems has the\npotential to improve both efficiency and accuracy. However, existing\nlearning-based solvers often struggle with generalization when faced with\nchanges in problem distributions and scales. In this paper, we propose a new\napproach called ASP: Adaptive Staircase Policy Space Response Oracle to address\nthese generalization issues and learn a universal neural solver. ASP consists\nof two components: Distributional Exploration, which enhances the solver's\nability to handle unknown distributions using Policy Space Response Oracles,\nand Persistent Scale Adaption, which improves scalability through curriculum\nlearning. We have tested ASP on several challenging COPs, including the\ntraveling salesman problem, the vehicle routing problem, and the prize\ncollecting TSP, as well as the real-world instances from TSPLib and CVRPLib.\nOur results show that even with the same model size and weak training signal,\nASP can help neural solvers explore and adapt to unseen distributions and\nvarying scales, achieving superior performance. In particular, compared with\nthe same neural solvers under a standard training pipeline, ASP produces a\nremarkable decrease in terms of the optimality gap with 90.9% and 47.43% on\ngenerated instances and real-world instances for TSP, and a decrease of 19% and\n45.57% for CVRP.\n","authors":["Chenguang Wang","Zhouliang Yu","Stephen McAleer","Tianshu Yu","Yaodong Yang"],"pdf_url":"https://arxiv.org/pdf/2303.00466v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12000v2","updated":"2023-03-01T12:43:16Z","published":"2023-02-22T12:02:23Z","title":"Graph Construction using Principal Axis Trees for Simple Graph\n  Convolution","summary":"  Graph Neural Networks (GNNs) are increasingly becoming the favorite method\nfor graph learning. They exploit the semi-supervised nature of deep learning,\nand they bypass computational bottlenecks associated with traditional graph\nlearning methods. In addition to the feature matrix $X$, GNNs need an adjacency\nmatrix $A$ to perform feature propagation. In many cases the adjacency matrix\n$A$ is missing. We introduce a graph construction scheme that construct the\nadjacency matrix $A$ using unsupervised and supervised information.\nUnsupervised information characterize the neighborhood around points. We used\nPrincipal Axis trees (PA-trees) as a source of unsupervised information, where\nwe create edges between points falling onto the same leaf node. For supervised\ninformation, we used the concept of penalty and intrinsic graphs. A penalty\ngraph connects points with different class labels, whereas intrinsic graph\nconnects points with the same class label. We used the penalty and intrinsic\ngraphs to remove or add edges to the graph constructed via PA-tree. This graph\nconstruction scheme was tested on two well-known GNNs: 1) Graph Convolutional\nNetwork (GCN) and 2) Simple Graph Convolution (SGC). The experiments show that\nit is better to use SGC because it is faster and delivers better or the same\nresults as GCN. We also test the effect of oversmoothing on both GCN and SGC.\nWe found out that the level of smoothing has to be selected carefully for SGC\nto avoid oversmoothing.\n","authors":["Mashaan Alshammari","John Stavrakakis","Adel F. Ahmed","Masahiro Takatsuka"],"pdf_url":"https://arxiv.org/pdf/2302.12000v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00462v1","updated":"2023-03-01T12:41:12Z","published":"2023-03-01T12:41:12Z","title":"Hidden Gems: 4D Radar Scene Flow Learning Using Cross-Modal Supervision","summary":"  This work proposes a novel approach to 4D radar-based scene flow estimation\nvia cross-modal learning. Our approach is motivated by the co-located sensing\nredundancy in modern autonomous vehicles. Such redundancy implicitly provides\nvarious forms of supervision cues to the radar scene flow estimation.\nSpecifically, we introduce a multi-task model architecture for the identified\ncross-modal learning problem and propose loss functions to opportunistically\nengage scene flow estimation using multiple cross-modal constraints for\neffective model training. Extensive experiments show the state-of-the-art\nperformance of our method and demonstrate the effectiveness of cross-modal\nsupervised learning to infer more accurate 4D radar scene flow. We also show\nits usefulness to two subtasks - motion segmentation and ego-motion estimation.\nOur source code will be available on \\url{https://github.com/Toytiny/CMFlow.}\n","authors":["Fangqiang Ding","Andras Palffy","Dariu M. Gavrila","Chris Xiaoxuan Lu"],"pdf_url":"https://arxiv.org/pdf/2303.00462v1.pdf","comment":"10 pages, 7 figures. Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2210.14103v2","updated":"2023-03-01T12:37:46Z","published":"2022-10-25T15:41:21Z","title":"Bit Error and Block Error Rate Training for ML-Assisted Communication","summary":"  Even though machine learning (ML) techniques are being widely used in\ncommunications, the question of how to train communication systems has received\nsurprisingly little attention. In this paper, we show that the commonly used\nbinary cross-entropy (BCE) loss is a sensible choice in uncoded systems, e.g.,\nfor training ML-assisted data detectors, but may not be optimal in coded\nsystems. We propose new loss functions targeted at minimizing the block error\nrate and SNR deweighting, a novel method that trains communication systems for\noptimal performance over a range of signal-to-noise ratios. The utility of the\nproposed loss functions as well as of SNR deweighting is shown through\nsimulations in NVIDIA Sionna.\n","authors":["Reinhard Wiesmayr","Gian Marti","Chris Dick","Haochuan Song","Christoph Studer"],"pdf_url":"https://arxiv.org/pdf/2210.14103v2.pdf","comment":"A shorter version of this paper will be presented at the 2023 IEEE\n  International Conference on Acoustics, Speech, and Signal Processing (ICASSP)"},{"id":"http://arxiv.org/abs/2012.01805v2","updated":"2023-03-01T12:31:39Z","published":"2020-12-03T10:11:52Z","title":"Interpretability and Explainability: A Machine Learning Zoo Mini-tour","summary":"  In this review, we examine the problem of designing interpretable and\nexplainable machine learning models. Interpretability and explainability lie at\nthe core of many machine learning and statistical applications in medicine,\neconomics, law, and natural sciences. Although interpretability and\nexplainability have escaped a clear universal definition, many techniques\nmotivated by these properties have been developed over the recent 30 years with\nthe focus currently shifting towards deep learning methods. In this review, we\nemphasise the divide between interpretability and explainability and illustrate\nthese two different research directions with concrete examples of the\nstate-of-the-art. The review is intended for a general machine learning\naudience with interest in exploring the problems of interpretation and\nexplanation beyond logistic regression or random forest variable importance.\nThis work is not an exhaustive literature survey, but rather a primer focusing\nselectively on certain lines of research which the authors found interesting or\ninformative.\n","authors":["Ričards Marcinkevičs","Julia E. Vogt"],"pdf_url":"https://arxiv.org/pdf/2012.01805v2.pdf","comment":"A preprint version of the 2023 WIREs Data Mining and Knowledge\n  Discovery article"},{"id":"http://arxiv.org/abs/2110.14468v3","updated":"2023-03-01T12:25:12Z","published":"2021-10-27T14:35:00Z","title":"DESTA: A Framework for Safe Reinforcement Learning with Markov Games of\n  Intervention","summary":"  Reinforcement learning (RL) involves performing exploratory actions in an\nunknown system. This can place a learning agent in dangerous and potentially\ncatastrophic system states. Current approaches for tackling safe learning in RL\nsimultaneously trade-off safe exploration and task fulfillment. In this paper,\nwe introduce a new generation of RL solvers that learn to minimise safety\nviolations while maximising the task reward to the extent that can be tolerated\nby the safe policy. Our approach introduces a novel two-player framework for\nsafe RL called Distributive Exploration Safety Training Algorithm (DESTA). The\ncore of DESTA is a game between two adaptive agents: Safety Agent that is\ndelegated the task of minimising safety violations and Task Agent whose goal is\nto maximise the environment reward. Specifically, Safety Agent can selectively\ntake control of the system at any given point to prevent safety violations\nwhile Task Agent is free to execute its policy at any other states. This\nframework enables Safety Agent to learn to take actions at certain states that\nminimise future safety violations, both during training and testing time, while\nTask Agent performs actions that maximise the task performance everywhere else.\nTheoretically, we prove that DESTA converges to stable points enabling safety\nviolations of pretrained policies to be minimised. Empirically, we show DESTA's\nability to augment the safety of existing policies and secondly, construct safe\nRL policies when the Task Agent and Safety Agent are trained concurrently. We\ndemonstrate DESTA's superior performance against leading RL methods in Lunar\nLander and Frozen Lake from OpenAI gym.\n","authors":["David Mguni","Usman Islam","Yaqi Sun","Xiuling Zhang","Joel Jennings","Aivar Sootla","Changmin Yu","Ziyan Wang","Jun Wang","Yaodong Yang"],"pdf_url":"https://arxiv.org/pdf/2110.14468v3.pdf","comment":"arXiv admin note: text overlap with arXiv:2103.09159"},{"id":"http://arxiv.org/abs/2209.07529v2","updated":"2023-03-01T12:21:06Z","published":"2022-09-15T04:54:02Z","title":"On the Soft-Subnetwork for Few-shot Class Incremental Learning","summary":"  Inspired by Regularized Lottery Ticket Hypothesis (RLTH), which hypothesizes\nthat there exist smooth (non-binary) subnetworks within a dense network that\nachieve the competitive performance of the dense network, we propose a few-shot\nclass incremental learning (FSCIL) method referred to as \\emph{Soft-SubNetworks\n(SoftNet)}. Our objective is to learn a sequence of sessions incrementally,\nwhere each session only includes a few training instances per class while\npreserving the knowledge of the previously learned ones. SoftNet jointly learns\nthe model weights and adaptive non-binary soft masks at a base training session\nin which each mask consists of the major and minor subnetwork; the former aims\nto minimize catastrophic forgetting during training, and the latter aims to\navoid overfitting to a few samples in each new training session. We provide\ncomprehensive empirical validations demonstrating that our SoftNet effectively\ntackles the few-shot incremental learning problem by surpassing the performance\nof state-of-the-art baselines over benchmark datasets.\n","authors":["Haeyong Kang","Jaehong Yoon","Sultan Rizky Hikmawan Madjid","Sung Ju Hwang","Chang D. Yoo"],"pdf_url":"https://arxiv.org/pdf/2209.07529v2.pdf","comment":"The Eleventh International Conference on Learning Representations\n  (ICLR, 2023)"},{"id":"http://arxiv.org/abs/2303.00450v1","updated":"2023-03-01T12:21:00Z","published":"2023-03-01T12:21:00Z","title":"Federated Learning based Hierarchical 3D Indoor Localization","summary":"  The proliferation of connected devices in indoor environments opens the floor\nto a myriad of indoor applications with positioning services as key enablers.\nHowever, as privacy issues and resource constraints arise, it becomes more\nchallenging to design accurate positioning systems as required by most\napplications. To overcome the latter challenges, we present in this paper, a\nfederated learning (FL) framework for hierarchical 3D indoor localization using\na deep neural network. Indeed, we firstly shed light on the prominence of\nexploiting the hierarchy between floors and buildings in a multi-building and\nmulti-floor indoor environment. Then, we propose an FL framework to train the\ndesigned hierarchical model. The performance evaluation shows that by adopting\na hierarchical learning scheme, we can improve the localization accuracy by up\nto 24.06% compared to the non-hierarchical approach. We also obtain a building\nand floor prediction accuracy of 99.90% and 94.87% respectively. With the\nproposed FL framework, we can achieve a near-performance characteristic as of\nthe central training with an increase of only 7.69% in the localization error.\nMoreover, the conducted scalability study reveals that the FL system accuracy\nis improved when more devices join the training.\n","authors":["Yaya Etiabi","Wafa Njima","El Mehdi Amhoud"],"pdf_url":"https://arxiv.org/pdf/2303.00450v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2008.04267v2","updated":"2023-03-01T12:14:52Z","published":"2020-08-10T17:09:16Z","title":"Robust Validation: Confident Predictions Even When Distributions Shift","summary":"  While the traditional viewpoint in machine learning and statistics assumes\ntraining and testing samples come from the same population, practice belies\nthis fiction. One strategy -- coming from robust statistics and optimization --\nis thus to build a model robust to distributional perturbations. In this paper,\nwe take a different approach to describe procedures for robust predictive\ninference, where a model provides uncertainty estimates on its predictions\nrather than point predictions. We present a method that produces prediction\nsets (almost exactly) giving the right coverage level for any test distribution\nin an $f$-divergence ball around the training population. The method, based on\nconformal inference, achieves (nearly) valid coverage in finite samples, under\nonly the condition that the training data be exchangeable. An essential\ncomponent of our methodology is to estimate the amount of expected future data\nshift and build robustness to it; we develop estimators and prove their\nconsistency for protection and validity of uncertainty estimates under shifts.\nBy experimenting on several large-scale benchmark datasets, including Recht et\nal.'s CIFAR-v4 and ImageNet-V2 datasets, we provide complementary empirical\nresults that highlight the importance of robust predictive validity.\n","authors":["Maxime Cauchois","Suyash Gupta","Alnur Ali","John C. Duchi"],"pdf_url":"https://arxiv.org/pdf/2008.04267v2.pdf","comment":"58 pages, 10 figures"},{"id":"http://arxiv.org/abs/2303.00442v1","updated":"2023-03-01T12:00:37Z","published":"2023-03-01T12:00:37Z","title":"Re-weighting Based Group Fairness Regularization via Classwise Robust\n  Optimization","summary":"  Many existing group fairness-aware training methods aim to achieve the group\nfairness by either re-weighting underrepresented groups based on certain rules\nor using weakly approximated surrogates for the fairness metrics in the\nobjective as regularization terms. Although each of the learning schemes has\nits own strength in terms of applicability or performance, respectively, it is\ndifficult for any method in the either category to be considered as a gold\nstandard since their successful performances are typically limited to specific\ncases. To that end, we propose a principled method, dubbed as \\ours, which\nunifies the two learning schemes by incorporating a well-justified group\nfairness metric into the training objective using a class wise distributionally\nrobust optimization (DRO) framework. We then develop an iterative optimization\nalgorithm that minimizes the resulting objective by automatically producing the\ncorrect re-weights for each group. Our experiments show that FairDRO is\nscalable and easily adaptable to diverse applications, and consistently\nachieves the state-of-the-art performance on several benchmark datasets in\nterms of the accuracy-fairness trade-off, compared to recent strong baselines.\n","authors":["Sangwon Jung","Taeeon Park","Sanghyuk Chun","Taesup Moon"],"pdf_url":"https://arxiv.org/pdf/2303.00442v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00438v1","updated":"2023-03-01T11:54:22Z","published":"2023-03-01T11:54:22Z","title":"A Framework to Generate Neurosymbolic PDDL-compliant Planners","summary":"  The problem of integrating high-level task planning in the execution loop of\na real-world robot architecture remains challenging, as the planning times of\ntraditional symbolic planners explode combinatorially with the number of\nsymbols to plan upon. In this paper, we present Teriyaki, a framework for\ntraining Large Language Models (LLMs), and in particular the now well-known\nGPT-3 model, into neurosymbolic planners compatible with the Planning Domain\nDefinition Language (PDDL). Unlike symbolic approaches, LLMs require a training\nprocess. However, their response time scales with the combined length of the\ninput and the output. Hence, LLM-based planners can potentially provide\nsignificant performance gains on complex planning problems as the technology\nmatures and becomes more accessible. In this preliminary work, which to our\nknowledge is the first using LLMs for planning in robotics, we (i) outline a\nmethodology for training LLMs as PDDL solvers, (ii) generate PDDL-compliant\nplanners for two challenging PDDL domains, and (iii) test the planning times\nand the plan quality associated with the obtained planners, while also\ncomparing them to a state-of-the-art PDDL planner, namely Probe. Results\nconfirm the viability of the approach, with Teriyaki-based planners being able\nto solve 95.5% of problems in a test data set of 1000 samples, and even\ngenerating plans up to 13.5% shorter on average than the employed traditional\nplanner, depending on the domain.\n","authors":["Alessio Capitanelli","Fulvio Mastrogiovanni"],"pdf_url":"https://arxiv.org/pdf/2303.00438v1.pdf","comment":"Submitted to the IEEE/RSJ International Conference on Intelligent\n  Robots and Systems. 7 pages, 2 figures, 3 tables"},{"id":"http://arxiv.org/abs/2303.00431v1","updated":"2023-03-01T11:39:54Z","published":"2023-03-01T11:39:54Z","title":"OliVaR: Improving Olive Variety Recognition using Deep Neural Networks","summary":"  The easy and accurate identification of varieties is fundamental in\nagriculture, especially in the olive sector, where more than 1200 olive\nvarieties are currently known worldwide. Varietal misidentification leads to\nmany potential problems for all the actors in the sector: farmers and nursery\nworkers may establish the wrong variety, leading to its maladaptation in the\nfield; olive oil and table olive producers may label and sell a non-authentic\nproduct; consumers may be misled; and breeders may commit errors during\ntargeted crossings between different varieties. To date, the standard for\nvarietal identification and certification consists of two methods:\nmorphological classification and genetic analysis. The morphological\nclassification consists of the visual pairwise comparison of different organs\nof the olive tree, where the most important organ is considered to be the\nendocarp. In contrast, different methods for genetic classification exist\n(RAPDs, SSR, and SNP). Both classification methods present advantages and\ndisadvantages. Visual morphological classification requires highly specialized\npersonnel and is prone to human error. Genetic identification methods are more\naccurate but incur a high cost and are difficult to implement. This paper\nintroduces OliVaR, a novel approach to olive varietal identification. OliVaR\nuses a teacher-student deep learning architecture to learn the defining\ncharacteristics of the endocarp of each specific olive variety and perform\nclassification. We construct what is, to the best of our knowledge, the largest\nolive variety dataset to date, comprising image data for 131 varieties from the\nMediterranean basin. We thoroughly test OliVaR on this dataset and show that it\ncorrectly predicts olive varieties with over 86% accuracy.\n","authors":["Hristofor Miho","Giulio Pagnotta","Dorjan Hitaj","Fabio De Gaspari","Luigi V. Mancini","Georgios Koubouris","Gianluca Godino","Mehmet Hakan","Concepcion Muñoz Diez"],"pdf_url":"https://arxiv.org/pdf/2303.00431v1.pdf","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2303.00428v1","updated":"2023-03-01T11:32:59Z","published":"2023-03-01T11:32:59Z","title":"Supporting Future Electrical Utilities: Using Deep Learning Methods in\n  EMS and DMS Algorithms","summary":"  Electrical power systems are increasing in size, complexity, as well as\ndynamics due to the growing integration of renewable energy resources, which\nhave sporadic power generation. This necessitates the development of near\nreal-time power system algorithms, demanding lower computational complexity\nregarding the power system size. Considering the growing trend in the\ncollection of historical measurement data and recent advances in the rapidly\ndeveloping deep learning field, the main goal of this paper is to provide a\nreview of recent deep learning-based power system monitoring and optimization\nalgorithms. Electrical utilities can benefit from this review by\nre-implementing or enhancing the algorithms traditionally used in energy\nmanagement systems (EMS) and distribution management systems (DMS).\n","authors":["Ognjen Kundacina","Gorana Gojic","Mile Mitrovic","Dragisa Miskovic","Dejan Vukobratovic"],"pdf_url":"https://arxiv.org/pdf/2303.00428v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.01217v2","updated":"2023-03-01T11:23:58Z","published":"2022-12-31T04:26:25Z","title":"Unlearnable Clusters: Towards Label-agnostic Unlearnable Examples","summary":"  There is a growing interest in developing unlearnable examples (UEs) against\nvisual privacy leaks on the Internet. UEs are training samples added with\ninvisible but unlearnable noise, which have been found can prevent unauthorized\ntraining of machine learning models. UEs typically are generated via a bilevel\noptimization framework with a surrogate model to remove (minimize) errors from\nthe original samples, and then applied to protect the data against unknown\ntarget models. However, existing UE generation methods all rely on an ideal\nassumption called label-consistency, where the hackers and protectors are\nassumed to hold the same label for a given sample. In this work, we propose and\npromote a more practical label-agnostic setting, where the hackers may exploit\nthe protected data quite differently from the protectors. E.g., a m-class\nunlearnable dataset held by the protector may be exploited by the hacker as a\nn-class dataset. Existing UE generation methods are rendered ineffective in\nthis challenging setting. To tackle this challenge, we present a novel\ntechnique called Unlearnable Clusters (UCs) to generate label-agnostic\nunlearnable examples with cluster-wise perturbations. Furthermore, we propose\nto leverage VisionandLanguage Pre-trained Models (VLPMs) like CLIP as the\nsurrogate model to improve the transferability of the crafted UCs to diverse\ndomains. We empirically verify the effectiveness of our proposed approach under\na variety of settings with different datasets, target models, and even\ncommercial platforms Microsoft Azure and Baidu PaddlePaddle. Code is available\nat \\url{https://github.com/jiamingzhang94/Unlearnable-Clusters}.\n","authors":["Jiaming Zhang","Xingjun Ma","Qi Yi","Jitao Sang","Yugang Jiang","Yaowei Wang","Changsheng Xu"],"pdf_url":"https://arxiv.org/pdf/2301.01217v2.pdf","comment":"CVPR2023"},{"id":"http://arxiv.org/abs/2303.00413v1","updated":"2023-03-01T11:09:06Z","published":"2023-03-01T11:09:06Z","title":"Automated Task-Time Interventions to Improve Teamwork using Imitation\n  Learning","summary":"  Effective human-human and human-autonomy teamwork is critical but often\nchallenging to perfect. The challenge is particularly relevant in time-critical\ndomains, such as healthcare and disaster response, where the time pressures can\nmake coordination increasingly difficult to achieve and the consequences of\nimperfect coordination can be severe. To improve teamwork in these and other\ndomains, we present TIC: an automated intervention approach for improving\ncoordination between team members. Using BTIL, a multi-agent imitation learning\nalgorithm, our approach first learns a generative model of team behavior from\npast task execution data. Next, it utilizes the learned generative model and\nteam's task objective (shared reward) to algorithmically generate\nexecution-time interventions. We evaluate our approach in synthetic multi-agent\nteaming scenarios, where team members make decentralized decisions without full\nobservability of the environment. The experiments demonstrate that the\nautomated interventions can successfully improve team performance and shed\nlight on the design of autonomous agents for improving teamwork.\n","authors":["Sangwon Seo","Bing Han","Vaibhav Unhelkar"],"pdf_url":"https://arxiv.org/pdf/2303.00413v1.pdf","comment":"Extended version of an identically-titled paper accepted at AAMAS\n  2023"},{"id":"http://arxiv.org/abs/2303.00409v1","updated":"2023-03-01T11:00:20Z","published":"2023-03-01T11:00:20Z","title":"RePAD2: Real-Time, Lightweight, and Adaptive Anomaly Detection for\n  Open-Ended Time Series","summary":"  An open-ended time series refers to a series of data points indexed in time\norder without an end. Such a time series can be found everywhere due to the\nprevalence of Internet of Things. Providing lightweight and real-time anomaly\ndetection for open-ended time series is highly desirable to industry and\norganizations since it allows immediate response and avoids potential financial\nloss. In the last few years, several real-time time series anomaly detection\napproaches have been introduced. However, they might exhaust system resources\nwhen they are applied to open-ended time series for a long time. To address\nthis issue, in this paper we propose RePAD2, a lightweight real-time anomaly\ndetection approach for open-ended time series by improving its predecessor\nRePAD, which is one of the state-of-the-art anomaly detection approaches. We\nconducted a series of experiments to compare RePAD2 with RePAD and another\nsimilar detection approach based on real-world time series datasets, and\ndemonstrated that RePAD2 can address the mentioned resource exhaustion issue\nwhile offering comparable detection accuracy and slightly less time\nconsumption.\n","authors":["Ming-Chang Lee","Jia-Chun Lin"],"pdf_url":"https://arxiv.org/pdf/2303.00409v1.pdf","comment":"10 pages, 11 figures, and 10 tables, 8th International Conference on\n  Internet of Things, Big Data and Security (IoTBDS 2023)"},{"id":"http://arxiv.org/abs/2303.00403v1","updated":"2023-03-01T10:51:27Z","published":"2023-03-01T10:51:27Z","title":"Can representation learning for multimodal image registration be\n  improved by supervision of intermediate layers?","summary":"  Multimodal imaging and correlative analysis typically require image\nalignment. Contrastive learning can generate representations of multimodal\nimages, reducing the challenging task of multimodal image registration to a\nmonomodal one. Previously, additional supervision on intermediate layers in\ncontrastive learning has improved biomedical image classification. We evaluate\nif a similar approach improves representations learned for registration to\nboost registration performance. We explore three approaches to add contrastive\nsupervision to the latent features of the bottleneck layer in the U-Nets\nencoding the multimodal images and evaluate three different critic functions.\nOur results show that representations learned without additional supervision on\nlatent features perform best in the downstream task of registration on two\npublic biomedical datasets. We investigate the performance drop by exploiting\nrecent insights in contrastive learning in classification and self-supervised\nlearning. We visualize the spatial relations of the learned representations by\nmeans of multidimensional scaling, and show that additional supervision on the\nbottleneck layer can lead to partial dimensional collapse of the intermediate\nembedding space.\n","authors":["Elisabeth Wetzer","Joakim Lindblad","Nataša Sladoje"],"pdf_url":"https://arxiv.org/pdf/2303.00403v1.pdf","comment":"15 Pages + 9 Pages Appendix, 10 Figures"},{"id":"http://arxiv.org/abs/2303.00400v1","updated":"2023-03-01T10:39:58Z","published":"2023-03-01T10:39:58Z","title":"A Study on Accuracy, Miscalibration, and Popularity Bias in\n  Recommendations","summary":"  Recent research has suggested different metrics to measure the inconsistency\nof recommendation performance, including the accuracy difference between user\ngroups, miscalibration, and popularity lift. However, a study that relates\nmiscalibration and popularity lift to recommendation accuracy across different\nuser groups is still missing. Additionally, it is unclear if particular genres\ncontribute to the emergence of inconsistency in recommendation performance\nacross user groups. In this paper, we present an analysis of these three\naspects of five well-known recommendation algorithms for user groups that\ndiffer in their preference for popular content. Additionally, we study how\ndifferent genres affect the inconsistency of recommendation performance, and\nhow this is aligned with the popularity of the genres. Using data from LastFm,\nMovieLens, and MyAnimeList, we present two key findings. First, we find that\nusers with little interest in popular content receive the worst recommendation\naccuracy, and that this is aligned with miscalibration and popularity lift.\nSecond, our experiments show that particular genres contribute to a different\nextent to the inconsistency of recommendation performance, especially in terms\nof miscalibration in the case of the MyAnimeList dataset.\n","authors":["Dominik Kowald","Gregor Mayr","Markus Schedl","Elisabeth Lex"],"pdf_url":"https://arxiv.org/pdf/2303.00400v1.pdf","comment":"Accepted at BIAS@ECIR WS 2023"},{"id":"http://arxiv.org/abs/2303.00399v1","updated":"2023-03-01T10:38:10Z","published":"2023-03-01T10:38:10Z","title":"D4FT: A Deep Learning Approach to Kohn-Sham Density Functional Theory","summary":"  Kohn-Sham Density Functional Theory (KS-DFT) has been traditionally solved by\nthe Self-Consistent Field (SCF) method. Behind the SCF loop is the physics\nintuition of solving a system of non-interactive single-electron wave functions\nunder an effective potential. In this work, we propose a deep learning approach\nto KS-DFT. First, in contrast to the conventional SCF loop, we propose to\ndirectly minimize the total energy by reparameterizing the orthogonal\nconstraint as a feed-forward computation. We prove that such an approach has\nthe same expressivity as the SCF method, yet reduces the computational\ncomplexity from O(N^4) to O(N^3). Second, the numerical integration which\ninvolves a summation over the quadrature grids can be amortized to the\noptimization steps. At each step, stochastic gradient descent (SGD) is\nperformed with a sampled minibatch of the grids. Extensive experiments are\ncarried out to demonstrate the advantage of our approach in terms of efficiency\nand stability. In addition, we show that our approach enables us to explore\nmore complex neural-based wave functions.\n","authors":["Tianbo Li","Min Lin","Zheyuan Hu","Kunhao Zheng","Giovanni Vignale","Kenji Kawaguchi","A. H. Castro Neto","Kostya S. Novoselov","Shuicheng Yan"],"pdf_url":"https://arxiv.org/pdf/2303.00399v1.pdf","comment":"Accepted by The Eleventh International Conference on Learning\n  Representations (ICLR 2023, notable-top-25%)"},{"id":"http://arxiv.org/abs/2204.02678v2","updated":"2023-03-01T10:14:50Z","published":"2022-04-06T08:59:38Z","title":"Random Features Model with General Convex Regularization: A Fine Grained\n  Analysis with Precise Asymptotic Learning Curves","summary":"  We compute precise asymptotic expressions for the learning curves of least\nsquares random feature (RF) models with either a separable strongly convex\nregularization or the $\\ell_1$ regularization. We propose a novel multi-level\napplication of the convex Gaussian min max theorem (CGMT) to overcome the\ntraditional difficulty of finding computable expressions for random features\nmodels with correlated data. Our result takes the form of a computable\n4-dimensional scalar optimization. In contrast to previous results, our\napproach does not require solving an often intractable proximal operator, which\nscales with the number of model parameters. Furthermore, we extend the\nuniversality results for the training and generalization errors for RF models\nto $\\ell_1$ regularization. In particular, we demonstrate that under mild\nconditions, random feature models with elastic net or $\\ell_1$ regularization\nare asymptotically equivalent to a surrogate Gaussian model with the same first\nand second moments. We numerically demonstrate the predictive capacity of our\nresults, and show experimentally that the predicted test error is accurate even\nin the non-asymptotic regime.\n","authors":["David Bosch","Ashkan Panahi","Ayca Özcelikkale","Devdatt Dubhash"],"pdf_url":"https://arxiv.org/pdf/2204.02678v2.pdf","comment":"52 pages, 3 figures"},{"id":"http://arxiv.org/abs/2203.00162v3","updated":"2023-03-01T10:01:16Z","published":"2022-02-19T09:56:38Z","title":"Do Transformers know symbolic rules, and would we know if they did?","summary":"  To improve the explainability of leading Transformer networks used in NLP, it\nis important to tease apart genuine symbolic rules from merely associative\ninput-output patterns. However, we identify several inconsistencies in how\n``symbolicity'' has been construed in recent NLP literature. To mitigate this\nproblem, we propose two criteria to be the most relevant, one pertaining to a\nsystem's internal architecture and the other to the dissociation between\nabstract rules and specific input identities. From this perspective, we\ncritically examine prior work on the symbolic capacities of Transformers, and\ndeem the results to be fundamentally inconclusive for reasons inherent in\nexperiment design. We further maintain that there is no simple fix to this\nproblem, since it arises -- to an extent -- in all end-to-end settings.\nNonetheless, we emphasize the need for more robust evaluation of whether\nnon-symbolic explanations exist for success in seemingly symbolic tasks. To\nfacilitate this, we experiment on four sequence modelling tasks on the T5\nTransformer in two experiment settings: zero-shot generalization, and\ngeneralization across class-specific vocabularies flipped between the training\nand test set. We observe that T5's generalization is markedly stronger in\nsequence-to-sequence tasks than in comparable classification tasks. Based on\nthis, we propose a thus far overlooked analysis, where the Transformer itself\ndoes not need to be symbolic to be part of a symbolic architecture as the\nprocessor, operating on the input and output as external memory components.\n","authors":["Tommi Gröndahl","Yujia Guo","N. Asokan"],"pdf_url":"https://arxiv.org/pdf/2203.00162v3.pdf","comment":"15 pages, 1 figure"},{"id":"http://arxiv.org/abs/2303.00364v1","updated":"2023-03-01T09:45:17Z","published":"2023-03-01T09:45:17Z","title":"Lessons Learned Report: Super-Resolution for Detection Tasks in\n  Engineering Problem-Solving","summary":"  We describe the lessons learned from targeting agricultural detection\nproblem-solving, when subject to low resolution input maps, by means of Machine\nLearning-based super-resolution approaches. The underlying domain is the\nso-called agro-detection class of problems, and the specific objective is to\nlearn a complementary ensemble of sporadic input maps. While super-resolution\nalgorithms are branded with the capacity to enhance various attractive features\nin generic photography, we argue that they must meet certain requirements, and\nmore importantly, that their outcome does not necessarily guarantee an\nimprovement in engineering detection problem-solving (unlike so-called\naesthetics/artistic super-resolution in ImageNet-like datasets). By presenting\nspecific data-driven case studies, we outline a set of limitations and\nrecommendations for deploying super-resolution algorithms for agro-detection\nproblems. Another conclusion states that super-resolution algorithms can be\nused for learning missing spectral channels, and that their usage may result in\nsome desired side-effects such as channels' synchronization.\n","authors":["Martin Feder","Michal Horovitz","Assaf Chen","Raphael Linker","Ofer M. Shir"],"pdf_url":"https://arxiv.org/pdf/2303.00364v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00356v1","updated":"2023-03-01T09:34:52Z","published":"2023-03-01T09:34:52Z","title":"A Deep Reinforcement Learning Trader without Offline Training","summary":"  In this paper we pursue the question of a fully online trading algorithm\n(i.e. one that does not need offline training on previously gathered data). For\nthis task we use Double Deep $Q$-learning in the episodic setting with Fast\nLearning Networks approximating the expected reward $Q$. Additionally, we\ndefine the possible terminal states of an episode in such a way as to introduce\na mechanism to conserve some of the money in the trading pool when market\nconditions are seen as unfavourable. Some of these money are taken as profit\nand some are reused at a later time according to certain criteria. After\ndescribing the algorithm, we test it using the 1-minute-tick data for Cardano's\nprice on Binance. We see that the agent performs better than trading with\nrandomly chosen actions on each timestep. And it does so when tested on the\nwhole dataset as well as on different subsets, capturing different market\ntrends.\n","authors":["Boian Lazov"],"pdf_url":"https://arxiv.org/pdf/2303.00356v1.pdf","comment":"17 pages, 5 figures, full Mathematica code included"},{"id":"http://arxiv.org/abs/2302.10747v2","updated":"2023-03-01T09:29:29Z","published":"2023-02-17T07:11:02Z","title":"Clustered Data Sharing for Non-IID Federated Learning over Wireless\n  Networks","summary":"  Federated Learning (FL) is a novel distributed machine learning approach to\nleverage data from Internet of Things (IoT) devices while maintaining data\nprivacy. However, the current FL algorithms face the challenges of\nnon-independent and identically distributed (non-IID) data, which causes high\ncommunication costs and model accuracy declines. To address the statistical\nimbalances in FL, we propose a clustered data sharing framework which spares\nthe partial data from cluster heads to credible associates through\ndevice-to-device (D2D) communication. Moreover, aiming at diluting the data\nskew on nodes, we formulate the joint clustering and data sharing problem based\non the privacy-preserving constrained graph. To tackle the serious coupling of\ndecisions on the graph, we devise a distribution-based adaptive clustering\nalgorithm (DACA) basing on three deductive cluster-forming conditions, which\nensures the maximum yield of data sharing. The experiments show that the\nproposed framework facilitates FL on non-IID datasets with better convergence\nand model accuracy under a limited communication environment.\n","authors":["Gang Hu","Yinglei Teng","Nan Wang","F. Richard Yu"],"pdf_url":"https://arxiv.org/pdf/2302.10747v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00351v1","updated":"2023-03-01T09:27:08Z","published":"2023-03-01T09:27:08Z","title":"An end-to-end SE(3)-equivariant segmentation network","summary":"  Convolutional neural networks (CNNs) allow for parameter sharing and\ntranslational equivariance by using convolutional kernels in their linear\nlayers. By restricting these kernels to be SO(3)-steerable, CNNs can further\nimprove parameter sharing and equivariance. These equivariant convolutional\nlayers have several advantages over standard convolutional layers, including\nincreased robustness to unseen poses, smaller network size, and improved sample\nefficiency. Despite this, most segmentation networks used in medical image\nanalysis continue to rely on standard convolutional kernels. In this paper, we\npresent a new family of segmentation networks that use equivariant voxel\nconvolutions based on spherical harmonics, as well as equivariant pooling and\nnormalization operations. These SE(3)-equivariant volumetric segmentation\nnetworks, which are robust to data poses not seen during training, do not\nrequire rotation-based data augmentation during training. In addition, we\ndemonstrate improved segmentation performance in MRI brain tumor and healthy\nbrain structure segmentation tasks, with enhanced robustness to reduced amounts\nof training data and improved parameter efficiency. Code to reproduce our\nresults, and to implement the equivariant segmentation networks for other tasks\nis available at~\\url{http://github.com/SCAN-NRAD/e3nn_Unet}.\n","authors":["Ivan Diaz","Mario Geiger","Richard Iain McKinley"],"pdf_url":"https://arxiv.org/pdf/2303.00351v1.pdf","comment":"19 pages, 10 figures, submitted to the Journal of Machine Learning\n  for Biomedical Imaging"},{"id":"http://arxiv.org/abs/2209.00588v2","updated":"2023-03-01T09:21:14Z","published":"2022-09-01T17:03:07Z","title":"Transformers are Sample-Efficient World Models","summary":"  Deep reinforcement learning agents are notoriously sample inefficient, which\nconsiderably limits their application to real-world problems. Recently, many\nmodel-based methods have been designed to address this issue, with learning in\nthe imagination of a world model being one of the most prominent approaches.\nHowever, while virtually unlimited interaction with a simulated environment\nsounds appealing, the world model has to be accurate over extended periods of\ntime. Motivated by the success of Transformers in sequence modeling tasks, we\nintroduce IRIS, a data-efficient agent that learns in a world model composed of\na discrete autoencoder and an autoregressive Transformer. With the equivalent\nof only two hours of gameplay in the Atari 100k benchmark, IRIS achieves a mean\nhuman normalized score of 1.046, and outperforms humans on 10 out of 26 games,\nsetting a new state of the art for methods without lookahead search. To foster\nfuture research on Transformers and world models for sample-efficient\nreinforcement learning, we release our code and models at\nhttps://github.com/eloialonso/iris.\n","authors":["Vincent Micheli","Eloi Alonso","François Fleuret"],"pdf_url":"https://arxiv.org/pdf/2209.00588v2.pdf","comment":"ICLR 2023 (notable top 5%)"},{"id":"http://arxiv.org/abs/2303.00340v1","updated":"2023-03-01T09:07:27Z","published":"2023-03-01T09:07:27Z","title":"A Practical Upper Bound for the Worst-Case Attribution Deviations","summary":"  Model attribution is a critical component of deep neural networks (DNNs) for\nits interpretability to complex models. Recent studies bring up attention to\nthe security of attribution methods as they are vulnerable to attribution\nattacks that generate similar images with dramatically different attributions.\nExisting works have been investigating empirically improving the robustness of\nDNNs against those attacks; however, none of them explicitly quantifies the\nactual deviations of attributions. In this work, for the first time, a\nconstrained optimization problem is formulated to derive an upper bound that\nmeasures the largest dissimilarity of attributions after the samples are\nperturbed by any noises within a certain region while the classification\nresults remain the same. Based on the formulation, different practical\napproaches are introduced to bound the attributions above using Euclidean\ndistance and cosine similarity under both $\\ell_2$ and $\\ell_\\infty$-norm\nperturbations constraints. The bounds developed by our theoretical study are\nvalidated on various datasets and two different types of attacks (PGD attack\nand IFIA attribution attack). Over 10 million attacks in the experiments\nindicate that the proposed upper bounds effectively quantify the robustness of\nmodels based on the worst-case attribution dissimilarities.\n","authors":["Fan Wang","Adams Wai-Kin Kong"],"pdf_url":"https://arxiv.org/pdf/2303.00340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2006.05534v4","updated":"2023-03-01T09:03:21Z","published":"2020-06-09T22:34:27Z","title":"Novelty Detection via Robust Variational Autoencoding","summary":"  We propose a new method for novelty detection that can tolerate high\ncorruption of the training points, whereas previous works assumed either no or\nvery low corruption. Our method trains a robust variational autoencoder (VAE),\nwhich aims to generate a model for the uncorrupted training points. To gain\nrobustness to high corruption, we incorporate the following four changes to the\ncommon VAE: 1. Extracting crucial features of the latent code by a carefully\ndesigned dimension reduction component for distributions; 2. Modeling the\nlatent distribution as a mixture of Gaussian low-rank inliers and full-rank\noutliers, where the testing only uses the inlier model; 3. Applying the\nWasserstein-1 metric for regularization, instead of the Kullback-Leibler (KL)\ndivergence; and 4. Using a robust error for reconstruction. We establish both\nrobustness to outliers and suitability to low-rank modeling of the Wasserstein\nmetric as opposed to the KL divergence. We illustrate state-of-the-art results\non standard benchmarks.\n","authors":["Chieh-Hsin Lai","Dongmian Zou","Gilad Lerman"],"pdf_url":"https://arxiv.org/pdf/2006.05534v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12840v2","updated":"2023-03-01T08:43:13Z","published":"2023-02-24T18:17:38Z","title":"HULAT at SemEval-2023 Task 10: Data augmentation for pre-trained\n  transformers applied to the detection of sexism in social media","summary":"  This paper describes our participation in SemEval-2023 Task 10, whose goal is\nthe detection of sexism in social media. We explore some of the most popular\ntransformer models such as BERT, DistilBERT, RoBERTa, and XLNet. We also study\ndifferent data augmentation techniques to increase the training dataset. During\nthe development phase, our best results were obtained by using RoBERTa and data\naugmentation for tasks B and C. However, the use of synthetic data does not\nimprove the results for task C. We participated in the three subtasks. Our\napproach still has much room for improvement, especially in the two\nfine-grained classifications. All our code is available in the repository\nhttps://github.com/isegura/hulat_edos.\n","authors":["Isabel Segura-Bedmar"],"pdf_url":"https://arxiv.org/pdf/2302.12840v2.pdf","comment":"The experiments are not reproducible because I did not use a seed for\n  replicability"},{"id":"http://arxiv.org/abs/2303.00326v1","updated":"2023-03-01T08:43:05Z","published":"2023-03-01T08:43:05Z","title":"Empowering Networks With Scale and Rotation Equivariance Using A\n  Similarity Convolution","summary":"  The translational equivariant nature of Convolutional Neural Networks (CNNs)\nis a reason for its great success in computer vision. However, networks do not\nenjoy more general equivariance properties such as rotation or scaling,\nultimately limiting their generalization performance. To address this\nlimitation, we devise a method that endows CNNs with simultaneous equivariance\nwith respect to translation, rotation, and scaling. Our approach defines a\nconvolution-like operation and ensures equivariance based on our proposed\nscalable Fourier-Argand representation. The method maintains similar efficiency\nas a traditional network and hardly introduces any additional learnable\nparameters, since it does not face the computational issue that often occurs in\ngroup-convolution operators. We validate the efficacy of our approach in the\nimage classification task, demonstrating its robustness and the generalization\nability to both scaled and rotated inputs.\n","authors":["Zikai Sun","Thierry Blu"],"pdf_url":"https://arxiv.org/pdf/2303.00326v1.pdf","comment":"Accepted for ICLR 2023"},{"id":"http://arxiv.org/abs/2303.00320v1","updated":"2023-03-01T08:33:16Z","published":"2023-03-01T08:33:16Z","title":"TimeMAE: Self-Supervised Representations of Time Series with Decoupled\n  Masked Autoencoders","summary":"  Enhancing the expressive capacity of deep learning-based time series models\nwith self-supervised pre-training has become ever-increasingly prevalent in\ntime series classification. Even though numerous efforts have been devoted to\ndeveloping self-supervised models for time series data, we argue that the\ncurrent methods are not sufficient to learn optimal time series representations\ndue to solely unidirectional encoding over sparse point-wise input units. In\nthis work, we propose TimeMAE, a novel self-supervised paradigm for learning\ntransferrable time series representations based on transformer networks. The\ndistinct characteristics of the TimeMAE lie in processing each time series into\na sequence of non-overlapping sub-series via window-slicing partitioning,\nfollowed by random masking strategies over the semantic units of localized\nsub-series. Such a simple yet effective setting can help us achieve the goal of\nkilling three birds with one stone, i.e., (1) learning enriched contextual\nrepresentations of time series with a bidirectional encoding scheme; (2)\nincreasing the information density of basic semantic units; (3) efficiently\nencoding representations of time series using transformer networks.\nNevertheless, it is a non-trivial to perform reconstructing task over such a\nnovel formulated modeling paradigm. To solve the discrepancy issue incurred by\nnewly injected masked embeddings, we design a decoupled autoencoder\narchitecture, which learns the representations of visible (unmasked) positions\nand masked ones with two different encoder modules, respectively. Furthermore,\nwe construct two types of informative targets to accomplish the corresponding\npretext tasks. One is to create a tokenizer module that assigns a codeword to\neach masked region, allowing the masked codeword classification (MCC) task to\nbe completed effectively...\n","authors":["Mingyue Cheng","Qi Liu","Zhiding Liu","Hao Zhang","Rujiao Zhang","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2303.00320v1.pdf","comment":"Submitted to IEEE TRANSACTIONS ON KNOWLEDGE AND DATA\n  ENGINEERING(TKDE), under review"},{"id":"http://arxiv.org/abs/2209.15420v2","updated":"2023-03-01T08:32:28Z","published":"2022-09-23T09:21:35Z","title":"Ensemble-based gradient inference for particle methods in optimization\n  and sampling","summary":"  We propose an approach based on function evaluations and Bayesian inference\nto extract higher-order differential information of objective functions {from a\ngiven ensemble of particles}. Pointwise evaluation $\\{V(x^i)\\}_i$ of some\npotential $V$ in an ensemble $\\{x^i\\}_i$ contains implicit information about\nfirst or higher order derivatives, which can be made explicit with little\ncomputational effort (ensemble-based gradient inference -- EGI). We suggest to\nuse this information for the improvement of established ensemble-based\nnumerical methods for optimization and sampling such as Consensus-based\noptimization and Langevin-based samplers. Numerical studies indicate that the\naugmented algorithms are often superior to their gradient-free variants, in\nparticular the augmented methods help the ensembles to escape their initial\ndomain, to explore multimodal, non-Gaussian settings and to speed up the\ncollapse at the end of optimization dynamics.}\n  The code for the numerical examples in this manuscript can be found in the\npaper's Github repository\n(https://github.com/MercuryBench/ensemble-based-gradient.git).\n","authors":["Claudia Schillings","Claudia Totzeck","Philipp Wacker"],"pdf_url":"https://arxiv.org/pdf/2209.15420v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00315v1","updated":"2023-03-01T08:24:54Z","published":"2023-03-01T08:24:54Z","title":"Efficient Explorative Key-term Selection Strategies for Conversational\n  Contextual Bandits","summary":"  Conversational contextual bandits elicit user preferences by occasionally\nquerying for explicit feedback on key-terms to accelerate learning. However,\nthere are aspects of existing approaches which limit their performance. First,\ninformation gained from key-term-level conversations and arm-level\nrecommendations is not appropriately incorporated to speed up learning. Second,\nit is important to ask explorative key-terms to quickly elicit the user's\npotential interests in various domains to accelerate the convergence of user\npreference estimation, which has never been considered in existing works. To\ntackle these issues, we first propose ``ConLinUCB\", a general framework for\nconversational bandits with better information incorporation, combining\narm-level and key-term-level feedback to estimate user preference in one step\nat each time. Based on this framework, we further design two bandit algorithms\nwith explorative key-term selection strategies, ConLinUCB-BS and ConLinUCB-MCR.\nWe prove tighter regret upper bounds of our proposed algorithms. Particularly,\nConLinUCB-BS achieves a regret bound of $O(\\sqrt{dT\\log T})$, better than the\nprevious result $O(d\\sqrt{T}\\log T)$. Extensive experiments on synthetic and\nreal-world data show significant advantages of our algorithms in learning\naccuracy (up to 54\\% improvement) and computational efficiency (up to 72\\%\nimprovement), compared to the classic ConUCB algorithm, showing the potential\nbenefit to recommender systems.\n","authors":["Zhiyong Wang","Xutong Liu","Shuai Li","John C. S. Lui"],"pdf_url":"https://arxiv.org/pdf/2303.00315v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.12886v2","updated":"2023-03-01T08:18:42Z","published":"2022-11-23T11:44:35Z","title":"OReX: Object Reconstruction from Planar Cross-sections Using Neural\n  Fields","summary":"  Reconstructing 3D shapes from planar cross-sections is a challenge inspired\nby downstream applications like medical imaging and geographic informatics. The\ninput is an in/out indicator function fully defined on a sparse collection of\nplanes in space, and the output is an interpolation of the indicator function\nto the entire volume. Previous works addressing this sparse and ill-posed\nproblem either produce low quality results, or rely on additional priors such\nas target topology, appearance information, or input normal directions. In this\npaper, we present OReX, a method for 3D shape reconstruction from slices alone,\nfeaturing a Neural Field as the interpolation prior. A simple neural network is\ntrained on the input planes to receive a 3D coordinate and return an\ninside/outside estimate for the query point. This prior is powerful in inducing\nsmoothness and self-similarities. The main challenge for this approach is\nhigh-frequency details, as the neural prior is overly smoothing. To alleviate\nthis, we offer an iterative estimation architecture and a hierarchical input\nsampling scheme that encourage coarse-to-fine training, allowing focusing on\nhigh frequencies at later stages. In addition, we identify and analyze a common\nripple-like effect stemming from the mesh extraction step. We mitigate it by\nregularizing the spatial gradients of the indicator function around input\nin/out boundaries, cutting the problem at the root.\n  Through extensive qualitative and quantitative experimentation, we\ndemonstrate our method is robust, accurate, and scales well with the size of\nthe input. We report state-of-the-art results compared to previous approaches\nand recent potential solutions, and demonstrate the benefit of our individual\ncontributions through analysis and ablation studies.\n","authors":["Haim Sawdayee","Amir Vaxman","Amit H. Bermano"],"pdf_url":"https://arxiv.org/pdf/2211.12886v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00313v1","updated":"2023-03-01T08:16:38Z","published":"2023-03-01T08:16:38Z","title":"Deep Learning Methods for Small Molecule Drug Discovery: A Survey","summary":"  With the development of computer-assisted techniques, research communities\nincluding biochemistry and deep learning have been devoted into the drug\ndiscovery field for over a decade. Various applications of deep learning have\ndrawn great attention in drug discovery, such as molecule generation, molecular\nproperty prediction, retrosynthesis prediction, and reaction prediction. While\nmost existing surveys only focus on one of the applications, limiting the view\nof researchers in the community. In this paper, we present a comprehensive\nreview on the aforementioned four aspects, and discuss the relationships among\ndifferent applications. The latest literature and classical benchmarks are\npresented for better understanding the development of variety of approaches.\n  We commence by summarizing the molecule representation format in these works,\nfollowed by an introduction of recent proposed approaches for each of the four\ntasks. Furthermore, we review a variety of commonly used datasets and\nevaluation metrics and compare the performance of deep learning-based models.\nFinally, we conclude by identifying remaining challenges and discussing the\nfuture trend for deep learning methods in drug discovery.\n","authors":["Wenhao Hu","Yingying Liu","Xuanyu Chen","Wenhao Chai","Hangyue Chen","Hongwei Wang","Gaoang Wang"],"pdf_url":"https://arxiv.org/pdf/2303.00313v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.01303v2","updated":"2023-03-01T08:13:11Z","published":"2022-03-02T18:41:22Z","title":"An Analysis of Ensemble Sampling","summary":"  Ensemble sampling serves as a practical approximation to Thompson sampling\nwhen maintaining an exact posterior distribution over model parameters is\ncomputationally intractable. In this paper, we establish a regret bound that\nensures desirable behavior when ensemble sampling is applied to the linear\nbandit problem. This represents the first rigorous regret analysis of ensemble\nsampling and is made possible by leveraging information-theoretic concepts and\nnovel analytic techniques that may prove useful beyond the scope of this paper.\n","authors":["Chao Qin","Zheng Wen","Xiuyuan Lu","Benjamin Van Roy"],"pdf_url":"https://arxiv.org/pdf/2203.01303v2.pdf","comment":"[NeurIPS 2022 camera-ready\n  version](https://openreview.net/forum?id=c6ibx0yl-aG) with improved regret\n  bounds"},{"id":"http://arxiv.org/abs/2210.07494v2","updated":"2023-03-01T08:02:27Z","published":"2022-10-14T03:43:05Z","title":"A Comprehensive Study on Large-Scale Graph Training: Benchmarking and\n  Rethinking","summary":"  Large-scale graph training is a notoriously challenging problem for graph\nneural networks (GNNs). Due to the nature of evolving graph structures into the\ntraining process, vanilla GNNs usually fail to scale up, limited by the GPU\nmemory space. Up to now, though numerous scalable GNN architectures have been\nproposed, we still lack a comprehensive survey and fair benchmark of this\nreservoir to find the rationale for designing scalable GNNs. To this end, we\nfirst systematically formulate the representative methods of large-scale graph\ntraining into several branches and further establish a fair and consistent\nbenchmark for them by a greedy hyperparameter searching. In addition, regarding\nefficiency, we theoretically evaluate the time and space complexity of various\nbranches and empirically compare them w.r.t GPU memory usage, throughput, and\nconvergence. Furthermore, We analyze the pros and cons for various branches of\nscalable GNNs and then present a new ensembling training manner, named EnGCN,\nto address the existing issues. Our code is available at\nhttps://github.com/VITA-Group/Large_Scale_GCN_Benchmarking.\n","authors":["Keyu Duan","Zirui Liu","Peihao Wang","Wenqing Zheng","Kaixiong Zhou","Tianlong Chen","Xia Hu","Zhangyang Wang"],"pdf_url":"https://arxiv.org/pdf/2210.07494v2.pdf","comment":"Accepted by NeurIPS 2022 Dataset and Benchmark Track"},{"id":"http://arxiv.org/abs/2303.00302v1","updated":"2023-03-01T07:54:54Z","published":"2023-03-01T07:54:54Z","title":"Mitigating Backdoors in Federated Learning with FLD","summary":"  Federated learning allows clients to collaboratively train a global model\nwithout uploading raw data for privacy preservation. This feature, i.e., the\ninability to review participants' datasets, has recently been found responsible\nfor federated learning's vulnerability in the face of backdoor attacks.\nExisting defense methods fall short from two perspectives: 1) they consider\nonly very specific and limited attacker models and unable to cope with advanced\nbackdoor attacks, such as distributed backdoor attacks, which break down the\nglobal trigger into multiple distributed triggers. 2) they conduct detection\nbased on model granularity thus the performance gets impacted by the model\ndimension. To address these challenges, we propose Federated Layer Detection\n(FLD), a novel model filtering approach for effectively defending against\nbackdoor attacks. FLD examines the models based on layer granularity to capture\nthe complete model details and effectively detect potential backdoor models\nregardless of model dimension. We provide theoretical analysis and proof for\nthe convergence of FLD. Extensive experiments demonstrate that FLD effectively\nmitigates state-of-the-art backdoor attacks with negligible impact on the\naccuracy of the primary task.\n","authors":["Yihang Lin","Pengyuan Zhou","Zhiqian Wu","Yong Liao"],"pdf_url":"https://arxiv.org/pdf/2303.00302v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00295v1","updated":"2023-03-01T07:42:48Z","published":"2023-03-01T07:42:48Z","title":"Region Prediction for Efficient Robot Localization on Large Maps","summary":"  Recognizing already explored places (a.k.a. place recognition) is a\nfundamental task in Simultaneous Localization and Mapping (SLAM) to enable\nrobot relocalization and loop closure detection. In topological SLAM the\nrecognition takes place by comparing a signature (or feature vector) associated\nto the current node with the signatures of the nodes in the known map. However,\nas the number of nodes increases, matching the current node signature against\nall the existing ones becomes inefficient and thwarts real-time navigation. In\nthis paper we propose a novel approach to pre-select a subset of map nodes for\nplace recognition. The map nodes are clustered during exploration and each\ncluster is associated with a region. The region labels become the prediction\ntargets of a deep neural network and, during navigation, only the nodes\nassociated with the regions predicted with high probability are considered for\nmatching. While the proposed technique can be integrated in different SLAM\napproaches, in this work we describe an effective integration with RTAB-Map (a\npopular framework for real-time topological SLAM) which allowed us to design\nand run several experiments to demonstrate its effectiveness. All the code and\nmaterial from the experiments will be available online at\nhttps://github.com/MI-BioLab/region-learner.\n","authors":["Matteo Scucchia","Davide Maltoni"],"pdf_url":"https://arxiv.org/pdf/2303.00295v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.07817v2","updated":"2023-03-01T07:38:13Z","published":"2022-09-16T09:33:09Z","title":"SPGP: Structure Prototype Guided Graph Pooling","summary":"  While graph neural networks (GNNs) have been successful for node\nclassification tasks and link prediction tasks in graph, learning graph-level\nrepresentations still remains a challenge. For the graph-level representation,\nit is important to learn both representation of neighboring nodes, i.e.,\naggregation, and graph structural information. A number of graph pooling\nmethods have been developed for this goal. However, most of the existing\npooling methods utilize k-hop neighborhood without considering explicit\nstructural information in a graph. In this paper, we propose Structure\nPrototype Guided Pooling (SPGP) that utilizes prior graph structures to\novercome the limitation. SPGP formulates graph structures as learnable\nprototype vectors and computes the affinity between nodes and prototype\nvectors. This leads to a novel node scoring scheme that prioritizes informative\nnodes while encapsulating the useful structures of the graph. Our experimental\nresults show that SPGP outperforms state-of-the-art graph pooling methods on\ngraph classification benchmark datasets in both accuracy and scalability.\n","authors":["Sangseon Lee","Dohoon Lee","Yinhua Piao","Sun Kim"],"pdf_url":"https://arxiv.org/pdf/2209.07817v2.pdf","comment":"20 pages, 6 figures"},{"id":"http://arxiv.org/abs/2012.08950v5","updated":"2023-03-01T07:35:43Z","published":"2020-12-16T13:48:48Z","title":"Revocable Deep Reinforcement Learning with Affinity Regularization for\n  Outlier-Robust Graph Matching","summary":"  Graph matching (GM) has been a building block in various areas including\ncomputer vision and pattern recognition. Despite recent impressive progress,\nexisting deep GM methods often have obvious difficulty in handling outliers,\nwhich are ubiquitous in practice. We propose a deep reinforcement learning\nbased approach RGM, whose sequential node matching scheme naturally fits the\nstrategy for selective inlier matching against outliers. A revocable action\nframework is devised to improve the agent's flexibility against the complex\nconstrained GM. Moreover, we propose a quadratic approximation technique to\nregularize the affinity score, in the presence of outliers. As such, the agent\ncan finish inlier matching timely when the affinity score stops growing, for\nwhich otherwise an additional parameter i.e. the number of inliers is needed to\navoid matching outliers. In this paper, we focus on learning the back-end\nsolver under the most general form of GM: the Lawler's QAP, whose input is the\naffinity matrix. Especially, our approach can also boost existing GM methods\nthat use such input. Experiments on multiple real-world datasets demonstrate\nits performance regarding both accuracy and robustness.\n","authors":["Chang Liu","Zetian Jiang","Runzhong Wang","Junchi Yan","Lingxiao Huang","Pinyan Lu"],"pdf_url":"https://arxiv.org/pdf/2012.08950v5.pdf","comment":"Proceedings of The Eleventh International Conference on Learning\n  Representations (ICLR 2023)"},{"id":"http://arxiv.org/abs/2303.00286v1","updated":"2023-03-01T07:25:28Z","published":"2023-03-01T07:25:28Z","title":"Enhancing Knowledge Graph Embedding Models with Semantic-driven Loss\n  Functions","summary":"  Knowledge graph embedding models (KGEMs) are used for various tasks related\nto knowledge graphs (KGs), including link prediction. They are trained with\nloss functions that are computed considering a batch of scored triples and\ntheir corresponding labels. Traditional approaches consider the label of a\ntriple to be either true or false. However, recent works suggest that all\nnegative triples should not be valued equally. In line with this commonly\nadopted assumption, we posit that semantically valid negative triples might be\nhigh-quality negative triples. As such, loss functions should treat them\ndifferently from semantically invalid negative ones. To this aim, we propose\nsemantic-driven versions for the three mostly used loss functions for link\nprediction. In particular, we treat the scores of negative triples differently\nby injecting background knowledge about relation domains and ranges into the\nloss functions. In an extensive and controlled experimental setting, we show\nthat the proposed loss functions systematically provide satisfying results on\nthree public benchmark KGs underpinned with different schemas, which\ndemonstrates both the generality and superiority of our proposed approach. In\nfact, the proposed loss functions do not only lead to better MRR and Hits@10\nvalues, but also drive KGEMs towards better semantic awareness. This highlights\nthat semantic information globally improves KGEMs, and thus should be\nincorporated into loss functions whenever such information is available.\n","authors":["Nicolas Hubert","Pierre Monnin","Armelle Brun","Davy Monticolo"],"pdf_url":"https://arxiv.org/pdf/2303.00286v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00282v1","updated":"2023-03-01T07:12:33Z","published":"2023-03-01T07:12:33Z","title":"FedScore: A privacy-preserving framework for federated scoring system\n  development","summary":"  We propose FedScore, a privacy-preserving federated learning framework for\nscoring system generation across multiple sites to facilitate\ncross-institutional collaborations. The FedScore framework includes five\nmodules: federated variable ranking, federated variable transformation,\nfederated score derivation, federated model selection and federated model\nevaluation. To illustrate usage and assess FedScore's performance, we built a\nhypothetical global scoring system for mortality prediction within 30 days\nafter a visit to an emergency department using 10 simulated sites divided from\na tertiary hospital in Singapore. We employed a pre-existing score generator to\nconstruct 10 local scoring systems independently at each site and we also\ndeveloped a scoring system using centralized data for comparison. We compared\nthe acquired FedScore model's performance with that of other scoring models\nusing the receiver operating characteristic (ROC) analysis. The FedScore model\nachieved an average area under the curve (AUC) value of 0.763 across all sites,\nwith a standard deviation (SD) of 0.020. We also calculated the average AUC\nvalues and SDs for each local model, and the FedScore model showed promising\naccuracy and stability with a high average AUC value which was closest to the\none of the pooled model and SD which was lower than that of most local models.\nThis study demonstrates that FedScore is a privacy-preserving scoring system\ngenerator with potentially good generalizability.\n","authors":["Siqi Li","Yilin Ning","Marcus Eng Hock Ong","Bibhas Chakraborty","Chuan Hong","Feng Xie","Han Yuan","Mingxuan Liu","Daniel M. Buckland","Yong Chen","Nan Liu"],"pdf_url":"https://arxiv.org/pdf/2303.00282v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12172v3","updated":"2023-03-01T07:11:16Z","published":"2023-02-23T17:13:25Z","title":"Unified Chest X-ray and Radiology Report Generation Model with\n  Multi-view Chest X-rays","summary":"  Generated synthetic data in medical research can substitute privacy and\nsecurity-sensitive data with a large-scale curated dataset, reducing data\ncollection and annotation costs. As part of this effort, we propose UniXGen, a\nunified chest X-ray and report generation model, with the following\ncontributions. First, we design a unified model for bidirectional chest X-ray\nand report generation by adopting a vector quantization method to discretize\nchest X-rays into discrete visual tokens and formulating both tasks as sequence\ngeneration tasks. Second, we introduce several special tokens to generate chest\nX-rays with specific views that can be useful when the desired views are\nunavailable. Furthermore, UniXGen can flexibly take various inputs from single\nto multiple views to take advantage of the additional findings available in\nother X-ray views. We adopt an efficient transformer for computational and\nmemory efficiency to handle the long-range input sequence of multi-view chest\nX-rays with high resolution and long paragraph reports. In extensive\nexperiments, we show that our unified model has a synergistic effect on both\ngeneration tasks, as opposed to training only the task-specific models. We also\nfind that view-specific special tokens can distinguish between different views\nand properly generate specific views even if they do not exist in the dataset,\nand utilizing multi-view chest X-rays can faithfully capture the abnormal\nfindings in the additional X-rays. The source code is publicly available at:\nhttps://github.com/ttumyche/UniXGen.\n","authors":["Hyungyung Lee","Da Young Lee","Wonjae Kim","Jin-Hwa Kim","Tackeun Kim","Jihang Kim","Leonard Sunwoo","Edward Choi"],"pdf_url":"https://arxiv.org/pdf/2302.12172v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00280v1","updated":"2023-03-01T07:02:09Z","published":"2023-03-01T07:02:09Z","title":"Label Attention Network for sequential multi-label classification","summary":"  Multi-label classification is a natural problem statement for sequential\ndata. We might be interested in the items of the next order by a customer, or\ntypes of financial transactions that will occur tomorrow. Most modern\napproaches focus on transformer architecture for multi-label classification,\nintroducing self-attention for the elements of a sequence with each element\nbeing a multi-label vector and supplementary information. However, in this way\nwe loose local information related to interconnections between particular\nlabels. We propose instead to use a self-attention mechanism over labels\npreceding the predicted step. Conducted experiments suggest that such\narchitecture improves the model performance and provides meaningful attention\nbetween labels. The metric such as micro-AUC of our label attention network is\n$0.9847$ compared to $0.7390$ for vanilla transformers benchmark.\n","authors":["Elizaveta Kovtun","Galina Boeva","Artem Zabolotnyi","Evgeny Burnaev","Martin Spindler","Alexey Zaytsev"],"pdf_url":"https://arxiv.org/pdf/2303.00280v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.00518v5","updated":"2023-03-01T06:47:38Z","published":"2022-06-01T14:28:35Z","title":"Efficient Scheduling of Data Augmentation for Deep Reinforcement\n  Learning","summary":"  In deep reinforcement learning (RL), data augmentation is widely considered\nas a tool to induce a set of useful priors about semantic consistency and\nimprove sample efficiency and generalization performance. However, even when\nthe prior is useful for generalization, distilling it to RL agent often\ninterferes with RL training and degenerates sample efficiency. Meanwhile, the\nagent is forgetful of the prior due to the non-stationary nature of RL. These\nobservations suggest two extreme schedules of distillation: (i) over the entire\ntraining; or (ii) only at the end. Hence, we devise a stand-alone network\ndistillation method to inject the consistency prior at any time (even after\nRL), and a simple yet efficient framework to automatically schedule the\ndistillation. Specifically, the proposed framework first focuses on mastering\ntrain environments regardless of generalization by adaptively deciding which\n{\\it or no} augmentation to be used for the training. After this, we add the\ndistillation to extract the remaining benefits for generalization from all the\naugmentations, which requires no additional new samples. In our experiments, we\ndemonstrate the utility of the proposed framework, in particular, that\nconsiders postponing the augmentation to the end of RL training.\n","authors":["Byungchan Ko","Jungseul Ok"],"pdf_url":"https://arxiv.org/pdf/2206.00518v5.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2102.08581"},{"id":"http://arxiv.org/abs/2303.00262v1","updated":"2023-03-01T06:35:42Z","published":"2023-03-01T06:35:42Z","title":"Collage Diffusion","summary":"  Text-conditional diffusion models generate high-quality, diverse images.\nHowever, text is often an ambiguous specification for a desired target image,\ncreating the need for additional user-friendly controls for diffusion-based\nimage generation. We focus on having precise control over image output for\nscenes with several objects. Users control image generation by defining a\ncollage: a text prompt paired with an ordered sequence of layers, where each\nlayer is an RGBA image and a corresponding text prompt. We introduce Collage\nDiffusion, a collage-conditional diffusion algorithm that allows users to\ncontrol both the spatial arrangement and visual attributes of objects in the\nscene, and also enables users to edit individual components of generated\nimages. To ensure that different parts of the input text correspond to the\nvarious locations specified in the input collage layers, Collage Diffusion\nmodifies text-image cross-attention with the layers' alpha masks. To maintain\ncharacteristics of individual collage layers that are not specified in text,\nCollage Diffusion learns specialized text representations per layer. Collage\ninput also enables layer-based controls that provide fine-grained control over\nthe final output: users can control image harmonization on a layer-by-layer\nbasis, and they can edit individual objects in generated images while keeping\nother objects fixed. Collage-conditional image generation requires harmonizing\nthe input collage to make objects fit together--the key challenge involves\nminimizing changes in the positions and key visual attributes of objects in the\ninput collage while allowing other attributes of the collage to change in the\nharmonization process. By leveraging the rich information present in layer\ninput, Collage Diffusion generates globally harmonized images that maintain\ndesired object locations and visual characteristics better than prior\napproaches.\n","authors":["Vishnu Sarukkai","Linden Li","Arden Ma","Christopher Ré","Kayvon Fatahalian"],"pdf_url":"https://arxiv.org/pdf/2303.00262v1.pdf","comment":"26 pages, 20 figures"},{"id":"http://arxiv.org/abs/2303.00261v1","updated":"2023-03-01T06:35:29Z","published":"2023-03-01T06:35:29Z","title":"Speeding Up EfficientNet: Selecting Update Blocks of Convolutional\n  Neural Networks using Genetic Algorithm in Transfer Learning","summary":"  The performance of convolutional neural networks (CNN) depends heavily on\ntheir architectures. Transfer learning performance of a CNN relies quite\nstrongly on selection of its trainable layers. Selecting the most effective\nupdate layers for a certain target dataset often requires expert knowledge on\nCNN architecture which many practitioners do not posses. General users prefer\nto use an available architecture (e.g. GoogleNet, ResNet, EfficientNet etc.)\nthat is developed by domain experts. With the ever-growing number of layers, it\nis increasingly becoming quite difficult and cumbersome to handpick the update\nlayers. Therefore, in this paper we explore the application of genetic\nalgorithm to mitigate this problem. The convolutional layers of popular\npretrained networks are often grouped into modules that constitute their\nbuilding blocks. We devise a genetic algorithm to select blocks of layers for\nupdating the parameters. By experimenting with EfficientNetB0 pre-trained on\nImageNet and using Food-101, CIFAR-100 and MangoLeafBD as target datasets, we\nshow that our algorithm yields similar or better results than the baseline in\nterms of accuracy, and requires lower training and evaluation time due to\nlearning less number of parameters. We also devise a metric called block\nimportance to measure efficacy of each block as update block and analyze the\nimportance of the blocks selected by our algorithm.\n","authors":["Md. Mehedi Hasana","Muhammad Ibrahim","Md. Sawkat Ali"],"pdf_url":"https://arxiv.org/pdf/2303.00261v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2303.00250v1","updated":"2023-03-01T06:16:15Z","published":"2023-03-01T06:16:15Z","title":"Combating Exacerbated Heterogeneity for Robust Models in Federated\n  Learning","summary":"  Privacy and security concerns in real-world applications have led to the\ndevelopment of adversarially robust federated models. However, the\nstraightforward combination between adversarial training and federated learning\nin one framework can lead to the undesired robustness deterioration. We\ndiscover that the attribution behind this phenomenon is that the generated\nadversarial data could exacerbate the data heterogeneity among local clients,\nmaking the wrapped federated learning perform poorly. To deal with this\nproblem, we propose a novel framework called Slack Federated Adversarial\nTraining (SFAT), assigning the client-wise slack during aggregation to combat\nthe intensified heterogeneity. Theoretically, we analyze the convergence of the\nproposed method to properly relax the objective when combining federated\nlearning and adversarial training. Experimentally, we verify the rationality\nand effectiveness of SFAT on various benchmarked and real-world datasets with\ndifferent adversarial training and federated optimization methods. The code is\npublicly available at https://github.com/ZFancy/SFAT.\n","authors":["Jianing Zhu","Jiangchao Yao","Tongliang Liu","Quanming Yao","Jianliang Xu","Bo Han"],"pdf_url":"https://arxiv.org/pdf/2303.00250v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2210.01302v2","updated":"2023-03-01T06:00:47Z","published":"2022-10-04T01:40:31Z","title":"Nuisances via Negativa: Adjusting for Spurious Correlations via Data\n  Augmentation","summary":"  In prediction tasks, there exist features that are related to the label in\nthe same way across different settings for that task; these are semantic\nfeatures or semantics. Features with varying relationships to the label are\nnuisances. For example, in detecting cows from natural images, the shape of the\nhead is a semantic but because images of cows often have grass backgrounds but\nnot always, the background is a nuisance. Relationships between a nuisance and\nthe label are unstable across settings and, consequently, models that exploit\nnuisance-label relationships face performance degradation when these\nrelationships change. Direct knowledge of a nuisance helps build models that\nare robust to such changes, but requires extra annotations beyond labels and\ncovariates. In this paper, we develop an alternative way to produce robust\nmodels by data augmentation. These data augmentations corrupt semantic\ninformation to produce models that identify and adjust for where nuisances\ndrive predictions. We study semantic corruptions in powering different\nspurious-correlation avoiding methods on multiple out-of distribution (OOD)\ntasks like classifying waterbirds, natural language inference (NLI), and\ndetecting cardiomegaly in chest X-rays.\n","authors":["Aahlad Puli","Nitish Joshi","He He","Rajesh Ranganath"],"pdf_url":"https://arxiv.org/pdf/2210.01302v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.14499v2","updated":"2023-03-01T05:45:02Z","published":"2022-09-29T01:30:34Z","title":"NVRadarNet: Real-Time Radar Obstacle and Free Space Detection for\n  Autonomous Driving","summary":"  Detecting obstacles is crucial for safe and efficient autonomous driving. To\nthis end, we present NVRadarNet, a deep neural network (DNN) that detects\ndynamic obstacles and drivable free space using automotive RADAR sensors. The\nnetwork utilizes temporally accumulated data from multiple RADAR sensors to\ndetect dynamic obstacles and compute their orientation in a top-down bird's-eye\nview (BEV). The network also regresses drivable free space to detect\nunclassified obstacles. Our DNN is the first of its kind to utilize sparse\nRADAR signals in order to perform obstacle and free space detection in real\ntime from RADAR data only. The network has been successfully used for\nperception on our autonomous vehicles in real self-driving scenarios. The\nnetwork runs faster than real time on an embedded GPU and shows good\ngeneralization across geographic regions.\n","authors":["Alexander Popov","Patrik Gebhardt","Ke Chen","Ryan Oldja","Heeseok Lee","Shane Murray","Ruchi Bhargava","Nikolai Smolyanskiy"],"pdf_url":"https://arxiv.org/pdf/2209.14499v2.pdf","comment":"7 pages, 6 figures, ICRA 2023 conference, for associated video file,\n  see https://youtu.be/WlwJJMltoJY"},{"id":"http://arxiv.org/abs/2302.10238v2","updated":"2023-03-01T05:22:32Z","published":"2023-02-20T19:07:42Z","title":"Multiagent Inverse Reinforcement Learning via Theory of Mind Reasoning","summary":"  We approach the problem of understanding how people interact with each other\nin collaborative settings, especially when individuals know little about their\nteammates, via Multiagent Inverse Reinforcement Learning (MIRL), where the goal\nis to infer the reward functions guiding the behavior of each individual given\ntrajectories of a team's behavior during some task. Unlike current MIRL\napproaches, we do not assume that team members know each other's goals a\npriori; rather, that they collaborate by adapting to the goals of others\nperceived by observing their behavior, all while jointly performing a task. To\naddress this problem, we propose a novel approach to MIRL via Theory of Mind\n(MIRL-ToM). For each agent, we first use ToM reasoning to estimate a posterior\ndistribution over baseline reward profiles given their demonstrated behavior.\nWe then perform MIRL via decentralized equilibrium by employing single-agent\nMaximum Entropy IRL to infer a reward function for each agent, where we\nsimulate the behavior of other teammates according to the time-varying\ndistribution over profiles. We evaluate our approach in a simulated 2-player\nsearch-and-rescue operation where the goal of the agents, playing different\nroles, is to search for and evacuate victims in the environment. Our results\nshow that the choice of baseline profiles is paramount to the recovery of the\nground-truth rewards, and that MIRL-ToM is able to recover the rewards used by\nagents interacting both with known and unknown teammates.\n","authors":["Haochen Wu","Pedro Sequeira","David V. Pynadath"],"pdf_url":"https://arxiv.org/pdf/2302.10238v2.pdf","comment":"Accepted as a full paper at AAMAS2023"},{"id":"http://arxiv.org/abs/2204.10414v3","updated":"2023-03-01T05:07:42Z","published":"2022-04-21T21:32:28Z","title":"Dirichlet Proportions Model for Hierarchically Coherent Probabilistic\n  Forecasting","summary":"  Probabilistic, hierarchically coherent forecasting is a key problem in many\npractical forecasting applications -- the goal is to obtain coherent\nprobabilistic predictions for a large number of time series arranged in a\npre-specified tree hierarchy. In this paper, we present an end-to-end deep\nprobabilistic model for hierarchical forecasting that is motivated by a\nclassical top-down strategy. It jointly learns the distribution of the root\ntime series, and the (dirichlet) proportions according to which each parent\ntime-series is split among its children at any point in time. The resulting\nforecasts are naturally coherent, and provide probabilistic predictions over\nall time series in the hierarchy. We experiment on several public datasets and\ndemonstrate significant improvements of up to 26% on most datasets compared to\nstate-of-the-art baselines. Finally, we also provide theoretical justification\nfor the superiority of our top-down approach compared to the more traditional\nbottom-up modeling.\n","authors":["Abhimanyu Das","Weihao Kong","Biswajit Paria","Rajat Sen"],"pdf_url":"https://arxiv.org/pdf/2204.10414v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00233v1","updated":"2023-03-01T05:03:23Z","published":"2023-03-01T05:03:23Z","title":"Single-Cell Multimodal Prediction via Transformers","summary":"  The recent development of multimodal single-cell technology has made the\npossibility of acquiring multiple omics data from individual cells, thereby\nenabling a deeper understanding of cellular states and dynamics. Nevertheless,\nthe proliferation of multimodal single-cell data also introduces tremendous\nchallenges in modeling the complex interactions among different modalities. The\nrecently advanced methods focus on constructing static interaction graphs and\napplying graph neural networks (GNNs) to learn from multimodal data. However,\nsuch static graphs can be suboptimal as they do not take advantage of the\ndownstream task information; meanwhile GNNs also have some inherent limitations\nwhen deeply stacking GNN layers. To tackle these issues, in this work, we\ninvestigate how to leverage transformers for multimodal single-cell data in an\nend-to-end manner while exploiting downstream task information. In particular,\nwe propose a scMoFormer framework which can readily incorporate external domain\nknowledge and model the interactions within each modality and cross modalities.\nExtensive experiments demonstrate that scMoFormer achieves superior performance\non various benchmark datasets. Note that scMoFormer won a Kaggle silver medal\nwith the rank of $24\\ /\\ 1221$ (Top 2%) without ensemble in a NeurIPS 2022\ncompetition. Our implementation is publicly available at Github.\n","authors":["Wenzhuo Tang","Hongzhi Wen","Renming Liu","Jiayuan Ding","Wei Jin","Yuying Xie","Hui Liu","Jiliang Tang"],"pdf_url":"https://arxiv.org/pdf/2303.00233v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.05833v2","updated":"2023-03-01T04:40:21Z","published":"2022-07-12T20:52:26Z","title":"Earthformer: Exploring Space-Time Transformers for Earth System\n  Forecasting","summary":"  Conventionally, Earth system (e.g., weather and climate) forecasting relies\non numerical simulation with complex physical models and are hence both\nexpensive in computation and demanding on domain expertise. With the explosive\ngrowth of the spatiotemporal Earth observation data in the past decade,\ndata-driven models that apply Deep Learning (DL) are demonstrating impressive\npotential for various Earth system forecasting tasks. The Transformer as an\nemerging DL architecture, despite its broad success in other domains, has\nlimited adoption in this area. In this paper, we propose Earthformer, a\nspace-time Transformer for Earth system forecasting. Earthformer is based on a\ngeneric, flexible and efficient space-time attention block, named Cuboid\nAttention. The idea is to decompose the data into cuboids and apply\ncuboid-level self-attention in parallel. These cuboids are further connected\nwith a collection of global vectors. We conduct experiments on the MovingMNIST\ndataset and a newly proposed chaotic N-body MNIST dataset to verify the\neffectiveness of cuboid attention and figure out the best design of\nEarthformer. Experiments on two real-world benchmarks about precipitation\nnowcasting and El Nino/Southern Oscillation (ENSO) forecasting show Earthformer\nachieves state-of-the-art performance. Code is available:\nhttps://github.com/amazon-science/earth-forecasting-transformer .\n","authors":["Zhihan Gao","Xingjian Shi","Hao Wang","Yi Zhu","Yuyang Wang","Mu Li","Dit-Yan Yeung"],"pdf_url":"https://arxiv.org/pdf/2207.05833v2.pdf","comment":"Published at NeurIPS 2022. Camera-ready version"},{"id":"http://arxiv.org/abs/2303.00228v1","updated":"2023-03-01T04:37:14Z","published":"2023-03-01T04:37:14Z","title":"Two Views of Constrained Differential Privacy: Belief Revision and\n  Update","summary":"  In this paper, we provide two views of constrained differential private (DP)\nmechanisms. The first one is as belief revision. A constrained DP mechanism is\nobtained by standard probabilistic conditioning, and hence can be naturally\nimplemented by Monte Carlo algorithms. The other is as belief update. A\nconstrained DP is defined according to l2-distance minimization postprocessing\nor projection and hence can be naturally implemented by optimization\nalgorithms. The main advantage of these two perspectives is that we can make\nfull use of the machinery of belief revision and update to show basic\nproperties for constrained differential privacy especially some important new\ncomposition properties. Within the framework established in this paper,\nconstrained DP algorithms in the literature can be classified either as belief\nrevision or belief update. At the end of the paper, we demonstrate their\ndifferences especially in utility in a couple of scenarios.\n","authors":["Likang Liu","Keke Sun","Chunlai Zhou","Yuan Feng"],"pdf_url":"https://arxiv.org/pdf/2303.00228v1.pdf","comment":"23 pages, 3 figures"},{"id":"http://arxiv.org/abs/2212.10701v2","updated":"2023-03-01T04:22:54Z","published":"2022-12-21T00:33:59Z","title":"A Non-Asymptotic Analysis of Oversmoothing in Graph Neural Networks","summary":"  Oversmoothing is a central challenge of building more powerful Graph Neural\nNetworks (GNNs). While previous works have only demonstrated that oversmoothing\nis inevitable when the number of graph convolutions tends to infinity, in this\npaper, we precisely characterize the mechanism behind the phenomenon via a\nnon-asymptotic analysis. Specifically, we distinguish between two different\neffects when applying graph convolutions -- an undesirable mixing effect that\nhomogenizes node representations in different classes, and a desirable\ndenoising effect that homogenizes node representations in the same class. By\nquantifying these two effects on random graphs sampled from the Contextual\nStochastic Block Model (CSBM), we show that oversmoothing happens once the\nmixing effect starts to dominate the denoising effect, and the number of layers\nrequired for this transition is $O(\\log N/\\log (\\log N))$ for sufficiently\ndense graphs with $N$ nodes. We also extend our analysis to study the effects\nof Personalized PageRank (PPR), or equivalently, the effects of initial\nresidual connections on oversmoothing. Our results suggest that while PPR\nmitigates oversmoothing at deeper layers, PPR-based architectures still achieve\ntheir best performance at a shallow depth and are outperformed by the graph\nconvolution approach on certain graphs. Finally, we support our theoretical\nresults with numerical experiments, which further suggest that the\noversmoothing phenomenon observed in practice can be magnified by the\ndifficulty of optimizing deep GNN models.\n","authors":["Xinyi Wu","Zhengdao Chen","William Wang","Ali Jadbabaie"],"pdf_url":"https://arxiv.org/pdf/2212.10701v2.pdf","comment":"Accepted by the 11th International Conference on Learning\n  Representations (ICLR 2023)"},{"id":"http://arxiv.org/abs/2209.06983v2","updated":"2023-03-01T04:01:40Z","published":"2022-09-15T00:20:38Z","title":"Double Doubly Robust Thompson Sampling for Generalized Linear Contextual\n  Bandits","summary":"  We propose a novel contextual bandit algorithm for generalized linear rewards\nwith an $\\tilde{O}(\\sqrt{\\kappa^{-1} \\phi T})$ regret over $T$ rounds where\n$\\phi$ is the minimum eigenvalue of the covariance of contexts and $\\kappa$ is\na lower bound of the variance of rewards. In several practical cases where\n$\\phi=O(d)$, our result is the first regret bound for generalized linear model\n(GLM) bandits with the order $\\sqrt{d}$ without relying on the approach of Auer\n[2002]. We achieve this bound using a novel estimator called double\ndoubly-robust (DDR) estimator, a subclass of doubly-robust (DR) estimator but\nwith a tighter error bound. The approach of Auer [2002] achieves independence\nby discarding the observed rewards, whereas our algorithm achieves independence\nconsidering all contexts using our DDR estimator. We also provide an\n$O(\\kappa^{-1} \\phi \\log (NT) \\log T)$ regret bound for $N$ arms under a\nprobabilistic margin condition. Regret bounds under the margin condition are\ngiven by Bastani and Bayati [2020] and Bastani et al. [2021] under the setting\nthat contexts are common to all arms but coefficients are arm-specific. When\ncontexts are different for all arms but coefficients are common, ours is the\nfirst regret bound under the margin condition for linear models or GLMs. We\nconduct empirical studies using synthetic data and real examples, demonstrating\nthe effectiveness of our algorithm.\n","authors":["Wonyoung Kim","Kyungbok Lee","Myunghee Cho Paik"],"pdf_url":"https://arxiv.org/pdf/2209.06983v2.pdf","comment":"2023 AAAI Press Proceedings (Full paper including Appendix) Selected\n  as an oral presentation at the 2023 AAAI conference"},{"id":"http://arxiv.org/abs/2206.09311v3","updated":"2023-03-01T03:56:51Z","published":"2022-06-19T02:33:14Z","title":"Primal Estimated Subgradient Solver for SVM for Imbalanced\n  Classification","summary":"  We aim to demonstrate in experiments that our cost sensitive PEGASOS SVM\n(without synthetic majority oversampling/under sampling (SMOTE) ) achieves good\nperformance on imbalanced data sets with a Majority to Minority Ratio ranging\nfrom 8.6:1 to 130:1. Although many resort to SMOTE methods, we aim for a less\ncomputationally intensive method. We evaluate the performance by examining the\nlearning curves. These curves diagnose whether we overfit or underfit or we\nchoose over-representive or under representative training/test data. We will\nalso examine the effect of varying the hyperparameters via validation curves.\nWe compare our PEGASOS Cost-Sensitive SVM's results on three of the datasets\nDing analyzed using his LINEAR SVM DECIDL method. He obtained an ROC-AUC of .5\nin one dataset. We consider that dataset the most promising use of kernel\nSupport Vector Machine. Our work will extend the work of Ding by incorporating\nkernels into Support Vector Machine. We will use Python rather than MatLab as\npython has dictionaries for storing mixed data types during multi-parameter\ncross-validation.\n","authors":["John Sun"],"pdf_url":"https://arxiv.org/pdf/2206.09311v3.pdf","comment":"10 pages, 4 tables, 3 figures"},{"id":"http://arxiv.org/abs/2302.09369v2","updated":"2023-03-01T03:48:17Z","published":"2023-02-18T15:53:55Z","title":"Calibrating the Rigged Lottery: Making All Tickets Reliable","summary":"  Although sparse training has been successfully used in various\nresource-limited deep learning tasks to save memory, accelerate training, and\nreduce inference time, the reliability of the produced sparse models remains\nunexplored. Previous research has shown that deep neural networks tend to be\nover-confident, and we find that sparse training exacerbates this problem.\nTherefore, calibrating the sparse models is crucial for reliable prediction and\ndecision-making. In this paper, we propose a new sparse training method to\nproduce sparse models with improved confidence calibration. In contrast to\nprevious research that uses only one mask to control the sparse topology, our\nmethod utilizes two masks, including a deterministic mask and a random mask.\nThe former efficiently searches and activates important weights by exploiting\nthe magnitude of weights and gradients. While the latter brings better\nexploration and finds more appropriate weight values by random updates.\nTheoretically, we prove our method can be viewed as a hierarchical variational\napproximation of a probabilistic deep Gaussian process. Extensive experiments\non multiple datasets, model architectures, and sparsities show that our method\nreduces ECE values by up to 47.8\\% and simultaneously maintains or even\nimproves accuracy with only a slight increase in computation and storage\nburden.\n","authors":["Bowen Lei","Ruqi Zhang","Dongkuan Xu","Bani Mallick"],"pdf_url":"https://arxiv.org/pdf/2302.09369v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.13602v2","updated":"2023-03-01T03:29:24Z","published":"2022-06-27T19:30:53Z","title":"Molecular Geometry Pretraining with SE(3)-Invariant Denoising Distance\n  Matching","summary":"  Molecular representation pretraining is critical in various applications for\ndrug and material discovery due to the limited number of labeled molecules, and\nmost existing work focuses on pretraining on 2D molecular graphs. However, the\npower of pretraining on 3D geometric structures has been less explored. This is\nowing to the difficulty of finding a sufficient proxy task that can empower the\npretraining to effectively extract essential features from the geometric\nstructures. Motivated by the dynamic nature of 3D molecules, where the\ncontinuous motion of a molecule in the 3D Euclidean space forms a smooth\npotential energy surface, we propose GeoSSL, a 3D coordinate denoising\npretraining framework to model such an energy landscape. Further by leveraging\nan SE(3)-invariant score matching method, we propose GeoSSL-DDM in which the\ncoordinate denoising proxy task is effectively boiled down to denoising the\npairwise atomic distances in a molecule. Our comprehensive experiments confirm\nthe effectiveness and robustness of our proposed method.\n","authors":["Shengchao Liu","Hongyu Guo","Jian Tang"],"pdf_url":"https://arxiv.org/pdf/2206.13602v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.15408v3","updated":"2023-03-01T03:23:32Z","published":"2022-09-30T12:10:15Z","title":"Equivariant Energy-Guided SDE for Inverse Molecular Design","summary":"  Inverse molecular design is critical in material science and drug discovery,\nwhere the generated molecules should satisfy certain desirable properties. In\nthis paper, we propose equivariant energy-guided stochastic differential\nequations (EEGSDE), a flexible framework for controllable 3D molecule\ngeneration under the guidance of an energy function in diffusion models.\nFormally, we show that EEGSDE naturally exploits the geometric symmetry in 3D\nmolecular conformation, as long as the energy function is invariant to\northogonal transformations. Empirically, under the guidance of designed energy\nfunctions, EEGSDE significantly improves the baseline on QM9, in inverse\nmolecular design targeted to quantum properties and molecular structures.\nFurthermore, EEGSDE is able to generate molecules with multiple target\nproperties by combining the corresponding energy functions linearly.\n","authors":["Fan Bao","Min Zhao","Zhongkai Hao","Peiyao Li","Chongxuan Li","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2209.15408v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00198v1","updated":"2023-03-01T03:06:29Z","published":"2023-03-01T03:06:29Z","title":"Self-Supervised Convolutional Visual Prompts","summary":"  Machine learning models often fail on out-of-distribution (OOD) samples.\nVisual prompts emerge as a light-weight adaptation method in input space for\nlarge-scale vision models. Existing vision prompts optimize a high-dimensional\nadditive vector and require labeled data on training. However, we find this\nparadigm fails on test-time adaptation when labeled data is unavailable, where\nthe high-dimensional visual prompt overfits to the self-supervised objective.\nWe present convolutional visual prompts for test-time adaptation without\nlabels. Our convolutional prompt is structured and requires fewer trainable\nparameters (less than 1 % parameters of standard visual prompts). Extensive\nexperiments on a wide variety of OOD recognition tasks show that our approach\nis effective, improving robustness by up to 5.87 % over a number of large-scale\nmodel architectures.\n","authors":["Yun-Yun Tsai","Chengzhi Mao","Yow-Kuan Lin","Junfeng Yang"],"pdf_url":"https://arxiv.org/pdf/2303.00198v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00196v1","updated":"2023-03-01T03:05:40Z","published":"2023-03-01T03:05:40Z","title":"Transformed Low-Rank Parameterization Can Help Robust Generalization for\n  Tensor Neural Networks","summary":"  Achieving efficient and robust multi-channel data learning is a challenging\ntask in data science. By exploiting low-rankness in the transformed domain,\ni.e., transformed low-rankness, tensor Singular Value Decomposition (t-SVD) has\nachieved extensive success in multi-channel data representation and has\nrecently been extended to function representation such as Neural Networks with\nt-product layers (t-NNs). However, it still remains unclear how t-SVD\ntheoretically affects the learning behavior of t-NNs. This paper is the first\nto answer this question by deriving the upper bounds of the generalization\nerror of both standard and adversarially trained t-NNs. It reveals that the\nt-NNs compressed by exact transformed low-rank parameterization can achieve a\nsharper adversarial generalization bound. In practice, although t-NNs rarely\nhave exactly transformed low-rank weights, our analysis further shows that by\nadversarial training with gradient flow (GF), the over-parameterized t-NNs with\nReLU activations are trained with implicit regularization towards transformed\nlow-rank parameterization under certain conditions. We also establish\nadversarial generalization bounds for t-NNs with approximately transformed\nlow-rank weights. Our analysis indicates that the transformed low-rank\nparameterization can promisingly enhance robust generalization for t-NNs.\n","authors":["Andong Wang","Chao Li","Mingyuan Bai","Zhong Jin","Guoxu Zhou","Qibin Zhao"],"pdf_url":"https://arxiv.org/pdf/2303.00196v1.pdf","comment":"55 pages, submitted for peer review"},{"id":"http://arxiv.org/abs/2205.14309v2","updated":"2023-03-01T02:54:36Z","published":"2022-05-28T02:58:37Z","title":"Federated Neural Bandits","summary":"  Recent works on neural contextual bandits have achieved compelling\nperformances due to their ability to leverage the strong representation power\nof neural networks (NNs) for reward prediction. Many applications of contextual\nbandits involve multiple agents who collaborate without sharing raw\nobservations, thus giving rise to the setting of federated contextual bandits.\nExisting works on federated contextual bandits rely on linear or kernelized\nbandits, which may fall short when modeling complex real-world reward\nfunctions. So, this paper introduces the federated neural-upper confidence\nbound (FN-UCB) algorithm. To better exploit the federated setting, FN-UCB\nadopts a weighted combination of two UCBs: $\\text{UCB}^{a}$ allows every agent\nto additionally use the observations from the other agents to accelerate\nexploration (without sharing raw observations), while $\\text{UCB}^{b}$ uses an\nNN with aggregated parameters for reward prediction in a similar way to\nfederated averaging for supervised learning. Notably, the weight between the\ntwo UCBs required by our theoretical analysis is amenable to an interesting\ninterpretation, which emphasizes $\\text{UCB}^{a}$ initially for accelerated\nexploration and relies more on $\\text{UCB}^{b}$ later after enough observations\nhave been collected to train the NNs for accurate reward prediction (i.e.,\nreliable exploitation). We prove sub-linear upper bounds on both the cumulative\nregret and the number of communication rounds of FN-UCB, and empirically\ndemonstrate its competitive performance.\n","authors":["Zhongxiang Dai","Yao Shu","Arun Verma","Flint Xiaofeng Fan","Bryan Kian Hsiang Low","Patrick Jaillet"],"pdf_url":"https://arxiv.org/pdf/2205.14309v2.pdf","comment":"ICLR 2023. Code:\n  https://github.com/daizhongxiang/Federated-Neural-Bandits"},{"id":"http://arxiv.org/abs/2210.00312v4","updated":"2023-03-01T02:51:12Z","published":"2022-10-01T16:24:15Z","title":"Multimodal Analogical Reasoning over Knowledge Graphs","summary":"  Analogical reasoning is fundamental to human cognition and holds an important\nplace in various fields. However, previous studies mainly focus on single-modal\nanalogical reasoning and ignore taking advantage of structure knowledge.\nNotably, the research in cognitive psychology has demonstrated that information\nfrom multimodal sources always brings more powerful cognitive transfer than\nsingle modality sources. To this end, we introduce the new task of multimodal\nanalogical reasoning over knowledge graphs, which requires multimodal reasoning\nability with the help of background knowledge. Specifically, we construct a\nMultimodal Analogical Reasoning dataSet (MARS) and a multimodal knowledge graph\nMarKG. We evaluate with multimodal knowledge graph embedding and pre-trained\nTransformer baselines, illustrating the potential challenges of the proposed\ntask. We further propose a novel model-agnostic Multimodal analogical reasoning\nframework with Transformer (MarT) motivated by the structure mapping theory,\nwhich can obtain better performance. Code and datasets are available in\nhttps://github.com/zjunlp/MKG_Analogy.\n","authors":["Ningyu Zhang","Lei Li","Xiang Chen","Xiaozhuan Liang","Shumin Deng","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2210.00312v4.pdf","comment":"Accepted by ICLR 2023. The project website is\n  https://zjunlp.github.io/project/MKG_Analogy/introduction.html"},{"id":"http://arxiv.org/abs/2303.00191v1","updated":"2023-03-01T02:48:55Z","published":"2023-03-01T02:48:55Z","title":"pyribs: A Bare-Bones Python Library for Quality Diversity Optimization","summary":"  Recent years have seen a rise in the popularity of quality diversity (QD)\noptimization, a branch of optimization that seeks to find a collection of\ndiverse, high-performing solutions to a given problem. To grow further, we\nbelieve the QD community faces two challenges: developing a framework to\nrepresent the field's growing array of algorithms, and implementing that\nframework in software that supports a range of researchers and practitioners.\nTo address these challenges, we have developed pyribs, a library built on a\nhighly modular conceptual QD framework. By replacing components in the\nconceptual framework, and hence in pyribs, users can compose algorithms from\nacross the QD literature; equally important, they can identify unexplored\nalgorithm variations. Furthermore, pyribs makes this framework simple,\nflexible, and accessible, with a user-friendly API supported by extensive\ndocumentation and tutorials. This paper overviews the creation of pyribs,\nfocusing on the conceptual framework that it implements and the design\nprinciples that have guided the library's development.\n","authors":["Bryon Tjanaka","Matthew C. Fontaine","David H. Lee","Yulun Zhang","Nivedit Reddy Balam","Nathaniel Dennler","Sujay S. Garlanka","Nikitas Dimitri Klapsis","Stefanos Nikolaidis"],"pdf_url":"https://arxiv.org/pdf/2303.00191v1.pdf","comment":"Pyribs is available at https://pyribs.org; supplemental material for\n  this paper is available at https://pyribs.org/paper"},{"id":"http://arxiv.org/abs/2210.10946v3","updated":"2023-03-01T02:41:41Z","published":"2022-10-20T01:29:10Z","title":"Causally-guided Regularization of Graph Attention Improves\n  Generalizability","summary":"  Graph attention networks estimate the relational importance of node neighbors\nto aggregate relevant information over local neighborhoods for a prediction\ntask. However, the inferred attentions are vulnerable to spurious correlations\nand connectivity in the training data, hampering the generalizability of the\nmodel. We introduce CAR, a general-purpose regularization framework for graph\nattention networks. Embodying a causal inference approach, CAR aligns the\nattention mechanism with the causal effects of active interventions on graph\nconnectivity in a scalable manner. CAR is compatible with a variety of graph\nattention architectures, and we show that it systematically improves\ngeneralizability on various node classification tasks. Our ablation studies\nindicate that CAR hones in on the aspects of graph structure most pertinent to\nthe prediction (e.g., homophily), and does so more effectively than alternative\napproaches. Finally, we also show that CAR enhances interpretability of\nattention weights by accentuating node-neighbor relations that point to causal\nhypotheses. For social media network-sized graphs, a CAR-guided graph rewiring\napproach could allow us to combine the scalability of graph convolutional\nmethods with the higher performance of graph attention.\n","authors":["Alexander P. Wu","Thomas Markovich","Bonnie Berger","Nils Hammerla","Rohit Singh"],"pdf_url":"https://arxiv.org/pdf/2210.10946v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00187v1","updated":"2023-03-01T02:29:41Z","published":"2023-03-01T02:29:41Z","title":"On the Integration of Physics-Based Machine Learning with Hierarchical\n  Bayesian Modeling Techniques","summary":"  Machine Learning (ML) has widely been used for modeling and predicting\nphysical systems. These techniques offer high expressive power and good\ngeneralizability for interpolation within observed data sets. However, the\ndisadvantage of black-box models is that they underperform under blind\nconditions since no physical knowledge is incorporated. Physics-based ML aims\nto address this problem by retaining the mathematical flexibility of ML\ntechniques while incorporating physics. In accord, this paper proposes to embed\nmechanics-based models into the mean function of a Gaussian Process (GP) model\nand characterize potential discrepancies through kernel machines. A specific\nclass of kernel function is promoted, which has a connection with the gradient\nof the physics-based model with respect to the input and parameters and shares\nsimilarity with the exact Autocovariance function of linear dynamical systems.\nThe spectral properties of the kernel function enable considering dominant\nperiodic processes originating from physics misspecification. Nevertheless, the\nstationarity of the kernel function is a difficult hurdle in the sequential\nprocessing of long data sets, resolved through hierarchical Bayesian\ntechniques. This implementation is also advantageous to mitigate computational\ncosts, alleviating the scalability of GPs when dealing with sequential data.\nUsing numerical and experimental examples, potential applications of the\nproposed method to structural dynamics inverse problems are demonstrated.\n","authors":["Omid Sedehi","Antonina M. Kosikova","Costas Papadimitriou","Lambros S. Katafygiotis"],"pdf_url":"https://arxiv.org/pdf/2303.00187v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00186v1","updated":"2023-03-01T02:29:30Z","published":"2023-03-01T02:29:30Z","title":"Towards a real-time demand response framework for smart communities\n  using clustering techniques","summary":"  The present study explores the use of clustering techniques for the design\nand implementation of a demand response (DR) program for commercial and\nresidential prosumers. The goal of the program is to shift the participants'\nconsumption behavior to mitigate two issues a) the reverse power flow at the\nprimary substation, that occurs when generation from solar panels in the local\ngrid exceeds consumption and b) the system wide peak demand, that typically\noccurs during hours of the late afternoon. For the clustering stage, three\npopular algorithms for electrical load clustering are employed -- namely\nk-means, k-medoids and a hierarchical clustering algorithm -- alongside two\ndifferent distance metrics -- namely euclidean and constrained Dynamic Time\nWarping (DTW). We evaluate the methods using different validation metrics\nincluding a novel metric -- namely peak performance score (PPS) -- that we\npropose in the context of this study. The best setup is employed to divide\ndaily prosumer load profiles into clusters and each cluster is analyzed in\nterms of load shape, mean entropy and distribution of load profiles from each\nload type. These characteristics are then used to distinguish the clusters that\nwould be most likely to aid with the DR schemes would fit each cluster.\nFinally, we conceptualize a DR system that combines forecasting, clustering and\na price-based demand projection engine to produce daily individualized DR\nrecommendations and pricing policies for prosumers participating in the\nprogram. The results of this study can be useful for network operators and\nutilities that aim to develop targeted DR programs for groups of prosumers\nwithin flexible energy communities.\n","authors":["Sotiris Pelekis","Angelos Pipergias","Evangelos Karakolis","Spiros Mouzakitis","Francesca Santori","Mohammad Ghoreishi","Dimitris Askounis"],"pdf_url":"https://arxiv.org/pdf/2303.00186v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.06545v4","updated":"2023-03-01T02:27:46Z","published":"2022-11-12T02:01:46Z","title":"Self-Supervised Graph Structure Refinement for Graph Neural Networks","summary":"  Graph structure learning (GSL), which aims to learn the adjacency matrix for\ngraph neural networks (GNNs), has shown great potential in boosting the\nperformance of GNNs. Most existing GSL works apply a joint learning framework\nwhere the estimated adjacency matrix and GNN parameters are optimized for\ndownstream tasks. However, as GSL is essentially a link prediction task, whose\ngoal may largely differ from the goal of the downstream task. The inconsistency\nof these two goals limits the GSL methods to learn the potential optimal graph\nstructure. Moreover, the joint learning framework suffers from scalability\nissues in terms of time and space during the process of estimation and\noptimization of the adjacency matrix. To mitigate these issues, we propose a\ngraph structure refinement (GSR) framework with a pretrain-finetune pipeline.\nSpecifically, The pre-training phase aims to comprehensively estimate the\nunderlying graph structure by a multi-view contrastive learning framework with\nboth intra- and inter-view link prediction tasks. Then, the graph structure is\nrefined by adding and removing edges according to the edge probabilities\nestimated by the pre-trained model. Finally, the fine-tuning GNN is initialized\nby the pre-trained model and optimized toward downstream tasks. With the\nrefined graph structure remaining static in the fine-tuning space, GSR avoids\nestimating and optimizing graph structure in the fine-tuning phase which enjoys\ngreat scalability and efficiency. Moreover, the fine-tuning GNN is boosted by\nboth migrating knowledge and refining graphs. Extensive experiments are\nconducted to evaluate the effectiveness (best performance on six benchmark\ndatasets), efficiency, and scalability (13.8x faster using 32.8% GPU memory\ncompared to the best GSL baseline on Cora) of the proposed model.\n","authors":["Jianan Zhao","Qianlong Wen","Mingxuan Ju","Chuxu Zhang","Yanfang Ye"],"pdf_url":"https://arxiv.org/pdf/2211.06545v4.pdf","comment":"WSDM 2023"},{"id":"http://arxiv.org/abs/2206.01729v2","updated":"2023-03-01T02:27:10Z","published":"2022-06-01T04:30:41Z","title":"Torsional Diffusion for Molecular Conformer Generation","summary":"  Molecular conformer generation is a fundamental task in computational\nchemistry. Several machine learning approaches have been developed, but none\nhave outperformed state-of-the-art cheminformatics methods. We propose\ntorsional diffusion, a novel diffusion framework that operates on the space of\ntorsion angles via a diffusion process on the hypertorus and an\nextrinsic-to-intrinsic score model. On a standard benchmark of drug-like\nmolecules, torsional diffusion generates superior conformer ensembles compared\nto machine learning and cheminformatics methods in terms of both RMSD and\nchemical properties, and is orders of magnitude faster than previous\ndiffusion-based models. Moreover, our model provides exact likelihoods, which\nwe employ to build the first generalizable Boltzmann generator. Code is\navailable at https://github.com/gcorso/torsional-diffusion.\n","authors":["Bowen Jing","Gabriele Corso","Jeffrey Chang","Regina Barzilay","Tommi Jaakkola"],"pdf_url":"https://arxiv.org/pdf/2206.01729v2.pdf","comment":"NeurIPS 2022"},{"id":"http://arxiv.org/abs/2303.00180v1","updated":"2023-03-01T02:14:20Z","published":"2023-03-01T02:14:20Z","title":"FaceRNET: a Facial Expression Intensity Estimation Network","summary":"  This paper presents our approach for Facial Expression Intensity Estimation\nfrom videos. It includes two components: i) a representation extractor network\nthat extracts various emotion descriptors (valence-arousal, action units and\nbasic expressions) from each videoframe; ii) a RNN that captures temporal\ninformation in the data, followed by a mask layer which enables handling\nvarying input video lengths through dynamic routing. This approach has been\ntested on the Hume-Reaction dataset yielding excellent results.\n","authors":["Dimitrios Kollias","Andreas Psaroudakis","Anastasios Arsenos","Paraskeui Theofilou"],"pdf_url":"https://arxiv.org/pdf/2303.00180v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00179v1","updated":"2023-03-01T02:13:22Z","published":"2023-03-01T02:13:22Z","title":"A Unified Momentum-based Paradigm of Decentralized SGD for Non-Convex\n  Models and Heterogeneous Data","summary":"  Emerging distributed applications recently boosted the development of\ndecentralized machine learning, especially in IoT and edge computing fields. In\nreal-world scenarios, the common problems of non-convexity and data\nheterogeneity result in inefficiency, performance degradation, and development\nstagnation. The bulk of studies concentrates on one of the issues mentioned\nabove without having a more general framework that has been proven optimal. To\nthis end, we propose a unified paradigm called UMP, which comprises two\nalgorithms, D-SUM and GT-DSUM, based on the momentum technique with\ndecentralized stochastic gradient descent(SGD). The former provides a\nconvergence guarantee for general non-convex objectives. At the same time, the\nlatter is extended by introducing gradient tracking, which estimates the global\noptimization direction to mitigate data heterogeneity(i.e., distribution\ndrift). We can cover most momentum-based variants based on the classical heavy\nball or Nesterov's acceleration with different parameters in UMP. In theory, we\nrigorously provide the convergence analysis of these two approaches for\nnon-convex objectives and conduct extensive experiments, demonstrating a\nsignificant improvement in model accuracy by up to 57.6% compared to other\nmethods in practice.\n","authors":["Haizhou Du","Chengdong Ni"],"pdf_url":"https://arxiv.org/pdf/2303.00179v1.pdf","comment":"24 pages"},{"id":"http://arxiv.org/abs/2303.00177v1","updated":"2023-03-01T02:09:49Z","published":"2023-03-01T02:09:49Z","title":"Finite-sample Guarantees for Nash Q-learning with Linear Function\n  Approximation","summary":"  Nash Q-learning may be considered one of the first and most known algorithms\nin multi-agent reinforcement learning (MARL) for learning policies that\nconstitute a Nash equilibrium of an underlying general-sum Markov game. Its\noriginal proof provided asymptotic guarantees and was for the tabular case.\nRecently, finite-sample guarantees have been provided using more modern RL\ntechniques for the tabular case. Our work analyzes Nash Q-learning using linear\nfunction approximation -- a representation regime introduced when the state\nspace is large or continuous -- and provides finite-sample guarantees that\nindicate its sample efficiency. We find that the obtained performance nearly\nmatches an existing efficient result for single-agent RL under the same\nrepresentation and has a polynomial gap when compared to the best-known result\nfor the tabular case.\n","authors":["Pedro Cisneros-Velarde","Sanmi Koyejo"],"pdf_url":"https://arxiv.org/pdf/2303.00177v1.pdf","comment":"25 pages. arXiv admin note: text overlap with arXiv:2205.15891"},{"id":"http://arxiv.org/abs/2303.00175v1","updated":"2023-03-01T02:07:48Z","published":"2023-03-01T02:07:48Z","title":"A Deep Neural Architecture for Harmonizing 3-D Input Data Analysis and\n  Decision Making in Medical Imaging","summary":"  Harmonizing the analysis of data, especially of 3-D image volumes, consisting\nof different number of slices and annotated per volume, is a significant\nproblem in training and using deep neural networks in various applications,\nincluding medical imaging. Moreover, unifying the decision making of the\nnetworks over different input datasets is crucial for the generation of rich\ndata-driven knowledge and for trusted usage in the applications. This paper\npresents a new deep neural architecture, named RACNet, which includes routing\nand feature alignment steps and effectively handles different input lengths and\nsingle annotations of the 3-D image inputs, whilst providing highly accurate\ndecisions. In addition, through latent variable extraction from the trained\nRACNet, a set of anchors are generated providing further insight on the\nnetwork's decision making. These can be used to enrich and unify data-driven\nknowledge extracted from different datasets. An extensive experimental study\nillustrates the above developments, focusing on COVID-19 diagnosis through\nanalysis of 3-D chest CT scans from databases generated in different countries\nand medical centers.\n","authors":["Dimitrios Kollias","Anastasios Arsenos","Stefanos Kollias"],"pdf_url":"https://arxiv.org/pdf/2303.00175v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.07924v3","updated":"2023-03-01T01:59:08Z","published":"2022-09-15T07:45:35Z","title":"GNNInterpreter: A Probabilistic Generative Model-Level Explanation for\n  Graph Neural Networks","summary":"  Recently, Graph Neural Networks (GNNs) have significantly advanced the\nperformance of machine learning tasks on graphs. However, this technological\nbreakthrough makes people wonder: how does a GNN make such decisions, and can\nwe trust its prediction with high confidence? When it comes to some critical\nfields, such as biomedicine, where making wrong decisions can have severe\nconsequences, it is crucial to interpret the inner working mechanisms of GNNs\nbefore applying them. In this paper, we propose a model-agnostic model-level\nexplanation method for different GNNs that follow the message passing scheme,\nGNNInterpreter, to explain the high-level decision-making process of the GNN\nmodel. More specifically, GNNInterpreter learns a probabilistic generative\ngraph distribution that produces the most discriminative graph pattern the GNN\ntries to detect when making a certain prediction by optimizing a novel\nobjective function specifically designed for the model-level explanation for\nGNNs. Compared to existing works, GNNInterpreter is more flexible and\ncomputationally efficient in generating explanation graphs with different types\nof node and edge features, without introducing another blackbox or requiring\nmanually specified domain-specific rules. In addition, the experimental studies\nconducted on four different datasets demonstrate that the explanation graphs\ngenerated by GNNInterpreter match the desired graph pattern if the model is\nideal; otherwise, potential model pitfalls can be revealed by the explanation.\n","authors":["Xiaoqi Wang","Han-Wei Shen"],"pdf_url":"https://arxiv.org/pdf/2209.07924v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00171v1","updated":"2023-03-01T01:53:11Z","published":"2023-03-01T01:53:11Z","title":"DTW-SiameseNet: Dynamic Time Warped Siamese Network for Mispronunciation\n  Detection and Correction","summary":"  Personal Digital Assistants (PDAs) - such as Siri, Alexa and Google\nAssistant, to name a few - play an increasingly important role to access\ninformation and complete tasks spanning multiple domains, and by diverse groups\nof users. A text-to-speech (TTS) module allows PDAs to interact in a natural,\nhuman-like manner, and play a vital role when the interaction involves people\nwith visual impairments or other disabilities. To cater to the needs of a\ndiverse set of users, inclusive TTS is important to recognize and pronounce\ncorrectly text in different languages and dialects. Despite great progress in\nspeech synthesis, the pronunciation accuracy of named entities in a\nmulti-lingual setting still has a large room for improvement. Existing\napproaches to correct named entity (NE) mispronunciations, like retraining\nGrapheme-to-Phoneme (G2P) models, or maintaining a TTS pronunciation\ndictionary, require expensive annotation of the ground truth pronunciation,\nwhich is also time consuming. In this work, we present a highly-precise,\nPDA-compatible pronunciation learning framework for the task of TTS\nmispronunciation detection and correction. In addition, we also propose a novel\nmispronunciation detection model called DTW-SiameseNet, which employs metric\nlearning with a Siamese architecture for Dynamic Time Warping (DTW) with\ntriplet loss. We demonstrate that a locale-agnostic, privacy-preserving\nsolution to the problem of TTS mispronunciation detection is feasible. We\nevaluate our approach on a real-world dataset, and a corpus of NE\npronunciations of an anonymized audio dataset of person names recorded by\nparticipants from 10 different locales. Human evaluation shows our proposed\napproach improves pronunciation accuracy on average by ~6% compared to strong\nphoneme-based and audio-based baselines.\n","authors":["Raviteja Anantha","Kriti Bhasin","Daniela de la Parra Aguilar","Prabal Vashisht","Becci Williamson","Srinivas Chappidi"],"pdf_url":"https://arxiv.org/pdf/2303.00171v1.pdf","comment":"Preprint version"},{"id":"http://arxiv.org/abs/2303.00170v1","updated":"2023-03-01T01:48:20Z","published":"2023-03-01T01:48:20Z","title":"Asymmetric Learning for Graph Neural Network based Link Prediction","summary":"  Link prediction is a fundamental problem in many graph based applications,\nsuch as protein-protein interaction prediction. Graph neural network (GNN) has\nrecently been widely used for link prediction. However, existing GNN based link\nprediction (GNN-LP) methods suffer from scalability problem during training for\nlarge-scale graphs, which has received little attention by researchers. In this\npaper, we first give computation complexity analysis of existing GNN-LP\nmethods, which reveals that the scalability problem stems from their symmetric\nlearning strategy adopting the same class of GNN models to learn representation\nfor both head and tail nodes. Then we propose a novel method, called asymmetric\nlearning (AML), for GNN-LP. The main idea of AML is to adopt a GNN model for\nlearning head node representation while using a multi-layer perceptron (MLP)\nmodel for learning tail node representation. Furthermore, AML proposes a\nrow-wise sampling strategy to generate mini-batch for training, which is a\nnecessary component to make the asymmetric learning strategy work for training\nspeedup. To the best of our knowledge, AML is the first GNN-LP method adopting\nan asymmetric learning strategy for node representation learning. Experiments\non three real large-scale datasets show that AML is 1.7X~7.3X faster in\ntraining than baselines with a symmetric learning strategy, while having almost\nno accuracy loss.\n","authors":["Kai-Lang Yao","Wu-Jun Li"],"pdf_url":"https://arxiv.org/pdf/2303.00170v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14165v2","updated":"2023-03-01T01:36:37Z","published":"2023-02-27T21:57:42Z","title":"GAM Coach: Towards Interactive and User-centered Algorithmic Recourse","summary":"  Machine learning (ML) recourse techniques are increasingly used in\nhigh-stakes domains, providing end users with actions to alter ML predictions,\nbut they assume ML developers understand what input variables can be changed.\nHowever, a recourse plan's actionability is subjective and unlikely to match\ndevelopers' expectations completely. We present GAM Coach, a novel open-source\nsystem that adapts integer linear programming to generate customizable\ncounterfactual explanations for Generalized Additive Models (GAMs), and\nleverages interactive visualizations to enable end users to iteratively\ngenerate recourse plans meeting their needs. A quantitative user study with 41\nparticipants shows our tool is usable and useful, and users prefer personalized\nrecourse plans over generic plans. Through a log analysis, we explore how users\ndiscover satisfactory recourse plans, and provide empirical evidence that\ntransparency can lead to more opportunities for everyday users to discover\ncounterintuitive patterns in ML models. GAM Coach is available at:\nhttps://poloclub.github.io/gam-coach/.\n","authors":["Zijie J. Wang","Jennifer Wortman Vaughan","Rich Caruana","Duen Horng Chau"],"pdf_url":"https://arxiv.org/pdf/2302.14165v2.pdf","comment":"Accepted to CHI 2023. 20 pages, 12 figures. For a demo video, see\n  https://youtu.be/ubacP34H9XE. For a live demo, visit\n  https://poloclub.github.io/gam-coach/"},{"id":"http://arxiv.org/abs/2210.01241v3","updated":"2023-03-01T01:31:17Z","published":"2022-10-03T21:38:29Z","title":"Is Reinforcement Learning (Not) for Natural Language Processing:\n  Benchmarks, Baselines, and Building Blocks for Natural Language Policy\n  Optimization","summary":"  We tackle the problem of aligning pre-trained large language models (LMs)\nwith human preferences. If we view text generation as a sequential\ndecision-making problem, reinforcement learning (RL) appears to be a natural\nconceptual framework. However, using RL for LM-based generation faces empirical\nchallenges, including training instability due to the combinatorial action\nspace, as well as a lack of open-source libraries and benchmarks customized for\nLM alignment. Thus, a question rises in the research community: is RL a\npractical paradigm for NLP?\n  To help answer this, we first introduce an open-source modular library,\nRL4LMs (Reinforcement Learning for Language Models), for optimizing language\ngenerators with RL. The library consists of on-policy RL algorithms that can be\nused to train any encoder or encoder-decoder LM in the HuggingFace library\n(Wolf et al. 2020) with an arbitrary reward function. Next, we present the GRUE\n(General Reinforced-language Understanding Evaluation) benchmark, a set of 6\nlanguage generation tasks which are supervised not by target strings, but by\nreward functions which capture automated measures of human preference.GRUE is\nthe first leaderboard-style evaluation of RL algorithms for NLP tasks. Finally,\nwe introduce an easy-to-use, performant RL algorithm, NLPO (Natural Language\nPolicy Optimization)} that learns to effectively reduce the combinatorial\naction space in language generation. We show 1) that RL techniques are\ngenerally better than supervised methods at aligning LMs to human preferences;\nand 2) that NLPO exhibits greater stability and performance than previous\npolicy gradient methods (e.g., PPO (Schulman et al. 2017)), based on both\nautomatic and human evaluations.\n","authors":["Rajkumar Ramamurthy","Prithviraj Ammanabrolu","Kianté Brantley","Jack Hessel","Rafet Sifa","Christian Bauckhage","Hannaneh Hajishirzi","Yejin Choi"],"pdf_url":"https://arxiv.org/pdf/2210.01241v3.pdf","comment":"In Proceedings of ICLR 2023. Code found at\n  https://github.com/allenai/rl4lms and Project website at\n  https://rl4lms.apps.allenai.org/"},{"id":"http://arxiv.org/abs/2210.11780v2","updated":"2023-03-01T01:14:55Z","published":"2022-10-21T07:25:57Z","title":"Correlating sparse sensing for large-scale traffic speed estimation: A\n  Laplacian enhanced low-rank tensor kriging approach","summary":"  Traffic speed is central to characterizing the fluidity of the road network.\nMany transportation applications rely on it, such as real-time navigation,\ndynamic route planning, and congestion management. Rapid advances in sensing\nand communication techniques make traffic speed detection easier than ever.\nHowever, due to sparse deployment of static sensors or low penetration of\nmobile sensors, speeds detected are incomplete and far from network-wide use.\nIn addition, sensors are prone to error or missing data due to various kinds of\nreasons, speeds from these sensors can become highly noisy. These drawbacks\ncall for effective techniques to recover credible estimates from the incomplete\ndata. In this work, we first identify the issue as a spatiotemporal kriging\nproblem and propose a Laplacian enhanced low-rank tensor completion (LETC)\nframework featuring both lowrankness and multi-dimensional correlations for\nlarge-scale traffic speed kriging under limited observations. To be specific,\nthree types of speed correlation including temporal continuity, temporal\nperiodicity, and spatial proximity are carefully chosen and simultaneously\nmodeled by three different forms of graph Laplacian, named temporal graph\nFourier transform, generalized temporal consistency regularization, and\ndiffusion graph regularization. We then design an efficient solution algorithm\nvia several effective numeric techniques to scale up the proposed model to\nnetwork-wide kriging. By performing experiments on two public million-level\ntraffic speed datasets, we finally draw the conclusion and find our proposed\nLETC achieves the state-of-the-art kriging performance even under low\nobservation rates, while at the same time saving more than half computing time\ncompared with baseline methods. Some insights into spatiotemporal traffic data\nmodeling and kriging at the network level are provided as well.\n","authors":["Tong Nie","Guoyang Qin","Yunpeng Wang","Jian Sun"],"pdf_url":"https://arxiv.org/pdf/2210.11780v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.04980v2","updated":"2023-03-01T01:02:23Z","published":"2022-07-23T15:24:07Z","title":"An NLP-Assisted Bayesian Time Series Analysis for Prevalence of Twitter\n  Cyberbullying During the COVID-19 Pandemic","summary":"  COVID-19 has brought about many changes in social dynamics. Stay-at-home\norders and disruptions in school teaching can influence bullying behavior\nin-person and online, both of which leading to negative outcomes in victims. To\nstudy cyberbullying specifically, 1 million tweets containing keywords\nassociated with abuse were collected from the beginning of 2019 to the end of\n2021 with the Twitter API search endpoint. A natural language processing model\npre-trained on a Twitter corpus generated probabilities for the tweets being\noffensive and hateful. To overcome limitations of sampling, data was also\ncollected using the count endpoint. The fraction of tweets from a given daily\nsample marked as abusive is multiplied to the number reported by the count\nendpoint. Once these adjusted counts are assembled, a Bayesian autoregressive\nPoisson model allows one to study the mean trend and lag functions of the data\nand how they vary over time. The results reveal strong weekly and yearly\nseasonality in hateful speech but with slight differences across years that may\nbe attributed to COVID-19.\n","authors":["Christopher Perez","Sayar Karmakar"],"pdf_url":"https://arxiv.org/pdf/2208.04980v2.pdf","comment":"22 pages, 15 figures"},{"id":"http://arxiv.org/abs/2208.04202v2","updated":"2023-03-01T00:18:33Z","published":"2022-08-08T15:08:40Z","title":"Analog Bits: Generating Discrete Data using Diffusion Models with\n  Self-Conditioning","summary":"  We present Bit Diffusion: a simple and generic approach for generating\ndiscrete data with continuous state and continuous time diffusion models. The\nmain idea behind our approach is to first represent the discrete data as binary\nbits, and then train a continuous diffusion model to model these bits as real\nnumbers which we call analog bits. To generate samples, the model first\ngenerates the analog bits, which are then thresholded to obtain the bits that\nrepresent the discrete variables. We further propose two simple techniques,\nnamely Self-Conditioning and Asymmetric Time Intervals, which lead to a\nsignificant improvement in sample quality. Despite its simplicity, the proposed\napproach can achieve strong performance in both discrete image generation and\nimage captioning tasks. For discrete image generation, we significantly improve\nprevious state-of-the-art on both CIFAR-10 (which has 3K discrete 8-bit tokens)\nand ImageNet-64x64 (which has 12K discrete 8-bit tokens), outperforming the\nbest autoregressive model in both sample quality (measured by FID) and\nefficiency. For image captioning on MS-COCO dataset, our approach achieves\ncompetitive results compared to autoregressive models.\n","authors":["Ting Chen","Ruixiang Zhang","Geoffrey Hinton"],"pdf_url":"https://arxiv.org/pdf/2208.04202v2.pdf","comment":"ICLR'23"},{"id":"http://arxiv.org/abs/2303.00141v1","updated":"2023-03-01T00:13:52Z","published":"2023-03-01T00:13:52Z","title":"Containing a spread through sequential learning: to exploit or to\n  explore?","summary":"  The spread of an undesirable contact process, such as an infectious disease\n(e.g. COVID-19), is contained through testing and isolation of infected nodes.\nThe temporal and spatial evolution of the process (along with containment\nthrough isolation) render such detection as fundamentally different from active\nsearch detection strategies. In this work, through an active learning approach,\nwe design testing and isolation strategies to contain the spread and minimize\nthe cumulative infections under a given test budget. We prove that the\nobjective can be optimized, with performance guarantees, by greedily selecting\nthe nodes to test. We further design reward-based methodologies that\neffectively minimize an upper bound on the cumulative infections and are\ncomputationally more tractable in large networks. These policies, however, need\nknowledge about the nodes' infection probabilities which are dynamically\nchanging and have to be learned by sequential testing. We develop a\nmessage-passing framework for this purpose and, building on that, show novel\ntradeoffs between exploitation of knowledge through reward-based heuristics and\nexploration of the unknown through a carefully designed probabilistic testing.\nThe tradeoffs are fundamentally distinct from the classical counterparts under\nactive search or multi-armed bandit problems (MABs). We provably show the\nnecessity of exploration in a stylized network and show through simulations\nthat exploration can outperform exploitation in various synthetic and real-data\nnetworks depending on the parameters of the network and the spread.\n","authors":["Xingran Chen","Hesam Nikpey","Jungyeol Kim","Saswati Sarkar","Shirin Saeedi-Bidokhti"],"pdf_url":"https://arxiv.org/pdf/2303.00141v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2206.00089v2","updated":"2023-03-01T13:33:47Z","published":"2022-05-31T19:59:00Z","title":"Defining Quantum Games","summary":"  In this article, we explore the concept of quantum games and define quantum\ngames as any type of playable games that are related to or reference quantum\nphysics through any of three proposed aspects. The rise of the quantum\ncomputers has made it possible to think about a new wave of computer games,\nnamely quantum computer games, games on quantum computers. But at the same\ntime, there are also various games that are exploring quantum mechanics and\nrelated topics through digital, analogue and hybrid means. In this article we\ngo through the emerging body of quantum games, the history of quantum games and\nthe different ways a game may be considered a quantum game. For this we propose\nthree dimensions for analysing and defining the phenomenon of quantum games:\nthe perceivable dimension of quantum physics, the dimension of quantum\ntechnologies and the dimension of scientific purposes.\n","authors":["Laura Piispanen","Marcel Pfaffhauser","Annakaisa Kultima","James R. Wootton"],"pdf_url":"https://arxiv.org/pdf/2206.00089v2.pdf","comment":"13 pages + references, 34 figures. Update on the previous version\n  with some typos"},{"id":"http://arxiv.org/abs/2303.00448v1","updated":"2023-03-01T12:17:33Z","published":"2023-03-01T12:17:33Z","title":"The style transformer with common knowledge optimization for image-text\n  retrieval","summary":"  Image-text retrieval which associates different modalities has drawn broad\nattention due to its excellent research value and broad real-world application.\nWhile the algorithms keep updated, most of them haven't taken the high-level\nsemantic relationships (\"style embedding\") and common knowledge from\nmulti-modalities into full consideration. To this end, we propose a novel style\ntransformer network with common knowledge optimization (CKSTN) for image-text\nretrieval. The main module is the common knowledge adaptor (CKA) with both the\nstyle embedding extractor (SEE) and the common knowledge optimization (CKO)\nmodules. Specifically, the SEE is designed to effectively extract high-level\nfeatures. The CKO module is introduced to dynamically capture the latent\nconcepts of common knowledge from different modalities. Together, they could\nassist in the formation of item representations in lightweight transformers.\nBesides, to get generalized temporal common knowledge, we propose a sequential\nupdate strategy to effectively integrate the features of different layers in\nSEE with previous common feature units. CKSTN outperforms the results of\nstate-of-the-art methods in image-text retrieval on MSCOCO and Flickr30K\ndatasets. Moreover, CKSTN is more convenient and practical for the application\nof real scenes, due to the better performance and lower parameters.\n","authors":["Wenrui Li","Zhengyu Ma","Xiaopeng Fan"],"pdf_url":"https://arxiv.org/pdf/2303.00448v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14472v2","updated":"2023-03-01T03:38:11Z","published":"2023-02-28T10:30:16Z","title":"TV-watching partner robot: Analysis of User's Experience","summary":"  Watching TV not only provides news information but also gives an opportunity\nfor different generations to communicate. With the proliferation of\nsmartphones, PC, and the Internet, increase the opportunities for communication\nin front of the television is also likely to diminish. This has led to some\nproblems further from face-to-face such as a lack of self-control and\ninsufficient development of communication skills. This paper proposes a\nTV-watching companion robot with open-domain chat ability. The robot contains\ntwo modes: TV-watching mode and conversation mode. In TV-watching mode, the\nrobot first extracts keywords from the TV program and then generates the\ndisclosure utterances based on the extracted keywords as if enjoying the TV\nprogram. In the conversation mode, the robot generates question utterances with\nkeywords in the same way and then employs a topics-based dialog management\nmethod consisting of multiple dialog engines for rich conversations related to\nthe TV program. We conduct the initial experiments and the result shows that\nall participants from the three groups enjoyed talking with the robot, and the\nquestion about their interests in the robot was rated 6.5/7-levels. This\nindicates that the proposed conversational features of TV-watching Companion\nRobot have the potential to make our daily lives more enjoyable. Under the\nanalysis of the initial experiments, we achieve further experiments with more\nparticipants by dividing them into two groups: a control group without a robot\nand an intervention group with a robot. The results show that people prefer to\ntalk to robots because the robot will bring more enjoyable, relaxed, and\ninteresting.\n","authors":["Donghuo Zeng","Jianming Wu","Gen Hattori","Yasuhiro Takishima"],"pdf_url":"https://arxiv.org/pdf/2302.14472v2.pdf","comment":"15 pages, 3 figures, 11 tables"},{"id":"http://arxiv.org/abs/2210.00312v4","updated":"2023-03-01T02:51:12Z","published":"2022-10-01T16:24:15Z","title":"Multimodal Analogical Reasoning over Knowledge Graphs","summary":"  Analogical reasoning is fundamental to human cognition and holds an important\nplace in various fields. However, previous studies mainly focus on single-modal\nanalogical reasoning and ignore taking advantage of structure knowledge.\nNotably, the research in cognitive psychology has demonstrated that information\nfrom multimodal sources always brings more powerful cognitive transfer than\nsingle modality sources. To this end, we introduce the new task of multimodal\nanalogical reasoning over knowledge graphs, which requires multimodal reasoning\nability with the help of background knowledge. Specifically, we construct a\nMultimodal Analogical Reasoning dataSet (MARS) and a multimodal knowledge graph\nMarKG. We evaluate with multimodal knowledge graph embedding and pre-trained\nTransformer baselines, illustrating the potential challenges of the proposed\ntask. We further propose a novel model-agnostic Multimodal analogical reasoning\nframework with Transformer (MarT) motivated by the structure mapping theory,\nwhich can obtain better performance. Code and datasets are available in\nhttps://github.com/zjunlp/MKG_Analogy.\n","authors":["Ningyu Zhang","Lei Li","Xiang Chen","Xiaozhuan Liang","Shumin Deng","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2210.00312v4.pdf","comment":"Accepted by ICLR 2023. The project website is\n  https://zjunlp.github.io/project/MKG_Analogy/introduction.html"},{"id":"http://arxiv.org/abs/2303.00181v1","updated":"2023-03-01T02:15:07Z","published":"2023-03-01T02:15:07Z","title":"Selectively Hard Negative Mining for Alleviating Gradient Vanishing in\n  Image-Text Matching","summary":"  Recently, a series of Image-Text Matching (ITM) methods achieve impressive\nperformance. However, we observe that most existing ITM models suffer from\ngradients vanishing at the beginning of training, which makes these models\nprone to falling into local minima. Most ITM models adopt triplet loss with\nHard Negative mining (HN) as the optimization objective. We find that\noptimizing an ITM model using only the hard negative samples can easily lead to\ngradient vanishing. In this paper, we derive the condition under which the\ngradient vanishes during training. When the difference between the positive\npair similarity and the negative pair similarity is close to 0, the gradients\non both the image and text encoders will approach 0. To alleviate the gradient\nvanishing problem, we propose a Selectively Hard Negative Mining (SelHN)\nstrategy, which chooses whether to mine hard negative samples according to the\ngradient vanishing condition. SelHN can be plug-and-play applied to existing\nITM models to give them better training behavior. To further ensure the\nback-propagation of gradients, we construct a Residual Visual Semantic\nEmbedding model with SelHN, denoted as RVSE++. Extensive experiments on two ITM\nbenchmarks demonstrate the strength of RVSE++, achieving state-of-the-art\nperformance.\n","authors":["Zheng Li","Caili Guo","Xin Wang","Zerun Feng","Zhongtian Du"],"pdf_url":"https://arxiv.org/pdf/2303.00181v1.pdf","comment":null}]},"2023-03-02T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2303.01502v1","updated":"2023-03-02T18:59:46Z","published":"2023-03-02T18:59:46Z","title":"Computational Language Acquisition with Theory of Mind","summary":"  Unlike current state-of-the-art language models, young children actively\nacquire language through interactions with their surrounding environment and\ncaretakers. One mechanism that has been argued to be critical to language\nlearning is the ability to infer the mental states of other agents in social\nenvironments, coined Theory of Mind (ToM) by Premack & Woodruff (1978). Drawing\ninspiration from the modern operationalized versions of ToM implemented in\nRabinowitz et al. (2018) and Zhu et al. (2021), we build language-learning\nagents equipped with ToM, and measure its effects on the learning process. We\nmodel ToM by giving the speaker agent an internal listener model that is\ntrained alongside the speaker and used to rerank potential utterances. We\nexperiment with varying task difficulty, hypothesizing that models will acquire\nmore complex language to adapt to stronger environmental pressures. We find\nthat training speakers with a highly weighted ToM listener component leads to\nperformance gains in our image referential game setting. We also find some\nevidence that increasing task difficulty in the training process results in\nmore fluent and precise utterances in evaluation. This suggests the potential\nutility of further incorporating ToM, as well as other insights from child\nlanguage acquisition, into computational models of language acquisition.\n","authors":["Andy Liu","Hao Zhu","Emmy Liu","Yonatan Bisk","Graham Neubig"],"pdf_url":"https://arxiv.org/pdf/2303.01502v1.pdf","comment":"9 pages, 3 figures. To be published in the 11th International\n  Conference on Learning Representations, ICLR 2023, Conference Track\n  Proceedings"},{"id":"http://arxiv.org/abs/2303.01490v1","updated":"2023-03-02T18:51:58Z","published":"2023-03-02T18:51:58Z","title":"Language Variety Identification with True Labels","summary":"  Language identification is an important first step in many IR and NLP\napplications. Most publicly available language identification datasets,\nhowever, are compiled under the assumption that the gold label of each instance\nis determined by where texts are retrieved from. Research has shown that this\nis a problematic assumption, particularly in the case of very similar languages\n(e.g., Croatian and Serbian) and national language varieties (e.g., Brazilian\nand European Portuguese), where texts may contain no distinctive marker of the\nparticular language or variety. To overcome this important limitation, this\npaper presents DSL True Labels (DSL-TL), the first human-annotated multilingual\ndataset for language variety identification. DSL-TL contains a total of 12,900\ninstances in Portuguese, split between European Portuguese and Brazilian\nPortuguese; Spanish, split between Argentine Spanish and Castilian Spanish; and\nEnglish, split between American English and British English. We trained\nmultiple models to discriminate between these language varieties, and we\npresent the results in detail. The data and models presented in this paper\nprovide a reliable benchmark toward the development of robust and fairer\nlanguage variety identification systems. We make DSL-TL freely available to the\nresearch community.\n","authors":["Marcos Zampieri","Kai North","Tommi Jauhiainen","Mariano Felice","Neha Kumari","Nishant Nair","Yash Bangera"],"pdf_url":"https://arxiv.org/pdf/2303.01490v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13817v2","updated":"2023-03-02T18:27:43Z","published":"2023-02-27T14:26:29Z","title":"Let's have a chat! A Conversation with ChatGPT: Technology,\n  Applications, and Limitations","summary":"  The emergence of an AI-powered chatbot that can generate human-like sentences\nand write coherent essays has caught the world's attention. This paper\ndiscusses the historical overview of chatbots and the technology behind Chat\nGenerative Pre-trained Transformer, better known as ChatGPT. Moreover,\npotential applications of ChatGPT in various domains, including healthcare,\neducation, and research, are highlighted. Despite promising results, there are\nseveral privacy and ethical concerns surrounding ChatGPT. In addition, we\nhighlight some of the important limitations of the current version of ChatGPT.\nWe also ask ChatGPT to provide its point of view and present its responses to\nseveral questions we attempt to answer.\n","authors":["Sakib Shahriar","Kadhim Hayawi"],"pdf_url":"https://arxiv.org/pdf/2302.13817v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01432v1","updated":"2023-03-02T17:45:32Z","published":"2023-03-02T17:45:32Z","title":"WiCE: Real-World Entailment for Claims in Wikipedia","summary":"  Models for textual entailment have increasingly been applied to settings like\nfact-checking, presupposition verification in question answering, and\nvalidating that generation models' outputs are faithful to a source. However,\nsuch applications are quite far from the settings that existing datasets are\nconstructed in. We propose WiCE, a new textual entailment dataset centered\naround verifying claims in text, built on real-world claims and evidence in\nWikipedia with fine-grained annotations. We collect sentences in Wikipedia that\ncite one or more webpages and annotate whether the content on those pages\nentails those sentences. Negative examples arise naturally, from slight\nmisinterpretation of text to minor aspects of the sentence that are not\nattested in the evidence. Our annotations are over sub-sentence units of the\nhypothesis, decomposed automatically by GPT-3, each of which is labeled with a\nsubset of evidence sentences from the source document. We show that real claims\nin our dataset involve challenging verification problems, and we benchmark\nexisting approaches on this dataset. In addition, we show that reducing the\ncomplexity of claims by decomposing them by GPT-3 can improve entailment\nmodels' performance on various domains.\n","authors":["Ryo Kamoi","Tanya Goyal","Juan Diego Rodriguez","Greg Durrett"],"pdf_url":"https://arxiv.org/pdf/2303.01432v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01421v1","updated":"2023-03-02T17:15:02Z","published":"2023-03-02T17:15:02Z","title":"Semiparametric Language Models Are Scalable Continual Learners","summary":"  Semiparametric language models (LMs) have shown promise in continuously\nlearning from new text data by combining a parameterized neural LM with a\ngrowable non-parametric memory for memorizing new content. However,\nconventional semiparametric LMs will finally become prohibitive for computing\nand storing if they are applied to continual learning over streaming data,\nbecause the non-parametric memory grows linearly with the amount of data they\nlearn from over time. To address the issue of scalability, we present a simple\nand intuitive approach called Selective Memorization (SeMem), which only\nmemorizes difficult samples that the model is likely to struggle with. We\ndemonstrate that SeMem improves the scalability of semiparametric LMs for\ncontinual learning over streaming data in two ways: (1) data-wise scalability:\nas the model becomes stronger through continual learning, it will encounter\nfewer difficult cases that need to be memorized, causing the growth of the\nnon-parametric memory to slow down over time rather than growing at a linear\nrate with the size of training data; (2) model-wise scalability: SeMem allows a\nlarger model to memorize fewer samples than its smaller counterpart because it\nis rarer for a larger model to encounter incomprehensible cases, resulting in a\nnon-parametric memory that does not scale linearly with model size. We conduct\nextensive experiments in language modeling and downstream tasks to test SeMem's\nresults, showing SeMem enables a semiparametric LM to be a scalable continual\nlearner with little forgetting.\n","authors":["Guangyue Peng","Tao Ge","Si-Qing Chen","Furu Wei","Houfeng Wang"],"pdf_url":"https://arxiv.org/pdf/2303.01421v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2303.01410v1","updated":"2023-03-02T16:59:31Z","published":"2023-03-02T16:59:31Z","title":"NLP Workbench: Efficient and Extensible Integration of State-of-the-art\n  Text Mining Tools","summary":"  NLP Workbench is a web-based platform for text mining that allows non-expert\nusers to obtain semantic understanding of large-scale corpora using\nstate-of-the-art text mining models. The platform is built upon latest\npre-trained models and open source systems from academia that provide semantic\nanalysis functionalities, including but not limited to entity linking,\nsentiment analysis, semantic parsing, and relation extraction. Its extensible\ndesign enables researchers and developers to smoothly replace an existing model\nor integrate a new one. To improve efficiency, we employ a microservice\narchitecture that facilitates allocation of acceleration hardware and\nparallelization of computation. This paper presents the architecture of NLP\nWorkbench and discusses the challenges we faced in designing it. We also\ndiscuss diverse use cases of NLP Workbench and the benefits of using it over\nother approaches. The platform is under active development, with its source\ncode released under the MIT license. A website and a short video demonstrating\nour platform are also available.\n","authors":["Peiran Yao","Matej Kosmajac","Abeer Waheed","Kostyantyn Guzhva","Natalie Hervieux","Denilson Barbosa"],"pdf_url":"https://arxiv.org/pdf/2303.01410v1.pdf","comment":"Camera-ready version for EACL 2023: System Demonstrations"},{"id":"http://arxiv.org/abs/2303.01396v1","updated":"2023-03-02T16:26:14Z","published":"2023-03-02T16:26:14Z","title":"MLANet: Multi-Level Attention Network with Sub-instruction for\n  Continuous Vision-and-Language Navigation","summary":"  Vision-and-Language Navigation (VLN) aims to develop intelligent agents to\nnavigate in unseen environments only through language and vision supervision.\nIn the recently proposed continuous settings (continuous VLN), the agent must\nact in a free 3D space and faces tougher challenges like real-time execution,\ncomplex instruction understanding, and long action sequence prediction. For a\nbetter performance in continuous VLN, we design a multi-level instruction\nunderstanding procedure and propose a novel model, Multi-Level Attention\nNetwork (MLANet). The first step of MLANet is to generate sub-instructions\nefficiently. We design a Fast Sub-instruction Algorithm (FSA) to segment the\nraw instruction into sub-instructions and generate a new sub-instruction\ndataset named ``FSASub\". FSA is annotation-free and faster than the current\nmethod by 70 times, thus fitting the real-time requirement in continuous VLN.\nTo solve the complex instruction understanding problem, MLANet needs a global\nperception of the instruction and observations. We propose a Multi-Level\nAttention (MLA) module to fuse vision, low-level semantics, and high-level\nsemantics, which produce features containing a dynamic and global comprehension\nof the task. MLA also mitigates the adverse effects of noise words, thus\nensuring a robust understanding of the instruction. To correctly predict\nactions in long trajectories, MLANet needs to focus on what sub-instruction is\nbeing executed every step. We propose a Peak Attention Loss (PAL) to improve\nthe flexible and adaptive selection of the current sub-instruction. PAL\nbenefits the navigation agent by concentrating its attention on the local\ninformation, thus helping the agent predict the most appropriate actions. We\ntrain and test MLANet in the standard benchmark. Experiment results show MLANet\noutperforms baselines by a significant margin.\n","authors":["Zongtao He","Liuyi Wang","Shu Li","Qingqing Yan","Chengju Liu","Qijun Chen"],"pdf_url":"https://arxiv.org/pdf/2303.01396v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.10314v6","updated":"2023-03-02T15:56:26Z","published":"2021-07-21T19:23:56Z","title":"Small-Text: Active Learning for Text Classification in Python","summary":"  We introduce small-text, an easy-to-use active learning library, which offers\npool-based active learning for single- and multi-label text classification in\nPython. It features numerous pre-implemented state-of-the-art query strategies,\nincluding some that leverage the GPU. Standardized interfaces allow the\ncombination of a variety of classifiers, query strategies, and stopping\ncriteria, facilitating a quick mix and match, and enabling a rapid and\nconvenient development of both active learning experiments and applications.\nWith the objective of making various classifiers and query strategies\naccessible for active learning, small-text integrates several well-known\nmachine learning libraries, namely scikit-learn, PyTorch, and Hugging Face\ntransformers. The latter integrations are optionally installable extensions, so\nGPUs can be used but are not required. Using this new library, we investigate\nthe performance of the recently published SetFit training paradigm, which we\ncompare to vanilla transformer fine-tuning, finding that it matches the latter\nin classification accuracy while outperforming it in area under the curve. The\nlibrary is available under the MIT License at\nhttps://github.com/webis-de/small-text, in version 1.3.0 at the time of\nwriting.\n","authors":["Christopher Schröder","Lydia Müller","Andreas Niekler","Martin Potthast"],"pdf_url":"https://arxiv.org/pdf/2107.10314v6.pdf","comment":"EACL 2023 System Demonstrations (camera-ready)"},{"id":"http://arxiv.org/abs/2208.01575v2","updated":"2023-03-02T15:46:26Z","published":"2022-08-02T16:21:42Z","title":"ferret: a Framework for Benchmarking Explainers on Transformers","summary":"  As Transformers are increasingly relied upon to solve complex NLP problems,\nthere is an increased need for their decisions to be humanly interpretable.\nWhile several explainable AI (XAI) techniques for interpreting the outputs of\ntransformer-based models have been proposed, there is still a lack of easy\naccess to using and comparing them. We introduce ferret, a Python library to\nsimplify the use and comparisons of XAI methods on transformer-based\nclassifiers. With ferret, users can visualize and compare transformers-based\nmodels output explanations using state-of-the-art XAI methods on any free-text\nor existing XAI corpora. Moreover, users can also evaluate ad-hoc XAI metrics\nto select the most faithful and plausible explanations. To align with the\nrecently consolidated process of sharing and using transformers-based models\nfrom Hugging Face, ferret interfaces directly with its Python library. In this\npaper, we showcase ferret to benchmark XAI methods used on transformers for\nsentiment analysis and hate speech detection. We show how specific methods\nprovide consistently better explanations and are preferable in the context of\ntransformer models.\n","authors":["Giuseppe Attanasio","Eliana Pastor","Chiara Di Bonaventura","Debora Nozza"],"pdf_url":"https://arxiv.org/pdf/2208.01575v2.pdf","comment":"11 pages, 3 figures. Accepted to EACL 2023 (System Demonstration).\n  More details at https://github.com/g8a9/ferret"},{"id":"http://arxiv.org/abs/2303.01347v1","updated":"2023-03-02T15:26:46Z","published":"2023-03-02T15:26:46Z","title":"Letz Translate: Low-Resource Machine Translation for Luxembourgish","summary":"  Natural language processing of Low-Resource Languages (LRL) is often\nchallenged by the lack of data. Therefore, achieving accurate machine\ntranslation (MT) in a low-resource environment is a real problem that requires\npractical solutions. Research in multilingual models have shown that some LRLs\ncan be handled with such models. However, their large size and computational\nneeds make their use in constrained environments (e.g., mobile/IoT devices or\nlimited/old servers) impractical. In this paper, we address this problem by\nleveraging the power of large multilingual MT models using knowledge\ndistillation. Knowledge distillation can transfer knowledge from a large and\ncomplex teacher model to a simpler and smaller student model without losing\nmuch in performance. We also make use of high-resource languages that are\nrelated or share the same linguistic root as the target LRL. For our\nevaluation, we consider Luxembourgish as the LRL that shares some roots and\nproperties with German. We build multiple resource-efficient models based on\nGerman, knowledge distillation from the multilingual No Language Left Behind\n(NLLB) model, and pseudo-translation. We find that our efficient models are\nmore than 30\\% faster and perform only 4\\% lower compared to the large\nstate-of-the-art NLLB model.\n","authors":["Yewei Song","Saad Ezzini","Jacques Klein","Tegawende Bissyande","Clément Lefebvre","Anne Goujon"],"pdf_url":"https://arxiv.org/pdf/2303.01347v1.pdf","comment":"The associated model is published on HuggingFace:\n  https://huggingface.co/etamin/Letz-Translate-OPUS-LB-EN The Dictionary used\n  in this paper is available in Github:\n  https://github.com/Etamin/Ltz_dictionary"},{"id":"http://arxiv.org/abs/2303.01341v1","updated":"2023-03-02T15:17:38Z","published":"2023-03-02T15:17:38Z","title":"Matching-based Term Semantics Pre-training for Spoken Patient Query\n  Understanding","summary":"  Medical Slot Filling (MSF) task aims to convert medical queries into\nstructured information, playing an essential role in diagnosis dialogue\nsystems. However, the lack of sufficient term semantics learning makes existing\napproaches hard to capture semantically identical but colloquial expressions of\nterms in medical conversations. In this work, we formalize MSF into a matching\nproblem and propose a Term Semantics Pre-trained Matching Network (TSPMN) that\ntakes both terms and queries as input to model their semantic interaction. To\nlearn term semantics better, we further design two self-supervised objectives,\nincluding Contrastive Term Discrimination (CTD) and Matching-based Mask Term\nModeling (MMTM). CTD determines whether it is the masked term in the dialogue\nfor each given term, while MMTM directly predicts the masked ones. Experimental\nresults on two Chinese benchmarks show that TSPMN outperforms strong baselines,\nespecially in few-shot settings.\n","authors":["Zefa Hu","Xiuyi Chen","Haoran Wu","Minglun Han","Ziyi Ni","Jing Shi","Shuang Xu","Bo Xu"],"pdf_url":"https://arxiv.org/pdf/2303.01341v1.pdf","comment":"ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.10198v2","updated":"2023-03-02T14:33:12Z","published":"2023-02-19T12:29:33Z","title":"Can ChatGPT Understand Too? A Comparative Study on ChatGPT and\n  Fine-tuned BERT","summary":"  Recently, ChatGPT has attracted great attention, as it can generate fluent\nand high-quality responses to human inquiries. Several prior studies have shown\nthat ChatGPT attains remarkable generation ability compared with existing\nmodels. However, the quantitative analysis of ChatGPT's understanding ability\nhas been given little attention. In this report, we explore the understanding\nability of ChatGPT by evaluating it on the most popular GLUE benchmark, and\ncomparing it with 4 representative fine-tuned BERT-style models. We find that:\n1) ChatGPT falls short in handling paraphrase and similarity tasks; 2) ChatGPT\noutperforms all BERT models on inference tasks by a large margin; 3) ChatGPT\nachieves comparable performance compared with BERT on sentiment analysis and\nquestion-answering tasks. Additionally, by combining some advanced prompting\nstrategies, we show that the understanding ability of ChatGPT can be further\nimproved.\n","authors":["Qihuang Zhong","Liang Ding","Juhua Liu","Bo Du","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2302.10198v2.pdf","comment":"Work in progress. Added results of advanced prompting strategies,\n  e.g., CoT. (19 pages)"},{"id":"http://arxiv.org/abs/2302.08957v2","updated":"2023-03-02T14:23:39Z","published":"2023-02-17T15:43:29Z","title":"Like a Good Nearest Neighbor: Practical Content Moderation with Sentence\n  Transformers","summary":"  Modern text classification systems have impressive capabilities but are\ninfeasible to deploy and use reliably due to their dependence on prompting and\nbillion-parameter language models. SetFit (Tunstall et al., 2022) is a recent,\npractical approach that fine-tunes a Sentence Transformer under a contrastive\nlearning paradigm and achieves similar results to more unwieldy systems. Text\nclassification is important for addressing the problem of domain drift in\ndetecting harmful content, which plagues all social media platforms. Here, we\npropose Like a Good Nearest Neighbor (LaGoNN), an inexpensive modification to\nSetFit that requires no additional parameters or hyperparameters but modifies\ninput with information about its nearest neighbor, for example, the label and\ntext, in the training data, making novel data appear similar to an instance on\nwhich the model was optimized. LaGoNN is effective at the task of detecting\nharmful content and generally improves performance compared to SetFit. To\ndemonstrate the value of our system, we conduct a thorough study of text\nclassification systems in the context of content moderation under four label\ndistributions.\n","authors":["Luke Bates","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2302.08957v2.pdf","comment":"8 pages, 4 figures, 13 supplemental pages, 15 supplemental figures"},{"id":"http://arxiv.org/abs/2209.13877v2","updated":"2023-03-02T13:06:10Z","published":"2022-09-28T07:25:04Z","title":"YATO: Yet Another deep learning based Text analysis Open toolkit","summary":"  We introduce YATO, an open-source toolkit for text analysis with deep\nlearning. It focuses on fundamental sequence labeling and sequence\nclassification tasks on text. Designed in a hierarchical structure, YATO\nsupports free combinations of three types of features including 1) traditional\nneural networks (CNN, RNN, etc.); 2) pre-trained language models (BERT,\nRoBERTa, ELECTRA, etc.); and 3) user-customed neural features via a simple\nconfigurable file. Benefiting from the advantages of flexibility and ease of\nuse, YATO can facilitate reproducing and refinement of state-of-the-art NLP\nmodels, and promote the cross-disciplinary applications of NLP techniques.\nSource code, examples, and documentation are publicly available at\nhttps://github.com/jiesutd/YATO. A demo video is also available at\nhttps://youtu.be/tSjjf5BzfQg.\n","authors":["Zeqiang Wang","Yile Wang","Jiageng Wu","Zhiyang Teng","Jie Yang"],"pdf_url":"https://arxiv.org/pdf/2209.13877v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01217v1","updated":"2023-03-02T12:59:01Z","published":"2023-03-02T12:59:01Z","title":"Synthetic Misinformers: Generating and Combating Multimodal\n  Misinformation","summary":"  With the expansion of social media and the increasing dissemination of\nmultimedia content, the spread of misinformation has become a major concern.\nThis necessitates effective strategies for multimodal misinformation detection\n(MMD) that detect whether the combination of an image and its accompanying text\ncould mislead or misinform. Due to the data-intensive nature of deep neural\nnetworks and the labor-intensive process of manual annotation, researchers have\nbeen exploring various methods for automatically generating synthetic\nmultimodal misinformation - which we refer to as Synthetic Misinformers - in\norder to train MMD models. However, limited evaluation on real-world\nmisinformation and a lack of comparisons with other Synthetic Misinformers\nmakes difficult to assess progress in the field. To address this, we perform a\ncomparative study on existing and new Synthetic Misinformers that involves (1)\nout-of-context (OOC) image-caption pairs, (2) cross-modal named entity\ninconsistency (NEI) as well as (3) hybrid approaches and we evaluate them\nagainst real-world misinformation; using the COSMOS benchmark. The comparative\nstudy showed that our proposed CLIP-based Named Entity Swapping can lead to MMD\nmodels that surpass other OOC and NEI Misinformers in terms of multimodal\naccuracy and that hybrid approaches can lead to even higher detection accuracy.\nNevertheless, after alleviating information leakage from the COSMOS evaluation\nprotocol, low Sensitivity scores indicate that the task is significantly more\nchallenging than previous studies suggested. Finally, our findings showed that\nNEI-based Synthetic Misinformers tend to suffer from a unimodal bias, where\ntext-only MMDs can outperform multimodal ones.\n","authors":["Stefanos-Iordanis Papadopoulos","Christos Koutlis","Symeon Papadopoulos","Panagiotis C. Petrantonakis"],"pdf_url":"https://arxiv.org/pdf/2303.01217v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.12502v2","updated":"2023-03-02T12:33:10Z","published":"2022-05-25T05:40:00Z","title":"The Dialog Must Go On: Improving Visual Dialog via Generative\n  Self-Training","summary":"  Visual dialog (VisDial) is a task of answering a sequence of questions\ngrounded in an image, using the dialog history as context. Prior work has\ntrained the dialog agents solely on VisDial data via supervised learning or\nleveraged pre-training on related vision-and-language datasets. This paper\npresents a semi-supervised learning approach for visually-grounded dialog,\ncalled Generative Self-Training (GST), to leverage unlabeled images on the Web.\nSpecifically, GST first retrieves in-domain images through out-of-distribution\ndetection and generates synthetic dialogs regarding the images via multimodal\nconditional text generation. GST then trains a dialog agent on the synthetic\nand the original VisDial data. As a result, GST scales the amount of training\ndata up to an order of magnitude that of VisDial (1.2M to 12.9M QA data). For\nrobust training of the synthetic dialogs, we also propose perplexity-based data\nselection and multimodal consistency regularization. Evaluation on VisDial v1.0\nand v0.9 datasets shows that GST achieves new state-of-the-art results on both\ndatasets. We further observe the robustness of GST against both visual and\ntextual adversarial attacks. Finally, GST yields strong performance gains in\nthe low-data regime. Code is available at\nhttps://github.com/gicheonkang/gst-visdial.\n","authors":["Gi-Cheon Kang","Sungdong Kim","Jin-Hwa Kim","Donghyun Kwak","Byoung-Tak Zhang"],"pdf_url":"https://arxiv.org/pdf/2205.12502v2.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2303.01197v1","updated":"2023-03-02T12:26:03Z","published":"2023-03-02T12:26:03Z","title":"Document Provenance and Authentication through Authorship Classification","summary":"  Style analysis, which is relatively a less explored topic, enables several\ninteresting applications. For instance, it allows authors to adjust their\nwriting style to produce a more coherent document in collaboration. Similarly,\nstyle analysis can also be used for document provenance and authentication as a\nprimary step. In this paper, we propose an ensemble-based text-processing\nframework for the classification of single and multi-authored documents, which\nis one of the key tasks in style analysis. The proposed framework incorporates\nseveral state-of-the-art text classification algorithms including classical\nMachine Learning (ML) algorithms, transformers, and deep learning algorithms\nboth individually and in merit-based late fusion. For the merit-based late\nfusion, we employed several weight optimization and selection methods to assign\nmerit-based weights to the individual text classification algorithms. We also\nanalyze the impact of the characters on the task that are usually excluded in\nNLP applications during pre-processing by conducting experiments on both clean\nand un-clean data. The proposed framework is evaluated on a large-scale\nbenchmark dataset, significantly improving performance over the existing\nsolutions.\n","authors":["Muhammad Tayyab Zamir","Muhammad Asif Ayub","Jebran Khan","Muhammad Jawad Ikram","Nasir Ahmad","Kashif Ahmad"],"pdf_url":"https://arxiv.org/pdf/2303.01197v1.pdf","comment":"7 pages; 3 tables; 1 figure"},{"id":"http://arxiv.org/abs/2303.01194v1","updated":"2023-03-02T12:18:53Z","published":"2023-03-02T12:18:53Z","title":"UZH_CLyp at SemEval-2023 Task 9: Head-First Fine-Tuning and ChatGPT Data\n  Generation for Cross-Lingual Learning in Tweet Intimacy Prediction","summary":"  This paper describes the submission of UZH_CLyp for the SemEval 2023 Task 9\n\"Multilingual Tweet Intimacy Analysis\". We achieved second-best results in all\n10 languages according to the official Pearson's correlation regression\nevaluation measure. Our cross-lingual transfer learning approach explores the\nbenefits of using a Head-First Fine-Tuning method (HeFiT) that first updates\nonly the regression head parameters and then also updates the pre-trained\ntransformer encoder parameters at a reduced learning rate. Additionally, we\nstudy the impact of using a small set of automatically generated examples (in\nour case, from ChatGPT) for low-resource settings where no human-labeled data\nis available. Our study shows that HeFiT stabilizes training and consistently\nimproves results for pre-trained models that lack domain adaptation to tweets.\nOur study also shows a noticeable performance increase in cross-lingual\nlearning when synthetic data is used, confirming the usefulness of current text\ngeneration systems to improve zero-shot baseline results. Finally, we examine\nhow possible inconsistencies in the annotated data contribute to cross-lingual\ninterference issues.\n","authors":["Andrianos Michail","Stefanos Konstantinou","Simon Clematide"],"pdf_url":"https://arxiv.org/pdf/2303.01194v1.pdf","comment":"Submitted for peer-review at SemEval-2023"},{"id":"http://arxiv.org/abs/2303.01191v1","updated":"2023-03-02T12:11:58Z","published":"2023-03-02T12:11:58Z","title":"Denoising-based UNMT is more robust to word-order divergence than\n  MASS-based UNMT","summary":"  We aim to investigate whether UNMT approaches with self-supervised\npre-training are robust to word-order divergence between language pairs. We\nachieve this by comparing two models pre-trained with the same self-supervised\npre-training objective. The first model is trained on language pairs with\ndifferent word-orders, and the second model is trained on the same language\npairs with source language re-ordered to match the word-order of the target\nlanguage. Ideally, UNMT approaches which are robust to word-order divergence\nshould exhibit no visible performance difference between the two\nconfigurations. In this paper, we investigate two such self-supervised\npre-training based UNMT approaches, namely Masked Sequence-to-Sequence\nPre-Training, (MASS) (which does not have shuffling noise) and Denoising\nAutoEncoder (DAE), (which has shuffling noise).\n  We experiment with five English$\\rightarrow$Indic language pairs, i.e.,\nen-hi, en-bn, en-gu, en-kn, and en-ta) where word-order of the source language\nis SVO (Subject-Verb-Object), and the word-order of the target languages is SOV\n(Subject-Object-Verb). We observed that for these language pairs, DAE-based\nUNMT approach consistently outperforms MASS in terms of translation accuracies.\nMoreover, bridging the word-order gap using reordering improves the translation\naccuracy of MASS-based UNMT models, while it cannot improve the translation\naccuracy of DAE-based UNMT models. This observation indicates that DAE-based\nUNMT is more robust to word-order divergence than MASS-based UNMT.\nWord-shuffling noise in DAE approach could be the possible reason for the\napproach being robust to word-order divergence.\n","authors":["Tamali Banerjee","Rudra Murthy V","Pushpak Bhattacharyya"],"pdf_url":"https://arxiv.org/pdf/2303.01191v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.00968v2","updated":"2023-03-02T11:51:48Z","published":"2022-11-02T09:15:20Z","title":"Internal Language Model Estimation based Adaptive Language Model Fusion\n  for Domain Adaptation","summary":"  ASR model deployment environment is ever-changing, and the incoming speech\ncan be switched across different domains during a session. This brings a\nchallenge for effective domain adaptation when only target domain text data is\navailable, and our objective is to obtain obviously improved performance on the\ntarget domain while the performance on the general domain is less undermined.\nIn this paper, we propose an adaptive LM fusion approach called internal\nlanguage model estimation based adaptive domain adaptation (ILME-ADA). To\nrealize such an ILME-ADA, an interpolated log-likelihood score is calculated\nbased on the maximum of the scores from the internal LM and the external LM\n(ELM) respectively. We demonstrate the efficacy of the proposed ILME-ADA method\nwith both RNN-T and LAS modeling frameworks employing neural network and n-gram\nLMs as ELMs respectively on two domain specific (target) test sets. The\nproposed method can achieve significantly better performance on the target test\nsets while it gets minimal performance degradation on the general test set,\ncompared with both shallow and ILME-based LM fusion methods.\n","authors":["Rao Ma","Xiaobo Wu","Jin Qiu","Yanan Qin","Haihua Xu","Peihao Wu","Zejun Ma"],"pdf_url":"https://arxiv.org/pdf/2211.00968v2.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.01094v1","updated":"2023-03-02T09:27:11Z","published":"2023-03-02T09:27:11Z","title":"CTRLStruct: Dialogue Structure Learning for Open-Domain Response\n  Generation","summary":"  Dialogue structure discovery is essential in dialogue generation.\nWell-structured topic flow can leverage background information and predict\nfuture topics to help generate controllable and explainable responses. However,\nmost previous work focused on dialogue structure learning in task-oriented\ndialogue other than open-domain dialogue which is more complicated and\nchallenging. In this paper, we present a new framework CTRLStruct for dialogue\nstructure learning to effectively explore topic-level dialogue clusters as well\nas their transitions with unlabelled information. Precisely, dialogue\nutterances encoded by bi-directional Transformer are further trained through a\nspecial designed contrastive learning task to improve representation. Then we\nperform clustering to utterance-level representations and form topic-level\nclusters that can be considered as vertices in dialogue structure graph. The\nedges in the graph indicating transition probability between vertices are\ncalculated by mimicking expert behavior in datasets. Finally, dialogue\nstructure graph is integrated into dialogue model to perform controlled\nresponse generation. Experiments on two popular open-domain dialogue datasets\nshow our model can generate more coherent responses compared to some excellent\ndialogue models, as well as outperform some typical sentence embedding methods\nin dialogue utterance representation. Code is available in GitHub.\n","authors":["Congchi Yin","Piji Li","Zhaochun Ren"],"pdf_url":"https://arxiv.org/pdf/2303.01094v1.pdf","comment":"12 pages, to be published in The Web Conference 2023"},{"id":"http://arxiv.org/abs/2205.12523v2","updated":"2023-03-02T09:17:01Z","published":"2022-05-25T06:34:14Z","title":"TranSpeech: Speech-to-Speech Translation With Bilateral Perturbation","summary":"  Direct speech-to-speech translation (S2ST) with discrete units leverages\nrecent progress in speech representation learning. Specifically, a sequence of\ndiscrete representations derived in a self-supervised manner are predicted from\nthe model and passed to a vocoder for speech reconstruction, while still facing\nthe following challenges: 1) Acoustic multimodality: the discrete units derived\nfrom speech with same content could be indeterministic due to the acoustic\nproperty (e.g., rhythm, pitch, and energy), which causes deterioration of\ntranslation accuracy; 2) high latency: current S2ST systems utilize\nautoregressive models which predict each unit conditioned on the sequence\npreviously generated, failing to take full advantage of parallelism. In this\nwork, we propose TranSpeech, a speech-to-speech translation model with\nbilateral perturbation. To alleviate the acoustic multimodal problem, we\npropose bilateral perturbation (BiP), which consists of the style normalization\nand information enhancement stages, to learn only the linguistic information\nfrom speech samples and generate more deterministic representations. With\nreduced multimodality, we step forward and become the first to establish a\nnon-autoregressive S2ST technique, which repeatedly masks and predicts unit\nchoices and produces high-accuracy results in just a few cycles. Experimental\nresults on three language pairs demonstrate that BiP yields an improvement of\n2.9 BLEU on average compared with a baseline textless S2ST model. Moreover, our\nparallel decoding shows a significant reduction of inference latency, enabling\nspeedup up to 21.4x than autoregressive technique. Audio samples are available\nat \\url{https://TranSpeech.github.io/}\n","authors":["Rongjie Huang","Jinglin Liu","Huadai Liu","Yi Ren","Lichao Zhang","Jinzheng He","Zhou Zhao"],"pdf_url":"https://arxiv.org/pdf/2205.12523v2.pdf","comment":"Accpeted to ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01086v1","updated":"2023-03-02T09:16:21Z","published":"2023-03-02T09:16:21Z","title":"LiteG2P: A fast, light and high accuracy model for grapheme-to-phoneme\n  conversion","summary":"  As a key component of automated speech recognition (ASR) and the front-end in\ntext-to-speech (TTS), grapheme-to-phoneme (G2P) plays the role of converting\nletters to their corresponding pronunciations. Existing methods are either slow\nor poor in performance, and are limited in application scenarios, particularly\nin the process of on-device inference. In this paper, we integrate the\nadvantages of both expert knowledge and connectionist temporal classification\n(CTC) based neural network and propose a novel method named LiteG2P which is\nfast, light and theoretically parallel. With the carefully leading design,\nLiteG2P can be applied both on cloud and on device. Experimental results on the\nCMU dataset show that the performance of the proposed method is superior to the\nstate-of-the-art CTC based method with 10 times fewer parameters, and even\ncomparable to the state-of-the-art Transformer-based sequence-to-sequence model\nwith less parameters and 33 times less computation.\n","authors":["Chunfeng Wang","Peisong Huang","Yuxiang Zou","Haoyu Zhang","Shichao Liu","Xiang Yin","Zejun Ma"],"pdf_url":"https://arxiv.org/pdf/2303.01086v1.pdf","comment":"Accepted by ICASSP2023"},{"id":"http://arxiv.org/abs/2206.04624v3","updated":"2023-03-02T09:11:34Z","published":"2022-06-09T17:16:43Z","title":"Factuality Enhanced Language Models for Open-Ended Text Generation","summary":"  Pretrained language models (LMs) are susceptible to generate text with\nnonfactual information. In this work, we measure and improve the factual\naccuracy of large-scale LMs for open-ended text generation. We design the\nFactualityPrompts test set and metrics to measure the factuality of LM\ngenerations. Based on that, we study the factual accuracy of LMs with parameter\nsizes ranging from 126M to 530B. Interestingly, we find that larger LMs are\nmore factual than smaller ones, although a previous study suggests that larger\nLMs can be less truthful in terms of misconceptions. In addition, popular\nsampling algorithms (e.g., top-p) in open-ended text generation can harm the\nfactuality due to the ''uniform randomness'' introduced at every sampling step.\nWe propose the factual-nucleus sampling algorithm that dynamically adapts the\nrandomness to improve the factuality of generation while maintaining quality.\nFurthermore, we analyze the inefficiencies of the standard training method in\nlearning correct associations between entities from factual text corpus (e.g.,\nWikipedia). We propose a factuality-enhanced training method that uses\nTopicPrefix for better awareness of facts and sentence completion as the\ntraining objective, which can vastly reduce the factual errors. We release our\ncode and FactualityPrompts benchmark at:\nhttps://github.com/nayeon7lee/FactualityPrompt.\n","authors":["Nayeon Lee","Wei Ping","Peng Xu","Mostofa Patwary","Pascale Fung","Mohammad Shoeybi","Bryan Catanzaro"],"pdf_url":"https://arxiv.org/pdf/2206.04624v3.pdf","comment":"NeurIPS 2022"},{"id":"http://arxiv.org/abs/2210.05193v2","updated":"2023-03-02T09:04:57Z","published":"2022-10-11T06:53:34Z","title":"Viterbi Decoding of Directed Acyclic Transformer for Non-Autoregressive\n  Machine Translation","summary":"  Non-autoregressive models achieve significant decoding speedup in neural\nmachine translation but lack the ability to capture sequential dependency.\nDirected Acyclic Transformer (DA-Transformer) was recently proposed to model\nsequential dependency with a directed acyclic graph. Consequently, it has to\napply a sequential decision process at inference time, which harms the global\ntranslation accuracy. In this paper, we present a Viterbi decoding framework\nfor DA-Transformer, which guarantees to find the joint optimal solution for the\ntranslation and decoding path under any length constraint. Experimental results\ndemonstrate that our approach consistently improves the performance of\nDA-Transformer while maintaining a similar decoding speedup.\n","authors":["Chenze Shao","Zhengrui Ma","Yang Feng"],"pdf_url":"https://arxiv.org/pdf/2210.05193v2.pdf","comment":"Findings of EMNLP 2022"},{"id":"http://arxiv.org/abs/2303.01081v1","updated":"2023-03-02T09:03:43Z","published":"2023-03-02T09:03:43Z","title":"Can BERT Refrain from Forgetting on Sequential Tasks? A Probing Study","summary":"  Large pre-trained language models help to achieve state of the art on a\nvariety of natural language processing (NLP) tasks, nevertheless, they still\nsuffer from forgetting when incrementally learning a sequence of tasks. To\nalleviate this problem, recent works enhance existing models by sparse\nexperience replay and local adaption, which yield satisfactory performance.\nHowever, in this paper we find that pre-trained language models like BERT have\na potential ability to learn sequentially, even without any sparse memory\nreplay. To verify the ability of BERT to maintain old knowledge, we adopt and\nre-finetune single-layer probe networks with the parameters of BERT fixed. We\ninvestigate the models on two types of NLP tasks, text classification and\nextractive question answering. Our experiments reveal that BERT can actually\ngenerate high quality representations for previously learned tasks in a long\nterm, under extremely sparse replay or even no replay. We further introduce a\nseries of novel methods to interpret the mechanism of forgetting and how memory\nrehearsal plays a significant role in task incremental learning, which bridges\nthe gap between our new discovery and previous studies about catastrophic\nforgetting.\n","authors":["Mingxu Tao","Yansong Feng","Dongyan Zhao"],"pdf_url":"https://arxiv.org/pdf/2303.01081v1.pdf","comment":"Accepted by ICLR 2023. URL:\n  https://openreview.net/forum?id=UazgYBMS9-W"},{"id":"http://arxiv.org/abs/2303.01080v1","updated":"2023-03-02T09:03:11Z","published":"2023-03-02T09:03:11Z","title":"LANDMARK: Language-guided Representation Enhancement Framework for Scene\n  Graph Generation","summary":"  Scene graph generation (SGG) is a sophisticated task that suffers from both\ncomplex visual features and dataset long-tail problem. Recently, various\nunbiased strategies have been proposed by designing novel loss functions and\ndata balancing strategies. Unfortunately, these unbiased methods fail to\nemphasize language priors in feature refinement perspective. Inspired by the\nfact that predicates are highly correlated with semantics hidden in\nsubject-object pair and global context, we propose LANDMARK (LANguage-guiDed\nrepresentationenhanceMent frAmewoRK) that learns predicate-relevant\nrepresentations from language-vision interactive patterns, global language\ncontext and pair-predicate correlation. Specifically, we first project object\nlabels to three distinctive semantic embeddings for different representation\nlearning. Then, Language Attention Module (LAM) and Experience Estimation\nModule (EEM) process subject-object word embeddings to attention vector and\npredicate distribution, respectively. Language Context Module (LCM) encodes\nglobal context from each word embed-ding, which avoids isolated learning from\nlocal information. Finally, modules outputs are used to update visual\nrepresentations and SGG model's prediction. All language representations are\npurely generated from object categories so that no extra knowledge is needed.\nThis framework is model-agnostic and consistently improves performance on\nexisting SGG models. Besides, representation-level unbiased strategies endow\nLANDMARK the advantage of compatibility with other methods. Code is available\nat https://github.com/rafa-cxg/PySGG-cxg.\n","authors":["Xiaoguang Chang","Teng Wang","Shaowei Cai","Changyin Sun"],"pdf_url":"https://arxiv.org/pdf/2303.01080v1.pdf","comment":"Revision period in Applied Intelligence (APIN)"},{"id":"http://arxiv.org/abs/2303.01068v1","updated":"2023-03-02T08:43:30Z","published":"2023-03-02T08:43:30Z","title":"Targeted Adversarial Attacks against Neural Machine Translation","summary":"  Neural Machine Translation (NMT) systems are used in various applications.\nHowever, it has been shown that they are vulnerable to very small perturbations\nof their inputs, known as adversarial attacks. In this paper, we propose a new\ntargeted adversarial attack against NMT models. In particular, our goal is to\ninsert a predefined target keyword into the translation of the adversarial\nsentence while maintaining similarity between the original sentence and the\nperturbed one in the source domain. To this aim, we propose an optimization\nproblem, including an adversarial loss term and a similarity term. We use\ngradient projection in the embedding space to craft an adversarial sentence.\nExperimental results show that our attack outperforms Seq2Sick, the other\ntargeted adversarial attack against NMT models, in terms of success rate and\ndecrease in translation quality. Our attack succeeds in inserting a keyword\ninto the translation for more than 75% of sentences while similarity with the\noriginal sentence stays preserved.\n","authors":["Sahar Sadrizadeh","AmirHossein Dabiri Aghdam","Ljiljana Dolamic","Pascal Frossard"],"pdf_url":"https://arxiv.org/pdf/2303.01068v1.pdf","comment":"ICASSP 2023, Code available at:\n  http://github.com/sssadrizadeh/NMT-targeted-attack"},{"id":"http://arxiv.org/abs/2303.01064v1","updated":"2023-03-02T08:40:31Z","published":"2023-03-02T08:40:31Z","title":"Adopting the Multi-answer Questioning Task with an Auxiliary Metric for\n  Extreme Multi-label Text Classification Utilizing the Label Hierarchy","summary":"  Extreme multi-label text classification utilizes the label hierarchy to\npartition extreme labels into multiple label groups, turning the task into\nsimple multi-group multi-label classification tasks. Current research encodes\nlabels as a vector with fixed length which needs establish multiple classifiers\nfor different label groups. The problem is how to build only one classifier\nwithout sacrificing the label relationship in the hierarchy. This paper adopts\nthe multi-answer questioning task for extreme multi-label classification. This\npaper also proposes an auxiliary classification evaluation metric. This study\nadopts the proposed method and the evaluation metric to the legal domain. The\nutilization of legal Berts and the study on task distribution are discussed.\nThe experiment results show that the proposed hierarchy and multi-answer\nquestioning task can do extreme multi-label classification for EURLEX dataset.\nAnd in minor/fine-tuning the multi-label classification task, the domain\nadapted BERT models could not show apparent advantages in this experiment. The\nmethod is also theoretically applicable to zero-shot learning.\n","authors":["Li Wang","Ying Wah Teh","Mohammed Ali Al-Garadi"],"pdf_url":"https://arxiv.org/pdf/2303.01064v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12095v3","updated":"2023-03-02T08:33:04Z","published":"2023-02-22T11:01:20Z","title":"On the Robustness of ChatGPT: An Adversarial and Out-of-distribution\n  Perspective","summary":"  ChatGPT is a recent chatbot service released by OpenAI and is receiving\nincreasing attention over the past few months. While evaluations of various\naspects of ChatGPT have been done, its robustness, i.e., the performance to\nunexpected inputs, is still unclear to the public. Robustness is of particular\nconcern in responsible AI, especially for safety-critical applications. In this\npaper, we conduct a thorough evaluation of the robustness of ChatGPT from the\nadversarial and out-of-distribution (OOD) perspective. To do so, we employ the\nAdvGLUE and ANLI benchmarks to assess adversarial robustness and the Flipkart\nreview and DDXPlus medical diagnosis datasets for OOD evaluation. We select\nseveral popular foundation models as baselines. Results show that ChatGPT shows\nconsistent advantages on most adversarial and OOD classification and\ntranslation tasks. However, the absolute performance is far from perfection,\nwhich suggests that adversarial and OOD robustness remains a significant threat\nto foundation models. Moreover, ChatGPT shows astounding performance in\nunderstanding dialogue-related texts and we find that it tends to provide\ninformal suggestions for medical tasks instead of definitive answers. Finally,\nwe present in-depth discussions of possible research directions.\n","authors":["Jindong Wang","Xixu Hu","Wenxin Hou","Hao Chen","Runkai Zheng","Yidong Wang","Linyi Yang","Haojun Huang","Wei Ye","Xiubo Geng","Binxin Jiao","Yue Zhang","Xing Xie"],"pdf_url":"https://arxiv.org/pdf/2302.12095v3.pdf","comment":"Technical report; code is at:\n  https://github.com/microsoft/robustlearn"},{"id":"http://arxiv.org/abs/2303.01037v1","updated":"2023-03-02T07:47:18Z","published":"2023-03-02T07:47:18Z","title":"Google USM: Scaling Automatic Speech Recognition Beyond 100 Languages","summary":"  We introduce the Universal Speech Model (USM), a single large model that\nperforms automatic speech recognition (ASR) across 100+ languages. This is\nachieved by pre-training the encoder of the model on a large unlabeled\nmultilingual dataset of 12 million (M) hours spanning over 300 languages, and\nfine-tuning on a smaller labeled dataset. We use multilingual pre-training with\nrandom-projection quantization and speech-text modality matching to achieve\nstate-of-the-art performance on downstream multilingual ASR and speech-to-text\ntranslation tasks. We also demonstrate that despite using a labeled training\nset 1/7-th the size of that used for the Whisper model, our model exhibits\ncomparable or better performance on both in-domain and out-of-domain speech\nrecognition tasks across many languages.\n","authors":["Yu Zhang","Wei Han","James Qin","Yongqiang Wang","Ankur Bapna","Zhehuai Chen","Nanxin Chen","Bo Li","Vera Axelrod","Gary Wang","Zhong Meng","Ke Hu","Andrew Rosenberg","Rohit Prabhavalkar","Daniel S. Park","Parisa Haghani","Jason Riesa","Ginger Perng","Hagen Soltau","Trevor Strohman","Bhuvana Ramabhadran","Tara Sainath","Pedro Moreno","Chung-Cheng Chiu","Johan Schalkwyk","Françoise Beaufays","Yonghui Wu"],"pdf_url":"https://arxiv.org/pdf/2303.01037v1.pdf","comment":"20 pages, 7 figures, 8 tables"},{"id":"http://arxiv.org/abs/2209.14610v3","updated":"2023-03-02T07:41:55Z","published":"2022-09-29T08:01:04Z","title":"Dynamic Prompt Learning via Policy Gradient for Semi-structured\n  Mathematical Reasoning","summary":"  Mathematical reasoning, a core ability of human intelligence, presents unique\nchallenges for machines in abstract thinking and logical reasoning. Recent\nlarge pre-trained language models such as GPT-3 have achieved remarkable\nprogress on mathematical reasoning tasks written in text form, such as math\nword problems (MWP). However, it is unknown if the models can handle more\ncomplex problems that involve math reasoning over heterogeneous information,\nsuch as tabular data. To fill the gap, we present Tabular Math Word Problems\n(TabMWP), a new dataset containing 38,431 open-domain grade-level problems that\nrequire mathematical reasoning on both textual and tabular data. Each question\nin TabMWP is aligned with a tabular context, which is presented as an image,\nsemi-structured text, and a structured table. There are two types of questions:\nfree-text and multi-choice, and each problem is annotated with gold solutions\nto reveal the multi-step reasoning process. We evaluate different pre-trained\nmodels on TabMWP, including the GPT-3 model in a few-shot setting. As earlier\nstudies suggest, since few-shot GPT-3 relies on the selection of in-context\nexamples, its performance is unstable and can degrade to near chance. The\nunstable issue is more severe when handling complex problems like TabMWP. To\nmitigate this, we further propose a novel approach, PromptPG, which utilizes\npolicy gradient to learn to select in-context examples from a small amount of\ntraining data and then constructs the corresponding prompt for the test\nexample. Experimental results show that our method outperforms the best\nbaseline by 5.31% on the accuracy metric and reduces the prediction variance\nsignificantly compared to random selection, which verifies its effectiveness in\nselecting in-context examples.\n","authors":["Pan Lu","Liang Qiu","Kai-Wei Chang","Ying Nian Wu","Song-Chun Zhu","Tanmay Rajpurohit","Peter Clark","Ashwin Kalyan"],"pdf_url":"https://arxiv.org/pdf/2209.14610v3.pdf","comment":"ICLR 2023. 26 pages and 18 figures. The data and code are available\n  at https://promptpg.github.io"},{"id":"http://arxiv.org/abs/2208.01174v2","updated":"2023-03-02T06:11:49Z","published":"2022-08-01T23:43:48Z","title":"TextWorldExpress: Simulating Text Games at One Million Steps Per Second","summary":"  Text-based games offer a challenging test bed to evaluate virtual agents at\nlanguage understanding, multi-step problem-solving, and common-sense reasoning.\nHowever, speed is a major limitation of current text-based games, capping at\n300 steps per second, mainly due to the use of legacy tooling. In this work we\npresent TextWorldExpress, a high-performance simulator that includes\nimplementations of three common text game benchmarks that increases simulation\nthroughput by approximately three orders of magnitude, reaching over one\nmillion steps per second on common desktop hardware. This significantly reduces\nexperiment runtime, enabling billion-step-scale experiments in about one day.\n","authors":["Peter A. Jansen","Marc-Alexandre Côté"],"pdf_url":"https://arxiv.org/pdf/2208.01174v2.pdf","comment":"Accepted to EACL 2023"},{"id":"http://arxiv.org/abs/2303.00978v1","updated":"2023-03-02T05:19:49Z","published":"2023-03-02T05:19:49Z","title":"Leveraging Large Text Corpora for End-to-End Speech Summarization","summary":"  End-to-end speech summarization (E2E SSum) is a technique to directly\ngenerate summary sentences from speech. Compared with the cascade approach,\nwhich combines automatic speech recognition (ASR) and text summarization\nmodels, the E2E approach is more promising because it mitigates ASR errors,\nincorporates nonverbal information, and simplifies the overall system. However,\nsince collecting a large amount of paired data (i.e., speech and summary) is\ndifficult, the training data is usually insufficient to train a robust E2E SSum\nsystem. In this paper, we present two novel methods that leverage a large\namount of external text summarization data for E2E SSum training. The first\ntechnique is to utilize a text-to-speech (TTS) system to generate synthesized\nspeech, which is used for E2E SSum training with the text summary. The second\nis a TTS-free method that directly inputs phoneme sequence instead of\nsynthesized speech to the E2E SSum model. Experiments show that our proposed\nTTS- and phoneme-based methods improve several metrics on the How2 dataset. In\nparticular, our best system outperforms a previous state-of-the-art one by a\nlarge margin (i.e., METEOR score improvements of more than 6 points). To the\nbest of our knowledge, this is the first work to use external language\nresources for E2E SSum. Moreover, we report a detailed analysis of the How2\ndataset to confirm the validity of our proposed E2E SSum system.\n","authors":["Kohei Matsuura","Takanori Ashihara","Takafumi Moriya","Tomohiro Tanaka","Atsunori Ogawa","Marc Delcroix","Ryo Masumura"],"pdf_url":"https://arxiv.org/pdf/2303.00978v1.pdf","comment":"Accepted to ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.00969v1","updated":"2023-03-02T05:06:44Z","published":"2023-03-02T05:06:44Z","title":"Rethinking the Reasonability of the Test Set for Simultaneous Machine\n  Translation","summary":"  Simultaneous machine translation (SimulMT) models start translation before\nthe end of the source sentence, making the translation monotonically aligned\nwith the source sentence. However, the general full-sentence translation test\nset is acquired by offline translation of the entire source sentence, which is\nnot designed for SimulMT evaluation, making us rethink whether this will\nunderestimate the performance of SimulMT models. In this paper, we manually\nannotate a monotonic test set based on the MuST-C English-Chinese test set,\ndenoted as SiMuST-C. Our human evaluation confirms the acceptability of our\nannotated test set. Evaluations on three different SimulMT models verify that\nthe underestimation problem can be alleviated on our test set. Further\nexperiments show that finetuning on an automatically extracted monotonic\ntraining set improves SimulMT models by up to 3 BLEU points.\n","authors":["Mengge Liu","Wen Zhang","Xiang Li","Jian Luan","Bin Wang","Yuhang Guo","Shuoying Chen"],"pdf_url":"https://arxiv.org/pdf/2303.00969v1.pdf","comment":"Accepted by 48th IEEE International Conference on Acoustics, Speech,\n  and Signal Processing (ICASSP 2023)"},{"id":"http://arxiv.org/abs/2210.01240v4","updated":"2023-03-02T03:54:28Z","published":"2022-10-03T21:34:32Z","title":"Language Models Are Greedy Reasoners: A Systematic Formal Analysis of\n  Chain-of-Thought","summary":"  Large language models (LLMs) have shown remarkable reasoning capabilities\ngiven chain-of-thought prompts (examples with intermediate reasoning steps).\nExisting benchmarks measure reasoning ability indirectly, by evaluating\naccuracy on downstream tasks such as mathematical reasoning. However, it is\nunclear how these models obtain the answers and whether they rely on simple\nheuristics rather than the generated chain-of-thought. To enable systematic\nexploration of the reasoning ability of LLMs, we present a new synthetic\nquestion-answering dataset called PrOntoQA, where each example is generated\nfrom a synthetic world model represented in first-order logic. This allows us\nto parse the generated chain-of-thought into symbolic proofs for formal\nanalysis. Our analysis on InstructGPT and GPT-3 shows that LLMs are quite\ncapable of making correct individual deduction steps, and so are generally\ncapable of reasoning, even in fictional contexts. However, they have difficulty\nwith proof planning: When multiple valid deduction steps are available, they\nare not able to systematically explore the different options.\n","authors":["Abulhair Saparov","He He"],"pdf_url":"https://arxiv.org/pdf/2210.01240v4.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.00915v1","updated":"2023-03-02T02:20:04Z","published":"2023-03-02T02:20:04Z","title":"Large-Scale Domain-Specific Pretraining for Biomedical Vision-Language\n  Processing","summary":"  Contrastive pretraining on parallel image-text data has attained great\nsuccess in vision-language processing (VLP), as exemplified by CLIP and related\nmethods. However, prior explorations tend to focus on general domains in the\nweb. Biomedical images and text are rather different, but publicly available\ndatasets are small and skew toward chest X-ray, thus severely limiting\nprogress. In this paper, we conducted by far the largest study on biomedical\nVLP, using 15 million figure-caption pairs extracted from biomedical research\narticles in PubMed Central. Our dataset (PMC-15M) is two orders of magnitude\nlarger than existing biomedical image-text datasets such as MIMIC-CXR, and\nspans a diverse range of biomedical images. The standard CLIP method is\nsuboptimal for the biomedical domain. We propose BiomedCLIP with\ndomain-specific adaptations tailored to biomedical VLP. We conducted extensive\nexperiments and ablation studies on standard biomedical imaging tasks from\nretrieval to classification to visual question-answering (VQA). BiomedCLIP\nestablished new state of the art in a wide range of standard datasets,\nsubstantially outperformed prior VLP approaches. Surprisingly, BiomedCLIP even\noutperformed radiology-specific state-of-the-art models such as BioViL on\nradiology-specific tasks such as RSNA pneumonia detection, thus highlighting\nthe utility in large-scale pretraining across all biomedical image types. We\nwill release our models at https://aka.ms/biomedclip to facilitate future\nresearch in biomedical VLP.\n","authors":["Sheng Zhang","Yanbo Xu","Naoto Usuyama","Jaspreet Bagga","Robert Tinn","Sam Preston","Rajesh Rao","Mu Wei","Naveen Valluri","Cliff Wong","Matthew P. Lungren","Tristan Naumann","Hoifung Poon"],"pdf_url":"https://arxiv.org/pdf/2303.00915v1.pdf","comment":"The models will be released soon at https://aka.ms/biomedclip"},{"id":"http://arxiv.org/abs/2303.00908v1","updated":"2023-03-02T01:57:17Z","published":"2023-03-02T01:57:17Z","title":"Interactive Text Generation","summary":"  Users interact with text, image, code, or other editors on a daily basis.\nHowever, machine learning models are rarely trained in the settings that\nreflect the interactivity between users and their editor. This is\nunderstandable as training AI models with real users is not only slow and\ncostly, but what these models learn may be specific to user interface design\nchoices. Unfortunately, this means most of the research on text, code, and\nimage generation has focused on non-interactive settings, whereby the model is\nexpected to get everything right without accounting for any input from a user\nwho may be willing to help.\n  We introduce a new Interactive Text Generation task that allows training\ngeneration models interactively without the costs of involving real users, by\nusing user simulators that provide edits that guide the model towards a given\ntarget text. We train our interactive models using Imitation Learning, and our\nexperiments against competitive non-interactive generation models show that\nmodels trained interactively are superior to their non-interactive\ncounterparts, even when all models are given the same budget of user inputs or\nedits.\n","authors":["Felix Faltings","Michel Galley","Baolin Peng","Kianté Brantley","Weixin Cai","Yizhe Zhang","Jianfeng Gao","Bill Dolan"],"pdf_url":"https://arxiv.org/pdf/2303.00908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.05423v4","updated":"2023-03-02T01:52:48Z","published":"2022-10-11T13:04:59Z","title":"Learning to Locate Visual Answer in Video Corpus Using Question","summary":"  We introduce a new task, named video corpus visual answer localization\n(VCVAL), which aims to locate the visual answer in a large collection of\nuntrimmed instructional videos using a natural language question. This task\nrequires a range of skills - the interaction between vision and language, video\nretrieval, passage comprehension, and visual answer localization. In this\npaper, we propose a cross-modal contrastive global-span (CCGS) method for the\nVCVAL, jointly training the video corpus retrieval and visual answer\nlocalization subtasks with the global-span matrix. We have reconstructed a\ndataset named MedVidCQA, on which the VCVAL task is benchmarked. Experimental\nresults show that the proposed method outperforms other competitive methods\nboth in the video corpus retrieval and visual answer localization subtasks.\nMost importantly, we perform detailed analyses on extensive experiments, paving\na new path for understanding the instructional videos, which ushers in further\nresearch.\n","authors":["Bin Li","Yixuan Weng","Bin Sun","Shutao Li"],"pdf_url":"https://arxiv.org/pdf/2210.05423v4.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2205.12636v2","updated":"2023-03-02T01:49:09Z","published":"2022-05-25T10:22:14Z","title":"A Zipf's Law-Driven Method for Extracting Entities from Documents","summary":"  Entity extraction is critical to the intelligent development of various\ndomains and the construction of knowledge agents. Yet, there is category\nimbalance problem in documents in some specific domains that some categories of\nentities are common, while some are rare and scattered. This paper proposes to\nuse Zipf's law to tackle this problem and to promote the performance of entity\nextraction from documents. Using two forms of Zipf's law, words in the\ndocuments are classified into common and rare ones, and then sentences are\nclassified into common and rare ones, and are further processed by text\ngeneration models respectively. Rare entities in the generated sentences are\nlabeled with human-designed rules, and serve as a supplement to the raw dataset\nso as to alleviate the category imbalance problem. A case of extracting\nentities from technical documents on industrial safety is given and the\nexperiments results on two datasets show the effectiveness of the proposed\nmethod.\n","authors":["Zhenhua Wang","Ming Ren","Dong Gao","Zhuang Li"],"pdf_url":"https://arxiv.org/pdf/2205.12636v2.pdf","comment":"Journal of Informetrics"},{"id":"http://arxiv.org/abs/2303.00897v1","updated":"2023-03-02T01:39:16Z","published":"2023-03-02T01:39:16Z","title":"Stochastic Clustered Federated Learning","summary":"  Federated learning is a distributed learning framework that takes full\nadvantage of private data samples kept on edge devices. In real-world federated\nlearning systems, these data samples are often decentralized and\nNon-Independently Identically Distributed (Non-IID), causing divergence and\nperformance degradation in the federated learning process. As a new solution,\nclustered federated learning groups federated clients with similar data\ndistributions to impair the Non-IID effects and train a better model for every\ncluster. This paper proposes StoCFL, a novel clustered federated learning\napproach for generic Non-IID issues. In detail, StoCFL implements a flexible\nCFL framework that supports an arbitrary proportion of client participation and\nnewly joined clients for a varying FL system, while maintaining a great\nimprovement in model performance. The intensive experiments are conducted by\nusing four basic Non-IID settings and a real-world dataset. The results show\nthat StoCFL could obtain promising cluster results even when the number of\nclusters is unknown. Based on the client clustering results, models trained\nwith StoCFL outperform baseline approaches in a variety of contexts.\n","authors":["Dun Zeng","Xiangjing Hu","Shiyu Liu","Yue Yu","Qifan Wang","Zenglin Xu"],"pdf_url":"https://arxiv.org/pdf/2303.00897v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.15162v2","updated":"2023-03-02T23:54:47Z","published":"2022-09-30T01:17:18Z","title":"Linearly Mapping from Image to Text Space","summary":"  The extent to which text-only language models (LMs) learn to represent\nfeatures of the non-linguistic world is an open question. Prior work has shown\nthat pretrained LMs can be taught to caption images when a vision model's\nparameters are optimized to encode images in the language space. We test a\nstronger hypothesis: that the conceptual representations learned by frozen\ntext-only models and vision-only models are similar enough that this can be\nachieved with a linear map. We show that the image representations from vision\nmodels can be transferred as continuous prompts to frozen LMs by training only\na single linear projection. Using these to prompt the LM achieves competitive\nperformance on captioning and visual question answering tasks compared to\nmodels that tune both the image encoder and text decoder (such as the MAGMA\nmodel). We compare three image encoders with increasing amounts of linguistic\nsupervision seen during pretraining: BEIT (no linguistic information),\nNF-ResNET (lexical category information), and CLIP (full natural language\ndescriptions). We find that all three encoders perform equally well at\ntransferring visual property information to the language model (e.g., whether\nan animal is large or small), but that image encoders pretrained with\nlinguistic supervision more saliently encode category information (e.g.,\ndistinguishing hippo vs. elephant) and thus perform significantly better on\nbenchmark language-and-vision tasks. Our results indicate that LMs encode\nconceptual information structurally similarly to vision-based models, even\nthose that are solely trained on images. Code is available here:\nhttps://github.com/jmerullo/limber\n","authors":["Jack Merullo","Louis Castricato","Carsten Eickhoff","Ellie Pavlick"],"pdf_url":"https://arxiv.org/pdf/2209.15162v2.pdf","comment":"Accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2302.12692v3","updated":"2023-03-02T23:52:00Z","published":"2023-02-24T15:35:36Z","title":"Language Models are Few-shot Learners for Prognostic Prediction","summary":"  Clinical prediction is an essential task in the healthcare industry. However,\nthe recent success of transformers, on which large language models are built,\nhas not been extended to this domain. In this research, we explore the use of\ntransformers and language models in prognostic prediction for immunotherapy\nusing real-world patients' clinical data and molecular profiles. This paper\ninvestigates the potential of transformers to improve clinical prediction\ncompared to conventional machine learning approaches and addresses the\nchallenge of few-shot learning in predicting rare disease areas. The study\nbenchmarks the efficacy of baselines and language models on prognostic\nprediction across multiple cancer types and investigates the impact of\ndifferent pretrained language models under few-shot regimes. The results\ndemonstrate significant improvements in accuracy and highlight the potential of\nNLP in clinical research to improve early detection and intervention for\ndifferent diseases.\n","authors":["Z. Chen","M. M. Balan","K. Brown"],"pdf_url":"https://arxiv.org/pdf/2302.12692v3.pdf","comment":"7 pages, 5 figures, 5 tables"},{"id":"http://arxiv.org/abs/2204.03972v3","updated":"2023-03-02T23:13:14Z","published":"2022-04-08T10:01:39Z","title":"FashionCLIP: Connecting Language and Images for Product Representations","summary":"  The steady rise of online shopping goes hand in hand with the development of\nincreasingly complex ML and NLP models. While most use cases are cast as\nspecialized supervised learning problems, we argue that practitioners would\ngreatly benefit from more transferable representations of products. In this\nwork, we build on recent developments in contrastive learning to train\nFashionCLIP, a CLIP-like model for the fashion industry. We showcase its\ncapabilities for retrieval, classification and grounding, and release our model\nand code to the community.\n","authors":["Patrick John Chia","Giuseppe Attanasio","Federico Bianchi","Silvia Terragni","Ana Rita Magalhães","Diogo Goncalves","Ciro Greco","Jacopo Tagliabue"],"pdf_url":"https://arxiv.org/pdf/2204.03972v3.pdf","comment":"Model available at\n  https://huggingface.co/patrickjohncyh/fashion-clip, dataset at\n  https://github.com/Farfetch"},{"id":"http://arxiv.org/abs/2303.01593v1","updated":"2023-03-02T21:35:15Z","published":"2023-03-02T21:35:15Z","title":"QAID: Question Answering Inspired Few-shot Intent Detection","summary":"  Intent detection with semantically similar fine-grained intents is a\nchallenging task. To address it, we reformulate intent detection as a\nquestion-answering retrieval task by treating utterances and intent names as\nquestions and answers. To that end, we utilize a question-answering retrieval\narchitecture and adopt a two stages training schema with batch contrastive\nloss. In the pre-training stage, we improve query representations through\nself-supervised training. Then, in the fine-tuning stage, we increase\ncontextualized token-level similarity scores between queries and answers from\nthe same intent. Our results on three few-shot intent detection benchmarks\nachieve state-of-the-art performance.\n","authors":["Asaf Yehudai","Matan Vetzler","Yosi Mass","Koren Lazar","Doron Cohen","Boaz Carmeli"],"pdf_url":"https://arxiv.org/pdf/2303.01593v1.pdf","comment":"ICLR paper"},{"id":"http://arxiv.org/abs/2303.01590v1","updated":"2023-03-02T21:27:54Z","published":"2023-03-02T21:27:54Z","title":"Technical report: Graph Neural Networks go Grammatical","summary":"  This paper proposes a new GNN design strategy. This strategy relies on\nContext-Free Grammars (CFG) generating the matrix language MATLANG. It enables\nus to ensure both WL-expressive power, substructure counting abilities and\nspectral properties. Applying our strategy, we design Grammatical Graph Neural\nNetwork G$ ^2$N$^2$, a provably 3-WL GNN able to count at edge-level cycles of\nlength up to 6 and able to reach band-pass filters. A large number of\nexperiments covering these properties corroborate the presented theoretical\nresults.\n","authors":["Jason Piquenot","Aldo Moscatelli","Maxime Bérar","Pierre Héroux","Jean-Yves Ramel","Romain raveaux","Sébastien Adam"],"pdf_url":"https://arxiv.org/pdf/2303.01590v1.pdf","comment":"17 pages, 6 figures"},{"id":"http://arxiv.org/abs/2303.01580v1","updated":"2023-03-02T21:13:56Z","published":"2023-03-02T21:13:56Z","title":"Mixture of Soft Prompts for Controllable Data Generation","summary":"  Large language models (LLMs) effectively generate fluent text when the target\noutput follows natural language patterns. However, structured prediction tasks\nconfine the output format to a limited ontology, causing even very large models\nto struggle since they were never trained with such restrictions in mind. The\ndifficulty of using LLMs for direct prediction is exacerbated in few-shot\nlearning scenarios, which commonly arise due to domain shift and resource\nlimitations. We flip the problem on its head by leveraging the LLM as a tool\nfor data augmentation rather than direct prediction. Our proposed Mixture of\nSoft Prompts (MSP) serves as a parameter-efficient procedure for generating\ndata in a controlled manner. Denoising mechanisms are further applied to\nimprove the quality of synthesized data. Automatic metrics show our method is\ncapable of producing diverse and natural text, while preserving label\nsemantics. Moreover, MSP achieves state-of-the-art results on three benchmarks\nwhen compared against strong baselines. Our method offers an alternate\ndata-centric approach for applying LLMs to complex prediction tasks.\n","authors":["Derek Chen","Celine Lee","Yunan Lu","Domenic Rosati","Zhou Yu"],"pdf_url":"https://arxiv.org/pdf/2303.01580v1.pdf","comment":"17 pages, Preprint"},{"id":"http://arxiv.org/abs/2302.03241v3","updated":"2023-03-02T19:38:17Z","published":"2023-02-07T03:57:55Z","title":"Continual Learning of Language Models","summary":"  Language models (LMs) have been instrumental for the rapid advance of natural\nlanguage processing. This paper studies continual learning of LMs, in\nparticular, continual domain-adaptive pre-training (or continual DAP-training).\nExisting research has shown that further pre-training an LM using a domain\ncorpus to adapt the LM to the domain can improve the end-task performance in\nthe domain. This paper proposes a novel method to continually DAP-train an LM\nwith a sequence of unlabeled domain corpora to adapt the LM to these domains to\nimprove their end-task performances. The key novelty of our method is a\nsoft-masking mechanism that directly controls the update to the LM. A novel\nproxy is also proposed to preserve the general knowledge in the original LM.\nAdditionally, it contrasts the representations of the previously learned domain\nknowledge (including the general knowledge in the pre-trained LM) and the\nknowledge from the current full network to achieve knowledge integration. The\nmethod not only overcomes catastrophic forgetting, but also achieves knowledge\ntransfer to improve end-task performances. Empirical evaluation demonstrates\nthe effectiveness of the proposed method.\n","authors":["Zixuan Ke","Yijia Shao","Haowei Lin","Tatsuya Konishi","Gyuhak Kim","Bing Liu"],"pdf_url":"https://arxiv.org/pdf/2302.03241v3.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01510v1","updated":"2023-03-02T11:18:56Z","published":"2023-03-02T11:18:56Z","title":"INO at Factify 2: Structure Coherence based Multi-Modal Fact\n  Verification","summary":"  This paper describes our approach to the multi-modal fact verification\n(FACTIFY) challenge at AAAI2023. In recent years, with the widespread use of\nsocial media, fake news can spread rapidly and negatively impact social\nsecurity. Automatic claim verification becomes more and more crucial to combat\nfake news. In fact verification involving multiple modal data, there should be\na structural coherence between claim and document. Therefore, we proposed a\nstructure coherence-based multi-modal fact verification scheme to classify fake\nnews. Our structure coherence includes the following four aspects: sentence\nlength, vocabulary similarity, semantic similarity, and image similarity.\nSpecifically, CLIP and Sentence BERT are combined to extract text features, and\nResNet50 is used to extract image features. In addition, we also extract the\nlength of the text as well as the lexical similarity. Then the features were\nconcatenated and passed through the random forest classifier. Finally, our\nweighted average F1 score has reached 0.8079, achieving 2nd place in FACTIFY2.\n","authors":["Yinuo Zhang","Zhulin Tao","Xi Wang","Tongyue Wang"],"pdf_url":"https://arxiv.org/pdf/2303.01510v1.pdf","comment":"AAAI-23 DeFactify 2 Workshop (2nd Prize)"},{"id":"http://arxiv.org/abs/2303.01962v1","updated":"2023-03-02T06:33:48Z","published":"2023-03-02T06:33:48Z","title":"Less is More: Mitigate Spurious Correlations for Open-Domain Dialogue\n  Response Generation Models by Causal Discovery","summary":"  In this paper, we conduct the first study on spurious correlations for\nopen-domain response generation models based on a corpus CGDIALOG curated in\nour work. The cur rent models indeed suffer from spurious correlations and have\na tendency of generating irrelevant and generic responses. Inspired by causal\ndiscovery algorithms, we propose a novel model-agnostic method for training and\ninference of response generation model using a conditional independence\nclassifier. The classifier is trained by a constrained self-training method,\ncoined CONSTRAIN, to overcome data scarcity. The experimental results based on\nboth human and automatic evaluation show that our method significantly\noutperforms the competitive baselines in terms of relevance, informativeness,\nand fluency.\n","authors":["Tao Feng","Lizhen Qu","Gholamreza Haffari"],"pdf_url":"https://arxiv.org/pdf/2303.01962v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03267v1","updated":"2023-03-02T08:57:33Z","published":"2023-03-02T08:57:33Z","title":"Evaluating Parameter-Efficient Transfer Learning Approaches on SURE\n  Benchmark for Speech Understanding","summary":"  Fine-tuning is widely used as the default algorithm for transfer learning\nfrom pre-trained models. Parameter inefficiency can however arise when, during\ntransfer learning, all the parameters of a large pre-trained model need to be\nupdated for individual downstream tasks. As the number of parameters grows,\nfine-tuning is prone to overfitting and catastrophic forgetting. In addition,\nfull fine-tuning can become prohibitively expensive when the model is used for\nmany tasks. To mitigate this issue, parameter-efficient transfer learning\nalgorithms, such as adapters and prefix tuning, have been proposed as a way to\nintroduce a few trainable parameters that can be plugged into large pre-trained\nlanguage models such as BERT, and HuBERT. In this paper, we introduce the\nSpeech UndeRstanding Evaluation (SURE) benchmark for parameter-efficient\nlearning for various speech-processing tasks. Additionally, we introduce a new\nadapter, ConvAdapter, based on 1D convolution. We show that ConvAdapter\noutperforms the standard adapters while showing comparable performance against\nprefix tuning and LoRA with only 0.94% of trainable parameters on some of the\ntask in SURE. We further explore the effectiveness of parameter efficient\ntransfer learning for speech synthesis task such as Text-to-Speech (TTS).\n","authors":["Yingting Li","Ambuj Mehrish","Shuai Zhao","Rishabh Bhardwaj","Amir Zadeh","Navonil Majumder","Rada Mihalcea","Soujanya Poria"],"pdf_url":"https://arxiv.org/pdf/2303.03267v1.pdf","comment":"ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.03387v1","updated":"2023-03-02T17:30:43Z","published":"2023-03-02T17:30:43Z","title":"CoSyn: Detecting Implicit Hate Speech in Online Conversations Using a\n  Context Synergized Hyperbolic Network","summary":"  The tremendous growth of social media users interacting in online\nconversations has also led to significant growth in hate speech. Most of the\nprior works focus on detecting explicit hate speech, which is overt and\nleverages hateful phrases, with very little work focusing on detecting hate\nspeech that is implicit or denotes hatred through indirect or coded language.\nIn this paper, we present CoSyn, a user- and conversational-context synergized\nnetwork for detecting implicit hate speech in online conversation trees. CoSyn\nfirst models the user's personal historical and social context using a novel\nhyperbolic Fourier attention mechanism and hyperbolic graph convolution\nnetwork. Next, we jointly model the user's personal context and the\nconversational context using a novel context interaction mechanism in the\nhyperbolic space that clearly captures the interplay between the two and makes\nindependent assessments on the amounts of information to be retrieved from both\ncontexts. CoSyn performs all operations in the hyperbolic space to account for\nthe scale-free dynamics of social media. We demonstrate the effectiveness of\nCoSyn both qualitatively and quantitatively on an open-source hate speech\ndataset with Twitter conversations and show that CoSyn outperforms all our\nbaselines in detecting implicit hate speech with absolute improvements in the\nrange of 8.15% - 19.50%.\n","authors":["Sreyan Ghosh","Manan Suri","Purva Chiniya","Utkarsh Tyagi","Sonal Kumar","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2303.03387v1.pdf","comment":"Under review at IJCAI 2023"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2303.01503v1","updated":"2023-03-02T18:59:48Z","published":"2023-03-02T18:59:48Z","title":"FeatAug-DETR: Enriching One-to-Many Matching for DETRs with Feature\n  Augmentation","summary":"  One-to-one matching is a crucial design in DETR-like object detection\nframeworks. It enables the DETR to perform end-to-end detection. However, it\nalso faces challenges of lacking positive sample supervision and slow\nconvergence speed. Several recent works proposed the one-to-many matching\nmechanism to accelerate training and boost detection performance. We revisit\nthese methods and model them in a unified format of augmenting the object\nqueries. In this paper, we propose two methods that realize one-to-many\nmatching from a different perspective of augmenting images or image features.\nThe first method is One-to-many Matching via Data Augmentation (denoted as\nDataAug-DETR). It spatially transforms the images and includes multiple\naugmented versions of each image in the same training batch. Such a simple\naugmentation strategy already achieves one-to-many matching and surprisingly\nimproves DETR's performance. The second method is One-to-many matching via\nFeature Augmentation (denoted as FeatAug-DETR). Unlike DataAug-DETR, it\naugments the image features instead of the original images and includes\nmultiple augmented features in the same batch to realize one-to-many matching.\nFeatAug-DETR significantly accelerates DETR training and boosts detection\nperformance while keeping the inference speed unchanged. We conduct extensive\nexperiments to evaluate the effectiveness of the proposed approach on DETR\nvariants, including DAB-DETR, Deformable-DETR, and H-Deformable-DETR. Without\nextra training data, FeatAug-DETR shortens the training convergence periods of\nDeformable-DETR to 24 epochs and achieves 58.3 AP on COCO val2017 set with\nSwin-L as the backbone.\n","authors":["Rongyao Fang","Peng Gao","Aojun Zhou","Yingjie Cai","Si Liu","Jifeng Dai","Hongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2303.01503v1.pdf","comment":"12 pages, 6 figures"},{"id":"http://arxiv.org/abs/2303.01500v1","updated":"2023-03-02T18:59:15Z","published":"2023-03-02T18:59:15Z","title":"Dropout Reduces Underfitting","summary":"  Introduced by Hinton et al. in 2012, dropout has stood the test of time as a\nregularizer for preventing overfitting in neural networks. In this study, we\ndemonstrate that dropout can also mitigate underfitting when used at the start\nof training. During the early phase, we find dropout reduces the directional\nvariance of gradients across mini-batches and helps align the mini-batch\ngradients with the entire dataset's gradient. This helps counteract the\nstochasticity of SGD and limit the influence of individual batches on model\ntraining. Our findings lead us to a solution for improving performance in\nunderfitting models - early dropout: dropout is applied only during the initial\nphases of training, and turned off afterwards. Models equipped with early\ndropout achieve lower final training loss compared to their counterparts\nwithout dropout. Additionally, we explore a symmetric technique for\nregularizing overfitting models - late dropout, where dropout is not used in\nthe early iterations and is only activated later in training. Experiments on\nImageNet and various vision tasks demonstrate that our methods consistently\nimprove generalization accuracy. Our results encourage more research on\nunderstanding regularization in deep learning and our methods can be useful\ntools for future neural network training, especially in the era of large data.\nCode is available at https://github.com/facebookresearch/dropout .\n","authors":["Zhuang Liu","Zhiqiu Xu","Joseph Jin","Zhiqiang Shen","Trevor Darrell"],"pdf_url":"https://arxiv.org/pdf/2303.01500v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2303.01498v1","updated":"2023-03-02T18:58:15Z","published":"2023-03-02T18:58:15Z","title":"ABAW: Valence-Arousal Estimation, Expression Recognition, Action Unit\n  Detection & Emotional Reaction Intensity Estimation Challenges","summary":"  The fifth Affective Behavior Analysis in-the-wild (ABAW) Competition is part\nof the respective ABAW Workshop which will be held in conjunction with IEEE\nComputer Vision and Pattern Recognition Conference (CVPR), 2023. The 5th ABAW\nCompetition is a continuation of the Competitions held at ECCV 2022, IEEE CVPR\n2022, ICCV 2021, IEEE FG 2020 and CVPR 2017 Conferences, and is dedicated at\nautomatically analyzing affect. For this year's Competition, we feature two\ncorpora: i) an extended version of the Aff-Wild2 database and ii) the\nHume-Reaction dataset. The former database is an audiovisual one of around 600\nvideos of around 3M frames and is annotated with respect to:a) two continuous\naffect dimensions -valence (how positive/negative a person is) and arousal (how\nactive/passive a person is)-; b) basic expressions (e.g. happiness, sadness,\nneutral state); and c) atomic facial muscle actions (i.e., action units). The\nlatter dataset is an audiovisual one in which reactions of individuals to\nemotional stimuli have been annotated with respect to seven emotional\nexpression intensities. Thus the 5th ABAW Competition encompasses four\nChallenges: i) uni-task Valence-Arousal Estimation, ii) uni-task Expression\nClassification, iii) uni-task Action Unit Detection, and iv) Emotional Reaction\nIntensity Estimation. In this paper, we present these Challenges, along with\ntheir corpora, we outline the evaluation metrics, we present the baseline\nsystems and illustrate their obtained performance.\n","authors":["Dimitrios Kollias","Panagiotis Tzirakis","Alice Baird","Alan Cowen","Stefanos Zafeiriou"],"pdf_url":"https://arxiv.org/pdf/2303.01498v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2202.10659"},{"id":"http://arxiv.org/abs/2202.00182v2","updated":"2023-03-02T18:57:56Z","published":"2022-02-01T02:06:54Z","title":"Semi-supervised 3D Object Detection via Temporal Graph Neural Networks","summary":"  3D object detection plays an important role in autonomous driving and other\nrobotics applications. However, these detectors usually require training on\nlarge amounts of annotated data that is expensive and time-consuming to\ncollect. Instead, we propose leveraging large amounts of unlabeled point cloud\nvideos by semi-supervised learning of 3D object detectors via temporal graph\nneural networks. Our insight is that temporal smoothing can create more\naccurate detection results on unlabeled data, and these smoothed detections can\nthen be used to retrain the detector. We learn to perform this temporal\nreasoning with a graph neural network, where edges represent the relationship\nbetween candidate detections in different time frames. After semi-supervised\nlearning, our method achieves state-of-the-art detection performance on the\nchallenging nuScenes and H3D benchmarks, compared to baselines trained on the\nsame amount of labeled data. Project and code are released at\nhttps://www.jianrenw.com/SOD-TGNN/.\n","authors":["Jianren Wang","Haiming Gang","Siddarth Ancha","Yi-Ting Chen","David Held"],"pdf_url":"https://arxiv.org/pdf/2202.00182v2.pdf","comment":"3DV 2021"},{"id":"http://arxiv.org/abs/2303.01497v1","updated":"2023-03-02T18:57:38Z","published":"2023-03-02T18:57:38Z","title":"Teach a Robot to FISH: Versatile Imitation from One Minute of\n  Demonstrations","summary":"  While imitation learning provides us with an efficient toolkit to train\nrobots, learning skills that are robust to environment variations remains a\nsignificant challenge. Current approaches address this challenge by relying\neither on large amounts of demonstrations that span environment variations or\non handcrafted reward functions that require state estimates. Both directions\nare not scalable to fast imitation. In this work, we present Fast Imitation of\nSkills from Humans (FISH), a new imitation learning approach that can learn\nrobust visual skills with less than a minute of human demonstrations. Given a\nweak base-policy trained by offline imitation of demonstrations, FISH computes\nrewards that correspond to the \"match\" between the robot's behavior and the\ndemonstrations. These rewards are then used to adaptively update a residual\npolicy that adds on to the base-policy. Across all tasks, FISH requires at most\ntwenty minutes of interactive learning to imitate demonstrations on object\nconfigurations that were not seen in the demonstrations. Importantly, FISH is\nconstructed to be versatile, which allows it to be used across robot\nmorphologies (e.g. xArm, Allegro, Stretch) and camera configurations (e.g.\nthird-person, eye-in-hand). Our experimental evaluations on 9 different tasks\nshow that FISH achieves an average success rate of 93%, which is around 3.8x\nhigher than prior state-of-the-art methods.\n","authors":["Siddhant Haldar","Jyothish Pari","Anant Rai","Lerrel Pinto"],"pdf_url":"https://arxiv.org/pdf/2303.01497v1.pdf","comment":"Code and robot videos are available at\n  https://fast-imitation.github.io/"},{"id":"http://arxiv.org/abs/2303.01494v1","updated":"2023-03-02T18:56:39Z","published":"2023-03-02T18:56:39Z","title":"Image as Set of Points","summary":"  What is an image and how to extract latent features? Convolutional Networks\n(ConvNets) consider an image as organized pixels in a rectangular shape and\nextract features via convolutional operation in local region; Vision\nTransformers (ViTs) treat an image as a sequence of patches and extract\nfeatures via attention mechanism in a global range. In this work, we introduce\na straightforward and promising paradigm for visual representation, which is\ncalled Context Clusters. Context clusters (CoCs) view an image as a set of\nunorganized points and extract features via simplified clustering algorithm. In\ndetail, each point includes the raw feature (e.g., color) and positional\ninformation (e.g., coordinates), and a simplified clustering algorithm is\nemployed to group and extract deep features hierarchically. Our CoCs are\nconvolution- and attention-free, and only rely on clustering algorithm for\nspatial interaction. Owing to the simple design, we show CoCs endow gratifying\ninterpretability via the visualization of clustering process. Our CoCs aim at\nproviding a new perspective on image and visual representation, which may enjoy\nbroad applications in different domains and exhibit profound insights. Even\nthough we are not targeting SOTA performance, COCs still achieve comparable or\neven better results than ConvNets or ViTs on several benchmarks. Codes are\navailable at: https://github.com/ma-xu/Context-Cluster.\n","authors":["Xu Ma","Yuqian Zhou","Huan Wang","Can Qin","Bin Sun","Chang Liu","Yun Fu"],"pdf_url":"https://arxiv.org/pdf/2303.01494v1.pdf","comment":"ICLR'23 Oral (top 5%); Codes:\n  https://github.com/ma-xu/Context-Cluster"},{"id":"http://arxiv.org/abs/2301.08965v2","updated":"2023-03-02T18:50:45Z","published":"2023-01-21T15:42:53Z","title":"Raw or Cooked? Object Detection on RAW Images","summary":"  Images fed to a deep neural network have in general undergone several\nhandcrafted image signal processing (ISP) operations, all of which have been\noptimized to produce visually pleasing images. In this work, we investigate the\nhypothesis that the intermediate representation of visually pleasing images is\nsub-optimal for downstream computer vision tasks compared to the RAW image\nrepresentation. We suggest that the operations of the ISP instead should be\noptimized towards the end task, by learning the parameters of the operations\njointly during training. We extend previous works on this topic and propose a\nnew learnable operation that enables an object detector to achieve superior\nperformance when compared to both previous works and traditional RGB images. In\nexperiments on the open PASCALRAW dataset, we empirically confirm our\nhypothesis.\n","authors":["William Ljungbergh","Joakim Johnander","Christoffer Petersson","Michael Felsberg"],"pdf_url":"https://arxiv.org/pdf/2301.08965v2.pdf","comment":"SCIA 2023"},{"id":"http://arxiv.org/abs/2206.12370v2","updated":"2023-03-02T18:45:57Z","published":"2022-06-24T16:44:06Z","title":"Mixed Sample Augmentation for Online Distillation","summary":"  Mixed Sample Regularization (MSR), such as MixUp or CutMix, is a powerful\ndata augmentation strategy to generalize convolutional neural networks.\nPrevious empirical analysis has illustrated an orthogonal performance gain\nbetween MSR and conventional offline Knowledge Distillation (KD). To be more\nspecific, student networks can be enhanced with the involvement of MSR in the\ntraining stage of sequential distillation. Yet, the interplay between MSR and\nonline knowledge distillation, where an ensemble of peer students learn\nmutually from each other, remains unexplored. To bridge the gap, we make the\nfirst attempt at incorporating CutMix into online distillation, where we\nempirically observe a significant improvement. Encouraged by this fact, we\npropose an even stronger MSR specifically for online distillation, named as\nCut\\textsuperscript{n}Mix. Furthermore, a novel online distillation framework\nis designed upon Cut\\textsuperscript{n}Mix, to enhance the distillation with\nfeature level mutual learning and a self-ensemble teacher. Comprehensive\nevaluations on CIFAR10 and CIFAR100 with six network architectures show that\nour approach can consistently outperform state-of-the-art distillation methods.\n","authors":["Yiqing Shen","Liwu Xu","Yuzhe Yang","Yaqian Li","Yandong Guo"],"pdf_url":"https://arxiv.org/pdf/2206.12370v2.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2303.01484v1","updated":"2023-03-02T18:45:02Z","published":"2023-03-02T18:45:02Z","title":"Predicting Motion Plans for Articulating Everyday Objects","summary":"  Mobile manipulation tasks such as opening a door, pulling open a drawer, or\nlifting a toilet lid require constrained motion of the end-effector under\nenvironmental and task constraints. This, coupled with partial information in\nnovel environments, makes it challenging to employ classical motion planning\napproaches at test time. Our key insight is to cast it as a learning problem to\nleverage past experience of solving similar planning problems to directly\npredict motion plans for mobile manipulation tasks in novel situations at test\ntime. To enable this, we develop a simulator, ArtObjSim, that simulates\narticulated objects placed in real scenes. We then introduce SeqIK+$\\theta_0$,\na fast and flexible representation for motion plans. Finally, we learn models\nthat use SeqIK+$\\theta_0$ to quickly predict motion plans for articulating\nnovel objects at test time. Experimental evaluation shows improved speed and\naccuracy at generating motion plans than pure search-based methods and pure\nlearning methods.\n","authors":["Arjun Gupta","Max E. Shepherd","Saurabh Gupta"],"pdf_url":"https://arxiv.org/pdf/2303.01484v1.pdf","comment":"To Appear in ICRA 2023. Project webpage:\n  https://arjung128.github.io/mpao/"},{"id":"http://arxiv.org/abs/2303.01480v1","updated":"2023-03-02T18:41:41Z","published":"2023-03-02T18:41:41Z","title":"Delivering Arbitrary-Modal Semantic Segmentation","summary":"  Multimodal fusion can make semantic segmentation more robust. However, fusing\nan arbitrary number of modalities remains underexplored. To delve into this\nproblem, we create the DeLiVER arbitrary-modal segmentation benchmark, covering\nDepth, LiDAR, multiple Views, Events, and RGB. Aside from this, we provide this\ndataset in four severe weather conditions as well as five sensor failure cases\nto exploit modal complementarity and resolve partial outages. To make this\npossible, we present the arbitrary cross-modal segmentation model CMNeXt. It\nencompasses a Self-Query Hub (SQ-Hub) designed to extract effective information\nfrom any modality for subsequent fusion with the RGB representation and adds\nonly negligible amounts of parameters (~0.01M) per additional modality. On top,\nto efficiently and flexibly harvest discriminative cues from the auxiliary\nmodalities, we introduce the simple Parallel Pooling Mixer (PPX). With\nextensive experiments on a total of six benchmarks, our CMNeXt achieves\nstate-of-the-art performance on the DeLiVER, KITTI-360, MFNet, NYU Depth V2,\nUrbanLF, and MCubeS datasets, allowing to scale from 1 to 81 modalities. On the\nfreshly collected DeLiVER, the quad-modal CMNeXt reaches up to 66.30% in mIoU\nwith a +9.10% gain as compared to the mono-modal baseline. The DeLiVER dataset\nand our code are at: https://jamycheung.github.io/DELIVER.html.\n","authors":["Jiaming Zhang","Ruiping Liu","Hao Shi","Kailun Yang","Simon Reiß","Kunyu Peng","Haodong Fu","Kaiwei Wang","Rainer Stiefelhagen"],"pdf_url":"https://arxiv.org/pdf/2303.01480v1.pdf","comment":"Accepted by CVPR 2023. Dataset and our code are at:\n  https://jamycheung.github.io/DELIVER.html"},{"id":"http://arxiv.org/abs/2303.01469v1","updated":"2023-03-02T18:30:16Z","published":"2023-03-02T18:30:16Z","title":"Consistency Models","summary":"  Diffusion models have made significant breakthroughs in image, audio, and\nvideo generation, but they depend on an iterative generation process that\ncauses slow sampling speed and caps their potential for real-time applications.\nTo overcome this limitation, we propose consistency models, a new family of\ngenerative models that achieve high sample quality without adversarial\ntraining. They support fast one-step generation by design, while still allowing\nfor few-step sampling to trade compute for sample quality. They also support\nzero-shot data editing, like image inpainting, colorization, and\nsuper-resolution, without requiring explicit training on these tasks.\nConsistency models can be trained either as a way to distill pre-trained\ndiffusion models, or as standalone generative models. Through extensive\nexperiments, we demonstrate that they outperform existing distillation\ntechniques for diffusion models in one- and few-step generation. For example,\nwe achieve the new state-of-the-art FID of 3.55 on CIFAR-10 and 6.20 on\nImageNet 64x64 for one-step generation. When trained as standalone generative\nmodels, consistency models also outperform single-step, non-adversarial\ngenerative models on standard benchmarks like CIFAR-10, ImageNet 64x64 and LSUN\n256x256.\n","authors":["Yang Song","Prafulla Dhariwal","Mark Chen","Ilya Sutskever"],"pdf_url":"https://arxiv.org/pdf/2303.01469v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03992v2","updated":"2023-03-02T18:29:24Z","published":"2023-02-08T11:01:19Z","title":"Convolutional Neural Networks Trained to Identify Words Provide a Good\n  Account of Visual Form Priming Effects","summary":"  A wide variety of orthographic coding schemes and models of visual word\nidentification have been developed to account for masked priming data that\nprovide a measure of orthographic similarity between letter strings. These\nmodels tend to include hand-coded orthographic representations with single unit\ncoding for specific forms of knowledge (e.g., units coding for a letter in a\ngiven position). Here we assess how well a range of these coding schemes and\nmodels account for the pattern of form priming effects taken from the Form\nPriming Project and compare these findings to results observed with 11 standard\ndeep neural network models (DNNs) developed in computer science. We find that\ndeep convolutional networks (CNNs) perform as well or better than the coding\nschemes and word recognition models, whereas transformer networks did less\nwell. The success of CNNs is remarkable as their architectures were not\ndeveloped to support word recognition (they were designed to perform well on\nobject recognition), they classify pixel images of words (rather than\nartificial encodings of letter strings), and their training was highly\nsimplified (not respecting many key aspects of human experience). In addition\nto these form priming effects, we find that the DNNs can account for visual\nsimilarity effects on priming that are beyond all current psychological models\nof priming. The findings add to the recent work of (Hannagan et al., 2021) and\nsuggest that CNNs should be given more attention in psychology as models of\nhuman visual word recognition.\n","authors":["Dong Yin","Valerio Biscione","Jeffrey Bowers"],"pdf_url":"https://arxiv.org/pdf/2302.03992v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01468v1","updated":"2023-03-02T18:28:29Z","published":"2023-03-02T18:28:29Z","title":"Dataset Creation Pipeline for Camera-Based Heart Rate Estimation","summary":"  Heart rate is one of the most vital health metrics which can be utilized to\ninvestigate and gain intuitions into various human physiological and\npsychological information. Estimating heart rate without the constraints of\ncontact-based sensors thus presents itself as a very attractive field of\nresearch as it enables well-being monitoring in a wider variety of scenarios.\nConsequently, various techniques for camera-based heart rate estimation have\nbeen developed ranging from classical image processing to convoluted deep\nlearning models and architectures. At the heart of such research efforts lies\nhealth and visual data acquisition, cleaning, transformation, and annotation.\nIn this paper, we discuss how to prepare data for the task of developing or\ntesting an algorithm or machine learning model for heart rate estimation from\nimages of facial regions. The data prepared is to include camera frames as well\nas sensor readings from an electrocardiograph sensor. The proposed pipeline is\ndivided into four main steps, namely removal of faulty data, frame and\nelectrocardiograph timestamp de-jittering, signal denoising and filtering, and\nframe annotation creation. Our main contributions are a novel technique of\neliminating jitter from health sensor and camera timestamps and a method to\naccurately time align both visual frame and electrocardiogram sensor data which\nis also applicable to other sensor types.\n","authors":["Mohamed Moustafa","Amr Elrasad","Joseph Lemley","Peter Corcoran"],"pdf_url":"https://arxiv.org/pdf/2303.01468v1.pdf","comment":"Presented at the International Conference on Machine Vision 2022,\n  Rome, Italy. Paper is 8 pages long and includes 7 figures (including table)"},{"id":"http://arxiv.org/abs/2303.01465v1","updated":"2023-03-02T18:27:48Z","published":"2023-03-02T18:27:48Z","title":"MoSFPAD: An end-to-end Ensemble of MobileNet and Support Vector\n  Classifier for Fingerprint Presentation Attack Detection","summary":"  Automatic fingerprint recognition systems are the most extensively used\nsystems for person authentication although they are vulnerable to Presentation\nattacks. Artificial artifacts created with the help of various materials are\nused to deceive these systems causing a threat to the security of\nfingerprint-based applications. This paper proposes a novel end-to-end model to\ndetect fingerprint Presentation attacks. The proposed model incorporates\nMobileNet as a feature extractor and a Support Vector Classifier as a\nclassifier to detect presentation attacks in cross-material and cross-sensor\nparadigms. The feature extractor's parameters are learned with the loss\ngenerated by the support vector classifier. The proposed model eliminates the\nneed for intermediary data preparation procedures, unlike other static hybrid\narchitectures. The performance of the proposed model has been validated on\nbenchmark LivDet 2011, 2013, 2015, 2017, and 2019 databases, and overall\naccuracy of 98.64%, 99.50%, 97.23%, 95.06%, and 95.20% is achieved on these\ndatabases, respectively. The performance of the proposed model is compared with\nstate-of-the-art methods and the proposed method outperforms in cross-material\nand cross-sensor paradigms in terms of average classification error.\n","authors":["Anuj Rai","Somnath Dey","Pradeep Patidar","Prakhar Rai"],"pdf_url":"https://arxiv.org/pdf/2303.01465v1.pdf","comment":"12 pages, 3 figures"},{"id":"http://arxiv.org/abs/2211.05778v3","updated":"2023-03-02T18:13:33Z","published":"2022-11-10T18:59:04Z","title":"InternImage: Exploring Large-Scale Vision Foundation Models with\n  Deformable Convolutions","summary":"  Compared to the great progress of large-scale vision transformers (ViTs) in\nrecent years, large-scale models based on convolutional neural networks (CNNs)\nare still in an early state. This work presents a new large-scale CNN-based\nfoundation model, termed InternImage, which can obtain the gain from increasing\nparameters and training data like ViTs. Different from the recent CNNs that\nfocus on large dense kernels, InternImage takes deformable convolution as the\ncore operator, so that our model not only has the large effective receptive\nfield required for downstream tasks such as detection and segmentation, but\nalso has the adaptive spatial aggregation conditioned by input and task\ninformation. As a result, the proposed InternImage reduces the strict inductive\nbias of traditional CNNs and makes it possible to learn stronger and more\nrobust patterns with large-scale parameters from massive data like ViTs. The\neffectiveness of our model is proven on challenging benchmarks including\nImageNet, COCO, and ADE20K. It is worth mentioning that InternImage-H achieved\na new record 65.4 mAP on COCO test-dev and 62.9 mIoU on ADE20K, outperforming\ncurrent leading CNNs and ViTs. The code will be released at\nhttps://github.com/OpenGVLab/InternImage.\n","authors":["Wenhai Wang","Jifeng Dai","Zhe Chen","Zhenhang Huang","Zhiqi Li","Xizhou Zhu","Xiaowei Hu","Tong Lu","Lewei Lu","Hongsheng Li","Xiaogang Wang","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2211.05778v3.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2208.11870v2","updated":"2023-03-02T17:27:13Z","published":"2022-08-25T04:52:21Z","title":"Fix-A-Step: Semi-supervised Learning from Uncurated Unlabeled Data","summary":"  Semi-supervised learning (SSL) promises improved accuracy compared to\ntraining classifiers on small labeled datasets by also training on many\nunlabeled images. In real applications like medical imaging, unlabeled data\nwill be collected for expediency and thus uncurated: possibly different from\nthe labeled set in classes or features. Unfortunately, modern deep SSL often\nmakes accuracy worse when given uncurated unlabeled data. Recent complex\nremedies try to detect out-of-distribution unlabeled images and then discard or\ndownweight them. Instead, we introduce Fix-A-Step, a simpler procedure that\nviews all uncurated unlabeled images as potentially helpful. Our first insight\nis that even uncurated images can yield useful augmentations of labeled data.\nSecond, we modify gradient descent updates to prevent optimizing a multi-task\nSSL loss from hurting labeled-set accuracy. Fix-A-Step can repair many common\ndeep SSL methods, improving accuracy on CIFAR benchmarks across all tested\nmethods and levels of artificial class mismatch. On a new medical SSL benchmark\ncalled Heart2Heart, Fix-A-Step can learn from 353,500 truly uncurated\nultrasound images to deliver gains that generalize across hospitals.\n","authors":["Zhe Huang","Mary-Joy Sidhom","Benjamin S. Wessler","Michael C. Hughes"],"pdf_url":"https://arxiv.org/pdf/2208.11870v2.pdf","comment":"AISTATS 2023"},{"id":"http://arxiv.org/abs/2303.01418v1","updated":"2023-03-02T17:09:27Z","published":"2023-03-02T17:09:27Z","title":"Human Motion Diffusion as a Generative Prior","summary":"  In recent months, we witness a leap forward as denoising diffusion models\nwere introduced to Motion Generation. Yet, the main gap in this field remains\nthe low availability of data. Furthermore, the expensive acquisition process of\nmotion biases the already modest data towards short single-person sequences.\nWith such a shortage, more elaborate generative tasks are left behind. In this\npaper, we show that this gap can be mitigated using a pre-trained\ndiffusion-based model as a generative prior. We demonstrate the prior is\neffective for fine-tuning, in a few-, and even a zero-shot manner. For the\nzero-shot setting, we tackle the challenge of long sequence generation. We\nintroduce DoubleTake, an inference-time method with which we demonstrate up to\n10-minute long animations of prompted intervals and their meaningful and\ncontrolled transition, using the prior that was trained for 10-second\ngenerations. For the few-shot setting, we consider two-person generation. Using\ntwo fixed priors and as few as a dozen training examples, we learn a slim\ncommunication block, ComMDM, to infuse interaction between the two resulting\nmotions. Finally, using fine-tuning, we train the prior to semantically\ncomplete motions from a single prescribed joint. Then, we use our\nDiffusionBlending to blend a few such models into a single one that responds\nwell to the combination of the individual control signals, enabling\nfine-grained joint- and trajectory-level control and editing. Using an\noff-the-shelf state-of-the-art (SOTA) motion diffusion model as a prior, we\nevaluate our approach for the three mentioned cases and show that we\nconsistently outperform SOTA models that were designed and trained for those\ntasks.\n","authors":["Yonatan Shafir","Guy Tevet","Roy Kapon","Amit H. Bermano"],"pdf_url":"https://arxiv.org/pdf/2303.01418v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01416v1","updated":"2023-03-02T17:06:57Z","published":"2023-03-02T17:06:57Z","title":"3D generation on ImageNet","summary":"  Existing 3D-from-2D generators are typically designed for well-curated\nsingle-category datasets, where all the objects have (approximately) the same\nscale, 3D location, and orientation, and the camera always points to the center\nof the scene. This makes them inapplicable to diverse, in-the-wild datasets of\nnon-alignable scenes rendered from arbitrary camera poses. In this work, we\ndevelop a 3D generator with Generic Priors (3DGP): a 3D synthesis framework\nwith more general assumptions about the training data, and show that it scales\nto very challenging datasets, like ImageNet. Our model is based on three new\nideas. First, we incorporate an inaccurate off-the-shelf depth estimator into\n3D GAN training via a special depth adaptation module to handle the\nimprecision. Then, we create a flexible camera model and a regularization\nstrategy for it to learn its distribution parameters during training. Finally,\nwe extend the recent ideas of transferring knowledge from pre-trained\nclassifiers into GANs for patch-wise trained models by employing a simple\ndistillation-based technique on top of the discriminator. It achieves more\nstable training than the existing methods and speeds up the convergence by at\nleast 40%. We explore our model on four datasets: SDIP Dogs 256x256, SDIP\nElephants 256x256, LSUN Horses 256x256, and ImageNet 256x256, and demonstrate\nthat 3DGP outperforms the recent state-of-the-art in terms of both texture and\ngeometry quality. Code and visualizations:\nhttps://snap-research.github.io/3dgp.\n","authors":["Ivan Skorokhodov","Aliaksandr Siarohin","Yinghao Xu","Jian Ren","Hsin-Ying Lee","Peter Wonka","Sergey Tulyakov"],"pdf_url":"https://arxiv.org/pdf/2303.01416v1.pdf","comment":"ICLR 2023 (Oral)"},{"id":"http://arxiv.org/abs/2301.02830v3","updated":"2023-03-02T16:49:52Z","published":"2023-01-07T11:37:32Z","title":"Advanced Data Augmentation Approaches: A Comprehensive Survey and Future\n  directions","summary":"  Deep learning (DL) algorithms have shown significant performance in various\ncomputer vision tasks. However, having limited labelled data lead to a network\noverfitting problem, where network performance is bad on unseen data as\ncompared to training data. Consequently, it limits performance improvement. To\ncope with this problem, various techniques have been proposed such as dropout,\nnormalization and advanced data augmentation. Among these, data augmentation,\nwhich aims to enlarge the dataset size by including sample diversity, has been\na hot topic in recent times. In this article, we focus on advanced data\naugmentation techniques. we provide a background of data augmentation, a novel\nand comprehensive taxonomy of reviewed data augmentation techniques, and the\nstrengths and weaknesses (wherever possible) of each technique. We also provide\ncomprehensive results of the data augmentation effect on three popular computer\nvision tasks, such as image classification, object detection and semantic\nsegmentation. For results reproducibility, we compiled available codes of all\ndata augmentation techniques. Finally, we discuss the challenges and\ndifficulties, and possible future direction for the research community. We\nbelieve, this survey provides several benefits i) readers will understand the\ndata augmentation working mechanism to fix overfitting problems ii) results\nwill save the searching time of the researcher for comparison purposes. iii)\nCodes of the mentioned data augmentation techniques are available at\nhttps://github.com/kmr2017/Advanced-Data-augmentation-codes iv) Future work\nwill spark interest in research community.\n","authors":["Teerath Kumar","Alessandra Mileo","Rob Brennan","Malika Bendechache"],"pdf_url":"https://arxiv.org/pdf/2301.02830v3.pdf","comment":"We need to make a lot changes to make its quality better"},{"id":"http://arxiv.org/abs/2302.07817v2","updated":"2023-03-02T16:41:45Z","published":"2023-02-15T17:58:10Z","title":"Tri-Perspective View for Vision-Based 3D Semantic Occupancy Prediction","summary":"  Modern methods for vision-centric autonomous driving perception widely adopt\nthe bird's-eye-view (BEV) representation to describe a 3D scene. Despite its\nbetter efficiency than voxel representation, it has difficulty describing the\nfine-grained 3D structure of a scene with a single plane. To address this, we\npropose a tri-perspective view (TPV) representation which accompanies BEV with\ntwo additional perpendicular planes. We model each point in the 3D space by\nsumming its projected features on the three planes. To lift image features to\nthe 3D TPV space, we further propose a transformer-based TPV encoder\n(TPVFormer) to obtain the TPV features effectively. We employ the attention\nmechanism to aggregate the image features corresponding to each query in each\nTPV plane. Experiments show that our model trained with sparse supervision\neffectively predicts the semantic occupancy for all voxels. We demonstrate for\nthe first time that using only camera inputs can achieve comparable performance\nwith LiDAR-based methods on the LiDAR segmentation task on nuScenes. Code:\nhttps://github.com/wzzheng/TPVFormer.\n","authors":["Yuanhui Huang","Wenzhao Zheng","Yunpeng Zhang","Jie Zhou","Jiwen Lu"],"pdf_url":"https://arxiv.org/pdf/2302.07817v2.pdf","comment":"Accepted to CVPR 2023. Code is available at\n  https://github.com/wzzheng/TPVFormer"},{"id":"http://arxiv.org/abs/2303.01396v1","updated":"2023-03-02T16:26:14Z","published":"2023-03-02T16:26:14Z","title":"MLANet: Multi-Level Attention Network with Sub-instruction for\n  Continuous Vision-and-Language Navigation","summary":"  Vision-and-Language Navigation (VLN) aims to develop intelligent agents to\nnavigate in unseen environments only through language and vision supervision.\nIn the recently proposed continuous settings (continuous VLN), the agent must\nact in a free 3D space and faces tougher challenges like real-time execution,\ncomplex instruction understanding, and long action sequence prediction. For a\nbetter performance in continuous VLN, we design a multi-level instruction\nunderstanding procedure and propose a novel model, Multi-Level Attention\nNetwork (MLANet). The first step of MLANet is to generate sub-instructions\nefficiently. We design a Fast Sub-instruction Algorithm (FSA) to segment the\nraw instruction into sub-instructions and generate a new sub-instruction\ndataset named ``FSASub\". FSA is annotation-free and faster than the current\nmethod by 70 times, thus fitting the real-time requirement in continuous VLN.\nTo solve the complex instruction understanding problem, MLANet needs a global\nperception of the instruction and observations. We propose a Multi-Level\nAttention (MLA) module to fuse vision, low-level semantics, and high-level\nsemantics, which produce features containing a dynamic and global comprehension\nof the task. MLA also mitigates the adverse effects of noise words, thus\nensuring a robust understanding of the instruction. To correctly predict\nactions in long trajectories, MLANet needs to focus on what sub-instruction is\nbeing executed every step. We propose a Peak Attention Loss (PAL) to improve\nthe flexible and adaptive selection of the current sub-instruction. PAL\nbenefits the navigation agent by concentrating its attention on the local\ninformation, thus helping the agent predict the most appropriate actions. We\ntrain and test MLANet in the standard benchmark. Experiment results show MLANet\noutperforms baselines by a significant margin.\n","authors":["Zongtao He","Liuyi Wang","Shu Li","Qingqing Yan","Chengju Liu","Qijun Chen"],"pdf_url":"https://arxiv.org/pdf/2303.01396v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01384v1","updated":"2023-03-02T16:08:23Z","published":"2023-03-02T16:08:23Z","title":"DAVA: Disentangling Adversarial Variational Autoencoder","summary":"  The use of well-disentangled representations offers many advantages for\ndownstream tasks, e.g. an increased sample efficiency, or better\ninterpretability. However, the quality of disentangled interpretations is often\nhighly dependent on the choice of dataset-specific hyperparameters, in\nparticular the regularization strength. To address this issue, we introduce\nDAVA, a novel training procedure for variational auto-encoders. DAVA completely\nalleviates the problem of hyperparameter selection. We compare DAVA to models\nwith optimal hyperparameters. Without any hyperparameter tuning, DAVA is\ncompetitive on a diverse range of commonly used datasets. Underlying DAVA, we\ndiscover a necessary condition for unsupervised disentanglement, which we call\nPIPE. We demonstrate the ability of PIPE to positively predict the performance\nof downstream models in abstract reasoning. We also thoroughly investigate\ncorrelations with existing supervised and unsupervised metrics. The code is\navailable at https://github.com/besterma/dava.\n","authors":["Benjamin Estermann","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2303.01384v1.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01377v1","updated":"2023-03-02T16:02:55Z","published":"2023-03-02T16:02:55Z","title":"BEL: A Bag Embedding Loss for Transformer enhances Multiple Instance\n  Whole Slide Image Classification","summary":"  Multiple Instance Learning (MIL) has become the predominant approach for\nclassification tasks on gigapixel histopathology whole slide images (WSIs).\nWithin the MIL framework, single WSIs (bags) are decomposed into patches\n(instances), with only WSI-level annotation available. Recent MIL approaches\nproduce highly informative bag level representations by utilizing the\ntransformer architecture's ability to model the dependencies between instances.\nHowever, when applied to high magnification datasets, problems emerge due to\nthe large number of instances and the weak supervisory learning signal. To\naddress this problem, we propose to additionally train transformers with a\nnovel Bag Embedding Loss (BEL). BEL forces the model to learn a discriminative\nbag-level representation by minimizing the distance between bag embeddings of\nthe same class and maximizing the distance between different classes. We\nevaluate BEL with the Transformer architecture TransMIL on two publicly\navailable histopathology datasets, BRACS and CAMELYON17. We show that with BEL,\nTransMIL outperforms the baseline models on both datasets, thus contributing to\nthe clinically highly relevant AI-based tumor classification of histological\npatient material.\n","authors":["Daniel Sens","Ario Sadafi","Francesco Paolo Casale","Nassir Navab","Carsten Marr"],"pdf_url":"https://arxiv.org/pdf/2303.01377v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01363v1","updated":"2023-03-02T15:48:02Z","published":"2023-03-02T15:48:02Z","title":"Deep-NFA: a Deep $\\textit{a contrario}$ Framework for Small Object\n  Detection","summary":"  The detection of small objects is a challenging task in computer vision.\nConventional object detection methods have difficulty in finding the balance\nbetween high detection and low false alarm rates. In the literature, some\nmethods have addressed this issue by enhancing the feature map responses, but\nwithout guaranteeing robustness with respect to the number of false alarms\ninduced by background elements. To tackle this problem, we introduce an\n$\\textit{a contrario}$ decision criterion into the learning process to take\ninto account the unexpectedness of small objects. This statistic criterion\nenhances the feature map responses while controlling the number of false alarms\n(NFA) and can be integrated into any semantic segmentation neural network. Our\nadd-on NFA module not only allows us to obtain competitive results for small\ntarget and crack detection tasks respectively, but also leads to more robust\nand interpretable results.\n","authors":["Alina Ciocarlan","Sylvie Le Hegarat-Mascle","Sidonie Lefebvre","Arnaud Woiselle"],"pdf_url":"https://arxiv.org/pdf/2303.01363v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01351v1","updated":"2023-03-02T15:31:53Z","published":"2023-03-02T15:31:53Z","title":"APARATE: Adaptive Adversarial Patch for CNN-based Monocular Depth\n  Estimation for Autonomous Navigation","summary":"  In recent years, monocular depth estimation (MDE) has witnessed a substantial\nperformance improvement due to convolutional neural networks (CNNs). However,\nCNNs are vulnerable to adversarial attacks, which pose serious concerns for\nsafety-critical and security-sensitive systems. Specifically, adversarial\nattacks can have catastrophic impact on MDE given its importance for scene\nunderstanding in applications like autonomous driving and robotic navigation.\nTo physically assess the vulnerability of CNN-based depth prediction methods,\nrecent work tries to design adversarial patches against MDE. However, these\nmethods are not powerful enough to fully fool the vision system in a\nsystemically threatening manner. In fact, their impact is partial and locally\nlimited; they mislead the depth prediction of only the overlapping region with\nthe input image regardless of the target object size, shape and location. In\nthis paper, we investigate MDE vulnerability to adversarial patches in a more\ncomprehensive manner. We propose a novel adaptive adversarial patch (APARATE)\nthat is able to selectively jeopardize MDE by either corrupting the estimated\ndistance, or simply manifesting an object as disappeared for the autonomous\nsystem. Specifically, APARATE is optimized to be shape and scale-aware, and its\nimpact adapts to the target object instead of being limited to the immediate\nneighborhood. Our proposed patch achieves more than $14~meters$ mean depth\nestimation error, with $99\\%$ of the target region being affected. We believe\nthis work highlights the threat of adversarial attacks in the context of MDE,\nand we hope it would alert the community to the real-life potential harm of\nthis attack and motivate investigating more robust and adaptive defenses for\nautonomous robots.\n","authors":["Amira Guesmi","Muhammad Abdullah Hanif","Ihsen Alouani","Muhammad Shafique"],"pdf_url":"https://arxiv.org/pdf/2303.01351v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.02295v3","updated":"2023-03-02T15:23:11Z","published":"2022-12-05T14:19:21Z","title":"Block Selection Method for Using Feature Norm in Out-of-distribution\n  Detection","summary":"  Detecting out-of-distribution (OOD) inputs during the inference stage is\ncrucial for deploying neural networks in the real world. Previous methods\ncommonly relied on the output of a network derived from the highly activated\nfeature map. In this study, we first revealed that a norm of the feature map\nobtained from the other block than the last block can be a better indicator of\nOOD detection. Motivated by this, we propose a simple framework consisting of\nFeatureNorm: a norm of the feature map and NormRatio: a ratio of FeatureNorm\nfor ID and OOD to measure the OOD detection performance of each block. In\nparticular, to select the block that provides the largest difference between\nFeatureNorm of ID and FeatureNorm of OOD, we create Jigsaw puzzle images as\npseudo OOD from ID training samples and calculate NormRatio, and the block with\nthe largest value is selected. After the suitable block is selected, OOD\ndetection with the FeatureNorm outperforms other OOD detection methods by\nreducing FPR95 by up to 52.77% on CIFAR10 benchmark and by up to 48.53% on\nImageNet benchmark. We demonstrate that our framework can generalize to various\narchitectures and the importance of block selection, which can improve previous\nOOD detection methods as well.\n","authors":["Yeonguk Yu","Sungho Shin","Seongju Lee","Changhyun Jun","Kyoobin Lee"],"pdf_url":"https://arxiv.org/pdf/2212.02295v3.pdf","comment":"CVPR2023 accepted; Code is available in\n  https://github.com/gist-ailab/block-selection-for-OOD-detection"},{"id":"http://arxiv.org/abs/2303.01342v1","updated":"2023-03-02T15:18:58Z","published":"2023-03-02T15:18:58Z","title":"Active Learning Enhances Classification of Histopathology Whole Slide\n  Images with Attention-based Multiple Instance Learning","summary":"  In many histopathology tasks, sample classification depends on morphological\ndetails in tissue or single cells that are only visible at the highest\nmagnification. For a pathologist, this implies tedious zooming in and out,\nwhile for a computational decision support algorithm, it leads to the analysis\nof a huge number of small image patches per whole slide image (WSI).\nAttention-based multiple instance learning (MIL), where attention estimation is\nlearned in a weakly supervised manner, has been successfully applied in\ncomputational histopathology, but it is challenged by large numbers of\nirrelevant patches, reducing its accuracy. Here, we present an active learning\napproach to the problem. Querying the expert to annotate regions of interest in\na WSI guides the formation of high-attention regions for MIL. We train an\nattention-based MIL and calculate a confidence metric for every image in the\ndataset to select the most uncertain WSIs for expert annotation. We test our\napproach on the CAMELYON17 dataset classifying metastatic lymph node sections\nin breast cancer. With a novel attention guiding loss, this leads to an\naccuracy boost of the trained models with few regions annotated for each class.\nActive learning thus improves WSIs classification accuracy, leads to faster and\nmore robust convergence, and speeds up the annotation process. It may in the\nfuture serve as an important contribution to train MIL models in the clinically\nrelevant context of cancer classification in histopathology.\n","authors":["Ario Sadafi","Nassir Navab","Carsten Marr"],"pdf_url":"https://arxiv.org/pdf/2303.01342v1.pdf","comment":"Accepted for publication at the 2023 IEEE International Symposium on\n  Biomedical Imaging (ISBI 2023)"},{"id":"http://arxiv.org/abs/2303.01338v1","updated":"2023-03-02T15:14:46Z","published":"2023-03-02T15:14:46Z","title":"AdvRain: Adversarial Raindrops to Attack Camera-based Smart Vision\n  Systems","summary":"  Vision-based perception modules are increasingly deployed in many\napplications, especially autonomous vehicles and intelligent robots. These\nmodules are being used to acquire information about the surroundings and\nidentify obstacles. Hence, accurate detection and classification are essential\nto reach appropriate decisions and take appropriate and safe actions at all\ntimes. Current studies have demonstrated that \"printed adversarial attacks\",\nknown as physical adversarial attacks, can successfully mislead perception\nmodels such as object detectors and image classifiers. However, most of these\nphysical attacks are based on noticeable and eye-catching patterns for\ngenerated perturbations making them identifiable/detectable by human eye or in\ntest drives. In this paper, we propose a camera-based inconspicuous adversarial\nattack (\\textbf{AdvRain}) capable of fooling camera-based perception systems\nover all objects of the same class. Unlike mask based fake-weather attacks that\nrequire access to the underlying computing hardware or image memory, our attack\nis based on emulating the effects of a natural weather condition (i.e.,\nRaindrops) that can be printed on a translucent sticker, which is externally\nplaced over the lens of a camera. To accomplish this, we provide an iterative\nprocess based on performing a random search aiming to identify critical\npositions to make sure that the performed transformation is adversarial for a\ntarget classifier. Our transformation is based on blurring predefined parts of\nthe captured image corresponding to the areas covered by the raindrop. We\nachieve a drop in average model accuracy of more than $45\\%$ and $40\\%$ on\nVGG19 for ImageNet and Resnet34 for Caltech-101, respectively, using only $20$\nraindrops.\n","authors":["Amira Guesmi","Muhammad Abdullah Hanif","Muhammad Shafique"],"pdf_url":"https://arxiv.org/pdf/2303.01338v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.07254v2","updated":"2023-03-02T15:10:12Z","published":"2022-11-14T10:32:51Z","title":"The Role of Local Alignment and Uniformity in Image-Text Contrastive\n  Learning on Medical Images","summary":"  Image-text contrastive learning has proven effective for pretraining medical\nimage models. When targeting localized downstream tasks like semantic\nsegmentation or object detection, additional local contrastive losses that\nalign image regions with sentences have shown promising results. We study how\nlocal contrastive losses are related to global (per-sample) contrastive losses\nand which effects they have on localized medical downstream tasks. Based on a\ntheoretical comparison, we propose to remove some components of local losses\nand replace others by a novel distribution prior which enforces uniformity of\nrepresentations within each sample. We empirically study this approach on chest\nX-ray tasks and find it to be very effective, outperforming methods without\nlocal losses on 12 of 18 tasks.\n","authors":["Philip Müller","Georgios Kaissis","Daniel Rueckert"],"pdf_url":"https://arxiv.org/pdf/2211.07254v2.pdf","comment":"NeurIPS 2022 Workshop: Self-Supervised Learning - Theory and Practice\n  (Reason for updated version: correction of a typo in Eq. (2) and (3))"},{"id":"http://arxiv.org/abs/2303.01332v1","updated":"2023-03-02T15:10:08Z","published":"2023-03-02T15:10:08Z","title":"Self-Supervised Few-Shot Learning for Ischemic Stroke Lesion\n  Segmentation","summary":"  Precise ischemic lesion segmentation plays an essential role in improving\ndiagnosis and treatment planning for ischemic stroke, one of the prevalent\ndiseases with the highest mortality rate. While numerous deep neural network\napproaches have recently been proposed to tackle this problem, these methods\nrequire large amounts of annotated regions during training, which can be\nimpractical in the medical domain where annotated data is scarce. As a remedy,\nwe present a prototypical few-shot segmentation approach for ischemic lesion\nsegmentation using only one annotated sample during training. The proposed\napproach leverages a novel self-supervised training mechanism that is tailored\nto the task of ischemic stroke lesion segmentation by exploiting color-coded\nparametric maps generated from Computed Tomography Perfusion scans. We\nillustrate the benefits of our proposed training mechanism, leading to\nconsiderable improvements in performance in the few-shot setting. Given a\nsingle annotated patient, an average Dice score of 0.58 is achieved for the\nsegmentation of ischemic lesions.\n","authors":["Luca Tomasetti","Stine Hansen","Mahdieh Khanmohammadi","Kjersti Engan","Liv Jorunn Høllesli","Kathinka Dæhli Kurz","Michael Kampffmeyer"],"pdf_url":"https://arxiv.org/pdf/2303.01332v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01331v1","updated":"2023-03-02T15:09:25Z","published":"2023-03-02T15:09:25Z","title":"Canonical mapping as a general-purpose object descriptor for robotic\n  manipulation","summary":"  Perception is an essential part of robotic manipulation in a semi-structured\nenvironment. Traditional approaches produce a narrow task-specific prediction\n(e.g., object's 6D pose), that cannot be adapted to other tasks and is\nill-suited for deformable objects. In this paper, we propose using canonical\nmapping as a near-universal and flexible object descriptor. We demonstrate that\ncommon object representations can be derived from a single pre-trained\ncanonical mapping model, which in turn can be generated with minimal manual\neffort using an automated data generation and training pipeline. We perform a\nmulti-stage experiment using two robot arms that demonstrate the robustness of\nthe perception approach and the ways it can inform the manipulation strategy,\nthus serving as a powerful foundation for general-purpose robotic manipulation.\n","authors":["Benjamin Joffe","Konrad Ahlin"],"pdf_url":"https://arxiv.org/pdf/2303.01331v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.02432v2","updated":"2023-03-02T15:00:46Z","published":"2022-11-04T13:16:20Z","title":"RCDPT: Radar-Camera fusion Dense Prediction Transformer","summary":"  Recently, transformer networks have outperformed traditional deep neural\nnetworks in natural language processing and show a large potential in many\ncomputer vision tasks compared to convolutional backbones. In the original\ntransformer, readout tokens are used as designated vectors for aggregating\ninformation from other tokens. However, the performance of using readout tokens\nin a vision transformer is limited. Therefore, we propose a novel fusion\nstrategy to integrate radar data into a dense prediction transformer network by\nreassembling camera representations with radar representations. Instead of\nusing readout tokens, radar representations contribute additional depth\ninformation to a monocular depth estimation model and improve performance. We\nfurther investigate different fusion approaches that are commonly used for\nintegrating additional modality in a dense prediction transformer network. The\nexperiments are conducted on the nuScenes dataset, which includes camera\nimages, lidar, and radar data. The results show that our proposed method yields\nbetter performance than the commonly used fusion strategies and outperforms\nexisting convolutional depth estimation models that fuse camera images and\nradar.\n","authors":["Chen-Chou Lo","Patrick Vandewalle"],"pdf_url":"https://arxiv.org/pdf/2211.02432v2.pdf","comment":"5 pages, 2 figures and 1 table, accepted to ICASSP2023"},{"id":"http://arxiv.org/abs/2207.07027v2","updated":"2023-03-02T14:49:06Z","published":"2022-07-14T15:59:03Z","title":"MedFuse: Multi-modal fusion with clinical time-series data and chest\n  X-ray images","summary":"  Multi-modal fusion approaches aim to integrate information from different\ndata sources. Unlike natural datasets, such as in audio-visual applications,\nwhere samples consist of \"paired\" modalities, data in healthcare is often\ncollected asynchronously. Hence, requiring the presence of all modalities for a\ngiven sample is not realistic for clinical tasks and significantly limits the\nsize of the dataset during training. In this paper, we propose MedFuse, a\nconceptually simple yet promising LSTM-based fusion module that can accommodate\nuni-modal as well as multi-modal input. We evaluate the fusion method and\nintroduce new benchmark results for in-hospital mortality prediction and\nphenotype classification, using clinical time-series data in the MIMIC-IV\ndataset and corresponding chest X-ray images in MIMIC-CXR. Compared to more\ncomplex multi-modal fusion strategies, MedFuse provides a performance\nimprovement by a large margin on the fully paired test set. It also remains\nrobust across the partially paired test set containing samples with missing\nchest X-ray images. We release our code for reproducibility and to enable the\nevaluation of competing models in the future.\n","authors":["Nasir Hayat","Krzysztof J. Geras","Farah E. Shamout"],"pdf_url":"https://arxiv.org/pdf/2207.07027v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01313v1","updated":"2023-03-02T14:41:31Z","published":"2023-03-02T14:41:31Z","title":"Weakly-supervised HOI Detection via Prior-guided Bi-level Representation\n  Learning","summary":"  Human object interaction (HOI) detection plays a crucial role in\nhuman-centric scene understanding and serves as a fundamental building-block\nfor many vision tasks. One generalizable and scalable strategy for HOI\ndetection is to use weak supervision, learning from image-level annotations\nonly. This is inherently challenging due to ambiguous human-object\nassociations, large search space of detecting HOIs and highly noisy training\nsignal. A promising strategy to address those challenges is to exploit\nknowledge from large-scale pretrained models (e.g., CLIP), but a direct\nknowledge distillation strategy~\\citep{liao2022gen} does not perform well on\nthe weakly-supervised setting. In contrast, we develop a CLIP-guided HOI\nrepresentation capable of incorporating the prior knowledge at both image level\nand HOI instance level, and adopt a self-taught mechanism to prune incorrect\nhuman-object associations. Experimental results on HICO-DET and V-COCO show\nthat our method outperforms the previous works by a sizable margin, showing the\nefficacy of our HOI representation.\n","authors":["Bo Wan","Yongfei Liu","Desen Zhou","Tinne Tuytelaars","Xuming He"],"pdf_url":"https://arxiv.org/pdf/2303.01313v1.pdf","comment":"Accepted by ICLR2023"},{"id":"http://arxiv.org/abs/2303.01311v1","updated":"2023-03-02T14:37:17Z","published":"2023-03-02T14:37:17Z","title":"Zero-Shot Text-to-Parameter Translation for Game Character Auto-Creation","summary":"  Recent popular Role-Playing Games (RPGs) saw the great success of character\nauto-creation systems. The bone-driven face model controlled by continuous\nparameters (like the position of bones) and discrete parameters (like the\nhairstyles) makes it possible for users to personalize and customize in-game\ncharacters. Previous in-game character auto-creation systems are mostly\nimage-driven, where facial parameters are optimized so that the rendered\ncharacter looks similar to the reference face photo. This paper proposes a\nnovel text-to-parameter translation method (T2P) to achieve zero-shot\ntext-driven game character auto-creation. With our method, users can create a\nvivid in-game character with arbitrary text description without using any\nreference photo or editing hundreds of parameters manually. In our method,\ntaking the power of large-scale pre-trained multi-modal CLIP and neural\nrendering, T2P searches both continuous facial parameters and discrete facial\nparameters in a unified framework. Due to the discontinuous parameter\nrepresentation, previous methods have difficulty in effectively learning\ndiscrete facial parameters. T2P, to our best knowledge, is the first method\nthat can handle the optimization of both discrete and continuous parameters.\nExperimental results show that T2P can generate high-quality and vivid game\ncharacters with given text prompts. T2P outperforms other SOTA text-to-3D\ngeneration methods on both objective evaluations and subjective evaluations.\n","authors":["Rui Zhao","Wei Li","Zhipeng Hu","Lincheng Li","Zhengxia Zou","Zhenwei Shi","Changjie Fan"],"pdf_url":"https://arxiv.org/pdf/2303.01311v1.pdf","comment":"Accepted in CVPR 2023"},{"id":"http://arxiv.org/abs/2303.01309v1","updated":"2023-03-02T14:33:43Z","published":"2023-03-02T14:33:43Z","title":"BIFRNet: A Brain-Inspired Feature Restoration DNN for Partially Occluded\n  Image Recognition","summary":"  The partially occluded image recognition (POIR) problem has been a challenge\nfor artificial intelligence for a long time. A common strategy to handle the\nPOIR problem is using the non-occluded features for classification.\nUnfortunately, this strategy will lose effectiveness when the image is severely\noccluded, since the visible parts can only provide limited information. Several\nstudies in neuroscience reveal that feature restoration which fills in the\noccluded information and is called amodal completion is essential for human\nbrains to recognize partially occluded images. However, feature restoration is\ncommonly ignored by CNNs, which may be the reason why CNNs are ineffective for\nthe POIR problem. Inspired by this, we propose a novel brain-inspired feature\nrestoration network (BIFRNet) to solve the POIR problem. It mimics a ventral\nvisual pathway to extract image features and a dorsal visual pathway to\ndistinguish occluded and visible image regions. In addition, it also uses a\nknowledge module to store object prior knowledge and uses a completion module\nto restore occluded features based on visible features and prior knowledge.\nThorough experiments on synthetic and real-world occluded image datasets show\nthat BIFRNet outperforms the existing methods in solving the POIR problem.\nEspecially for severely occluded images, BIRFRNet surpasses other methods by a\nlarge margin and is close to the human brain performance. Furthermore, the\nbrain-inspired design makes BIFRNet more interpretable.\n","authors":["Jiahong Zhang","Lihong Cao","Qiuxia Lai","Binyao Li","Yunxiao Qin"],"pdf_url":"https://arxiv.org/pdf/2303.01309v1.pdf","comment":"This paper has been accepted by AAAI-2023"},{"id":"http://arxiv.org/abs/2303.01295v1","updated":"2023-03-02T14:21:54Z","published":"2023-03-02T14:21:54Z","title":"Iterative Assessment and Improvement of DNN Operational Accuracy","summary":"  Deep Neural Networks (DNN) are nowadays largely adopted in many application\ndomains thanks to their human-like, or even superhuman, performance in specific\ntasks. However, due to unpredictable/unconsidered operating conditions,\nunexpected failures show up on field, making the performance of a DNN in\noperation very different from the one estimated prior to release. In the life\ncycle of DNN systems, the assessment of accuracy is typically addressed in two\nways: offline, via sampling of operational inputs, or online, via\npseudo-oracles. The former is considered more expensive due to the need for\nmanual labeling of the sampled inputs. The latter is automatic but less\naccurate. We believe that emerging iterative industrial-strength life cycle\nmodels for Machine Learning systems, like MLOps, offer the possibility to\nleverage inputs observed in operation not only to provide faithful estimates of\na DNN accuracy, but also to improve it through remodeling/retraining actions.\nWe propose DAIC (DNN Assessment and Improvement Cycle), an approach which\ncombines ''low-cost'' online pseudo-oracles and ''high-cost'' offline sampling\ntechniques to estimate and improve the operational accuracy of a DNN in the\niterations of its life cycle. Preliminary results show the benefits of\ncombining the two approaches and integrating them in the DNN life cycle.\n","authors":["Antonio Guerriero","Roberto Pietrantuono","Stefano Russo"],"pdf_url":"https://arxiv.org/pdf/2303.01295v1.pdf","comment":"Paper accepted at 45th International Conference on Software\n  Engineering (ICSE'23 NIER), May 2023"},{"id":"http://arxiv.org/abs/2111.03815v2","updated":"2023-03-02T14:18:57Z","published":"2021-11-06T06:53:40Z","title":"Order-Guided Disentangled Representation Learning for Ulcerative Colitis\n  Classification with Limited Labels","summary":"  Ulcerative colitis (UC) classification, which is an important task for\nendoscopic diagnosis, involves two main difficulties. First, endoscopic images\nwith the annotation about UC (positive or negative) are usually limited.\nSecond, they show a large variability in their appearance due to the location\nin the colon. Especially, the second difficulty prevents us from using existing\nsemi-supervised learning techniques, which are the common remedy for the first\ndifficulty. In this paper, we propose a practical semi-supervised learning\nmethod for UC classification by newly exploiting two additional features, the\nlocation in a colon (e.g., left colon) and image capturing order, both of which\nare often attached to individual images in endoscopic image sequences. The\nproposed method can extract the essential information of UC classification\nefficiently by a disentanglement process with those features. Experimental\nresults demonstrate that the proposed method outperforms several existing\nsemi-supervised learning methods in the classification task, even with a small\nnumber of annotated images.\n","authors":["Shota Harada","Ryoma Bise","Hideaki Hayashi","Kiyohito Tanaka","Seiichi Uchida"],"pdf_url":"https://arxiv.org/pdf/2111.03815v2.pdf","comment":"Accepted by MICCAI 2021"},{"id":"http://arxiv.org/abs/2205.14589v2","updated":"2023-03-02T14:10:40Z","published":"2022-05-29T07:32:00Z","title":"Masked Distillation with Receptive Tokens","summary":"  Distilling from the feature maps can be fairly effective for dense prediction\ntasks since both the feature discriminability and localization priors can be\nwell transferred. However, not every pixel contributes equally to the\nperformance, and a good student should learn from what really matters to the\nteacher. In this paper, we introduce a learnable embedding dubbed receptive\ntoken to localize those pixels of interests (PoIs) in the feature map, with a\ndistillation mask generated via pixel-wise attention. Then the distillation\nwill be performed on the mask via pixel-wise reconstruction. In this way, a\ndistillation mask actually indicates a pattern of pixel dependencies within\nfeature maps of teacher. We thus adopt multiple receptive tokens to investigate\nmore sophisticated and informative pixel dependencies to further enhance the\ndistillation. To obtain a group of masks, the receptive tokens are learned via\nthe regular task loss but with teacher fixed, and we also leverage a Dice loss\nto enrich the diversity of learned masks. Our method dubbed MasKD is simple and\npractical, and needs no priors of tasks in application. Experiments show that\nour MasKD can achieve state-of-the-art performance consistently on object\ndetection and semantic segmentation benchmarks. Code is available at:\nhttps://github.com/hunto/MasKD .\n","authors":["Tao Huang","Yuan Zhang","Shan You","Fei Wang","Chen Qian","Jian Cao","Chang Xu"],"pdf_url":"https://arxiv.org/pdf/2205.14589v2.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01283v1","updated":"2023-03-02T14:07:36Z","published":"2023-03-02T14:07:36Z","title":"Cluster-Guided Semi-Supervised Domain Adaptation for Imbalanced Medical\n  Image Classification","summary":"  Semi-supervised domain adaptation is a technique to build a classifier for a\ntarget domain by modifying a classifier in another (source) domain using many\nunlabeled samples and a small number of labeled samples from the target domain.\nIn this paper, we develop a semi-supervised domain adaptation method, which has\nrobustness to class-imbalanced situations, which are common in medical image\nclassification tasks. For robustness, we propose a weakly-supervised clustering\npipeline to obtain high-purity clusters and utilize the clusters in\nrepresentation learning for domain adaptation. The proposed method showed\nstate-of-the-art performance in the experiment using severely class-imbalanced\npathological image patches.\n","authors":["Shota Harada","Ryoma Bise","Kengo Araki","Akihiko Yoshizawa","Kazuhiro Terada","Mariyo Kurata","Naoki Nakajima","Hiroyuki Abe","Tetsuo Ushiku","Seiichi Uchida"],"pdf_url":"https://arxiv.org/pdf/2303.01283v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10518v3","updated":"2023-03-02T14:06:01Z","published":"2023-02-21T08:48:27Z","title":"USR: Unsupervised Separated 3D Garment and Human Reconstruction via\n  Geometry and Semantic Consistency","summary":"  Dressed people reconstruction from images is a popular task with promising\napplications in the creative media and game industry. However, most existing\nmethods reconstruct the human body and garments as a whole with the supervision\nof 3D models, which hinders the downstream interaction tasks and requires\nhard-to-obtain data. To address these issues, we propose an unsupervised\nseparated 3D garments and human reconstruction model (USR), which reconstructs\nthe human body and authentic textured clothes in layers without 3D models. More\nspecifically, our method proposes a generalized surface-aware neural radiance\nfield to learn the mapping between sparse multi-view images and geometries of\nthe dressed people. Based on the full geometry, we introduce a Semantic and\nConfidence Guided Separation strategy (SCGS) to detect, segment, and\nreconstruct the clothes layer, leveraging the consistency between 2D semantic\nand 3D geometry. Moreover, we propose a Geometry Fine-tune Module to smooth\nedges. Extensive experiments on our dataset show that comparing with\nstate-of-the-art methods, USR achieves improvements on both geometry and\nappearance reconstruction while supporting generalizing to unseen people in\nreal time. Besides, we also introduce SMPL-D model to show the benefit of the\nseparated modeling of clothes and the human body that allows swapping clothes\nand virtual try-on.\n","authors":["Yue Shi","Yuxuan Xiong","Jingyi Chai","Bingbing Ni","Wenjun Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.10518v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01276v1","updated":"2023-03-02T14:02:16Z","published":"2023-03-02T14:02:16Z","title":"Conflict-Based Cross-View Consistency for Semi-Supervised Semantic\n  Segmentation","summary":"  Semi-supervised semantic segmentation has recently gained increasing research\ninterest as it can reduce the requirement for large-scale fully-annotated\ntraining data by effectively exploiting large amounts of unlabelled data. The\ncurrent methods often suffer from the confirmation bias from the\npseudo-labelling process, which can be alleviated by the co-training framework.\nThe current co-training-based semi-supervised semantic segmentation methods\nrely on hand-crafted perturbations to prevent the different sub-nets from\ncollapsing into each other, but these artificial perturbations cannot lead to\nthe optimal solution. In this work, we propose a new conflict-based cross-view\nconsistency (CCVC) method based on a two-branch co-training framework for\nsemi-supervised semantic segmentation. Our work aims at enforcing the two\nsub-nets to learn informative features from irrelevant views. In particular, we\nfirst propose a new cross-view consistency (CVC) strategy that encourages the\ntwo sub-nets to learn distinct features from the same input by introducing a\nfeature discrepancy loss, while these distinct features are expected to\ngenerate consistent prediction scores of the input. The CVC strategy helps to\nprevent the two sub-nets from stepping into the collapse. In addition, we\nfurther propose a conflict-based pseudo-labelling (CPL) method to guarantee the\nmodel will learn more useful information from conflicting predictions, which\nwill lead to a stable training process. We validate our new semi-supervised\nsemantic segmentation approach on the widely used benchmark datasets PASCAL VOC\n2012 and Cityscapes, where our method achieves new state-of-the-art\nperformance.\n","authors":["Zicheng Wang","Zhen Zhao","Luping Zhou","Dong Xu","Xiaoxia Xing","Xiangyu Kong"],"pdf_url":"https://arxiv.org/pdf/2303.01276v1.pdf","comment":"accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2303.01274v1","updated":"2023-03-02T13:59:07Z","published":"2023-03-02T13:59:07Z","title":"Measuring axiomatic soundness of counterfactual image models","summary":"  We present a general framework for evaluating image counterfactuals. The\npower and flexibility of deep generative models make them valuable tools for\nlearning mechanisms in structural causal models. However, their flexibility\nmakes counterfactual identifiability impossible in the general case. Motivated\nby these issues, we revisit Pearl's axiomatic definition of counterfactuals to\ndetermine the necessary constraints of any counterfactual inference model:\ncomposition, reversibility, and effectiveness. We frame counterfactuals as\nfunctions of an input variable, its parents, and counterfactual parents and use\nthe axiomatic constraints to restrict the set of functions that could represent\nthe counterfactual, thus deriving distance metrics between the approximate and\nideal functions. We demonstrate how these metrics can be used to compare and\nchoose between different approximate counterfactual inference models and to\nprovide insight into a model's shortcomings and trade-offs.\n","authors":["Miguel Monteiro","Fabio De Sousa Ribeiro","Nick Pawlowski","Daniel C. Castro","Ben Glocker"],"pdf_url":"https://arxiv.org/pdf/2303.01274v1.pdf","comment":"Counterfactual inference, Generative Models, Computer Vision,\n  Published in ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01268v1","updated":"2023-03-02T13:53:22Z","published":"2023-03-02T13:53:22Z","title":"Analyzing Effects of Fake Training Data on the Performance of Deep\n  Learning Systems","summary":"  Deep learning models frequently suffer from various problems such as class\nimbalance and lack of robustness to distribution shift. It is often difficult\nto find data suitable for training beyond the available benchmarks. This is\nespecially the case for computer vision models. However, with the advent of\nGenerative Adversarial Networks (GANs), it is now possible to generate\nhigh-quality synthetic data. This synthetic data can be used to alleviate some\nof the challenges faced by deep learning models. In this work we present a\ndetailed analysis of the effect of training computer vision models using\ndifferent proportions of synthetic data along with real (organic) data. We\nanalyze the effect that various quantities of synthetic data, when mixed with\noriginal data, can have on a model's robustness to out-of-distribution data and\nthe general quality of predictions.\n","authors":["Pratinav Seth","Akshat Bhandari","Kumud Lakara"],"pdf_url":"https://arxiv.org/pdf/2303.01268v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2303.01267v1","updated":"2023-03-02T13:51:58Z","published":"2023-03-02T13:51:58Z","title":"Token Contrast for Weakly-Supervised Semantic Segmentation","summary":"  Weakly-Supervised Semantic Segmentation (WSSS) using image-level labels\ntypically utilizes Class Activation Map (CAM) to generate the pseudo labels.\nLimited by the local structure perception of CNN, CAM usually cannot identify\nthe integral object regions. Though the recent Vision Transformer (ViT) can\nremedy this flaw, we observe it also brings the over-smoothing issue, \\ie, the\nfinal patch tokens incline to be uniform. In this work, we propose Token\nContrast (ToCo) to address this issue and further explore the virtue of ViT for\nWSSS. Firstly, motivated by the observation that intermediate layers in ViT can\nstill retain semantic diversity, we designed a Patch Token Contrast module\n(PTC). PTC supervises the final patch tokens with the pseudo token relations\nderived from intermediate layers, allowing them to align the semantic regions\nand thus yield more accurate CAM. Secondly, to further differentiate the\nlow-confidence regions in CAM, we devised a Class Token Contrast module (CTC)\ninspired by the fact that class tokens in ViT can capture high-level semantics.\nCTC facilitates the representation consistency between uncertain local regions\nand global objects by contrasting their class tokens. Experiments on the PASCAL\nVOC and MS COCO datasets show the proposed ToCo can remarkably surpass other\nsingle-stage competitors and achieve comparable performance with\nstate-of-the-art multi-stage methods. Code is available at\nhttps://github.com/rulixiang/ToCo.\n","authors":["Lixiang Ru","Heliang Zheng","Yibing Zhan","Bo Du"],"pdf_url":"https://arxiv.org/pdf/2303.01267v1.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2202.13808v3","updated":"2023-03-02T13:44:43Z","published":"2022-02-28T14:12:00Z","title":"DropIT: Dropping Intermediate Tensors for Memory-Efficient DNN Training","summary":"  A standard hardware bottleneck when training deep neural networks is GPU\nmemory. The bulk of memory is occupied by caching intermediate tensors for\ngradient computation in the backward pass. We propose a novel method to reduce\nthis footprint - Dropping Intermediate Tensors (DropIT). DropIT drops min-k\nelements of the intermediate tensors and approximates gradients from the\nsparsified tensors in the backward pass. Theoretically, DropIT reduces noise on\nestimated gradients and therefore has a higher rate of convergence than\nvanilla-SGD. Experiments show that we can drop up to 90\\% of the intermediate\ntensor elements in fully-connected and convolutional layers while achieving\nhigher testing accuracy for Visual Transformers and Convolutional Neural\nNetworks on various tasks (e.g., classification, object detection, instance\nsegmentation). Our code and models are available at\nhttps://github.com/chenjoya/dropit.\n","authors":["Joya Chen","Kai Xu","Yuhui Wang","Yifei Cheng","Angela Yao"],"pdf_url":"https://arxiv.org/pdf/2202.13808v3.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2212.10390v3","updated":"2023-03-02T13:36:47Z","published":"2022-12-20T16:17:40Z","title":"ADAS: A Simple Active-and-Adaptive Baseline for Cross-Domain 3D Semantic\n  Segmentation","summary":"  State-of-the-art 3D semantic segmentation models are trained on the\noff-the-shelf public benchmarks, but they often face the major challenge when\nthese well-trained models are deployed to a new domain. In this paper, we\npropose an Active-and-Adaptive Segmentation (ADAS) baseline to enhance the weak\ncross-domain generalization ability of a well-trained 3D segmentation model,\nand bridge the point distribution gap between domains. Specifically, before the\ncross-domain adaptation stage begins, ADAS performs an active sampling\noperation to select a maximally-informative subset from both source and target\ndomains for effective adaptation, reducing the adaptation difficulty under 3D\nscenarios. Benefiting from the rise of multi-modal 2D-3D datasets, ADAS\nutilizes a cross-modal attention-based feature fusion module that can extract a\nrepresentative pair of image features and point features to achieve a\nbi-directional image-point feature interaction for better safe adaptation.\nExperimentally, ADAS is verified to be effective in many cross-domain settings\nincluding: 1) Unsupervised Domain Adaptation (UDA), which means that all\nsamples from target domain are unlabeled; 2) Unsupervised Few-shot Domain\nAdaptation (UFDA) which means that only a few unlabeled samples are available\nin the unlabeled target domain; 3) Active Domain Adaptation (ADA) which means\nthat the selected target samples by ADAS are manually annotated. Their results\ndemonstrate that ADAS achieves a significant accuracy gain by easily coupling\nADAS with self-training methods or off-the-shelf UDA works.\n","authors":["Ben Fei","Siyuan Huang","Jiakang Yuan","Botian Shi","Bo Zhang","Tao Chen","Min Dou","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2212.10390v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12245v2","updated":"2023-03-02T13:36:28Z","published":"2023-02-23T18:58:57Z","title":"Set Features for Fine-grained Anomaly Detection","summary":"  Fine-grained anomaly detection has recently been dominated by segmentation\nbased approaches. These approaches first classify each element of the sample\n(e.g., image patch) as normal or anomalous and then classify the entire sample\nas anomalous if it contains anomalous elements. However, such approaches do not\nextend to scenarios where the anomalies are expressed by an unusual combination\nof normal elements. In this paper, we overcome this limitation by proposing set\nfeatures that model each sample by the distribution its elements. We compute\nthe anomaly score of each sample using a simple density estimation method. Our\nsimple-to-implement approach outperforms the state-of-the-art in image-level\nlogical anomaly detection (+3.4%) and sequence-level time-series anomaly\ndetection (+2.4%).\n","authors":["Niv Cohen","Issar Tzachor","Yedid Hoshen"],"pdf_url":"https://arxiv.org/pdf/2302.12245v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01256v1","updated":"2023-03-02T13:36:28Z","published":"2023-03-02T13:36:28Z","title":"Choosing Public Datasets for Private Machine Learning via Gradient\n  Subspace Distance","summary":"  Differentially private stochastic gradient descent privatizes model training\nby injecting noise into each iteration, where the noise magnitude increases\nwith the number of model parameters. Recent works suggest that we can reduce\nthe noise by leveraging public data for private machine learning, by projecting\ngradients onto a subspace prescribed by the public data. However, given a\nchoice of public datasets, it is not a priori clear which one may be most\nappropriate for the private task. We give an algorithm for selecting a public\ndataset by measuring a low-dimensional subspace distance between gradients of\nthe public and private examples. We provide theoretical analysis demonstrating\nthat the excess risk scales with this subspace distance. This distance is easy\nto compute and robust to modifications in the setting. Empirical evaluation\nshows that trained model accuracy is monotone in this distance.\n","authors":["Xin Gu","Gautam Kamath","Zhiwei Steven Wu"],"pdf_url":"https://arxiv.org/pdf/2303.01256v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01239v1","updated":"2023-03-02T13:28:50Z","published":"2023-03-02T13:28:50Z","title":"MixPHM: Redundancy-Aware Parameter-Efficient Tuning for Low-Resource\n  Visual Question Answering","summary":"  Recently, finetuning pretrained vision-language models (VLMs) has become one\nprevailing paradigm to achieve state-of-the-art performance in VQA. However, as\nVLMs scale, it becomes computationally expensive, storage inefficient, and\nprone to overfitting to tune full model parameters for a specific task in\nlow-resource settings. Although current parameter-efficient tuning methods\ndramatically reduce the number of tunable parameters, there still exists a\nsignificant performance gap with full finetuning. In this paper, we propose\n\\textbf{MixPHM}, a redundancy-aware parameter-efficient tuning method that\noutperforms full finetuning in low-resource VQA. Specifically, MixPHM is a\nlightweight module implemented by multiple PHM-experts in a mixture-of-experts\nmanner. To reduce parameter redundancy, we reparameterize expert weights in a\nlow-rank subspace and share part of the weights inside and across MixPHM.\nMoreover, based on our quantitative analysis of representation redundancy, we\npropose \\textbf{redundancy regularization}, which facilitates MixPHM to reduce\ntask-irrelevant redundancy while promoting task-relevant correlation.\nExperiments conducted on VQA v2, GQA, and OK-VQA with different low-resource\nsettings show that our MixPHM outperforms state-of-the-art parameter-efficient\nmethods and is the only one consistently surpassing full finetuning.\n","authors":["Jingjing Jiang","Nanning Zheng"],"pdf_url":"https://arxiv.org/pdf/2303.01239v1.pdf","comment":"14 pages, 6 figures, 9 tables. Accepted by CVPR 2023. Code will be\n  available at \\url{https://github.com/jingjing12110/MixPHM}"},{"id":"http://arxiv.org/abs/2303.01237v1","updated":"2023-03-02T13:28:07Z","published":"2023-03-02T13:28:07Z","title":"FlowFormer++: Masked Cost Volume Autoencoding for Pretraining Optical\n  Flow Estimation","summary":"  FlowFormer introduces a transformer architecture into optical flow estimation\nand achieves state-of-the-art performance. The core component of FlowFormer is\nthe transformer-based cost-volume encoder. Inspired by the recent success of\nmasked autoencoding (MAE) pretraining in unleashing transformers' capacity of\nencoding visual representation, we propose Masked Cost Volume Autoencoding\n(MCVA) to enhance FlowFormer by pretraining the cost-volume encoder with a\nnovel MAE scheme. Firstly, we introduce a block-sharing masking strategy to\nprevent masked information leakage, as the cost maps of neighboring source\npixels are highly correlated. Secondly, we propose a novel pre-text\nreconstruction task, which encourages the cost-volume encoder to aggregate\nlong-range information and ensures pretraining-finetuning consistency. We also\nshow how to modify the FlowFormer architecture to accommodate masks during\npretraining. Pretrained with MCVA, FlowFormer++ ranks 1st among published\nmethods on both Sintel and KITTI-2015 benchmarks. Specifically, FlowFormer++\nachieves 1.07 and 1.94 average end-point error (AEPE) on the clean and final\npass of Sintel benchmark, leading to 7.76\\% and 7.18\\% error reductions from\nFlowFormer. FlowFormer++ obtains 4.52 F1-all on the KITTI-2015 test set,\nimproving FlowFormer by 0.16.\n","authors":["Xiaoyu Shi","Zhaoyang Huang","Dasong Li","Manyuan Zhang","Ka Chun Cheung","Simon See","Hongwei Qin","Jifeng Dai","Hongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2303.01237v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01219v1","updated":"2023-03-02T13:04:33Z","published":"2023-03-02T13:04:33Z","title":"A Coarse to Fine Framework for Object Detection in High Resolution Image","summary":"  Object detection is a fundamental problem in computer vision, aiming at\nlocating and classifying objects in image. Although current devices can easily\ntake very high-resolution images, current approaches of object detection seldom\nconsider detecting tiny object or the large scale variance problem in high\nresolution images. In this paper, we introduce a simple yet efficient approach\nthat improves accuracy of object detection especially for small objects and\nlarge scale variance scene while reducing the computational cost in high\nresolution image. Inspired by observing that overall detection accuracy is\nreduced if the image is properly down-sampled but the recall rate is not\nsignificantly reduced. Besides, small objects can be better detected by\ninputting high-resolution images even if using lightweight detector. We propose\na cluster-based coarse-to-fine object detection framework to enhance the\nperformance for detecting small objects while ensure the accuracy of large\nobjects in high-resolution images. For the first stage, we perform coarse\ndetection on the down-sampled image and center localization of small objects by\nlightweight detector on high-resolution image, and then obtains image chips\nbased on cluster region generation method by coarse detection and center\nlocalization results, and further sends chips to the second stage detector for\nfine detection. Finally, we merge the coarse detection and fine detection\nresults. Our approach can make good use of the sparsity of the objects and the\ninformation in high-resolution image, thereby making the detection more\nefficient. Experiment results show that our proposed approach achieves\npromising performance compared with other state-of-the-art detectors.\n","authors":["Jinyan Liu","Jie Chen"],"pdf_url":"https://arxiv.org/pdf/2303.01219v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.11436v2","updated":"2023-03-02T12:56:46Z","published":"2022-11-21T13:23:52Z","title":"N-Gram in Swin Transformers for Efficient Lightweight Image\n  Super-Resolution","summary":"  While some studies have proven that Swin Transformer (SwinT) with window\nself-attention (WSA) is suitable for single image super-resolution (SR), SwinT\nignores the broad regions for reconstructing high-resolution images due to\nwindow and shift size. In addition, many deep learning SR methods suffer from\nintensive computations. To address these problems, we introduce the N-Gram\ncontext to the image domain for the first time in history. We define N-Gram as\nneighboring local windows in SwinT, which differs from text analysis that views\nN-Gram as consecutive characters or words. N-Grams interact with each other by\nsliding-WSA, expanding the regions seen to restore degraded pixels. Using the\nN-Gram context, we propose NGswin, an efficient SR network with SCDP bottleneck\ntaking all outputs of the hierarchical encoder. Experimental results show that\nNGswin achieves competitive performance while keeping an efficient structure,\ncompared with previous leading methods. Moreover, we also improve other\nSwinT-based SR methods with the N-Gram context, thereby building an enhanced\nmodel: SwinIR-NG. Our improved SwinIR-NG outperforms the current best\nlightweight SR approaches and establishes state-of-the-art results. Codes will\nbe available soon.\n","authors":["Haram Choi","Jeongmin Lee","Jihoon Yang"],"pdf_url":"https://arxiv.org/pdf/2211.11436v2.pdf","comment":"Accepted at CVPR 2023. Codes are available at\n  https://github.com/rami0205/NGramSwin"},{"id":"http://arxiv.org/abs/2303.01212v1","updated":"2023-03-02T12:52:46Z","published":"2023-03-02T12:52:46Z","title":"Grid-Centric Traffic Scenario Perception for Autonomous Driving: A\n  Comprehensive Review","summary":"  Grid-centric perception is a crucial field for mobile robot perception and\nnavigation. Nonetheless, grid-centric perception is less prevalent than\nobject-centric perception for autonomous driving as autonomous vehicles need to\naccurately perceive highly dynamic, large-scale outdoor traffic scenarios and\nthe complexity and computational costs of grid-centric perception are high. The\nrapid development of deep learning techniques and hardware gives fresh insights\ninto the evolution of grid-centric perception and enables the deployment of\nmany real-time algorithms. Current industrial and academic research\ndemonstrates the great advantages of grid-centric perception, such as\ncomprehensive fine-grained environmental representation, greater robustness to\nocclusion, more efficient sensor fusion, and safer planning policies. Given the\nlack of current surveys for this rapidly expanding field, we present a\nhierarchically-structured review of grid-centric perception for autonomous\nvehicles. We organize previous and current knowledge of occupancy grid\ntechniques and provide a systematic in-depth analysis of algorithms in terms of\nthree aspects: feature representation, data utility, and applications in\nautonomous driving systems. Lastly, we present a summary of the current\nresearch trend and provide some probable future outlooks.\n","authors":["Yining Shi","Kun Jiang","Jiusi Li","Junze Wen","Zelin Qian","Mengmeng Yang","Ke Wang","Diange Yang"],"pdf_url":"https://arxiv.org/pdf/2303.01212v1.pdf","comment":"The first version of the review. Comments are welcomed"},{"id":"http://arxiv.org/abs/2303.01201v1","updated":"2023-03-02T12:34:38Z","published":"2023-03-02T12:34:38Z","title":"Average of Pruning: Improving Performance and Stability of\n  Out-of-Distribution Detection","summary":"  Detecting Out-of-distribution (OOD) inputs have been a critical issue for\nneural networks in the open world. However, the unstable behavior of OOD\ndetection along the optimization trajectory during training has not been\nexplored clearly. In this paper, we first find the performance of OOD detection\nsuffers from overfitting and instability during training: 1) the performance\ncould decrease when the training error is near zero, and 2) the performance\nwould vary sharply in the final stage of training. Based on our findings, we\npropose Average of Pruning (AoP), consisting of model averaging and pruning, to\nmitigate the unstable behaviors. Specifically, model averaging can help achieve\na stable performance by smoothing the landscape, and pruning is certified to\neliminate the overfitting by eliminating redundant features. Comprehensive\nexperiments on various datasets and architectures are conducted to verify the\neffectiveness of our method.\n","authors":["Zhen Cheng","Fei Zhu","Xu-Yao Zhang","Cheng-Lin Liu"],"pdf_url":"https://arxiv.org/pdf/2303.01201v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.12502v2","updated":"2023-03-02T12:33:10Z","published":"2022-05-25T05:40:00Z","title":"The Dialog Must Go On: Improving Visual Dialog via Generative\n  Self-Training","summary":"  Visual dialog (VisDial) is a task of answering a sequence of questions\ngrounded in an image, using the dialog history as context. Prior work has\ntrained the dialog agents solely on VisDial data via supervised learning or\nleveraged pre-training on related vision-and-language datasets. This paper\npresents a semi-supervised learning approach for visually-grounded dialog,\ncalled Generative Self-Training (GST), to leverage unlabeled images on the Web.\nSpecifically, GST first retrieves in-domain images through out-of-distribution\ndetection and generates synthetic dialogs regarding the images via multimodal\nconditional text generation. GST then trains a dialog agent on the synthetic\nand the original VisDial data. As a result, GST scales the amount of training\ndata up to an order of magnitude that of VisDial (1.2M to 12.9M QA data). For\nrobust training of the synthetic dialogs, we also propose perplexity-based data\nselection and multimodal consistency regularization. Evaluation on VisDial v1.0\nand v0.9 datasets shows that GST achieves new state-of-the-art results on both\ndatasets. We further observe the robustness of GST against both visual and\ntextual adversarial attacks. Finally, GST yields strong performance gains in\nthe low-data regime. Code is available at\nhttps://github.com/gicheonkang/gst-visdial.\n","authors":["Gi-Cheon Kang","Sungdong Kim","Jin-Hwa Kim","Donghyun Kwak","Byoung-Tak Zhang"],"pdf_url":"https://arxiv.org/pdf/2205.12502v2.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2303.01196v1","updated":"2023-03-02T12:22:51Z","published":"2023-03-02T12:22:51Z","title":"STDepthFormer: Predicting Spatio-temporal Depth from Video with a\n  Self-supervised Transformer Model","summary":"  In this paper, a self-supervised model that simultaneously predicts a\nsequence of future frames from video-input with a novel spatial-temporal\nattention (ST) network is proposed. The ST transformer network allows\nconstraining both temporal consistency across future frames whilst constraining\nconsistency across spatial objects in the image at different scales. This was\nnot the case in prior works for depth prediction, which focused on predicting a\nsingle frame as output. The proposed model leverages prior scene knowledge such\nas object shape and texture similar to single-image depth inference methods,\nwhilst also constraining the motion and geometry from a sequence of input\nimages. Apart from the transformer architecture, one of the main contributions\nwith respect to prior works lies in the objective function that enforces\nspatio-temporal consistency across a sequence of output frames rather than a\nsingle output frame. As will be shown, this results in more accurate and robust\ndepth sequence forecasting. The model achieves highly accurate depth\nforecasting results that outperform existing baselines on the KITTI benchmark.\nExtensive ablation studies were performed to assess the effectiveness of the\nproposed techniques. One remarkable result of the proposed model is that it is\nimplicitly capable of forecasting the motion of objects in the scene, rather\nthan requiring complex models involving multi-object detection, segmentation\nand tracking.\n","authors":["Houssem Boulahbal","Adrian Voicila","Andrew Comport"],"pdf_url":"https://arxiv.org/pdf/2303.01196v1.pdf","comment":"Submitted to IROS 2023"},{"id":"http://arxiv.org/abs/2211.11393v2","updated":"2023-03-02T12:12:12Z","published":"2022-11-21T12:07:05Z","title":"TFormer: A throughout fusion transformer for multi-modal skin lesion\n  diagnosis","summary":"  Multi-modal skin lesion diagnosis (MSLD) has achieved remarkable success by\nmodern computer-aided diagnosis (CAD) technology based on deep convolutions.\nHowever, the information aggregation across modalities in MSLD remains\nchallenging due to severity unaligned spatial resolution (e.g., dermoscopic\nimage and clinical image) and heterogeneous data (e.g., dermoscopic image and\npatients' meta-data). Limited by the intrinsic local attention, most recent\nMSLD pipelines using pure convolutions struggle to capture representative\nfeatures in shallow layers, thus the fusion across different modalities is\nusually done at the end of the pipelines, even at the last layer, leading to an\ninsufficient information aggregation. To tackle the issue, we introduce a pure\ntransformer-based method, which we refer to as ``Throughout Fusion Transformer\n(TFormer)'', for sufficient information integration in MSLD. Different from the\nexisting approaches with convolutions, the proposed network leverages\ntransformer as feature extraction backbone, bringing more representative\nshallow features. We then carefully design a stack of dual-branch hierarchical\nmulti-modal transformer (HMT) blocks to fuse information across different image\nmodalities in a stage-by-stage way. With the aggregated information of image\nmodalities, a multi-modal transformer post-fusion (MTP) block is designed to\nintegrate features across image and non-image data. Such a strategy that\ninformation of the image modalities is firstly fused then the heterogeneous\nones enables us to better divide and conquer the two major challenges while\nensuring inter-modality dynamics are effectively modeled.\n","authors":["Yilan Zhang","Fengying Xie","Jianqi Chen"],"pdf_url":"https://arxiv.org/pdf/2211.11393v2.pdf","comment":"16 pages, 6 figures"},{"id":"http://arxiv.org/abs/2303.01178v1","updated":"2023-03-02T11:47:55Z","published":"2023-03-02T11:47:55Z","title":"Augmenting Medical Imaging: A Comprehensive Catalogue of 65 Techniques\n  for Enhanced Data Analysis","summary":"  In the realm of medical imaging, the training of machine learning models\nnecessitates a large and varied training dataset to ensure robustness and\ninteroperability. However, acquiring such diverse and heterogeneous data can be\ndifficult due to the need for expert labeling of each image and privacy\nconcerns associated with medical data. To circumvent these challenges, data\naugmentation has emerged as a promising and cost-effective technique for\nincreasing the size and diversity of the training dataset. In this study, we\nprovide a comprehensive review of the specific data augmentation techniques\nemployed in medical imaging and explore their benefits. We conducted an\nin-depth study of all data augmentation techniques used in medical imaging,\nidentifying 11 different purposes and collecting 65 distinct techniques. The\ntechniques were operationalized into spatial transformation-based, color and\ncontrast adjustment-based, noise-based, deformation-based, data mixing-based,\nfilters and mask-based, division-based, multi-scale and multi-view-based, and\nmeta-learning-based categories. We observed that some techniques require manual\nspecification of all parameters, while others rely on automation to adjust the\ntype and magnitude of augmentation based on task requirements. The utilization\nof these techniques enables the development of more robust models that can be\napplied in domains with limited or challenging data availability. It is\nexpected that the list of available techniques will expand in the future,\nproviding researchers with additional options to consider.\n","authors":["Manuel Cossio"],"pdf_url":"https://arxiv.org/pdf/2303.01178v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2303.01166v1","updated":"2023-03-02T11:15:59Z","published":"2023-03-02T11:15:59Z","title":"BPT: Binary Point Cloud Transformer for Place Recognition","summary":"  Place recognition, an algorithm to recognize the re-visited places, plays the\nrole of back-end optimization trigger in a full SLAM system. Many works\nequipped with deep learning tools, such as MLP, CNN, and transformer, have\nachieved great improvements in this research field. Point cloud transformer is\none of the excellent frameworks for place recognition applied in robotics, but\nwith large memory consumption and expensive computation, it is adverse to\nwidely deploy the various point cloud transformer networks in mobile or\nembedded devices. To solve this issue, we propose a binary point cloud\ntransformer for place recognition. As a result, a 32-bit full-precision model\ncan be reduced to a 1-bit model with less memory occupation and faster\nbinarized bitwise operations. To our best knowledge, this is the first binary\npoint cloud transformer that can be deployed on mobile devices for online\napplications such as place recognition. Experiments on several standard\nbenchmarks demonstrate that the proposed method can get comparable results with\nthe corresponding full-precision transformer model and even outperform some\nfull-precision deep learning methods. For example, the proposed method achieves\n93.28% at the top @1% and 85.74% at the top @1% on the Oxford RobotCar dataset\nin terms of the metric of the average recall rate. Meanwhile, the size and\nfloating point operations of the model with the same transformer structure\nreduce 56.1% and 34.1% respectively from original precision to binary\nprecision.\n","authors":["Zhixing Hou","Yuzhang Shang","Tian Gao","Yan Yan"],"pdf_url":"https://arxiv.org/pdf/2303.01166v1.pdf","comment":"Submitted to the IEEE/RSJ International Conference on Intelligent\n  Robots (IROS 2023)"},{"id":"http://arxiv.org/abs/2303.01147v1","updated":"2023-03-02T10:52:30Z","published":"2023-03-02T10:52:30Z","title":"GeoLab: Geometry-based Tractography Parcellation of Superficial White\n  Matter","summary":"  Superficial white matter (SWM) has been less studied than long-range\nconnections despite being of interest to clinical research, andfew tractography\nparcellation methods have been adapted to SWM. Here, we propose an efficient\ngeometry-based parcellation method (GeoLab) that allows high-performance\nsegmentation of hundreds of short white matter bundles from a subject. This\nmethod has been designed for the SWM atlas of EBRAINS European infrastructure,\nwhich is composed of 657 bundles. The atlas projection relies on the\nprecomputed statistics of six bundle-specific geometrical properties of atlas\nstreamlines. In the spirit of RecoBundles, a global and local streamline-based\nregistration (SBR) is used to align the subject to the atlas space. Then, the\nstreamlines are labeled taking into account the six geometrical parameters\ndescribing the similarity to the streamlines in the model bundle. Compared to\nother state-of-the-art methods, GeoLab allows the extraction of more bundles\nwith a higher number of streamlines.\n","authors":["Nabil Vindas","Nicole Labra Avila","Fan Zhang","Tengfei Xue","Lauren J. O'Donnell","Jean-François Mangin"],"pdf_url":"https://arxiv.org/pdf/2303.01147v1.pdf","comment":"Accepted by the ISBI 2023 conference, 5 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2212.14441v3","updated":"2023-03-02T10:48:12Z","published":"2022-12-29T19:32:20Z","title":"Fruit Ripeness Classification: a Survey","summary":"  Fruit is a key crop in worldwide agriculture feeding millions of people. The\nstandard supply chain of fruit products involves quality checks to guarantee\nfreshness, taste, and, most of all, safety. An important factor that determines\nfruit quality is its stage of ripening. This is usually manually classified by\nfield experts, making it a labor-intensive and error-prone process. Thus, there\nis an arising need for automation in fruit ripeness classification. Many\nautomatic methods have been proposed that employ a variety of feature\ndescriptors for the food item to be graded. Machine learning and deep learning\ntechniques dominate the top-performing methods. Furthermore, deep learning can\noperate on raw data and thus relieve the users from having to compute complex\nengineered features, which are often crop-specific. In this survey, we review\nthe latest methods proposed in the literature to automatize fruit ripeness\nclassification, highlighting the most common feature descriptors they operate\non.\n","authors":["Matteo Rizzo","Matteo Marcuzzo","Alessandro Zangari","Andrea Gasparetto","Andrea Albarelli"],"pdf_url":"https://arxiv.org/pdf/2212.14441v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00232v2","updated":"2023-03-02T10:02:03Z","published":"2023-03-01T04:52:49Z","title":"Towards more precise automatic analysis: a comprehensive survey of deep\n  learning-based multi-organ segmentation","summary":"  Accurate segmentation of multiple organs of the head, neck, chest, and\nabdomen from medical images is an essential step in computer-aided diagnosis,\nsurgical navigation, and radiation therapy. In the past few years, with a\ndata-driven feature extraction approach and end-to-end training, automatic deep\nlearning-based multi-organ segmentation method has far outperformed traditional\nmethods and become a new research topic. This review systematically summarizes\nthe latest research in this field. For the first time, from the perspective of\nfull and imperfect annotation, we comprehensively compile 161 studies on deep\nlearning-based multi-organ segmentation in multiple regions such as the head\nand neck, chest, and abdomen, containing a total of 214 related references. The\nmethod based on full annotation summarizes the existing methods from four\naspects: network architecture, network dimension, network dedicated modules,\nand network loss function. The method based on imperfect annotation summarizes\nthe existing methods from two aspects: weak annotation-based methods and semi\nannotation-based methods. We also summarize frequently used datasets for\nmulti-organ segmentation and discuss new challenges and new research trends in\nthis field.\n","authors":["Xiaoyu Liu","Linhao Qu","Ziyue Xie","Jiayue Zhao","Yonghong Shi","Zhijian Song"],"pdf_url":"https://arxiv.org/pdf/2303.00232v2.pdf","comment":"25 pages, 9 figures, 16 tabels"},{"id":"http://arxiv.org/abs/2303.01112v1","updated":"2023-03-02T09:47:28Z","published":"2023-03-02T09:47:28Z","title":"Visual Atoms: Pre-training Vision Transformers with Sinusoidal Waves","summary":"  Formula-driven supervised learning (FDSL) has been shown to be an effective\nmethod for pre-training vision transformers, where ExFractalDB-21k was shown to\nexceed the pre-training effect of ImageNet-21k. These studies also indicate\nthat contours mattered more than textures when pre-training vision\ntransformers. However, the lack of a systematic investigation as to why these\ncontour-oriented synthetic datasets can achieve the same accuracy as real\ndatasets leaves much room for skepticism. In the present work, we develop a\nnovel methodology based on circular harmonics for systematically investigating\nthe design space of contour-oriented synthetic datasets. This allows us to\nefficiently search the optimal range of FDSL parameters and maximize the\nvariety of synthetic images in the dataset, which we found to be a critical\nfactor. When the resulting new dataset VisualAtom-21k is used for pre-training\nViT-Base, the top-1 accuracy reached 83.7% when fine-tuning on ImageNet-1k.\nThis is close to the top-1 accuracy (84.2%) achieved by JFT-300M pre-training,\nwhile the number of images is 1/14. Unlike JFT-300M which is a static dataset,\nthe quality of synthetic datasets will continue to improve, and the current\nwork is a testament to this possibility. FDSL is also free of the common issues\nassociated with real images, e.g. privacy/copyright issues, labeling\ncosts/errors, and ethical biases.\n","authors":["Sora Takashima","Ryo Hayamizu","Nakamasa Inoue","Hirokatsu Kataoka","Rio Yokota"],"pdf_url":"https://arxiv.org/pdf/2303.01112v1.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2210.14648v3","updated":"2023-03-02T09:42:58Z","published":"2022-10-26T11:49:30Z","title":"Masked Modeling Duo: Learning Representations by Encouraging Both\n  Networks to Model the Input","summary":"  Masked Autoencoders is a simple yet powerful self-supervised learning method.\nHowever, it learns representations indirectly by reconstructing masked input\npatches. Several methods learn representations directly by predicting\nrepresentations of masked patches; however, we think using all patches to\nencode training signal representations is suboptimal. We propose a new method,\nMasked Modeling Duo (M2D), that learns representations directly while obtaining\ntraining signals using only masked patches. In the M2D, the online network\nencodes visible patches and predicts masked patch representations, and the\ntarget network, a momentum encoder, encodes masked patches. To better predict\ntarget representations, the online network should model the input well, while\nthe target network should also model it well to agree with online predictions.\nThen the learned representations should better model the input. We validated\nthe M2D by learning general-purpose audio representations, and M2D set new\nstate-of-the-art performance on tasks such as UrbanSound8K, VoxCeleb1,\nAudioSet20K, GTZAN, and SpeechCommandsV2. We additionally validate the\neffectiveness of M2D for images using ImageNet-1K in the appendix.\n","authors":["Daisuke Niizumi","Daiki Takeuchi","Yasunori Ohishi","Noboru Harada","Kunio Kashino"],"pdf_url":"https://arxiv.org/pdf/2210.14648v3.pdf","comment":"6 pages, 3 figures, and 6 tables. To appear at ICASSP2023"},{"id":"http://arxiv.org/abs/2303.01105v1","updated":"2023-03-02T09:37:56Z","published":"2023-03-02T09:37:56Z","title":"Evidence-empowered Transfer Learning for Alzheimer's Disease","summary":"  Transfer learning has been widely utilized to mitigate the data scarcity\nproblem in the field of Alzheimer's disease (AD). Conventional transfer\nlearning relies on re-using models trained on AD-irrelevant tasks such as\nnatural image classification. However, it often leads to negative transfer due\nto the discrepancy between the non-medical source and target medical domains.\nTo address this, we present evidence-empowered transfer learning for AD\ndiagnosis. Unlike conventional approaches, we leverage an AD-relevant auxiliary\ntask, namely morphological change prediction, without requiring additional MRI\ndata. In this auxiliary task, the diagnosis model learns the evidential and\ntransferable knowledge from morphological features in MRI scans. Experimental\nresults demonstrate that our framework is not only effective in improving\ndetection performance regardless of model capacity, but also more\ndata-efficient and faithful.\n","authors":["Kai Tzu-iunn Ong","Hana Kim","Minjin Kim","Jinseong Jang","Beomseok Sohn","Yoon Seong Choi","Dosik Hwang","Seong Jae Hwang","Jinyoung Yeo"],"pdf_url":"https://arxiv.org/pdf/2303.01105v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01099v1","updated":"2023-03-02T09:32:32Z","published":"2023-03-02T09:32:32Z","title":"Multi-Head Multi-Loss Model Calibration","summary":"  Delivering meaningful uncertainty estimates is essential for a successful\ndeployment of machine learning models in the clinical practice. A central\naspect of uncertainty quantification is the ability of a model to return\npredictions that are well-aligned with the actual probability of the model\nbeing correct, also known as model calibration. Although many methods have been\nproposed to improve calibration, no technique can match the simple, but\nexpensive approach of training an ensemble of deep neural networks. In this\npaper we introduce a form of simplified ensembling that bypasses the costly\ntraining and inference of deep ensembles, yet it keeps its calibration\ncapabilities. The idea is to replace the common linear classifier at the end of\na network by a set of heads that are supervised with different loss functions\nto enforce diversity on their predictions. Specifically, each head is trained\nto minimize a weighted Cross-Entropy loss, but the weights are different among\nthe different branches. We show that the resulting averaged predictions can\nachieve excellent calibration without sacrificing accuracy in two challenging\ndatasets for histopathological and endoscopic image classification. Our\nexperiments indicate that Multi-Head Multi-Loss classifiers are inherently\nwell-calibrated, outperforming other recent calibration techniques and even\nchallenging Deep Ensembles' performance. Code to reproduce our experiments can\nbe found at \\url{https://github.com/agaldran/mhml_calibration} .\n","authors":["Adrian Galdran","Johan Verjans","Gustavo Carneiro","Miguel A. González Ballester"],"pdf_url":"https://arxiv.org/pdf/2303.01099v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2111.00743v4","updated":"2023-03-02T09:31:50Z","published":"2021-11-01T07:39:38Z","title":"Towards the Generalization of Contrastive Self-Supervised Learning","summary":"  Recently, self-supervised learning has attracted great attention, since it\nonly requires unlabeled data for model training. Contrastive learning is one\npopular method for self-supervised learning and has achieved promising\nempirical performance. However, the theoretical understanding of its\ngeneralization ability is still limited. To this end, we define a kind of\n$(\\sigma,\\delta)$-measure to mathematically quantify the data augmentation, and\nthen provide an upper bound of the downstream classification error rate based\non the measure. It reveals that the generalization ability of contrastive\nself-supervised learning is related to three key factors: alignment of positive\nsamples, divergence of class centers, and concentration of augmented data. The\nfirst two factors are properties of learned representations, while the third\none is determined by pre-defined data augmentation. We further investigate two\ncanonical contrastive losses, InfoNCE and cross-correlation, to show how they\nprovably achieve the first two factors. Moreover, we conduct experiments to\nstudy the third factor, and observe a strong correlation between downstream\nperformance and the concentration of augmented data.\n","authors":["Weiran Huang","Mingyang Yi","Xuyang Zhao","Zihao Jiang"],"pdf_url":"https://arxiv.org/pdf/2111.00743v4.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01092v1","updated":"2023-03-02T09:26:20Z","published":"2023-03-02T09:26:20Z","title":"ArCL: Enhancing Contrastive Learning with Augmentation-Robust\n  Representations","summary":"  Self-Supervised Learning (SSL) is a paradigm that leverages unlabeled data\nfor model training. Empirical studies show that SSL can achieve promising\nperformance in distribution shift scenarios, where the downstream and training\ndistributions differ. However, the theoretical understanding of its\ntransferability remains limited. In this paper, we develop a theoretical\nframework to analyze the transferability of self-supervised contrastive\nlearning, by investigating the impact of data augmentation on it. Our results\nreveal that the downstream performance of contrastive learning depends largely\non the choice of data augmentation. Moreover, we show that contrastive learning\nfails to learn domain-invariant features, which limits its transferability.\nBased on these theoretical insights, we propose a novel method called\nAugmentation-robust Contrastive Learning (ArCL), which guarantees to learn\ndomain-invariant features and can be easily integrated with existing\ncontrastive learning algorithms. We conduct experiments on several datasets and\nshow that ArCL significantly improves the transferability of contrastive\nlearning.\n","authors":["Xuyang Zhao","Tianqi Du","Yisen Wang","Jun Yao","Weiran Huang"],"pdf_url":"https://arxiv.org/pdf/2303.01092v1.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01091v1","updated":"2023-03-02T09:26:14Z","published":"2023-03-02T09:26:14Z","title":"OPE-SR: Orthogonal Position Encoding for Designing a Parameter-free\n  Upsampling Module in Arbitrary-scale Image Super-Resolution","summary":"  Implicit neural representation (INR) is a popular approach for\narbitrary-scale image super-resolution (SR), as a key component of INR,\nposition encoding improves its representation ability. Motivated by position\nencoding, we propose orthogonal position encoding (OPE) - an extension of\nposition encoding - and an OPE-Upscale module to replace the INR-based\nupsampling module for arbitrary-scale image super-resolution. Same as INR, our\nOPE-Upscale Module takes 2D coordinates and latent code as inputs; however it\ndoes not require training parameters. This parameter-free feature allows the\nOPE-Upscale Module to directly perform linear combination operations to\nreconstruct an image in a continuous manner, achieving an arbitrary-scale image\nreconstruction. As a concise SR framework, our method has high computing\nefficiency and consumes less memory comparing to the state-of-the-art (SOTA),\nwhich has been confirmed by extensive experiments and evaluations. In addition,\nour method has comparable results with SOTA in arbitrary scale image\nsuper-resolution. Last but not the least, we show that OPE corresponds to a set\nof orthogonal basis, justifying our design principle.\n","authors":["Gaochao Song","Luo Zhang","Ran Su","Jianfeng Shi","Ying He","Qian Sun"],"pdf_url":"https://arxiv.org/pdf/2303.01091v1.pdf","comment":"Accepted by CVPR 2023. 11 pages"},{"id":"http://arxiv.org/abs/2212.09748v2","updated":"2023-03-02T09:06:55Z","published":"2022-12-19T18:59:58Z","title":"Scalable Diffusion Models with Transformers","summary":"  We explore a new class of diffusion models based on the transformer\narchitecture. We train latent diffusion models of images, replacing the\ncommonly-used U-Net backbone with a transformer that operates on latent\npatches. We analyze the scalability of our Diffusion Transformers (DiTs)\nthrough the lens of forward pass complexity as measured by Gflops. We find that\nDiTs with higher Gflops -- through increased transformer depth/width or\nincreased number of input tokens -- consistently have lower FID. In addition to\npossessing good scalability properties, our largest DiT-XL/2 models outperform\nall prior diffusion models on the class-conditional ImageNet 512x512 and\n256x256 benchmarks, achieving a state-of-the-art FID of 2.27 on the latter.\n","authors":["William Peebles","Saining Xie"],"pdf_url":"https://arxiv.org/pdf/2212.09748v2.pdf","comment":"Code, project page and videos available at\n  https://www.wpeebles.com/DiT"},{"id":"http://arxiv.org/abs/2210.06031v2","updated":"2023-03-02T09:05:43Z","published":"2022-10-12T09:08:27Z","title":"Long-Form Video-Language Pre-Training with Multimodal Temporal\n  Contrastive Learning","summary":"  Large-scale video-language pre-training has shown significant improvement in\nvideo-language understanding tasks. Previous studies of video-language\npretraining mainly focus on short-form videos (i.e., within 30 seconds) and\nsentences, leaving long-form video-language pre-training rarely explored.\nDirectly learning representation from long-form videos and language may benefit\nmany long-form video-language understanding tasks. However, it is challenging\ndue to the difficulty of modeling long-range relationships and the heavy\ncomputational burden caused by more frames. In this paper, we introduce a\nLong-Form VIdeo-LAnguage pre-training model (LF-VILA) and train it on a\nlarge-scale long-form video and paragraph dataset constructed from an existing\npublic dataset. To effectively capture the rich temporal dynamics and to better\nalign video and language in an efficient end-to-end manner, we introduce two\nnovel designs in our LF-VILA model. We first propose a Multimodal Temporal\nContrastive (MTC) loss to learn the temporal relation across different\nmodalities by encouraging fine-grained alignment between long-form videos and\nparagraphs. Second, we propose a Hierarchical Temporal Window Attention (HTWA)\nmechanism to effectively capture long-range dependency while reducing\ncomputational cost in Transformer. We fine-tune the pre-trained LF-VILA model\non seven downstream long-form video-language understanding tasks of\nparagraph-to-video retrieval and long-form video question-answering, and\nachieve new state-of-the-art performances. Specifically, our model achieves\n16.1% relative improvement on ActivityNet paragraph-to-video retrieval task and\n2.4% on How2QA task, respectively. We release our code, dataset, and\npre-trained models at https://github.com/microsoft/XPretrain.\n","authors":["Yuchong Sun","Hongwei Xue","Ruihua Song","Bei Liu","Huan Yang","Jianlong Fu"],"pdf_url":"https://arxiv.org/pdf/2210.06031v2.pdf","comment":"Accepted by NeurIPS 2022"},{"id":"http://arxiv.org/abs/2303.01080v1","updated":"2023-03-02T09:03:11Z","published":"2023-03-02T09:03:11Z","title":"LANDMARK: Language-guided Representation Enhancement Framework for Scene\n  Graph Generation","summary":"  Scene graph generation (SGG) is a sophisticated task that suffers from both\ncomplex visual features and dataset long-tail problem. Recently, various\nunbiased strategies have been proposed by designing novel loss functions and\ndata balancing strategies. Unfortunately, these unbiased methods fail to\nemphasize language priors in feature refinement perspective. Inspired by the\nfact that predicates are highly correlated with semantics hidden in\nsubject-object pair and global context, we propose LANDMARK (LANguage-guiDed\nrepresentationenhanceMent frAmewoRK) that learns predicate-relevant\nrepresentations from language-vision interactive patterns, global language\ncontext and pair-predicate correlation. Specifically, we first project object\nlabels to three distinctive semantic embeddings for different representation\nlearning. Then, Language Attention Module (LAM) and Experience Estimation\nModule (EEM) process subject-object word embeddings to attention vector and\npredicate distribution, respectively. Language Context Module (LCM) encodes\nglobal context from each word embed-ding, which avoids isolated learning from\nlocal information. Finally, modules outputs are used to update visual\nrepresentations and SGG model's prediction. All language representations are\npurely generated from object categories so that no extra knowledge is needed.\nThis framework is model-agnostic and consistently improves performance on\nexisting SGG models. Besides, representation-level unbiased strategies endow\nLANDMARK the advantage of compatibility with other methods. Code is available\nat https://github.com/rafa-cxg/PySGG-cxg.\n","authors":["Xiaoguang Chang","Teng Wang","Shaowei Cai","Changyin Sun"],"pdf_url":"https://arxiv.org/pdf/2303.01080v1.pdf","comment":"Revision period in Applied Intelligence (APIN)"},{"id":"http://arxiv.org/abs/2112.01784v2","updated":"2023-03-02T08:54:48Z","published":"2021-12-03T08:37:52Z","title":"Fully automatic integration of dental CBCT images and full-arch\n  intraoral impressions with stitching error correction via individual tooth\n  segmentation and identification","summary":"  We present a fully automated method of integrating intraoral scan (IOS) and\ndental cone-beam computerized tomography (CBCT) images into one image by\ncomplementing each image's weaknesses. Dental CBCT alone may not be able to\ndelineate precise details of the tooth surface due to limited image resolution\nand various CBCT artifacts, including metal-induced artifacts. IOS is very\naccurate for the scanning of narrow areas, but it produces cumulative stitching\nerrors during full-arch scanning. The proposed method is intended not only to\ncompensate the low-quality of CBCT-derived tooth surfaces with IOS, but also to\ncorrect the cumulative stitching errors of IOS across the entire dental arch.\nMoreover, the integration provide both gingival structure of IOS and tooth\nroots of CBCT in one image. The proposed fully automated method consists of\nfour parts; (i) individual tooth segmentation and identification module for IOS\ndata (TSIM-IOS); (ii) individual tooth segmentation and identification module\nfor CBCT data (TSIM-CBCT); (iii) global-to-local tooth registration between IOS\nand CBCT; and (iv) stitching error correction of full-arch IOS. The\nexperimental results show that the proposed method achieved landmark and\nsurface distance errors of 112.4 $\\mu$m and 301.7 $\\mu$m, respectively.\n","authors":["Tae Jun Jang","Hye Sun Yun","Chang Min Hyun","Jong-Eun Kim","Sang-Hwy Lee","Jin Keun Seo"],"pdf_url":"https://arxiv.org/pdf/2112.01784v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01069v1","updated":"2023-03-02T08:43:40Z","published":"2023-03-02T08:43:40Z","title":"Implicit Neural Representations for Modeling of Abdominal Aortic\n  Aneurysm Progression","summary":"  Abdominal aortic aneurysms (AAAs) are progressive dilatations of the\nabdominal aorta that, if left untreated, can rupture with lethal consequences.\nImaging-based patient monitoring is required to select patients eligible for\nsurgical repair. In this work, we present a model based on implicit neural\nrepresentations (INRs) to model AAA progression. We represent the AAA wall over\ntime as the zero-level set of a signed distance function (SDF), estimated by a\nmultilayer perception that operates on space and time. We optimize this INR\nusing automatically extracted segmentation masks in longitudinal CT data. This\nnetwork is conditioned on spatiotemporal coordinates and represents the AAA\nsurface at any desired resolution at any moment in time. Using regularization\non spatial and temporal gradients of the SDF, we ensure proper interpolation of\nthe AAA shape. We demonstrate the network's ability to produce AAA\ninterpolations with average surface distances ranging between 0.72 and 2.52 mm\nfrom images acquired at highly irregular intervals. The results indicate that\nour model can accurately interpolate AAA shapes over time, with potential\nclinical value for a more personalised assessment of AAA progression.\n","authors":["Dieuwertje Alblas","Marieke Hofman","Christoph Brune","Kak Khee Yeung","Jelmer M. Wolterink"],"pdf_url":"https://arxiv.org/pdf/2303.01069v1.pdf","comment":"FIMH 2023 (submitted)"},{"id":"http://arxiv.org/abs/2210.15075v2","updated":"2023-03-02T08:25:37Z","published":"2022-10-26T23:11:02Z","title":"IDEAL: Improved DEnse locAL Contrastive Learning for Semi-Supervised\n  Medical Image Segmentation","summary":"  Due to the scarcity of labeled data, Contrastive Self-Supervised Learning\n(SSL) frameworks have lately shown great potential in several medical image\nanalysis tasks. However, the existing contrastive mechanisms are sub-optimal\nfor dense pixel-level segmentation tasks due to their inability to mine local\nfeatures. To this end, we extend the concept of metric learning to the\nsegmentation task, using a dense (dis)similarity learning for pre-training a\ndeep encoder network, and employing a semi-supervised paradigm to fine-tune for\nthe downstream task. Specifically, we propose a simple convolutional projection\nhead for obtaining dense pixel-level features, and a new contrastive loss to\nutilize these dense projections thereby improving the local representations. A\nbidirectional consistency regularization mechanism involving two-stream model\ntraining is devised for the downstream task. Upon comparison, our IDEAL method\noutperforms the SoTA methods by fair margins on cardiac MRI segmentation. Code\navailable: https://github.com/hritam-98/IDEAL-ICASSP23\n","authors":["Hritam Basak","Soumitri Chattopadhyay","Rohit Kundu","Sayan Nag","Rammohan Mallipeddi"],"pdf_url":"https://arxiv.org/pdf/2210.15075v2.pdf","comment":"Paper accepted for publication at IEEE ICASSP 2023"},{"id":"http://arxiv.org/abs/2209.06430v4","updated":"2023-03-02T08:24:23Z","published":"2022-09-14T05:47:02Z","title":"CLIP-ViP: Adapting Pre-trained Image-Text Model to Video-Language\n  Representation Alignment","summary":"  The pre-trained image-text models, like CLIP, have demonstrated the strong\npower of vision-language representation learned from a large scale of\nweb-collected image-text data. In light of the well-learned visual features,\nsome existing works transfer image representation to video domain and achieve\ngood results. However, how to utilize image-language pre-trained model (e.g.,\nCLIP) for video-language pre-training (post-pretraining) is still under\nexplored. In this paper, we investigate two questions: 1) what are the factors\nhindering post-pretraining CLIP to further improve the performance on\nvideo-language tasks? and 2) how to mitigate the impact of these factors?\nThrough a series of comparative experiments and analyses, we find that the data\nscale and domain gap between language sources have great impacts. Motivated by\nthese, we propose a Omnisource Cross-modal Learning method equipped with a\nVideo Proxy mechanism on the basis of CLIP, namely CLIP-ViP. Extensive results\nshow that our approach improves the performance of CLIP on video-text retrieval\nby a large margin. Our model also achieves SOTA results on a variety of\ndatasets, including MSR-VTT, DiDeMo, LSMDC, and ActivityNet. We will release\nour code and pre-trained CLIP-ViP models at\nhttps://github.com/microsoft/XPretrain/tree/main/CLIP-ViP.\n","authors":["Hongwei Xue","Yuchong Sun","Bei Liu","Jianlong Fu","Ruihua Song","Houqiang Li","Jiebo Luo"],"pdf_url":"https://arxiv.org/pdf/2209.06430v4.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01054v1","updated":"2023-03-02T08:24:13Z","published":"2023-03-02T08:24:13Z","title":"Deep Learning based Segmentation of Optical Coherence Tomographic Images\n  of Human Saphenous Varicose Vein","summary":"  Deep-learning based segmentation model is proposed for Optical Coherence\nTomography images of human varicose vein based on the U-Net model employing\natrous convolution with residual blocks, which gives an accuracy of 0.9932.\n","authors":["Maryam Viqar","Violeta Madjarova","Amit Kumar Yadav","Desislava Pashkuleva","Alexander S. Machikhin"],"pdf_url":"https://arxiv.org/pdf/2303.01054v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01052v1","updated":"2023-03-02T08:18:22Z","published":"2023-03-02T08:18:22Z","title":"Demystifying Causal Features on Adversarial Examples and Causal\n  Inoculation for Robust Network by Adversarial Instrumental Variable\n  Regression","summary":"  The origin of adversarial examples is still inexplicable in research fields,\nand it arouses arguments from various viewpoints, albeit comprehensive\ninvestigations. In this paper, we propose a way of delving into the unexpected\nvulnerability in adversarially trained networks from a causal perspective,\nnamely adversarial instrumental variable (IV) regression. By deploying it, we\nestimate the causal relation of adversarial prediction under an unbiased\nenvironment dissociated from unknown confounders. Our approach aims to\ndemystify inherent causal features on adversarial examples by leveraging a\nzero-sum optimization game between a casual feature estimator (i.e., hypothesis\nmodel) and worst-case counterfactuals (i.e., test function) disturbing to find\ncausal features. Through extensive analyses, we demonstrate that the estimated\ncausal features are highly related to the correct prediction for adversarial\nrobustness, and the counterfactuals exhibit extreme features significantly\ndeviating from the correct prediction. In addition, we present how to\neffectively inoculate CAusal FEatures (CAFE) into defense networks for\nimproving adversarial robustness.\n","authors":["Junho Kim. Byung-Kwan Lee","Yong Man Ro"],"pdf_url":"https://arxiv.org/pdf/2303.01052v1.pdf","comment":"Accepted in CVPR 2023"},{"id":"http://arxiv.org/abs/2303.01047v1","updated":"2023-03-02T08:02:14Z","published":"2023-03-02T08:02:14Z","title":"Task-Specific Context Decoupling for Object Detection","summary":"  Classification and localization are two main sub-tasks in object detection.\nNonetheless, these two tasks have inconsistent preferences for feature context,\ni.e., localization expects more boundary-aware features to accurately regress\nthe bounding box, while more semantic context is preferred for object\nclassification. Exsiting methods usually leverage disentangled heads to learn\ndifferent feature context for each task. However, the heads are still applied\non the same input features, which leads to an imperfect balance between\nclassifcation and localization. In this work, we propose a novel Task-Specific\nCOntext DEcoupling (TSCODE) head which further disentangles the feature\nencoding for two tasks. For classification, we generate spatially-coarse but\nsemantically-strong feature encoding. For localization, we provide\nhigh-resolution feature map containing more edge information to better regress\nobject boundaries. TSCODE is plug-and-play and can be easily incorperated into\nexisting detection pipelines. Extensive experiments demonstrate that our method\nstably improves different detectors by over 1.0 AP with less computational\ncost. Our code and models will be publicly released.\n","authors":["Jiayuan Zhuang","Zheng Qin","Hao Yu","Xucan Chen"],"pdf_url":"https://arxiv.org/pdf/2303.01047v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01046v1","updated":"2023-03-02T08:00:22Z","published":"2023-03-02T08:00:22Z","title":"Jointly Visual- and Semantic-Aware Graph Memory Networks for Temporal\n  Sentence Localization in Videos","summary":"  Temporal sentence localization in videos (TSLV) aims to retrieve the most\ninterested segment in an untrimmed video according to a given sentence query.\nHowever, almost of existing TSLV approaches suffer from the same limitations:\n(1) They only focus on either frame-level or object-level visual representation\nlearning and corresponding correlation reasoning, but fail to integrate them\nboth; (2) They neglect to leverage the rich semantic contexts to further\nbenefit the query reasoning. To address these issues, in this paper, we propose\na novel Hierarchical Visual- and Semantic-Aware Reasoning Network (HVSARN),\nwhich enables both visual- and semantic-aware query reasoning from object-level\nto frame-level. Specifically, we present a new graph memory mechanism to\nperform visual-semantic query reasoning: For visual reasoning, we design a\nvisual graph memory to leverage visual information of video; For semantic\nreasoning, a semantic graph memory is also introduced to explicitly leverage\nsemantic knowledge contained in the classes and attributes of video objects,\nand perform correlation reasoning in the semantic space. Experiments on three\ndatasets demonstrate that our HVSARN achieves a new state-of-the-art\nperformance.\n","authors":["Daizong Liu","Pan Zhou"],"pdf_url":"https://arxiv.org/pdf/2303.01046v1.pdf","comment":"Accepted by ICASSP2023"},{"id":"http://arxiv.org/abs/2303.00351v2","updated":"2023-03-02T07:59:22Z","published":"2023-03-01T09:27:08Z","title":"An end-to-end SE(3)-equivariant segmentation network","summary":"  Convolutional neural networks (CNNs) allow for parameter sharing and\ntranslational equivariance by using convolutional kernels in their linear\nlayers. By restricting these kernels to be SO(3)-steerable, CNNs can further\nimprove parameter sharing and equivariance. These equivariant convolutional\nlayers have several advantages over standard convolutional layers, including\nincreased robustness to unseen poses, smaller network size, and improved sample\nefficiency. Despite this, most segmentation networks used in medical image\nanalysis continue to rely on standard convolutional kernels. In this paper, we\npresent a new family of segmentation networks that use equivariant voxel\nconvolutions based on spherical harmonics, as well as equivariant pooling and\nnormalization operations. These SE(3)-equivariant volumetric segmentation\nnetworks, which are robust to data poses not seen during training, do not\nrequire rotation-based data augmentation during training. In addition, we\ndemonstrate improved segmentation performance in MRI brain tumor and healthy\nbrain structure segmentation tasks, with enhanced robustness to reduced amounts\nof training data and improved parameter efficiency. Code to reproduce our\nresults, and to implement the equivariant segmentation networks for other tasks\nis available at http://github.com/SCAN-NRAD/e3nn_Unet\n","authors":["Ivan Diaz","Mario Geiger","Richard Iain McKinley"],"pdf_url":"https://arxiv.org/pdf/2303.00351v2.pdf","comment":"19 pages, 10 figures, submitted to the Journal of Machine Learning\n  for Biomedical Imaging"},{"id":"http://arxiv.org/abs/2303.01043v1","updated":"2023-03-02T07:56:04Z","published":"2023-03-02T07:56:04Z","title":"I2P-Rec: Recognizing Images on Large-scale Point Cloud Maps through\n  Bird's Eye View Projections","summary":"  Place recognition is an important technique for autonomous cars to achieve\nfull autonomy since it can provide an initial guess to online localization\nalgorithms. Although current methods based on images or point clouds have\nachieved satisfactory performance, localizing the images on a large-scale point\ncloud map remains a fairly unexplored problem. This cross-modal matching task\nis challenging due to the difficulty in extracting consistent descriptors from\nimages and point clouds. In this paper, we propose the I2P-Rec method to solve\nthe problem by transforming the cross-modal data into the same modality.\nSpecifically, we leverage on the recent success of depth estimation networks to\nrecover point clouds from images. We then project the point clouds into Bird's\nEye View (BEV) images. Using the BEV image as an intermediate representation,\nwe extract global features with a Convolutional Neural Network followed by a\nNetVLAD layer to perform matching. We evaluate our method on the KITTI dataset.\nThe experimental results show that, with only a small set of training data,\nI2P-Rec can achieve a recall rate at Top-1 over 90\\%. Also, it can generalize\nwell to unknown environments, achieving recall rates at Top-1\\% over 80\\% and\n90\\%, when localizing monocular images and stereo images on point cloud maps,\nrespectively.\n","authors":["Yixuan Li","Shuhang Zheng","Zhu Yu","Beinan Yu","Si-Yuan Cao","Lun Luo","Hui-Liang Shen"],"pdf_url":"https://arxiv.org/pdf/2303.01043v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.11294v2","updated":"2023-03-02T07:51:07Z","published":"2022-09-22T20:14:43Z","title":"T2FPV: Dataset and Method for Correcting First-Person View Errors in\n  Pedestrian Trajectory Prediction","summary":"  Predicting pedestrian motion is essential for developing socially-aware\nrobots that interact in a crowded environment. While the natural visual\nperspective for a social interaction setting is an egocentric view, the\nmajority of existing work in trajectory prediction therein has been\ninvestigated purely in the top-down trajectory space. To support first-person\nview trajectory prediction research, we present T2FPV, a method for\nconstructing high-fidelity first-person view (FPV) datasets given a real-world,\ntop-down trajectory dataset; we showcase our approach on the ETH/UCY pedestrian\ndataset to generate the egocentric visual data of all interacting pedestrians,\ncreating the T2FPV-ETH dataset. In this setting, FPV-specific errors arise due\nto imperfect detection and tracking, occlusions, and field-of-view (FOV)\nlimitations of the camera. To address these errors, we propose CoFE, a module\nthat further refines the imputation of missing data in an end-to-end manner\nwith trajectory forecasting algorithms. Our method reduces the impact of such\nFPV errors on downstream prediction performance, decreasing displacement error\nby more than 10% on average. To facilitate research engagement, we release our\nT2FPV-ETH dataset and software tools.\n","authors":["Benjamin Stoler","Meghdeep Jana","Soonmin Hwang","Jean Oh"],"pdf_url":"https://arxiv.org/pdf/2209.11294v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01038v1","updated":"2023-03-02T07:50:41Z","published":"2023-03-02T07:50:41Z","title":"Neural Intrinsic Embedding for Non-rigid Point Cloud Matching","summary":"  As a primitive 3D data representation, point clouds are prevailing in 3D\nsensing, yet short of intrinsic structural information of the underlying\nobjects. Such discrepancy poses great challenges on directly establishing\ncorrespondences between point clouds sampled from deformable shapes. In light\nof this, we propose Neural Intrinsic Embedding (NIE) to embed each vertex into\na high-dimensional space in a way that respects the intrinsic structure. Based\nupon NIE, we further present a weakly-supervised learning framework for\nnon-rigid point cloud registration. Unlike the prior works, we do not require\nexpansive and sensitive off-line basis construction (e.g., eigen-decomposition\nof Laplacians), nor do we require ground-truth correspondence labels for\nsupervision. We empirically show that our framework performs on par with or\neven better than the state-of-the-art baselines, which generally require more\nsupervision and/or more structural geometric input.\n","authors":["Puhua Jiang","Mingze Sun","Ruqi Huang"],"pdf_url":"https://arxiv.org/pdf/2303.01038v1.pdf","comment":"To appear at CVPR 2023"},{"id":"http://arxiv.org/abs/2303.01036v1","updated":"2023-03-02T07:47:07Z","published":"2023-03-02T07:47:07Z","title":"Validated respiratory drug deposition predictions from 2D and 3D medical\n  images with statistical shape models and convolutional neural networks","summary":"  For the one billion sufferers of respiratory disease, managing their disease\nwith inhalers crucially influences their quality of life. Generic treatment\nplans could be improved with the aid of computational models that account for\npatient-specific features such as breathing pattern, lung pathology and\nmorphology. Therefore, we aim to develop and validate an automated\ncomputational framework for patient-specific deposition modelling. To that end,\nan image processing approach is proposed that could produce 3D patient\nrespiratory geometries from 2D chest X-rays and 3D CT images. We evaluated the\nairway and lung morphology produced by our image processing framework, and\nassessed deposition compared to in vivo data. The 2D-to-3D image processing\nreproduces airway diameter to 9% median error compared to ground truth\nsegmentations, but is sensitive to outliers of up to 33% due to lung outline\nnoise. Predicted regional deposition gave 5% median error compared to in vivo\nmeasurements. The proposed framework is capable of providing patient-specific\ndeposition measurements for varying treatments, to determine which treatment\nwould best satisfy the needs imposed by each patient (such as disease and\nlung/airway morphology). Integration of patient-specific modelling into\nclinical practice as an additional decision-making tool could optimise\ntreatment plans and lower the burden of respiratory diseases.\n","authors":["Josh Williams","Haavard Ahlqvist","Alexander Cunningham","Andrew Kirby","Ira Katz","John Fleming","Joy Conway","Steve Cunningham","Ali Ozel","Uwe Wolfram"],"pdf_url":"https://arxiv.org/pdf/2303.01036v1.pdf","comment":"37 pages main text (including frontmatter). 9 figures. Additional\n  supplementary material"},{"id":"http://arxiv.org/abs/2303.01032v1","updated":"2023-03-02T07:42:07Z","published":"2023-03-02T07:42:07Z","title":"ESceme: Vision-and-Language Navigation with Episodic Scene Memory","summary":"  Vision-and-language navigation (VLN) simulates a visual agent that follows\nnatural-language navigation instructions in real-world scenes. Existing\napproaches have made enormous progress in navigation in new environments, such\nas beam search, pre-exploration, and dynamic or hierarchical history encoding.\nTo balance generalization and efficiency, we resort to memorizing visited\nscenarios apart from the ongoing route while navigating. In this work, we\nintroduce a mechanism of Episodic Scene memory (ESceme) for VLN that wakes an\nagent's memories of past visits when it enters the current scene. The episodic\nscene memory allows the agent to envision a bigger picture of the next\nprediction. In this way, the agent learns to make the most of currently\navailable information instead of merely adapting to the seen environments. We\nprovide a simple yet effective implementation by enhancing the observation\nfeatures of candidate nodes during training. We verify the superiority of\nESceme on three VLN tasks, including short-horizon navigation (R2R),\nlong-horizon navigation (R4R), and vision-and-dialog navigation (CVDN), and\nachieve a new state-of-the-art. Code is available:\n\\url{https://github.com/qizhust/esceme}.\n","authors":["Qi Zheng","Daqing Liu","Chaoyue Wang","Jing Zhang","Dadong Wang","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2303.01032v1.pdf","comment":"Tech. report"},{"id":"http://arxiv.org/abs/2209.14610v3","updated":"2023-03-02T07:41:55Z","published":"2022-09-29T08:01:04Z","title":"Dynamic Prompt Learning via Policy Gradient for Semi-structured\n  Mathematical Reasoning","summary":"  Mathematical reasoning, a core ability of human intelligence, presents unique\nchallenges for machines in abstract thinking and logical reasoning. Recent\nlarge pre-trained language models such as GPT-3 have achieved remarkable\nprogress on mathematical reasoning tasks written in text form, such as math\nword problems (MWP). However, it is unknown if the models can handle more\ncomplex problems that involve math reasoning over heterogeneous information,\nsuch as tabular data. To fill the gap, we present Tabular Math Word Problems\n(TabMWP), a new dataset containing 38,431 open-domain grade-level problems that\nrequire mathematical reasoning on both textual and tabular data. Each question\nin TabMWP is aligned with a tabular context, which is presented as an image,\nsemi-structured text, and a structured table. There are two types of questions:\nfree-text and multi-choice, and each problem is annotated with gold solutions\nto reveal the multi-step reasoning process. We evaluate different pre-trained\nmodels on TabMWP, including the GPT-3 model in a few-shot setting. As earlier\nstudies suggest, since few-shot GPT-3 relies on the selection of in-context\nexamples, its performance is unstable and can degrade to near chance. The\nunstable issue is more severe when handling complex problems like TabMWP. To\nmitigate this, we further propose a novel approach, PromptPG, which utilizes\npolicy gradient to learn to select in-context examples from a small amount of\ntraining data and then constructs the corresponding prompt for the test\nexample. Experimental results show that our method outperforms the best\nbaseline by 5.31% on the accuracy metric and reduces the prediction variance\nsignificantly compared to random selection, which verifies its effectiveness in\nselecting in-context examples.\n","authors":["Pan Lu","Liang Qiu","Kai-Wei Chang","Ying Nian Wu","Song-Chun Zhu","Tanmay Rajpurohit","Peter Clark","Ashwin Kalyan"],"pdf_url":"https://arxiv.org/pdf/2209.14610v3.pdf","comment":"ICLR 2023. 26 pages and 18 figures. The data and code are available\n  at https://promptpg.github.io"},{"id":"http://arxiv.org/abs/2207.00193v2","updated":"2023-03-02T07:39:00Z","published":"2022-07-01T03:50:26Z","title":"Reading and Writing: Discriminative and Generative Modeling for\n  Self-Supervised Text Recognition","summary":"  Existing text recognition methods usually need large-scale training data.\nMost of them rely on synthetic training data due to the lack of annotated real\nimages. However, there is a domain gap between the synthetic data and real\ndata, which limits the performance of the text recognition models. Recent\nself-supervised text recognition methods attempted to utilize unlabeled real\nimages by introducing contrastive learning, which mainly learns the\ndiscrimination of the text images. Inspired by the observation that humans\nlearn to recognize the texts through both reading and writing, we propose to\nlearn discrimination and generation by integrating contrastive learning and\nmasked image modeling in our self-supervised method. The contrastive learning\nbranch is adopted to learn the discrimination of text images, which imitates\nthe reading behavior of humans. Meanwhile, masked image modeling is firstly\nintroduced for text recognition to learn the context generation of the text\nimages, which is similar to the writing behavior. The experimental results show\nthat our method outperforms previous self-supervised text recognition methods\nby 10.2%-20.2% on irregular scene text recognition datasets. Moreover, our\nproposed text recognizer exceeds previous state-of-the-art text recognition\nmethods by averagely 5.3% on 11 benchmarks, with similar model size. We also\ndemonstrate that our pre-trained model can be easily applied to other\ntext-related tasks with obvious performance gain. The code is available at\nhttps://github.com/ayumiymk/DiG.\n","authors":["Mingkun Yang","Minghui Liao","Pu Lu","Jing Wang","Shenggao Zhu","Hualin Luo","Qi Tian","Xiang Bai"],"pdf_url":"https://arxiv.org/pdf/2207.00193v2.pdf","comment":"Accepted by ACM MM 2022. The code is available at\n  https://github.com/ayumiymk/DiG"},{"id":"http://arxiv.org/abs/2002.03328v5","updated":"2023-03-02T06:56:26Z","published":"2020-02-09T09:54:12Z","title":"Kullback-Leibler Divergence-Based Out-of-Distribution Detection with\n  Flow-Based Generative Models","summary":"  Recent research has revealed that deep generative models including flow-based\nmodels and Variational Autoencoders may assign higher likelihoods to\nout-of-distribution (OOD) data than in-distribution (ID) data. However, we\ncannot sample OOD data from the model. This counterintuitive phenomenon has not\nbeen satisfactorily explained and brings obstacles to OOD detection with\nflow-based models. In this paper, we prove theorems to investigate the\nKullback-Leibler divergence in flow-based model and give two explanations for\nthe above phenomenon. Based on our theoretical analysis, we propose a new\nmethod \\PADmethod\\ to leverage KL divergence and local pixel dependence of\nrepresentations to perform anomaly detection. Experimental results on prevalent\nbenchmarks demonstrate the effectiveness and robustness of our method. For\ngroup anomaly detection, our method achieves 98.1\\% AUROC on average with a\nsmall batch size of 5. On the contrary, the baseline typicality test-based\nmethod only achieves 64.6\\% AUROC on average due to its failure on challenging\nproblems. Our method also outperforms the state-of-the-art method by 9.1\\%\nAUROC. For point-wise anomaly detection, our method achieves 90.7\\% AUROC on\naverage and outperforms the baseline by 5.2\\% AUROC. Besides, our method has\nthe least notable failures and is the most robust one.\n","authors":["Yufeng Zhang","Jialu Pan","Wanwei Liu","Zhenbang Chen","Ji Wang","Zhiming Liu","Kenli Li","Hongmei Wei"],"pdf_url":"https://arxiv.org/pdf/2002.03328v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01003v1","updated":"2023-03-02T06:44:21Z","published":"2023-03-02T06:44:21Z","title":"Target Domain Data induces Negative Transfer in Mixed Domain Training\n  with Disjoint Classes","summary":"  In practical scenarios, it is often the case that the available training data\nwithin the target domain only exist for a limited number of classes, with the\nremaining classes only available within surrogate domains. We show that\nincluding the target domain in training when there exist disjoint classes\nbetween the target and surrogate domains creates significant negative transfer,\nand causes performance to significantly decrease compared to training without\nthe target domain at all. We hypothesize that this negative transfer is due to\nan intermediate shortcut that only occurs when multiple source domains are\npresent, and provide experimental evidence that this may be the case. We show\nthat this phenomena occurs on over 25 distinct domain shifts, both synthetic\nand real, and in many cases deteriorates the performance to well worse than\nrandom, even when using state-of-the-art domain adaptation methods.\n","authors":["Eryk Banatt","Vickram Rajendran","Liam Packer"],"pdf_url":"https://arxiv.org/pdf/2303.01003v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2107.13429v2","updated":"2023-03-02T06:39:53Z","published":"2021-07-28T15:21:01Z","title":"Task-Specific Normalization for Continual Learning of Blind Image\n  Quality Models","summary":"  The computational vision community has recently paid attention to continual\nlearning for blind image quality assessment (BIQA). The primary challenge is to\ncombat catastrophic forgetting of previously-seen IQA datasets (i.e., tasks).\nIn this paper, we present a simple yet effective continual learning method for\nBIQA with improved quality prediction accuracy, plasticity-stability trade-off,\nand task-order/-length robustness. The key step in our approach is to freeze\nall convolution filters of a pre-trained deep neural network (DNN) for an\nexplicit promise of stability, and learn task-specific normalization parameters\nfor plasticity. We assign each new task a prediction head, and load the\ncorresponding normalization parameters to produce a quality score. The final\nquality estimate is computed by a weighted summation of predictions from all\nheads with a lightweight K-means gating mechanism, without leveraging the\ntest-time oracle. Extensive experiments on six IQA datasets demonstrate the\nadvantages of the proposed method in comparison to previous training techniques\nfor BIQA.\n","authors":["Weixia Zhang","Kede Ma","Guangtao Zhai","Xiaokang Yang"],"pdf_url":"https://arxiv.org/pdf/2107.13429v2.pdf","comment":"Revise the performance metrics, methodological updates, and new\n  experimental results"},{"id":"http://arxiv.org/abs/2205.14083v3","updated":"2023-03-02T06:39:34Z","published":"2022-05-27T16:32:43Z","title":"Sharpness-Aware Training for Free","summary":"  Modern deep neural networks (DNNs) have achieved state-of-the-art\nperformances but are typically over-parameterized. The over-parameterization\nmay result in undesirably large generalization error in the absence of other\ncustomized training strategies. Recently, a line of research under the name of\nSharpness-Aware Minimization (SAM) has shown that minimizing a sharpness\nmeasure, which reflects the geometry of the loss landscape, can significantly\nreduce the generalization error. However, SAM-like methods incur a two-fold\ncomputational overhead of the given base optimizer (e.g. SGD) for approximating\nthe sharpness measure. In this paper, we propose Sharpness-Aware Training for\nFree, or SAF, which mitigates the sharp landscape at almost zero additional\ncomputational cost over the base optimizer. Intuitively, SAF achieves this by\navoiding sudden drops in the loss in the sharp local minima throughout the\ntrajectory of the updates of the weights. Specifically, we suggest a novel\ntrajectory loss, based on the KL-divergence between the outputs of DNNs with\nthe current weights and past weights, as a replacement of the SAM's sharpness\nmeasure. This loss captures the rate of change of the training loss along the\nmodel's update trajectory. By minimizing it, SAF ensures the convergence to a\nflat minimum with improved generalization capabilities. Extensive empirical\nresults show that SAF minimizes the sharpness in the same way that SAM does,\nyielding better results on the ImageNet dataset with essentially the same\ncomputational cost as the base optimizer.\n","authors":["Jiawei Du","Daquan Zhou","Jiashi Feng","Vincent Y. F. Tan","Joey Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2205.14083v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01000v1","updated":"2023-03-02T06:33:33Z","published":"2023-03-02T06:33:33Z","title":"X&Fuse: Fusing Visual Information in Text-to-Image Generation","summary":"  We introduce X&Fuse, a general approach for conditioning on visual\ninformation when generating images from text. We demonstrate the potential of\nX&Fuse in three different text-to-image generation scenarios. (i) When a bank\nof images is available, we retrieve and condition on a related image\n(Retrieve&Fuse), resulting in significant improvements on the MS-COCO\nbenchmark, gaining a state-of-the-art FID score of 6.65 in zero-shot settings.\n(ii) When cropped-object images are at hand, we utilize them and perform\nsubject-driven generation (Crop&Fuse), outperforming the textual inversion\nmethod while being more than x100 faster. (iii) Having oracle access to the\nimage scene (Scene&Fuse), allows us to achieve an FID score of 5.03 on MS-COCO\nin zero-shot settings. Our experiments indicate that X&Fuse is an effective,\neasy-to-adapt, simple, and general approach for scenarios in which the model\nmay benefit from additional visual information.\n","authors":["Yuval Kirstain","Omer Levy","Adam Polyak"],"pdf_url":"https://arxiv.org/pdf/2303.01000v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.05086v2","updated":"2023-03-02T06:14:19Z","published":"2023-02-10T07:08:13Z","title":"Making Substitute Models More Bayesian Can Enhance Transferability of\n  Adversarial Examples","summary":"  The transferability of adversarial examples across deep neural networks\n(DNNs) is the crux of many black-box attacks. Many prior efforts have been\ndevoted to improving the transferability via increasing the diversity in inputs\nof some substitute models. In this paper, by contrast, we opt for the diversity\nin substitute models and advocate to attack a Bayesian model for achieving\ndesirable transferability. Deriving from the Bayesian formulation, we develop a\nprincipled strategy for possible finetuning, which can be combined with many\noff-the-shelf Gaussian posterior approximations over DNN parameters. Extensive\nexperiments have been conducted to verify the effectiveness of our method, on\ncommon benchmark datasets, and the results demonstrate that our method\noutperforms recent state-of-the-arts by large margins (roughly 19% absolute\nincrease in average attack success rate on ImageNet), and, by combining with\nthese recent methods, further performance gain can be obtained. Our code:\nhttps://github.com/qizhangli/MoreBayesian-attack.\n","authors":["Qizhang Li","Yiwen Guo","Wangmeng Zuo","Hao Chen"],"pdf_url":"https://arxiv.org/pdf/2302.05086v2.pdf","comment":"Accepted by ICLR 2023, fix typos"},{"id":"http://arxiv.org/abs/2303.00996v1","updated":"2023-03-02T06:10:13Z","published":"2023-03-02T06:10:13Z","title":"Unsupervised Meta-Learning via Few-shot Pseudo-supervised Contrastive\n  Learning","summary":"  Unsupervised meta-learning aims to learn generalizable knowledge across a\ndistribution of tasks constructed from unlabeled data. Here, the main challenge\nis how to construct diverse tasks for meta-learning without label information;\nrecent works have proposed to create, e.g., pseudo-labeling via pretrained\nrepresentations or creating synthetic samples via generative models. However,\nsuch a task construction strategy is fundamentally limited due to heavy\nreliance on the immutable pseudo-labels during meta-learning and the quality of\nthe representations or the generated samples. To overcome the limitations, we\npropose a simple yet effective unsupervised meta-learning framework, coined\nPseudo-supervised Contrast (PsCo), for few-shot classification. We are inspired\nby the recent self-supervised learning literature; PsCo utilizes a momentum\nnetwork and a queue of previous batches to improve pseudo-labeling and\nconstruct diverse tasks in a progressive manner. Our extensive experiments\ndemonstrate that PsCo outperforms existing unsupervised meta-learning methods\nunder various in-domain and cross-domain few-shot classification benchmarks. We\nalso validate that PsCo is easily scalable to a large-scale benchmark, while\nrecent prior-art meta-schemes are not.\n","authors":["Huiwon Jang","Hankook Lee","Jinwoo Shin"],"pdf_url":"https://arxiv.org/pdf/2303.00996v1.pdf","comment":"Accepted to ICLR 2023 (Spotlight). The first two authors contributed\n  equally. The code is available at https://github.com/alinlab/PsCo"},{"id":"http://arxiv.org/abs/2303.00983v1","updated":"2023-03-02T05:28:35Z","published":"2023-03-02T05:28:35Z","title":"Using simulation to quantify the performance of automotive perception\n  systems","summary":"  The design and evaluation of complex systems can benefit from a software\nsimulation - sometimes called a digital twin. The simulation can be used to\ncharacterize system performance or to test its performance under conditions\nthat are difficult to measure (e.g., nighttime for automotive perception\nsystems). We describe the image system simulation software tools that we use to\nevaluate the performance of image systems for object (automobile) detection. We\ndescribe experiments with 13 different cameras with a variety of optics and\npixel sizes. To measure the impact of camera spatial resolution, we designed a\ncollection of driving scenes that had cars at many different distances. We\nquantified system performance by measuring average precision and we report a\ntrend relating system resolution and object detection performance. We also\nquantified the large performance degradation under nighttime conditions,\ncompared to daytime, for all cameras and a COCO pre-trained network.\n","authors":["Zhenyi Liu","Devesh Shah","Alireza Rahimpour","Devesh Upadhyay","Joyce Farrell","Brian A Wandell"],"pdf_url":"https://arxiv.org/pdf/2303.00983v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00979v1","updated":"2023-03-02T05:20:36Z","published":"2023-03-02T05:20:36Z","title":"Multi-Source Soft Pseudo-Label Learning with Domain Similarity-based\n  Weighting for Semantic Segmentation","summary":"  This paper describes a method of domain adaptive training for semantic\nsegmentation using multiple source datasets that are not necessarily relevant\nto the target dataset. We propose a soft pseudo-label generation method by\nintegrating predicted object probabilities from multiple source models. The\nprediction of each source model is weighted based on the estimated domain\nsimilarity between the source and the target datasets to emphasize contribution\nof a model trained on a source that is more similar to the target and generate\nreasonable pseudo-labels. We also propose a training method using the soft\npseudo-labels considering their entropy to fully exploit information from the\nsource datasets while suppressing the influence of possibly misclassified\npixels. The experiments show comparative or better performance than our\nprevious work and another existing multi-source domain adaptation method, and\napplicability to a variety of target environments.\n","authors":["Shigemichi Matsuzaki","Hiroaki Masuzawa","Jun Miura"],"pdf_url":"https://arxiv.org/pdf/2303.00979v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00977v1","updated":"2023-03-02T05:19:31Z","published":"2023-03-02T05:19:31Z","title":"Ego-Vehicle Action Recognition based on Semi-Supervised Contrastive\n  Learning","summary":"  In recent years, many automobiles have been equipped with cameras, which have\naccumulated an enormous amount of video footage of driving scenes. Autonomous\ndriving demands the highest level of safety, for which even unimaginably rare\ndriving scenes have to be collected in training data to improve the recognition\naccuracy for specific scenes. However, it is prohibitively costly to find very\nfew specific scenes from an enormous amount of videos. In this article, we show\nthat proper video-to-video distances can be defined by focusing on ego-vehicle\nactions. It is well known that existing methods based on supervised learning\ncannot handle videos that do not fall into predefined classes, though they work\nwell in defining video-to-video distances in the embedding space between\nlabeled videos. To tackle this problem, we propose a method based on\nsemi-supervised contrastive learning. We consider two related but distinct\ncontrastive learning: standard graph contrastive learning and our proposed\nSOIA-based contrastive learning. We observe that the latter approach can\nprovide more sensible video-to-video distances between unlabeled videos. Next,\nthe effectiveness of our method is quantified by evaluating the classification\nperformance of the ego-vehicle action recognition using HDD dataset, which\nshows that our method including unlabeled data in training significantly\noutperforms the existing methods using only labeled data in training.\n","authors":["Chihiro Noguchi","Toshihiro Tanizawa"],"pdf_url":"https://arxiv.org/pdf/2303.00977v1.pdf","comment":"19 pages, 17 figures"},{"id":"http://arxiv.org/abs/2303.00973v1","updated":"2023-03-02T05:10:57Z","published":"2023-03-02T05:10:57Z","title":"Image Labels Are All You Need for Coarse Seagrass Segmentation","summary":"  Seagrass meadows serve as critical carbon sinks, but accurately estimating\nthe amount of carbon they store requires knowledge of the seagrass species\npresent. Using underwater and surface vehicles equipped with machine learning\nalgorithms can help to accurately estimate the composition and extent of\nseagrass meadows at scale. However, previous approaches for seagrass detection\nand classification have required full supervision from patch-level labels. In\nthis paper, we reframe seagrass classification as a weakly supervised coarse\nsegmentation problem where image-level labels are used during training (25\ntimes fewer labels compared to patch-level labeling) and patch-level outputs\nare obtained at inference time. To this end, we introduce SeaFeats, an\narchitecture that uses unsupervised contrastive pretraining and feature\nsimilarity to separate background and seagrass patches, and SeaCLIP, a model\nthat showcases the effectiveness of large language models as a supervisory\nsignal in domain-specific applications. We demonstrate that an ensemble of\nSeaFeats and SeaCLIP leads to highly robust performance, with SeaCLIP\nconservatively predicting the background class to avoid false seagrass\nmisclassifications in blurry or dark patches. Our method outperforms previous\napproaches that require patch-level labels on the multi-species 'DeepSeagrass'\ndataset by 6.8% (absolute) for the class-weighted F1 score, and by 12.1%\n(absolute) F1 score for seagrass presence/absence on the 'Global Wetlands'\ndataset. We also present two case studies for real-world deployment: outlier\ndetection on the Global Wetlands dataset, and application of our method on\nimagery collected by FloatyBoat, an autonomous surface vehicle.\n","authors":["Scarlett Raine","Ross Marchant","Brano Kusy","Frederic Maire","Tobias Fischer"],"pdf_url":"https://arxiv.org/pdf/2303.00973v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2303.00972v1","updated":"2023-03-02T05:10:31Z","published":"2023-03-02T05:10:31Z","title":"Practical Network Acceleration with Tiny Sets: Hypothesis, Theory, and\n  Algorithm","summary":"  Due to data privacy issues, accelerating networks with tiny training sets has\nbecome a critical need in practice. Previous methods achieved promising results\nempirically by filter-level pruning. In this paper, we both study this problem\ntheoretically and propose an effective algorithm aligning well with our\ntheoretical results. First, we propose the finetune convexity hypothesis to\nexplain why recent few-shot compression algorithms do not suffer from\noverfitting problems. Based on it, a theory is further established to explain\nthese methods for the first time. Compared to naively finetuning a pruned\nnetwork, feature mimicking is proved to achieve a lower variance of parameters\nand hence enjoys easier optimization. With our theoretical conclusions, we\nclaim dropping blocks is a fundamentally superior few-shot compression scheme\nin terms of more convex optimization and a higher acceleration ratio. To choose\nwhich blocks to drop, we propose a new metric, recoverability, to effectively\nmeasure the difficulty of recovering the compressed network. Finally, we\npropose an algorithm named PRACTISE to accelerate networks using only tiny\ntraining sets. PRACTISE outperforms previous methods by a significant margin.\nFor 22% latency reduction, it surpasses previous methods by on average 7\npercentage points on ImageNet-1k. It also works well under data-free or\nout-of-domain data settings. Our code is at\nhttps://github.com/DoctorKey/Practise\n","authors":["Guo-Hua Wang","Jianxin Wu"],"pdf_url":"https://arxiv.org/pdf/2303.00972v1.pdf","comment":"under review for TPAMI"},{"id":"http://arxiv.org/abs/2303.00971v1","updated":"2023-03-02T05:10:23Z","published":"2023-03-02T05:10:23Z","title":"Disentangling Orthogonal Planes for Indoor Panoramic Room Layout\n  Estimation with Cross-Scale Distortion Awareness","summary":"  Based on the Manhattan World assumption, most existing indoor layout\nestimation schemes focus on recovering layouts from vertically compressed 1D\nsequences. However, the compression procedure confuses the semantics of\ndifferent planes, yielding inferior performance with ambiguous\ninterpretability.\n  To address this issue, we propose to disentangle this 1D representation by\npre-segmenting orthogonal (vertical and horizontal) planes from a complex\nscene, explicitly capturing the geometric cues for indoor layout estimation.\nConsidering the symmetry between the floor boundary and ceiling boundary, we\nalso design a soft-flipping fusion strategy to assist the pre-segmentation.\nBesides, we present a feature assembling mechanism to effectively integrate\nshallow and deep features with distortion distribution awareness. To compensate\nfor the potential errors in pre-segmentation, we further leverage triple\nattention to reconstruct the disentangled sequences for better performance.\nExperiments on four popular benchmarks demonstrate our superiority over\nexisting SoTA solutions, especially on the 3DIoU metric. The code is available\nat \\url{https://github.com/zhijieshen-bjtu/DOPNet}.\n","authors":["Zhijie Shen","Zishuo Zheng","Chunyu Lin","Lang Nie","Kang Liao","Yao Zhao"],"pdf_url":"https://arxiv.org/pdf/2303.00971v1.pdf","comment":"Accepted to CVPR2023"},{"id":"http://arxiv.org/abs/2207.13298v3","updated":"2023-03-02T04:54:00Z","published":"2022-07-27T05:09:54Z","title":"Is Attention All That NeRF Needs?","summary":"  We present Generalizable NeRF Transformer (GNT), a transformer-based\narchitecture that reconstructs Neural Radiance Fields (NeRFs) and learns to\nrenders novel views on the fly from source views. While prior works on NeRFs\noptimize a scene representation by inverting a handcrafted rendering equation,\nGNT achieves neural representation and rendering that generalizes across scenes\nusing transformers at two stages. (1) The view transformer leverages multi-view\ngeometry as an inductive bias for attention-based scene representation, and\npredicts coordinate-aligned features by aggregating information from epipolar\nlines on the neighboring views. (2) The ray transformer renders novel views\nusing attention to decode the features from the view transformer along the\nsampled points during ray marching. Our experiments demonstrate that when\noptimized on a single scene, GNT can successfully reconstruct NeRF without an\nexplicit rendering formula due to the learned ray renderer. When trained on\nmultiple scenes, GNT consistently achieves state-of-the-art performance when\ntransferring to unseen scenes and outperform all other methods by ~10% on\naverage. Our analysis of the learned attention maps to infer depth and\nocclusion indicate that attention enables learning a physically-grounded\nrendering. Our results show the promise of transformers as a universal modeling\ntool for graphics. Please refer to our project page for video results:\nhttps://vita-group.github.io/GNT/.\n","authors":["Mukund Varma T","Peihao Wang","Xuxi Chen","Tianlong Chen","Subhashini Venugopalan","Zhangyang Wang"],"pdf_url":"https://arxiv.org/pdf/2207.13298v3.pdf","comment":"International Conference on Learning Representations (ICLR), 2023"},{"id":"http://arxiv.org/abs/2212.03125v4","updated":"2023-03-02T04:44:43Z","published":"2022-12-06T16:42:22Z","title":"Self-supervised and Weakly Supervised Contrastive Learning for\n  Frame-wise Action Representations","summary":"  Previous work on action representation learning focused on global\nrepresentations for short video clips. In contrast, many practical\napplications, such as video alignment, strongly demand learning the intensive\nrepresentation of long videos. In this paper, we introduce a new framework of\ncontrastive action representation learning (CARL) to learn frame-wise action\nrepresentation in a self-supervised or weakly-supervised manner, especially for\nlong videos. Specifically, we introduce a simple but effective video encoder\nthat considers both spatial and temporal context by combining convolution and\ntransformer. Inspired by the recent massive progress in self-supervised\nlearning, we propose a new sequence contrast loss (SCL) applied to two related\nviews obtained by expanding a series of spatio-temporal data in two versions.\nOne is the self-supervised version that optimizes embedding space by minimizing\nKL-divergence between sequence similarity of two augmented views and prior\nGaussian distribution of timestamp distance. The other is the weakly-supervised\nversion that builds more sample pairs among videos using video-level labels by\ndynamic time wrapping (DTW). Experiments on FineGym, PennAction, and Pouring\ndatasets show that our method outperforms previous state-of-the-art by a large\nmargin for downstream fine-grained action classification and even faster\ninference. Surprisingly, although without training on paired videos like in\nprevious works, our self-supervised version also shows outstanding performance\nin video alignment and fine-grained frame retrieval tasks.\n","authors":["Minghao Chen","Renbo Tu","Chenxi Huang","Yuqi Lin","Boxi Wu","Deng Cai"],"pdf_url":"https://arxiv.org/pdf/2212.03125v4.pdf","comment":"author conflicts"},{"id":"http://arxiv.org/abs/2303.00952v1","updated":"2023-03-02T04:12:53Z","published":"2023-03-02T04:12:53Z","title":"MuscleMap: Towards Video-based Activated Muscle Group Estimation","summary":"  In this paper, we tackle the new task of video-based Activated Muscle Group\nEstimation (AMGE) aiming at identifying currently activated muscular regions of\nhumans performing a specific activity. Video-based AMGE is an important yet\noverlooked problem. To this intent, we provide the MuscleMap136 featuring >15K\nvideo clips with 136 different activities and 20 labeled muscle groups. This\ndataset opens the vistas to multiple video-based applications in sports and\nrehabilitation medicine. We further complement the main MuscleMap136 dataset,\nwhich specifically targets physical exercise, with Muscle-UCF90 and\nMuscle-HMDB41, which are new variants of the well-known activity recognition\nbenchmarks extended with AMGE annotations. With MuscleMap136, we discover\nlimitations of state-of-the-art architectures for human activity recognition\nwhen dealing with multi-label muscle annotations and good generalization to\nunseen activities is required. To address this, we propose a new multimodal\ntransformer-based model, TransM3E, which surpasses current activity recognition\nmodels for AMGE, especially as it comes to dealing with previously unseen\nactivities. The datasets and code will be publicly available at\nhttps://github.com/KPeng9510/MuscleMap.\n","authors":["Kunyu Peng","David Schneider","Alina Roitberg","Kailun Yang","Jiaming Zhang","M. Saquib Sarfraz","Rainer Stiefelhagen"],"pdf_url":"https://arxiv.org/pdf/2303.00952v1.pdf","comment":"The datasets and code will be publicly available at\n  https://github.com/KPeng9510/MuscleMap"},{"id":"http://arxiv.org/abs/2209.15076v4","updated":"2023-03-02T03:58:57Z","published":"2022-09-29T19:54:13Z","title":"3D UX-Net: A Large Kernel Volumetric ConvNet Modernizing Hierarchical\n  Transformer for Medical Image Segmentation","summary":"  The recent 3D medical ViTs (e.g., SwinUNETR) achieve the state-of-the-art\nperformances on several 3D volumetric data benchmarks, including 3D medical\nimage segmentation. Hierarchical transformers (e.g., Swin Transformers)\nreintroduced several ConvNet priors and further enhanced the practical\nviability of adapting volumetric segmentation in 3D medical datasets. The\neffectiveness of hybrid approaches is largely credited to the large receptive\nfield for non-local self-attention and the large number of model parameters. In\nthis work, we propose a lightweight volumetric ConvNet, termed 3D UX-Net, which\nadapts the hierarchical transformer using ConvNet modules for robust volumetric\nsegmentation. Specifically, we revisit volumetric depth-wise convolutions with\nlarge kernel size (e.g. starting from $7\\times7\\times7$) to enable the larger\nglobal receptive fields, inspired by Swin Transformer. We further substitute\nthe multi-layer perceptron (MLP) in Swin Transformer blocks with pointwise\ndepth convolutions and enhance model performances with fewer normalization and\nactivation layers, thus reducing the number of model parameters. 3D UX-Net\ncompetes favorably with current SOTA transformers (e.g. SwinUNETR) using three\nchallenging public datasets on volumetric brain and abdominal imaging: 1)\nMICCAI Challenge 2021 FLARE, 2) MICCAI Challenge 2021 FeTA, and 3) MICCAI\nChallenge 2022 AMOS. 3D UX-Net consistently outperforms SwinUNETR with\nimprovement from 0.929 to 0.938 Dice (FLARE2021) and 0.867 to 0.874 Dice\n(Feta2021). We further evaluate the transfer learning capability of 3D UX-Net\nwith AMOS2022 and demonstrates another improvement of $2.27\\%$ Dice (from 0.880\nto 0.900). The source code with our proposed model are available at\nhttps://github.com/MASILab/3DUX-Net.\n","authors":["Ho Hin Lee","Shunxing Bao","Yuankai Huo","Bennett A. Landman"],"pdf_url":"https://arxiv.org/pdf/2209.15076v4.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2303.00944v1","updated":"2023-03-02T03:40:05Z","published":"2023-03-02T03:40:05Z","title":"Attention-based Graph Convolution Fusing Latent Structures and Multiple\n  Features for Graph Neural Networks","summary":"  We present an attention-based spatial graph convolution (AGC) for graph\nneural networks (GNNs). Existing AGCs focus on only using node-wise features\nand utilizing one type of attention function when calculating attention\nweights. Instead, we propose two methods to improve the representational power\nof AGCs by utilizing 1) structural information in a high-dimensional space and\n2) multiple attention functions when calculating their weights. The first\nmethod computes a local structure representation of a graph in a\nhigh-dimensional space. The second method utilizes multiple attention functions\nsimultaneously in one AGC. Both approaches can be combined. We also propose a\nGNN for the classification of point clouds and that for the prediction of point\nlabels in a point cloud based on the proposed AGC. According to experiments,\nthe proposed GNNs perform better than existing methods. Our codes open at\nhttps://github.com/liyang-tuat/SFAGC.\n","authors":["Yang Li","Yuichi Tanaka"],"pdf_url":"https://arxiv.org/pdf/2303.00944v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00943v1","updated":"2023-03-02T03:36:15Z","published":"2023-03-02T03:36:15Z","title":"Evolutionary Computation in Action: Hyperdimensional Deep Embedding\n  Spaces of Gigapixel Pathology Images","summary":"  One of the main obstacles of adopting digital pathology is the challenge of\nefficient processing of hyperdimensional digitized biopsy samples, called whole\nslide images (WSIs). Exploiting deep learning and introducing compact WSI\nrepresentations are urgently needed to accelerate image analysis and facilitate\nthe visualization and interpretability of pathology results in a postpandemic\nworld. In this paper, we introduce a new evolutionary approach for WSI\nrepresentation based on large-scale multi-objective optimization (LSMOP) of\ndeep embeddings. We start with patch-based sampling to feed KimiaNet , a\nhistopathology-specialized deep network, and to extract a multitude of feature\nvectors. Coarse multi-objective feature selection uses the reduced search space\nstrategy guided by the classification accuracy and the number of features. In\nthe second stage, the frequent features histogram (FFH), a novel WSI\nrepresentation, is constructed by multiple runs of coarse LSMOP. Fine\nevolutionary feature selection is then applied to find a compact (short-length)\nfeature vector based on the FFH and contributes to a more robust deep-learning\napproach to digital pathology supported by the stochastic power of evolutionary\nalgorithms. We validate the proposed schemes using The Cancer Genome Atlas\n(TCGA) images in terms of WSI representation, classification accuracy, and\nfeature quality. Furthermore, a novel decision space for multicriteria decision\nmaking in the LSMOP field is introduced. Finally, a patch-level visualization\napproach is proposed to increase the interpretability of deep features. The\nproposed evolutionary algorithm finds a very compact feature vector to\nrepresent a WSI (almost 14,000 times smaller than the original feature vectors)\nwith 8% higher accuracy compared to the codes provided by the state-of-the-art\nmethods.\n","authors":["Azam Asilian Bidgoli","Shahryar Rahnamayan","Taher Dehkharghanian","Abtin Riasatian","H. R. Tizhoosh"],"pdf_url":"https://arxiv.org/pdf/2303.00943v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00942v1","updated":"2023-03-02T03:34:28Z","published":"2023-03-02T03:34:28Z","title":"Meta-information-aware Dual-path Transformer for Differential Diagnosis\n  of Multi-type Pancreatic Lesions in Multi-phase CT","summary":"  Pancreatic cancer is one of the leading causes of cancer-related death.\nAccurate detection, segmentation, and differential diagnosis of the full\ntaxonomy of pancreatic lesions, i.e., normal, seven major types of lesions, and\nother lesions, is critical to aid the clinical decision-making of patient\nmanagement and treatment. However, existing works focus on segmentation and\nclassification for very specific lesion types (PDAC) or groups. Moreover, none\nof the previous work considers using lesion prevalence-related non-imaging\npatient information to assist the differential diagnosis. To this end, we\ndevelop a meta-information-aware dual-path transformer and exploit the\nfeasibility of classification and segmentation of the full taxonomy of\npancreatic lesions. Specifically, the proposed method consists of a CNN-based\nsegmentation path (S-path) and a transformer-based classification path\n(C-path). The S-path focuses on initial feature extraction by semantic\nsegmentation using a UNet-based network. The C-path utilizes both the extracted\nfeatures and meta-information for patient-level classification based on stacks\nof dual-path transformer blocks that enhance the modeling of global contextual\ninformation. A large-scale multi-phase CT dataset of 3,096 patients with\npathology-confirmed pancreatic lesion class labels, voxel-wise manual\nannotations of lesions from radiologists, and patient meta-information, was\ncollected for training and evaluations. Our results show that our method can\nenable accurate classification and segmentation of the full taxonomy of\npancreatic lesions, approaching the accuracy of the radiologist's report and\nsignificantly outperforming previous baselines. Results also show that adding\nthe common meta-information, i.e., gender and age, can boost the model's\nperformance, thus demonstrating the importance of meta-information for aiding\npancreatic disease diagnosis.\n","authors":["Bo Zhou","Yingda Xia","Jiawen Yao","Le Lu","Jingren Zhou","Chi Liu","James S. Duncan","Ling Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.00942v1.pdf","comment":"Accepted at Information Processing in Medical Imaging (IPMI 2023)"},{"id":"http://arxiv.org/abs/2303.00941v1","updated":"2023-03-02T03:29:16Z","published":"2023-03-02T03:29:16Z","title":"ParaFormer: Parallel Attention Transformer for Efficient Feature\n  Matching","summary":"  Heavy computation is a bottleneck limiting deep-learningbased feature\nmatching algorithms to be applied in many realtime applications. However,\nexisting lightweight networks optimized for Euclidean data cannot address\nclassical feature matching tasks, since sparse keypoint based descriptors are\nexpected to be matched. This paper tackles this problem and proposes two\nconcepts: 1) a novel parallel attention model entitled ParaFormer and 2) a\ngraph based U-Net architecture with attentional pooling. First, ParaFormer\nfuses features and keypoint positions through the concept of amplitude and\nphase, and integrates self- and cross-attention in a parallel manner which\nachieves a win-win performance in terms of accuracy and efficiency. Second,\nwith U-Net architecture and proposed attentional pooling, the ParaFormer-U\nvariant significantly reduces computational complexity, and minimize\nperformance loss caused by downsampling. Sufficient experiments on various\napplications, including homography estimation, pose estimation, and image\nmatching, demonstrate that ParaFormer achieves state-of-the-art performance\nwhile maintaining high efficiency. The efficient ParaFormer-U variant achieves\ncomparable performance with less than 50% FLOPs of the existing attention-based\nmodels.\n","authors":["Xiaoyong Lu","Yaping Yan","Bin Kang","Songlin Du"],"pdf_url":"https://arxiv.org/pdf/2303.00941v1.pdf","comment":"Have been accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2303.00939v1","updated":"2023-03-02T03:24:21Z","published":"2023-03-02T03:24:21Z","title":"Spatial Layout Consistency for 3D Semantic Segmentation","summary":"  Due to the aged nature of much of the utility network infrastructure,\ndeveloping a robust and trustworthy computer vision system capable of\ninspecting it with minimal human intervention has attracted considerable\nresearch attention. The airborne laser terrain mapping (ALTM) system quickly\nbecomes the central data collection system among the numerous available\nsensors. Its ability to penetrate foliage with high-powered energy provides\nwide coverage and achieves survey-grade ranging accuracy. However, the\npost-data acquisition process for classifying the ALTM's dense and irregular\npoint clouds is a critical bottleneck that must be addressed to improve\nefficiency and accuracy. We introduce a novel deep convolutional neural network\n(DCNN) technique for achieving voxel-based semantic segmentation of the ALTM's\npoint clouds. The suggested deep learning method, Semantic Utility Network\n(SUNet) is a multi-dimensional and multi-resolution network. SUNet combines two\nnetworks: one classifies point clouds at multi-resolution with object\ncategories in three dimensions and another predicts two-dimensional regional\nlabels distinguishing corridor regions from non-corridors. A significant\ninnovation of the SUNet is that it imposes spatial layout consistency on the\noutcomes of voxel-based and regional segmentation results. The proposed\nmulti-dimensional DCNN combines hierarchical context for spatial layout\nembedding with a coarse-to-fine strategy. We conducted a comprehensive ablation\nstudy to test SUNet's performance using 67 km x 67 km of utility corridor data\nat a density of 5pp/m2. Our experiments demonstrated that SUNet's spatial\nlayout consistency and a multi-resolution feature aggregation could\nsignificantly improve performance, outperforming the SOTA baseline network and\nachieving a good F1 score for pylon 89%, ground 99%, vegetation 99% and\npowerline 98% classes.\n","authors":["Maryam Jameela","Gunho Sohn"],"pdf_url":"https://arxiv.org/pdf/2303.00939v1.pdf","comment":"12th IAPR International Workshop on Pattern Recognition in Remote\n  Sensing, ICPR 2022"},{"id":"http://arxiv.org/abs/2303.00938v1","updated":"2023-03-02T03:23:18Z","published":"2023-03-02T03:23:18Z","title":"UniDexGrasp: Universal Robotic Dexterous Grasping via Learning Diverse\n  Proposal Generation and Goal-Conditioned Policy","summary":"  In this work, we tackle the problem of learning universal robotic dexterous\ngrasping from a point cloud observation under a table-top setting. The goal is\nto grasp and lift up objects in high-quality and diverse ways and generalize\nacross hundreds of categories and even the unseen. Inspired by successful\npipelines used in parallel gripper grasping, we split the task into two stages:\n1) grasp proposal (pose) generation and 2) goal-conditioned grasp execution.\nFor the first stage, we propose a novel probabilistic model of grasp pose\nconditioned on the point cloud observation that factorizes rotation from\ntranslation and articulation. Trained on our synthesized large-scale dexterous\ngrasp dataset, this model enables us to sample diverse and high-quality\ndexterous grasp poses for the object in the point cloud. For the second stage,\nwe propose to replace the motion planning used in parallel gripper grasping\nwith a goal-conditioned grasp policy, due to the complexity involved in\ndexterous grasping execution. Note that it is very challenging to learn this\nhighly generalizable grasp policy that only takes realistic inputs without\noracle states. We thus propose several important innovations, including state\ncanonicalization, object curriculum, and teacher-student distillation.\nIntegrating the two stages, our final pipeline becomes the first to achieve\nuniversal generalization for dexterous grasping, demonstrating an average\nsuccess rate of more than 60% on thousands of object instances, which\nsignificantly out performs all baselines, meanwhile showing only a minimal\ngeneralization gap.\n","authors":["Yinzhen Xu","Weikang Wan","Jialiang Zhang","Haoran Liu","Zikang Shan","Hao Shen","Ruicheng Wang","Haoran Geng","Yijia Weng","Jiayi Chen","Tengyu Liu","Li Yi","He Wang"],"pdf_url":"https://arxiv.org/pdf/2303.00938v1.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2107.10998v4","updated":"2023-03-02T03:11:04Z","published":"2021-07-23T02:18:00Z","title":"Pruning Ternary Quantization","summary":"  Inference time, model size, and accuracy are three key factors in deep model\ncompression.\n  Most of the existing work addresses these three key factors separately as it\nis difficult to optimize them all at the same time.\n  For example, low-bit quantization aims at obtaining a faster model; weight\nsharing quantization aims at improving compression ratio and accuracy; and\nmixed-precision quantization aims at balancing accuracy and inference time. To\nsimultaneously optimize bit-width, model size, and accuracy, we propose pruning\nternary quantization (PTQ): a simple, effective, symmetric ternary quantization\nmethod. We integrate L2 normalization, pruning, and the weight decay term to\nreduce the weight discrepancy in the gradient estimator during quantization,\nthus producing highly compressed ternary weights. Our method brings the highest\ntest accuracy and the highest compression ratio. For example, it produces a\n939kb (49$\\times$) 2bit ternary ResNet-18 model with only 4\\% accuracy drop on\nthe ImageNet dataset. It compresses 170MB Mask R-CNN to 5MB (34$\\times$) with\nonly 2.8\\% average precision drop. Our method is verified on image\nclassification, object detection/segmentation tasks with different network\nstructures such as ResNet-18, ResNet-50, and MobileNetV2.\n","authors":["Dan Liu","Xi Chen","Jie Fu","Chen Ma","Xue Liu"],"pdf_url":"https://arxiv.org/pdf/2107.10998v4.pdf","comment":"old version"},{"id":"http://arxiv.org/abs/2210.03310v3","updated":"2023-03-02T03:08:10Z","published":"2022-10-07T03:52:27Z","title":"Scaling Forward Gradient With Local Losses","summary":"  Forward gradient learning computes a noisy directional gradient and is a\nbiologically plausible alternative to backprop for learning deep neural\nnetworks. However, the standard forward gradient algorithm, when applied\nnaively, suffers from high variance when the number of parameters to be learned\nis large. In this paper, we propose a series of architectural and algorithmic\nmodifications that together make forward gradient learning practical for\nstandard deep learning benchmark tasks. We show that it is possible to\nsubstantially reduce the variance of the forward gradient estimator by applying\nperturbations to activations rather than weights. We further improve the\nscalability of forward gradient by introducing a large number of local greedy\nloss functions, each of which involves only a small number of learnable\nparameters, and a new MLPMixer-inspired architecture, LocalMixer, that is more\nsuitable for local learning. Our approach matches backprop on MNIST and\nCIFAR-10 and significantly outperforms previously proposed backprop-free\nalgorithms on ImageNet.\n","authors":["Mengye Ren","Simon Kornblith","Renjie Liao","Geoffrey Hinton"],"pdf_url":"https://arxiv.org/pdf/2210.03310v3.pdf","comment":"31 pages, ICLR 2023"},{"id":"http://arxiv.org/abs/2207.00215v2","updated":"2023-03-02T03:07:47Z","published":"2022-07-01T05:52:14Z","title":"Polarized Color Image Denoising using Pocoformer","summary":"  Polarized color photography provides both visual textures and object\nsurficial information in one single snapshot. However, the use of the\ndirectional polarizing filter array causes extremely lower photon count and SNR\ncompared to conventional color imaging. Thus, the feature essentially leads to\nunpleasant noisy images and destroys polarization analysis performance. It is a\nchallenge for traditional image processing pipelines owing to the fact that the\nphysical constraints exerted implicitly in the channels are excessively\ncomplicated. To address this issue, we propose a learning-based approach to\nsimultaneously restore clean signals and precise polarization information. A\nreal-world polarized color image dataset of paired raw short-exposed noisy and\nlong-exposed reference images are captured to support the learning-based\npipeline. Moreover, we embrace the development of vision Transformer and\npropose a hybrid transformer model for the Polarized Color image denoising,\nnamely PoCoformer, for a better restoration performance. Abundant experiments\ndemonstrate the effectiveness of proposed method and key factors that affect\nresults are analyzed.\n","authors":["Zhuoxiao Li","Haiyang Jiang","Yinqiang Zheng"],"pdf_url":"https://arxiv.org/pdf/2207.00215v2.pdf","comment":"New version is accpeted by CVPR 2023 and great modifications are\n  taken"},{"id":"http://arxiv.org/abs/2210.00788v2","updated":"2023-03-02T03:00:36Z","published":"2022-10-03T09:54:39Z","title":"Towards a Unified View on Visual Parameter-Efficient Transfer Learning","summary":"  Parameter efficient transfer learning (PETL) aims at making good use of the\nrepresentation knowledge in the pre-trained large models by fine-tuning a small\nnumber of parameters. Recently, taking inspiration from the natural language\nprocessing (NLP) domain, popular PETL techniques such as prompt-tuning and\nAdapter have also been successfully applied to the vision domain. However,\nprefix-tuning remains under-explored for vision tasks. In this work, we intend\nto adapt large vision models (LVMs) to downstream tasks with a good\nparameter-accuracy trade-off. Towards this goal, we propose a framework with a\nunified view of PETL called visual-PETL (V-PETL) to investigate the effects of\ndifferent PETL techniques, data scales of downstream domains, positions of\ntrainable parameters, and other aspects affecting the trade-off. Specifically,\nwe analyze the positional importance of trainable parameters and differences\nbetween NLP and vision tasks in terms of data structures and pre-training\nmechanisms while implementing various PETL techniques, especially for the\nunder-explored prefix-tuning technique. Based on a comprehensive understanding\nof the differences between NLP and vision data, we propose a new variation of\nthe prefix-tuning module called parallel attention (PATT) for vision downstream\ntasks. An extensive empirical analysis on vision tasks via different frozen\nLVMs has been carried and the findings show that the proposed PATT can\neffectively contribute to other PETL techniques. An effective scheme Swin-BAPAT\nderived from the proposed V-PETL framework achieves significantly better\nperformance than the state-of-the-art AdaptFormer-Swin with slightly more\nparameters and outperforms full-tuning with far fewer parameters. Code and data\nare available at: https://github.com/bruceyo/V-PETL.\n","authors":["Bruce X. B. Yu","Jianlong Chang","Lingbo Liu","Qi Tian","Chang Wen Chen"],"pdf_url":"https://arxiv.org/pdf/2210.00788v2.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2303.00563v2","updated":"2023-03-02T02:26:07Z","published":"2023-03-01T15:09:45Z","title":"ROCO: A Roundabout Traffic Conflict Dataset","summary":"  Traffic conflicts have been studied by the transportation research community\nas a surrogate safety measure for decades. However, due to the rarity of\ntraffic conflicts, collecting large-scale real-world traffic conflict data\nbecomes extremely challenging. In this paper, we introduce and analyze ROCO - a\nreal-world roundabout traffic conflict dataset. The data is collected at a\ntwo-lane roundabout at the intersection of State St. and W. Ellsworth Rd. in\nAnn Arbor, Michigan. We use raw video dataflow captured from four fisheye\ncameras installed at the roundabout as our input data source. We adopt a\nlearning-based conflict identification algorithm from video to find potential\ntraffic conflicts, and then manually label them for dataset collection and\nannotation. In total 557 traffic conflicts and 17 traffic crashes are collected\nfrom August 2021 to October 2021. We provide trajectory data of the traffic\nconflict scenes extracted using our roadside perception system. Taxonomy based\non traffic conflict severity, reason for the traffic conflict, and its effect\non the traffic flow is provided. With the traffic conflict data collected, we\ndiscover that failure to yield to circulating vehicles when entering the\nroundabout is the largest contributing reason for traffic conflicts. ROCO\ndataset will be made public in the short future.\n","authors":["Depu Meng","Owen Sayer","Rusheng Zhang","Shengyin Shen","Houqiang Li","Henry X. Liu"],"pdf_url":"https://arxiv.org/pdf/2303.00563v2.pdf","comment":"Accepted by TRBAM 2023 presentation"},{"id":"http://arxiv.org/abs/2303.00917v1","updated":"2023-03-02T02:26:04Z","published":"2023-03-02T02:26:04Z","title":"Enhancing General Face Forgery Detection via Vision Transformer with\n  Low-Rank Adaptation","summary":"  Nowadays, forgery faces pose pressing security concerns over fake news,\nfraud, impersonation, etc. Despite the demonstrated success in intra-domain\nface forgery detection, existing detection methods lack generalization\ncapability and tend to suffer from dramatic performance drops when deployed to\nunforeseen domains. To mitigate this issue, this paper designs a more general\nfake face detection model based on the vision transformer(ViT) architecture. In\nthe training phase, the pretrained ViT weights are freezed, and only the\nLow-Rank Adaptation(LoRA) modules are updated. Additionally, the Single Center\nLoss(SCL) is applied to supervise the training process, further improving the\ngeneralization capability of the model. The proposed method achieves\nstate-of-the-arts detection performances in both cross-manipulation and\ncross-dataset evaluations.\n","authors":["Chenqi Kong","Haoliang Li","Shiqi Wang"],"pdf_url":"https://arxiv.org/pdf/2303.00917v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00915v1","updated":"2023-03-02T02:20:04Z","published":"2023-03-02T02:20:04Z","title":"Large-Scale Domain-Specific Pretraining for Biomedical Vision-Language\n  Processing","summary":"  Contrastive pretraining on parallel image-text data has attained great\nsuccess in vision-language processing (VLP), as exemplified by CLIP and related\nmethods. However, prior explorations tend to focus on general domains in the\nweb. Biomedical images and text are rather different, but publicly available\ndatasets are small and skew toward chest X-ray, thus severely limiting\nprogress. In this paper, we conducted by far the largest study on biomedical\nVLP, using 15 million figure-caption pairs extracted from biomedical research\narticles in PubMed Central. Our dataset (PMC-15M) is two orders of magnitude\nlarger than existing biomedical image-text datasets such as MIMIC-CXR, and\nspans a diverse range of biomedical images. The standard CLIP method is\nsuboptimal for the biomedical domain. We propose BiomedCLIP with\ndomain-specific adaptations tailored to biomedical VLP. We conducted extensive\nexperiments and ablation studies on standard biomedical imaging tasks from\nretrieval to classification to visual question-answering (VQA). BiomedCLIP\nestablished new state of the art in a wide range of standard datasets,\nsubstantially outperformed prior VLP approaches. Surprisingly, BiomedCLIP even\noutperformed radiology-specific state-of-the-art models such as BioViL on\nradiology-specific tasks such as RSNA pneumonia detection, thus highlighting\nthe utility in large-scale pretraining across all biomedical image types. We\nwill release our models at https://aka.ms/biomedclip to facilitate future\nresearch in biomedical VLP.\n","authors":["Sheng Zhang","Yanbo Xu","Naoto Usuyama","Jaspreet Bagga","Robert Tinn","Sam Preston","Rajesh Rao","Mu Wei","Naveen Valluri","Cliff Wong","Matthew P. Lungren","Tristan Naumann","Hoifung Poon"],"pdf_url":"https://arxiv.org/pdf/2303.00915v1.pdf","comment":"The models will be released soon at https://aka.ms/biomedclip"},{"id":"http://arxiv.org/abs/2303.00914v1","updated":"2023-03-02T02:18:56Z","published":"2023-03-02T02:18:56Z","title":"Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation","summary":"  Fully test-time adaptation aims to adapt the network model based on\nsequential analysis of input samples during the inference stage to address the\ncross-domain performance degradation problem of deep neural networks. We take\ninspiration from the biological plausibility learning where the neuron\nresponses are tuned based on a local synapse-change procedure and activated by\ncompetitive lateral inhibition rules. Based on these feed-forward learning\nrules, we design a soft Hebbian learning process which provides an unsupervised\nand effective mechanism for online adaptation. We observe that the performance\nof this feed-forward Hebbian learning for fully test-time adaptation can be\nsignificantly improved by incorporating a feedback neuro-modulation layer. It\nis able to fine-tune the neuron responses based on the external feedback\ngenerated by the error back-propagation from the top inference layers. This\nleads to our proposed neuro-modulated Hebbian learning (NHL) method for fully\ntest-time adaptation. With the unsupervised feed-forward soft Hebbian learning\nbeing combined with a learned neuro-modulator to capture feedback from external\nresponses, the source model can be effectively adapted during the testing\nprocess. Experimental results on benchmark datasets demonstrate that our\nproposed method can significantly improve the adaptation performance of network\nmodels and outperforms existing state-of-the-art methods.\n","authors":["Yushun Tang","Ce Zhang","Heng Xu","Shuoshuo Chen","Jie Cheng","Luziwei Leng","Qinghai Guo","Zhihai He"],"pdf_url":"https://arxiv.org/pdf/2303.00914v1.pdf","comment":"CVPR2023 accepted"},{"id":"http://arxiv.org/abs/2302.14557v2","updated":"2023-03-02T02:01:19Z","published":"2023-02-28T13:26:24Z","title":"GRAN: Ghost Residual Attention Network for Single Image Super Resolution","summary":"  Recently, many works have designed wider and deeper networks to achieve\nhigher image super-resolution performance. Despite their outstanding\nperformance, they still suffer from high computational resources, preventing\nthem from directly applying to embedded devices. To reduce the computation\nresources and maintain performance, we propose a novel Ghost Residual Attention\nNetwork (GRAN) for efficient super-resolution. This paper introduces Ghost\nResidual Attention Block (GRAB) groups to overcome the drawbacks of the\nstandard convolutional operation, i.e., redundancy of the intermediate feature.\nGRAB consists of the Ghost Module and Channel and Spatial Attention Module\n(CSAM) to alleviate the generation of redundant features. Specifically, Ghost\nModule can reveal information underlying intrinsic features by employing linear\noperations to replace the standard convolutions. Reducing redundant features by\nthe Ghost Module, our model decreases memory and computing resource\nrequirements in the network. The CSAM pays more comprehensive attention to\nwhere and what the feature extraction is, which is critical to recovering the\nimage details. Experiments conducted on the benchmark datasets demonstrate the\nsuperior performance of our method in both qualitative and quantitative.\nCompared to the baseline models, we achieve higher performance with lower\ncomputational resources, whose parameters and FLOPs have decreased by more than\nten times.\n","authors":["Axi Niu","Pei Wang","Yu Zhu","Jinqiu Sun","Qingsen Yan","Yanning Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.14557v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00905v1","updated":"2023-03-02T01:55:10Z","published":"2023-03-02T01:55:10Z","title":"Open-World Object Manipulation using Pre-trained Vision-Language Models","summary":"  For robots to follow instructions from people, they must be able to connect\nthe rich semantic information in human vocabulary, e.g. \"can you get me the\npink stuffed whale?\" to their sensory observations and actions. This brings up\na notably difficult challenge for robots: while robot learning approaches allow\nrobots to learn many different behaviors from first-hand experience, it is\nimpractical for robots to have first-hand experiences that span all of this\nsemantic information. We would like a robot's policy to be able to perceive and\npick up the pink stuffed whale, even if it has never seen any data interacting\nwith a stuffed whale before. Fortunately, static data on the internet has vast\nsemantic information, and this information is captured in pre-trained\nvision-language models. In this paper, we study whether we can interface robot\npolicies with these pre-trained models, with the aim of allowing robots to\ncomplete instructions involving object categories that the robot has never seen\nfirst-hand. We develop a simple approach, which we call Manipulation of\nOpen-World Objects (MOO), which leverages a pre-trained vision-language model\nto extract object-identifying information from the language command and image,\nand conditions the robot policy on the current image, the instruction, and the\nextracted object information. In a variety of experiments on a real mobile\nmanipulator, we find that MOO generalizes zero-shot to a wide range of novel\nobject categories and environments. In addition, we show how MOO generalizes to\nother, non-language-based input modalities to specify the object of interest\nsuch as finger pointing, and how it can be further extended to enable\nopen-world navigation and manipulation. The project's website and evaluation\nvideos can be found at https://robot-moo.github.io/\n","authors":["Austin Stone","Ted Xiao","Yao Lu","Keerthana Gopalakrishnan","Kuang-Huei Lee","Quan Vuong","Paul Wohlhart","Brianna Zitkovich","Fei Xia","Chelsea Finn","Karol Hausman"],"pdf_url":"https://arxiv.org/pdf/2303.00905v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.05423v4","updated":"2023-03-02T01:52:48Z","published":"2022-10-11T13:04:59Z","title":"Learning to Locate Visual Answer in Video Corpus Using Question","summary":"  We introduce a new task, named video corpus visual answer localization\n(VCVAL), which aims to locate the visual answer in a large collection of\nuntrimmed instructional videos using a natural language question. This task\nrequires a range of skills - the interaction between vision and language, video\nretrieval, passage comprehension, and visual answer localization. In this\npaper, we propose a cross-modal contrastive global-span (CCGS) method for the\nVCVAL, jointly training the video corpus retrieval and visual answer\nlocalization subtasks with the global-span matrix. We have reconstructed a\ndataset named MedVidCQA, on which the VCVAL task is benchmarked. Experimental\nresults show that the proposed method outperforms other competitive methods\nboth in the video corpus retrieval and visual answer localization subtasks.\nMost importantly, we perform detailed analyses on extensive experiments, paving\na new path for understanding the instructional videos, which ushers in further\nresearch.\n","authors":["Bin Li","Yixuan Weng","Bin Sun","Shutao Li"],"pdf_url":"https://arxiv.org/pdf/2210.05423v4.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.00900v1","updated":"2023-03-02T01:48:05Z","published":"2023-03-02T01:48:05Z","title":"Transmission-Guided Bayesian Generative Model for Smoke Segmentation","summary":"  Smoke segmentation is essential to precisely localize wildfire so that it can\nbe extinguished in an early phase. Although deep neural networks have achieved\npromising results on image segmentation tasks, they are prone to be\noverconfident for smoke segmentation due to its non-rigid shape and transparent\nappearance. This is caused by both knowledge level uncertainty due to limited\ntraining data for accurate smoke segmentation and labeling level uncertainty\nrepresenting the difficulty in labeling ground-truth. To effectively model the\ntwo types of uncertainty, we introduce a Bayesian generative model to\nsimultaneously estimate the posterior distribution of model parameters and its\npredictions. Further, smoke images suffer from low contrast and ambiguity,\ninspired by physics-based image dehazing methods, we design a\ntransmission-guided local coherence loss to guide the network to learn\npair-wise relationships based on pixel distance and the transmission feature.\nTo promote the development of this field, we also contribute a high-quality\nsmoke segmentation dataset, SMOKE5K, consisting of 1,400 real and 4,000\nsynthetic images with pixel-wise annotation. Experimental results on benchmark\ntesting datasets illustrate that our model achieves both accurate predictions\nand reliable uncertainty maps representing model ignorance about its\nprediction. Our code and dataset are publicly available at:\nhttps://github.com/redlessme/Transmission-BVM.\n","authors":["Siyuan Yan","Jing Zhang","Nick Barnes"],"pdf_url":"https://arxiv.org/pdf/2303.00900v1.pdf","comment":"Accepted by AAAI2022"},{"id":"http://arxiv.org/abs/2204.07946v2","updated":"2023-03-02T01:42:42Z","published":"2022-04-17T07:20:50Z","title":"Integrated In-vehicle Monitoring System Using 3D Human Pose Estimation\n  and Seat Belt Segmentation","summary":"  Recently, along with interest in autonomous vehicles, the importance of\nmonitoring systems for both drivers and passengers inside vehicles has been\nincreasing. This paper proposes a novel in-vehicle monitoring system the\ncombines 3D pose estimation, seat-belt segmentation, and seat-belt status\nclassification networks. Our system outputs various information necessary for\nmonitoring by accurately considering the data characteristics of the in-vehicle\nenvironment. Specifically, the proposed 3D pose estimation directly estimates\nthe absolute coordinates of keypoints for a driver and passengers, and the\nproposed seat-belt segmentation is implemented by applying a structure based on\nthe feature pyramid. In addition, we propose a classification task to\ndistinguish between normal and abnormal states of wearing a seat belt using\nresults that combine 3D pose estimation with seat-belt segmentation. These\ntasks can be learned simultaneously and operate in real-time. Our method was\nevaluated on a private dataset we newly created and annotated. The experimental\nresults show that our method has significantly high performance that can be\napplied directly to real in-vehicle monitoring systems.\n","authors":["Ginam Kim","Hyunsung Kim","Joseph Kihoon Kim","Sung-Sik Cho","Yeong-Hun Park","Suk-Ju Kang"],"pdf_url":"https://arxiv.org/pdf/2204.07946v2.pdf","comment":"AAAI 2022 workshop AI for Transportation accepted"},{"id":"http://arxiv.org/abs/2303.00175v2","updated":"2023-03-02T01:40:50Z","published":"2023-03-01T02:07:48Z","title":"A Deep Neural Architecture for Harmonizing 3-D Input Data Analysis and\n  Decision Making in Medical Imaging","summary":"  Harmonizing the analysis of data, especially of 3-D image volumes, consisting\nof different number of slices and annotated per volume, is a significant\nproblem in training and using deep neural networks in various applications,\nincluding medical imaging. Moreover, unifying the decision making of the\nnetworks over different input datasets is crucial for the generation of rich\ndata-driven knowledge and for trusted usage in the applications. This paper\npresents a new deep neural architecture, named RACNet, which includes routing\nand feature alignment steps and effectively handles different input lengths and\nsingle annotations of the 3-D image inputs, whilst providing highly accurate\ndecisions. In addition, through latent variable extraction from the trained\nRACNet, a set of anchors are generated providing further insight on the\nnetwork's decision making. These can be used to enrich and unify data-driven\nknowledge extracted from different datasets. An extensive experimental study\nillustrates the above developments, focusing on COVID-19 diagnosis through\nanalysis of 3-D chest CT scans from databases generated in different countries\nand medical centers.\n","authors":["Dimitrios Kollias","Anastasios Arsenos","Stefanos Kollias"],"pdf_url":"https://arxiv.org/pdf/2303.00175v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00180v2","updated":"2023-03-02T01:32:53Z","published":"2023-03-01T02:14:20Z","title":"FaceRNET: a Facial Expression Intensity Estimation Network","summary":"  This paper presents our approach for Facial Expression Intensity Estimation\nfrom videos. It includes two components: i) a representation extractor network\nthat extracts various emotion descriptors (valence-arousal, action units and\nbasic expressions) from each videoframe; ii) a RNN that captures temporal\ninformation in the data, followed by a mask layer which enables handling\nvarying input video lengths through dynamic routing. This approach has been\ntested on the Hume-Reaction dataset yielding excellent results.\n","authors":["Dimitrios Kollias","Andreas Psaroudakis","Anastasios Arsenos","Paraskeui Theofilou"],"pdf_url":"https://arxiv.org/pdf/2303.00180v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00369v2","updated":"2023-03-02T01:23:23Z","published":"2023-03-01T09:50:39Z","title":"Indescribable Multi-modal Spatial Evaluator","summary":"  Multi-modal image registration spatially aligns two images with different\ndistributions. One of its major challenges is that images acquired from\ndifferent imaging machines have different imaging distributions, making it\ndifficult to focus only on the spatial aspect of the images and ignore\ndifferences in distributions. In this study, we developed a self-supervised\napproach, Indescribable Multi-model Spatial Evaluator (IMSE), to address\nmulti-modal image registration. IMSE creates an accurate multi-modal spatial\nevaluator to measure spatial differences between two images, and then optimizes\nregistration by minimizing the error predicted of the evaluator. To optimize\nIMSE performance, we also proposed a new style enhancement method called\nShuffle Remap which randomizes the image distribution into multiple segments,\nand then randomly disorders and remaps these segments, so that the distribution\nof the original image is changed. Shuffle Remap can help IMSE to predict the\ndifference in spatial location from unseen target distributions. Our results\nshow that IMSE outperformed the existing methods for registration using T1-T2\nand CT-MRI datasets. IMSE also can be easily integrated into the traditional\nregistration process, and can provide a convenient way to evaluate and\nvisualize registration results. IMSE also has the potential to be used as a new\nparadigm for image-to-image translation. Our code is available at\nhttps://github.com/Kid-Liet/IMSE.\n","authors":["Lingke Kong","X. Sharon Qi","Qijin Shen","Jiacheng Wang","Jingyi Zhang","Yanle Hu","Qichao Zhou"],"pdf_url":"https://arxiv.org/pdf/2303.00369v2.pdf","comment":"Accepted by CVPR2023"},{"id":"http://arxiv.org/abs/2303.00891v1","updated":"2023-03-02T01:14:32Z","published":"2023-03-02T01:14:32Z","title":"MoSS: Monocular Shape Sensing for Continuum Robots","summary":"  Continuum robots are promising candidates for interactive tasks in various\napplications due to their unique shape, compliance, and miniaturization\ncapability. Accurate and real-time shape sensing is essential for such tasks\nyet remains a challenge. Embedded shape sensing has high hardware complexity\nand cost, while vision-based methods require stereo setup and struggle to\nachieve real-time performance. This paper proposes the first eye-to-hand\nmonocular approach to continuum robot shape sensing. Utilizing a deep\nencoder-decoder network, our method, MoSSNet, eliminates the computation cost\nof stereo matching and reduces requirements on sensing hardware. In particular,\nMoSSNet comprises an encoder and three parallel decoders to uncover spatial,\nlength, and contour information from a single RGB image, and then obtains the\n3D shape through curve fitting. A two-segment tendon-driven continuum robot is\nused for data collection and testing, demonstrating accurate (mean shape error\nof 0.91 mm, or 0.36% of robot length) and real-time (70 fps) shape sensing on\nreal-world data. Additionally, the method is optimized end-to-end and does not\nrequire fiducial markers, manual segmentation, or camera calibration. Code and\ndatasets will be made available at\nhttps://github.com/ContinuumRoboticsLab/MoSSNet.\n","authors":["Chengnan Shentu","Enxu Li","Chaojun Chen","Puspita Triana Dewi","David B. Lindell","Jessica Burgner-Kahrs"],"pdf_url":"https://arxiv.org/pdf/2303.00891v1.pdf","comment":"8 pages, 6 figures, submitted to IROS 2023"},{"id":"http://arxiv.org/abs/2206.06487v3","updated":"2023-03-02T01:12:05Z","published":"2022-06-13T21:34:21Z","title":"The Modality Focusing Hypothesis: Towards Understanding Crossmodal\n  Knowledge Distillation","summary":"  Crossmodal knowledge distillation (KD) extends traditional knowledge\ndistillation to the area of multimodal learning and demonstrates great success\nin various applications. To achieve knowledge transfer across modalities, a\npretrained network from one modality is adopted as the teacher to provide\nsupervision signals to a student network learning from another modality. In\ncontrast to the empirical success reported in prior works, the working\nmechanism of crossmodal KD remains a mystery. In this paper, we present a\nthorough understanding of crossmodal KD. We begin with two case studies and\ndemonstrate that KD is not a universal cure in crossmodal knowledge transfer.\nWe then present the modality Venn diagram to understand modality relationships\nand the modality focusing hypothesis revealing the decisive factor in the\nefficacy of crossmodal KD. Experimental results on 6 multimodal datasets help\njustify our hypothesis, diagnose failure cases, and point directions to improve\ncrossmodal knowledge transfer in the future.\n","authors":["Zihui Xue","Zhengqi Gao","Sucheng Ren","Hang Zhao"],"pdf_url":"https://arxiv.org/pdf/2206.06487v3.pdf","comment":"Accepted by ICLR 2023 (top-5%). The first three authors contribute\n  equally. Project website: https://zihuixue.github.io/MFH/index.html"},{"id":"http://arxiv.org/abs/2303.00886v1","updated":"2023-03-02T01:06:35Z","published":"2023-03-02T01:06:35Z","title":"Photovoltaic Panel Defect Detection Based on Ghost Convolution with\n  BottleneckCSP and Tiny Target Prediction Head Incorporating YOLOv5","summary":"  Photovoltaic (PV) panel surface-defect detection technology is crucial for\nthe PV industry to perform smart maintenance. Using computer vision technology\nto detect PV panel surface defects can ensure better accuracy while reducing\nthe workload of traditional worker field inspections. However, multiple tiny\ndefects on the PV panel surface and the high similarity between different\ndefects make it challenging to {accurately identify and detect such defects}.\nThis paper proposes an approach named Ghost convolution with BottleneckCSP and\na tiny target prediction head incorporating YOLOv5 (GBH-YOLOv5) for PV panel\ndefect detection. To ensure better accuracy on multiscale targets, the\nBottleneckCSP module is introduced to add a prediction head for tiny target\ndetection to alleviate tiny defect misses, using Ghost convolution to improve\nthe model inference speed and reduce the number of parameters. First, the\noriginal image is compressed and cropped to enlarge the defect size physically.\nThen, the processed images are input into GBH-YOLOv5, and the depth features\nare extracted through network processing based on Ghost convolution, the\napplication of the BottleneckCSP module, and the prediction head of tiny\ntargets. Finally, the extracted features are classified by a Feature Pyramid\nNetwork (FPN) and a Path Aggregation Network (PAN) structure. Meanwhile, we\ncompare our method with state-of-the-art methods to verify the effectiveness of\nthe proposed method. The proposed PV panel surface-defect detection network\nimproves the mAP performance by at least 27.8%.\n","authors":["Longlong Li","Zhifeng Wang","Tingting Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.00886v1.pdf","comment":"16 pages, 8 figures"},{"id":"http://arxiv.org/abs/2303.00885v1","updated":"2023-03-02T01:02:18Z","published":"2023-03-02T01:02:18Z","title":"Towards Trustable Skin Cancer Diagnosis via Rewriting Model's Decision","summary":"  Deep neural networks have demonstrated promising performance on image\nrecognition tasks. However, they may heavily rely on confounding factors, using\nirrelevant artifacts or bias within the dataset as the cue to improve\nperformance. When a model performs decision-making based on these spurious\ncorrelations, it can become untrustable and lead to catastrophic outcomes when\ndeployed in the real-world scene. In this paper, we explore and try to solve\nthis problem in the context of skin cancer diagnosis. We introduce a\nhuman-in-the-loop framework in the model training process such that users can\nobserve and correct the model's decision logic when confounding behaviors\nhappen. Specifically, our method can automatically discover confounding factors\nby analyzing the co-occurrence behavior of the samples. It is capable of\nlearning confounding concepts using easily obtained concept exemplars. By\nmapping the black-box model's feature representation onto an explainable\nconcept space, human users can interpret the concept and intervene via first\norder-logic instruction. We systematically evaluate our method on our newly\ncrafted, well-controlled skin lesion dataset and several public skin lesion\ndatasets. Experiments show that our method can effectively detect and remove\nconfounding factors from datasets without any prior knowledge about the\ncategory distribution and does not require fully annotated concept labels. We\nalso show that our method enables the model to focus on clinical-related\nconcepts, improving the model's performance and trustworthiness during model\ninference.\n","authors":["Siyuan Yan","Zhen Yu","Xuelin Zhang","Dwarikanath Mahapatra","Shekhar S. Chandra","Monika Janda","Peter Soyer","Zongyuan Ge"],"pdf_url":"https://arxiv.org/pdf/2303.00885v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2303.00882v1","updated":"2023-03-02T00:52:41Z","published":"2023-03-02T00:52:41Z","title":"X-Ray2EM: Uncertainty-Aware Cross-Modality Image Reconstruction from\n  X-Ray to Electron Microscopy in Connectomics","summary":"  Comprehensive, synapse-resolution imaging of the brain will be crucial for\nunderstanding neuronal computations and function. In connectomics, this has\nbeen the sole purview of volume electron microscopy (EM), which entails an\nexcruciatingly difficult process because it requires cutting tissue into many\nthin, fragile slices that then need to be imaged, aligned, and reconstructed.\nUnlike EM, hard X-ray imaging is compatible with thick tissues, eliminating the\nneed for thin sectioning, and delivering fast acquisition, intrinsic alignment,\nand isotropic resolution. Unfortunately, current state-of-the-art X-ray\nmicroscopy provides much lower resolution, to the extent that segmenting\nmembranes is very challenging. We propose an uncertainty-aware 3D\nreconstruction model that translates X-ray images to EM-like images with\nenhanced membrane segmentation quality, showing its potential for developing\nsimpler, faster, and more accurate X-ray based connectomics pipelines.\n","authors":["Yicong Li","Yaron Meirovitch","Aaron T. Kuan","Jasper S. Phelps","Alexandra Pacureanu","Wei-Chung Allen Lee","Nir Shavit","Lu Mi"],"pdf_url":"https://arxiv.org/pdf/2303.00882v1.pdf","comment":"Accepted by ISBI 2023 conference. Supplementary material is available\n  in this arXiv version"},{"id":"http://arxiv.org/abs/2203.08382v3","updated":"2023-03-02T00:32:44Z","published":"2022-03-16T04:10:45Z","title":"Dual Diffusion Implicit Bridges for Image-to-Image Translation","summary":"  Common image-to-image translation methods rely on joint training over data\nfrom both source and target domains. The training process requires concurrent\naccess to both datasets, which hinders data separation and privacy protection;\nand existing models cannot be easily adapted for translation of new domain\npairs. We present Dual Diffusion Implicit Bridges (DDIBs), an image translation\nmethod based on diffusion models, that circumvents training on domain pairs.\nImage translation with DDIBs relies on two diffusion models trained\nindependently on each domain, and is a two-step process: DDIBs first obtain\nlatent encodings for source images with the source diffusion model, and then\ndecode such encodings using the target model to construct target images. Both\nsteps are defined via ordinary differential equations (ODEs), thus the process\nis cycle consistent only up to discretization errors of the ODE solvers.\nTheoretically, we interpret DDIBs as concatenation of source to latent, and\nlatent to target Schrodinger Bridges, a form of entropy-regularized optimal\ntransport, to explain the efficacy of the method. Experimentally, we apply\nDDIBs on synthetic and high-resolution image datasets, to demonstrate their\nutility in a wide variety of translation tasks and their inherent optimal\ntransport properties.\n","authors":["Xuan Su","Jiaming Song","Chenlin Meng","Stefano Ermon"],"pdf_url":"https://arxiv.org/pdf/2203.08382v3.pdf","comment":"18 pages, 12 figures, in the Eleventh International Conference on\n  Learning Representations (ICLR 2023)"},{"id":"http://arxiv.org/abs/2205.13192v2","updated":"2023-03-02T00:27:11Z","published":"2022-05-26T07:08:32Z","title":"Tree Reconstruction using Topology Optimisation","summary":"  Generating accurate digital tree models from scanned environments is\ninvaluable for forestry, agriculture, and other outdoor industries in tasks\nsuch as identifying biomass, fall hazards and traversability, as well as\ndigital applications such as animation and gaming. Existing methods for tree\nreconstruction rely on feature identification (trunk, crown, etc) to\nheuristically segment a forest into individual trees and generate a branch\nstructure graph, limiting their application to sparse trees and uniform\nforests. However, the natural world is a messy place in which trees present\nwith significant heterogeneity and are frequently encroached upon by the\nsurrounding environment. We present a general method for extracting the branch\nstructure of trees from point cloud data, which estimates the structure of\ntrees by adapting the methods of structural topology optimisation to find the\noptimal material distribution to support wind-loading. We present the results\nof this optimisation over a wide variety of scans, and discuss the benefits and\ndrawbacks of this novel approach to tree structure reconstruction. Despite the\nhigh variability of datasets containing trees, and the high rate of occlusions,\nour method generates detailed and accurate tree structures in most cases.\n","authors":["Thomas Lowe","Joshua Pinskier"],"pdf_url":"https://arxiv.org/pdf/2205.13192v2.pdf","comment":"The datasets generated and used in the current study are available in\n  the Tree Reconstructions from Pointclouds Scanned in Pullenvale QLD\n  repository, https://doi.org/10.25919/yt2m-9373"},{"id":"http://arxiv.org/abs/2303.00874v1","updated":"2023-03-02T00:21:15Z","published":"2023-03-02T00:21:15Z","title":"Geometric Visual Similarity Learning in 3D Medical Image Self-supervised\n  Pre-training","summary":"  Learning inter-image similarity is crucial for 3D medical images\nself-supervised pre-training, due to their sharing of numerous same semantic\nregions. However, the lack of the semantic prior in metrics and the\nsemantic-independent variation in 3D medical images make it challenging to get\na reliable measurement for the inter-image similarity, hindering the learning\nof consistent representation for same semantics. We investigate the challenging\nproblem of this task, i.e., learning a consistent representation between images\nfor a clustering effect of same semantic features. We propose a novel visual\nsimilarity learning paradigm, Geometric Visual Similarity Learning, which\nembeds the prior of topological invariance into the measurement of the\ninter-image similarity for consistent representation of semantic regions. To\ndrive this paradigm, we further construct a novel geometric matching head, the\nZ-matching head, to collaboratively learn the global and local similarity of\nsemantic regions, guiding the efficient representation learning for different\nscale-level inter-image semantic features. Our experiments demonstrate that the\npre-training with our learning of inter-image similarity yields more powerful\ninner-scene, inter-scene, and global-local transferring ability on four\nchallenging 3D medical image tasks. Our codes and pre-trained models will be\npublicly available on https://github.com/YutingHe-list/GVSL.\n","authors":["Yuting He","Guanyu Yang","Rongjun Ge","Yang Chen","Jean-Louis Coatrieux","Boyu Wang","Shuo Li"],"pdf_url":"https://arxiv.org/pdf/2303.00874v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2303.00871v1","updated":"2023-03-02T00:01:13Z","published":"2023-03-02T00:01:13Z","title":"Bayesian Deep Learning for Affordance Segmentation in images","summary":"  Affordances are a fundamental concept in robotics since they relate available\nactions for an agent depending on its sensory-motor capabilities and the\nenvironment. We present a novel Bayesian deep network to detect affordances in\nimages, at the same time that we quantify the distribution of the aleatoric and\nepistemic variance at the spatial level. We adapt the Mask-RCNN architecture to\nlearn a probabilistic representation using Monte Carlo dropout. Our results\noutperform the state-of-the-art of deterministic networks. We attribute this\nimprovement to a better probabilistic feature space representation on the\nencoder and the Bayesian variability induced at the mask generation, which\nadapts better to the object contours. We also introduce the new\nProbability-based Mask Quality measure that reveals the semantic and spatial\ndifferences on a probabilistic instance segmentation model. We modify the\nexisting Probabilistic Detection Quality metric by comparing the binary masks\nrather than the predicted bounding boxes, achieving a finer-grained evaluation\nof the probabilistic segmentation. We find aleatoric variance in the contours\nof the objects due to the camera noise, while epistemic variance appears in\nvisual challenging pixels.\n","authors":["Lorenzo Mur-Labadia","Ruben Martinez-Cantin","Jose J. Guerrero"],"pdf_url":"https://arxiv.org/pdf/2303.00871v1.pdf","comment":"2023 IEEE International Conference on Robotics and Automation (ICRA)"},{"id":"http://arxiv.org/abs/2209.04934v2","updated":"2023-03-02T23:50:34Z","published":"2022-09-08T17:35:30Z","title":"Clifford Neural Layers for PDE Modeling","summary":"  Partial differential equations (PDEs) see widespread use in sciences and\nengineering to describe simulation of physical processes as scalar and vector\nfields interacting and coevolving over time. Due to the computationally\nexpensive nature of their standard solution methods, neural PDE surrogates have\nbecome an active research topic to accelerate these simulations. However,\ncurrent methods do not explicitly take into account the relationship between\ndifferent fields and their internal components, which are often correlated.\nViewing the time evolution of such correlated fields through the lens of\nmultivector fields allows us to overcome these limitations. Multivector fields\nconsist of scalar, vector, as well as higher-order components, such as\nbivectors and trivectors. Their algebraic properties, such as multiplication,\naddition and other arithmetic operations can be described by Clifford algebras.\nTo our knowledge, this paper presents the first usage of such multivector\nrepresentations together with Clifford convolutions and Clifford Fourier\ntransforms in the context of deep learning. The resulting Clifford neural\nlayers are universally applicable and will find direct use in the areas of\nfluid dynamics, weather forecasting, and the modeling of physical systems in\ngeneral. We empirically evaluate the benefit of Clifford neural layers by\nreplacing convolution and Fourier operations in common neural PDE surrogates by\ntheir Clifford counterparts on 2D Navier-Stokes and weather modeling tasks, as\nwell as 3D Maxwell equations. For similar parameter count, Clifford neural\nlayers consistently improve generalization capabilities of the tested neural\nPDE surrogates. Source code for our PyTorch implementation is available at\nhttps://microsoft.github.io/cliffordlayers/.\n","authors":["Johannes Brandstetter","Rianne van den Berg","Max Welling","Jayesh K. Gupta"],"pdf_url":"https://arxiv.org/pdf/2209.04934v2.pdf","comment":"Accepted at ICLR-2023"},{"id":"http://arxiv.org/abs/2303.01615v1","updated":"2023-03-02T22:36:19Z","published":"2023-03-02T22:36:19Z","title":"ConTEXTual Net: A Multimodal Vision-Language Model for Segmentation of\n  Pneumothorax","summary":"  Clinical imaging databases contain not only medical images but also text\nreports generated by physicians. These narrative reports often describe the\nlocation, size, and shape of the disease, but using descriptive text to guide\nmedical image analysis has been understudied. Vision-language models are\nincreasingly used for multimodal tasks like image generation, image captioning,\nand visual question answering but have been scarcely used in medical imaging.\nIn this work, we develop a vision-language model for the task of pneumothorax\nsegmentation. Our model, ConTEXTual Net, detects and segments pneumothorax in\nchest radiographs guided by free-form radiology reports. ConTEXTual Net\nachieved a Dice score of 0.72 $\\pm$ 0.02, which was similar to the level of\nagreement between the primary physician annotator and the other physician\nannotators (0.71 $\\pm$ 0.04). ConTEXTual Net also outperformed a U-Net. We\ndemonstrate that descriptive language can be incorporated into a segmentation\nmodel for improved performance. Through an ablative study, we show that it is\nthe text information that is responsible for the performance gains.\nAdditionally, we show that certain augmentation methods worsen ConTEXTual Net's\nsegmentation performance by breaking the image-text concordance. We propose a\nset of augmentations that maintain this concordance and improve segmentation\ntraining.\n","authors":["Zachary Huemann","Junjie Hu","Tyler Bradshaw"],"pdf_url":"https://arxiv.org/pdf/2303.01615v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01605v1","updated":"2023-03-02T22:04:42Z","published":"2023-03-02T22:04:42Z","title":"Hierarchical discriminative learning improves visual representations of\n  biomedical microscopy","summary":"  Learning high-quality, self-supervised, visual representations is essential\nto advance the role of computer vision in biomedical microscopy and clinical\nmedicine. Previous work has focused on self-supervised representation learning\n(SSL) methods developed for instance discrimination and applied them directly\nto image patches, or fields-of-view, sampled from gigapixel whole-slide images\n(WSIs) used for cancer diagnosis. However, this strategy is limited because it\n(1) assumes patches from the same patient are independent, (2) neglects the\npatient-slide-patch hierarchy of clinical biomedical microscopy, and (3)\nrequires strong data augmentations that can degrade downstream performance.\nImportantly, sampled patches from WSIs of a patient's tumor are a diverse set\nof image examples that capture the same underlying cancer diagnosis. This\nmotivated HiDisc, a data-driven method that leverages the inherent\npatient-slide-patch hierarchy of clinical biomedical microscopy to define a\nhierarchical discriminative learning task that implicitly learns features of\nthe underlying diagnosis. HiDisc uses a self-supervised contrastive learning\nframework in which positive patch pairs are defined based on a common ancestry\nin the data hierarchy, and a unified patch, slide, and patient discriminative\nlearning objective is used for visual SSL. We benchmark HiDisc visual\nrepresentations on two vision tasks using two biomedical microscopy datasets,\nand demonstrate that (1) HiDisc pretraining outperforms current\nstate-of-the-art self-supervised pretraining methods for cancer diagnosis and\ngenetic mutation prediction, and (2) HiDisc learns high-quality visual\nrepresentations using natural patch diversity without strong data\naugmentations.\n","authors":["Cheng Jiang","Xinhai Hou","Akhil Kondepudi","Asadur Chowdury","Christian W. Freudiger","Daniel A. Orringer","Honglak Lee","Todd C. Hollon"],"pdf_url":"https://arxiv.org/pdf/2303.01605v1.pdf","comment":"CVPR 2023. Project page: https://hidisc.mlins.org"},{"id":"http://arxiv.org/abs/2303.01598v1","updated":"2023-03-02T21:48:22Z","published":"2023-03-02T21:48:22Z","title":"A Meta-Learning Approach to Predicting Performance and Data Requirements","summary":"  We propose an approach to estimate the number of samples required for a model\nto reach a target performance. We find that the power law, the de facto\nprinciple to estimate model performance, leads to large error when using a\nsmall dataset (e.g., 5 samples per class) for extrapolation. This is because\nthe log-performance error against the log-dataset size follows a nonlinear\nprogression in the few-shot regime followed by a linear progression in the\nhigh-shot regime. We introduce a novel piecewise power law (PPL) that handles\nthe two data regimes differently. To estimate the parameters of the PPL, we\nintroduce a random forest regressor trained via meta learning that generalizes\nacross classification/detection tasks, ResNet/ViT based architectures, and\nrandom/pre-trained initializations. The PPL improves the performance estimation\non average by 37% across 16 classification and 33% across 10 detection\ndatasets, compared to the power law. We further extend the PPL to provide a\nconfidence bound and use it to limit the prediction horizon that reduces\nover-estimation of data by 76% on classification and 91% on detection datasets.\n","authors":["Achin Jain","Gurumurthy Swaminathan","Paolo Favaro","Hao Yang","Avinash Ravichandran","Hrayr Harutyunyan","Alessandro Achille","Onkar Dabeer","Bernt Schiele","Ashwin Swaminathan","Stefano Soatto"],"pdf_url":"https://arxiv.org/pdf/2303.01598v1.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2303.01592v1","updated":"2023-03-02T21:31:35Z","published":"2023-03-02T21:31:35Z","title":"Joint cortical registration of geometry and function using\n  semi-supervised learning","summary":"  Brain surface-based image registration, an important component of brain image\nanalysis, establishes spatial correspondence between cortical surfaces.\nExisting iterative and learning-based approaches focus on accurate registration\nof folding patterns of the cerebral cortex, and assume that geometry predicts\nfunction and thus functional areas will also be well aligned. However,\nstructure/functional variability of anatomically corresponding areas across\nsubjects has been widely reported. In this work, we introduce a learning-based\ncortical registration framework, JOSA, which jointly aligns folding patterns\nand functional maps while simultaneously learning an optimal atlas. We\ndemonstrate that JOSA can substantially improve registration performance in\nboth anatomical and functional domains over existing methods. By employing a\nsemi-supervised training strategy, the proposed framework obviates the need for\nfunctional data during inference, enabling its use in broad neuroscientific\ndomains where functional data may not be observed.\n","authors":["Jian Li","Greta Tuckute","Evelina Fedorenko","Brian L. Edlow","Bruce Fischl","Adrian V. Dalca"],"pdf_url":"https://arxiv.org/pdf/2303.01592v1.pdf","comment":"15 pages, 5 figures, cortical registration, semi-supervised Learning"},{"id":"http://arxiv.org/abs/2303.01589v1","updated":"2023-03-02T21:24:19Z","published":"2023-03-02T21:24:19Z","title":"AZTR: Aerial Video Action Recognition with Auto Zoom and Temporal\n  Reasoning","summary":"  We propose a novel approach for aerial video action recognition. Our method\nis designed for videos captured using UAVs and can run on edge or mobile\ndevices. We present a learning-based approach that uses customized auto zoom to\nautomatically identify the human target and scale it appropriately. This makes\nit easier to extract the key features and reduces the computational overhead.\nWe also present an efficient temporal reasoning algorithm to capture the action\ninformation along the spatial and temporal domains within a controllable\ncomputational cost. Our approach has been implemented and evaluated both on the\ndesktop with high-end GPUs and on the low power Robotics RB5 Platform for\nrobots and drones. In practice, we achieve 6.1-7.4% improvement over SOTA in\nTop-1 accuracy on the RoCoG-v2 dataset, 8.3-10.4% improvement on the UAV-Human\ndataset and 3.2% improvement on the Drone Action dataset.\n","authors":["Xijun Wang","Ruiqi Xian","Tianrui Guan","Celso M. de Melo","Stephen M. Nogar","Aniket Bera","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2303.01589v1.pdf","comment":"Accepted for publication at ICRA 2023"},{"id":"http://arxiv.org/abs/2303.01584v1","updated":"2023-03-02T21:16:53Z","published":"2023-03-02T21:16:53Z","title":"Evolutionary Augmentation Policy Optimization for Self-supervised\n  Learning","summary":"  Self-supervised learning (SSL) is a Machine Learning algorithm for\npretraining Deep Neural Networks (DNNs) without requiring manually labeled\ndata. The central idea of this learning technique is based on an auxiliary\nstage aka pretext task in which labeled data are created automatically through\ndata augmentation and exploited for pretraining the DNN. However, the effect of\neach pretext task is not well studied or compared in the literature. In this\npaper, we study the contribution of augmentation operators on the performance\nof self supervised learning algorithms in a constrained settings. We propose an\nevolutionary search method for optimization of data augmentation pipeline in\npretext tasks and measure the impact of augmentation operators in several SOTA\nSSL algorithms. By encoding different combination of augmentation operators in\nchromosomes we seek the optimal augmentation policies through an evolutionary\noptimization mechanism. We further introduce methods for analyzing and\nexplaining the performance of optimized SSL algorithms. Our results indicate\nthat our proposed method can find solutions that outperform the accuracy of\nclassification of SSL algorithms which confirms the influence of augmentation\npolicy choice on the overall performance of SSL algorithms. We also compare\noptimal SSL solutions found by our evolutionary search mechanism and show the\neffect of batch size in the pretext task on two visual datasets.\n","authors":["Noah Barrett","Zahra Sadeghi","Stan Matwin"],"pdf_url":"https://arxiv.org/pdf/2303.01584v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01582v1","updated":"2023-03-02T21:16:17Z","published":"2023-03-02T21:16:17Z","title":"A Few-Shot Attention Recurrent Residual U-Net for Crack Segmentation","summary":"  Recent studies indicate that deep learning plays a crucial role in the\nautomated visual inspection of road infrastructures. However, current learning\nschemes are static, implying no dynamic adaptation to users' feedback. To\naddress this drawback, we present a few-shot learning paradigm for the\nautomated segmentation of road cracks, which is based on a U-Net architecture\nwith recurrent residual and attention modules (R2AU-Net). The retraining\nstrategy dynamically fine-tunes the weights of the U-Net as a few new rectified\nsamples are being fed into the classifier. Extensive experiments show that the\nproposed few-shot R2AU-Net framework outperforms other state-of-the-art\nnetworks in terms of Dice and IoU metrics, on a new dataset, named CrackMap,\nwhich is made publicly available at https://github.com/ikatsamenis/CrackMap.\n","authors":["Iason Katsamenis","Eftychios Protopapadakis","Nikolaos Bakalos","Anastasios Doulamis","Nikolaos Doulamis","Athanasios Voulodimos"],"pdf_url":"https://arxiv.org/pdf/2303.01582v1.pdf","comment":"5 pages, 4 figures, 2 tables"},{"id":"http://arxiv.org/abs/2302.09200v2","updated":"2023-03-02T21:07:43Z","published":"2023-02-18T00:42:58Z","title":"Brainomaly: Unsupervised Neurologic Disease Detection Utilizing\n  Unannotated T1-weighted Brain MR Images","summary":"  Deep neural networks have revolutionized the field of supervised learning by\nenabling accurate predictions through learning from large annotated datasets.\nHowever, acquiring large annotated medical imaging datasets is a challenging\ntask, especially for rare diseases, due to the high cost, time, and effort\nrequired for annotation. In these scenarios, unsupervised disease detection\nmethods, such as anomaly detection, can save significant human effort. A\ntypically used approach for anomaly detection is to learn the images from\nhealthy subjects only, assuming the model will detect the images from diseased\nsubjects as outliers. However, in many real-world scenarios, unannotated\ndatasets with a mix of healthy and diseased individuals are available. Recent\nstudies have shown improvement in unsupervised disease/anomaly detection using\nsuch datasets of unannotated images from healthy and diseased individuals\ncompared to datasets that only include images from healthy individuals. A major\nissue remains unaddressed in these studies, which is selecting the best model\nfor inference from a set of trained models without annotated samples. To\naddress this issue, we propose Brainomaly, a GAN-based image-to-image\ntranslation method for neurologic disease detection using unannotated\nT1-weighted brain MRIs of individuals with neurologic diseases and healthy\nsubjects. Brainomaly is trained to remove the diseased regions from the input\nbrain MRIs and generate MRIs of corresponding healthy brains. Instead of\ngenerating the healthy images directly, Brainomaly generates an additive map\nwhere each voxel indicates the amount of changes required to make the input\nimage look healthy. In addition, Brainomaly uses a pseudo-AUC metric for\ninference model selection, which further improves the detection performance.\nOur Brainomaly outperforms existing state-of-the-art methods by large margins.\n","authors":["Md Mahfuzur Rahman Siddiquee","Jay Shah","Teresa Wu","Catherine Chong","Todd J. Schwedt","Gina Dumkrieger","Simona Nikolova","Baoxin Li"],"pdf_url":"https://arxiv.org/pdf/2302.09200v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01573v1","updated":"2023-03-02T20:56:36Z","published":"2023-03-02T20:56:36Z","title":"DejaVu: Conditional Regenerative Learning to Enhance Dense Prediction","summary":"  We present DejaVu, a novel framework which leverages conditional image\nregeneration as additional supervision during training to improve deep networks\nfor dense prediction tasks such as segmentation, depth estimation, and surface\nnormal prediction. First, we apply redaction to the input image, which removes\ncertain structural information by sparse sampling or selective frequency\nremoval. Next, we use a conditional regenerator, which takes the redacted image\nand the dense predictions as inputs, and reconstructs the original image by\nfilling in the missing structural information. In the redacted image,\nstructural attributes like boundaries are broken while semantic context is\nlargely preserved. In order to make the regeneration feasible, the conditional\ngenerator will then require the structure information from the other input\nsource, i.e., the dense predictions. As such, by including this conditional\nregeneration objective during training, DejaVu encourages the base network to\nlearn to embed accurate scene structure in its dense prediction. This leads to\nmore accurate predictions with clearer boundaries and better spatial\nconsistency. When it is feasible to leverage additional computation, DejaVu can\nbe extended to incorporate an attention-based regeneration module within the\ndense prediction network, which further improves accuracy. Through extensive\nexperiments on multiple dense prediction benchmarks such as Cityscapes, COCO,\nADE20K, NYUD-v2, and KITTI, we demonstrate the efficacy of employing DejaVu\nduring training, as it outperforms SOTA methods at no added computation cost.\n","authors":["Shubhankar Borse","Debasmit Das","Hyojin Park","Hong Cai","Risheek Garrepalli","Fatih Porikli"],"pdf_url":"https://arxiv.org/pdf/2303.01573v1.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2303.00462v2","updated":"2023-03-02T20:54:29Z","published":"2023-03-01T12:41:12Z","title":"Hidden Gems: 4D Radar Scene Flow Learning Using Cross-Modal Supervision","summary":"  This work proposes a novel approach to 4D radar-based scene flow estimation\nvia cross-modal learning. Our approach is motivated by the co-located sensing\nredundancy in modern autonomous vehicles. Such redundancy implicitly provides\nvarious forms of supervision cues to the radar scene flow estimation.\nSpecifically, we introduce a multi-task model architecture for the identified\ncross-modal learning problem and propose loss functions to opportunistically\nengage scene flow estimation using multiple cross-modal constraints for\neffective model training. Extensive experiments show the state-of-the-art\nperformance of our method and demonstrate the effectiveness of cross-modal\nsupervised learning to infer more accurate 4D radar scene flow. We also show\nits usefulness to two subtasks - motion segmentation and ego-motion estimation.\nOur source code will be available on https://github.com/Toytiny/CMFlow.\n","authors":["Fangqiang Ding","Andras Palffy","Dariu M. Gavrila","Chris Xiaoxuan Lu"],"pdf_url":"https://arxiv.org/pdf/2303.00462v2.pdf","comment":"10 pages, 7 figures. Accepted by CVPR 2023. Supplementary materials\n  can be found at\n  https://drive.google.com/file/d/1Iewcqnjzecge2ePBM8k2tg-85LX5xs3N/view"},{"id":"http://arxiv.org/abs/2303.01567v1","updated":"2023-03-02T20:44:45Z","published":"2023-03-02T20:44:45Z","title":"Deep Neural Networks with Efficient Guaranteed Invariances","summary":"  We address the problem of improving the performance and in particular the\nsample complexity of deep neural networks by enforcing and guaranteeing\ninvariances to symmetry transformations rather than learning them from data.\nGroup-equivariant convolutions are a popular approach to obtain equivariant\nrepresentations. The desired corresponding invariance is then imposed using\npooling operations. For rotations, it has been shown that using invariant\nintegration instead of pooling further improves the sample complexity. In this\ncontribution, we first expand invariant integration beyond rotations to flips\nand scale transformations. We then address the problem of incorporating\nmultiple desired invariances into a single network. For this purpose, we\npropose a multi-stream architecture, where each stream is invariant to a\ndifferent transformation such that the network can simultaneously benefit from\nmultiple invariances. We demonstrate our approach with successful experiments\non Scaled-MNIST, SVHN, CIFAR-10 and STL-10.\n","authors":["Matthias Rath","Alexandru Paul Condurache"],"pdf_url":"https://arxiv.org/pdf/2303.01567v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01559v1","updated":"2023-03-02T20:22:24Z","published":"2023-03-02T20:22:24Z","title":"Improving GAN Training via Feature Space Shrinkage","summary":"  Due to the outstanding capability for data generation, Generative Adversarial\nNetworks (GANs) have attracted considerable attention in unsupervised learning.\nHowever, training GANs is difficult, since the training distribution is dynamic\nfor the discriminator, leading to unstable image representation. In this paper,\nwe address the problem of training GANs from a novel perspective, \\emph{i.e.,}\nrobust image classification. Motivated by studies on robust image\nrepresentation, we propose a simple yet effective module, namely AdaptiveMix,\nfor GANs, which shrinks the regions of training data in the image\nrepresentation space of the discriminator. Considering it is intractable to\ndirectly bound feature space, we propose to construct hard samples and narrow\ndown the feature distance between hard and easy samples. The hard samples are\nconstructed by mixing a pair of training images. We evaluate the effectiveness\nof our AdaptiveMix with widely-used and state-of-the-art GAN architectures. The\nevaluation results demonstrate that our AdaptiveMix can facilitate the training\nof GANs and effectively improve the image quality of generated samples. We also\nshow that our AdaptiveMix can be further applied to image classification and\nOut-Of-Distribution (OOD) detection tasks, by equipping it with\nstate-of-the-art methods. Extensive experiments on seven publicly available\ndatasets show that our method effectively boosts the performance of baselines.\nThe code is publicly available at\nhttps://github.com/WentianZhang-ML/AdaptiveMix.\n","authors":["Haozhe Liu","Wentian Zhang","Bing Li","Haoqian Wu","Nanjun He","Yawen Huang","Yuexiang Li","Bernard Ghanem","Yefeng Zheng"],"pdf_url":"https://arxiv.org/pdf/2303.01559v1.pdf","comment":"Accepted by CVPR'2023. Code, Demo, and Homepage will be released soon"},{"id":"http://arxiv.org/abs/2303.01555v1","updated":"2023-03-02T20:10:18Z","published":"2023-03-02T20:10:18Z","title":"Counterfactual Edits for Generative Evaluation","summary":"  Evaluation of generative models has been an underrepresented field despite\nthe surge of generative architectures. Most recent models are evaluated upon\nrather obsolete metrics which suffer from robustness issues, while being unable\nto assess more aspects of visual quality, such as compositionality and logic of\nsynthesis. At the same time, the explainability of generative models remains a\nlimited, though important, research direction with several current attempts\nrequiring access to the inner functionalities of generative models. Contrary to\nprior literature, we view generative models as a black box, and we propose a\nframework for the evaluation and explanation of synthesized results based on\nconcepts instead of pixels. Our framework exploits knowledge-based\ncounterfactual edits that underline which objects or attributes should be\ninserted, removed, or replaced from generated images to approach their ground\ntruth conditioning. Moreover, global explanations produced by accumulating\nlocal edits can also reveal what concepts a model cannot generate in total. The\napplication of our framework on various models designed for the challenging\ntasks of Story Visualization and Scene Synthesis verifies the power of our\napproach in the model-agnostic setting.\n","authors":["Maria Lymperaiou","Giorgos Filandrianos","Konstantinos Thomas","Giorgos Stamou"],"pdf_url":"https://arxiv.org/pdf/2303.01555v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01547v1","updated":"2023-03-02T19:25:40Z","published":"2023-03-02T19:25:40Z","title":"Simultaneous prediction of hand gestures, handedness, and hand keypoints\n  using thermal images","summary":"  Hand gesture detection is a well-explored area in computer vision with\napplications in various forms of Human-Computer Interactions. In this work, we\npropose a technique for simultaneous hand gesture classification, handedness\ndetection, and hand keypoints localization using thermal data captured by an\ninfrared camera. Our method uses a novel deep multi-task learning architecture\nthat includes shared encoderdecoder layers followed by three branches dedicated\nfor each mentioned task. We performed extensive experimental validation of our\nmodel on an in-house dataset consisting of 24 users data. The results confirm\nhigher than 98 percent accuracy for gesture classification, handedness\ndetection, and fingertips localization, and more than 91 percent accuracy for\nwrist points localization.\n","authors":["Sichao Li","Sean Banerjee","Natasha Kholgade Banerjee","Soumyabrata Dey"],"pdf_url":"https://arxiv.org/pdf/2303.01547v1.pdf","comment":"ICDEC 2022"},{"id":"http://arxiv.org/abs/2303.01546v1","updated":"2023-03-02T19:21:21Z","published":"2023-03-02T19:21:21Z","title":"MiShape: 3D Shape Modelling of Mitochondria in Microscopy","summary":"  Fluorescence microscopy is a quintessential tool for observing cells and\nunderstanding the underlying mechanisms of life-sustaining processes of all\nliving organisms. The problem of extracting 3D shape of mitochondria from\nfluorescence microscopy images remains unsolved due to the complex and varied\nshapes expressed by mitochondria and the poor resolving capacity of these\nmicroscopes. We propose an approach to bridge this gap by learning a shape\nprior for mitochondria termed as MiShape, by leveraging high-resolution\nelectron microscopy data. MiShape is a generative model learned using implicit\nrepresentations of mitochondrial shapes. It provides a shape distribution that\ncan be used to generate infinite realistic mitochondrial shapes. We demonstrate\nthe representation power of MiShape and its utility for 3D shape reconstruction\ngiven a single 2D fluorescence image or a small 3D stack of 2D slices. We also\nshowcase applications of our method by deriving simulated fluorescence\nmicroscope datasets that have realistic 3D ground truths for the problem of 2D\nsegmentation and microscope-to-microscope transformation.\n","authors":["Abhinanda R. Punnakkal","Suyog S Jadhav","Alexander Horsch","Krishna Agarwal","Dilip K. Prasad"],"pdf_url":"https://arxiv.org/pdf/2303.01546v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01542v1","updated":"2023-03-02T19:18:11Z","published":"2023-03-02T19:18:11Z","title":"Self-attention in Vision Transformers Performs Perceptual Grouping, Not\n  Attention","summary":"  Recently, a considerable number of studies in computer vision involves deep\nneural architectures called vision transformers. Visual processing in these\nmodels incorporates computational models that are claimed to implement\nattention mechanisms. Despite an increasing body of work that attempts to\nunderstand the role of attention mechanisms in vision transformers, their\neffect is largely unknown. Here, we asked if the attention mechanisms in vision\ntransformers exhibit similar effects as those known in human visual attention.\nTo answer this question, we revisited the attention formulation in these models\nand found that despite the name, computationally, these models perform a\nspecial class of relaxation labeling with similarity grouping effects.\nAdditionally, whereas modern experimental findings reveal that human visual\nattention involves both feed-forward and feedback mechanisms, the purely\nfeed-forward architecture of vision transformers suggests that attention in\nthese models will not have the same effects as those known in humans. To\nquantify these observations, we evaluated grouping performance in a family of\nvision transformers. Our results suggest that self-attention modules group\nfigures in the stimuli based on similarity in visual features such as color.\nAlso, in a singleton detection experiment as an instance of saliency detection,\nwe studied if these models exhibit similar effects as those of feed-forward\nvisual salience mechanisms utilized in human visual attention. We found that\ngenerally, the transformer-based attention modules assign more salience either\nto distractors or the ground. Together, our study suggests that the attention\nmechanisms in vision transformers perform similarity grouping and not\nattention.\n","authors":["Paria Mehrani","John K. Tsotsos"],"pdf_url":"https://arxiv.org/pdf/2303.01542v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01538v1","updated":"2023-03-02T19:05:46Z","published":"2023-03-02T19:05:46Z","title":"Feature Perturbation Augmentation for Reliable Evaluation of Importance\n  Estimators","summary":"  Post-hoc explanation methods attempt to make the inner workings of deep\nneural networks more interpretable. However, since a ground truth is in general\nlacking, local post-hoc interpretability methods, which assign importance\nscores to input features, are challenging to evaluate. One of the most popular\nevaluation frameworks is to perturb features deemed important by an\ninterpretability method and to measure the change in prediction accuracy.\nIntuitively, a large decrease in prediction accuracy would indicate that the\nexplanation has correctly quantified the importance of features with respect to\nthe prediction outcome (e.g., logits). However, the change in the prediction\noutcome may stem from perturbation artifacts, since perturbed samples in the\ntest dataset are out of distribution (OOD) compared to the training dataset and\ncan therefore potentially disturb the model in an unexpected manner. To\novercome this challenge, we propose feature perturbation augmentation (FPA)\nwhich creates and adds perturbed images during the model training. Through\nextensive computational experiments, we demonstrate that FPA makes deep neural\nnetworks (DNNs) more robust against perturbations. Furthermore, training DNNs\nwith FPA demonstrate that the sign of importance scores may explain the model\nmore meaningfully than has previously been assumed. Overall, FPA is an\nintuitive data augmentation technique that improves the evaluation of post-hoc\ninterpretability methods.\n","authors":["Lennart Brocki","Neo Christopher Chung"],"pdf_url":"https://arxiv.org/pdf/2303.01538v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01526v1","updated":"2023-03-02T19:00:05Z","published":"2023-03-02T19:00:05Z","title":"Semantic Attention Flow Fields for Dynamic Scene Decomposition","summary":"  We present SAFF: a dynamic neural volume reconstruction of a casual monocular\nvideo that consists of time-varying color, density, scene flow, semantics, and\nattention information. The semantics and attention let us identify salient\nforeground objects separately from the background in arbitrary spacetime views.\nWe add two network heads to represent the semantic and attention information.\nFor optimization, we design semantic attention pyramids from DINO-ViT outputs\nthat trade detail with whole-image context. After optimization, we perform a\nsaliency-aware clustering to decompose the scene. For evaluation on real-world\ndynamic scene decomposition across spacetime, we annotate object masks in the\nNVIDIA Dynamic Scene Dataset. We demonstrate that SAFF can decompose dynamic\nscenes without affecting RGB or depth reconstruction quality, that\nvolume-integrated SAFF outperforms 2D baselines, and that SAFF improves\nforeground/background segmentation over recent static/dynamic split methods.\nProject Webpage: https://visual.cs.brown.edu/saff\n","authors":["Yiqing Liang","Eliot Laidlaw","Alexander Meyerowitz","Srinath Sridhar","James Tompkin"],"pdf_url":"https://arxiv.org/pdf/2303.01526v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01515v1","updated":"2023-03-02T18:59:44Z","published":"2023-03-02T18:59:44Z","title":"Optimization-Based Deep learning methods for Magnetic Resonance Imaging\n  Reconstruction and Synthesis","summary":"  This dissertation is devoted to provide advanced nonconvex nonsmooth\nvariational models of (Magnetic Resonance Image) MRI reconstruction, efficient\nlearnable image reconstruction algorithms and parameter training algorithms\nthat improve the accuracy and robustness of the optimization-based deep\nlearning methods for compressed sensing MRI reconstruction and synthesis. The\nfirst part introduces a novel optimization based deep neural network whose\narchitecture is inspired by proximal gradient descent for solving a variational\nmodel. The second part is a substantial extension of the preliminary work in\nthe first part by solving the calibration-free fast pMRI reconstruction problem\nin a discrete-time optimal control framework. The third part aims at developing\na generalizable Magnetic Resonance Imaging (MRI) reconstruction method in the\nmeta-learning framework. The last part aims to synthesize target modality of\nMRI by using partially scanned k-space data from source modalities instead of\nfully scanned data that is used in the state-of-the-art multimodal synthesis.\n","authors":["Wanyu Bian"],"pdf_url":"https://arxiv.org/pdf/2303.01515v1.pdf","comment":"PhD thesis, 145 pages"},{"id":"http://arxiv.org/abs/2212.07593v2","updated":"2023-03-02T18:54:31Z","published":"2022-12-15T02:45:57Z","title":"Enhanced Training of Query-Based Object Detection via Selective Query\n  Recollection","summary":"  This paper investigates a phenomenon where query-based object detectors\nmispredict at the last decoding stage while predicting correctly at an\nintermediate stage. We review the training process and attribute the overlooked\nphenomenon to two limitations: lack of training emphasis and cascading errors\nfrom decoding sequence. We design and present Selective Query Recollection\n(SQR), a simple and effective training strategy for query-based object\ndetectors. It cumulatively collects intermediate queries as decoding stages go\ndeeper and selectively forwards the queries to the downstream stages aside from\nthe sequential structure. Such-wise, SQR places training emphasis on later\nstages and allows later stages to work with intermediate queries from earlier\nstages directly. SQR can be easily plugged into various query-based object\ndetectors and significantly enhances their performance while leaving the\ninference pipeline unchanged. As a result, we apply SQR on Adamixer, DAB-DETR,\nand Deformable-DETR across various settings (backbone, number of queries,\nschedule) and consistently brings 1.4-2.8 AP improvement.\n","authors":["Fangyi Chen","Han Zhang","Kai Hu","Yu-kai Huang","Chenchen Zhu","Marios Savvides"],"pdf_url":"https://arxiv.org/pdf/2212.07593v2.pdf","comment":"CVPR2023"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2303.01297v1","updated":"2023-03-02T14:23:27Z","published":"2023-03-02T14:23:27Z","title":"Creating Synthetic Datasets for Collaborative Filtering Recommender\n  Systems using Generative Adversarial Networks","summary":"  Research and education in machine learning needs diverse, representative, and\nopen datasets that contain sufficient samples to handle the necessary training,\nvalidation, and testing tasks. Currently, the Recommender Systems area includes\na large number of subfields in which accuracy and beyond accuracy quality\nmeasures are continuously improved. To feed this research variety, it is\nnecessary and convenient to reinforce the existing datasets with synthetic\nones. This paper proposes a Generative Adversarial Network (GAN)-based method\nto generate collaborative filtering datasets in a parameterized way, by\nselecting their preferred number of users, items, samples, and stochastic\nvariability. This parameterization cannot be made using regular GANs. Our GAN\nmodel is fed with dense, short, and continuous embedding representations of\nitems and users, instead of sparse, large, and discrete vectors, to make an\naccurate and quick learning, compared to the traditional approach based on\nlarge and sparse input vectors. The proposed architecture includes a DeepMF\nmodel to extract the dense user and item embeddings, as well as a clustering\nprocess to convert from the dense GAN generated samples to the discrete and\nsparse ones, necessary to create each required synthetic dataset. The results\nof three different source datasets show adequate distributions and expected\nquality values and evolutions on the generated datasets compared to the source\nones. Synthetic datasets and source codes are available to researchers.\n","authors":["Jesús Bobadilla","Abraham Gutiérrez","Raciel Yera","Luis Martínez"],"pdf_url":"https://arxiv.org/pdf/2303.01297v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.10258v3","updated":"2023-03-02T12:50:53Z","published":"2022-03-19T06:48:50Z","title":"TDR-CL: Targeted Doubly Robust Collaborative Learning for Debiased\n  Recommendations","summary":"  Bias is a common problem inherent in recommender systems, which is entangled\nwith users' preferences and poses a great challenge to unbiased learning. For\ndebiasing tasks, the doubly robust (DR) method and its variants show superior\nperformance due to the double robustness property, that is, DR is unbiased when\neither imputed errors or learned propensities are accurate. However, our\ntheoretical analysis reveals that DR usually has a large variance. Meanwhile,\nDR would suffer unexpectedly large bias and poor generalization caused by\ninaccurate imputed errors and learned propensities, which usually occur in\npractice. In this paper, we propose a principled approach that can effectively\nreduce bias and variance simultaneously for existing DR approaches when the\nerror imputation model is misspecified. In addition, we further propose a novel\nsemi-parametric collaborative learning approach that decomposes imputed errors\ninto parametric and nonparametric parts and updates them collaboratively,\nresulting in more accurate predictions. Both theoretical analysis and\nexperiments demonstrate the superiority of the proposed methods compared with\nexisting debiasing methods.\n","authors":["Haoxuan Li","Yan Lyu","Chunyuan Zheng","Peng Wu"],"pdf_url":"https://arxiv.org/pdf/2203.10258v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01200v1","updated":"2023-03-02T12:33:52Z","published":"2023-03-02T12:33:52Z","title":"Retrieval for Extremely Long Queries and Documents with RPRS: a Highly\n  Efficient and Effective Transformer-based Re-Ranker","summary":"  Retrieval with extremely long queries and documents is a well-known and\nchallenging task in information retrieval and is commonly known as\nQuery-by-Document (QBD) retrieval. Specifically designed Transformer models\nthat can handle long input sequences have not shown high effectiveness in QBD\ntasks in previous work. We propose a Re-Ranker based on the novel Proportional\nRelevance Score (RPRS) to compute the relevance score between a query and the\ntop-k candidate documents. Our extensive evaluation shows RPRS obtains\nsignificantly better results than the state-of-the-art models on five different\ndatasets. Furthermore, RPRS is highly efficient since all documents can be\npre-processed, embedded, and indexed before query time which gives our\nre-ranker the advantage of having a complexity of O(N) where N is the total\nnumber of sentences in the query and candidate documents. Furthermore, our\nmethod solves the problem of the low-resource training in QBD retrieval tasks\nas it does not need large amounts of training data, and has only three\nparameters with a limited range that can be optimized with a grid search even\nif a small amount of labeled data is available. Our detailed analysis shows\nthat RPRS benefits from covering the full length of candidate documents and\nqueries.\n","authors":["Arian Askari","Suzan Verberne","Amin Abolghasemi","Wessel Kraaij","Gabriella Pasi"],"pdf_url":"https://arxiv.org/pdf/2303.01200v1.pdf","comment":"Under peer review"},{"id":"http://arxiv.org/abs/2303.01136v1","updated":"2023-03-02T10:33:11Z","published":"2023-03-02T10:33:11Z","title":"Effective Visualization and Analysis of Recommender Systems","summary":"  Recommender system exists everywhere in the business world. From Goodreads to\nTikTok, customers of internet products become more addicted to the products\nthanks to the technology. Industrial practitioners focus on increasing the\ntechnical accuracy of recommender systems while at same time balancing other\nfactors such as diversity and serendipity. In spite of the length of the\nresearch and development history of recommender systems, there has been little\ndiscussion on how to take advantage of visualization techniques to facilitate\nthe algorithmic design of the technology. In this paper, we use a series of\ndata analysis and visualization techniques such as Takens Embedding,\nDeterminantal Point Process and Social Network Analysis to help people develop\neffective recommender systems by predicting intermediate computational cost and\noutput performance. Our work is pioneering in the field, as to our limited\nknowledge, there have been few publications (if any) on visualization of\nrecommender systems.\n","authors":["Hao Wang"],"pdf_url":"https://arxiv.org/pdf/2303.01136v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01130v1","updated":"2023-03-02T10:23:50Z","published":"2023-03-02T10:23:50Z","title":"Distillation from Heterogeneous Models for Top-K Recommendation","summary":"  Recent recommender systems have shown remarkable performance by using an\nensemble of heterogeneous models. However, it is exceedingly costly because it\nrequires resources and inference latency proportional to the number of models,\nwhich remains the bottleneck for production. Our work aims to transfer the\nensemble knowledge of heterogeneous teachers to a lightweight student model\nusing knowledge distillation (KD), to reduce the huge inference costs while\nretaining high accuracy. Through an empirical study, we find that the efficacy\nof distillation severely drops when transferring knowledge from heterogeneous\nteachers. Nevertheless, we show that an important signal to ease the difficulty\ncan be obtained from the teacher's training trajectory. This paper proposes a\nnew KD framework, named HetComp, that guides the student model by transferring\neasy-to-hard sequences of knowledge generated from the teachers' trajectories.\nTo provide guidance according to the student's learning state, HetComp uses\ndynamic knowledge construction to provide progressively difficult ranking\nknowledge and adaptive knowledge transfer to gradually transfer finer-grained\nranking information. Our comprehensive experiments show that HetComp\nsignificantly improves the distillation quality and the generalization of the\nstudent model.\n","authors":["SeongKu Kang","Wonbin Kweon","Dongha Lee","Jianxun Lian","Xing Xie","Hwanjo Yu"],"pdf_url":"https://arxiv.org/pdf/2303.01130v1.pdf","comment":"TheWebConf'23"},{"id":"http://arxiv.org/abs/2303.00995v1","updated":"2023-03-02T06:07:22Z","published":"2023-03-02T06:07:22Z","title":"Heterogeneous Graph Contrastive Learning for Recommendation","summary":"  Graph Neural Networks (GNNs) have become powerful tools in modeling\ngraph-structured data in recommender systems. However, real-life recommendation\nscenarios usually involve heterogeneous relationships (e.g., social-aware user\ninfluence, knowledge-aware item dependency) which contains fruitful information\nto enhance the user preference learning. In this paper, we study the problem of\nheterogeneous graph-enhanced relational learning for recommendation. Recently,\ncontrastive self-supervised learning has become successful in recommendation.\nIn light of this, we propose a Heterogeneous Graph Contrastive Learning (HGCL),\nwhich is able to incorporate heterogeneous relational semantics into the\nuser-item interaction modeling with contrastive learning-enhanced knowledge\ntransfer across different views. However, the influence of heterogeneous side\ninformation on interactions may vary by users and items. To move this idea\nforward, we enhance our heterogeneous graph contrastive learning with meta\nnetworks to allow the personalized knowledge transformer with adaptive\ncontrastive augmentation. The experimental results on three real-world datasets\ndemonstrate the superiority of HGCL over state-of-the-art recommendation\nmethods. Through ablation study, key components in HGCL method are validated to\nbenefit the recommendation performance improvement. The source code of the\nmodel implementation is available at the link https://github.com/HKUDS/HGCL.\n","authors":["Mengru Chen","Chao Huang","Lianghao Xia","Wei Wei","Yong Xu","Ronghua Luo"],"pdf_url":"https://arxiv.org/pdf/2303.00995v1.pdf","comment":"This paper has been published as a full paper at WSDM 2023"},{"id":"http://arxiv.org/abs/2204.03972v3","updated":"2023-03-02T23:13:14Z","published":"2022-04-08T10:01:39Z","title":"FashionCLIP: Connecting Language and Images for Product Representations","summary":"  The steady rise of online shopping goes hand in hand with the development of\nincreasingly complex ML and NLP models. While most use cases are cast as\nspecialized supervised learning problems, we argue that practitioners would\ngreatly benefit from more transferable representations of products. In this\nwork, we build on recent developments in contrastive learning to train\nFashionCLIP, a CLIP-like model for the fashion industry. We showcase its\ncapabilities for retrieval, classification and grounding, and release our model\nand code to the community.\n","authors":["Patrick John Chia","Giuseppe Attanasio","Federico Bianchi","Silvia Terragni","Ana Rita Magalhães","Diogo Goncalves","Ciro Greco","Jacopo Tagliabue"],"pdf_url":"https://arxiv.org/pdf/2204.03972v3.pdf","comment":"Model available at\n  https://huggingface.co/patrickjohncyh/fashion-clip, dataset at\n  https://github.com/Farfetch"},{"id":"http://arxiv.org/abs/2303.01593v1","updated":"2023-03-02T21:35:15Z","published":"2023-03-02T21:35:15Z","title":"QAID: Question Answering Inspired Few-shot Intent Detection","summary":"  Intent detection with semantically similar fine-grained intents is a\nchallenging task. To address it, we reformulate intent detection as a\nquestion-answering retrieval task by treating utterances and intent names as\nquestions and answers. To that end, we utilize a question-answering retrieval\narchitecture and adopt a two stages training schema with batch contrastive\nloss. In the pre-training stage, we improve query representations through\nself-supervised training. Then, in the fine-tuning stage, we increase\ncontextualized token-level similarity scores between queries and answers from\nthe same intent. Our results on three few-shot intent detection benchmarks\nachieve state-of-the-art performance.\n","authors":["Asaf Yehudai","Matan Vetzler","Yosi Mass","Koren Lazar","Doron Cohen","Boaz Carmeli"],"pdf_url":"https://arxiv.org/pdf/2303.01593v1.pdf","comment":"ICLR paper"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2303.01500v1","updated":"2023-03-02T18:59:15Z","published":"2023-03-02T18:59:15Z","title":"Dropout Reduces Underfitting","summary":"  Introduced by Hinton et al. in 2012, dropout has stood the test of time as a\nregularizer for preventing overfitting in neural networks. In this study, we\ndemonstrate that dropout can also mitigate underfitting when used at the start\nof training. During the early phase, we find dropout reduces the directional\nvariance of gradients across mini-batches and helps align the mini-batch\ngradients with the entire dataset's gradient. This helps counteract the\nstochasticity of SGD and limit the influence of individual batches on model\ntraining. Our findings lead us to a solution for improving performance in\nunderfitting models - early dropout: dropout is applied only during the initial\nphases of training, and turned off afterwards. Models equipped with early\ndropout achieve lower final training loss compared to their counterparts\nwithout dropout. Additionally, we explore a symmetric technique for\nregularizing overfitting models - late dropout, where dropout is not used in\nthe early iterations and is only activated later in training. Experiments on\nImageNet and various vision tasks demonstrate that our methods consistently\nimprove generalization accuracy. Our results encourage more research on\nunderstanding regularization in deep learning and our methods can be useful\ntools for future neural network training, especially in the era of large data.\nCode is available at https://github.com/facebookresearch/dropout .\n","authors":["Zhuang Liu","Zhiqiu Xu","Joseph Jin","Zhiqiang Shen","Trevor Darrell"],"pdf_url":"https://arxiv.org/pdf/2303.01500v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2303.01498v1","updated":"2023-03-02T18:58:15Z","published":"2023-03-02T18:58:15Z","title":"ABAW: Valence-Arousal Estimation, Expression Recognition, Action Unit\n  Detection & Emotional Reaction Intensity Estimation Challenges","summary":"  The fifth Affective Behavior Analysis in-the-wild (ABAW) Competition is part\nof the respective ABAW Workshop which will be held in conjunction with IEEE\nComputer Vision and Pattern Recognition Conference (CVPR), 2023. The 5th ABAW\nCompetition is a continuation of the Competitions held at ECCV 2022, IEEE CVPR\n2022, ICCV 2021, IEEE FG 2020 and CVPR 2017 Conferences, and is dedicated at\nautomatically analyzing affect. For this year's Competition, we feature two\ncorpora: i) an extended version of the Aff-Wild2 database and ii) the\nHume-Reaction dataset. The former database is an audiovisual one of around 600\nvideos of around 3M frames and is annotated with respect to:a) two continuous\naffect dimensions -valence (how positive/negative a person is) and arousal (how\nactive/passive a person is)-; b) basic expressions (e.g. happiness, sadness,\nneutral state); and c) atomic facial muscle actions (i.e., action units). The\nlatter dataset is an audiovisual one in which reactions of individuals to\nemotional stimuli have been annotated with respect to seven emotional\nexpression intensities. Thus the 5th ABAW Competition encompasses four\nChallenges: i) uni-task Valence-Arousal Estimation, ii) uni-task Expression\nClassification, iii) uni-task Action Unit Detection, and iv) Emotional Reaction\nIntensity Estimation. In this paper, we present these Challenges, along with\ntheir corpora, we outline the evaluation metrics, we present the baseline\nsystems and illustrate their obtained performance.\n","authors":["Dimitrios Kollias","Panagiotis Tzirakis","Alice Baird","Alan Cowen","Stefanos Zafeiriou"],"pdf_url":"https://arxiv.org/pdf/2303.01498v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2202.10659"},{"id":"http://arxiv.org/abs/2303.01497v1","updated":"2023-03-02T18:57:38Z","published":"2023-03-02T18:57:38Z","title":"Teach a Robot to FISH: Versatile Imitation from One Minute of\n  Demonstrations","summary":"  While imitation learning provides us with an efficient toolkit to train\nrobots, learning skills that are robust to environment variations remains a\nsignificant challenge. Current approaches address this challenge by relying\neither on large amounts of demonstrations that span environment variations or\non handcrafted reward functions that require state estimates. Both directions\nare not scalable to fast imitation. In this work, we present Fast Imitation of\nSkills from Humans (FISH), a new imitation learning approach that can learn\nrobust visual skills with less than a minute of human demonstrations. Given a\nweak base-policy trained by offline imitation of demonstrations, FISH computes\nrewards that correspond to the \"match\" between the robot's behavior and the\ndemonstrations. These rewards are then used to adaptively update a residual\npolicy that adds on to the base-policy. Across all tasks, FISH requires at most\ntwenty minutes of interactive learning to imitate demonstrations on object\nconfigurations that were not seen in the demonstrations. Importantly, FISH is\nconstructed to be versatile, which allows it to be used across robot\nmorphologies (e.g. xArm, Allegro, Stretch) and camera configurations (e.g.\nthird-person, eye-in-hand). Our experimental evaluations on 9 different tasks\nshow that FISH achieves an average success rate of 93%, which is around 3.8x\nhigher than prior state-of-the-art methods.\n","authors":["Siddhant Haldar","Jyothish Pari","Anant Rai","Lerrel Pinto"],"pdf_url":"https://arxiv.org/pdf/2303.01497v1.pdf","comment":"Code and robot videos are available at\n  https://fast-imitation.github.io/"},{"id":"http://arxiv.org/abs/2208.05424v5","updated":"2023-03-02T18:54:00Z","published":"2022-08-08T16:54:01Z","title":"Physics-Constrained Deep Learning for Climate Downscaling","summary":"  The availability of reliable, high-resolution climate and weather data is\nimportant to inform long-term decisions on climate adaptation and mitigation\nand to guide rapid responses to extreme events. Forecasting models are limited\nby computational costs and, therefore, often generate coarse-resolution\npredictions. Statistical downscaling, including super-resolution methods from\ndeep learning, can provide an efficient method of upsampling low-resolution\ndata. However, despite achieving visually compelling results in some cases,\nsuch models frequently violate conservation laws when predicting physical\nvariables. In order to conserve physical quantities, we develop methods that\nguarantee physical constraints are satisfied by a deep learning downscaling\nmodel while also improving their performance according to traditional metrics.\nWe compare different constraining approaches and demonstrate their\napplicability across different neural architectures as well as a variety of\nclimate and weather datasets. Besides enabling faster and more accurate climate\npredictions, we also show that our novel methodologies can improve\nsuper-resolution for satellite data and standard datasets.\n","authors":["Paula Harder","Venkatesh Ramesh","Alex Hernandez-Garcia","Qidong Yang","Prasanna Sattigeri","Daniela Szwarcman","Campbell Watson","David Rolnick"],"pdf_url":"https://arxiv.org/pdf/2208.05424v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01491v1","updated":"2023-03-02T18:52:31Z","published":"2023-03-02T18:52:31Z","title":"Transferring Models Trained on Natural Images to 3D MRI via Position\n  Encoded Slice Models","summary":"  Transfer learning has remarkably improved computer vision. These advances\nalso promise improvements in neuroimaging, where training set sizes are often\nsmall. However, various difficulties arise in directly applying models\npretrained on natural images to radiologic images, such as MRIs. In particular,\na mismatch in the input space (2D images vs. 3D MRIs) restricts the direct\ntransfer of models, often forcing us to consider only a few MRI slices as\ninput. To this end, we leverage the 2D-Slice-CNN architecture of Gupta et al.\n(2021), which embeds all the MRI slices with 2D encoders (neural networks that\ntake 2D image input) and combines them via permutation-invariant layers. With\nthe insight that the pretrained model can serve as the 2D encoder, we\ninitialize the 2D encoder with ImageNet pretrained weights that outperform\nthose initialized and trained from scratch on two neuroimaging tasks -- brain\nage prediction on the UK Biobank dataset and Alzheimer's disease detection on\nthe ADNI dataset. Further, we improve the modeling capabilities of 2D-Slice\nmodels by incorporating spatial information through position embeddings, which\ncan improve the performance in some cases.\n","authors":["Umang Gupta","Tamoghna Chattopadhyay","Nikhil Dhinagar","Paul M. Thompson","Greg Ver Steeg","The Alzheimer's Disease Neuroimaging Initiative"],"pdf_url":"https://arxiv.org/pdf/2303.01491v1.pdf","comment":"To appear at IEEE International Symposium on Biomedical Imaging 2023\n  (ISBI 2023). Code is available at\n  https://github.com/umgupta/2d-slice-set-networks"},{"id":"http://arxiv.org/abs/2207.08435v3","updated":"2023-03-02T18:51:38Z","published":"2022-07-18T08:41:00Z","title":"Robust Simulation-Based Inference in Cosmology with Bayesian Neural\n  Networks","summary":"  Simulation-based inference (SBI) is rapidly establishing itself as a standard\nmachine learning technique for analyzing data in cosmological surveys. Despite\ncontinual improvements to the quality of density estimation by learned models,\napplications of such techniques to real data are entirely reliant on the\ngeneralization power of neural networks far outside the training distribution,\nwhich is mostly unconstrained. Due to the imperfections in scientist-created\nsimulations, and the large computational expense of generating all possible\nparameter combinations, SBI methods in cosmology are vulnerable to such\ngeneralization issues. Here, we discuss the effects of both issues, and show\nhow using a Bayesian neural network framework for training SBI can mitigate\nbiases, and result in more reliable inference outside the training set. We\nintroduce cosmoSWAG, the first application of Stochastic Weight Averaging to\ncosmology, and apply it to SBI trained for inference on the cosmic microwave\nbackground.\n","authors":["Pablo Lemos","Miles Cranmer","Muntazir Abidi","ChangHoon Hahn","Michael Eickenberg","Elena Massara","David Yallup","Shirley Ho"],"pdf_url":"https://arxiv.org/pdf/2207.08435v3.pdf","comment":"5 pages, 3 figures. Preliminary version accepted at the ML4Astro\n  Machine Learning for Astrophysics Workshop at the Thirty-ninth International\n  Conference on Machine Learning (ICML 2022). Final version published at\n  Machine Learning: Science and Technology"},{"id":"http://arxiv.org/abs/2303.01488v1","updated":"2023-03-02T18:51:38Z","published":"2023-03-02T18:51:38Z","title":"Self-Improving Robots: End-to-End Autonomous Visuomotor Reinforcement\n  Learning","summary":"  In imitation and reinforcement learning, the cost of human supervision limits\nthe amount of data that robots can be trained on. An aspirational goal is to\nconstruct self-improving robots: robots that can learn and improve on their\nown, from autonomous interaction with minimal human supervision or oversight.\nSuch robots could collect and train on much larger datasets, and thus learn\nmore robust and performant policies. While reinforcement learning offers a\nframework for such autonomous learning via trial-and-error, practical\nrealizations end up requiring extensive human supervision for reward function\ndesign and repeated resetting of the environment between episodes of\ninteractions. In this work, we propose MEDAL++, a novel design for\nself-improving robotic systems: given a small set of expert demonstrations at\nthe start, the robot autonomously practices the task by learning to both do and\nundo the task, simultaneously inferring the reward function from the\ndemonstrations. The policy and reward function are learned end-to-end from\nhigh-dimensional visual inputs, bypassing the need for explicit state\nestimation or task-specific pre-training for visual encoders used in prior\nwork. We first evaluate our proposed algorithm on a simulated non-episodic\nbenchmark EARL, finding that MEDAL++ is both more data efficient and gets up to\n30% better final performance compared to state-of-the-art vision-based methods.\nOur real-robot experiments show that MEDAL++ can be applied to manipulation\nproblems in larger environments than those considered in prior work, and\nautonomous self-improvement can improve the success rate by 30-70% over\nbehavior cloning on just the expert data. Code, training and evaluation videos\nalong with a brief overview is available at:\nhttps://architsharma97.github.io/self-improving-robots/\n","authors":["Archit Sharma","Ahmed M. Ahmed","Rehaan Ahmad","Chelsea Finn"],"pdf_url":"https://arxiv.org/pdf/2303.01488v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08965v2","updated":"2023-03-02T18:50:45Z","published":"2023-01-21T15:42:53Z","title":"Raw or Cooked? Object Detection on RAW Images","summary":"  Images fed to a deep neural network have in general undergone several\nhandcrafted image signal processing (ISP) operations, all of which have been\noptimized to produce visually pleasing images. In this work, we investigate the\nhypothesis that the intermediate representation of visually pleasing images is\nsub-optimal for downstream computer vision tasks compared to the RAW image\nrepresentation. We suggest that the operations of the ISP instead should be\noptimized towards the end task, by learning the parameters of the operations\njointly during training. We extend previous works on this topic and propose a\nnew learnable operation that enables an object detector to achieve superior\nperformance when compared to both previous works and traditional RGB images. In\nexperiments on the open PASCALRAW dataset, we empirically confirm our\nhypothesis.\n","authors":["William Ljungbergh","Joakim Johnander","Christoffer Petersson","Michael Felsberg"],"pdf_url":"https://arxiv.org/pdf/2301.08965v2.pdf","comment":"SCIA 2023"},{"id":"http://arxiv.org/abs/2303.01486v1","updated":"2023-03-02T18:47:51Z","published":"2023-03-02T18:47:51Z","title":"Understanding plasticity in neural networks","summary":"  Plasticity, the ability of a neural network to quickly change its predictions\nin response to new information, is essential for the adaptability and\nrobustness of deep reinforcement learning systems. Deep neural networks are\nknown to lose plasticity over the course of training even in relatively simple\nlearning problems, but the mechanisms driving this phenomenon are still poorly\nunderstood. This paper conducts a systematic empirical analysis into plasticity\nloss, with the goal of understanding the phenomenon mechanistically in order to\nguide the future development of targeted solutions. We find that loss of\nplasticity is deeply connected to changes in the curvature of the loss\nlandscape, but that it typically occurs in the absence of saturated units or\ndivergent gradient norms. Based on this insight, we identify a number of\nparameterization and optimization design choices which enable networks to\nbetter preserve plasticity over the course of training. We validate the utility\nof these findings in larger-scale learning problems by applying the\nbest-performing intervention, layer normalization, to a deep RL agent trained\non the Arcade Learning Environment.\n","authors":["Clare Lyle","Zeyu Zheng","Evgenii Nikishin","Bernardo Avila Pires","Razvan Pascanu","Will Dabney"],"pdf_url":"https://arxiv.org/pdf/2303.01486v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01484v1","updated":"2023-03-02T18:45:02Z","published":"2023-03-02T18:45:02Z","title":"Predicting Motion Plans for Articulating Everyday Objects","summary":"  Mobile manipulation tasks such as opening a door, pulling open a drawer, or\nlifting a toilet lid require constrained motion of the end-effector under\nenvironmental and task constraints. This, coupled with partial information in\nnovel environments, makes it challenging to employ classical motion planning\napproaches at test time. Our key insight is to cast it as a learning problem to\nleverage past experience of solving similar planning problems to directly\npredict motion plans for mobile manipulation tasks in novel situations at test\ntime. To enable this, we develop a simulator, ArtObjSim, that simulates\narticulated objects placed in real scenes. We then introduce SeqIK+$\\theta_0$,\na fast and flexible representation for motion plans. Finally, we learn models\nthat use SeqIK+$\\theta_0$ to quickly predict motion plans for articulating\nnovel objects at test time. Experimental evaluation shows improved speed and\naccuracy at generating motion plans than pure search-based methods and pure\nlearning methods.\n","authors":["Arjun Gupta","Max E. Shepherd","Saurabh Gupta"],"pdf_url":"https://arxiv.org/pdf/2303.01484v1.pdf","comment":"To Appear in ICRA 2023. Project webpage:\n  https://arjung128.github.io/mpao/"},{"id":"http://arxiv.org/abs/2303.01483v1","updated":"2023-03-02T18:44:18Z","published":"2023-03-02T18:44:18Z","title":"Auxiliary Functions as Koopman Observables: Data-Driven Polynomial\n  Optimization for Dynamical Systems","summary":"  We present a flexible data-driven method for dynamical system analysis that\ndoes not require explicit model discovery. The method is rooted in\nwell-established techniques for approximating the Koopman operator from data\nand is implemented as a semidefinite program that can be solved numerically.\nThe method is agnostic of whether data is generated through a deterministic or\nstochastic process, so its implementation requires no prior adjustments by the\nuser to accommodate these different scenarios. Rigorous convergence results\njustify the applicability of the method, while also extending and uniting\nsimilar results from across the literature. Examples on discovering Lyapunov\nfunctions and on performing ergodic optimization for both deterministic and\nstochastic dynamics exemplify these convergence results and demonstrate the\nperformance of the method.\n","authors":["Jason J. Bramburger","Giovanni Fantuzzi"],"pdf_url":"https://arxiv.org/pdf/2303.01483v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01475v1","updated":"2023-03-02T18:37:34Z","published":"2023-03-02T18:37:34Z","title":"Over-training with Mixup May Hurt Generalization","summary":"  Mixup, which creates synthetic training instances by linearly interpolating\nrandom sample pairs, is a simple and yet effective regularization technique to\nboost the performance of deep models trained with SGD. In this work, we report\na previously unobserved phenomenon in Mixup training: on a number of standard\ndatasets, the performance of Mixup-trained models starts to decay after\ntraining for a large number of epochs, giving rise to a U-shaped generalization\ncurve. This behavior is further aggravated when the size of original dataset is\nreduced. To help understand such a behavior of Mixup, we show theoretically\nthat Mixup training may introduce undesired data-dependent label noises to the\nsynthesized data. Via analyzing a least-square regression problem with a random\nfeature model, we explain why noisy labels may cause the U-shaped curve to\noccur: Mixup improves generalization through fitting the clean patterns at the\nearly training stage, but as training progresses, Mixup becomes over-fitting to\nthe noise in the synthetic data. Extensive experiments are performed on a\nvariety of benchmark datasets, validating this explanation.\n","authors":["Zixuan Liu","Ziqiao Wang","Hongyu Guo","Yongyi Mao"],"pdf_url":"https://arxiv.org/pdf/2303.01475v1.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01471v1","updated":"2023-03-02T18:34:38Z","published":"2023-03-02T18:34:38Z","title":"Quantum Hamiltonian Descent","summary":"  Gradient descent is a fundamental algorithm in both theory and practice for\ncontinuous optimization. Identifying its quantum counterpart would be appealing\nto both theoretical and practical quantum applications. A conventional approach\nto quantum speedups in optimization relies on the quantum acceleration of\nintermediate steps of classical algorithms, while keeping the overall\nalgorithmic trajectory and solution quality unchanged. We propose Quantum\nHamiltonian Descent (QHD), which is derived from the path integral of dynamical\nsystems referring to the continuous-time limit of classical gradient descent\nalgorithms, as a truly quantum counterpart of classical gradient methods where\nthe contribution from classically-prohibited trajectories can significantly\nboost QHD's performance for non-convex optimization. Moreover, QHD is described\nas a Hamiltonian evolution efficiently simulatable on both digital and analog\nquantum computers. By embedding the dynamics of QHD into the evolution of the\nso-called Quantum Ising Machine (including D-Wave and others), we empirically\nobserve that the D-Wave-implemented QHD outperforms a selection of\nstate-of-the-art gradient-based classical solvers and the standard quantum\nadiabatic algorithm, based on the time-to-solution metric, on non-convex\nconstrained quadratic programming instances up to 75 dimensions. Finally, we\npropose a \"three-phase picture\" to explain the behavior of QHD, especially its\ndifference from the quantum adiabatic algorithm.\n","authors":["Jiaqi Leng","Ethan Hickman","Joseph Li","Xiaodi Wu"],"pdf_url":"https://arxiv.org/pdf/2303.01471v1.pdf","comment":"71 pages, 13 figures, an accompanying website is at\n  https://jiaqileng.github.io/quantum-hamiltonian-descent/"},{"id":"http://arxiv.org/abs/2303.01469v1","updated":"2023-03-02T18:30:16Z","published":"2023-03-02T18:30:16Z","title":"Consistency Models","summary":"  Diffusion models have made significant breakthroughs in image, audio, and\nvideo generation, but they depend on an iterative generation process that\ncauses slow sampling speed and caps their potential for real-time applications.\nTo overcome this limitation, we propose consistency models, a new family of\ngenerative models that achieve high sample quality without adversarial\ntraining. They support fast one-step generation by design, while still allowing\nfor few-step sampling to trade compute for sample quality. They also support\nzero-shot data editing, like image inpainting, colorization, and\nsuper-resolution, without requiring explicit training on these tasks.\nConsistency models can be trained either as a way to distill pre-trained\ndiffusion models, or as standalone generative models. Through extensive\nexperiments, we demonstrate that they outperform existing distillation\ntechniques for diffusion models in one- and few-step generation. For example,\nwe achieve the new state-of-the-art FID of 3.55 on CIFAR-10 and 6.20 on\nImageNet 64x64 for one-step generation. When trained as standalone generative\nmodels, consistency models also outperform single-step, non-adversarial\ngenerative models on standard benchmarks like CIFAR-10, ImageNet 64x64 and LSUN\n256x256.\n","authors":["Yang Song","Prafulla Dhariwal","Mark Chen","Ilya Sutskever"],"pdf_url":"https://arxiv.org/pdf/2303.01469v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01464v1","updated":"2023-03-02T18:27:00Z","published":"2023-03-02T18:27:00Z","title":"Efficient Rate Optimal Regret for Adversarial Contextual MDPs Using\n  Online Function Approximation","summary":"  We present the OMG-CMDP! algorithm for regret minimization in adversarial\nContextual MDPs. The algorithm operates under the minimal assumptions of\nrealizable function class and access to online least squares and log loss\nregression oracles. Our algorithm is efficient (assuming efficient online\nregression oracles), simple and robust to approximation errors. It enjoys an\n$\\widetilde{O}(H^{2.5} \\sqrt{ T|S||A| ( \\mathcal{R}(\\mathcal{O}) + H\n\\log(\\delta^{-1}) )})$ regret guarantee, with $T$ being the number of episodes,\n$S$ the state space, $A$ the action space, $H$ the horizon and\n$\\mathcal{R}(\\mathcal{O}) = \\mathcal{R}(\\mathcal{O}_{\\mathrm{sq}}^\\mathcal{F})\n+ \\mathcal{R}(\\mathcal{O}_{\\mathrm{log}}^\\mathcal{P})$ is the sum of the\nregression oracles' regret, used to approximate the context-dependent rewards\nand dynamics, respectively. To the best of our knowledge, our algorithm is the\nfirst efficient rate optimal regret minimization algorithm for adversarial\nCMDPs that operates under the minimal standard assumption of online function\napproximation.\n","authors":["Orin Levy","Alon Cohen","Asaf Cassel","Yishay Mansour"],"pdf_url":"https://arxiv.org/pdf/2303.01464v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01462v1","updated":"2023-03-02T18:24:26Z","published":"2023-03-02T18:24:26Z","title":"Benign Overfitting in Linear Classifiers and Leaky ReLU Networks from\n  KKT Conditions for Margin Maximization","summary":"  Linear classifiers and leaky ReLU networks trained by gradient flow on the\nlogistic loss have an implicit bias towards solutions which satisfy the\nKarush--Kuhn--Tucker (KKT) conditions for margin maximization. In this work we\nestablish a number of settings where the satisfaction of these KKT conditions\nimplies benign overfitting in linear classifiers and in two-layer leaky ReLU\nnetworks: the estimators interpolate noisy training data and simultaneously\ngeneralize well to test data. The settings include variants of the noisy\nclass-conditional Gaussians considered in previous work as well as new\ndistributional settings where benign overfitting has not been previously\nobserved. The key ingredient to our proof is the observation that when the\ntraining data is nearly-orthogonal, both linear classifiers and leaky ReLU\nnetworks satisfying the KKT conditions for their respective margin maximization\nproblems behave like a nearly uniform average of the training examples.\n","authors":["Spencer Frei","Gal Vardi","Peter L. Bartlett","Nathan Srebro"],"pdf_url":"https://arxiv.org/pdf/2303.01462v1.pdf","comment":"53 pages"},{"id":"http://arxiv.org/abs/2303.01456v1","updated":"2023-03-02T18:14:35Z","published":"2023-03-02T18:14:35Z","title":"The Double-Edged Sword of Implicit Bias: Generalization vs. Robustness\n  in ReLU Networks","summary":"  In this work, we study the implications of the implicit bias of gradient flow\non generalization and adversarial robustness in ReLU networks. We focus on a\nsetting where the data consists of clusters and the correlations between\ncluster means are small, and show that in two-layer ReLU networks gradient flow\nis biased towards solutions that generalize well, but are highly vulnerable to\nadversarial examples. Our results hold even in cases where the network has many\nmore parameters than training examples. Despite the potential for harmful\noverfitting in such overparameterized settings, we prove that the implicit bias\nof gradient flow prevents it. However, the implicit bias also leads to\nnon-robust solutions (susceptible to small adversarial $\\ell_2$-perturbations),\neven though robust networks that fit the data exist.\n","authors":["Spencer Frei","Gal Vardi","Peter L. Bartlett","Nathan Srebro"],"pdf_url":"https://arxiv.org/pdf/2303.01456v1.pdf","comment":"41 pages"},{"id":"http://arxiv.org/abs/2303.01455v1","updated":"2023-03-02T18:13:27Z","published":"2023-03-02T18:13:27Z","title":"Learning Contact-based Navigation in Crowds","summary":"  Navigation strategies that intentionally incorporate contact with humans\n(i.e. \"contact-based\" social navigation) in crowded environments are largely\nunexplored even though collision-free social navigation is a well studied\nproblem. Traditional social navigation frameworks require the robot to stop\nsuddenly or \"freeze\" whenever a collision is imminent. This paradigm poses two\nproblems: 1) freezing while navigating a crowd may cause people to trip and\nfall over the robot, resulting in more harm than the collision itself, and 2)\nin very dense social environments where collisions are unavoidable, such a\ncontrol scheme would render the robot unable to move and preclude the\nopportunity to study how humans incorporate robots into these environments.\nHowever, if robots are to be meaningfully included in crowded social spaces,\nsuch as busy streets, subways, stores, or other densely populated locales,\nthere may not exist trajectories that can guarantee zero collisions. Thus,\nadoption of robots in these environments requires the development of minimally\ndisruptive navigation plans that can safely plan for and respond to contacts.\nWe propose a learning-based motion planner and control scheme to navigate dense\nsocial environments using safe contacts for an omnidirectional mobile robot.\nThe planner is evaluated in simulation over 360 trials with crowd densities\nvarying between 0.0 and 1.6 people per square meter. Our navigation scheme is\nable to use contact to safely navigate in crowds of higher density than has\nbeen previously reported, to our knowledge.\n","authors":["Kyle Morgenstein","Junfeng Jiao","Luis Sentis"],"pdf_url":"https://arxiv.org/pdf/2303.01455v1.pdf","comment":"Presented at the Human Interactive Robot Learning worksop at HRI2023"},{"id":"http://arxiv.org/abs/2212.08570v2","updated":"2023-03-02T18:12:11Z","published":"2022-12-15T15:44:02Z","title":"Audio-based AI classifiers show no evidence of improved COVID-19\n  screening over simple symptoms checkers","summary":"  Recent work has reported that AI classifiers trained on audio recordings can\naccurately predict severe acute respiratory syndrome coronavirus 2 (SARSCoV2)\ninfection status. Here, we undertake a large scale study of audio-based deep\nlearning classifiers, as part of the UK governments pandemic response. We\ncollect and analyse a dataset of audio recordings from 67,842 individuals with\nlinked metadata, including reverse transcription polymerase chain reaction\n(PCR) test outcomes, of whom 23,514 tested positive for SARS CoV 2. Subjects\nwere recruited via the UK governments National Health Service Test-and-Trace\nprogramme and the REal-time Assessment of Community Transmission (REACT)\nrandomised surveillance survey. In an unadjusted analysis of our dataset AI\nclassifiers predict SARS-CoV-2 infection status with high accuracy (Receiver\nOperating Characteristic Area Under the Curve (ROCAUC) 0.846 [0.838, 0.854])\nconsistent with the findings of previous studies. However, after matching on\nmeasured confounders, such as age, gender, and self reported symptoms, our\nclassifiers performance is much weaker (ROC-AUC 0.619 [0.594, 0.644]). Upon\nquantifying the utility of audio based classifiers in practical settings, we\nfind them to be outperformed by simple predictive scores based on user reported\nsymptoms.\n","authors":["Harry Coppock","George Nicholson","Ivan Kiskin","Vasiliki Koutra","Kieran Baker","Jobie Budd","Richard Payne","Emma Karoune","David Hurley","Alexander Titcomb","Sabrina Egglestone","Ana Tendero Cañadas","Lorraine Butler","Radka Jersakova","Jonathon Mellor","Selina Patel","Tracey Thornley","Peter Diggle","Sylvia Richardson","Josef Packham","Björn W. Schuller","Davide Pigoli","Steven Gilmour","Stephen Roberts","Chris Holmes"],"pdf_url":"https://arxiv.org/pdf/2212.08570v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01453v1","updated":"2023-03-02T18:11:39Z","published":"2023-03-02T18:11:39Z","title":"Improved Space Bounds for Learning with Experts","summary":"  We give improved tradeoffs between space and regret for the online learning\nwith expert advice problem over $T$ days with $n$ experts. Given a space budget\nof $n^{\\delta}$ for $\\delta \\in (0,1)$, we provide an algorithm achieving\nregret $\\tilde{O}(n^2 T^{1/(1+\\delta)})$, improving upon the regret bound\n$\\tilde{O}(n^2 T^{2/(2+\\delta)})$ in the recent work of [PZ23]. The improvement\nis particularly salient in the regime $\\delta \\rightarrow 1$ where the regret\nof our algorithm approaches $\\tilde{O}_n(\\sqrt{T})$, matching the $T$\ndependence in the standard online setting without space restrictions.\n","authors":["Anders Aamand","Justin Y. Chen","Huy Lê Nguyen","Sandeep Silwal"],"pdf_url":"https://arxiv.org/pdf/2303.01453v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00654v2","updated":"2023-03-02T17:53:38Z","published":"2023-03-01T16:56:39Z","title":"How to DP-fy ML: A Practical Guide to Machine Learning with Differential\n  Privacy","summary":"  ML models are ubiquitous in real world applications and are a constant focus\nof research. At the same time, the community has started to realize the\nimportance of protecting the privacy of ML training data.\n  Differential Privacy (DP) has become a gold standard for making formal\nstatements about data anonymization. However, while some adoption of DP has\nhappened in industry, attempts to apply DP to real world complex ML models are\nstill few and far between. The adoption of DP is hindered by limited practical\nguidance of what DP protection entails, what privacy guarantees to aim for, and\nthe difficulty of achieving good privacy-utility-computation trade-offs for ML\nmodels. Tricks for tuning and maximizing performance are scattered among papers\nor stored in the heads of practitioners. Furthermore, the literature seems to\npresent conflicting evidence on how and whether to apply architectural\nadjustments and which components are \"safe\" to use with DP.\n  This work is a self-contained guide that gives an in-depth overview of the\nfield of DP ML and presents information about achieving the best possible DP ML\nmodel with rigorous privacy guarantees. Our target audience is both researchers\nand practitioners. Researchers interested in DP for ML will benefit from a\nclear overview of current advances and areas for improvement. We include\ntheory-focused sections that highlight important topics such as privacy\naccounting and its assumptions, and convergence. For a practitioner, we provide\na background in DP theory and a clear step-by-step guide for choosing an\nappropriate privacy definition and approach, implementing DP training,\npotentially updating the model architecture, and tuning hyperparameters. For\nboth researchers and practitioners, consistently and fully reporting privacy\nguarantees is critical, and so we propose a set of specific best practices for\nstating guarantees.\n","authors":["Natalia Ponomareva","Hussein Hazimeh","Alex Kurakin","Zheng Xu","Carson Denison","H. Brendan McMahan","Sergei Vassilvitskii","Steve Chien","Abhradeep Thakurta"],"pdf_url":"https://arxiv.org/pdf/2303.00654v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01433v1","updated":"2023-03-02T17:47:02Z","published":"2023-03-02T17:47:02Z","title":"Do Machine Learning Models Learn Common Sense?","summary":"  Machine learning models can make basic errors that are easily hidden within\nvast amounts of data. Such errors often run counter to human intuition referred\nto as \"common sense\". We thereby seek to characterize common sense for\ndata-driven models, and quantify the extent to which a model has learned common\nsense. We propose a framework that integrates logic-based methods with\nstatistical inference to derive common sense rules from a model's training data\nwithout supervision. We further show how to adapt models at test-time to reduce\ncommon sense rule violations and produce more coherent predictions. We evaluate\nour framework on datasets and models for three different domains. It generates\naround 250 to 300k rules over these datasets, and uncovers 1.5k to 26k\nviolations of those rules by state-of-the-art models for the respective\ndatasets. Test-time adaptation reduces these violations by up to 38% without\nimpacting overall model accuracy.\n","authors":["Aaditya Naik","Yinjun Wu","Mayur Naik","Eric Wong"],"pdf_url":"https://arxiv.org/pdf/2303.01433v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00580v3","updated":"2023-03-02T17:43:38Z","published":"2022-10-02T17:41:01Z","title":"GFlowNets and variational inference","summary":"  This paper builds bridges between two families of probabilistic algorithms:\n(hierarchical) variational inference (VI), which is typically used to model\ndistributions over continuous spaces, and generative flow networks (GFlowNets),\nwhich have been used for distributions over discrete structures such as graphs.\nWe demonstrate that, in certain cases, VI algorithms are equivalent to special\ncases of GFlowNets in the sense of equality of expected gradients of their\nlearning objectives. We then point out the differences between the two families\nand show how these differences emerge experimentally. Notably, GFlowNets, which\nborrow ideas from reinforcement learning, are more amenable than VI to\noff-policy training without the cost of high gradient variance induced by\nimportance sampling. We argue that this property of GFlowNets can provide\nadvantages for capturing diversity in multimodal target distributions.\n","authors":["Nikolay Malkin","Salem Lahlou","Tristan Deleu","Xu Ji","Edward Hu","Katie Everett","Dinghuai Zhang","Yoshua Bengio"],"pdf_url":"https://arxiv.org/pdf/2210.00580v3.pdf","comment":"ICLR 2023 final version; code: https://github.com/GFNOrg/GFN_vs_HVI"},{"id":"http://arxiv.org/abs/2206.05825v3","updated":"2023-03-02T17:37:59Z","published":"2022-06-12T19:49:14Z","title":"A Unified Approach to Reinforcement Learning, Quantal Response\n  Equilibria, and Two-Player Zero-Sum Games","summary":"  This work studies an algorithm, which we call magnetic mirror descent, that\nis inspired by mirror descent and the non-Euclidean proximal gradient\nalgorithm. Our contribution is demonstrating the virtues of magnetic mirror\ndescent as both an equilibrium solver and as an approach to reinforcement\nlearning in two-player zero-sum games. These virtues include: 1) Being the\nfirst quantal response equilibria solver to achieve linear convergence for\nextensive-form games with first order feedback; 2) Being the first standard\nreinforcement learning algorithm to achieve empirically competitive results\nwith CFR in tabular settings; 3) Achieving favorable performance in 3x3 Dark\nHex and Phantom Tic-Tac-Toe as a self-play deep reinforcement learning\nalgorithm.\n","authors":["Samuel Sokota","Ryan D'Orazio","J. Zico Kolter","Nicolas Loizou","Marc Lanctot","Ioannis Mitliagkas","Noam Brown","Christian Kroer"],"pdf_url":"https://arxiv.org/pdf/2206.05825v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01429v1","updated":"2023-03-02T17:32:11Z","published":"2023-03-02T17:32:11Z","title":"Optimal transfer protocol by incremental layer defrosting","summary":"  Transfer learning is a powerful tool enabling model training with limited\namounts of data. This technique is particularly useful in real-world problems\nwhere data availability is often a serious limitation. The simplest transfer\nlearning protocol is based on ``freezing\" the feature-extractor layers of a\nnetwork pre-trained on a data-rich source task, and then adapting only the last\nlayers to a data-poor target task. This workflow is based on the assumption\nthat the feature maps of the pre-trained model are qualitatively similar to the\nones that would have been learned with enough data on the target task. In this\nwork, we show that this protocol is often sub-optimal, and the largest\nperformance gain may be achieved when smaller portions of the pre-trained\nnetwork are kept frozen. In particular, we make use of a controlled framework\nto identify the optimal transfer depth, which turns out to depend non-trivially\non the amount of available training data and on the degree of source-target\ntask correlation. We then characterize transfer optimality by analyzing the\ninternal representations of two networks trained from scratch on the source and\nthe target task through multiple established similarity measures.\n","authors":["Federica Gerace","Diego Doimo","Stefano Sarao Mannelli","Luca Saglietti","Alessandro Laio"],"pdf_url":"https://arxiv.org/pdf/2303.01429v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.11870v2","updated":"2023-03-02T17:27:13Z","published":"2022-08-25T04:52:21Z","title":"Fix-A-Step: Semi-supervised Learning from Uncurated Unlabeled Data","summary":"  Semi-supervised learning (SSL) promises improved accuracy compared to\ntraining classifiers on small labeled datasets by also training on many\nunlabeled images. In real applications like medical imaging, unlabeled data\nwill be collected for expediency and thus uncurated: possibly different from\nthe labeled set in classes or features. Unfortunately, modern deep SSL often\nmakes accuracy worse when given uncurated unlabeled data. Recent complex\nremedies try to detect out-of-distribution unlabeled images and then discard or\ndownweight them. Instead, we introduce Fix-A-Step, a simpler procedure that\nviews all uncurated unlabeled images as potentially helpful. Our first insight\nis that even uncurated images can yield useful augmentations of labeled data.\nSecond, we modify gradient descent updates to prevent optimizing a multi-task\nSSL loss from hurting labeled-set accuracy. Fix-A-Step can repair many common\ndeep SSL methods, improving accuracy on CIFAR benchmarks across all tested\nmethods and levels of artificial class mismatch. On a new medical SSL benchmark\ncalled Heart2Heart, Fix-A-Step can learn from 353,500 truly uncurated\nultrasound images to deliver gains that generalize across hospitals.\n","authors":["Zhe Huang","Mary-Joy Sidhom","Benjamin S. Wessler","Michael C. Hughes"],"pdf_url":"https://arxiv.org/pdf/2208.11870v2.pdf","comment":"AISTATS 2023"},{"id":"http://arxiv.org/abs/2205.13303v2","updated":"2023-03-02T17:21:48Z","published":"2022-05-26T12:25:24Z","title":"Gaussian Universality of Perceptrons with Random Labels","summary":"  While classical in many theoretical settings - and in particular in\nstatistical physics-inspired works - the assumption of Gaussian i.i.d. input\ndata is often perceived as a strong limitation in the context of statistics and\nmachine learning. In this study, we redeem this line of work in the case of\ngeneralized linear classification, a.k.a. the perceptron model, with random\nlabels. We argue that there is a large universality class of high-dimensional\ninput data for which we obtain the same minimum training loss as for Gaussian\ndata with corresponding data covariance. In the limit of vanishing\nregularization, we further demonstrate that the training loss is independent of\nthe data covariance. On the theoretical side, we prove this universality for an\narbitrary mixture of homogeneous Gaussian clouds. Empirically, we show that the\nuniversality holds also for a broad range of real datasets.\n","authors":["Federica Gerace","Florent Krzakala","Bruno Loureiro","Ludovic Stephan","Lenka Zdeborová"],"pdf_url":"https://arxiv.org/pdf/2205.13303v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.16966v2","updated":"2023-03-02T17:21:16Z","published":"2022-10-30T22:24:43Z","title":"Interpretable Geometric Deep Learning via Learnable Randomness Injection","summary":"  Point cloud data is ubiquitous in scientific fields. Recently, geometric deep\nlearning (GDL) has been widely applied to solve prediction tasks with such\ndata. However, GDL models are often complicated and hardly interpretable, which\nposes concerns to scientists who are to deploy these models in scientific\nanalysis and experiments. This work proposes a general mechanism, learnable\nrandomness injection (LRI), which allows building inherently interpretable\nmodels based on general GDL backbones. LRI-induced models, once trained, can\ndetect the points in the point cloud data that carry information indicative of\nthe prediction label. We also propose four datasets from real scientific\napplications that cover the domains of high-energy physics and biochemistry to\nevaluate the LRI mechanism. Compared with previous post-hoc interpretation\nmethods, the points detected by LRI align much better and stabler with the\nground-truth patterns that have actual scientific meanings. LRI is grounded by\nthe information bottleneck principle, and thus LRI-induced models are also more\nrobust to distribution shifts between training and test scenarios. Our code and\ndatasets are available at \\url{https://github.com/Graph-COM/LRI}.\n","authors":["Siqi Miao","Yunan Luo","Mia Liu","Pan Li"],"pdf_url":"https://arxiv.org/pdf/2210.16966v2.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01421v1","updated":"2023-03-02T17:15:02Z","published":"2023-03-02T17:15:02Z","title":"Semiparametric Language Models Are Scalable Continual Learners","summary":"  Semiparametric language models (LMs) have shown promise in continuously\nlearning from new text data by combining a parameterized neural LM with a\ngrowable non-parametric memory for memorizing new content. However,\nconventional semiparametric LMs will finally become prohibitive for computing\nand storing if they are applied to continual learning over streaming data,\nbecause the non-parametric memory grows linearly with the amount of data they\nlearn from over time. To address the issue of scalability, we present a simple\nand intuitive approach called Selective Memorization (SeMem), which only\nmemorizes difficult samples that the model is likely to struggle with. We\ndemonstrate that SeMem improves the scalability of semiparametric LMs for\ncontinual learning over streaming data in two ways: (1) data-wise scalability:\nas the model becomes stronger through continual learning, it will encounter\nfewer difficult cases that need to be memorized, causing the growth of the\nnon-parametric memory to slow down over time rather than growing at a linear\nrate with the size of training data; (2) model-wise scalability: SeMem allows a\nlarger model to memorize fewer samples than its smaller counterpart because it\nis rarer for a larger model to encounter incomprehensible cases, resulting in a\nnon-parametric memory that does not scale linearly with model size. We conduct\nextensive experiments in language modeling and downstream tasks to test SeMem's\nresults, showing SeMem enables a semiparametric LM to be a scalable continual\nlearner with little forgetting.\n","authors":["Guangyue Peng","Tao Ge","Si-Qing Chen","Furu Wei","Houfeng Wang"],"pdf_url":"https://arxiv.org/pdf/2303.01421v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2302.03439v4","updated":"2023-03-02T17:04:51Z","published":"2023-02-07T12:51:20Z","title":"Ensemble Value Functions for Efficient Exploration in Multi-Agent\n  Reinforcement Learning","summary":"  Cooperative multi-agent reinforcement learning (MARL) requires agents to\nexplore to learn to cooperate. Existing value-based MARL algorithms commonly\nrely on random exploration, such as $\\epsilon$-greedy, which is inefficient in\ndiscovering multi-agent cooperation. Additionally, the environment in MARL\nappears non-stationary to any individual agent due to the simultaneous training\nof other agents, leading to highly variant and thus unstable optimisation\nsignals. In this work, we propose ensemble value functions for multi-agent\nexploration (EMAX), a general framework to extend any value-based MARL\nalgorithm. EMAX trains ensembles of value functions for each agent to address\nthe key challenges of exploration and non-stationarity: (1) The uncertainty of\nvalue estimates across the ensemble is used in a UCB policy to guide the\nexploration of agents to parts of the environment which require cooperation.\n(2) Average value estimates across the ensemble serve as target values. These\ntargets exhibit lower variance compared to commonly applied target networks and\nwe show that they lead to more stable gradients during the optimisation. We\ninstantiate three value-based MARL algorithms with EMAX, independent DQN, VDN\nand QMIX, and evaluate them in 21 tasks across four environments. Using\nensembles of five value functions, EMAX improves sample efficiency and final\nevaluation returns of these algorithms by 54%, 55%, and 844%, respectively,\naveraged all 21 tasks.\n","authors":["Lukas Schäfer","Oliver Slumbers","Stephen McAleer","Yali Du","Stefano V. Albrecht","David Mguni"],"pdf_url":"https://arxiv.org/pdf/2302.03439v4.pdf","comment":"Preprint. Under review"},{"id":"http://arxiv.org/abs/2303.01412v1","updated":"2023-03-02T17:03:02Z","published":"2023-03-02T17:03:02Z","title":"Hyperparameter Tuning and Model Evaluation in Causal Effect Estimation","summary":"  The performance of most causal effect estimators relies on accurate\npredictions of high-dimensional non-linear functions of the observed data. The\nremarkable flexibility of modern Machine Learning (ML) methods is perfectly\nsuited to this task. However, data-driven hyperparameter tuning of ML methods\nrequires effective model evaluation to avoid large errors in causal estimates,\na task made more challenging because causal inference involves unavailable\ncounterfactuals. Multiple performance-validation metrics have recently been\nproposed such that practitioners now not only have to make complex decisions\nabout which causal estimators, ML learners and hyperparameters to choose, but\nalso about which evaluation metric to use. This paper, motivated by unclear\nrecommendations, investigates the interplay between the four different aspects\nof model evaluation for causal effect estimation. We develop a comprehensive\nexperimental setup that involves many commonly used causal estimators, ML\nmethods and evaluation approaches and apply it to four well-known causal\ninference benchmark datasets. Our results suggest that optimal hyperparameter\ntuning of ML learners is enough to reach state-of-the-art performance in effect\nestimation, regardless of estimators and learners. We conclude that most causal\nestimators are roughly equivalent in performance if tuned thoroughly enough. We\nalso find hyperparameter tuning and model evaluation are much more important\nthan causal estimators and ML methods. Finally, from the significant gap we\nfind in estimation performance of popular evaluation metrics compared with\noptimal model selection choices, we call for more research into causal model\nevaluation to unlock the optimum performance not currently being delivered even\nby state-of-the-art procedures.\n","authors":["Damian Machlanski","Spyridon Samothrakis","Paul Clarke"],"pdf_url":"https://arxiv.org/pdf/2303.01412v1.pdf","comment":"36 pages, 3 figures"},{"id":"http://arxiv.org/abs/2303.01406v1","updated":"2023-03-02T16:53:51Z","published":"2023-03-02T16:53:51Z","title":"Sparse-penalized deep neural networks estimator under weak dependence","summary":"  We consider the nonparametric regression and the classification problems for\n$\\psi$-weakly dependent processes. This weak dependence structure is more\ngeneral than conditions such as, mixing, association, $\\ldots$. A penalized\nestimation method for sparse deep neural networks is performed. In both\nnonparametric regression and binary classification problems, we establish\noracle inequalities for the excess risk of the sparse-penalized deep neural\nnetworks estimators. Convergence rates of the excess risk of these estimators\nare also derived. The simulation results displayed show that, the proposed\nestimators overall work well than the non penalized estimators.\n","authors":["William Kengne","Modou Wade"],"pdf_url":"https://arxiv.org/pdf/2303.01406v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.02830v3","updated":"2023-03-02T16:49:52Z","published":"2023-01-07T11:37:32Z","title":"Advanced Data Augmentation Approaches: A Comprehensive Survey and Future\n  directions","summary":"  Deep learning (DL) algorithms have shown significant performance in various\ncomputer vision tasks. However, having limited labelled data lead to a network\noverfitting problem, where network performance is bad on unseen data as\ncompared to training data. Consequently, it limits performance improvement. To\ncope with this problem, various techniques have been proposed such as dropout,\nnormalization and advanced data augmentation. Among these, data augmentation,\nwhich aims to enlarge the dataset size by including sample diversity, has been\na hot topic in recent times. In this article, we focus on advanced data\naugmentation techniques. we provide a background of data augmentation, a novel\nand comprehensive taxonomy of reviewed data augmentation techniques, and the\nstrengths and weaknesses (wherever possible) of each technique. We also provide\ncomprehensive results of the data augmentation effect on three popular computer\nvision tasks, such as image classification, object detection and semantic\nsegmentation. For results reproducibility, we compiled available codes of all\ndata augmentation techniques. Finally, we discuss the challenges and\ndifficulties, and possible future direction for the research community. We\nbelieve, this survey provides several benefits i) readers will understand the\ndata augmentation working mechanism to fix overfitting problems ii) results\nwill save the searching time of the researcher for comparison purposes. iii)\nCodes of the mentioned data augmentation techniques are available at\nhttps://github.com/kmr2017/Advanced-Data-augmentation-codes iv) Future work\nwill spark interest in research community.\n","authors":["Teerath Kumar","Alessandra Mileo","Rob Brennan","Malika Bendechache"],"pdf_url":"https://arxiv.org/pdf/2301.02830v3.pdf","comment":"We need to make a lot changes to make its quality better"},{"id":"http://arxiv.org/abs/2302.07817v2","updated":"2023-03-02T16:41:45Z","published":"2023-02-15T17:58:10Z","title":"Tri-Perspective View for Vision-Based 3D Semantic Occupancy Prediction","summary":"  Modern methods for vision-centric autonomous driving perception widely adopt\nthe bird's-eye-view (BEV) representation to describe a 3D scene. Despite its\nbetter efficiency than voxel representation, it has difficulty describing the\nfine-grained 3D structure of a scene with a single plane. To address this, we\npropose a tri-perspective view (TPV) representation which accompanies BEV with\ntwo additional perpendicular planes. We model each point in the 3D space by\nsumming its projected features on the three planes. To lift image features to\nthe 3D TPV space, we further propose a transformer-based TPV encoder\n(TPVFormer) to obtain the TPV features effectively. We employ the attention\nmechanism to aggregate the image features corresponding to each query in each\nTPV plane. Experiments show that our model trained with sparse supervision\neffectively predicts the semantic occupancy for all voxels. We demonstrate for\nthe first time that using only camera inputs can achieve comparable performance\nwith LiDAR-based methods on the LiDAR segmentation task on nuScenes. Code:\nhttps://github.com/wzzheng/TPVFormer.\n","authors":["Yuanhui Huang","Wenzhao Zheng","Yunpeng Zhang","Jie Zhou","Jiwen Lu"],"pdf_url":"https://arxiv.org/pdf/2302.07817v2.pdf","comment":"Accepted to CVPR 2023. Code is available at\n  https://github.com/wzzheng/TPVFormer"},{"id":"http://arxiv.org/abs/2303.01391v1","updated":"2023-03-02T16:20:46Z","published":"2023-03-02T16:20:46Z","title":"The Ladder in Chaos: A Simple and Effective Improvement to General DRL\n  Algorithms by Policy Path Trimming and Boosting","summary":"  Knowing the learning dynamics of policy is significant to unveiling the\nmysteries of Reinforcement Learning (RL). It is especially crucial yet\nchallenging to Deep RL, from which the remedies to notorious issues like sample\ninefficiency and learning instability could be obtained. In this paper, we\nstudy how the policy networks of typical DRL agents evolve during the learning\nprocess by empirically investigating several kinds of temporal change for each\npolicy parameter. On typical MuJoCo and DeepMind Control Suite (DMC)\nbenchmarks, we find common phenomena for TD3 and RAD agents: 1) the activity of\npolicy network parameters is highly asymmetric and policy networks advance\nmonotonically along very few major parameter directions; 2) severe detours\noccur in parameter update and harmonic-like changes are observed for all minor\nparameter directions. By performing a novel temporal SVD along policy learning\npath, the major and minor parameter directions are identified as the columns of\nright unitary matrix associated with dominant and insignificant singular values\nrespectively. Driven by the discoveries above, we propose a simple and\neffective method, called Policy Path Trimming and Boosting (PPTB), as a general\nplug-in improvement to DRL algorithms. The key idea of PPTB is to periodically\ntrim the policy learning path by canceling the policy updates in minor\nparameter directions, while boost the learning path by encouraging the advance\nin major directions. In experiments, we demonstrate the general and significant\nperformance improvements brought by PPTB, when combined with TD3 and RAD in\nMuJoCo and DMC environments respectively.\n","authors":["Hongyao Tang","Min Zhang","Jianye Hao"],"pdf_url":"https://arxiv.org/pdf/2303.01391v1.pdf","comment":"Rudimentary version. Work in progress"},{"id":"http://arxiv.org/abs/2303.01389v1","updated":"2023-03-02T16:19:24Z","published":"2023-03-02T16:19:24Z","title":"Machine Learning-Based Detection of Parkinson's Disease From\n  Resting-State EEG: A Multi-Center Study","summary":"  Resting-state EEG (rs-EEG) has been demonstrated to aid in Parkinson's\ndisease (PD) diagnosis. In particular, the power spectral density (PSD) of\nlow-frequency bands ({\\delta} and {\\theta}) and high-frequency bands ({\\alpha}\nand \\b{eta}) has been shown to be significantly different in patients with PD\nas compared to subjects without PD (non-PD). However, rs-EEG feature extraction\nand the interpretation thereof can be time-intensive and prone to examiner\nvariability. Machine learning (ML) has the potential to automatize the analysis\nof rs-EEG recordings and provides a supportive tool for clinicians to ease\ntheir workload. In this work, we use rs-EEG recordings of 84 PD and 85 non-PD\nsubjects pooled from four datasets obtained at different centers. We propose an\nend-to-end pipeline consisting of preprocessing, extraction of PSD features\nfrom clinically validated frequency bands, and feature selection before\nevaluating the classification ability of the features via ML algorithms to\nstratify between PD and non-PD subjects. Further, we evaluate the effect of\nfeature harmonization, given the multi-center nature of the datasets. Our\nvalidation results show, on average, an improvement in PD detection ability\n(69.6% vs. 75.5% accuracy) by logistic regression when harmonizing the features\nand performing univariate feature selection (k = 202 features). Our final\nresults show an average global accuracy of 72.2% with balanced accuracy results\nfor all the centers included in the study: 60.6%, 68.7%, 77.7%, and 82.2%,\nrespectively.\n","authors":["Anna Kurbatskaya","Alberto Jaramillo-Jimenez","John Fredy Ochoa-Gomez","Kolbjørn Brønnick","Alvaro Fernandez-Quilez"],"pdf_url":"https://arxiv.org/pdf/2303.01389v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01388v1","updated":"2023-03-02T16:18:00Z","published":"2023-03-02T16:18:00Z","title":"Reinforced Labels: Multi-Agent Deep Reinforcement Learning for\n  Point-feature Label Placement","summary":"  Over the past few years, Reinforcement Learning combined with Deep Learning\ntechniques has successfully proven to solve complex problems in various domains\nincluding robotics, self-driving cars, finance, and gaming. In this paper, we\nare introducing Reinforcement Learning (RL) to another domain - visualization.\nOur novel point-feature label placement method utilizes Multi-Agent Deep\nReinforcement Learning (MADRL) to learn label placement strategy, which is the\nfirst machine-learning-driven labeling method in contrast to existing\nhand-crafted algorithms designed by human experts. To facilitate the RL\nlearning paradigm, we developed an environment where an agent acts as a proxy\nfor a label, a short textual annotation that augments visualizations like\ngeographical maps, illustrations, and technical drawings. Our results\ndemonstrate that the strategy trained by our method significantly outperforms\nthe random strategy of an untrained agent and also performs superior to the\ncompared methods designed by human experts in terms of completeness (i.e., the\nnumber of placed labels). The trade-off is increased computation time, making\nthe proposed method slower than compared methods. Nevertheless, our method is\nideal for situations where the labeling can be computed in advance, and\ncompleteness is essential, such as cartographic maps, technical drawings, and\nmedical atlases. Additionally, we conducted a user study to assess the\nperceived performance. The outcomes revealed that the participants considered\nthe proposed method to be significantly better than the other examined methods.\nThis indicates that the improved completeness is not just reflected in the\nquantitative metrics but also in the subjective evaluation of the participants.\n","authors":["Petr Bobák","Ladislav Čmolík","Martin Čadík"],"pdf_url":"https://arxiv.org/pdf/2303.01388v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01384v1","updated":"2023-03-02T16:08:23Z","published":"2023-03-02T16:08:23Z","title":"DAVA: Disentangling Adversarial Variational Autoencoder","summary":"  The use of well-disentangled representations offers many advantages for\ndownstream tasks, e.g. an increased sample efficiency, or better\ninterpretability. However, the quality of disentangled interpretations is often\nhighly dependent on the choice of dataset-specific hyperparameters, in\nparticular the regularization strength. To address this issue, we introduce\nDAVA, a novel training procedure for variational auto-encoders. DAVA completely\nalleviates the problem of hyperparameter selection. We compare DAVA to models\nwith optimal hyperparameters. Without any hyperparameter tuning, DAVA is\ncompetitive on a diverse range of commonly used datasets. Underlying DAVA, we\ndiscover a necessary condition for unsupervised disentanglement, which we call\nPIPE. We demonstrate the ability of PIPE to positively predict the performance\nof downstream models in abstract reasoning. We also thoroughly investigate\ncorrelations with existing supervised and unsupervised metrics. The code is\navailable at https://github.com/besterma/dava.\n","authors":["Benjamin Estermann","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2303.01384v1.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01378v1","updated":"2023-03-02T16:03:12Z","published":"2023-03-02T16:03:12Z","title":"A Vision for Semantically Enriched Data Science","summary":"  The recent efforts in automation of machine learning or data science has\nachieved success in various tasks such as hyper-parameter optimization or model\nselection. However, key areas such as utilizing domain knowledge and data\nsemantics are areas where we have seen little automation. Data Scientists have\nlong leveraged common sense reasoning and domain knowledge to understand and\nenrich data for building predictive models. In this paper we discuss important\nshortcomings of current data science and machine learning solutions. We then\nenvision how leveraging \"semantic\" understanding and reasoning on data in\ncombination with novel tools for data science automation can help with\nconsistent and explainable data augmentation and transformation. Additionally,\nwe discuss how semantics can assist data scientists in a new manner by helping\nwith challenges related to trust, bias, and explainability in machine learning.\nSemantic annotation can also help better explore and organize large data\nsources.\n","authors":["Udayan Khurana","Kavitha Srinivas","Sainyam Galhotra","Horst Samulowitz"],"pdf_url":"https://arxiv.org/pdf/2303.01378v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2205.08018"},{"id":"http://arxiv.org/abs/2303.01377v1","updated":"2023-03-02T16:02:55Z","published":"2023-03-02T16:02:55Z","title":"BEL: A Bag Embedding Loss for Transformer enhances Multiple Instance\n  Whole Slide Image Classification","summary":"  Multiple Instance Learning (MIL) has become the predominant approach for\nclassification tasks on gigapixel histopathology whole slide images (WSIs).\nWithin the MIL framework, single WSIs (bags) are decomposed into patches\n(instances), with only WSI-level annotation available. Recent MIL approaches\nproduce highly informative bag level representations by utilizing the\ntransformer architecture's ability to model the dependencies between instances.\nHowever, when applied to high magnification datasets, problems emerge due to\nthe large number of instances and the weak supervisory learning signal. To\naddress this problem, we propose to additionally train transformers with a\nnovel Bag Embedding Loss (BEL). BEL forces the model to learn a discriminative\nbag-level representation by minimizing the distance between bag embeddings of\nthe same class and maximizing the distance between different classes. We\nevaluate BEL with the Transformer architecture TransMIL on two publicly\navailable histopathology datasets, BRACS and CAMELYON17. We show that with BEL,\nTransMIL outperforms the baseline models on both datasets, thus contributing to\nthe clinically highly relevant AI-based tumor classification of histological\npatient material.\n","authors":["Daniel Sens","Ario Sadafi","Francesco Paolo Casale","Nassir Navab","Carsten Marr"],"pdf_url":"https://arxiv.org/pdf/2303.01377v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01372v1","updated":"2023-03-02T15:58:09Z","published":"2023-03-02T15:58:09Z","title":"High-dimensional analysis of double descent for linear regression with\n  random projections","summary":"  We consider linear regression problems with a varying number of random\nprojections, where we provably exhibit a double descent curve for a fixed\nprediction problem, with a high-dimensional analysis based on random matrix\ntheory. We first consider the ridge regression estimator and re-interpret\nearlier results using classical notions from non-parametric statistics, namely\ndegrees of freedom, also known as effective dimensionality. In particular, we\nshow that the random design performance of ridge regression with a specific\nregularization parameter matches the classical bias and variance expressions\ncoming from the easier fixed design analysis but for another larger implicit\nregularization parameter. We then compute asymptotic equivalents of the\ngeneralization performance (in terms of bias and variance) of the minimum norm\nleast-squares fit with random projections, providing simple expressions for the\ndouble descent phenomenon.\n","authors":["Francis Bach"],"pdf_url":"https://arxiv.org/pdf/2303.01372v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.10314v6","updated":"2023-03-02T15:56:26Z","published":"2021-07-21T19:23:56Z","title":"Small-Text: Active Learning for Text Classification in Python","summary":"  We introduce small-text, an easy-to-use active learning library, which offers\npool-based active learning for single- and multi-label text classification in\nPython. It features numerous pre-implemented state-of-the-art query strategies,\nincluding some that leverage the GPU. Standardized interfaces allow the\ncombination of a variety of classifiers, query strategies, and stopping\ncriteria, facilitating a quick mix and match, and enabling a rapid and\nconvenient development of both active learning experiments and applications.\nWith the objective of making various classifiers and query strategies\naccessible for active learning, small-text integrates several well-known\nmachine learning libraries, namely scikit-learn, PyTorch, and Hugging Face\ntransformers. The latter integrations are optionally installable extensions, so\nGPUs can be used but are not required. Using this new library, we investigate\nthe performance of the recently published SetFit training paradigm, which we\ncompare to vanilla transformer fine-tuning, finding that it matches the latter\nin classification accuracy while outperforming it in area under the curve. The\nlibrary is available under the MIT License at\nhttps://github.com/webis-de/small-text, in version 1.3.0 at the time of\nwriting.\n","authors":["Christopher Schröder","Lydia Müller","Andreas Niekler","Martin Potthast"],"pdf_url":"https://arxiv.org/pdf/2107.10314v6.pdf","comment":"EACL 2023 System Demonstrations (camera-ready)"},{"id":"http://arxiv.org/abs/2203.08089v3","updated":"2023-03-02T15:53:20Z","published":"2022-03-15T17:18:48Z","title":"On Suspicious Coincidences and Pointwise Mutual Information","summary":"  Barlow (1985) hypothesized that the co-occurrence of two events $A$ and $B$\nis \"suspicious\" if $P(A,B) \\gg P(A) P(B)$. We first review classical measures\nof association for $2 \\times 2$ contingency tables, including Yule's $Y$ (Yule,\n1912), which depends only on the odds ratio $\\lambda$, and is independent of\nthe marginal probabilities of the table. We then discuss the mutual information\n(MI) and pointwise mutual information (PMI), which depend on the ratio\n$P(A,B)/P(A)P(B)$, as measures of association. We show that, once the effect of\nthe marginals is removed, MI and PMI behave similarly to $Y$ as functions of\n$\\lambda$. The pointwise mutual information is used extensively in some\nresearch communities for flagging suspicious coincidences, but it is important\nto bear in mind the sensitivity of the PMI to the marginals, with increased\nscores for sparser events.\n","authors":["Christopher K. I. Williams"],"pdf_url":"https://arxiv.org/pdf/2203.08089v3.pdf","comment":"9 pages, 1 figure. Addendum added March 2023"},{"id":"http://arxiv.org/abs/2302.01518v2","updated":"2023-03-02T15:36:08Z","published":"2023-02-03T03:26:08Z","title":"LSA-PINN: Linear Boundary Connectivity Loss for Solving PDEs on Complex\n  Geometry","summary":"  We present a novel loss formulation for efficient learning of complex\ndynamics from governing physics, typically described by partial differential\nequations (PDEs), using physics-informed neural networks (PINNs). In our\nexperiments, existing versions of PINNs are seen to learn poorly in many\nproblems, especially for complex geometries, as it becomes increasingly\ndifficult to establish appropriate sampling strategy at the near boundary\nregion. Overly dense sampling can adversely impede training convergence if the\nlocal gradient behaviors are too complex to be adequately modelled by PINNs. On\nthe other hand, if the samples are too sparse, existing PINNs tend to overfit\nthe near boundary region, leading to incorrect solution. To prevent such\nissues, we propose a new Boundary Connectivity (BCXN) loss function which\nprovides linear local structure approximation (LSA) to the gradient behaviors\nat the boundary for PINN. Our BCXN-loss implicitly imposes local structure\nduring training, thus facilitating fast physics-informed learning across entire\nproblem domains with order of magnitude sparser training samples. This LSA-PINN\nmethod shows a few orders of magnitude smaller errors than existing methods in\nterms of the standard L2-norm metric, while using dramatically fewer training\nsamples and iterations. Our proposed LSA-PINN does not pose any requirement on\nthe differentiable property of the networks, and we demonstrate its benefits\nand ease of implementation on both multi-layer perceptron and convolutional\nneural network versions as commonly used in current PINN literature.\n","authors":["Jian Cheng Wong","Pao-Hsiung Chiu","Chinchun Ooi","My Ha Dao","Yew-Soon Ong"],"pdf_url":"https://arxiv.org/pdf/2302.01518v2.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2303.01353v1","updated":"2023-03-02T15:33:18Z","published":"2023-03-02T15:33:18Z","title":"Penalising the biases in norm regularisation enforces sparsity","summary":"  Controlling the parameters' norm often yields good generalisation when\ntraining neural networks. Beyond simple intuitions, the relation between\nparameters' norm and obtained estimators theoretically remains misunderstood.\nFor one hidden ReLU layer networks with unidimensional data, this work shows\nthe minimal parameters' norm required to represent a function is given by the\ntotal variation of its second derivative, weighted by a $\\sqrt{1+x^2}$ factor.\nAs a comparison, this $\\sqrt{1+x^2}$ weighting disappears when the norm of the\nbias terms are ignored. This additional weighting is of crucial importance,\nsince it is shown in this work to enforce uniqueness and sparsity (in number of\nkinks) of the minimal norm interpolator. On the other hand, omitting the bias'\nnorm allows for non-sparse solutions. Penalising the bias terms in the\nregularisation, either explicitly or implicitly, thus leads to sparse\nestimators. This sparsity might take part in the good generalisation of neural\nnetworks that is empirically observed.\n","authors":["Etienne Boursier","Nicolas Flammarion"],"pdf_url":"https://arxiv.org/pdf/2303.01353v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.07624v2","updated":"2023-03-02T15:33:06Z","published":"2022-12-15T05:54:16Z","title":"Neuroevolution Surpasses Stochastic Gradient Descent for\n  Physics-Informed Neural Networks","summary":"  The potential of learned models for fundamental scientific research and\ndiscovery is drawing increasing attention. Physics-informed neural networks\n(PINNs), where the loss function directly embeds governing equations of\nscientific phenomena, is one of the key techniques at the forefront of recent\nadvances. These models are typically trained using stochastic gradient descent,\nakin to their standard deep learning counterparts. However, in this paper, we\ncarry out a simple analysis showing that the loss functions arising in PINNs\nlead to a high degree of complexity and ruggedness that may not be conducive\nfor gradient-descent and its variants. It is therefore clear that the use of\nneuro-evolutionary algorithms as alternatives to gradient descent for PINNs may\nbe a better choice. Our claim is strongly supported herein by benchmark\nproblems and baseline results demonstrating that convergence rates achieved by\nneuroevolution can indeed surpass that of gradient descent for PINN training.\nFurthermore, implementing neuroevolution with JAX leads to orders of magnitude\nspeedup relative to standard implementations.\n","authors":["Nicholas Sung Wei Yong","Jian Cheng Wong","Pao-Hsiung Chiu","Abhishek Gupta","Chinchun Ooi","Yew-Soon Ong"],"pdf_url":"https://arxiv.org/pdf/2212.07624v2.pdf","comment":"10 pages, 9 figures, 5 tables"},{"id":"http://arxiv.org/abs/2303.01346v1","updated":"2023-03-02T15:24:24Z","published":"2023-03-02T15:24:24Z","title":"Co-learning Planning and Control Policies Using Differentiable Formal\n  Task Constraints","summary":"  This paper presents a hierarchical reinforcement learning algorithm\nconstrained by differentiable signal temporal logic. Previous work on\nlogic-constrained reinforcement learning consider encoding these constraints\nwith a reward function, constraining policy updates with a sample-based policy\ngradient. However, such techniques oftentimes tend to be inefficient because of\nthe significant number of samples required to obtain accurate policy gradients.\nIn this paper, instead of implicitly constraining policy search with\nsample-based policy gradients, we directly constrain policy search by\nbackpropagating through formal constraints, enabling training hierarchical\npolicies with substantially fewer training samples. The use of hierarchical\npolicies is recognized as a crucial component of reinforcement learning with\ntask constraints. We show that we can stably constrain policy updates, thus\nenabling different levels of the policy to be learned simultaneously, yielding\nsuperior performance compared with training them separately. Experiment results\non several simulated high-dimensional robot dynamics and a real-world\ndifferential drive robot (TurtleBot3) demonstrate the effectiveness of our\napproach on five different types of task constraints. Demo videos, code, and\nmodels can be found at our project website: https://sites.google.com/view/dscrl\n","authors":["Zikang Xiong","Joe Eappen","Daniel Lawson","Ahmed H. Qureshi","Suresh Jagannathan"],"pdf_url":"https://arxiv.org/pdf/2303.01346v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01335v1","updated":"2023-03-02T15:13:37Z","published":"2023-03-02T15:13:37Z","title":"Model agnostic methods meta-learn despite misspecifications","summary":"  Due to its empirical success on few shot classification and reinforcement\nlearning, meta-learning recently received a lot of interest. Meta-learning\nleverages data from previous tasks to quickly learn a new task, despite limited\ndata. In particular, model agnostic methods look for initialisation points from\nwhich gradient descent quickly adapts to any new task. Although it has been\nempirically suggested that such methods learn a good shared representation\nduring training, there is no strong theoretical evidence of such behavior. More\nimportantly, it is unclear whether these methods truly are model agnostic,\ni.e., whether they still learn a shared structure despite architecture\nmisspecifications. To fill this gap, this work shows in the limit of an\ninfinite number of tasks that first order ANIL with a linear two-layer network\narchitecture successfully learns a linear shared representation. Moreover, this\nresult holds despite misspecifications: having a large width with respect to\nthe hidden dimension of the shared representation does not harm the algorithm\nperformance. The learnt parameters then allow to get a small test loss after a\nsingle gradient step on any new task. Overall this illustrates how well model\nagnostic methods can adapt to any (unknown) model structure.\n","authors":["Oguz Yuksel","Etienne Boursier","Nicolas Flammarion"],"pdf_url":"https://arxiv.org/pdf/2303.01335v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.07254v2","updated":"2023-03-02T15:10:12Z","published":"2022-11-14T10:32:51Z","title":"The Role of Local Alignment and Uniformity in Image-Text Contrastive\n  Learning on Medical Images","summary":"  Image-text contrastive learning has proven effective for pretraining medical\nimage models. When targeting localized downstream tasks like semantic\nsegmentation or object detection, additional local contrastive losses that\nalign image regions with sentences have shown promising results. We study how\nlocal contrastive losses are related to global (per-sample) contrastive losses\nand which effects they have on localized medical downstream tasks. Based on a\ntheoretical comparison, we propose to remove some components of local losses\nand replace others by a novel distribution prior which enforces uniformity of\nrepresentations within each sample. We empirically study this approach on chest\nX-ray tasks and find it to be very effective, outperforming methods without\nlocal losses on 12 of 18 tasks.\n","authors":["Philip Müller","Georgios Kaissis","Daniel Rueckert"],"pdf_url":"https://arxiv.org/pdf/2211.07254v2.pdf","comment":"NeurIPS 2022 Workshop: Self-Supervised Learning - Theory and Practice\n  (Reason for updated version: correction of a typo in Eq. (2) and (3))"},{"id":"http://arxiv.org/abs/2303.01332v1","updated":"2023-03-02T15:10:08Z","published":"2023-03-02T15:10:08Z","title":"Self-Supervised Few-Shot Learning for Ischemic Stroke Lesion\n  Segmentation","summary":"  Precise ischemic lesion segmentation plays an essential role in improving\ndiagnosis and treatment planning for ischemic stroke, one of the prevalent\ndiseases with the highest mortality rate. While numerous deep neural network\napproaches have recently been proposed to tackle this problem, these methods\nrequire large amounts of annotated regions during training, which can be\nimpractical in the medical domain where annotated data is scarce. As a remedy,\nwe present a prototypical few-shot segmentation approach for ischemic lesion\nsegmentation using only one annotated sample during training. The proposed\napproach leverages a novel self-supervised training mechanism that is tailored\nto the task of ischemic stroke lesion segmentation by exploiting color-coded\nparametric maps generated from Computed Tomography Perfusion scans. We\nillustrate the benefits of our proposed training mechanism, leading to\nconsiderable improvements in performance in the few-shot setting. Given a\nsingle annotated patient, an average Dice score of 0.58 is achieved for the\nsegmentation of ischemic lesions.\n","authors":["Luca Tomasetti","Stine Hansen","Mahdieh Khanmohammadi","Kjersti Engan","Liv Jorunn Høllesli","Kathinka Dæhli Kurz","Michael Kampffmeyer"],"pdf_url":"https://arxiv.org/pdf/2303.01332v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01331v1","updated":"2023-03-02T15:09:25Z","published":"2023-03-02T15:09:25Z","title":"Canonical mapping as a general-purpose object descriptor for robotic\n  manipulation","summary":"  Perception is an essential part of robotic manipulation in a semi-structured\nenvironment. Traditional approaches produce a narrow task-specific prediction\n(e.g., object's 6D pose), that cannot be adapted to other tasks and is\nill-suited for deformable objects. In this paper, we propose using canonical\nmapping as a near-universal and flexible object descriptor. We demonstrate that\ncommon object representations can be derived from a single pre-trained\ncanonical mapping model, which in turn can be generated with minimal manual\neffort using an automated data generation and training pipeline. We perform a\nmulti-stage experiment using two robot arms that demonstrate the robustness of\nthe perception approach and the ways it can inform the manipulation strategy,\nthus serving as a powerful foundation for general-purpose robotic manipulation.\n","authors":["Benjamin Joffe","Konrad Ahlin"],"pdf_url":"https://arxiv.org/pdf/2303.01331v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.07027v2","updated":"2023-03-02T14:49:06Z","published":"2022-07-14T15:59:03Z","title":"MedFuse: Multi-modal fusion with clinical time-series data and chest\n  X-ray images","summary":"  Multi-modal fusion approaches aim to integrate information from different\ndata sources. Unlike natural datasets, such as in audio-visual applications,\nwhere samples consist of \"paired\" modalities, data in healthcare is often\ncollected asynchronously. Hence, requiring the presence of all modalities for a\ngiven sample is not realistic for clinical tasks and significantly limits the\nsize of the dataset during training. In this paper, we propose MedFuse, a\nconceptually simple yet promising LSTM-based fusion module that can accommodate\nuni-modal as well as multi-modal input. We evaluate the fusion method and\nintroduce new benchmark results for in-hospital mortality prediction and\nphenotype classification, using clinical time-series data in the MIMIC-IV\ndataset and corresponding chest X-ray images in MIMIC-CXR. Compared to more\ncomplex multi-modal fusion strategies, MedFuse provides a performance\nimprovement by a large margin on the fully paired test set. It also remains\nrobust across the partially paired test set containing samples with missing\nchest X-ray images. We release our code for reproducibility and to enable the\nevaluation of competing models in the future.\n","authors":["Nasir Hayat","Krzysztof J. Geras","Farah E. Shamout"],"pdf_url":"https://arxiv.org/pdf/2207.07027v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.10313v2","updated":"2023-03-02T14:47:43Z","published":"2021-12-20T03:06:08Z","title":"Semi-Decentralized Federated Edge Learning with Data and Device\n  Heterogeneity","summary":"  Federated edge learning (FEEL) has attracted much attention as a\nprivacy-preserving paradigm to effectively incorporate the distributed data at\nthe network edge for training deep learning models. Nevertheless, the limited\ncoverage of a single edge server results in an insufficient number of\nparticipated client nodes, which may impair the learning performance. In this\npaper, we investigate a novel framework of FEEL, namely semi-decentralized\nfederated edge learning (SD-FEEL), where multiple edge servers are employed to\ncollectively coordinate a large number of client nodes. By exploiting the\nlow-latency communication among edge servers for efficient model sharing,\nSD-FEEL can incorporate more training data, while enjoying much lower latency\ncompared with conventional federated learning. We detail the training algorithm\nfor SD-FEEL with three main steps, including local model update, intra-cluster,\nand inter-cluster model aggregations. The convergence of this algorithm is\nproved on non-independent and identically distributed (non-IID) data, which\nalso helps to reveal the effects of key parameters on the training efficiency\nand provides practical design guidelines. Meanwhile, the heterogeneity of edge\ndevices may cause the straggler effect and deteriorate the convergence speed of\nSD-FEEL. To resolve this issue, we propose an asynchronous training algorithm\nwith a staleness-aware aggregation scheme for SD-FEEL, of which, the\nconvergence performance is also analyzed. The simulation results demonstrate\nthe effectiveness and efficiency of the proposed algorithms for SD-FEEL and\ncorroborate our analysis.\n","authors":["Yuchang Sun","Jiawei Shao","Yuyi Mao","Jessie Hui Wang","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2112.10313v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.11602v2","updated":"2023-03-02T14:42:41Z","published":"2021-12-22T01:04:50Z","title":"Identifying Mixtures of Bayesian Network Distributions","summary":"  A Bayesian Network is a directed acyclic graph (DAG) on a set of $n$ random\nvariables (the vertices); a Bayesian Network Distribution (BND) is a\nprobability distribution on the random variables that is Markovian on the\ngraph. A finite $k$-mixture of such models is graphically represented by a\nlarger graph which has an additional ``hidden'' (or ``latent'') random variable\n$U$, ranging in $\\{1,\\ldots,k\\}$, and a directed edge from $U$ to every other\nvertex. Models of this type are fundamental to causal inference, where $U$\nmodels an unobserved confounding effect of multiple populations, obscuring the\ncausal relationships in the observable DAG. By solving the mixture problem and\nrecovering the joint probability distribution on $U$, traditionally\nunidentifiable causal relationships become identifiable. Using a reduction to\nthe more well-studied ``product'' case on empty graphs, we give the first\nalgorithm to learn mixtures of non-empty DAGs.\n","authors":["Spencer L. Gordon","Bijan Mazaheri","Yuval Rabani","Leonard J. Schulman"],"pdf_url":"https://arxiv.org/pdf/2112.11602v2.pdf","comment":"Paper accepted and to appear in CLEAR 2023"},{"id":"http://arxiv.org/abs/2205.15434v4","updated":"2023-03-02T14:39:09Z","published":"2022-05-30T21:20:30Z","title":"A Game-Theoretic Framework for Managing Risk in Multi-Agent Systems","summary":"  In order for agents in multi-agent systems (MAS) to be safe, they need to\ntake into account the risks posed by the actions of other agents. However, the\ndominant paradigm in game theory (GT) assumes that agents are not affected by\nrisk from other agents and only strive to maximise their expected utility. For\nexample, in hybrid human-AI driving systems, it is necessary to limit large\ndeviations in reward resulting from car crashes. Although there are equilibrium\nconcepts in game theory that take into account risk aversion, they either\nassume that agents are risk-neutral with respect to the uncertainty caused by\nthe actions of other agents, or they are not guaranteed to exist. We introduce\na new GT-based Risk-Averse Equilibrium (RAE) that always produces a solution\nthat minimises the potential variance in reward accounting for the strategy of\nother agents. Theoretically and empirically, we show RAE shares many properties\nwith a Nash Equilibrium (NE), establishing convergence properties and\ngeneralising to risk-dominant NE in certain cases. To tackle large-scale\nproblems, we extend RAE to the PSRO multi-agent reinforcement learning (MARL)\nframework. We empirically demonstrate the minimum reward variance benefits of\nRAE in matrix games with high-risk outcomes. Results on MARL experiments show\nRAE generalises to risk-dominant NE in a trust dilemma game and that it reduces\ninstances of crashing by 7x in an autonomous driving setting versus the best\nperforming baseline.\n","authors":["Oliver Slumbers","David Henry Mguni","Stephen Marcus McAleer","Stefano B. Blumberg","Jun Wang","Yaodong Yang"],"pdf_url":"https://arxiv.org/pdf/2205.15434v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.13180v3","updated":"2023-03-02T14:31:28Z","published":"2021-11-25T17:22:22Z","title":"Variational Gibbs inference for statistical model estimation from\n  incomplete data","summary":"  Statistical models are central to machine learning with broad applicability\nacross a range of downstream tasks. The models are controlled by free\nparameters that are typically estimated from data by maximum-likelihood\nestimation or approximations thereof. However, when faced with real-world\ndatasets many of the models run into a critical issue: they are formulated in\nterms of fully-observed data, whereas in practice the datasets are plagued with\nmissing data. The theory of statistical model estimation from incomplete data\nis conceptually similar to the estimation of latent-variable models, where\npowerful tools such as variational inference (VI) exist. However, in contrast\nto standard latent-variable models, parameter estimation with incomplete data\noften requires estimating exponentially-many conditional distributions of the\nmissing variables, hence making standard VI methods intractable. We address\nthis gap by introducing variational Gibbs inference (VGI), a new\ngeneral-purpose method to estimate the parameters of statistical models from\nincomplete data. We validate VGI on a set of synthetic and real-world\nestimation tasks, estimating important machine learning models such as VAEs and\nnormalising flows from incomplete data. The proposed method, whilst\ngeneral-purpose, achieves competitive or better performance than existing\nmodel-specific estimation methods.\n","authors":["Vaidotas Simkus","Benjamin Rhodes","Michael U. Gutmann"],"pdf_url":"https://arxiv.org/pdf/2111.13180v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01297v1","updated":"2023-03-02T14:23:27Z","published":"2023-03-02T14:23:27Z","title":"Creating Synthetic Datasets for Collaborative Filtering Recommender\n  Systems using Generative Adversarial Networks","summary":"  Research and education in machine learning needs diverse, representative, and\nopen datasets that contain sufficient samples to handle the necessary training,\nvalidation, and testing tasks. Currently, the Recommender Systems area includes\na large number of subfields in which accuracy and beyond accuracy quality\nmeasures are continuously improved. To feed this research variety, it is\nnecessary and convenient to reinforce the existing datasets with synthetic\nones. This paper proposes a Generative Adversarial Network (GAN)-based method\nto generate collaborative filtering datasets in a parameterized way, by\nselecting their preferred number of users, items, samples, and stochastic\nvariability. This parameterization cannot be made using regular GANs. Our GAN\nmodel is fed with dense, short, and continuous embedding representations of\nitems and users, instead of sparse, large, and discrete vectors, to make an\naccurate and quick learning, compared to the traditional approach based on\nlarge and sparse input vectors. The proposed architecture includes a DeepMF\nmodel to extract the dense user and item embeddings, as well as a clustering\nprocess to convert from the dense GAN generated samples to the discrete and\nsparse ones, necessary to create each required synthetic dataset. The results\nof three different source datasets show adequate distributions and expected\nquality values and evolutions on the generated datasets compared to the source\nones. Synthetic datasets and source codes are available to researchers.\n","authors":["Jesús Bobadilla","Abraham Gutiérrez","Raciel Yera","Luis Martínez"],"pdf_url":"https://arxiv.org/pdf/2303.01297v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01295v1","updated":"2023-03-02T14:21:54Z","published":"2023-03-02T14:21:54Z","title":"Iterative Assessment and Improvement of DNN Operational Accuracy","summary":"  Deep Neural Networks (DNN) are nowadays largely adopted in many application\ndomains thanks to their human-like, or even superhuman, performance in specific\ntasks. However, due to unpredictable/unconsidered operating conditions,\nunexpected failures show up on field, making the performance of a DNN in\noperation very different from the one estimated prior to release. In the life\ncycle of DNN systems, the assessment of accuracy is typically addressed in two\nways: offline, via sampling of operational inputs, or online, via\npseudo-oracles. The former is considered more expensive due to the need for\nmanual labeling of the sampled inputs. The latter is automatic but less\naccurate. We believe that emerging iterative industrial-strength life cycle\nmodels for Machine Learning systems, like MLOps, offer the possibility to\nleverage inputs observed in operation not only to provide faithful estimates of\na DNN accuracy, but also to improve it through remodeling/retraining actions.\nWe propose DAIC (DNN Assessment and Improvement Cycle), an approach which\ncombines ''low-cost'' online pseudo-oracles and ''high-cost'' offline sampling\ntechniques to estimate and improve the operational accuracy of a DNN in the\niterations of its life cycle. Preliminary results show the benefits of\ncombining the two approaches and integrating them in the DNN life cycle.\n","authors":["Antonio Guerriero","Roberto Pietrantuono","Stefano Russo"],"pdf_url":"https://arxiv.org/pdf/2303.01295v1.pdf","comment":"Paper accepted at 45th International Conference on Software\n  Engineering (ICSE'23 NIER), May 2023"},{"id":"http://arxiv.org/abs/2303.01289v1","updated":"2023-03-02T14:11:54Z","published":"2023-03-02T14:11:54Z","title":"Rethinking the Effect of Data Augmentation in Adversarial Contrastive\n  Learning","summary":"  Recent works have shown that self-supervised learning can achieve remarkable\nrobustness when integrated with adversarial training (AT). However, the\nrobustness gap between supervised AT (sup-AT) and self-supervised AT (self-AT)\nremains significant. Motivated by this observation, we revisit existing self-AT\nmethods and discover an inherent dilemma that affects self-AT robustness:\neither strong or weak data augmentations are harmful to self-AT, and a medium\nstrength is insufficient to bridge the gap. To resolve this dilemma, we propose\na simple remedy named DYNACL (Dynamic Adversarial Contrastive Learning). In\nparticular, we propose an augmentation schedule that gradually anneals from a\nstrong augmentation to a weak one to benefit from both extreme cases. Besides,\nwe adopt a fast post-processing stage for adapting it to downstream tasks.\nThrough extensive experiments, we show that DYNACL can improve state-of-the-art\nself-AT robustness by 8.84% under Auto-Attack on the CIFAR-10 dataset, and can\neven outperform vanilla supervised adversarial training for the first time. Our\ncode is available at \\url{https://github.com/PKU-ML/DYNACL}.\n","authors":["Rundong Luo","Yifei Wang","Yisen Wang"],"pdf_url":"https://arxiv.org/pdf/2303.01289v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2205.14589v2","updated":"2023-03-02T14:10:40Z","published":"2022-05-29T07:32:00Z","title":"Masked Distillation with Receptive Tokens","summary":"  Distilling from the feature maps can be fairly effective for dense prediction\ntasks since both the feature discriminability and localization priors can be\nwell transferred. However, not every pixel contributes equally to the\nperformance, and a good student should learn from what really matters to the\nteacher. In this paper, we introduce a learnable embedding dubbed receptive\ntoken to localize those pixels of interests (PoIs) in the feature map, with a\ndistillation mask generated via pixel-wise attention. Then the distillation\nwill be performed on the mask via pixel-wise reconstruction. In this way, a\ndistillation mask actually indicates a pattern of pixel dependencies within\nfeature maps of teacher. We thus adopt multiple receptive tokens to investigate\nmore sophisticated and informative pixel dependencies to further enhance the\ndistillation. To obtain a group of masks, the receptive tokens are learned via\nthe regular task loss but with teacher fixed, and we also leverage a Dice loss\nto enrich the diversity of learned masks. Our method dubbed MasKD is simple and\npractical, and needs no priors of tasks in application. Experiments show that\nour MasKD can achieve state-of-the-art performance consistently on object\ndetection and semantic segmentation benchmarks. Code is available at:\nhttps://github.com/hunto/MasKD .\n","authors":["Tao Huang","Yuan Zhang","Shan You","Fei Wang","Chen Qian","Jian Cao","Chang Xu"],"pdf_url":"https://arxiv.org/pdf/2205.14589v2.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.00105v2","updated":"2023-03-02T14:05:50Z","published":"2023-02-28T22:09:12Z","title":"Scalability and Sample Efficiency Analysis of Graph Neural Networks for\n  Power System State Estimation","summary":"  Data-driven state estimation (SE) is becoming increasingly important in\nmodern power systems, as it allows for more efficient analysis of system\nbehaviour using real-time measurement data. This paper thoroughly evaluates a\nphasor measurement unit-only state estimator based on graph neural networks\n(GNNs) applied over factor graphs. To assess the sample efficiency of the GNN\nmodel, we perform multiple training experiments on various training set sizes.\nAdditionally, to evaluate the scalability of the GNN model, we conduct\nexperiments on power systems of various sizes. Our results show that the\nGNN-based state estimator exhibits high accuracy and efficient use of data.\nAdditionally, it demonstrated scalability in terms of both memory usage and\ninference time, making it a promising solution for data-driven SE in modern\npower systems.\n","authors":["Ognjen Kundacina","Gorana Gojic","Mirsad Cosovic","Dragisa Miskovic","Dejan Vukobratovic"],"pdf_url":"https://arxiv.org/pdf/2303.00105v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01277v1","updated":"2023-03-02T14:02:39Z","published":"2023-03-02T14:02:39Z","title":"Boosting Distributed Full-graph GNN Training with Asynchronous One-bit\n  Communication","summary":"  Training Graph Neural Networks (GNNs) on large graphs is challenging due to\nthe conflict between the high memory demand and limited GPU memory. Recently,\ndistributed full-graph GNN training has been widely adopted to tackle this\nproblem. However, the substantial inter-GPU communication overhead can cause\nsevere throughput degradation. Existing communication compression techniques\nmainly focus on traditional DNN training, whose bottleneck lies in\nsynchronizing gradients and parameters. We find they do not work well in\ndistributed GNN training as the barrier is the layer-wise communication of\nfeatures during the forward pass & feature gradients during the backward pass.\nTo this end, we propose an efficient distributed GNN training framework Sylvie,\nwhich employs one-bit quantization technique in GNNs and further pipelines the\ncurtailed communication with computation to enormously shrink the overhead\nwhile maintaining the model quality. In detail, Sylvie provides a lightweight\nLow-bit Module to quantize the sent data and dequantize the received data back\nto full precision values in each layer. Additionally, we propose a Bounded\nStaleness Adaptor to control the introduced staleness to achieve further\nperformance enhancement. We conduct theoretical convergence analysis and\nextensive experiments on various models & datasets to demonstrate Sylvie can\nconsiderably boost the training throughput by up to 28.1x.\n","authors":["Meng Zhang","Qinghao Hu","Peng Sun","Yonggang Wen","Tianwei Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.01277v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01274v1","updated":"2023-03-02T13:59:07Z","published":"2023-03-02T13:59:07Z","title":"Measuring axiomatic soundness of counterfactual image models","summary":"  We present a general framework for evaluating image counterfactuals. The\npower and flexibility of deep generative models make them valuable tools for\nlearning mechanisms in structural causal models. However, their flexibility\nmakes counterfactual identifiability impossible in the general case. Motivated\nby these issues, we revisit Pearl's axiomatic definition of counterfactuals to\ndetermine the necessary constraints of any counterfactual inference model:\ncomposition, reversibility, and effectiveness. We frame counterfactuals as\nfunctions of an input variable, its parents, and counterfactual parents and use\nthe axiomatic constraints to restrict the set of functions that could represent\nthe counterfactual, thus deriving distance metrics between the approximate and\nideal functions. We demonstrate how these metrics can be used to compare and\nchoose between different approximate counterfactual inference models and to\nprovide insight into a model's shortcomings and trade-offs.\n","authors":["Miguel Monteiro","Fabio De Sousa Ribeiro","Nick Pawlowski","Daniel C. Castro","Ben Glocker"],"pdf_url":"https://arxiv.org/pdf/2303.01274v1.pdf","comment":"Counterfactual inference, Generative Models, Computer Vision,\n  Published in ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01272v1","updated":"2023-03-02T13:58:06Z","published":"2023-03-02T13:58:06Z","title":"Navigating the Metric Maze: A Taxonomy of Evaluation Metrics for Anomaly\n  Detection in Time Series","summary":"  The field of time series anomaly detection is constantly advancing, with\nseveral methods available, making it a challenge to determine the most\nappropriate method for a specific domain. The evaluation of these methods is\nfacilitated by the use of metrics, which vary widely in their properties.\nDespite the existence of new evaluation metrics, there is limited agreement on\nwhich metrics are best suited for specific scenarios and domain, and the most\ncommonly used metrics have faced criticism in the literature. This paper\nprovides a comprehensive overview of the metrics used for the evaluation of\ntime series anomaly detection methods, and also defines a taxonomy of these\nbased on how they are calculated. By defining a set of properties for\nevaluation metrics and a set of specific case studies and experiments, twenty\nmetrics are analyzed and discussed in detail, highlighting the unique\nsuitability of each for specific tasks. Through extensive experimentation and\nanalysis, this paper argues that the choice of evaluation metric must be made\nwith care, taking into account the specific requirements of the task at hand.\n","authors":["Sondre Sørbø","Massimiliano Ruocco"],"pdf_url":"https://arxiv.org/pdf/2303.01272v1.pdf","comment":"29 pages, 28 figures and tables"},{"id":"http://arxiv.org/abs/2303.01265v1","updated":"2023-03-02T13:50:23Z","published":"2023-03-02T13:50:23Z","title":"Steering Graph Neural Networks with Pinning Control","summary":"  In the semi-supervised setting where labeled data are largely limited, it\nremains to be a big challenge for message passing based graph neural networks\n(GNNs) to learn feature representations for the nodes with the same class label\nthat is distributed discontinuously over the graph. To resolve the\ndiscontinuous information transmission problem, we propose a control principle\nto supervise representation learning by leveraging the prototypes (i.e., class\ncenters) of labeled data. Treating graph learning as a discrete dynamic process\nand the prototypes of labeled data as \"desired\" class representations, we\nborrow the pinning control idea from automatic control theory to design\nlearning feedback controllers for the feature learning process, attempting to\nminimize the differences between message passing derived features and the class\nprototypes in every round so as to generate class-relevant features.\nSpecifically, we equip every node with an optimal controller in each round\nthrough learning the matching relationships between nodes and the class\nprototypes, enabling nodes to rectify the aggregated information from\nincompatible neighbors in a graph with strong heterophily. Our experiments\ndemonstrate that the proposed PCGCN model achieves better performances than\ndeep GNNs and other competitive heterophily-oriented methods, especially when\nthe graph has very few labels and strong heterophily.\n","authors":["Acong Zhang","Ping Li","Guanrong Chen"],"pdf_url":"https://arxiv.org/pdf/2303.01265v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2212.10390v3","updated":"2023-03-02T13:36:47Z","published":"2022-12-20T16:17:40Z","title":"ADAS: A Simple Active-and-Adaptive Baseline for Cross-Domain 3D Semantic\n  Segmentation","summary":"  State-of-the-art 3D semantic segmentation models are trained on the\noff-the-shelf public benchmarks, but they often face the major challenge when\nthese well-trained models are deployed to a new domain. In this paper, we\npropose an Active-and-Adaptive Segmentation (ADAS) baseline to enhance the weak\ncross-domain generalization ability of a well-trained 3D segmentation model,\nand bridge the point distribution gap between domains. Specifically, before the\ncross-domain adaptation stage begins, ADAS performs an active sampling\noperation to select a maximally-informative subset from both source and target\ndomains for effective adaptation, reducing the adaptation difficulty under 3D\nscenarios. Benefiting from the rise of multi-modal 2D-3D datasets, ADAS\nutilizes a cross-modal attention-based feature fusion module that can extract a\nrepresentative pair of image features and point features to achieve a\nbi-directional image-point feature interaction for better safe adaptation.\nExperimentally, ADAS is verified to be effective in many cross-domain settings\nincluding: 1) Unsupervised Domain Adaptation (UDA), which means that all\nsamples from target domain are unlabeled; 2) Unsupervised Few-shot Domain\nAdaptation (UFDA) which means that only a few unlabeled samples are available\nin the unlabeled target domain; 3) Active Domain Adaptation (ADA) which means\nthat the selected target samples by ADAS are manually annotated. Their results\ndemonstrate that ADAS achieves a significant accuracy gain by easily coupling\nADAS with self-training methods or off-the-shelf UDA works.\n","authors":["Ben Fei","Siyuan Huang","Jiakang Yuan","Botian Shi","Bo Zhang","Tao Chen","Min Dou","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2212.10390v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12245v2","updated":"2023-03-02T13:36:28Z","published":"2023-02-23T18:58:57Z","title":"Set Features for Fine-grained Anomaly Detection","summary":"  Fine-grained anomaly detection has recently been dominated by segmentation\nbased approaches. These approaches first classify each element of the sample\n(e.g., image patch) as normal or anomalous and then classify the entire sample\nas anomalous if it contains anomalous elements. However, such approaches do not\nextend to scenarios where the anomalies are expressed by an unusual combination\nof normal elements. In this paper, we overcome this limitation by proposing set\nfeatures that model each sample by the distribution its elements. We compute\nthe anomaly score of each sample using a simple density estimation method. Our\nsimple-to-implement approach outperforms the state-of-the-art in image-level\nlogical anomaly detection (+3.4%) and sequence-level time-series anomaly\ndetection (+2.4%).\n","authors":["Niv Cohen","Issar Tzachor","Yedid Hoshen"],"pdf_url":"https://arxiv.org/pdf/2302.12245v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01256v1","updated":"2023-03-02T13:36:28Z","published":"2023-03-02T13:36:28Z","title":"Choosing Public Datasets for Private Machine Learning via Gradient\n  Subspace Distance","summary":"  Differentially private stochastic gradient descent privatizes model training\nby injecting noise into each iteration, where the noise magnitude increases\nwith the number of model parameters. Recent works suggest that we can reduce\nthe noise by leveraging public data for private machine learning, by projecting\ngradients onto a subspace prescribed by the public data. However, given a\nchoice of public datasets, it is not a priori clear which one may be most\nappropriate for the private task. We give an algorithm for selecting a public\ndataset by measuring a low-dimensional subspace distance between gradients of\nthe public and private examples. We provide theoretical analysis demonstrating\nthat the excess risk scales with this subspace distance. This distance is easy\nto compute and robust to modifications in the setting. Empirical evaluation\nshows that trained model accuracy is monotone in this distance.\n","authors":["Xin Gu","Gautam Kamath","Zhiwei Steven Wu"],"pdf_url":"https://arxiv.org/pdf/2303.01256v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.13366v3","updated":"2023-03-02T13:33:41Z","published":"2022-04-28T09:17:50Z","title":"Semantic Information Recovery in Wireless Networks","summary":"  Motivated by the recent success of Machine Learning (ML) tools in wireless\ncommunications, the idea of semantic communication by Weaver from 1949 has\nreceived considerable attention. It breaks with the classic design paradigm of\nShannon by aiming to transmit the meaning of a message, i.e., semantics, rather\nthan its exact copy and thus allows for savings in information rate. In this\nwork, we extend the fundamental approach from Basu et al. for modeling\nsemantics to the complete communications Markov chain. Thus, we model semantics\nby means of hidden random variables and define the semantic communication task\nas the data-reduced and reliable transmission of messages over a communication\nchannel such that semantics is best preserved. We cast this task as an\nend-to-end Information Bottleneck problem allowing for compression while\npreserving relevant information at most. As a solution approach, we propose the\nML-based semantic communication system SINFONY and use it for a distributed\nmultipoint scenario: SINFONY communicates the meaning behind multiple messages\nthat are observed at different senders to a single receiver for semantic\nrecovery. We analyze SINFONY by processing images as message examples.\nNumerical results reveal a tremendous rate-normalized SNR shift up to 20 dB\ncompared to classically designed communication systems.\n","authors":["Edgar Beck","Carsten Bockelmann","Armin Dekorsy"],"pdf_url":"https://arxiv.org/pdf/2204.13366v3.pdf","comment":"Submitted for peer review"},{"id":"http://arxiv.org/abs/2303.01220v1","updated":"2023-03-02T13:04:47Z","published":"2023-03-02T13:04:47Z","title":"Evaluation of drain, a deep-learning approach to rain retrieval from gpm\n  passive microwave radiometer","summary":"  Retrieval of rain from Passive Microwave radiometers data has been a\nchallenge ever since the launch of the first Defense Meteorological Satellite\nProgram in the late 70s. Enormous progress has been made since the launch of\nthe Tropical Rainfall Measuring Mission (TRMM) in 1997 but until recently the\ndata were processed pixel-by-pixel or taking a few neighboring pixels into\naccount. Deep learning has obtained remarkable improvement in the computer\nvision field, and offers a whole new way to tackle the rain retrieval problem.\nThe Global Precipitation Measurement (GPM) Core satellite carries similarly to\nTRMM, a passive microwave radiometer and a radar that share part of their\nswath. The brightness temperatures measured in the 37 and 89 GHz channels are\nused like the RGB components of a regular image while rain rate from Dual\nFrequency radar provides the surface rain. A U-net is then trained on these\ndata to develop a retrieval algorithm: Deep-learning RAIN (DRAIN). With only\nfour brightness temperatures as an input and no other a priori information,\nDRAIN is offering similar or slightly better performances than GPROF, the GPM\nofficial algorithm, in most situations. These performances are assumed to be\ndue to the fact that DRAIN works on an image basis instead of the classical\npixel-by-pixel basis.\n","authors":["Nicolas Viltard","Vibolroth Sambath","Pierre Lepetit","Audrey Martini","Laurent Barthès","Cécile Mallet"],"pdf_url":"https://arxiv.org/pdf/2303.01220v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01215v1","updated":"2023-03-02T12:56:52Z","published":"2023-03-02T12:56:52Z","title":"Why (and When) does Local SGD Generalize Better than SGD?","summary":"  Local SGD is a communication-efficient variant of SGD for large-scale\ntraining, where multiple GPUs perform SGD independently and average the model\nparameters periodically. It has been recently observed that Local SGD can not\nonly achieve the design goal of reducing the communication overhead but also\nlead to higher test accuracy than the corresponding SGD baseline (Lin et al.,\n2020b), though the training regimes for this to happen are still in debate\n(Ortiz et al., 2021). This paper aims to understand why (and when) Local SGD\ngeneralizes better based on Stochastic Differential Equation (SDE)\napproximation. The main contributions of this paper include (i) the derivation\nof an SDE that captures the long-term behavior of Local SGD in the small\nlearning rate regime, showing how noise drives the iterate to drift and diffuse\nafter it has reached close to the manifold of local minima, (ii) a comparison\nbetween the SDEs of Local SGD and SGD, showing that Local SGD induces a\nstronger drift term that can result in a stronger effect of regularization,\ne.g., a faster reduction of sharpness, and (iii) empirical evidence validating\nthat having a small learning rate and long enough training time enables the\ngeneralization improvement over SGD but removing either of the two conditions\nleads to no improvement.\n","authors":["Xinran Gu","Kaifeng Lyu","Longbo Huang","Sanjeev Arora"],"pdf_url":"https://arxiv.org/pdf/2303.01215v1.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01213v1","updated":"2023-03-02T12:54:12Z","published":"2023-03-02T12:54:12Z","title":"Dodging the Sparse Double Descent","summary":"  This paper presents an approach to addressing the issue of\nover-parametrization in deep neural networks, more specifically by avoiding the\n``sparse double descent'' phenomenon. The authors propose a learning framework\nthat allows avoidance of this phenomenon and improves generalization, an\nentropy measure to provide more insights on its insurgence, and provide a\ncomprehensive quantitative analysis of various factors such as\nre-initialization methods, model width and depth, and dataset noise. The\nproposed approach is supported by experimental results achieved using typical\nadversarial learning setups. The source code to reproduce the experiments is\nprovided in the supplementary materials and will be publicly released upon\nacceptance of the paper.\n","authors":["Victor Quétu","Enzo Tartaglione"],"pdf_url":"https://arxiv.org/pdf/2303.01213v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01211v1","updated":"2023-03-02T12:52:22Z","published":"2023-03-02T12:52:22Z","title":"Learning From Yourself: A Self-Distillation Method for Fake Speech\n  Detection","summary":"  In this paper, we propose a novel self-distillation method for fake speech\ndetection (FSD), which can significantly improve the performance of FSD without\nincreasing the model complexity. For FSD, some fine-grained information is very\nimportant, such as spectrogram defects, mute segments, and so on, which are\noften perceived by shallow networks. However, shallow networks have much noise,\nwhich can not capture this very well. To address this problem, we propose using\nthe deepest network instruct shallow network for enhancing shallow networks.\nSpecifically, the networks of FSD are divided into several segments, the\ndeepest network being used as the teacher model, and all shallow networks\nbecome multiple student models by adding classifiers. Meanwhile, the\ndistillation path between the deepest network feature and shallow network\nfeatures is used to reduce the feature difference. A series of experimental\nresults on the ASVspoof 2019 LA and PA datasets show the effectiveness of the\nproposed method, with significant improvements compared to the baseline.\n","authors":["Jun Xue","Cunhang Fan","Jiangyan Yi","Chenglong Wang","Zhengqi Wen","Dan Zhang","Zhao Lv"],"pdf_url":"https://arxiv.org/pdf/2303.01211v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2203.10258v3","updated":"2023-03-02T12:50:53Z","published":"2022-03-19T06:48:50Z","title":"TDR-CL: Targeted Doubly Robust Collaborative Learning for Debiased\n  Recommendations","summary":"  Bias is a common problem inherent in recommender systems, which is entangled\nwith users' preferences and poses a great challenge to unbiased learning. For\ndebiasing tasks, the doubly robust (DR) method and its variants show superior\nperformance due to the double robustness property, that is, DR is unbiased when\neither imputed errors or learned propensities are accurate. However, our\ntheoretical analysis reveals that DR usually has a large variance. Meanwhile,\nDR would suffer unexpectedly large bias and poor generalization caused by\ninaccurate imputed errors and learned propensities, which usually occur in\npractice. In this paper, we propose a principled approach that can effectively\nreduce bias and variance simultaneously for existing DR approaches when the\nerror imputation model is misspecified. In addition, we further propose a novel\nsemi-parametric collaborative learning approach that decomposes imputed errors\ninto parametric and nonparametric parts and updates them collaboratively,\nresulting in more accurate predictions. Both theoretical analysis and\nexperiments demonstrate the superiority of the proposed methods compared with\nexisting debiasing methods.\n","authors":["Haoxuan Li","Yan Lyu","Chunyuan Zheng","Peng Wu"],"pdf_url":"https://arxiv.org/pdf/2203.10258v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2102.08817v4","updated":"2023-03-02T12:50:24Z","published":"2021-02-17T15:22:38Z","title":"Dissecting Supervised Contrastive Learning","summary":"  Minimizing cross-entropy over the softmax scores of a linear map composed\nwith a high-capacity encoder is arguably the most popular choice for training\nneural networks on supervised learning tasks. However, recent works show that\none can directly optimize the encoder instead, to obtain equally (or even more)\ndiscriminative representations via a supervised variant of a contrastive\nobjective. In this work, we address the question whether there are fundamental\ndifferences in the sought-for representation geometry in the output space of\nthe encoder at minimal loss. Specifically, we prove, under mild assumptions,\nthat both losses attain their minimum once the representations of each class\ncollapse to the vertices of a regular simplex, inscribed in a hypersphere. We\nprovide empirical evidence that this configuration is attained in practice and\nthat reaching a close-to-optimal state typically indicates good generalization\nperformance. Yet, the two losses show remarkably different optimization\nbehavior. The number of iterations required to perfectly fit to data scales\nsuperlinearly with the amount of randomly flipped labels for the supervised\ncontrastive loss. This is in contrast to the approximately linear scaling\npreviously reported for networks trained with cross-entropy.\n","authors":["Florian Graf","Christoph D. Hofer","Marc Niethammer","Roland Kwitt"],"pdf_url":"https://arxiv.org/pdf/2102.08817v4.pdf","comment":"v4 updates: - updated appendix section S1.3 - this includes fixing an\n  oversight in the proofs (Lemma 1 missed an equality condition, which now\n  appears in Lemma 2) - improved figure quality"},{"id":"http://arxiv.org/abs/2111.13802v4","updated":"2023-03-02T12:40:23Z","published":"2021-11-27T03:34:13Z","title":"Factorized Fourier Neural Operators","summary":"  We propose the Factorized Fourier Neural Operator (F-FNO), a learning-based\napproach for simulating partial differential equations (PDEs). Starting from a\nrecently proposed Fourier representation of flow fields, the F-FNO bridges the\nperformance gap between pure machine learning approaches to that of the best\nnumerical or hybrid solvers. This is achieved with new representations -\nseparable spectral layers and improved residual connections - and a combination\nof training strategies such as the Markov assumption, Gaussian noise, and\ncosine learning rate decay. On several challenging benchmark PDEs on regular\ngrids, structured meshes, and point clouds, the F-FNO can scale to deeper\nnetworks and outperform both the FNO and the geo-FNO, reducing the error by 83%\non the Navier-Stokes problem, 31% on the elasticity problem, 57% on the airfoil\nflow problem, and 60% on the plastic forging problem. Compared to the\nstate-of-the-art pseudo-spectral method, the F-FNO can take a step size that is\nan order of magnitude larger in time and achieve an order of magnitude speedup\nto produce the same solution quality.\n","authors":["Alasdair Tran","Alexander Mathews","Lexing Xie","Cheng Soon Ong"],"pdf_url":"https://arxiv.org/pdf/2111.13802v4.pdf","comment":"Published in The Eleventh International Conference on Learning\n  Representations (2023). Code is available at\n  https://github.com/alasdairtran/fourierflow"},{"id":"http://arxiv.org/abs/2303.01201v1","updated":"2023-03-02T12:34:38Z","published":"2023-03-02T12:34:38Z","title":"Average of Pruning: Improving Performance and Stability of\n  Out-of-Distribution Detection","summary":"  Detecting Out-of-distribution (OOD) inputs have been a critical issue for\nneural networks in the open world. However, the unstable behavior of OOD\ndetection along the optimization trajectory during training has not been\nexplored clearly. In this paper, we first find the performance of OOD detection\nsuffers from overfitting and instability during training: 1) the performance\ncould decrease when the training error is near zero, and 2) the performance\nwould vary sharply in the final stage of training. Based on our findings, we\npropose Average of Pruning (AoP), consisting of model averaging and pruning, to\nmitigate the unstable behaviors. Specifically, model averaging can help achieve\na stable performance by smoothing the landscape, and pruning is certified to\neliminate the overfitting by eliminating redundant features. Comprehensive\nexperiments on various datasets and architectures are conducted to verify the\neffectiveness of our method.\n","authors":["Zhen Cheng","Fei Zhu","Xu-Yao Zhang","Cheng-Lin Liu"],"pdf_url":"https://arxiv.org/pdf/2303.01201v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.12502v2","updated":"2023-03-02T12:33:10Z","published":"2022-05-25T05:40:00Z","title":"The Dialog Must Go On: Improving Visual Dialog via Generative\n  Self-Training","summary":"  Visual dialog (VisDial) is a task of answering a sequence of questions\ngrounded in an image, using the dialog history as context. Prior work has\ntrained the dialog agents solely on VisDial data via supervised learning or\nleveraged pre-training on related vision-and-language datasets. This paper\npresents a semi-supervised learning approach for visually-grounded dialog,\ncalled Generative Self-Training (GST), to leverage unlabeled images on the Web.\nSpecifically, GST first retrieves in-domain images through out-of-distribution\ndetection and generates synthetic dialogs regarding the images via multimodal\nconditional text generation. GST then trains a dialog agent on the synthetic\nand the original VisDial data. As a result, GST scales the amount of training\ndata up to an order of magnitude that of VisDial (1.2M to 12.9M QA data). For\nrobust training of the synthetic dialogs, we also propose perplexity-based data\nselection and multimodal consistency regularization. Evaluation on VisDial v1.0\nand v0.9 datasets shows that GST achieves new state-of-the-art results on both\ndatasets. We further observe the robustness of GST against both visual and\ntextual adversarial attacks. Finally, GST yields strong performance gains in\nthe low-data regime. Code is available at\nhttps://github.com/gicheonkang/gst-visdial.\n","authors":["Gi-Cheon Kang","Sungdong Kim","Jin-Hwa Kim","Donghyun Kwak","Byoung-Tak Zhang"],"pdf_url":"https://arxiv.org/pdf/2205.12502v2.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2210.12048v2","updated":"2023-03-02T12:31:39Z","published":"2022-10-21T15:40:49Z","title":"Ollivier-Ricci Curvature for Hypergraphs: A Unified Framework","summary":"  Bridging geometry and topology, curvature is a powerful and expressive\ninvariant. While the utility of curvature has been theoretically and\nempirically confirmed in the context of manifolds and graphs, its\ngeneralization to the emerging domain of hypergraphs has remained largely\nunexplored. On graphs, the Ollivier-Ricci curvature measures differences\nbetween random walks via Wasserstein distances, thus grounding a geometric\nconcept in ideas from probability theory and optimal transport. We develop O\nRCHID, a flexible framework generalizing Ollivier-Ricci curvature to\nhypergraphs, and prove that the resulting curvatures have favorable theoretical\nproperties. Through extensive experiments on synthetic and real-world\nhypergraphs from different domains, we demonstrate that ORCHID curvatures are\nboth scalable and useful to perform a variety of hypergraph tasks in practice.\n","authors":["Corinna Coupette","Sebastian Dalleiger","Bastian Rieck"],"pdf_url":"https://arxiv.org/pdf/2210.12048v2.pdf","comment":"Accepted at ICLR 2023 (https://openreview.net/forum?id=sPCKNl5qDps)"},{"id":"http://arxiv.org/abs/2303.01193v1","updated":"2023-03-02T12:16:24Z","published":"2023-03-02T12:16:24Z","title":"Interpretable System Identification and Long-term Prediction on\n  Time-Series Data","summary":"  Time-series prediction has drawn considerable attention during the past\ndecades fueled by the emerging advances of deep learning methods. However, most\nneural network based methods lack interpretability and fail in extracting the\nhidden mechanism of the targeted physical system. To overcome these\nshortcomings, an interpretable sparse system identification method without any\nprior knowledge is proposed in this study. This method adopts the Fourier\ntransform to reduces the irrelevant items in the dictionary matrix, instead of\nindiscriminate usage of polynomial functions in most system identification\nmethods. It shows an interpretable system representation and greatly reduces\ncomputing cost. With the adoption of $l_1$ norm in regularizing the parameter\nmatrix, a sparse description of the system model can be achieved. Moreover,\nThree data sets including the water conservancy data, global temperature data\nand financial data are used to test the performance of the proposed method.\nAlthough no prior knowledge was known about the physical background,\nexperimental results show that our method can achieve long-term prediction\nregardless of the noise and incompleteness in the original data more accurately\nthan the widely-used baseline data-driven methods. This study may provide some\ninsight into time-series prediction investigations, and suggests that an\nwhite-box system identification method may extract the easily overlooked yet\ninherent periodical features and may beat neural-network based black-box\nmethods on long-term prediction tasks.\n","authors":["Xiaoyi Liu","Duxin Chen","Wenjia Wei","Xia Zhu","Wenwu Yu"],"pdf_url":"https://arxiv.org/pdf/2303.01193v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01181v1","updated":"2023-03-02T11:51:54Z","published":"2023-03-02T11:51:54Z","title":"iSAGE: An Incremental Version of SAGE for Online Explanation on Data\n  Streams","summary":"  Explainable Artificial Intelligence (XAI) focuses mainly on batch learning\nscenarios. In the static learning tasks, various XAI methods, like SAGE, have\nbeen proposed that distribute the importance of a model on its input features.\nHowever, models are often applied in ever-changing dynamic environments like\nincremental learning. As a result, we propose iSAGE as a direct\nincrementalization of SAGE suited for dynamic learning environments. We further\nprovide an efficient approximation method to model feature removal based on the\nconditional data distribution in an incremental setting. We formally analyze\nour explanation method to show that it is an unbiased estimator and construct\nconfidence bounds for the point estimates. Lastly, we evaluate our approach in\na thorough experimental analysis based on well-established data sets and\nconcept drift streams.\n","authors":["Maximilian Muschalik","Fabian Fumagalli","Barbara Hammer","Eyke Hüllermeier"],"pdf_url":"https://arxiv.org/pdf/2303.01181v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01179v1","updated":"2023-03-02T11:49:05Z","published":"2023-03-02T11:49:05Z","title":"SHAP-IQ: Unified Approximation of any-order Shapley Interactions","summary":"  Predominately in explainable artificial intelligence (XAI) research, the\nShapley value (SV) is applied to determine feature importance scores for any\nblack box model. Shapley interaction indices extend the Shapley value to define\nany-order feature interaction scores. Defining a unique Shapley interaction\nindex is an open research question and, so far, three definitions have been\nproposed, which differ by their choice of axioms. Moreover, each definition\nrequires a specific approximation technique. We, however, propose SHAPley\nInteraction Quantification (SHAP-IQ), an efficient sampling-based approximator\nto compute Shapley interactions for all three definitions, as well as all other\nthat satisfy the linearity, symmetry and dummy axiom. SHAP-IQ is based on a\nnovel representation and, in contrast to existing methods, we provide\ntheoretical guarantees for its approximation quality, as well as estimates for\nthe variance of the point estimates. For the special case of SV, our approach\nreveals a novel representation of the SV and corresponds to Unbiased KernelSHAP\nwith a greatly simplified calculation. We illustrate the computational\nefficiency and effectiveness by explaining state-of-the-art language models\namong high-dimensional synthetic models.\n","authors":["Fabian Fumagalli","Maximilian Muschalik","Patrick Kolpaczki","Eyke Hüllermeier","Barbara Hammer"],"pdf_url":"https://arxiv.org/pdf/2303.01179v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01173v1","updated":"2023-03-02T11:35:59Z","published":"2023-03-02T11:35:59Z","title":"Resource-Constrained Station-Keeping for Helium Balloons using\n  Reinforcement Learning","summary":"  High altitude balloons have proved useful for ecological aerial surveys,\natmospheric monitoring, and communication relays. However, due to weight and\npower constraints, there is a need to investigate alternate modes of propulsion\nto navigate in the stratosphere. Very recently, reinforcement learning has been\nproposed as a control scheme to maintain the balloon in the region of a fixed\nlocation, facilitated through diverse opposing wind-fields at different\naltitudes. Although air-pump based station keeping has been explored, there is\nno research on the control problem for venting and ballasting actuated\nballoons, which is commonly used as a low-cost alternative. We show how\nreinforcement learning can be used for this type of balloon. Specifically, we\nuse the soft actor-critic algorithm, which on average is able to station-keep\nwithin 50\\;km for 25\\% of the flight, consistent with state-of-the-art.\nFurthermore, we show that the proposed controller effectively minimises the\nconsumption of resources, thereby supporting long duration flights. We frame\nthe controller as a continuous control reinforcement learning problem, which\nallows for a more diverse range of trajectories, as opposed to current\nstate-of-the-art work, which uses discrete action spaces. Furthermore, through\ncontinuous control, we can make use of larger ascent rates which are not\npossible using air-pumps. The desired ascent-rate is decoupled into desired\naltitude and time-factor to provide a more transparent policy, compared to\nlow-level control commands used in previous works. Finally, by applying the\nequations of motion, we establish appropriate thresholds for venting and\nballasting to prevent the agent from exploiting the environment. More\nspecifically, we ensure actions are physically feasible by enforcing\nconstraints on venting and ballasting.\n","authors":["Jack Saunders","Loïc Prenevost","Özgür Şimşek","Alan Hunter","Wenbin Li"],"pdf_url":"https://arxiv.org/pdf/2303.01173v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.07850v4","updated":"2023-03-02T11:33:24Z","published":"2022-09-16T10:43:10Z","title":"FairGBM: Gradient Boosting with Fairness Constraints","summary":"  Tabular data is prevalent in many high stakes domains, such as financial\nservices or public policy. Gradient boosted decision trees (GBDT) are popular\nin these settings due to performance guarantees and low cost. However, in\nconsequential decision-making fairness is a foremost concern. Despite GBDT's\npopularity, existing in-processing Fair ML methods are either inapplicable to\nGBDT, or incur in significant train time overhead, or are inadequate for\nproblems with high class imbalance -- a typical issue in these domains. We\npresent FairGBM, a dual ascent learning framework for training GBDT under\nfairness constraints, with little to no impact on predictive performance when\ncompared to unconstrained GBDT. Since observational fairness metrics are\nnon-differentiable, we have to employ a \"proxy-Lagrangian\" formulation using\nsmooth convex error rate proxies to enable gradient-based optimization. Our\nimplementation shows an order of magnitude speedup in training time when\ncompared with related work, a pivotal aspect to foster the widespread adoption\nof FairGBM by real-world practitioners.\n","authors":["André F Cruz","Catarina Belém","Sérgio Jesus","João Bravo","Pedro Saleiro","Pedro Bizarro"],"pdf_url":"https://arxiv.org/pdf/2209.07850v4.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2206.00470v3","updated":"2023-03-02T11:24:51Z","published":"2022-06-01T13:02:19Z","title":"Good Intentions: Adaptive Parameter Management via Intent Signaling","summary":"  Parameter management is essential for distributed training of large machine\nlearning (ML) tasks. Some ML tasks are hard to distribute because common\napproaches to parameter management can be highly inefficient. Advanced\nparameter management approaches -- such as selective replication or dynamic\nparameter allocation -- can improve efficiency, but to do so, they typically\nneed to be integrated manually into each task's implementation and they require\nexpensive upfront experimentation to tune correctly. In this work, we explore\nwhether these two problems can be avoided. We first propose a novel intent\nsignaling mechanism that integrates naturally into existing ML stacks and\nprovides the parameter manager with crucial information about parameter\naccesses. We then describe AdaPM, a fully adaptive, zero-tuning parameter\nmanager based on this mechanism. In contrast to prior systems, this approach\nseparates providing information (simple, done by the task) from exploiting it\neffectively (hard, done automatically by AdaPM). In our experimental\nevaluation, AdaPM matched or outperformed state-of-the-art parameter managers\nout of the box, suggesting that automatic parameter management is possible.\n","authors":["Alexander Renz-Wieland","Andreas Kieslinger","Robert Gericke","Rainer Gemulla","Zoi Kaoudi","Volker Markl"],"pdf_url":"https://arxiv.org/pdf/2206.00470v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01170v1","updated":"2023-03-02T11:21:03Z","published":"2023-03-02T11:21:03Z","title":"Expert-Free Online Transfer Learning in Multi-Agent Reinforcement\n  Learning","summary":"  Transfer learning in Reinforcement Learning (RL) has been widely studied to\novercome training issues of Deep-RL, i.e., exploration cost, data availability\nand convergence time, by introducing a way to enhance training phase with\nexternal knowledge. Generally, knowledge is transferred from expert-agents to\nnovices. While this fixes the issue for a novice agent, a good understanding of\nthe task on expert agent is required for such transfer to be effective. As an\nalternative, in this paper we propose Expert-Free Online Transfer Learning\n(EF-OnTL), an algorithm that enables expert-free real-time dynamic transfer\nlearning in multi-agent system. No dedicated expert exists, and transfer source\nagent and knowledge to be transferred are dynamically selected at each transfer\nstep based on agents' performance and uncertainty. To improve uncertainty\nestimation, we also propose State Action Reward Next-State Random Network\nDistillation (sars-RND), an extension of RND that estimates uncertainty from RL\nagent-environment interaction. We demonstrate EF-OnTL effectiveness against a\nno-transfer scenario and advice-based baselines, with and without expert\nagents, in three benchmark tasks: Cart-Pole, a grid-based Multi-Team\nPredator-Prey (mt-pp) and Half Field Offense (HFO). Our results show that\nEF-OnTL achieve overall comparable performance when compared against\nadvice-based baselines while not requiring any external input nor threshold\ntuning. EF-OnTL outperforms no-transfer with an improvement related to the\ncomplexity of the task addressed.\n","authors":["Alberto Castagna","Ivana Dusparic"],"pdf_url":"https://arxiv.org/pdf/2303.01170v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01169v1","updated":"2023-03-02T11:19:44Z","published":"2023-03-02T11:19:44Z","title":"Risk-aware Path Planning via Probabilistic Fusion of Traversability\n  Prediction for Planetary Rovers on Heterogeneous Terrains","summary":"  Machine learning (ML) plays a crucial role in assessing traversability for\nautonomous rover operations on deformable terrains but suffers from inevitable\nprediction errors. Especially for heterogeneous terrains where the geological\nfeatures vary from place to place, erroneous traversability prediction can\nbecome more apparent, increasing the risk of unrecoverable rover's wheel slip\nand immobilization. In this work, we propose a new path planning algorithm that\nexplicitly accounts for such erroneous prediction. The key idea is the\nprobabilistic fusion of distinctive ML models for terrain type classification\nand slip prediction into a single distribution. This gives us a multimodal slip\ndistribution accounting for heterogeneous terrains and further allows\nstatistical risk assessment to be applied to derive risk-aware traversing costs\nfor path planning. Extensive simulation experiments have demonstrated that the\nproposed method is able to generate more feasible paths on heterogeneous\nterrains compared to existing methods.\n","authors":["Masafumi Endo","Tatsunori Taniai","Ryo Yonetani","Genya Ishigami"],"pdf_url":"https://arxiv.org/pdf/2303.01169v1.pdf","comment":"7 pages, 4 figures. Accepted article for presentation at the 2023\n  IEEE International Conference on Robotics and Automation (ICRA)"},{"id":"http://arxiv.org/abs/2303.01158v1","updated":"2023-03-02T11:05:10Z","published":"2023-03-02T11:05:10Z","title":"Iterative Circuit Repair Against Formal Specifications","summary":"  We present a deep learning approach for repairing sequential circuits against\nformal specifications given in linear-time temporal logic (LTL). Given a\ndefective circuit and its formal specification, we train Transformer models to\noutput circuits that satisfy the corresponding specification. We propose a\nseparated hierarchical Transformer for multimodal representation learning of\nthe formal specification and the circuit. We introduce a data generation\nalgorithm that enables generalization to more complex specifications and\nout-of-distribution datasets. In addition, our proposed repair mechanism\nsignificantly improves the automated synthesis of circuits from LTL\nspecifications with Transformers. It improves the state-of-the-art by $6.8$\npercentage points on held-out instances and $11.8$ percentage points on an\nout-of-distribution dataset from the annual reactive synthesis competition.\n","authors":["Matthias Cosler","Frederik Schmitt","Christopher Hahn","Bernd Finkbeiner"],"pdf_url":"https://arxiv.org/pdf/2303.01158v1.pdf","comment":"To appear at ICLR'23"},{"id":"http://arxiv.org/abs/2303.01156v1","updated":"2023-03-02T11:01:49Z","published":"2023-03-02T11:01:49Z","title":"A Notion of Feature Importance by Decorrelation and Detection of Trends\n  by Random Forest Regression","summary":"  In many studies, we want to determine the influence of certain features on a\ndependent variable. More specifically, we are interested in the strength of the\ninfluence -- i.e., is the feature relevant? -- and, if so, how the feature\ninfluences the dependent variable. Recently, data-driven approaches such as\n\\emph{random forest regression} have found their way into applications\n(Boulesteix et al., 2012). These models allow to directly derive measures of\nfeature importance, which are a natural indicator of the strength of the\ninfluence. For the relevant features, the correlation or rank correlation\nbetween the feature and the dependent variable has typically been used to\ndetermine the nature of the influence. More recent methods, some of which can\nalso measure interactions between features, are based on a modeling approach.\nIn particular, when machine learning models are used, SHAP scores are a recent\nand prominent method to determine these trends (Lundberg et al., 2017).\n  In this paper, we introduce a novel notion of feature importance based on the\nwell-studied Gram-Schmidt decorrelation method. Furthermore, we propose two\nestimators for identifying trends in the data using random forest regression,\nthe so-called absolute and relative transversal rate. We empirically compare\nthe properties of our estimators with those of well-established estimators on a\nvariety of synthetic and real-world datasets.\n","authors":["Yannick Gerstorfer","Lena Krieg","Max Hahn-Klimroth"],"pdf_url":"https://arxiv.org/pdf/2303.01156v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.13956v2","updated":"2023-03-02T10:53:40Z","published":"2022-11-25T08:39:12Z","title":"Learning General Audio Representations with Large-Scale Training of\n  Patchout Audio Transformers","summary":"  The success of supervised deep learning methods is largely due to their\nability to learn relevant features from raw data. Deep Neural Networks (DNNs)\ntrained on large-scale datasets are capable of capturing a diverse set of\nfeatures, and learning a representation that can generalize onto unseen tasks\nand datasets that are from the same domain. Hence, these models can be used as\npowerful feature extractors, in combination with shallower models as\nclassifiers, for smaller tasks and datasets where the amount of training data\nis insufficient for learning an end-to-end model from scratch. During the past\nyears, Convolutional Neural Networks (CNNs) have largely been the method of\nchoice for audio processing. However, recently attention-based transformer\nmodels have demonstrated great potential in supervised settings, outperforming\nCNNs. In this work, we investigate the use of audio transformers trained on\nlarge-scale datasets to learn general-purpose representations. We study how the\ndifferent setups in these audio transformers affect the quality of their\nembeddings. We experiment with the models' time resolution, extracted embedding\nlevel, and receptive fields in order to see how they affect performance on a\nvariety of tasks and datasets, following the HEAR 2021 NeurIPS challenge\nevaluation setup. Our results show that representations extracted by audio\ntransformers outperform CNN representations. Furthermore, we will show that\ntransformers trained on Audioset can be extremely effective representation\nextractors for a wide range of downstream tasks.\n","authors":["Khaled Koutini","Shahed Masoudian","Florian Schmid","Hamid Eghbal-zadeh","Jan Schlüter","Gerhard Widmer"],"pdf_url":"https://arxiv.org/pdf/2211.13956v2.pdf","comment":"will apear in HEAR: Holistic Evaluation of Audio Representations\n  Proceedings of Machine Learning Research PMLR 166. Source code:\n  https://github.com/kkoutini/passt_hear21"},{"id":"http://arxiv.org/abs/2212.14441v3","updated":"2023-03-02T10:48:12Z","published":"2022-12-29T19:32:20Z","title":"Fruit Ripeness Classification: a Survey","summary":"  Fruit is a key crop in worldwide agriculture feeding millions of people. The\nstandard supply chain of fruit products involves quality checks to guarantee\nfreshness, taste, and, most of all, safety. An important factor that determines\nfruit quality is its stage of ripening. This is usually manually classified by\nfield experts, making it a labor-intensive and error-prone process. Thus, there\nis an arising need for automation in fruit ripeness classification. Many\nautomatic methods have been proposed that employ a variety of feature\ndescriptors for the food item to be graded. Machine learning and deep learning\ntechniques dominate the top-performing methods. Furthermore, deep learning can\noperate on raw data and thus relieve the users from having to compute complex\nengineered features, which are often crop-specific. In this survey, we review\nthe latest methods proposed in the literature to automatize fruit ripeness\nclassification, highlighting the most common feature descriptors they operate\non.\n","authors":["Matteo Rizzo","Matteo Marcuzzo","Alessandro Zangari","Andrea Gasparetto","Andrea Albarelli"],"pdf_url":"https://arxiv.org/pdf/2212.14441v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01141v1","updated":"2023-03-02T10:40:50Z","published":"2023-03-02T10:40:50Z","title":"DeepSaDe: Learning Neural Networks that Guarantee Domain Constraint\n  Satisfaction","summary":"  As machine learning models, specifically neural networks, are becoming\nincreasingly popular, there are concerns regarding their trustworthiness,\nspecially in safety-critical applications, e.g. actions of an autonomous\nvehicle must be safe. There are approaches that can train neural networks where\nsuch domain requirements are enforced as constraints, but they either cannot\nguarantee that the constraint will be satisfied by all possible predictions\n(even on unseen data) or they are limited in the type of constraints that can\nbe enforced. In this paper, we present an approach to train neural networks\nwhich can enforce a wide variety of constraints and guarantee that the\nconstraint is satisfied by all possible predictions. The approach builds on\nearlier work where learning linear models is formulated as a constraint\nsatisfaction problem (CSP). To make this idea applicable to neural networks,\ntwo crucial new elements are added: constraint propagation over the network\nlayers, and weight updates based on a mix of gradient descent and CSP solving.\nEvaluation on various machine learning tasks demonstrates that our approach is\nflexible enough to enforce a wide variety of domain constraints and is able to\nguarantee them in neural networks.\n","authors":["Kshitij Goyal","Sebastijan Dumancic","Hendrik Blockeel"],"pdf_url":"https://arxiv.org/pdf/2303.01141v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2303.01140v1","updated":"2023-03-02T10:39:13Z","published":"2023-03-02T10:39:13Z","title":"Cardinality Estimation over Knowledge Graphs with Embeddings and Graph\n  Neural Networks","summary":"  Cardinality Estimation over Knowledge Graphs (KG) is crucial for query\noptimization, yet remains a challenging task due to the semi-structured nature\nand complex correlations of typical Knowledge Graphs. In this work, we propose\nGNCE, a novel approach that leverages knowledge graph embeddings and Graph\nNeural Networks (GNN) to accurately predict the cardinality of conjunctive\nqueries. GNCE first creates semantically meaningful embeddings for all entities\nin the KG, which are then integrated into the given query, which is processed\nby a GNN to estimate the cardinality of the query. We evaluate GNCE on several\nKGs in terms of q-Error and demonstrate that it outperforms state-of-the-art\napproaches based on sampling, summaries, and (machine) learning in terms of\nestimation accuracy while also having lower execution time and less parameters.\nAdditionally, we show that GNCE can inductively generalise to unseen entities,\nmaking it suitable for use in dynamic query processing scenarios. Our proposed\napproach has the potential to significantly improve query optimization and\nrelated applications that rely on accurate cardinality estimates of conjunctive\nqueries.\n","authors":["Tim Schwabe","Maribel Acosta"],"pdf_url":"https://arxiv.org/pdf/2303.01140v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.03880v2","updated":"2023-03-02T10:39:10Z","published":"2022-09-08T15:35:42Z","title":"Learning Sparse Graphon Mean Field Games","summary":"  Although the field of multi-agent reinforcement learning (MARL) has made\nconsiderable progress in the last years, solving systems with a large number of\nagents remains a hard challenge. Graphon mean field games (GMFGs) enable the\nscalable analysis of MARL problems that are otherwise intractable. By the\nmathematical structure of graphons, this approach is limited to dense graphs\nwhich are insufficient to describe many real-world networks such as power law\ngraphs. Our paper introduces a novel formulation of GMFGs, called LPGMFGs,\nwhich leverages the graph theoretical concept of $L^p$ graphons and provides a\nmachine learning tool to efficiently and accurately approximate solutions for\nsparse network problems. This especially includes power law networks which are\nempirically observed in various application areas and cannot be captured by\nstandard graphons. We derive theoretical existence and convergence guarantees\nand give empirical examples that demonstrate the accuracy of our learning\napproach for systems with many agents. Furthermore, we extend the Online Mirror\nDescent (OMD) learning algorithm to our setup to accelerate learning speed,\nempirically show its capabilities, and conduct a theoretical analysis using the\nnovel concept of smoothed step graphons. In general, we provide a scalable,\nmathematically well-founded machine learning approach to a large class of\notherwise intractable problems of great relevance in numerous research fields.\n","authors":["Christian Fabian","Kai Cui","Heinz Koeppl"],"pdf_url":"https://arxiv.org/pdf/2209.03880v2.pdf","comment":"accepted for publication at the International Conference on\n  Artificial Intelligence and Statistics (AISTATS) 2023"},{"id":"http://arxiv.org/abs/2210.09186v4","updated":"2023-03-02T10:37:17Z","published":"2022-10-17T15:38:41Z","title":"Implicit models, latent compression, intrinsic biases, and cheap lunches\n  in community detection","summary":"  The task of community detection, which aims to partition a network into\nclusters of nodes to summarize its large-scale structure, has spawned the\ndevelopment of many competing algorithms with varying objectives. Some\ncommunity detection methods are inferential, explicitly deriving the clustering\nobjective through a probabilistic generative model, while other methods are\ndescriptive, dividing a network according to an objective motivated by a\nparticular application, making it challenging to compare these methods on the\nsame scale. Here we present a solution to this problem that associates any\ncommunity detection objective, inferential or descriptive, with its\ncorresponding implicit network generative model. This allows us to compute the\ndescription length of a network and its partition under arbitrary objectives,\nproviding a principled measure to compare the performance of different\nalgorithms without the need for \"ground truth\" labels. Our approach also gives\naccess to instances of the community detection problem that are optimal to any\ngiven algorithm, and in this way reveals intrinsic biases in popular\ndescriptive methods, explaining their tendency to overfit. Using our framework,\nwe compare a number of community detection methods on artificial networks, and\non a corpus of over 500 structurally diverse empirical networks. We find that\nmore expressive community detection methods exhibit consistently superior\ncompression performance on structured data instances, without having degraded\nperformance on a minority of situations where more specialized algorithms\nperform optimally. Our results undermine the implications of the \"no free\nlunch\" theorem for community detection, both conceptually and in practice,\nsince it is confined to unstructured data instances, unlike relevant community\ndetection problems which are structured by requirement.\n","authors":["Tiago P. Peixoto","Alec Kirkley"],"pdf_url":"https://arxiv.org/pdf/2210.09186v4.pdf","comment":"27 pages, 17 figures"},{"id":"http://arxiv.org/abs/2303.01135v1","updated":"2023-03-02T10:31:58Z","published":"2023-03-02T10:31:58Z","title":"Tight Risk Bounds for Gradient Descent on Separable Data","summary":"  We study the generalization properties of unregularized gradient methods\napplied to separable linear classification -- a setting that has received\nconsiderable attention since the pioneering work of Soudry et al. (2018). We\nestablish tight upper and lower (population) risk bounds for gradient descent\nin this setting, for any smooth loss function, expressed in terms of its tail\ndecay rate. Our bounds take the form $\\Theta(r_{\\ell,T}^2 / \\gamma^2 T +\nr_{\\ell,T}^2 / \\gamma^2 n)$, where $T$ is the number of gradient steps, $n$ is\nsize of the training set, $\\gamma$ is the data margin, and $r_{\\ell,T}$ is a\ncomplexity term that depends on the (tail decay rate) of the loss function (and\non $T$). Our upper bound matches the best known upper bounds due to Shamir\n(2021); Schliserman and Koren (2022), while extending their applicability to\nvirtually any smooth loss function and relaxing technical assumptions they\nimpose. Our risk lower bounds are the first in this context and establish the\ntightness of our upper bounds for any given tail decay rate and in all\nparameter regimes. The proof technique used to show these results is also\nmarkedly simpler compared to previous work, and is straightforward to extend to\nother gradient methods; we illustrate this by providing analogous results for\nStochastic Gradient Descent.\n","authors":["Matan Schliserman","Tomer Koren"],"pdf_url":"https://arxiv.org/pdf/2303.01135v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01134v1","updated":"2023-03-02T10:30:52Z","published":"2023-03-02T10:30:52Z","title":"Error mitigation of entangled states using brainbox quantum autoencoders","summary":"  Current quantum hardware is subject to various sources of noise that limits\nthe access to multi-qubit entangled states. Quantum autoencoder circuits with a\nsingle qubit bottleneck have shown capability to correct error in noisy\nentangled state. By introducing slightly more complex structures in the\nbottleneck, the so-called brainboxes, the denoising process can take place\nfaster and for stronger noise channels. Choosing the most suitable brainbox for\nthe bottleneck is the result of a trade-off between noise intensity on the\nhardware, and the training impedance. Finally, by studying R\\'enyi entropy flow\nthroughout the networks we demonstrate that the localization of entanglement\nplays a central role in denoising through learning.\n","authors":["Joséphine Pazem","Mohammad H. Ansari"],"pdf_url":"https://arxiv.org/pdf/2303.01134v1.pdf","comment":"13 pages, 10 figures"},{"id":"http://arxiv.org/abs/2303.01125v1","updated":"2023-03-02T10:09:11Z","published":"2023-03-02T10:09:11Z","title":"Distilling Multi-Level X-vector Knowledge for Small-footprint Speaker\n  Verification","summary":"  Deep speaker models yield low error rates in speaker verification.\nNonetheless, the high performance tends to be exchanged for model size and\ncomputation time, making these models challenging to run under limited\nconditions. We focus on small-footprint deep speaker embedding extraction,\nleveraging knowledge distillation. While prior work on this topic has addressed\nspeaker embedding extraction at the utterance level, we propose to combine\nembeddings from various levels of the x-vector model (teacher network) to train\nsmall-footprint student networks. Results indicate the usefulness of\nframe-level information, with the student models being 85%-91% smaller than\ntheir teacher, depending on the size of the teacher embeddings. Concatenation\nof teacher embeddings results in student networks that reach comparable\nperformance along with the teacher while utilizing a 75% relative size\nreduction from the teacher. The findings and analogies are furthered to other\nx-vector variants.\n","authors":["Xuechen Liu","Md Sahidullah","Tomi Kinnunen"],"pdf_url":"https://arxiv.org/pdf/2303.01125v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01117v1","updated":"2023-03-02T10:00:37Z","published":"2023-03-02T10:00:37Z","title":"In all LikelihoodS: How to Reliably Select Pseudo-Labeled Data for\n  Self-Training in Semi-Supervised Learning","summary":"  Self-training is a simple yet effective method within semi-supervised\nlearning. The idea is to iteratively enhance training data by adding\npseudo-labeled data. Its generalization performance heavily depends on the\nselection of these pseudo-labeled data (PLS). In this paper, we aim at\nrendering PLS more robust towards the involved modeling assumptions. To this\nend, we propose to select pseudo-labeled data that maximize a multi-objective\nutility function. The latter is constructed to account for different sources of\nuncertainty, three of which we discuss in more detail: model selection,\naccumulation of errors and covariate shift. In the absence of second-order\ninformation on such uncertainties, we furthermore consider the generic approach\nof the generalized Bayesian alpha-cut updating rule for credal sets. As a\npractical proof of concept, we spotlight the application of three of our robust\nextensions on simulated and real-world data. Results suggest that in particular\nrobustness w.r.t. model choice can lead to substantial accuracy gains.\n","authors":["Julian Rodemann","Christoph Jansen","Georg Schollmeyer","Thomas Augustin"],"pdf_url":"https://arxiv.org/pdf/2303.01117v1.pdf","comment":"9 pages, 1 figure, under review"},{"id":"http://arxiv.org/abs/2303.01112v1","updated":"2023-03-02T09:47:28Z","published":"2023-03-02T09:47:28Z","title":"Visual Atoms: Pre-training Vision Transformers with Sinusoidal Waves","summary":"  Formula-driven supervised learning (FDSL) has been shown to be an effective\nmethod for pre-training vision transformers, where ExFractalDB-21k was shown to\nexceed the pre-training effect of ImageNet-21k. These studies also indicate\nthat contours mattered more than textures when pre-training vision\ntransformers. However, the lack of a systematic investigation as to why these\ncontour-oriented synthetic datasets can achieve the same accuracy as real\ndatasets leaves much room for skepticism. In the present work, we develop a\nnovel methodology based on circular harmonics for systematically investigating\nthe design space of contour-oriented synthetic datasets. This allows us to\nefficiently search the optimal range of FDSL parameters and maximize the\nvariety of synthetic images in the dataset, which we found to be a critical\nfactor. When the resulting new dataset VisualAtom-21k is used for pre-training\nViT-Base, the top-1 accuracy reached 83.7% when fine-tuning on ImageNet-1k.\nThis is close to the top-1 accuracy (84.2%) achieved by JFT-300M pre-training,\nwhile the number of images is 1/14. Unlike JFT-300M which is a static dataset,\nthe quality of synthetic datasets will continue to improve, and the current\nwork is a testament to this possibility. FDSL is also free of the common issues\nassociated with real images, e.g. privacy/copyright issues, labeling\ncosts/errors, and ethical biases.\n","authors":["Sora Takashima","Ryo Hayamizu","Nakamasa Inoue","Hirokatsu Kataoka","Rio Yokota"],"pdf_url":"https://arxiv.org/pdf/2303.01112v1.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2303.01111v1","updated":"2023-03-02T09:47:14Z","published":"2023-03-02T09:47:14Z","title":"Predicting Stock Price Movement as an Image Classification Problem","summary":"  The paper studies intraday price movement of stocks that is considered as an\nimage classification problem. Using a CNN-based model we make a compelling case\nfor the high-level relationship between the first hour of trading and the\nclose. The algorithm managed to adequately separate between the two opposing\nclasses and investing according to the algorithm's predictions outperformed all\nalternative constructs but the theoretical maximum. To support the thesis, we\nran several additional tests. The findings in the paper highlight the\nsuitability of computer vision techniques for studying financial markets and in\nparticular prediction of stock price movements.\n","authors":["Matej Steinbacher"],"pdf_url":"https://arxiv.org/pdf/2303.01111v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.07766v2","updated":"2023-03-02T09:43:58Z","published":"2022-06-15T19:04:02Z","title":"Pareto Invariant Risk Minimization: Towards Mitigating the Optimization\n  Dilemma in Out-of-Distribution Generalization","summary":"  Recently, there has been a growing surge of interest in enabling machine\nlearning systems to generalize well to Out-of-Distribution (OOD) data. Most\nefforts are devoted to advancing optimization objectives that regularize models\nto capture the underlying invariance; however, there often are compromises in\nthe optimization process of these OOD objectives: i) Many OOD objectives have\nto be relaxed as penalty terms of Empirical Risk Minimization (ERM) for the\nease of optimization, while the relaxed forms can weaken the robustness of the\noriginal objective; ii) The penalty terms also require careful tuning of the\npenalty weights due to the intrinsic conflicts between ERM and OOD objectives.\nConsequently, these compromises could easily lead to suboptimal performance of\neither the ERM or OOD objective. To address these issues, we introduce a\nmulti-objective optimization (MOO) perspective to understand the OOD\noptimization process, and propose a new optimization scheme called PAreto\nInvariant Risk Minimization (PAIR). PAIR improves the robustness of OOD\nobjectives by cooperatively optimizing with other OOD objectives, thereby\nbridging the gaps caused by the relaxations. Then PAIR approaches a Pareto\noptimal solution that trades off the ERM and OOD objectives properly. Extensive\nexperiments on challenging benchmarks, WILDS, show that PAIR alleviates the\ncompromises and yields top OOD performances.\n","authors":["Yongqiang Chen","Kaiwen Zhou","Yatao Bian","Binghui Xie","Bingzhe Wu","Yonggang Zhang","Kaili Ma","Han Yang","Peilin Zhao","Bo Han","James Cheng"],"pdf_url":"https://arxiv.org/pdf/2206.07766v2.pdf","comment":"ICLR 2023, 50 pages, 58 figures"},{"id":"http://arxiv.org/abs/2210.14648v3","updated":"2023-03-02T09:42:58Z","published":"2022-10-26T11:49:30Z","title":"Masked Modeling Duo: Learning Representations by Encouraging Both\n  Networks to Model the Input","summary":"  Masked Autoencoders is a simple yet powerful self-supervised learning method.\nHowever, it learns representations indirectly by reconstructing masked input\npatches. Several methods learn representations directly by predicting\nrepresentations of masked patches; however, we think using all patches to\nencode training signal representations is suboptimal. We propose a new method,\nMasked Modeling Duo (M2D), that learns representations directly while obtaining\ntraining signals using only masked patches. In the M2D, the online network\nencodes visible patches and predicts masked patch representations, and the\ntarget network, a momentum encoder, encodes masked patches. To better predict\ntarget representations, the online network should model the input well, while\nthe target network should also model it well to agree with online predictions.\nThen the learned representations should better model the input. We validated\nthe M2D by learning general-purpose audio representations, and M2D set new\nstate-of-the-art performance on tasks such as UrbanSound8K, VoxCeleb1,\nAudioSet20K, GTZAN, and SpeechCommandsV2. We additionally validate the\neffectiveness of M2D for images using ImageNet-1K in the appendix.\n","authors":["Daisuke Niizumi","Daiki Takeuchi","Yasunori Ohishi","Noboru Harada","Kunio Kashino"],"pdf_url":"https://arxiv.org/pdf/2210.14648v3.pdf","comment":"6 pages, 3 figures, and 6 tables. To appear at ICASSP2023"},{"id":"http://arxiv.org/abs/2302.13259v3","updated":"2023-03-02T09:40:17Z","published":"2023-02-26T08:12:28Z","title":"Can we avoid Double Descent in Deep Neural Networks?","summary":"  Finding the optimal size of deep learning models is very actual and of broad\nimpact, especially in energy-saving schemes. Very recently, an unexpected\nphenomenon, the ``double descent'', has caught the attention of the deep\nlearning community. As the model's size grows, the performance gets first\nworse, and then goes back to improving. It raises serious questions about the\noptimal model's size to maintain high generalization: the model needs to be\nsufficiently over-parametrized, but adding too many parameters wastes training\nresources. Is it possible to find, in an efficient way, the best trade-off? Our\nwork shows that the double descent phenomenon is potentially avoidable with\nproper conditioning of the learning problem, but a final answer is yet to be\nfound. We empirically observe that there is hope to dodge the double descent in\ncomplex scenarios with proper regularization, as a simple $\\ell_2$\nregularization is already positively contributing to such a perspective.\n","authors":["Victor Quétu","Enzo Tartaglione"],"pdf_url":"https://arxiv.org/pdf/2302.13259v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01105v1","updated":"2023-03-02T09:37:56Z","published":"2023-03-02T09:37:56Z","title":"Evidence-empowered Transfer Learning for Alzheimer's Disease","summary":"  Transfer learning has been widely utilized to mitigate the data scarcity\nproblem in the field of Alzheimer's disease (AD). Conventional transfer\nlearning relies on re-using models trained on AD-irrelevant tasks such as\nnatural image classification. However, it often leads to negative transfer due\nto the discrepancy between the non-medical source and target medical domains.\nTo address this, we present evidence-empowered transfer learning for AD\ndiagnosis. Unlike conventional approaches, we leverage an AD-relevant auxiliary\ntask, namely morphological change prediction, without requiring additional MRI\ndata. In this auxiliary task, the diagnosis model learns the evidential and\ntransferable knowledge from morphological features in MRI scans. Experimental\nresults demonstrate that our framework is not only effective in improving\ndetection performance regardless of model capacity, but also more\ndata-efficient and faithful.\n","authors":["Kai Tzu-iunn Ong","Hana Kim","Minjin Kim","Jinseong Jang","Beomseok Sohn","Yoon Seong Choi","Dosik Hwang","Seong Jae Hwang","Jinyoung Yeo"],"pdf_url":"https://arxiv.org/pdf/2303.01105v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.00743v4","updated":"2023-03-02T09:31:50Z","published":"2021-11-01T07:39:38Z","title":"Towards the Generalization of Contrastive Self-Supervised Learning","summary":"  Recently, self-supervised learning has attracted great attention, since it\nonly requires unlabeled data for model training. Contrastive learning is one\npopular method for self-supervised learning and has achieved promising\nempirical performance. However, the theoretical understanding of its\ngeneralization ability is still limited. To this end, we define a kind of\n$(\\sigma,\\delta)$-measure to mathematically quantify the data augmentation, and\nthen provide an upper bound of the downstream classification error rate based\non the measure. It reveals that the generalization ability of contrastive\nself-supervised learning is related to three key factors: alignment of positive\nsamples, divergence of class centers, and concentration of augmented data. The\nfirst two factors are properties of learned representations, while the third\none is determined by pre-defined data augmentation. We further investigate two\ncanonical contrastive losses, InfoNCE and cross-correlation, to show how they\nprovably achieve the first two factors. Moreover, we conduct experiments to\nstudy the third factor, and observe a strong correlation between downstream\nperformance and the concentration of augmented data.\n","authors":["Weiran Huang","Mingyang Yi","Xuyang Zhao","Zihao Jiang"],"pdf_url":"https://arxiv.org/pdf/2111.00743v4.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2211.10445v3","updated":"2023-03-02T09:28:25Z","published":"2022-11-18T14:59:42Z","title":"Building a Subspace of Policies for Scalable Continual Learning","summary":"  The ability to continuously acquire new knowledge and skills is crucial for\nautonomous agents. Existing methods are typically based on either fixed-size\nmodels that struggle to learn a large number of diverse behaviors, or\ngrowing-size models that scale poorly with the number of tasks. In this work,\nwe aim to strike a better balance between an agent's size and performance by\ndesigning a method that grows adaptively depending on the task sequence. We\nintroduce Continual Subspace of Policies (CSP), a new approach that\nincrementally builds a subspace of policies for training a reinforcement\nlearning agent on a sequence of tasks. The subspace's high expressivity allows\nCSP to perform well for many different tasks while growing sublinearly with the\nnumber of tasks. Our method does not suffer from forgetting and displays\npositive transfer to new tasks. CSP outperforms a number of popular baselines\non a wide range of scenarios from two challenging domains, Brax (locomotion)\nand Continual World (manipulation).\n","authors":["Jean-Baptiste Gaya","Thang Doan","Lucas Caccia","Laure Soulier","Ludovic Denoyer","Roberta Raileanu"],"pdf_url":"https://arxiv.org/pdf/2211.10445v3.pdf","comment":"Accepted at ICLR2023 (notable-top-25%). website:\n  https://continual-subspace-policies-streamlit-app-gofujp.streamlit.app/ code:\n  https://github.com/facebookresearch/salina/tree/main/salina_cl"},{"id":"http://arxiv.org/abs/2303.01092v1","updated":"2023-03-02T09:26:20Z","published":"2023-03-02T09:26:20Z","title":"ArCL: Enhancing Contrastive Learning with Augmentation-Robust\n  Representations","summary":"  Self-Supervised Learning (SSL) is a paradigm that leverages unlabeled data\nfor model training. Empirical studies show that SSL can achieve promising\nperformance in distribution shift scenarios, where the downstream and training\ndistributions differ. However, the theoretical understanding of its\ntransferability remains limited. In this paper, we develop a theoretical\nframework to analyze the transferability of self-supervised contrastive\nlearning, by investigating the impact of data augmentation on it. Our results\nreveal that the downstream performance of contrastive learning depends largely\non the choice of data augmentation. Moreover, we show that contrastive learning\nfails to learn domain-invariant features, which limits its transferability.\nBased on these theoretical insights, we propose a novel method called\nAugmentation-robust Contrastive Learning (ArCL), which guarantees to learn\ndomain-invariant features and can be easily integrated with existing\ncontrastive learning algorithms. We conduct experiments on several datasets and\nshow that ArCL significantly improves the transferability of contrastive\nlearning.\n","authors":["Xuyang Zhao","Tianqi Du","Yisen Wang","Jun Yao","Weiran Huang"],"pdf_url":"https://arxiv.org/pdf/2303.01092v1.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2302.13417v2","updated":"2023-03-02T09:13:05Z","published":"2023-02-26T22:10:23Z","title":"Training neural networks with structured noise improves classification\n  and generalization","summary":"  The beneficial role of noise in learning is nowadays a consolidated concept\nin the field of artificial neural networks. The training-with-noise algorithm\nproposed by Gardner and collaborators is an emblematic example of a noise\ninjection procedure in recurrent networks. We show how adding structure into\nnoisy training data can substantially improve memory performance, allowing to\napproach perfect classification and maximal basins of attraction. We also prove\nthat the so-called unlearning rule coincides with the training-with-noise\nalgorithm when noise is maximal and data are fixed points of the network\ndynamics. Moreover, a sampling scheme for optimal noisy data is proposed and\nimplemented to outperform both the training-with-noise and the unlearning\nprocedures.\n","authors":["Marco Benedetti","Enrico Ventura"],"pdf_url":"https://arxiv.org/pdf/2302.13417v2.pdf","comment":"20 pages, 18 figures, main text and appendices"},{"id":"http://arxiv.org/abs/2206.04624v3","updated":"2023-03-02T09:11:34Z","published":"2022-06-09T17:16:43Z","title":"Factuality Enhanced Language Models for Open-Ended Text Generation","summary":"  Pretrained language models (LMs) are susceptible to generate text with\nnonfactual information. In this work, we measure and improve the factual\naccuracy of large-scale LMs for open-ended text generation. We design the\nFactualityPrompts test set and metrics to measure the factuality of LM\ngenerations. Based on that, we study the factual accuracy of LMs with parameter\nsizes ranging from 126M to 530B. Interestingly, we find that larger LMs are\nmore factual than smaller ones, although a previous study suggests that larger\nLMs can be less truthful in terms of misconceptions. In addition, popular\nsampling algorithms (e.g., top-p) in open-ended text generation can harm the\nfactuality due to the ''uniform randomness'' introduced at every sampling step.\nWe propose the factual-nucleus sampling algorithm that dynamically adapts the\nrandomness to improve the factuality of generation while maintaining quality.\nFurthermore, we analyze the inefficiencies of the standard training method in\nlearning correct associations between entities from factual text corpus (e.g.,\nWikipedia). We propose a factuality-enhanced training method that uses\nTopicPrefix for better awareness of facts and sentence completion as the\ntraining objective, which can vastly reduce the factual errors. We release our\ncode and FactualityPrompts benchmark at:\nhttps://github.com/nayeon7lee/FactualityPrompt.\n","authors":["Nayeon Lee","Wei Ping","Peng Xu","Mostofa Patwary","Pascale Fung","Mohammad Shoeybi","Bryan Catanzaro"],"pdf_url":"https://arxiv.org/pdf/2206.04624v3.pdf","comment":"NeurIPS 2022"},{"id":"http://arxiv.org/abs/2212.09748v2","updated":"2023-03-02T09:06:55Z","published":"2022-12-19T18:59:58Z","title":"Scalable Diffusion Models with Transformers","summary":"  We explore a new class of diffusion models based on the transformer\narchitecture. We train latent diffusion models of images, replacing the\ncommonly-used U-Net backbone with a transformer that operates on latent\npatches. We analyze the scalability of our Diffusion Transformers (DiTs)\nthrough the lens of forward pass complexity as measured by Gflops. We find that\nDiTs with higher Gflops -- through increased transformer depth/width or\nincreased number of input tokens -- consistently have lower FID. In addition to\npossessing good scalability properties, our largest DiT-XL/2 models outperform\nall prior diffusion models on the class-conditional ImageNet 512x512 and\n256x256 benchmarks, achieving a state-of-the-art FID of 2.27 on the latter.\n","authors":["William Peebles","Saining Xie"],"pdf_url":"https://arxiv.org/pdf/2212.09748v2.pdf","comment":"Code, project page and videos available at\n  https://www.wpeebles.com/DiT"},{"id":"http://arxiv.org/abs/2303.01082v1","updated":"2023-03-02T09:04:35Z","published":"2023-03-02T09:04:35Z","title":"GBMST: An Efficient Minimum Spanning Tree Clustering Based on\n  Granular-Ball","summary":"  Most of the existing clustering methods are based on a single granularity of\ninformation, such as the distance and density of each data. This most\nfine-grained based approach is usually inefficient and susceptible to noise.\nTherefore, we propose a clustering algorithm that combines multi-granularity\nGranular-Ball and minimum spanning tree (MST). We construct coarsegrained\ngranular-balls, and then use granular-balls and MST to implement the clustering\nmethod based on \"large-scale priority\", which can greatly avoid the influence\nof outliers and accelerate the construction process of MST. Experimental\nresults on several data sets demonstrate the power of the algorithm. All codes\nhave been released at https://github.com/xjnine/GBMST.\n","authors":["Jiang Xie","Shuyin Xia","Guoyin Wang","Xinbo Gao"],"pdf_url":"https://arxiv.org/pdf/2303.01082v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01076v1","updated":"2023-03-02T08:57:35Z","published":"2023-03-02T08:57:35Z","title":"Hallucinated Adversarial Control for Conservative Offline Policy\n  Evaluation","summary":"  We study the problem of conservative off-policy evaluation (COPE) where given\nan offline dataset of environment interactions, collected by other agents, we\nseek to obtain a (tight) lower bound on a policy's performance. This is crucial\nwhen deciding whether a given policy satisfies certain minimal\nperformance/safety criteria before it can be deployed in the real world. To\nthis end, we introduce HAMBO, which builds on an uncertainty-aware learned\nmodel of the transition dynamics. To form a conservative estimate of the\npolicy's performance, HAMBO hallucinates worst-case trajectories that the\npolicy may take, within the margin of the models' epistemic confidence regions.\nWe prove that the resulting COPE estimates are valid lower bounds, and, under\nregularity conditions, show their convergence to the true expected return.\nFinally, we discuss scalable variants of our approach based on Bayesian Neural\nNetworks and empirically demonstrate that they yield reliable and tight lower\nbounds in various continuous control environments.\n","authors":["Jonas Rothfuss","Bhavya Sukhija","Tobias Birchler","Parnian Kassraie","Andreas Krause"],"pdf_url":"https://arxiv.org/pdf/2303.01076v1.pdf","comment":"24 pages"},{"id":"http://arxiv.org/abs/2303.01074v1","updated":"2023-03-02T08:56:12Z","published":"2023-03-02T08:56:12Z","title":"Learning not to Regret","summary":"  Regret minimization is a key component of many algorithms for finding Nash\nequilibria in imperfect-information games. To scale to games that cannot fit in\nmemory, we can use search with value functions. However, calling the value\nfunctions repeatedly in search can be expensive. Therefore, it is desirable to\nminimize regret in the search tree as fast as possible. We propose to\naccelerate the regret minimization by introducing a general ``learning not to\nregret'' framework, where we meta-learn the regret minimizer. The resulting\nalgorithm is guaranteed to minimize regret in arbitrary settings and is\n(meta)-learned to converge fast on a selected distribution of games. Our\nexperiments show that meta-learned algorithms converge substantially faster\nthan prior regret minimization algorithms.\n","authors":["David Sychrovsky","Michal Sustr","Elnaz Davoodi","Marc Lanctot","Martin Schmid"],"pdf_url":"https://arxiv.org/pdf/2303.01074v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01070v1","updated":"2023-03-02T08:45:49Z","published":"2023-03-02T08:45:49Z","title":"GHQ: Grouped Hybrid Q Learning for Heterogeneous Cooperative Multi-agent\n  Reinforcement Learning","summary":"  Previous deep multi-agent reinforcement learning (MARL) algorithms have\nachieved impressive results, typically in homogeneous scenarios. However,\nheterogeneous scenarios are also very common and usually harder to solve. In\nthis paper, we mainly discuss cooperative heterogeneous MARL problems in\nStarcraft Multi-Agent Challenges (SMAC) environment. We firstly define and\ndescribe the heterogeneous problems in SMAC. In order to comprehensively reveal\nand study the problem, we make new maps added to the original SMAC maps. We\nfind that baseline algorithms fail to perform well in those heterogeneous maps.\nTo address this issue, we propose the Grouped Individual-Global-Max Consistency\n(GIGM) and a novel MARL algorithm, Grouped Hybrid Q Learning (GHQ). GHQ\nseparates agents into several groups and keeps individual parameters for each\ngroup, along with a novel hybrid structure for factorization. To enhance\ncoordination between groups, we maximize the Inter-group Mutual Information\n(IGMI) between groups' trajectories. Experiments on original and new\nheterogeneous maps show the fabulous performance of GHQ compared to other\nstate-of-the-art algorithms.\n","authors":["Xiaoyang Yu","Youfang Lin","Xiangsen Wang","Sheng Han","Kai Lv"],"pdf_url":"https://arxiv.org/pdf/2303.01070v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01069v1","updated":"2023-03-02T08:43:40Z","published":"2023-03-02T08:43:40Z","title":"Implicit Neural Representations for Modeling of Abdominal Aortic\n  Aneurysm Progression","summary":"  Abdominal aortic aneurysms (AAAs) are progressive dilatations of the\nabdominal aorta that, if left untreated, can rupture with lethal consequences.\nImaging-based patient monitoring is required to select patients eligible for\nsurgical repair. In this work, we present a model based on implicit neural\nrepresentations (INRs) to model AAA progression. We represent the AAA wall over\ntime as the zero-level set of a signed distance function (SDF), estimated by a\nmultilayer perception that operates on space and time. We optimize this INR\nusing automatically extracted segmentation masks in longitudinal CT data. This\nnetwork is conditioned on spatiotemporal coordinates and represents the AAA\nsurface at any desired resolution at any moment in time. Using regularization\non spatial and temporal gradients of the SDF, we ensure proper interpolation of\nthe AAA shape. We demonstrate the network's ability to produce AAA\ninterpolations with average surface distances ranging between 0.72 and 2.52 mm\nfrom images acquired at highly irregular intervals. The results indicate that\nour model can accurately interpolate AAA shapes over time, with potential\nclinical value for a more personalised assessment of AAA progression.\n","authors":["Dieuwertje Alblas","Marieke Hofman","Christoph Brune","Kak Khee Yeung","Jelmer M. Wolterink"],"pdf_url":"https://arxiv.org/pdf/2303.01069v1.pdf","comment":"FIMH 2023 (submitted)"},{"id":"http://arxiv.org/abs/2303.01068v1","updated":"2023-03-02T08:43:30Z","published":"2023-03-02T08:43:30Z","title":"Targeted Adversarial Attacks against Neural Machine Translation","summary":"  Neural Machine Translation (NMT) systems are used in various applications.\nHowever, it has been shown that they are vulnerable to very small perturbations\nof their inputs, known as adversarial attacks. In this paper, we propose a new\ntargeted adversarial attack against NMT models. In particular, our goal is to\ninsert a predefined target keyword into the translation of the adversarial\nsentence while maintaining similarity between the original sentence and the\nperturbed one in the source domain. To this aim, we propose an optimization\nproblem, including an adversarial loss term and a similarity term. We use\ngradient projection in the embedding space to craft an adversarial sentence.\nExperimental results show that our attack outperforms Seq2Sick, the other\ntargeted adversarial attack against NMT models, in terms of success rate and\ndecrease in translation quality. Our attack succeeds in inserting a keyword\ninto the translation for more than 75% of sentences while similarity with the\noriginal sentence stays preserved.\n","authors":["Sahar Sadrizadeh","AmirHossein Dabiri Aghdam","Ljiljana Dolamic","Pascal Frossard"],"pdf_url":"https://arxiv.org/pdf/2303.01068v1.pdf","comment":"ICASSP 2023, Code available at:\n  http://github.com/sssadrizadeh/NMT-targeted-attack"},{"id":"http://arxiv.org/abs/2207.13856v2","updated":"2023-03-02T08:38:26Z","published":"2022-07-28T02:15:47Z","title":"Imbalanced Semi-supervised Learning with Bias Adaptive Classifier","summary":"  Pseudo-labeling has proven to be a promising semi-supervised learning (SSL)\nparadigm. Existing pseudo-labeling methods commonly assume that the class\ndistributions of training data are balanced. However, such an assumption is far\nfrom realistic scenarios and thus severely limits the performance of current\npseudo-labeling methods under the context of class-imbalance. To alleviate this\nproblem, we design a bias adaptive classifier that targets the imbalanced SSL\nsetups. The core idea is to automatically assimilate the training bias caused\nby class imbalance via the bias adaptive classifier, which is composed of a\nnovel bias attractor and the original linear classifier. The bias attractor is\ndesigned as a light-weight residual network and optimized through a bi-level\nlearning framework. Such a learning strategy enables the bias adaptive\nclassifier to fit imbalanced training data, while the linear classifier can\nprovide unbiased label prediction for each class. We conduct extensive\nexperiments under various imbalanced semi-supervised setups, and the results\ndemonstrate that our method can be applied to different pseudo-labeling models\nand is superior to current state-of-the-art methods.\n","authors":["Renzhen Wang","Xixi Jia","Quanziang Wang","Yichen Wu","Deyu Meng"],"pdf_url":"https://arxiv.org/pdf/2207.13856v2.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2302.12095v3","updated":"2023-03-02T08:33:04Z","published":"2023-02-22T11:01:20Z","title":"On the Robustness of ChatGPT: An Adversarial and Out-of-distribution\n  Perspective","summary":"  ChatGPT is a recent chatbot service released by OpenAI and is receiving\nincreasing attention over the past few months. While evaluations of various\naspects of ChatGPT have been done, its robustness, i.e., the performance to\nunexpected inputs, is still unclear to the public. Robustness is of particular\nconcern in responsible AI, especially for safety-critical applications. In this\npaper, we conduct a thorough evaluation of the robustness of ChatGPT from the\nadversarial and out-of-distribution (OOD) perspective. To do so, we employ the\nAdvGLUE and ANLI benchmarks to assess adversarial robustness and the Flipkart\nreview and DDXPlus medical diagnosis datasets for OOD evaluation. We select\nseveral popular foundation models as baselines. Results show that ChatGPT shows\nconsistent advantages on most adversarial and OOD classification and\ntranslation tasks. However, the absolute performance is far from perfection,\nwhich suggests that adversarial and OOD robustness remains a significant threat\nto foundation models. Moreover, ChatGPT shows astounding performance in\nunderstanding dialogue-related texts and we find that it tends to provide\ninformal suggestions for medical tasks instead of definitive answers. Finally,\nwe present in-depth discussions of possible research directions.\n","authors":["Jindong Wang","Xixu Hu","Wenxin Hou","Hao Chen","Runkai Zheng","Yidong Wang","Linyi Yang","Haojun Huang","Wei Ye","Xiubo Geng","Binxin Jiao","Yue Zhang","Xing Xie"],"pdf_url":"https://arxiv.org/pdf/2302.12095v3.pdf","comment":"Technical report; code is at:\n  https://github.com/microsoft/robustlearn"},{"id":"http://arxiv.org/abs/2205.14592v2","updated":"2023-03-02T08:25:36Z","published":"2022-05-29T07:44:09Z","title":"GBC: An Efficient and Adaptive Clustering Algorithm Based on\n  Granular-Ball","summary":"  Existing clustering methods are based on a single granularity of information,\nsuch as the distance and density of each data. This most fine-grained based\napproach is usually inefficient and susceptible to noise. Inspired by adaptive\nprocess of granular-ball division and differentiation, we present a novel\nclustering approach that retains the speed and efficiency of K-means clustering\nwhile out-performing time-tested density clustering approaches widely used in\nindustry today. Our simple, robust, adaptive granular-ball clustering method\ncan efficiently recognize clusters with unknown and complex shapes without the\nuse of extra parameters. Moreover, the proposed method provides an efficient,\nadaptive way to depict the world, and will promote the research and development\nof adaptive and efficient AI technologies, especially density computing models,\nand improve the efficiency of many existing clustering methods.\n","authors":["Shuyin Xia","Jiang Xie","Guoyin Wang"],"pdf_url":"https://arxiv.org/pdf/2205.14592v2.pdf","comment":"5 pages, 1 figures"},{"id":"http://arxiv.org/abs/2303.01055v1","updated":"2023-03-02T08:24:27Z","published":"2023-03-02T08:24:27Z","title":"Physics-informed neural networks for solving forward and inverse\n  problems in complex beam systems","summary":"  This paper proposes a new framework using physics-informed neural networks\n(PINNs) to simulate complex structural systems that consist of single and\ndouble beams based on Euler-Bernoulli and Timoshenko theory, where the double\nbeams are connected with a Winkler foundation. In particular, forward and\ninverse problems for the Euler-Bernoulli and Timoshenko partial differential\nequations (PDEs) are solved using nondimensional equations with the\nphysics-informed loss function. Higher-order complex beam PDEs are efficiently\nsolved for forward problems to compute the transverse displacements and\ncross-sectional rotations with less than 1e-3 percent error. Furthermore,\ninverse problems are robustly solved to determine the unknown dimensionless\nmodel parameters and applied force in the entire space-time domain, even in the\ncase of noisy data. The results suggest that PINNs are a promising strategy for\nsolving problems in engineering structures and machines involving beam systems.\n","authors":["Taniya Kapoor","Hongrui Wang","Alfredo Nunez","Rolf Dollevoet"],"pdf_url":"https://arxiv.org/pdf/2303.01055v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01052v1","updated":"2023-03-02T08:18:22Z","published":"2023-03-02T08:18:22Z","title":"Demystifying Causal Features on Adversarial Examples and Causal\n  Inoculation for Robust Network by Adversarial Instrumental Variable\n  Regression","summary":"  The origin of adversarial examples is still inexplicable in research fields,\nand it arouses arguments from various viewpoints, albeit comprehensive\ninvestigations. In this paper, we propose a way of delving into the unexpected\nvulnerability in adversarially trained networks from a causal perspective,\nnamely adversarial instrumental variable (IV) regression. By deploying it, we\nestimate the causal relation of adversarial prediction under an unbiased\nenvironment dissociated from unknown confounders. Our approach aims to\ndemystify inherent causal features on adversarial examples by leveraging a\nzero-sum optimization game between a casual feature estimator (i.e., hypothesis\nmodel) and worst-case counterfactuals (i.e., test function) disturbing to find\ncausal features. Through extensive analyses, we demonstrate that the estimated\ncausal features are highly related to the correct prediction for adversarial\nrobustness, and the counterfactuals exhibit extreme features significantly\ndeviating from the correct prediction. In addition, we present how to\neffectively inoculate CAusal FEatures (CAFE) into defense networks for\nimproving adversarial robustness.\n","authors":["Junho Kim. Byung-Kwan Lee","Yong Man Ro"],"pdf_url":"https://arxiv.org/pdf/2303.01052v1.pdf","comment":"Accepted in CVPR 2023"},{"id":"http://arxiv.org/abs/2209.15278v3","updated":"2023-03-02T08:08:49Z","published":"2022-09-30T07:31:49Z","title":"Rethinking skip connection model as a learnable Markov chain","summary":"  Over past few years afterward the birth of ResNet, skip connection has become\nthe defacto standard for the design of modern architectures due to its\nwidespread adoption, easy optimization and proven performance. Prior work has\nexplained the effectiveness of the skip connection mechanism from different\nperspectives. In this work, we deep dive into the model's behaviors with skip\nconnections which can be formulated as a learnable Markov chain. An efficient\nMarkov chain is preferred as it always maps the input data to the target domain\nin a better way. However, while a model is explained as a Markov chain, it is\nnot guaranteed to be optimized following an efficient Markov chain by existing\nSGD-based optimizers which are prone to get trapped in local optimal points. In\norder to towards a more efficient Markov chain, we propose a simple routine of\npenal connection to make any residual-like model become a learnable Markov\nchain. Aside from that, the penal connection can also be viewed as a particular\nmodel regularization and can be easily implemented with one line of code in the\nmost popular deep learning frameworks~\\footnote{Source code:\n\\url{https://github.com/densechen/penal-connection}}. The encouraging\nexperimental results in multi-modal translation and image recognition\nempirically confirm our conjecture of the learnable Markov chain view and\ndemonstrate the superiority of the proposed penal connection.\n","authors":["Dengsheng Chen","Jie Hu","Wenwen Qiang","Xiaoming Wei","Enhua Wu"],"pdf_url":"https://arxiv.org/pdf/2209.15278v3.pdf","comment":"12 pages, 4 figures"},{"id":"http://arxiv.org/abs/2303.00409v2","updated":"2023-03-02T08:04:03Z","published":"2023-03-01T11:00:20Z","title":"RePAD2: Real-Time, Lightweight, and Adaptive Anomaly Detection for\n  Open-Ended Time Series","summary":"  An open-ended time series refers to a series of data points indexed in time\norder without an end. Such a time series can be found everywhere due to the\nprevalence of Internet of Things. Providing lightweight and real-time anomaly\ndetection for open-ended time series is highly desirable to industry and\norganizations since it allows immediate response and avoids potential financial\nloss. In the last few years, several real-time time series anomaly detection\napproaches have been introduced. However, they might exhaust system resources\nwhen they are applied to open-ended time series for a long time. To address\nthis issue, in this paper we propose RePAD2, a lightweight real-time anomaly\ndetection approach for open-ended time series by improving its predecessor\nRePAD, which is one of the state-of-the-art anomaly detection approaches. We\nconducted a series of experiments to compare RePAD2 with RePAD and another\nsimilar detection approach based on real-world time series datasets, and\ndemonstrated that RePAD2 can address the mentioned resource exhaustion issue\nwhile offering comparable detection accuracy and slightly less time\nconsumption.\n","authors":["Ming-Chang Lee","Jia-Chun Lin"],"pdf_url":"https://arxiv.org/pdf/2303.00409v2.pdf","comment":"10 pages, 11 figures, and 10 tables, the paper is accepted by 8th\n  International Conference on Internet of Things, Big Data and Security (IoTBDS\n  2023)"},{"id":"http://arxiv.org/abs/2303.00351v2","updated":"2023-03-02T07:59:22Z","published":"2023-03-01T09:27:08Z","title":"An end-to-end SE(3)-equivariant segmentation network","summary":"  Convolutional neural networks (CNNs) allow for parameter sharing and\ntranslational equivariance by using convolutional kernels in their linear\nlayers. By restricting these kernels to be SO(3)-steerable, CNNs can further\nimprove parameter sharing and equivariance. These equivariant convolutional\nlayers have several advantages over standard convolutional layers, including\nincreased robustness to unseen poses, smaller network size, and improved sample\nefficiency. Despite this, most segmentation networks used in medical image\nanalysis continue to rely on standard convolutional kernels. In this paper, we\npresent a new family of segmentation networks that use equivariant voxel\nconvolutions based on spherical harmonics, as well as equivariant pooling and\nnormalization operations. These SE(3)-equivariant volumetric segmentation\nnetworks, which are robust to data poses not seen during training, do not\nrequire rotation-based data augmentation during training. In addition, we\ndemonstrate improved segmentation performance in MRI brain tumor and healthy\nbrain structure segmentation tasks, with enhanced robustness to reduced amounts\nof training data and improved parameter efficiency. Code to reproduce our\nresults, and to implement the equivariant segmentation networks for other tasks\nis available at http://github.com/SCAN-NRAD/e3nn_Unet\n","authors":["Ivan Diaz","Mario Geiger","Richard Iain McKinley"],"pdf_url":"https://arxiv.org/pdf/2303.00351v2.pdf","comment":"19 pages, 10 figures, submitted to the Journal of Machine Learning\n  for Biomedical Imaging"},{"id":"http://arxiv.org/abs/2210.11466v2","updated":"2023-03-02T07:56:13Z","published":"2022-10-20T17:59:15Z","title":"Surgical Fine-Tuning Improves Adaptation to Distribution Shifts","summary":"  A common approach to transfer learning under distribution shift is to\nfine-tune the last few layers of a pre-trained model, preserving learned\nfeatures while also adapting to the new task. This paper shows that in such\nsettings, selectively fine-tuning a subset of layers (which we term surgical\nfine-tuning) matches or outperforms commonly used fine-tuning approaches.\nMoreover, the type of distribution shift influences which subset is more\neffective to tune: for example, for image corruptions, fine-tuning only the\nfirst few layers works best. We validate our findings systematically across\nseven real-world data tasks spanning three types of distribution shifts.\nTheoretically, we prove that for two-layer neural networks in an idealized\nsetting, first-layer tuning can outperform fine-tuning all layers. Intuitively,\nfine-tuning more parameters on a small target dataset can cause information\nlearned during pre-training to be forgotten, and the relevant information\ndepends on the type of shift.\n","authors":["Yoonho Lee","Annie S. Chen","Fahim Tajwar","Ananya Kumar","Huaxiu Yao","Percy Liang","Chelsea Finn"],"pdf_url":"https://arxiv.org/pdf/2210.11466v2.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01042v1","updated":"2023-03-02T07:55:52Z","published":"2023-03-02T07:55:52Z","title":"Reinforcement Learning Guided Multi-Objective Exam Paper Generation","summary":"  To reduce the repetitive and complex work of instructors, exam paper\ngeneration (EPG) technique has become a salient topic in the intelligent\neducation field, which targets at generating high-quality exam paper\nautomatically according to instructor-specified assessment criteria. The\ncurrent advances utilize the ability of heuristic algorithms to optimize\nseveral well-known objective constraints, such as difficulty degree, number of\nquestions, etc., for producing optimal solutions. However, in real scenarios,\nconsidering other equally relevant objectives (e.g., distribution of exam\nscores, skill coverage) is extremely important. Besides, how to develop an\nautomatic multi-objective solution that finds an optimal subset of questions\nfrom a huge search space of large-sized question datasets and thus composes a\nhigh-quality exam paper is urgent but non-trivial. To this end, we skillfully\ndesign a reinforcement learning guided Multi-Objective Exam Paper Generation\nframework, termed MOEPG, to simultaneously optimize three exam domain-specific\nobjectives including difficulty degree, distribution of exam scores, and skill\ncoverage. Specifically, to accurately measure the skill proficiency of the\nexaminee group, we first employ deep knowledge tracing to model the interaction\ninformation between examinees and response logs. We then design the flexible\nExam Q-Network, a function approximator, which automatically selects the\nappropriate question to update the exam paper composition process. Later, MOEPG\ndivides the decision space into multiple subspaces to better guide the updated\ndirection of the exam paper. Through extensive experiments on two real-world\ndatasets, we demonstrate that MOEPG is feasible in addressing the multiple\ndilemmas of exam paper generation scenario.\n","authors":["Yuhu Shang","Xuexiong Luo","Lihong Wang","Hao Peng","Xiankun Zhang","Yimeng Ren","Kun Liang"],"pdf_url":"https://arxiv.org/pdf/2303.01042v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01034v1","updated":"2023-03-02T07:44:06Z","published":"2023-03-02T07:44:06Z","title":"Multi-Task Self-Supervised Time-Series Representation Learning","summary":"  Time-series representation learning can extract representations from data\nwith temporal dynamics and sparse labels. When labeled data are sparse but\nunlabeled data are abundant, contrastive learning, i.e., a framework to learn a\nlatent space where similar samples are close to each other while dissimilar\nones are far from each other, has shown outstanding performance. This strategy\ncan encourage varied consistency of time-series representations depending on\nthe positive pair selection and contrastive loss. We propose a new time-series\nrepresentation learning method by combining the advantages of self-supervised\ntasks related to contextual, temporal, and transformation consistency. It\nallows the network to learn general representations for various downstream\ntasks and domains. Specifically, we first adopt data preprocessing to generate\npositive and negative pairs for each self-supervised task. The model then\nperforms contextual, temporal, and transformation contrastive learning and is\noptimized jointly using their contrastive losses. We further investigate an\nuncertainty weighting approach to enable effective multi-task learning by\nconsidering the contribution of each consistency. We evaluate the proposed\nframework on three downstream tasks: time-series classification, forecasting,\nand anomaly detection. Experimental results show that our method not only\noutperforms the benchmark models on these downstream tasks, but also shows\nefficiency in cross-domain transfer learning.\n","authors":["Heejeong Choi","Pilsung Kang"],"pdf_url":"https://arxiv.org/pdf/2303.01034v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.14610v3","updated":"2023-03-02T07:41:55Z","published":"2022-09-29T08:01:04Z","title":"Dynamic Prompt Learning via Policy Gradient for Semi-structured\n  Mathematical Reasoning","summary":"  Mathematical reasoning, a core ability of human intelligence, presents unique\nchallenges for machines in abstract thinking and logical reasoning. Recent\nlarge pre-trained language models such as GPT-3 have achieved remarkable\nprogress on mathematical reasoning tasks written in text form, such as math\nword problems (MWP). However, it is unknown if the models can handle more\ncomplex problems that involve math reasoning over heterogeneous information,\nsuch as tabular data. To fill the gap, we present Tabular Math Word Problems\n(TabMWP), a new dataset containing 38,431 open-domain grade-level problems that\nrequire mathematical reasoning on both textual and tabular data. Each question\nin TabMWP is aligned with a tabular context, which is presented as an image,\nsemi-structured text, and a structured table. There are two types of questions:\nfree-text and multi-choice, and each problem is annotated with gold solutions\nto reveal the multi-step reasoning process. We evaluate different pre-trained\nmodels on TabMWP, including the GPT-3 model in a few-shot setting. As earlier\nstudies suggest, since few-shot GPT-3 relies on the selection of in-context\nexamples, its performance is unstable and can degrade to near chance. The\nunstable issue is more severe when handling complex problems like TabMWP. To\nmitigate this, we further propose a novel approach, PromptPG, which utilizes\npolicy gradient to learn to select in-context examples from a small amount of\ntraining data and then constructs the corresponding prompt for the test\nexample. Experimental results show that our method outperforms the best\nbaseline by 5.31% on the accuracy metric and reduces the prediction variance\nsignificantly compared to random selection, which verifies its effectiveness in\nselecting in-context examples.\n","authors":["Pan Lu","Liang Qiu","Kai-Wei Chang","Ying Nian Wu","Song-Chun Zhu","Tanmay Rajpurohit","Peter Clark","Ashwin Kalyan"],"pdf_url":"https://arxiv.org/pdf/2209.14610v3.pdf","comment":"ICLR 2023. 26 pages and 18 figures. The data and code are available\n  at https://promptpg.github.io"},{"id":"http://arxiv.org/abs/2303.01030v1","updated":"2023-03-02T07:40:40Z","published":"2023-03-02T07:40:40Z","title":"Node Embedding from Hamiltonian Information Propagation in Graph Neural\n  Networks","summary":"  Graph neural networks (GNNs) have achieved success in various inference tasks\non graph-structured data. However, common challenges faced by many GNNs in the\nliterature include the problem of graph node embedding under various geometries\nand the over-smoothing problem. To address these issues, we propose a novel\ngraph information propagation strategy called Hamiltonian Dynamic GNN (HDG)\nthat uses a Hamiltonian mechanics approach to learn node embeddings in a graph.\nThe Hamiltonian energy function in HDG is learnable and can adapt to the\nunderlying geometry of any given graph dataset. We demonstrate the ability of\nHDG to automatically learn the underlying geometry of graph datasets, even\nthose with complex and mixed geometries, through comprehensive evaluations\nagainst state-of-the-art baselines on various downstream tasks. We also verify\nthat HDG is stable against small perturbations and can mitigate the\nover-smoothing problem when stacking many layers.\n","authors":["Qiyu Kang","Kai Zhao","Yang Song","Sijie Wang","Rui She","Wee Peng Tay"],"pdf_url":"https://arxiv.org/pdf/2303.01030v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01028v1","updated":"2023-03-02T07:36:23Z","published":"2023-03-02T07:36:23Z","title":"Specformer: Spectral Graph Neural Networks Meet Transformers","summary":"  Spectral graph neural networks (GNNs) learn graph representations via\nspectral-domain graph convolutions. However, most existing spectral graph\nfilters are scalar-to-scalar functions, i.e., mapping a single eigenvalue to a\nsingle filtered value, thus ignoring the global pattern of the spectrum.\nFurthermore, these filters are often constructed based on some fixed-order\npolynomials, which have limited expressiveness and flexibility. To tackle these\nissues, we introduce Specformer, which effectively encodes the set of all\neigenvalues and performs self-attention in the spectral domain, leading to a\nlearnable set-to-set spectral filter. We also design a decoder with learnable\nbases to enable non-local graph convolution. Importantly, Specformer is\nequivariant to permutation. By stacking multiple Specformer layers, one can\nbuild a powerful spectral GNN. On synthetic datasets, we show that our\nSpecformer can better recover ground-truth spectral filters than other spectral\nGNNs. Extensive experiments of both node-level and graph-level tasks on\nreal-world graph datasets show that our Specformer outperforms state-of-the-art\nGNNs and learns meaningful spectrum patterns. Code and data are available at\nhttps://github.com/bdy9527/Specformer.\n","authors":["Deyu Bo","Chuan Shi","Lele Wang","Renjie Liao"],"pdf_url":"https://arxiv.org/pdf/2303.01028v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01021v1","updated":"2023-03-02T07:22:26Z","published":"2023-03-02T07:22:26Z","title":"CADeSH: Collaborative Anomaly Detection for Smart Homes","summary":"  Although home IoT (Internet of Things) devices are typically plain and task\noriented, the context of their daily use may affect their traffic patterns. For\nthis reason, anomaly-based intrusion detection systems tend to suffer from a\nhigh false positive rate (FPR). To overcome this, we propose a two-step\ncollaborative anomaly detection method which first uses an autoencoder to\ndifferentiate frequent (`benign') and infrequent (possibly `malicious') traffic\nflows. Clustering is then used to analyze only the infrequent flows and\nclassify them as either known ('rare yet benign') or unknown (`malicious'). Our\nmethod is collaborative, in that (1) normal behaviors are characterized more\nrobustly, as they take into account a variety of user interactions and network\ntopologies, and (2) several features are computed based on a pool of identical\ndevices rather than just the inspected device.\n  We evaluated our method empirically, using 21 days of real-world traffic data\nthat emanated from eight identical IoT devices deployed on various networks,\none of which was located in our controlled lab where we implemented two popular\nIoT-related cyber-attacks. Our collaborative anomaly detection method achieved\na macro-average area under the precision-recall curve of 0.841, an F1 score of\n0.929, and an FPR of only 0.014. These promising results were obtained by using\nlabeled traffic data from our lab as the test set, while training the models on\nthe traffic of devices deployed outside the lab, and thus demonstrate a high\nlevel of generalizability. In addition to its high generalizability and\npromising performance, our proposed method also offers benefits such as privacy\npreservation, resource savings, and model poisoning mitigation. On top of that,\nas a contribution to the scientific community, our novel dataset is available\nonline.\n","authors":["Yair Meidan","Dan Avraham","Hanan Libhaber","Asaf Shabtai"],"pdf_url":"https://arxiv.org/pdf/2303.01021v1.pdf","comment":"in IEEE Internet of Things Journal, 2022"},{"id":"http://arxiv.org/abs/2206.09670v3","updated":"2023-03-02T07:20:08Z","published":"2022-06-20T09:22:20Z","title":"Benchmarking Constraint Inference in Inverse Reinforcement Learning","summary":"  When deploying Reinforcement Learning (RL) agents into a physical system, we\nmust ensure that these agents are well aware of the underlying constraints. In\nmany real-world problems, however, the constraints are often hard to specify\nmathematically and unknown to the RL agents. To tackle these issues, Inverse\nConstrained Reinforcement Learning (ICRL) empirically estimates constraints\nfrom expert demonstrations. As an emerging research topic, ICRL does not have\ncommon benchmarks, and previous works tested algorithms under hand-crafted\nenvironments with manually-generated expert demonstrations. In this paper, we\nconstruct an ICRL benchmark in the context of RL application domains, including\nrobot control, and autonomous driving. For each environment, we design relevant\nconstraints and train expert agents to generate demonstration data. Besides,\nunlike existing baselines that learn a deterministic constraint, we propose a\nvariational ICRL method to model a posterior distribution of candidate\nconstraints. We conduct extensive experiments on these algorithms under our\nbenchmark and show how they can facilitate studying important research\nchallenges for ICRL. The benchmark, including the instructions for reproducing\nICRL algorithms, is available at\nhttps://github.com/Guiliang/ICRL-benchmarks-public.\n","authors":["Guiliang Liu","Yudong Luo","Ashish Gaurav","Kasra Rezaee","Pascal Poupart"],"pdf_url":"https://arxiv.org/pdf/2206.09670v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.01130v4","updated":"2023-03-02T07:15:09Z","published":"2022-12-02T12:19:12Z","title":"Improving Pareto Front Learning via Multi-Sample Hypernetworks","summary":"  Pareto Front Learning (PFL) was recently introduced as an effective approach\nto obtain a mapping function from a given trade-off vector to a solution on the\nPareto front, which solves the multi-objective optimization (MOO) problem. Due\nto the inherent trade-off between conflicting objectives, PFL offers a flexible\napproach in many scenarios in which the decision makers can not specify the\npreference of one Pareto solution over another, and must switch between them\ndepending on the situation. However, existing PFL methods ignore the\nrelationship between the solutions during the optimization process, which\nhinders the quality of the obtained front. To overcome this issue, we propose a\nnovel PFL framework namely PHN-HVI, which employs a hypernetwork to generate\nmultiple solutions from a set of diverse trade-off preferences and enhance the\nquality of the Pareto front by maximizing the Hypervolume indicator defined by\nthese solutions. The experimental results on several MOO machine learning tasks\nshow that the proposed framework significantly outperforms the baselines in\nproducing the trade-off Pareto front.\n","authors":["Long P. Hoang","Dung D. Le","Tran Anh Tuan","Tran Ngoc Thang"],"pdf_url":"https://arxiv.org/pdf/2212.01130v4.pdf","comment":"Accepted to AAAI-23"},{"id":"http://arxiv.org/abs/2210.08761v2","updated":"2023-03-02T07:09:46Z","published":"2022-10-17T06:00:12Z","title":"Protein Sequence and Structure Co-Design with Equivariant Translation","summary":"  Proteins are macromolecules that perform essential functions in all living\norganisms. Designing novel proteins with specific structures and desired\nfunctions has been a long-standing challenge in the field of bioengineering.\nExisting approaches generate both protein sequence and structure using either\nautoregressive models or diffusion models, both of which suffer from high\ninference costs. In this paper, we propose a new approach capable of protein\nsequence and structure co-design, which iteratively translates both protein\nsequence and structure into the desired state from random initialization, based\non context features given a priori. Our model consists of a trigonometry-aware\nencoder that reasons geometrical constraints and interactions from context\nfeatures, and a roto-translation equivariant decoder that translates protein\nsequence and structure interdependently. Notably, all protein amino acids are\nupdated in one shot in each translation step, which significantly accelerates\nthe inference process. Experimental results across multiple tasks show that our\nmodel outperforms previous state-of-the-art baselines by a large margin, and is\nable to design proteins of high fidelity as regards both sequence and\nstructure, with running time orders of magnitude less than sampling-based\nmethods.\n","authors":["Chence Shi","Chuanrui Wang","Jiarui Lu","Bozitao Zhong","Jian Tang"],"pdf_url":"https://arxiv.org/pdf/2210.08761v2.pdf","comment":"Published as a conference paper at ICLR 2023, see\n  https://openreview.net/forum?id=pRCMXcfdihq"},{"id":"http://arxiv.org/abs/2303.01013v1","updated":"2023-03-02T06:57:35Z","published":"2023-03-02T06:57:35Z","title":"Domain Adaptation of Reinforcement Learning Agents based on Network\n  Service Proximity","summary":"  The dynamic and evolutionary nature of service requirements in wireless\nnetworks has motivated the telecom industry to consider intelligent\nself-adapting Reinforcement Learning (RL) agents for controlling the growing\nportfolio of network services. Infusion of many new types of services is\nanticipated with future adoption of 6G networks, and sometimes these services\nwill be defined by applications that are external to the network. An RL agent\ntrained for managing the needs of a specific service type may not be ideal for\nmanaging a different service type without domain adaptation. We provide a\nsimple heuristic for evaluating a measure of proximity between a new service\nand existing services, and show that the RL agent of the most proximal service\nrapidly adapts to the new service type through a well defined process of domain\nadaptation. Our approach enables a trained source policy to adapt to new\nsituations with changed dynamics without retraining a new policy, thereby\nachieving significant computing and cost-effectiveness. Such domain adaptation\ntechniques may soon provide a foundation for more generalized RL-based service\nmanagement under the face of rapidly evolving service types.\n","authors":["Kaushik Dey","Satheesh K. Perepu","Pallab Dasgupta","Abir Das"],"pdf_url":"https://arxiv.org/pdf/2303.01013v1.pdf","comment":"9 pages, Submitted to Netsoft 2023 conference"},{"id":"http://arxiv.org/abs/2002.03328v5","updated":"2023-03-02T06:56:26Z","published":"2020-02-09T09:54:12Z","title":"Kullback-Leibler Divergence-Based Out-of-Distribution Detection with\n  Flow-Based Generative Models","summary":"  Recent research has revealed that deep generative models including flow-based\nmodels and Variational Autoencoders may assign higher likelihoods to\nout-of-distribution (OOD) data than in-distribution (ID) data. However, we\ncannot sample OOD data from the model. This counterintuitive phenomenon has not\nbeen satisfactorily explained and brings obstacles to OOD detection with\nflow-based models. In this paper, we prove theorems to investigate the\nKullback-Leibler divergence in flow-based model and give two explanations for\nthe above phenomenon. Based on our theoretical analysis, we propose a new\nmethod \\PADmethod\\ to leverage KL divergence and local pixel dependence of\nrepresentations to perform anomaly detection. Experimental results on prevalent\nbenchmarks demonstrate the effectiveness and robustness of our method. For\ngroup anomaly detection, our method achieves 98.1\\% AUROC on average with a\nsmall batch size of 5. On the contrary, the baseline typicality test-based\nmethod only achieves 64.6\\% AUROC on average due to its failure on challenging\nproblems. Our method also outperforms the state-of-the-art method by 9.1\\%\nAUROC. For point-wise anomaly detection, our method achieves 90.7\\% AUROC on\naverage and outperforms the baseline by 5.2\\% AUROC. Besides, our method has\nthe least notable failures and is the most robust one.\n","authors":["Yufeng Zhang","Jialu Pan","Wanwei Liu","Zhenbang Chen","Ji Wang","Zhiming Liu","Kenli Li","Hongmei Wei"],"pdf_url":"https://arxiv.org/pdf/2002.03328v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12391v2","updated":"2023-03-02T06:54:15Z","published":"2023-02-24T01:43:17Z","title":"PITS: Variational Pitch Inference without Fundamental Frequency for\n  End-to-End Pitch-controllable TTS","summary":"  Previous pitch-controllable text-to-speech (TTS) models rely on directly\nmodeling fundamental frequency, leading to low variance in synthesized speech.\nTo address this issue, we propose PITS, an end-to-end pitch-controllable TTS\nmodel that utilizes variational inference to model pitch. Based on VITS, PITS\nincorporates the Yingram encoder, the Yingram decoder, and adversarial training\nof pitch-shifted synthesis to achieve pitch-controllability. Experiments\ndemonstrate that PITS generates high-quality speech that is indistinguishable\nfrom ground truth speech and has high pitch-controllability without quality\ndegradation. Code and audio samples will be available at\nhttps://github.com/anonymous-pits/pits.\n","authors":["Junhyeok Lee","Wonbin Jung","Hyunjae Cho","Jaeyeon Kim"],"pdf_url":"https://arxiv.org/pdf/2302.12391v2.pdf","comment":"5 pages, preprint"},{"id":"http://arxiv.org/abs/2303.01003v1","updated":"2023-03-02T06:44:21Z","published":"2023-03-02T06:44:21Z","title":"Target Domain Data induces Negative Transfer in Mixed Domain Training\n  with Disjoint Classes","summary":"  In practical scenarios, it is often the case that the available training data\nwithin the target domain only exist for a limited number of classes, with the\nremaining classes only available within surrogate domains. We show that\nincluding the target domain in training when there exist disjoint classes\nbetween the target and surrogate domains creates significant negative transfer,\nand causes performance to significantly decrease compared to training without\nthe target domain at all. We hypothesize that this negative transfer is due to\nan intermediate shortcut that only occurs when multiple source domains are\npresent, and provide experimental evidence that this may be the case. We show\nthat this phenomena occurs on over 25 distinct domain shifts, both synthetic\nand real, and in many cases deteriorates the performance to well worse than\nrandom, even when using state-of-the-art domain adaptation methods.\n","authors":["Eryk Banatt","Vickram Rajendran","Liam Packer"],"pdf_url":"https://arxiv.org/pdf/2303.01003v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2211.00854v2","updated":"2023-03-02T06:43:56Z","published":"2022-11-02T03:50:40Z","title":"More Speaking or More Speakers?","summary":"  Self-training (ST) and self-supervised learning (SSL) methods have\ndemonstrated strong improvements in automatic speech recognition (ASR). In\nspite of these advances, to the best of our knowledge, there is no analysis of\nhow the composition of the labelled and unlabelled datasets used in these\nmethods affects the results. In this work we aim to analyse the effect of\nnumber of speakers in the training data on a recent SSL algorithm (wav2vec\n2.0), and a recent ST algorithm (slimIPL). We perform a systematic analysis on\nboth labeled and unlabeled data by varying the number of speakers while keeping\nthe number of hours fixed and vice versa. Our findings suggest that SSL\nrequires a large amount of unlabeled data to produce high accuracy results,\nwhile ST requires a sufficient number of speakers in the labelled data,\nespecially in the low-regime setting. In this manner these two approaches\nimprove supervised learning in different regimes of data composition.\n","authors":["Dan Berrebbi","Ronan Collobert","Navdeep Jaitly","Tatiana Likhomanenko"],"pdf_url":"https://arxiv.org/pdf/2211.00854v2.pdf","comment":"ICASSP 2023"},{"id":"http://arxiv.org/abs/2205.13697v3","updated":"2023-03-02T06:43:05Z","published":"2022-05-27T01:19:22Z","title":"FedFormer: Contextual Federation with Attention in Reinforcement\n  Learning","summary":"  A core issue in multi-agent federated reinforcement learning is defining how\nto aggregate insights from multiple agents. This is commonly done by taking the\naverage of each participating agent's model weights into one common model\n(FedAvg). We instead propose FedFormer, a novel federation strategy that\nutilizes Transformer Attention to contextually aggregate embeddings from models\noriginating from different learner agents. In so doing, we attentively weigh\nthe contributions of other agents with respect to the current agent's\nenvironment and learned relationships, thus providing a more effective and\nefficient federation. We evaluate our methods on the Meta-World environment and\nfind that our approach yields significant improvements over FedAvg and\nnon-federated Soft Actor-Critic single-agent methods. Our results compared to\nSoft Actor-Critic show that FedFormer achieves higher episodic return while\nstill abiding by the privacy constraints of federated learning. Finally, we\nalso demonstrate improvements in effectiveness with increased agent pools\nacross all methods in certain tasks. This is contrasted by FedAvg, which fails\nto make noticeable improvements when scaled.\n","authors":["Liam Hebert","Lukasz Golab","Pascal Poupart","Robin Cohen"],"pdf_url":"https://arxiv.org/pdf/2205.13697v3.pdf","comment":"Our source code can be found at\n  https://github.com/liamhebert/FedFormer. Accepted at AAMAS 2023"},{"id":"http://arxiv.org/abs/2205.14083v3","updated":"2023-03-02T06:39:34Z","published":"2022-05-27T16:32:43Z","title":"Sharpness-Aware Training for Free","summary":"  Modern deep neural networks (DNNs) have achieved state-of-the-art\nperformances but are typically over-parameterized. The over-parameterization\nmay result in undesirably large generalization error in the absence of other\ncustomized training strategies. Recently, a line of research under the name of\nSharpness-Aware Minimization (SAM) has shown that minimizing a sharpness\nmeasure, which reflects the geometry of the loss landscape, can significantly\nreduce the generalization error. However, SAM-like methods incur a two-fold\ncomputational overhead of the given base optimizer (e.g. SGD) for approximating\nthe sharpness measure. In this paper, we propose Sharpness-Aware Training for\nFree, or SAF, which mitigates the sharp landscape at almost zero additional\ncomputational cost over the base optimizer. Intuitively, SAF achieves this by\navoiding sudden drops in the loss in the sharp local minima throughout the\ntrajectory of the updates of the weights. Specifically, we suggest a novel\ntrajectory loss, based on the KL-divergence between the outputs of DNNs with\nthe current weights and past weights, as a replacement of the SAM's sharpness\nmeasure. This loss captures the rate of change of the training loss along the\nmodel's update trajectory. By minimizing it, SAF ensures the convergence to a\nflat minimum with improved generalization capabilities. Extensive empirical\nresults show that SAF minimizes the sharpness in the same way that SAM does,\nyielding better results on the ImageNet dataset with essentially the same\ncomputational cost as the base optimizer.\n","authors":["Jiawei Du","Daquan Zhou","Jiashi Feng","Vincent Y. F. Tan","Joey Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2205.14083v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.09138v2","updated":"2023-03-02T06:27:20Z","published":"2023-01-22T15:17:12Z","title":"Explaining Quantum Circuits with Shapley Values: Towards Explainable\n  Quantum Machine Learning","summary":"  Methods of artificial intelligence (AI) and especially machine learning (ML)\nhave been growing ever more complex, and at the same time have more and more\nimpact on people's lives. This leads to explainable AI (XAI) manifesting itself\nas an important research field that helps humans to better comprehend ML\nsystems. In parallel, quantum machine learning (QML) is emerging with the\nongoing improvement of quantum computing hardware combined with its increasing\navailability via cloud services. QML enables quantum-enhanced ML in which\nquantum mechanics is exploited to facilitate ML tasks, typically in form of\nquantum-classical hybrid algorithms that combine quantum and classical\nresources. Quantum gates constitute the building blocks of gate-based quantum\nhardware and form circuits that can be used for quantum computations. For QML\napplications, quantum circuits are typically parameterized and their parameters\nare optimized classically such that a suitably defined objective function is\nminimized. Inspired by XAI, we raise the question of explainability of such\ncircuits by quantifying the importance of (groups of) gates for specific goals.\nTo this end, we transfer and adapt the well-established concept of Shapley\nvalues to the quantum realm. The resulting attributions can be interpreted as\nexplanations for why a specific circuit works well for a given task, improving\nthe understanding of how to construct parameterized (or variational) quantum\ncircuits, and fostering their human interpretability in general. An\nexperimental evaluation on simulators and two superconducting quantum hardware\ndevices demonstrates the benefits of the proposed framework for classification,\ngenerative modeling, transpilation, and optimization. Furthermore, our results\nshed some light on the role of specific gates in popular QML approaches.\n","authors":["Raoul Heese","Thore Gerlach","Sascha Mücke","Sabine Müller","Matthias Jakobs","Nico Piatkowski"],"pdf_url":"https://arxiv.org/pdf/2301.09138v2.pdf","comment":"36 pages, 27 figures, 3 tables"},{"id":"http://arxiv.org/abs/2302.05086v2","updated":"2023-03-02T06:14:19Z","published":"2023-02-10T07:08:13Z","title":"Making Substitute Models More Bayesian Can Enhance Transferability of\n  Adversarial Examples","summary":"  The transferability of adversarial examples across deep neural networks\n(DNNs) is the crux of many black-box attacks. Many prior efforts have been\ndevoted to improving the transferability via increasing the diversity in inputs\nof some substitute models. In this paper, by contrast, we opt for the diversity\nin substitute models and advocate to attack a Bayesian model for achieving\ndesirable transferability. Deriving from the Bayesian formulation, we develop a\nprincipled strategy for possible finetuning, which can be combined with many\noff-the-shelf Gaussian posterior approximations over DNN parameters. Extensive\nexperiments have been conducted to verify the effectiveness of our method, on\ncommon benchmark datasets, and the results demonstrate that our method\noutperforms recent state-of-the-arts by large margins (roughly 19% absolute\nincrease in average attack success rate on ImageNet), and, by combining with\nthese recent methods, further performance gain can be obtained. Our code:\nhttps://github.com/qizhangli/MoreBayesian-attack.\n","authors":["Qizhang Li","Yiwen Guo","Wangmeng Zuo","Hao Chen"],"pdf_url":"https://arxiv.org/pdf/2302.05086v2.pdf","comment":"Accepted by ICLR 2023, fix typos"},{"id":"http://arxiv.org/abs/2210.15598v2","updated":"2023-03-02T06:12:50Z","published":"2022-10-27T16:37:52Z","title":"Provable Sim-to-real Transfer in Continuous Domain with Partial\n  Observations","summary":"  Sim-to-real transfer trains RL agents in the simulated environments and then\ndeploys them in the real world. Sim-to-real transfer has been widely used in\npractice because it is often cheaper, safer and much faster to collect samples\nin simulation than in the real world. Despite the empirical success of the\nsim-to-real transfer, its theoretical foundation is much less understood. In\nthis paper, we study the sim-to-real transfer in continuous domain with partial\nobservations, where the simulated environments and real-world environments are\nmodeled by linear quadratic Gaussian (LQG) systems. We show that a popular\nrobust adversarial training algorithm is capable of learning a policy from the\nsimulated environment that is competitive to the optimal policy in the\nreal-world environment. To achieve our results, we design a new algorithm for\ninfinite-horizon average-cost LQGs and establish a regret bound that depends on\nthe intrinsic complexity of the model class. Our algorithm crucially relies on\na novel history clipping scheme, which might be of independent interest.\n","authors":["Jiachen Hu","Han Zhong","Chi Jin","Liwei Wang"],"pdf_url":"https://arxiv.org/pdf/2210.15598v2.pdf","comment":"Accepted at ICLR2023"},{"id":"http://arxiv.org/abs/2303.00996v1","updated":"2023-03-02T06:10:13Z","published":"2023-03-02T06:10:13Z","title":"Unsupervised Meta-Learning via Few-shot Pseudo-supervised Contrastive\n  Learning","summary":"  Unsupervised meta-learning aims to learn generalizable knowledge across a\ndistribution of tasks constructed from unlabeled data. Here, the main challenge\nis how to construct diverse tasks for meta-learning without label information;\nrecent works have proposed to create, e.g., pseudo-labeling via pretrained\nrepresentations or creating synthetic samples via generative models. However,\nsuch a task construction strategy is fundamentally limited due to heavy\nreliance on the immutable pseudo-labels during meta-learning and the quality of\nthe representations or the generated samples. To overcome the limitations, we\npropose a simple yet effective unsupervised meta-learning framework, coined\nPseudo-supervised Contrast (PsCo), for few-shot classification. We are inspired\nby the recent self-supervised learning literature; PsCo utilizes a momentum\nnetwork and a queue of previous batches to improve pseudo-labeling and\nconstruct diverse tasks in a progressive manner. Our extensive experiments\ndemonstrate that PsCo outperforms existing unsupervised meta-learning methods\nunder various in-domain and cross-domain few-shot classification benchmarks. We\nalso validate that PsCo is easily scalable to a large-scale benchmark, while\nrecent prior-art meta-schemes are not.\n","authors":["Huiwon Jang","Hankook Lee","Jinwoo Shin"],"pdf_url":"https://arxiv.org/pdf/2303.00996v1.pdf","comment":"Accepted to ICLR 2023 (Spotlight). The first two authors contributed\n  equally. The code is available at https://github.com/alinlab/PsCo"},{"id":"http://arxiv.org/abs/2210.00189v2","updated":"2023-03-02T05:41:40Z","published":"2022-10-01T04:42:56Z","title":"Pitfalls of Gaussians as a noise distribution in NCE","summary":"  Noise Contrastive Estimation (NCE) is a popular approach for learning\nprobability density functions parameterized up to a constant of\nproportionality. The main idea is to design a classification problem for\ndistinguishing training data from samples from an easy-to-sample noise\ndistribution $q$, in a manner that avoids having to calculate a partition\nfunction. It is well-known that the choice of $q$ can severely impact the\ncomputational and statistical efficiency of NCE. In practice, a common choice\nfor $q$ is a Gaussian which matches the mean and covariance of the data.\n  In this paper, we show that such a choice can result in an exponentially bad\n(in the ambient dimension) conditioning of the Hessian of the loss, even for\nvery simple data distributions. As a consequence, both the statistical and\nalgorithmic complexity for such a choice of $q$ will be problematic in\npractice, suggesting that more complex noise distributions are essential to the\nsuccess of NCE.\n","authors":["Holden Lee","Chirag Pabbaraju","Anish Sevekari","Andrej Risteski"],"pdf_url":"https://arxiv.org/pdf/2210.00189v2.pdf","comment":"14 pages, 1 figure"},{"id":"http://arxiv.org/abs/2211.09981v2","updated":"2023-03-02T05:37:48Z","published":"2022-11-18T02:00:17Z","title":"Weighted Ensemble Self-Supervised Learning","summary":"  Ensembling has proven to be a powerful technique for boosting model\nperformance, uncertainty estimation, and robustness in supervised learning.\nAdvances in self-supervised learning (SSL) enable leveraging large unlabeled\ncorpora for state-of-the-art few-shot and supervised learning performance. In\nthis paper, we explore how ensemble methods can improve recent SSL techniques\nby developing a framework that permits data-dependent weighted cross-entropy\nlosses. We refrain from ensembling the representation backbone; this choice\nyields an efficient ensemble method that incurs a small training cost and\nrequires no architectural changes or computational overhead to downstream\nevaluation. The effectiveness of our method is demonstrated with two\nstate-of-the-art SSL methods, DINO (Caron et al., 2021) and MSN (Assran et al.,\n2022). Our method outperforms both in multiple evaluation metrics on\nImageNet-1K, particularly in the few-shot setting. We explore several weighting\nschemes and find that those which increase the diversity of ensemble heads lead\nto better downstream evaluation results. Thorough experiments yield improved\nprior art baselines which our method still surpasses; e.g., our overall\nimprovement with MSN ViT-B/16 is 3.9 p.p. for 1-shot learning.\n","authors":["Yangjun Ruan","Saurabh Singh","Warren Morningstar","Alexander A. Alemi","Sergey Ioffe","Ian Fischer","Joshua V. Dillon"],"pdf_url":"https://arxiv.org/pdf/2211.09981v2.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2303.00984v1","updated":"2023-03-02T05:29:27Z","published":"2023-03-02T05:29:27Z","title":"Encoding of data sets and algorithms","summary":"  In many high-impact applications, it is important to ensure the quality of\noutput of a machine learning algorithm as well as its reliability in comparison\nwith the complexity of the algorithm used. In this paper, we have initiated a\nmathematically rigorous theory to decide which models (algorithms applied on\ndata sets) are close to each other in terms of certain metrics, such as\nperformance and the complexity level of the algorithm. This involves creating a\ngrid on the hypothetical spaces of data sets and algorithms so as to identify a\nfinite set of probability distributions from which the data sets are sampled\nand a finite set of algorithms. A given threshold metric acting on this grid\nwill express the nearness (or statistical distance) from each algorithm and\ndata set of interest to any given application. A technically difficult part of\nthis project is to estimate the so-called metric entropy of a compact subset of\nfunctions of \\textbf{infinitely many variables} that arise in the definition of\nthese spaces.\n","authors":["Katarina Doctor","Tong Mao","Hrushikesh Mhaskar"],"pdf_url":"https://arxiv.org/pdf/2303.00984v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.14106v2","updated":"2023-03-02T05:23:15Z","published":"2022-12-28T22:05:32Z","title":"Robust Ranking Explanations","summary":"  Gradient-based explanation is the cornerstone of explainable deep networks,\nbut it has been shown to be vulnerable to adversarial attacks. However,\nexisting works measure the explanation robustness based on $\\ell_p$-norm, which\ncan be counter-intuitive to humans, who only pay attention to the top few\nsalient features. We propose explanation ranking thickness as a more suitable\nexplanation robustness metric. We then present a new practical adversarial\nattacking goal for manipulating explanation rankings. To mitigate the\nranking-based attacks while maintaining computational feasibility, we derive\nsurrogate bounds of the thickness that involve expensive sampling and\nintegration. We use a multi-objective approach to analyze the convergence of a\ngradient-based attack to confirm that the explanation robustness can be\nmeasured by the thickness metric. We conduct experiments on various network\narchitectures and diverse datasets to prove the superiority of the proposed\nmethods, while the widely accepted Hessian-based curvature smoothing approaches\nare not as robust as our method.\n","authors":["Chao Chen","Chenghua Guo","Guixiang Ma","Ming Zeng","Xi Zhang","Sihong Xie"],"pdf_url":"https://arxiv.org/pdf/2212.14106v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.15162v2","updated":"2023-03-02T23:54:47Z","published":"2022-09-30T01:17:18Z","title":"Linearly Mapping from Image to Text Space","summary":"  The extent to which text-only language models (LMs) learn to represent\nfeatures of the non-linguistic world is an open question. Prior work has shown\nthat pretrained LMs can be taught to caption images when a vision model's\nparameters are optimized to encode images in the language space. We test a\nstronger hypothesis: that the conceptual representations learned by frozen\ntext-only models and vision-only models are similar enough that this can be\nachieved with a linear map. We show that the image representations from vision\nmodels can be transferred as continuous prompts to frozen LMs by training only\na single linear projection. Using these to prompt the LM achieves competitive\nperformance on captioning and visual question answering tasks compared to\nmodels that tune both the image encoder and text decoder (such as the MAGMA\nmodel). We compare three image encoders with increasing amounts of linguistic\nsupervision seen during pretraining: BEIT (no linguistic information),\nNF-ResNET (lexical category information), and CLIP (full natural language\ndescriptions). We find that all three encoders perform equally well at\ntransferring visual property information to the language model (e.g., whether\nan animal is large or small), but that image encoders pretrained with\nlinguistic supervision more saliently encode category information (e.g.,\ndistinguishing hippo vs. elephant) and thus perform significantly better on\nbenchmark language-and-vision tasks. Our results indicate that LMs encode\nconceptual information structurally similarly to vision-based models, even\nthose that are solely trained on images. Code is available here:\nhttps://github.com/jmerullo/limber\n","authors":["Jack Merullo","Louis Castricato","Carsten Eickhoff","Ellie Pavlick"],"pdf_url":"https://arxiv.org/pdf/2209.15162v2.pdf","comment":"Accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2302.12692v3","updated":"2023-03-02T23:52:00Z","published":"2023-02-24T15:35:36Z","title":"Language Models are Few-shot Learners for Prognostic Prediction","summary":"  Clinical prediction is an essential task in the healthcare industry. However,\nthe recent success of transformers, on which large language models are built,\nhas not been extended to this domain. In this research, we explore the use of\ntransformers and language models in prognostic prediction for immunotherapy\nusing real-world patients' clinical data and molecular profiles. This paper\ninvestigates the potential of transformers to improve clinical prediction\ncompared to conventional machine learning approaches and addresses the\nchallenge of few-shot learning in predicting rare disease areas. The study\nbenchmarks the efficacy of baselines and language models on prognostic\nprediction across multiple cancer types and investigates the impact of\ndifferent pretrained language models under few-shot regimes. The results\ndemonstrate significant improvements in accuracy and highlight the potential of\nNLP in clinical research to improve early detection and intervention for\ndifferent diseases.\n","authors":["Z. Chen","M. M. Balan","K. Brown"],"pdf_url":"https://arxiv.org/pdf/2302.12692v3.pdf","comment":"7 pages, 5 figures, 5 tables"}],"Multimedia":[{"id":"http://arxiv.org/abs/2303.01457v1","updated":"2023-03-02T18:15:03Z","published":"2023-03-02T18:15:03Z","title":"AI as mediator between composers, sound designers, and creative media\n  producers","summary":"  Musical professionals who produce material for non-musical stakeholders often\nface communication challenges in the early ideation stage. Expressing musical\nideas can be difficult, especially when domain-specific vocabulary is lacking.\nThis position paper proposes the use of artificial intelligence to facilitate\ncommunication between stakeholders and accelerate the consensus-building\nprocess. Rather than fully or partially automating the creative process, the\naim is to give more time for creativity by reducing time spent on defining the\nexpected outcome. To demonstrate this point, the paper discusses two\napplication scenarios for interactive music systems that are based on the\nauthors' research into gesture-to-sound mapping.\n","authors":["Sebastian Löbbers","Mathieu Barthet","György Fazekas"],"pdf_url":"https://arxiv.org/pdf/2303.01457v1.pdf","comment":"Position paper submitted to Integrating AI in Human-Human\n  Collaborative Ideation workshop at the ACM CHI Conference on Human Factors in\n  Computing System"},{"id":"http://arxiv.org/abs/2303.01396v1","updated":"2023-03-02T16:26:14Z","published":"2023-03-02T16:26:14Z","title":"MLANet: Multi-Level Attention Network with Sub-instruction for\n  Continuous Vision-and-Language Navigation","summary":"  Vision-and-Language Navigation (VLN) aims to develop intelligent agents to\nnavigate in unseen environments only through language and vision supervision.\nIn the recently proposed continuous settings (continuous VLN), the agent must\nact in a free 3D space and faces tougher challenges like real-time execution,\ncomplex instruction understanding, and long action sequence prediction. For a\nbetter performance in continuous VLN, we design a multi-level instruction\nunderstanding procedure and propose a novel model, Multi-Level Attention\nNetwork (MLANet). The first step of MLANet is to generate sub-instructions\nefficiently. We design a Fast Sub-instruction Algorithm (FSA) to segment the\nraw instruction into sub-instructions and generate a new sub-instruction\ndataset named ``FSASub\". FSA is annotation-free and faster than the current\nmethod by 70 times, thus fitting the real-time requirement in continuous VLN.\nTo solve the complex instruction understanding problem, MLANet needs a global\nperception of the instruction and observations. We propose a Multi-Level\nAttention (MLA) module to fuse vision, low-level semantics, and high-level\nsemantics, which produce features containing a dynamic and global comprehension\nof the task. MLA also mitigates the adverse effects of noise words, thus\nensuring a robust understanding of the instruction. To correctly predict\nactions in long trajectories, MLANet needs to focus on what sub-instruction is\nbeing executed every step. We propose a Peak Attention Loss (PAL) to improve\nthe flexible and adaptive selection of the current sub-instruction. PAL\nbenefits the navigation agent by concentrating its attention on the local\ninformation, thus helping the agent predict the most appropriate actions. We\ntrain and test MLANet in the standard benchmark. Experiment results show MLANet\noutperforms baselines by a significant margin.\n","authors":["Zongtao He","Liuyi Wang","Shu Li","Qingqing Yan","Chengju Liu","Qijun Chen"],"pdf_url":"https://arxiv.org/pdf/2303.01396v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01217v1","updated":"2023-03-02T12:59:01Z","published":"2023-03-02T12:59:01Z","title":"Synthetic Misinformers: Generating and Combating Multimodal\n  Misinformation","summary":"  With the expansion of social media and the increasing dissemination of\nmultimedia content, the spread of misinformation has become a major concern.\nThis necessitates effective strategies for multimodal misinformation detection\n(MMD) that detect whether the combination of an image and its accompanying text\ncould mislead or misinform. Due to the data-intensive nature of deep neural\nnetworks and the labor-intensive process of manual annotation, researchers have\nbeen exploring various methods for automatically generating synthetic\nmultimodal misinformation - which we refer to as Synthetic Misinformers - in\norder to train MMD models. However, limited evaluation on real-world\nmisinformation and a lack of comparisons with other Synthetic Misinformers\nmakes difficult to assess progress in the field. To address this, we perform a\ncomparative study on existing and new Synthetic Misinformers that involves (1)\nout-of-context (OOC) image-caption pairs, (2) cross-modal named entity\ninconsistency (NEI) as well as (3) hybrid approaches and we evaluate them\nagainst real-world misinformation; using the COSMOS benchmark. The comparative\nstudy showed that our proposed CLIP-based Named Entity Swapping can lead to MMD\nmodels that surpass other OOC and NEI Misinformers in terms of multimodal\naccuracy and that hybrid approaches can lead to even higher detection accuracy.\nNevertheless, after alleviating information leakage from the COSMOS evaluation\nprotocol, low Sensitivity scores indicate that the task is significantly more\nchallenging than previous studies suggested. Finally, our findings showed that\nNEI-based Synthetic Misinformers tend to suffer from a unimodal bias, where\ntext-only MMDs can outperform multimodal ones.\n","authors":["Stefanos-Iordanis Papadopoulos","Christos Koutlis","Symeon Papadopoulos","Panagiotis C. Petrantonakis"],"pdf_url":"https://arxiv.org/pdf/2303.01217v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01211v1","updated":"2023-03-02T12:52:22Z","published":"2023-03-02T12:52:22Z","title":"Learning From Yourself: A Self-Distillation Method for Fake Speech\n  Detection","summary":"  In this paper, we propose a novel self-distillation method for fake speech\ndetection (FSD), which can significantly improve the performance of FSD without\nincreasing the model complexity. For FSD, some fine-grained information is very\nimportant, such as spectrogram defects, mute segments, and so on, which are\noften perceived by shallow networks. However, shallow networks have much noise,\nwhich can not capture this very well. To address this problem, we propose using\nthe deepest network instruct shallow network for enhancing shallow networks.\nSpecifically, the networks of FSD are divided into several segments, the\ndeepest network being used as the teacher model, and all shallow networks\nbecome multiple student models by adding classifiers. Meanwhile, the\ndistillation path between the deepest network feature and shallow network\nfeatures is used to reduce the feature difference. A series of experimental\nresults on the ASVspoof 2019 LA and PA datasets show the effectiveness of the\nproposed method, with significant improvements compared to the baseline.\n","authors":["Jun Xue","Cunhang Fan","Jiangyan Yi","Chenglong Wang","Zhengqi Wen","Dan Zhang","Zhao Lv"],"pdf_url":"https://arxiv.org/pdf/2303.01211v1.pdf","comment":"Accepted by ICASSP 2023"}]},"2023-03-03T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2303.02151v1","updated":"2023-03-03T18:58:16Z","published":"2023-03-03T18:58:16Z","title":"Prompt, Generate, then Cache: Cascade of Foundation Models makes Strong\n  Few-shot Learners","summary":"  Visual recognition in low-data regimes requires deep neural networks to learn\ngeneralized representations from limited training samples. Recently, CLIP-based\nmethods have shown promising few-shot performance benefited from the\ncontrastive language-image pre-training. We then question, if the more diverse\npre-training knowledge can be cascaded to further assist few-shot\nrepresentation learning. In this paper, we propose CaFo, a Cascade of\nFoundation models that incorporates diverse prior knowledge of various\npre-training paradigms for better few-shot learning. Our CaFo incorporates\nCLIP's language-contrastive knowledge, DINO's vision-contrastive knowledge,\nDALL-E's vision-generative knowledge, and GPT-3's language-generative\nknowledge. Specifically, CaFo works by 'Prompt, Generate, then Cache'. Firstly,\nwe leverage GPT-3 to produce textual inputs for prompting CLIP with rich\ndownstream linguistic semantics. Then, we generate synthetic images via DALL-E\nto expand the few-shot training data without any manpower. At last, we\nintroduce a learnable cache model to adaptively blend the predictions from CLIP\nand DINO. By such collaboration, CaFo can fully unleash the potential of\ndifferent pre-training methods and unify them to perform state-of-the-art for\nfew-shot classification. Code is available at\nhttps://github.com/ZrrSkywalker/CaFo.\n","authors":["Renrui Zhang","Xiangfei Hu","Bohao Li","Siyuan Huang","Hanqiu Deng","Hongsheng Li","Yu Qiao","Peng Gao"],"pdf_url":"https://arxiv.org/pdf/2303.02151v1.pdf","comment":"Accepted by CVPR 2023. Code is available at\n  https://github.com/ZrrSkywalker/CaFo. arXiv admin note: substantial text\n  overlap with arXiv:2209.12255"},{"id":"http://arxiv.org/abs/2303.02078v1","updated":"2023-03-03T16:50:12Z","published":"2023-03-03T16:50:12Z","title":"Who could be behind QAnon? Authorship attribution with supervised\n  machine-learning","summary":"  A series of social media posts signed under the pseudonym \"Q\", started a\nmovement known as QAnon, which led some of its most radical supporters to\nviolent and illegal actions. To identify the person(s) behind Q, we evaluate\nthe coincidence between the linguistic properties of the texts written by Q and\nto those written by a list of suspects provided by journalistic investigation.\nTo identify the authors of these posts, serious challenges have to be\naddressed. The \"Q drops\" are very short texts, written in a way that constitute\na sort of literary genre in itself, with very peculiar features of style. These\ntexts might have been written by different authors, whose other writings are\noften hard to find. After an online ethnology of the movement, necessary to\ncollect enough material written by these thirteen potential authors, we use\nsupervised machine learning to build stylistic profiles for each of them. We\nthen performed a rolling analysis on Q's writings, to see if any of those\nlinguistic profiles match the so-called 'QDrops' in part or entirety. We\nconclude that two different individuals, Paul F. and Ron W., are the closest\nmatch to Q's linguistic signature, and they could have successively written Q's\ntexts. These potential authors are not high-ranked personality from the U.S.\nadministration, but rather social media activists.\n","authors":["Florian Cafiero","Jean-Baptiste Camps"],"pdf_url":"https://arxiv.org/pdf/2303.02078v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.03954v2","updated":"2023-03-03T14:36:11Z","published":"2022-04-08T09:28:20Z","title":"Are We Really Making Much Progress? Bag-of-Words vs. Sequence vs. Graph\n  vs. Hierarchy for Single- and Multi-Label Text Classification","summary":"  The popularity of graph neural networks has triggered a resurgence of\ngraph-based methods for single-label and multi-label text classification.\nHowever, it is unclear whether these graph-based methods are beneficial\ncompared to standard machine learning methods and modern pretrained language\nmodels. We compare a rich selection of bag-of-words, sequence-based,\ngraph-based, and hierarchical methods for text classification. We aggregate\nresults from the literature over 5 single-label and 7 multi-label datasets and\nrun our own experiments. Our findings unambiguously demonstrate that for\nsingle-label and multi-label classification tasks, the graph-based methods fail\nto outperform fine-tuned language models and sometimes even perform worse than\nstandard machine learning methods like multilayer perceptron (MLP) on a\nbag-of-words. This questions the enormous amount of effort put into the\ndevelopment of new graph-based methods in the last years and the promises they\nmake for text classification. Given our extensive experiments, we confirm that\npretrained language models remain state-of-the-art in text classification\ndespite all recent specialized advances. We argue that future work in text\nclassification should thoroughly test against strong baselines like MLPs to\nproperly assess the true scientific progress.\n  The source code is available: https://github.com/drndr/multilabel-text-clf\n","authors":["Lukas Galke","Andor Diera","Bao Xin Lin","Bhakti Khera","Tim Meuser","Tushar Singhal","Fabian Karl","Ansgar Scherp"],"pdf_url":"https://arxiv.org/pdf/2204.03954v2.pdf","comment":"This work is an extension of \"Bag-of-Words vs. Graph vs. Sequence in\n  Text Classification: Questioning the Necessity of Text-Graphs and the\n  Surprising Strength of a Wide MLP. ACL (1) 2022: 4038-4051\", URL:\n  https://aclanthology.org/2022.acl-long.279/"},{"id":"http://arxiv.org/abs/2303.01912v1","updated":"2023-03-03T13:24:17Z","published":"2023-03-03T13:24:17Z","title":"Ancient Chinese Word Segmentation and Part-of-Speech Tagging Using\n  Distant Supervision","summary":"  Ancient Chinese word segmentation (WSG) and part-of-speech tagging (POS) are\nimportant to study ancient Chinese, but the amount of ancient Chinese WSG and\nPOS tagging data is still rare. In this paper, we propose a novel augmentation\nmethod of ancient Chinese WSG and POS tagging data using distant supervision\nover parallel corpus. However, there are still mislabeled and unlabeled ancient\nChinese words inevitably in distant supervision. To address this problem, we\ntake advantage of the memorization effects of deep neural networks and a small\namount of annotated data to get a model with much knowledge and a little noise,\nand then we use this model to relabel the ancient Chinese sentences in parallel\ncorpus. Experiments show that the model trained over the relabeled data\noutperforms the model trained over the data generated from distant supervision\nand the annotated data. Our code is available at\nhttps://github.com/farlit/ACDS.\n","authors":["Shuo Feng","Piji Li"],"pdf_url":"https://arxiv.org/pdf/2303.01912v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01911v1","updated":"2023-03-03T13:23:42Z","published":"2023-03-03T13:23:42Z","title":"Investigating the Translation Performance of a Large Multilingual\n  Language Model: the Case of BLOOM","summary":"  The NLP community recently saw the release of a new large open-access\nmultilingual language model, BLOOM (BigScience et al., 2022) covering 46\nlanguages. We focus on BLOOM's multilingual ability by evaluating its machine\ntranslation performance across several datasets (WMT, Flores-101 and DiaBLa)\nand language pairs (high- and low-resourced). Our results show that 0-shot\nperformance suffers from overgeneration and generating in the wrong language,\nbut this is greatly improved in the few-shot setting, with very good results\nfor a number of language pairs. We study several aspects including prompt\ndesign, model sizes, cross-lingual transfer and the use of discursive context.\n","authors":["Rachel Bawden","François Yvon"],"pdf_url":"https://arxiv.org/pdf/2303.01911v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01903v1","updated":"2023-03-03T13:05:15Z","published":"2023-03-03T13:05:15Z","title":"Prompting Large Language Models with Answer Heuristics for\n  Knowledge-based Visual Question Answering","summary":"  Knowledge-based visual question answering (VQA) requires external knowledge\nbeyond the image to answer the question. Early studies retrieve required\nknowledge from explicit knowledge bases (KBs), which often introduces\nirrelevant information to the question, hence restricting the performance of\ntheir models. Recent works have sought to use a large language model (i.e.,\nGPT-3) as an implicit knowledge engine to acquire the necessary knowledge for\nanswering. Despite the encouraging results achieved by these methods, we argue\nthat they have not fully activated the capacity of GPT-3 as the provided input\ninformation is insufficient. In this paper, we present Prophet -- a\nconceptually simple framework designed to prompt GPT-3 with answer heuristics\nfor knowledge-based VQA. Specifically, we first train a vanilla VQA model on a\nspecific knowledge-based VQA dataset without external knowledge. After that, we\nextract two types of complementary answer heuristics from the model: answer\ncandidates and answer-aware examples. Finally, the two types of answer\nheuristics are encoded into the prompts to enable GPT-3 to better comprehend\nthe task thus enhancing its capacity. Prophet significantly outperforms all\nexisting state-of-the-art methods on two challenging knowledge-based VQA\ndatasets, OK-VQA and A-OKVQA, delivering 61.1% and 55.7% accuracies on their\ntesting sets, respectively.\n","authors":["Zhenwei Shao","Zhou Yu","Meng Wang","Jun Yu"],"pdf_url":"https://arxiv.org/pdf/2303.01903v1.pdf","comment":"Accepted at CVPR 2023, code available at\n  https://github.com/MILVLG/prophet"},{"id":"http://arxiv.org/abs/2211.15363v2","updated":"2023-03-03T11:10:16Z","published":"2022-11-28T14:38:45Z","title":"On the Security Vulnerabilities of Text-to-SQL Models","summary":"  Although it has been demonstrated that Natural Language Processing (NLP)\nalgorithms are vulnerable to deliberate attacks, the question of whether such\nweaknesses can lead to software security threats is under-explored. To bridge\nthis gap, we conducted vulnerability tests on Text-to-SQL systems that are\ncommonly used to create natural language interfaces to databases. We showed\nthat the Text-to-SQL modules within six commercial applications can be\nmanipulated to produce malicious code, potentially leading to data breaches and\nDenial of Service attacks. This is the first demonstration that NLP models can\nbe exploited as attack vectors in the wild. In addition, experiments using four\nopen-source language models verified that straightforward backdoor attacks on\nText-to-SQL systems achieve a 100% success rate without affecting their\nperformance. The aim of this work is to draw the community's attention to\npotential software security issues associated with NLP algorithms and encourage\nexploration of methods to mitigate against them.\n","authors":["Xutan Peng","Yipeng Zhang","Jingfeng Yang","Mark Stevenson"],"pdf_url":"https://arxiv.org/pdf/2211.15363v2.pdf","comment":"Added demonstrations on four more online systems"},{"id":"http://arxiv.org/abs/2303.01847v1","updated":"2023-03-03T11:01:10Z","published":"2023-03-03T11:01:10Z","title":"Mapping Wordnets on the Fly with Permanent Sense Keys","summary":"  Most of the major databases on the semantic web have links to Princeton\nWordNet (PWN) synonym set (synset) identifiers, which differ for each PWN\nrelease, and are thus incompatible between versions. On the other hand, both\nPWN and the more recent Open English Wordnet (OEWN) provide permanent word\nsense identifiers (the sense keys), which can solve this interoperability\nproblem.\n  We present an algorithm that runs in linear time, to automatically derive a\nsynset mapping between any pair of Wordnet versions that use PWN sense keys.\nThis allows to update old WordNet links, and seamlessly interoperate with newer\nEnglish Wordnet versions for which no prior mapping exists.\n  By applying the proposed algorithm on the fly, at load time, we combine the\nOpen Multilingual Wordnet (OMW 1.4, which uses old PWN 3.0 identifiers) with\nOEWN Edition 2021, and obtain almost perfect precision and recall. We compare\nthe results of our approach using respectively synset offsets, versus the\nCollaborative InterLingual Index (CILI version 1.0) as synset identifiers, and\nfind that the synset offsets perform better than CILI 1.0 in all cases, except\na few ties.\n","authors":["Eric Kafe"],"pdf_url":"https://arxiv.org/pdf/2303.01847v1.pdf","comment":"Presented at GWC 2023"},{"id":"http://arxiv.org/abs/2303.01795v1","updated":"2023-03-03T09:13:23Z","published":"2023-03-03T09:13:23Z","title":"PAGE: A Position-Aware Graph-Based Model for Emotion Cause Entailment in\n  Conversation","summary":"  Conversational Causal Emotion Entailment (C2E2) is a task that aims at\nrecognizing the causes corresponding to a target emotion in a conversation. The\norder of utterances in the conversation affects the causal inference. However,\nmost current position encoding strategies ignore the order relation among\nutterances and speakers. To address the issue, we devise a novel position-aware\ngraph to encode the entire conversation, fully modeling causal relations among\nutterances. The comprehensive experiments show that our method consistently\nachieves state-of-the-art performance on two challenging test sets, proving the\neffectiveness of our model. Our source code is available on Github:\nhttps://github.com/XiaojieGu/PAGE.\n","authors":["Xiaojie Gu","Renze Lou","Lin Sun","Shangxin Li"],"pdf_url":"https://arxiv.org/pdf/2303.01795v1.pdf","comment":"ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.01794v1","updated":"2023-03-03T09:12:55Z","published":"2023-03-03T09:12:55Z","title":"Team Hitachi at SemEval-2023 Task 3: Exploring Cross-lingual Multi-task\n  Strategies for Genre and Framing Detection in Online News","summary":"  This paper explains the participation of team Hitachi to SemEval-2023 Task 3\n\"Detecting the genre, the framing, and the persuasion techniques in online news\nin a multi-lingual setup.\" Based on the multilingual, multi-task nature of the\ntask and the setting that training data is limited, we investigated different\nstrategies for training the pretrained language models under low resource\nsettings. Through extensive experiments, we found that (a)\ncross-lingual/multi-task training, and (b) collecting an external balanced\ndataset, can benefit the genre and framing detection. We constructed ensemble\nmodels from the results and achieved the highest macro-averaged F1 scores in\nItalian and Russian genre categorization subtasks.\n","authors":["Yuta Koreeda","Ken-ichi Yokote","Hiroaki Ozaki","Atsuki Yamaguchi","Masaya Tsunokake","Yasuhiro Sogawa"],"pdf_url":"https://arxiv.org/pdf/2303.01794v1.pdf","comment":"Submitted to SemEval-2023 Task 3"},{"id":"http://arxiv.org/abs/2303.01793v1","updated":"2023-03-03T09:07:30Z","published":"2023-03-03T09:07:30Z","title":"Exploiting Language Relatedness in Machine Translation Through Domain\n  Adaptation Techniques","summary":"  One of the significant challenges of Machine Translation (MT) is the scarcity\nof large amounts of data, mainly parallel sentence aligned corpora. If the\nevaluation is as rigorous as resource-rich languages, both Neural Machine\nTranslation (NMT) and Statistical Machine Translation (SMT) can produce good\nresults with such large amounts of data. However, it is challenging to improve\nthe quality of MT output for low resource languages, especially in NMT and SMT.\nIn order to tackle the challenges faced by MT, we present a novel approach of\nusing a scaled similarity score of sentences, especially for related languages\nbased on a 5-gram KenLM language model with Kneser-ney smoothing technique for\nfiltering in-domain data from out-of-domain corpora that boost the translation\nquality of MT. Furthermore, we employ other domain adaptation techniques such\nas multi-domain, fine-tuning and iterative back-translation approach to compare\nour novel approach on the Hindi-Nepali language pair for NMT and SMT. Our\napproach succeeds in increasing ~2 BLEU point on multi-domain approach, ~3 BLEU\npoint on fine-tuning for NMT and ~2 BLEU point on iterative back-translation\napproach.\n","authors":["Amit Kumar","Rupjyoti Baruah","Ajay Pratap","Mayank Swarnkar","Anil Kumar Singh"],"pdf_url":"https://arxiv.org/pdf/2303.01793v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01781v1","updated":"2023-03-03T08:44:20Z","published":"2023-03-03T08:44:20Z","title":"Meme Sentiment Analysis Enhanced with Multimodal Spatial Encoding and\n  Facial Embedding","summary":"  Internet memes are characterised by the interspersing of text amongst visual\nelements. State-of-the-art multimodal meme classifiers do not account for the\nrelative positions of these elements across the two modalities, despite the\nlatent meaning associated with where text and visual elements are placed.\nAgainst two meme sentiment classification datasets, we systematically show\nperformance gains from incorporating the spatial position of visual objects,\nfaces, and text clusters extracted from memes. In addition, we also present\nfacial embedding as an impactful enhancement to image representation in a\nmultimodal meme classifier. Finally, we show that incorporating this spatial\ninformation allows our fully automated approaches to outperform their\ncorresponding baselines that rely on additional human validation of\nOCR-extracted text.\n","authors":["Muzhaffar Hazman","Susan McKeever","Josephine Griffith"],"pdf_url":"https://arxiv.org/pdf/2303.01781v1.pdf","comment":"Published as chapter in ISBN:978-3-031-26438-2"},{"id":"http://arxiv.org/abs/2208.10806v2","updated":"2023-03-03T07:42:54Z","published":"2022-08-23T08:27:52Z","title":"Learning Better Masking for Better Language Model Pre-training","summary":"  Masked Language Modeling (MLM) has been widely used as the denoising\nobjective in pre-training language models (PrLMs). Existing PrLMs commonly\nadopt a Random-Token Masking strategy where a fixed masking ratio is applied\nand different contents are masked by an equal probability throughout the entire\ntraining. However, the model may receive complicated impact from pre-training\nstatus, which changes accordingly as training time goes on. In this paper, we\nshow that such time-invariant MLM settings on masking ratio and masked content\nare unlikely to deliver an optimal outcome, which motivates us to explore the\ninfluence of time-variant MLM settings. We propose two scheduled masking\napproaches that adaptively tune the masking ratio and masked content in\ndifferent training stages, which improves the pre-training efficiency and\neffectiveness verified on the downstream tasks. Our work is a pioneer study on\ntime-variant masking strategy on ratio and content and gives a better\nunderstanding of how masking ratio and masked content influence the MLM\npre-training.\n","authors":["Dongjie Yang","Zhuosheng Zhang","Hai Zhao"],"pdf_url":"https://arxiv.org/pdf/2208.10806v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01742v1","updated":"2023-03-03T07:07:04Z","published":"2023-03-03T07:07:04Z","title":"NCL: Textual Backdoor Defense Using Noise-augmented Contrastive Learning","summary":"  At present, backdoor attacks attract attention as they do great harm to deep\nlearning models. The adversary poisons the training data making the model being\ninjected with a backdoor after being trained unconsciously by victims using the\npoisoned dataset. In the field of text, however, existing works do not provide\nsufficient defense against backdoor attacks. In this paper, we propose a\nNoise-augmented Contrastive Learning (NCL) framework to defend against textual\nbackdoor attacks when training models with untrustworthy data. With the aim of\nmitigating the mapping between triggers and the target label, we add\nappropriate noise perturbing possible backdoor triggers, augment the training\ndataset, and then pull homology samples in the feature space utilizing\ncontrastive learning objective. Experiments demonstrate the effectiveness of\nour method in defending three types of textual backdoor attacks, outperforming\nthe prior works.\n","authors":["Shengfang Zhai","Qingni Shen","Xiaoyi Chen","Weilong Wang","Cong Li","Yuejian Fang","Zhonghai Wu"],"pdf_url":"https://arxiv.org/pdf/2303.01742v1.pdf","comment":"6 pages, 5 figures. To appear in ICASSP 2023"},{"id":"http://arxiv.org/abs/2302.07845v2","updated":"2023-03-03T04:55:05Z","published":"2023-02-15T18:31:36Z","title":"NL2CMD: An Updated Workflow for Natural Language to Bash Commands\n  Translation","summary":"  Translating natural language into Bash Commands is an emerging research field\nthat has gained attention in recent years. Most efforts have focused on\nproducing more accurate translation models. To the best of our knowledge, only\ntwo datasets are available, with one based on the other. Both datasets involve\nscraping through known data sources (through platforms like stack overflow,\ncrowdsourcing, etc.) and hiring experts to validate and correct either the\nEnglish text or Bash Commands. This paper provides two contributions to\nresearch on synthesizing Bash Commands from scratch. First, we describe a\nstate-of-the-art translation model used to generate Bash Commands from the\ncorresponding English text. Second, we introduce a new NL2CMD dataset that is\nautomatically generated, involves minimal human intervention, and is over six\ntimes larger than prior datasets. Since the generation pipeline does not rely\non existing Bash Commands, the distribution and types of commands can be custom\nadjusted. We evaluate the performance of ChatGPT on this task and discuss the\npotential of using it as a data generator. Our empirical results show how the\nscale and diversity of our dataset can offer unique opportunities for semantic\nparsing researchers.\n","authors":["Quchen Fu","Zhongwei Teng","Marco Georgaklis","Jules White","Douglas C. Schmidt"],"pdf_url":"https://arxiv.org/pdf/2302.07845v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10871v2","updated":"2023-03-03T04:54:25Z","published":"2023-01-25T23:32:32Z","title":"Qualitative Analysis of a Graph Transformer Approach to Addressing Hate\n  Speech: Adapting to Dynamically Changing Content","summary":"  Our work advances an approach for predicting hate speech in social media,\ndrawing out the critical need to consider the discussions that follow a post to\nsuccessfully detect when hateful discourse may arise. Using graph transformer\nnetworks, coupled with modelling attention and BERT-level natural language\nprocessing, our approach can capture context and anticipate upcoming\nanti-social behaviour. In this paper, we offer a detailed qualitative analysis\nof this solution for hate speech detection in social networks, leading to\ninsights into where the method has the most impressive outcomes in comparison\nwith competitors and identifying scenarios where there are challenges to\nachieving ideal performance. Included is an exploration of the kinds of posts\nthat permeate social media today, including the use of hateful images. This\nsuggests avenues for extending our model to be more comprehensive. A key\ninsight is that the focus on reasoning about the concept of context positions\nus well to be able to support multi-modal analysis of online posts. We conclude\nwith a reflection on how the problem we are addressing relates especially well\nto the theme of dynamic change, a critical concern for all AI solutions for\nsocial impact. We also comment briefly on how mental health well-being can be\nadvanced with our work, through curated content attuned to the extent of hate\nin posts.\n","authors":["Liam Hebert","Hong Yi Chen","Robin Cohen","Lukasz Golab"],"pdf_url":"https://arxiv.org/pdf/2301.10871v2.pdf","comment":"Accepted at AAAI 2023 AI for Social Good"},{"id":"http://arxiv.org/abs/2208.13661v2","updated":"2023-03-03T03:42:13Z","published":"2022-08-29T15:09:28Z","title":"LED: Lexicon-Enlightened Dense Retriever for Large-Scale Retrieval","summary":"  Retrieval models based on dense representations in semantic space have become\nan indispensable branch for first-stage retrieval. These retrievers benefit\nfrom surging advances in representation learning towards compressive global\nsequence-level embeddings. However, they are prone to overlook local salient\nphrases and entity mentions in texts, which usually play pivot roles in\nfirst-stage retrieval. To mitigate this weakness, we propose to make a dense\nretriever align a well-performing lexicon-aware representation model. The\nalignment is achieved by weakened knowledge distillations to enlighten the\nretriever via two aspects -- 1) a lexicon-augmented contrastive objective to\nchallenge the dense encoder and 2) a pair-wise rank-consistent regularization\nto make dense model's behavior incline to the other. We evaluate our model on\nthree public benchmarks, which shows that with a comparable lexicon-aware\nretriever as the teacher, our proposed dense one can bring consistent and\nsignificant improvements, and even outdo its teacher. In addition, we found our\nimprovement on the dense retriever is complementary to the standard ranker\ndistillation, which can further lift state-of-the-art performance.\n","authors":["Kai Zhang","Chongyang Tao","Tao Shen","Can Xu","Xiubo Geng","Binxing Jiao","Daxin Jiang"],"pdf_url":"https://arxiv.org/pdf/2208.13661v2.pdf","comment":"14 pages, 6 tables, 4 figures. WWW 2023"},{"id":"http://arxiv.org/abs/2303.01694v1","updated":"2023-03-03T03:26:53Z","published":"2023-03-03T03:26:53Z","title":"DWFormer: Dynamic Window transFormer for Speech Emotion Recognition","summary":"  Speech emotion recognition is crucial to human-computer interaction. The\ntemporal regions that represent different emotions scatter in different parts\nof the speech locally. Moreover, the temporal scales of important information\nmay vary over a large range within and across speech segments. Although\ntransformer-based models have made progress in this field, the existing models\ncould not precisely locate important regions at different temporal scales. To\naddress the issue, we propose Dynamic Window transFormer (DWFormer), a new\narchitecture that leverages temporal importance by dynamically splitting\nsamples into windows. Self-attention mechanism is applied within windows for\ncapturing temporal important information locally in a fine-grained way.\nCross-window information interaction is also taken into account for global\ncommunication. DWFormer is evaluated on both the IEMOCAP and the MELD datasets.\nExperimental results show that the proposed model achieves better performance\nthan the previous state-of-the-art methods.\n","authors":["Shuaiqi Chen","Xiaofen Xing","Weibin Zhang","Weidong Chen","Xiangmin Xu"],"pdf_url":"https://arxiv.org/pdf/2303.01694v1.pdf","comment":"4 pages, 5 figures, 3 tables, accepted by 2023 International\n  Conference on Acoustics, Speech, and Signal Processing (ICASSP2023)"},{"id":"http://arxiv.org/abs/2108.10015v2","updated":"2023-03-03T01:58:16Z","published":"2021-08-23T09:05:18Z","title":"Semantic-Preserving Adversarial Text Attacks","summary":"  Deep neural networks (DNNs) are known to be vulnerable to adversarial images,\nwhile their robustness in text classification is rarely studied. Several lines\nof text attack methods have been proposed in the literature, including\ncharacter-level, word-level, and sentence-level attacks. However, it is still a\nchallenge to minimize the number of word changes necessary to induce\nmisclassification, while simultaneously ensuring lexical correctness, syntactic\nsoundness, and semantic similarity. In this paper, we propose a Bigram and\nUnigram based adaptive Semantic Preservation Optimization (BU-SPO) method to\nexamine the vulnerability of deep models. Our method has four major merits.\nFirstly, we propose to attack text documents not only at the unigram word level\nbut also at the bigram level which better keeps semantics and avoids producing\nmeaningless outputs. Secondly, we propose a hybrid method to replace the input\nwords with options among both their synonyms candidates and sememe candidates,\nwhich greatly enriches the potential substitutions compared to only using\nsynonyms. Thirdly, we design an optimization algorithm, i.e., Semantic\nPreservation Optimization (SPO), to determine the priority of word\nreplacements, aiming to reduce the modification cost. Finally, we further\nimprove the SPO with a semantic Filter (named SPOF) to find the adversarial\nexample with the highest semantic similarity. We evaluate the effectiveness of\nour BU-SPO and BU-SPOF on IMDB, AG's News, and Yahoo! Answers text datasets by\nattacking four popular DNNs models. Results show that our methods achieve the\nhighest attack success rates and semantics rates by changing the smallest\nnumber of words compared with existing methods.\n","authors":["Xinghao Yang","Weifeng Liu","James Bailey","Dacheng Tao","Wei Liu"],"pdf_url":"https://arxiv.org/pdf/2108.10015v2.pdf","comment":"12 pages, 3 figures, 10 tables"},{"id":"http://arxiv.org/abs/2303.01037v2","updated":"2023-03-03T01:18:52Z","published":"2023-03-02T07:47:18Z","title":"Google USM: Scaling Automatic Speech Recognition Beyond 100 Languages","summary":"  We introduce the Universal Speech Model (USM), a single large model that\nperforms automatic speech recognition (ASR) across 100+ languages. This is\nachieved by pre-training the encoder of the model on a large unlabeled\nmultilingual dataset of 12 million (M) hours spanning over 300 languages, and\nfine-tuning on a smaller labeled dataset. We use multilingual pre-training with\nrandom-projection quantization and speech-text modality matching to achieve\nstate-of-the-art performance on downstream multilingual ASR and speech-to-text\ntranslation tasks. We also demonstrate that despite using a labeled training\nset 1/7-th the size of that used for the Whisper model, our model exhibits\ncomparable or better performance on both in-domain and out-of-domain speech\nrecognition tasks across many languages.\n","authors":["Yu Zhang","Wei Han","James Qin","Yongqiang Wang","Ankur Bapna","Zhehuai Chen","Nanxin Chen","Bo Li","Vera Axelrod","Gary Wang","Zhong Meng","Ke Hu","Andrew Rosenberg","Rohit Prabhavalkar","Daniel S. Park","Parisa Haghani","Jason Riesa","Ginger Perng","Hagen Soltau","Trevor Strohman","Bhuvana Ramabhadran","Tara Sainath","Pedro Moreno","Chung-Cheng Chiu","Johan Schalkwyk","Françoise Beaufays","Yonghui Wu"],"pdf_url":"https://arxiv.org/pdf/2303.01037v2.pdf","comment":"20 pages, 7 figures, 8 tables"},{"id":"http://arxiv.org/abs/2303.01645v1","updated":"2023-03-03T00:38:01Z","published":"2023-03-03T00:38:01Z","title":"APIContext2Com: Code Comment Generation by Incorporating Pre-Defined API\n  Documentation","summary":"  Code comments are significantly helpful in comprehending software programs\nand also aid developers to save a great deal of time in software maintenance.\nCode comment generation aims to automatically predict comments in natural\nlanguage given a code snippet. Several works investigate the effect of\nintegrating external knowledge on the quality of generated comments. In this\nstudy, we propose a solution, namely APIContext2Com, to improve the\neffectiveness of generated comments by incorporating the pre-defined\nApplication Programming Interface (API) context. The API context includes the\ndefinition and description of the pre-defined APIs that are used within the\ncode snippets. As the detailed API information expresses the functionality of a\ncode snippet, it can be helpful in better generating the code summary. We\nintroduce a seq-2-seq encoder-decoder neural network model with different sets\nof multiple encoders to effectively transform distinct inputs into target\ncomments. A ranking mechanism is also developed to exclude non-informative\nAPIs, so that we can filter out unrelated APIs. We evaluate our approach using\nthe Java dataset from CodeSearchNet. The findings reveal that the proposed\nmodel improves the best baseline by 1.88 (8.24 %), 2.16 (17.58 %), 1.38 (18.3\n%), 0.73 (14.17 %), 1.58 (14.98 %) and 1.9 (6.92 %) for BLEU1, BLEU2, BLEU3,\nBLEU4, METEOR, ROUGE-L respectively. Human evaluation and ablation studies\nconfirm the quality of the generated comments and the effect of architecture\nand ranking APIs.\n","authors":["Ramin Shahbazi","Fatemeh Fard"],"pdf_url":"https://arxiv.org/pdf/2303.01645v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2107.09099v3","updated":"2023-03-03T23:49:19Z","published":"2021-07-19T18:24:33Z","title":"Token-Level Supervised Contrastive Learning for Punctuation Restoration","summary":"  Punctuation is critical in understanding natural language text. Currently,\nmost automatic speech recognition (ASR) systems do not generate punctuation,\nwhich affects the performance of downstream tasks, such as intent detection and\nslot filling. This gives rise to the need for punctuation restoration. Recent\nwork in punctuation restoration heavily utilizes pre-trained language models\nwithout considering data imbalance when predicting punctuation classes. In this\nwork, we address this problem by proposing a token-level supervised contrastive\nlearning method that aims at maximizing the distance of representation of\ndifferent punctuation marks in the embedding space. The result shows that\ntraining with token-level supervised contrastive learning obtains up to 3.2%\nabsolute F1 improvement on the test set.\n","authors":["Qiushi Huang","Tom Ko","H Lilian Tang","Xubo Liu","Bo Wu"],"pdf_url":"https://arxiv.org/pdf/2107.09099v3.pdf","comment":"5 pages, 3 figures, Accepted by INTERSPEECH 2021"},{"id":"http://arxiv.org/abs/2303.02260v1","updated":"2023-03-03T23:19:42Z","published":"2023-03-03T23:19:42Z","title":"Learning to reason over visual objects","summary":"  A core component of human intelligence is the ability to identify abstract\npatterns inherent in complex, high-dimensional perceptual data, as exemplified\nby visual reasoning tasks such as Raven's Progressive Matrices (RPM). Motivated\nby the goal of designing AI systems with this capacity, recent work has focused\non evaluating whether neural networks can learn to solve RPM-like problems.\nPrevious work has generally found that strong performance on these problems\nrequires the incorporation of inductive biases that are specific to the RPM\nproblem format, raising the question of whether such models might be more\nbroadly useful. Here, we investigated the extent to which a general-purpose\nmechanism for processing visual scenes in terms of objects might help promote\nabstract visual reasoning. We found that a simple model, consisting only of an\nobject-centric encoder and a transformer reasoning module, achieved\nstate-of-the-art results on both of two challenging RPM-like benchmarks (PGM\nand I-RAVEN), as well as a novel benchmark with greater visual complexity\n(CLEVR-Matrices). These results suggest that an inductive bias for\nobject-centric processing may be a key component of abstract visual reasoning,\nobviating the need for problem-specific inductive biases.\n","authors":["Shanka Subhra Mondal","Taylor Webb","Jonathan D. Cohen"],"pdf_url":"https://arxiv.org/pdf/2303.02260v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.02242v1","updated":"2023-03-03T22:19:22Z","published":"2023-03-03T22:19:22Z","title":"TrojText: Test-time Invisible Textual Trojan Insertion","summary":"  In Natural Language Processing (NLP), intelligent neuron models can be\nsusceptible to textual Trojan attacks. Such attacks occur when Trojan models\nbehave normally for standard inputs but generate malicious output for inputs\nthat contain a specific trigger. Syntactic-structure triggers, which are\ninvisible, are becoming more popular for Trojan attacks because they are\ndifficult to detect and defend against. However, these types of attacks require\na large corpus of training data to generate poisoned samples with the necessary\nsyntactic structures for Trojan insertion. Obtaining such data can be difficult\nfor attackers, and the process of generating syntactic poisoned triggers and\ninserting Trojans can be time-consuming. This paper proposes a solution called\nTrojText, which aims to determine whether invisible textual Trojan attacks can\nbe performed more efficiently and cost-effectively without training data. The\nproposed approach, called the Representation-Logit Trojan Insertion (RLI)\nalgorithm, uses smaller sampled test data instead of large training data to\nachieve the desired attack. The paper also introduces two additional\ntechniques, namely the accumulated gradient ranking (AGR) and Trojan Weights\nPruning (TWP), to reduce the number of tuned parameters and the attack\noverhead. The TrojText approach was evaluated on three datasets (AG's News,\nSST-2, and OLID) using three NLP models (BERT, XLNet, and DeBERTa). The\nexperiments demonstrated that the TrojText approach achieved a 98.35\\%\nclassification accuracy for test sentences in the target class on the BERT\nmodel for the AG's News dataset. The source code for TrojText is available at\nhttps://github.com/UCF-ML-Research/TrojText.\n","authors":["Yepeng Liu","Bo Feng","Qian Lou"],"pdf_url":"https://arxiv.org/pdf/2303.02242v1.pdf","comment":"ICLR 2023 Camera Ready"},{"id":"http://arxiv.org/abs/2303.02206v1","updated":"2023-03-03T20:35:38Z","published":"2023-03-03T20:35:38Z","title":"Answering Questions Over Knowledge Graphs Using Logic Programming Along\n  with Language Models","summary":"  Question Answering over Knowledge Graphs (KGQA) is the task of answering\nnatural language questions over a knowledge graph (KG). This task requires a\nmodel to reason over multiple edges of the KG to reach the right answer. In\nthis work, we present a method to equip large language models (LLMs) with\nclassic logical programming languages to provide an explainable solution to the\nproblem. Our goal is to extract the representation of the question in the form\nof a Prolog query, which can then be used to answer the query programmatically.\nTo demonstrate the effectiveness of this approach, we use the MetaQA dataset\nand show that our method finds the correct answer entities for all the\nquestions in the test dataset.\n","authors":["Navid Madani","Kenneth Joseph"],"pdf_url":"https://arxiv.org/pdf/2303.02206v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02198v1","updated":"2023-03-03T20:15:35Z","published":"2023-03-03T20:15:35Z","title":"Exploring Data Augmentation Methods on Social Media Corpora","summary":"  Data augmentation has proven widely effective in computer vision. In Natural\nLanguage Processing (NLP) data augmentation remains an area of active research.\nThere is no widely accepted augmentation technique that works well across tasks\nand model architectures. In this paper we explore data augmentation techniques\nin the context of text classification using two social media datasets. We\nexplore popular varieties of data augmentation, starting with oversampling,\nEasy Data Augmentation (Wei and Zou, 2019) and Back-Translation (Sennrich et\nal., 2015). We also consider Greyscaling, a relatively unexplored data\naugmentation technique that seeks to mitigate the intensity of adjectives in\nexamples. Finally, we consider a few-shot learning approach: Pattern-Exploiting\nTraining (PET) (Schick et al., 2020). For the experiments we use a BERT\ntransformer architecture. Results show that augmentation techniques provide\nonly minimal and inconsistent improvements. Synonym replacement provided\nevidence of some performance improvement and adjective scales with Grayscaling\nis an area where further exploration would be valuable. Few-shot learning\nexperiments show consistent improvement over supervised training, and seem very\npromising when classes are easily separable but further exploration would be\nvaluable.\n","authors":["Isabel Garcia Pietri","Kineret Stanley"],"pdf_url":"https://arxiv.org/pdf/2303.02198v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03177v1","updated":"2023-03-03T18:22:32Z","published":"2023-03-03T18:22:32Z","title":"Pre-trained Model Representations and their Robustness against Noise for\n  Speech Emotion Analysis","summary":"  Pre-trained model representations have demonstrated state-of-the-art\nperformance in speech recognition, natural language processing, and other\napplications. Speech models, such as Bidirectional Encoder Representations from\nTransformers (BERT) and Hidden units BERT (HuBERT), have enabled generating\nlexical and acoustic representations to benefit speech recognition\napplications. We investigated the use of pre-trained model representations for\nestimating dimensional emotions, such as activation, valence, and dominance,\nfrom speech. We observed that while valence may rely heavily on lexical\nrepresentations, activation and dominance rely mostly on acoustic information.\nIn this work, we used multi-modal fusion representations from pre-trained\nmodels to generate state-of-the-art speech emotion estimation, and we showed a\n100% and 30% relative improvement in concordance correlation coefficient (CCC)\non valence estimation compared to standard acoustic and lexical baselines.\nFinally, we investigated the robustness of pre-trained model representations\nagainst noise and reverberation degradation and noticed that lexical and\nacoustic representations are impacted differently. We discovered that lexical\nrepresentations are more robust to distortions compared to acoustic\nrepresentations, and demonstrated that knowledge distillation from a\nmulti-modal model helps to improve the noise-robustness of acoustic-based\nmodels.\n","authors":["Vikramjit Mitra","Vasudha Kowtha","Hsiang-Yun Sherry Chien","Erdrin Azemi","Carlos Avendano"],"pdf_url":"https://arxiv.org/pdf/2303.03177v1.pdf","comment":"5 pages, conference"},{"id":"http://arxiv.org/abs/2303.03186v1","updated":"2023-03-03T16:11:37Z","published":"2023-03-03T16:11:37Z","title":"Will Affective Computing Emerge from Foundation Models and General AI? A\n  First Evaluation on ChatGPT","summary":"  ChatGPT has shown the potential of emerging general artificial intelligence\ncapabilities, as it has demonstrated competent performance across many natural\nlanguage processing tasks. In this work, we evaluate the capabilities of\nChatGPT to perform text classification on three affective computing problems,\nnamely, big-five personality prediction, sentiment analysis, and suicide\ntendency detection. We utilise three baselines, a robust language model\n(RoBERTa-base), a legacy word model with pretrained embeddings (Word2Vec), and\na simple bag-of-words baseline (BoW). Results show that the RoBERTa trained for\na specific downstream task generally has a superior performance. On the other\nhand, ChatGPT provides decent results, and is relatively comparable to the\nWord2Vec and BoW baselines. ChatGPT further shows robustness against noisy\ndata, where Word2Vec models achieve worse results due to noise. Results\nindicate that ChatGPT is a good generalist model that is capable of achieving\ngood results across various problems without any specialised training, however,\nit is not as good as a specialised model for a downstream task.\n","authors":["Mostafa M. Amin","Erik Cambria","Björn W. Schuller"],"pdf_url":"https://arxiv.org/pdf/2303.03186v1.pdf","comment":"9 Pages (8 pages + 1 page for references), 1 Figure, 3 Tables"},{"id":"http://arxiv.org/abs/2303.03165v1","updated":"2023-03-03T12:27:24Z","published":"2023-03-03T12:27:24Z","title":"Multi label classification of Artificial Intelligence related patents\n  using Modified D2SBERT and Sentence Attention mechanism","summary":"  Patent classification is an essential task in patent information management\nand patent knowledge mining. It is very important to classify patents related\nto artificial intelligence, which is the biggest topic these days. However,\nartificial intelligence-related patents are very difficult to classify because\nit is a mixture of complex technologies and legal terms. Moreover, due to the\nunsatisfactory performance of current algorithms, it is still mostly done\nmanually, wasting a lot of time and money. Therefore, we present a method for\nclassifying artificial intelligence-related patents published by the USPTO\nusing natural language processing technique and deep learning methodology. We\nuse deformed BERT and sentence attention overcome the limitations of BERT. Our\nexperiment result is highest performance compared to other deep learning\nmethods.\n","authors":["Yongmin Yoo","Tak-Sung Heo","Dongjin Lim","Deaho Seo"],"pdf_url":"https://arxiv.org/pdf/2303.03165v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03329v1","updated":"2023-03-03T01:46:41Z","published":"2023-03-03T01:46:41Z","title":"End-to-End Speech Recognition: A Survey","summary":"  In the last decade of automatic speech recognition (ASR) research, the\nintroduction of deep learning brought considerable reductions in word error\nrate of more than 50% relative, compared to modeling without deep learning. In\nthe wake of this transition, a number of all-neural ASR architectures were\nintroduced. These so-called end-to-end (E2E) models provide highly integrated,\ncompletely neural ASR models, which rely strongly on general machine learning\nknowledge, learn more consistently from data, while depending less on ASR\ndomain-specific experience. The success and enthusiastic adoption of deep\nlearning accompanied by more generic model architectures lead to E2E models now\nbecoming the prominent ASR approach. The goal of this survey is to provide a\ntaxonomy of E2E ASR models and corresponding improvements, and to discuss their\nproperties and their relation to the classical hidden Markov model (HMM) based\nASR architecture. All relevant aspects of E2E ASR are covered in this work:\nmodeling, training, decoding, and external language model integration,\naccompanied by discussions of performance and deployment opportunities, as well\nas an outlook into potential future developments.\n","authors":["Rohit Prabhavalkar","Takaaki Hori","Tara N. Sainath","Ralf Schlüter","Shinji Watanabe"],"pdf_url":"https://arxiv.org/pdf/2303.03329v1.pdf","comment":"Submitted to IEEE/ACM Transactions on Audio, Speech, and Language\n  Processing"},{"id":"http://arxiv.org/abs/2303.03922v1","updated":"2023-03-03T02:58:17Z","published":"2023-03-03T02:58:17Z","title":"Structure Pretraining and Prompt Tuning for Knowledge Graph Transfer","summary":"  Knowledge graphs (KG) are essential background knowledge providers in many\ntasks. When designing models for KG-related tasks, one of the key tasks is to\ndevise the Knowledge Representation and Fusion (KRF) module that learns the\nrepresentation of elements from KGs and fuses them with task representations.\nWhile due to the difference of KGs and perspectives to be considered during\nfusion across tasks, duplicate and ad hoc KRF modules design are conducted\namong tasks. In this paper, we propose a novel knowledge graph pretraining\nmodel KGTransformer that could serve as a uniform KRF module in diverse\nKG-related tasks. We pretrain KGTransformer with three self-supervised tasks\nwith sampled sub-graphs as input. For utilization, we propose a general\nprompt-tuning mechanism regarding task data as a triple prompt to allow\nflexible interactions between task KGs and task data. We evaluate pretrained\nKGTransformer on three tasks, triple classification, zero-shot image\nclassification, and question answering. KGTransformer consistently achieves\nbetter results than specifically designed task models. Through experiments, we\njustify that the pretrained KGTransformer could be used off the shelf as a\ngeneral and effective KRF module across KG-related tasks. The code and datasets\nare available at https://github.com/zjukg/KGTransformer.\n","authors":["Wen Zhang","Yushan Zhu","Mingyang Chen","Yuxia Geng","Yufeng Huang","Yajing Xu","Wenting Song","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2303.03922v1.pdf","comment":"Work accepted by WWW2023"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2303.02153v1","updated":"2023-03-03T18:59:47Z","published":"2023-03-03T18:59:47Z","title":"Unleashing Text-to-Image Diffusion Models for Visual Perception","summary":"  Diffusion models (DMs) have become the new trend of generative models and\nhave demonstrated a powerful ability of conditional synthesis. Among those,\ntext-to-image diffusion models pre-trained on large-scale image-text pairs are\nhighly controllable by customizable prompts. Unlike the unconditional\ngenerative models that focus on low-level attributes and details, text-to-image\ndiffusion models contain more high-level knowledge thanks to the\nvision-language pre-training. In this paper, we propose VPD (Visual Perception\nwith a pre-trained Diffusion model), a new framework that exploits the semantic\ninformation of a pre-trained text-to-image diffusion model in visual perception\ntasks. Instead of using the pre-trained denoising autoencoder in a\ndiffusion-based pipeline, we simply use it as a backbone and aim to study how\nto take full advantage of the learned knowledge. Specifically, we prompt the\ndenoising decoder with proper textual inputs and refine the text features with\nan adapter, leading to a better alignment to the pre-trained stage and making\nthe visual contents interact with the text prompts. We also propose to utilize\nthe cross-attention maps between the visual features and the text features to\nprovide explicit guidance. Compared with other pre-training methods, we show\nthat vision-language pre-trained diffusion models can be faster adapted to\ndownstream visual perception tasks using the proposed VPD. Extensive\nexperiments on semantic segmentation, referring image segmentation and depth\nestimation demonstrates the effectiveness of our method. Notably, VPD attains\n0.254 RMSE on NYUv2 depth estimation and 73.3% oIoU on RefCOCO-val referring\nimage segmentation, establishing new records on these two benchmarks. Code is\navailable at https://github.com/wl-zhao/VPD\n","authors":["Wenliang Zhao","Yongming Rao","Zuyan Liu","Benlin Liu","Jie Zhou","Jiwen Lu"],"pdf_url":"https://arxiv.org/pdf/2303.02153v1.pdf","comment":"project page: https://vpd.ivg-research.xyz"},{"id":"http://arxiv.org/abs/2303.02151v1","updated":"2023-03-03T18:58:16Z","published":"2023-03-03T18:58:16Z","title":"Prompt, Generate, then Cache: Cascade of Foundation Models makes Strong\n  Few-shot Learners","summary":"  Visual recognition in low-data regimes requires deep neural networks to learn\ngeneralized representations from limited training samples. Recently, CLIP-based\nmethods have shown promising few-shot performance benefited from the\ncontrastive language-image pre-training. We then question, if the more diverse\npre-training knowledge can be cascaded to further assist few-shot\nrepresentation learning. In this paper, we propose CaFo, a Cascade of\nFoundation models that incorporates diverse prior knowledge of various\npre-training paradigms for better few-shot learning. Our CaFo incorporates\nCLIP's language-contrastive knowledge, DINO's vision-contrastive knowledge,\nDALL-E's vision-generative knowledge, and GPT-3's language-generative\nknowledge. Specifically, CaFo works by 'Prompt, Generate, then Cache'. Firstly,\nwe leverage GPT-3 to produce textual inputs for prompting CLIP with rich\ndownstream linguistic semantics. Then, we generate synthetic images via DALL-E\nto expand the few-shot training data without any manpower. At last, we\nintroduce a learnable cache model to adaptively blend the predictions from CLIP\nand DINO. By such collaboration, CaFo can fully unleash the potential of\ndifferent pre-training methods and unify them to perform state-of-the-art for\nfew-shot classification. Code is available at\nhttps://github.com/ZrrSkywalker/CaFo.\n","authors":["Renrui Zhang","Xiangfei Hu","Bohao Li","Siyuan Huang","Hanqiu Deng","Hongsheng Li","Yu Qiao","Peng Gao"],"pdf_url":"https://arxiv.org/pdf/2303.02151v1.pdf","comment":"Accepted by CVPR 2023. Code is available at\n  https://github.com/ZrrSkywalker/CaFo. arXiv admin note: substantial text\n  overlap with arXiv:2209.12255"},{"id":"http://arxiv.org/abs/2303.02133v1","updated":"2023-03-03T18:25:07Z","published":"2023-03-03T18:25:07Z","title":"Depth-based 6DoF Object Pose Estimation using Swin Transformer","summary":"  Accurately estimating the 6D pose of objects is crucial for many\napplications, such as robotic grasping, autonomous driving, and augmented\nreality. However, this task becomes more challenging in poor lighting\nconditions or when dealing with textureless objects. To address this issue,\ndepth images are becoming an increasingly popular choice due to their\ninvariance to a scene's appearance and the implicit incorporation of essential\ngeometric characteristics. However, fully leveraging depth information to\nimprove the performance of pose estimation remains a difficult and\nunder-investigated problem. To tackle this challenge, we propose a novel\nframework called SwinDePose, that uses only geometric information from depth\nimages to achieve accurate 6D pose estimation. SwinDePose first calculates the\nangles between each normal vector defined in a depth image and the three\ncoordinate axes in the camera coordinate system. The resulting angles are then\nformed into an image, which is encoded using Swin Transformer. Additionally, we\napply RandLA-Net to learn the representations from point clouds. The resulting\nimage and point clouds embeddings are concatenated and fed into a semantic\nsegmentation module and a 3D keypoints localization module. Finally, we\nestimate 6D poses using a least-square fitting approach based on the target\nobject's predicted semantic mask and 3D keypoints. In experiments on the\nLineMod and Occlusion LineMod datasets, SwinDePose outperforms existing\nstate-of-the-art methods for 6D object pose estimation using depth images. This\ndemonstrates the effectiveness of our approach and highlights its potential for\nimproving performance in real-world scenarios. Our code is at\nhttps://github.com/zhujunli1993/SwinDePose.\n","authors":["Zhujun Li","Ioannis Stamos"],"pdf_url":"https://arxiv.org/pdf/2303.02133v1.pdf","comment":"8 pages. We have submitted the paper to The IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS 2023) on March 1st 2023"},{"id":"http://arxiv.org/abs/2303.02128v1","updated":"2023-03-03T18:12:46Z","published":"2023-03-03T18:12:46Z","title":"TRUSformer: Improving Prostate Cancer Detection from Micro-Ultrasound\n  Using Attention and Self-Supervision","summary":"  A large body of previous machine learning methods for ultrasound-based\nprostate cancer detection classify small regions of interest (ROIs) of\nultrasound signals that lie within a larger needle trace corresponding to a\nprostate tissue biopsy (called biopsy core). These ROI-scale models suffer from\nweak labeling as histopathology results available for biopsy cores only\napproximate the distribution of cancer in the ROIs. ROI-scale models do not\ntake advantage of contextual information that are normally considered by\npathologists, i.e. they do not consider information about surrounding tissue\nand larger-scale trends when identifying cancer. We aim to improve cancer\ndetection by taking a multi-scale, i.e. ROI-scale and biopsy core-scale,\napproach. Methods: Our multi-scale approach combines (i) an \"ROI-scale\" model\ntrained using self-supervised learning to extract features from small ROIs and\n(ii) a \"core-scale\" transformer model that processes a collection of extracted\nfeatures from multiple ROIs in the needle trace region to predict the tissue\ntype of the corresponding core. Attention maps, as a byproduct, allow us to\nlocalize cancer at the ROI scale. We analyze this method using a dataset of\nmicro-ultrasound acquired from 578 patients who underwent prostate biopsy, and\ncompare our model to baseline models and other large-scale studies in the\nliterature. Results and Conclusions: Our model shows consistent and substantial\nperformance improvements compared to ROI-scale-only models. It achieves 80.3%\nAUROC, a statistically significant improvement over ROI-scale classification.\nWe also compare our method to large studies on prostate cancer detection, using\nother imaging modalities. Our code is publicly available at\nwww.github.com/med-i-lab/TRUSFormer\n","authors":["Mahdi Gilany","Paul Wilson","Andrea Perera-Ortega","Amoon Jamzad","Minh Nguyen Nhat To","Fahimeh Fooladgar","Brian Wodlinger","Purang Abolmaesumi","Parvin Mousavi"],"pdf_url":"https://arxiv.org/pdf/2303.02128v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02123v1","updated":"2023-03-03T18:08:12Z","published":"2023-03-03T18:08:12Z","title":"Skeletal Point Representations with Geometric Deep Learning","summary":"  Skeletonization has been a popular shape analysis technique that models both\nthe interior and exterior of an object. Existing template-based calculations of\nskeletal models from anatomical structures are a time-consuming manual process.\nRecently, learning-based methods have been used to extract skeletons from 3D\nshapes. In this work, we propose novel additional geometric terms for\ncalculating skeletal structures of objects. The results are similar to\ntraditional fitted s-reps but but are produced much more quickly. Evaluation on\nreal clinical data shows that the learned model predicts accurate skeletal\nrepresentations and shows the impact of proposed geometric losses along with\nusing s-reps as weak supervision.\n","authors":["Ninad Khargonkar","Beatriz Paniagua","Jared Vicory"],"pdf_url":"https://arxiv.org/pdf/2303.02123v1.pdf","comment":"5 pages, 5 figures, 2 tables. Accepted to IEEE International\n  Symposium on Biomedical Imaging (ISBI) 2023"},{"id":"http://arxiv.org/abs/2303.02110v1","updated":"2023-03-03T17:51:08Z","published":"2023-03-03T17:51:08Z","title":"Need for Objective Task-based Evaluation of Deep Learning-Based\n  Denoising Methods: A Study in the Context of Myocardial Perfusion SPECT","summary":"  Artificial intelligence-based methods have generated substantial interest in\nnuclear medicine. An area of significant interest has been using deep-learning\n(DL)-based approaches for denoising images acquired with lower doses, shorter\nacquisition times, or both. Objective evaluation of these approaches is\nessential for clinical application. DL-based approaches for denoising\nnuclear-medicine images have typically been evaluated using fidelity-based\nfigures of merit (FoMs) such as RMSE and SSIM. However, these images are\nacquired for clinical tasks and thus should be evaluated based on their\nperformance in these tasks. Our objectives were to (1) investigate whether\nevaluation with these FoMs is consistent with objective clinical-task-based\nevaluation; (2) provide a theoretical analysis for determining the impact of\ndenoising on signal-detection tasks; (3) demonstrate the utility of virtual\nclinical trials (VCTs) to evaluate DL-based methods. A VCT to evaluate a\nDL-based method for denoising myocardial perfusion SPECT (MPS) images was\nconducted. The impact of DL-based denoising was evaluated using fidelity-based\nFoMs and AUC, which quantified performance on detecting perfusion defects in\nMPS images as obtained using a model observer with anthropomorphic channels.\nBased on fidelity-based FoMs, denoising using the considered DL-based method\nled to significantly superior performance. However, based on ROC analysis,\ndenoising did not improve, and in fact, often degraded detection-task\nperformance. The results motivate the need for objective task-based evaluation\nof DL-based denoising approaches. Further, this study shows how VCTs provide a\nmechanism to conduct such evaluations using VCTs. Finally, our theoretical\ntreatment reveals insights into the reasons for the limited performance of the\ndenoising approach.\n","authors":["Zitong Yu","Md Ashequr Rahman","Richard Laforest","Thomas H. Schindler","Robert J. Gropler","Richard L. Wahl","Barry A. Siegel","Abhinav K. Jha"],"pdf_url":"https://arxiv.org/pdf/2303.02110v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.00082v2","updated":"2023-03-03T17:27:47Z","published":"2022-08-31T19:32:17Z","title":"Multi-View Reconstruction using Signed Ray Distance Functions (SRDF)","summary":"  In this paper, we investigate a new optimization framework for multi-view 3D\nshape reconstructions. Recent differentiable rendering approaches have provided\nbreakthrough performances with implicit shape representations though they can\nstill lack precision in the estimated geometries. On the other hand multi-view\nstereo methods can yield pixel wise geometric accuracy with local depth\npredictions along viewing rays. Our approach bridges the gap between the two\nstrategies with a novel volumetric shape representation that is implicit but\nparameterized with pixel depths to better materialize the shape surface with\nconsistent signed distances along viewing rays. The approach retains\npixel-accuracy while benefiting from volumetric integration in the\noptimization. To this aim, depths are optimized by evaluating, at each 3D\nlocation within the volumetric discretization, the agreement between the depth\nprediction consistency and the photometric consistency for the corresponding\npixels. The optimization is agnostic to the associated photo-consistency term\nwhich can vary from a median-based baseline to more elaborate criteria learned\nfunctions. Our experiments demonstrate the benefit of the volumetric\nintegration with depth predictions. They also show that our approach\noutperforms existing approaches over standard 3D benchmarks with better\ngeometry estimations.\n","authors":["Pierre Zins","Yuanlu Xu","Edmond Boyer","Stefanie Wuhrer","Tony Tung"],"pdf_url":"https://arxiv.org/pdf/2209.00082v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02094v1","updated":"2023-03-03T17:24:39Z","published":"2023-03-03T17:24:39Z","title":"Bi-parametric prostate MR image synthesis using pathology and\n  sequence-conditioned stable diffusion","summary":"  We propose an image synthesis mechanism for multi-sequence prostate MR images\nconditioned on text, to control lesion presence and sequence, as well as to\ngenerate paired bi-parametric images conditioned on images e.g. for generating\ndiffusion-weighted MR from T2-weighted MR for paired data, which are two\nchallenging tasks in pathological image synthesis. Our proposed mechanism\nutilises and builds upon the recent stable diffusion model by proposing\nimage-based conditioning for paired data generation. We validate our method\nusing 2D image slices from real suspected prostate cancer patients. The realism\nof the synthesised images is validated by means of a blind expert evaluation\nfor identifying real versus fake images, where a radiologist with 4 years\nexperience reading urological MR only achieves 59.4% accuracy across all tested\nsequences (where chance is 50%). For the first time, we evaluate the realism of\nthe generated pathology by blind expert identification of the presence of\nsuspected lesions, where we find that the clinician performs similarly for both\nreal and synthesised images, with a 2.9 percentage point difference in lesion\nidentification accuracy between real and synthesised images, demonstrating the\npotentials in radiological training purposes. Furthermore, we also show that a\nmachine learning model, trained for lesion identification, shows better\nperformance (76.2% vs 70.4%, statistically significant improvement) when\ntrained with real data augmented by synthesised data as opposed to training\nwith only real images, demonstrating usefulness for model training.\n","authors":["Shaheer U. Saeed","Tom Syer","Wen Yan","Qianye Yang","Mark Emberton","Shonit Punwani","Matthew J. Clarkson","Dean C. Barratt","Yipeng Hu"],"pdf_url":"https://arxiv.org/pdf/2303.02094v1.pdf","comment":"Accepted at MIDL 2023 (The Medical Imaging with Deep Learning\n  conference, 2023)"},{"id":"http://arxiv.org/abs/2303.02095v1","updated":"2023-03-03T17:24:39Z","published":"2023-03-03T17:24:39Z","title":"Data-Efficient Training of CNNs and Transformers with Coresets: A\n  Stability Perspective","summary":"  Coreset selection is among the most effective ways to reduce the training\ntime of CNNs, however, only limited is known on how the resultant models will\nbehave under variations of the coreset size, and choice of datasets and models.\nMoreover, given the recent paradigm shift towards transformer-based models, it\nis still an open question how coreset selection would impact their performance.\nThere are several similar intriguing questions that need to be answered for a\nwide acceptance of coreset selection methods, and this paper attempts to answer\nsome of these. We present a systematic benchmarking setup and perform a\nrigorous comparison of different coreset selection methods on CNNs and\ntransformers. Our investigation reveals that under certain circumstances,\nrandom selection of subsets is more robust and stable when compared with the\nSOTA selection methods. We demonstrate that the conventional concept of uniform\nsubset sampling across the various classes of the data is not the appropriate\nchoice. Rather samples should be adaptively chosen based on the complexity of\nthe data distribution for each class. Transformers are generally pretrained on\nlarge datasets, and we show that for certain target datasets, it helps to keep\ntheir performance stable at even very small coreset sizes. We further show that\nwhen no pretraining is done or when the pretrained transformer models are used\nwith non-natural images (e.g. medical data), CNNs tend to generalize better\nthan transformers at even very small coreset sizes. Lastly, we demonstrate that\nin the absence of the right pretraining, CNNs are better at learning the\nsemantic coherence between spatially distant objects within an image, and these\ntend to outperform transformers at almost all choices of the coreset size.\n","authors":["Animesh Gupta","Irtiza Hassan","Dilip K. Prasad","Deepak K. Gupta"],"pdf_url":"https://arxiv.org/pdf/2303.02095v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.16140v2","updated":"2023-03-03T17:19:40Z","published":"2022-10-28T14:10:24Z","title":"Localized Randomized Smoothing for Collective Robustness Certification","summary":"  Models for image segmentation, node classification and many other tasks map a\nsingle input to multiple labels. By perturbing this single shared input (e.g.\nthe image) an adversary can manipulate several predictions (e.g. misclassify\nseveral pixels). Collective robustness certification is the task of provably\nbounding the number of robust predictions under this threat model. The only\ndedicated method that goes beyond certifying each output independently is\nlimited to strictly local models, where each prediction is associated with a\nsmall receptive field. We propose a more general collective robustness\ncertificate for all types of models. We further show that this approach is\nbeneficial for the larger class of softly local models, where each output is\ndependent on the entire input but assigns different levels of importance to\ndifferent input regions (e.g. based on their proximity in the image). The\ncertificate is based on our novel localized randomized smoothing approach,\nwhere the random perturbation strength for different input regions is\nproportional to their importance for the outputs. Localized smoothing\nPareto-dominates existing certificates on both image segmentation and node\nclassification tasks, simultaneously offering higher accuracy and stronger\ncertificates.\n","authors":["Jan Schuchardt","Tom Wollschläger","Aleksandar Bojchevski","Stephan Günnemann"],"pdf_url":"https://arxiv.org/pdf/2210.16140v2.pdf","comment":"Accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.02091v1","updated":"2023-03-03T17:14:44Z","published":"2023-03-03T17:14:44Z","title":"Delicate Textured Mesh Recovery from NeRF via Adaptive Surface\n  Refinement","summary":"  Neural Radiance Fields (NeRF) have constituted a remarkable breakthrough in\nimage-based 3D reconstruction. However, their implicit volumetric\nrepresentations differ significantly from the widely-adopted polygonal meshes\nand lack support from common 3D software and hardware, making their rendering\nand manipulation inefficient. To overcome this limitation, we present a novel\nframework that generates textured surface meshes from images. Our approach\nbegins by efficiently initializing the geometry and view-dependency decomposed\nappearance with a NeRF. Subsequently, a coarse mesh is extracted, and an\niterative surface refining algorithm is developed to adaptively adjust both\nvertex positions and face density based on re-projected rendering errors. We\njointly refine the appearance with geometry and bake it into texture images for\nreal-time rendering. Extensive experiments demonstrate that our method achieves\nsuperior mesh quality and competitive rendering quality.\n","authors":["Jiaxiang Tang","Hang Zhou","Xiaokang Chen","Tianshu Hu","Errui Ding","Jingdong Wang","Gang Zeng"],"pdf_url":"https://arxiv.org/pdf/2303.02091v1.pdf","comment":"Project Page: https://me.kiui.moe/nerf2mesh"},{"id":"http://arxiv.org/abs/2303.02081v1","updated":"2023-03-03T16:55:44Z","published":"2023-03-03T16:55:44Z","title":"Unproportional mosaicing","summary":"  Data shift is a gap between data distribution used for training and data\ndistribution encountered in the real-world. Data augmentations help narrow the\ngap by generating new data samples, increasing data variability, and data space\ncoverage. We present a new data augmentation: Unproportional mosaicing\n(Unprop). Our augmentation randomly splits an image into various-sized blocks\nand swaps its content (pixels) while maintaining block sizes. Our method\nachieves a lower error rate when combined with other state-of-the-art\naugmentations.\n","authors":["Vojtech Molek","Petr Hurtik","Pavel Vlasanek","David Adamczyk"],"pdf_url":"https://arxiv.org/pdf/2303.02081v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.12240v4","updated":"2023-03-03T16:34:22Z","published":"2022-01-28T16:51:54Z","title":"Continuous Deep Equilibrium Models: Training Neural ODEs faster by\n  integrating them to Infinity","summary":"  Implicit models separate the definition of a layer from the description of\nits solution process. While implicit layers allow features such as depth to\nadapt to new scenarios and inputs automatically, this adaptivity makes its\ncomputational expense challenging to predict. In this manuscript, we increase\nthe \"implicitness\" of the DEQ by redefining the method in terms of an infinite\ntime neural ODE, which paradoxically decreases the training cost over a\nstandard neural ODE by 2-4x. Additionally, we address the question: is there a\nway to simultaneously achieve the robustness of implicit layers while allowing\nthe reduced computational expense of an explicit layer? To solve this, we\ndevelop Skip and Skip Reg. DEQ, an implicit-explicit (IMEX) layer that\nsimultaneously trains an explicit prediction followed by an implicit\ncorrection. We show that training this explicit predictor is free and even\ndecreases the training time by 1.11-3.19x. Together, this manuscript shows how\nbridging the dichotomy of implicit and explicit deep learning can combine the\nadvantages of both techniques.\n","authors":["Avik Pal","Alan Edelman","Christopher Rackauckas"],"pdf_url":"https://arxiv.org/pdf/2201.12240v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02058v1","updated":"2023-03-03T16:28:22Z","published":"2023-03-03T16:28:22Z","title":"3D-Aware Object Localization using Gaussian Implicit Occupancy Function","summary":"  To automatically localize a target object in an image is crucial for many\ncomputer vision applications. Recently ellipse representations have been\nidentified as an alternative to axis-aligned bounding boxes for object\nlocalization. This paper considers 3D-aware ellipse labels, i.e., which are\nprojections of a 3D ellipsoidal approximation of the object in the images for\n2D target localization. Such generic ellipsoidal models allow for handling\ncoarsely known targets, and 3D-aware ellipse detections carry more geometric\ninformation about the object than traditional 3D-agnostic bounding box labels.\nWe propose to have a new look at ellipse regression and replace the geometric\nellipse parameters with the parameters of an implicit Gaussian distribution\nencoding object occupancy in the image. The models are trained to regress the\nvalues of this bivariate Gaussian distribution over the image pixels using a\ncontinuous statistical loss function. We introduce a novel non-trainable\ndifferentiable layer, E-DSNT, to extract the distribution parameters. Also, we\ndescribe how to readily generate consistent 3D-aware Gaussian occupancy\nparameters using only coarse dimensions of the target and relative pose labels.\nWe extend three existing spacecraft pose estimation datasets with 3D-aware\nGaussian occupancy labels to validate our hypothesis.\n","authors":["Vincent Gaudillière","Leo Pauly","Arunkumar Rathinam","Albert Garcia Sanchez","Mohamed Adel Musallam","Djamila Aouada"],"pdf_url":"https://arxiv.org/pdf/2303.02058v1.pdf","comment":"6 pages, 5 figures"},{"id":"http://arxiv.org/abs/2303.02057v1","updated":"2023-03-03T16:26:38Z","published":"2023-03-03T16:26:38Z","title":"Unsupervised Deep Digital Staining For Microscopic Cell Images Via\n  Knowledge Distillation","summary":"  Staining is critical to cell imaging and medical diagnosis, which is\nexpensive, time-consuming, labor-intensive, and causes irreversible changes to\ncell tissues. Recent advances in deep learning enabled digital staining via\nsupervised model training. However, it is difficult to obtain large-scale\nstained/unstained cell image pairs in practice, which need to be perfectly\naligned with the supervision. In this work, we propose a novel unsupervised\ndeep learning framework for the digital staining of cell images using knowledge\ndistillation and generative adversarial networks (GANs). A teacher model is\nfirst trained mainly for the colorization of bright-field images. After that,a\nstudent GAN for staining is obtained by knowledge distillation with hybrid\nnon-reference losses. We show that the proposed unsupervised deep staining\nmethod can generate stained images with more accurate positions and shapes of\nthe cell targets. Compared with other unsupervised deep generative models for\nstaining, our method achieves much more promising results both qualitatively\nand quantitatively.\n","authors":["Ziwang Xu","Lanqing Guo","Shuyan Zhang","Alex C. Kot","Bihan Wen"],"pdf_url":"https://arxiv.org/pdf/2303.02057v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2210.07182v5","updated":"2023-03-03T16:09:32Z","published":"2022-10-13T17:03:36Z","title":"PDEBENCH: An Extensive Benchmark for Scientific Machine Learning","summary":"  Machine learning-based modeling of physical systems has experienced increased\ninterest in recent years. Despite some impressive progress, there is still a\nlack of benchmarks for Scientific ML that are easy to use but still challenging\nand representative of a wide range of problems. We introduce PDEBench, a\nbenchmark suite of time-dependent simulation tasks based on Partial\nDifferential Equations (PDEs). PDEBench comprises both code and data to\nbenchmark the performance of novel machine learning models against both\nclassical numerical simulations and machine learning baselines. Our proposed\nset of benchmark problems contribute the following unique features: (1) A much\nwider range of PDEs compared to existing benchmarks, ranging from relatively\ncommon examples to more realistic and difficult problems; (2) much larger\nready-to-use datasets compared to prior work, comprising multiple simulation\nruns across a larger number of initial and boundary conditions and PDE\nparameters; (3) more extensible source codes with user-friendly APIs for data\ngeneration and baseline results with popular machine learning models (FNO,\nU-Net, PINN, Gradient-Based Inverse Method). PDEBench allows researchers to\nextend the benchmark freely for their own purposes using a standardized API and\nto compare the performance of new models to existing baseline methods. We also\npropose new evaluation metrics with the aim to provide a more holistic\nunderstanding of learning methods in the context of Scientific ML. With those\nmetrics we identify tasks which are challenging for recent ML methods and\npropose these tasks as future challenges for the community. The code is\navailable at https://github.com/pdebench/PDEBench.\n","authors":["Makoto Takamoto","Timothy Praditia","Raphael Leiteritz","Dan MacKinlay","Francesco Alesiani","Dirk Pflüger","Mathias Niepert"],"pdf_url":"https://arxiv.org/pdf/2210.07182v5.pdf","comment":"16 pages (main body) + 34 pages (supplemental material), accepted for\n  publication in NeurIPS 2022 Track Datasets and Benchmarks"},{"id":"http://arxiv.org/abs/1909.03354v7","updated":"2023-03-03T16:04:31Z","published":"2019-09-08T00:01:37Z","title":"Deep Weakly-Supervised Learning Methods for Classification and\n  Localization in Histology Images: A Survey","summary":"  Using deep learning models to diagnose cancer from histology data presents\nseveral challenges. Cancer grading and localization of regions of interest\n(ROIs) in these images normally relies on both image- and pixel-level labels,\nthe latter requiring a costly annotation process. Deep weakly-supervised object\nlocalization (WSOL) methods provide different strategies for low-cost training\nof deep learning models. Using only image-class annotations, these methods can\nbe trained to classify an image, and yield class activation maps (CAMs) for ROI\nlocalization. This paper provides a review of state-of-art DL methods for WSOL.\nWe propose a taxonomy where these methods are divided into bottom-up and\ntop-down methods according to the information flow in models. Although the\nlatter have seen limited progress, recent bottom-up methods are currently\ndriving much progress with deep WSOL methods. Early works focused on designing\ndifferent spatial pooling functions. However, these methods reached limited\nlocalization accuracy, and unveiled a major limitation -- the under-activation\nof CAMs which leads to high false negative localization. Subsequent works aimed\nto alleviate this issue and recover complete object. Representative methods\nfrom our taxonomy are evaluated and compared in terms of classification and\nlocalization accuracy on two challenging histology datasets. Overall, the\nresults indicate poor localization performance, particularly for generic\nmethods that were initially designed to process natural images. Methods\ndesigned to address the challenges of histology data yielded good results.\nHowever, all methods suffer from high false positive/negative localization.\nFour key challenges are identified for the application of deep WSOL methods in\nhistology -- under/over activation of CAMs, sensitivity to thresholding, and\nmodel selection.\n","authors":["Jérôme Rony","Soufiane Belharbi","Jose Dolz","Ismail Ben Ayed","Luke McCaffrey","Eric Granger"],"pdf_url":"https://arxiv.org/pdf/1909.03354v7.pdf","comment":"Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA) https://melba-journal.org/2023:004"},{"id":"http://arxiv.org/abs/2203.06122v2","updated":"2023-03-03T16:02:43Z","published":"2022-03-06T17:51:31Z","title":"Modeling the Shape of the Brain Connectome via Deep Neural Networks","summary":"  The goal of diffusion-weighted magnetic resonance imaging (DWI) is to infer\nthe structural connectivity of an individual subject's brain in vivo. To\nstatistically study the variability and differences between normal and abnormal\nbrain connectomes, a mathematical model of the neural connections is required.\nIn this paper, we represent the brain connectome as a Riemannian manifold,\nwhich allows us to model neural connections as geodesics. This leads to the\nchallenging problem of estimating a Riemannian metric that is compatible with\nthe DWI data, i.e., a metric such that the geodesic curves represent individual\nfiber tracts of the connectomics. We reduce this problem to that of solving a\nhighly nonlinear set of partial differential equations (PDEs) and study the\napplicability of convolutional encoder-decoder neural networks (CEDNNs) for\nsolving this geometrically motivated PDE. Our method achieves excellent\nperformance in the alignment of geodesics with white matter pathways and\ntackles a long-standing issue in previous geodesic tractography methods: the\ninability to recover crossing fibers with high fidelity.\n","authors":["Haocheng Dai","Martin Bauer","P. Thomas Fletcher","Sarang Joshi"],"pdf_url":"https://arxiv.org/pdf/2203.06122v2.pdf","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2303.02034v1","updated":"2023-03-03T15:52:06Z","published":"2023-03-03T15:52:06Z","title":"Linear CNNs Discover the Statistical Structure of the Dataset Using Only\n  the Most Dominant Frequencies","summary":"  Our theoretical understanding of the inner workings of general convolutional\nneural networks (CNN) is limited. We here present a new stepping stone towards\nsuch understanding in the form of a theory of learning in linear CNNs. By\nanalyzing the gradient descent equations, we discover that using convolutions\nleads to a mismatch between the dataset structure and the network structure. We\nshow that linear CNNs discover the statistical structure of the dataset with\nnon-linear, stage-like transitions, and that the speed of discovery changes\ndepending on this structural mismatch. Moreover, we find that the mismatch lies\nat the heart of what we call the 'dominant frequency bias', where linear CNNs\narrive at these discoveries using only the dominant frequencies of the\ndifferent structural parts present in the dataset. Our findings can help\nexplain several characteristics of general CNNs, such as their shortcut\nlearning and their tendency to rely on texture instead of shape.\n","authors":["Hannah Pinson","Joeri Lenaerts","Vincent Ginis"],"pdf_url":"https://arxiv.org/pdf/2303.02034v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02033v1","updated":"2023-03-03T15:52:01Z","published":"2023-03-03T15:52:01Z","title":"Single-photon Image Super-resolution via Self-supervised Learning","summary":"  Single-Photon Image Super-Resolution (SPISR) aims to recover a\nhigh-resolution volumetric photon counting cube from a noisy low-resolution one\nby computational imaging algorithms. In real-world scenarios, pairs of training\nsamples are often expensive or impossible to obtain. By extending Equivariant\nImaging (EI) to volumetric single-photon data, we propose a self-supervised\nlearning framework for the SPISR task. Particularly, using the Poisson unbiased\nKullback-Leibler risk estimator and equivariance, our method is able to learn\nfrom noisy measurements without ground truths. Comprehensive experiments on\nsimulated and real-world dataset demonstrate that the proposed method achieves\ncomparable performance with supervised learning and outperforms\ninterpolation-based methods.\n","authors":["Yiwei Chen","Chen Jiang","Yu Pan"],"pdf_url":"https://arxiv.org/pdf/2303.02033v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.00795v2","updated":"2023-03-03T15:47:01Z","published":"2023-03-01T19:48:45Z","title":"Improved Segmentation of Deep Sulci in Cortical Gray Matter Using a Deep\n  Learning Framework Incorporating Laplace's Equation","summary":"  When developing tools for automated cortical segmentation, the ability to\nproduce topologically correct segmentations is important in order to compute\ngeometrically valid morphometry measures. In practice, accurate cortical\nsegmentation is challenged by image artifacts and the highly convoluted anatomy\nof the cortex itself. To address this, we propose a novel deep learning-based\ncortical segmentation method in which prior knowledge about the geometry of the\ncortex is incorporated into the network during the training process. We design\na loss function which uses the theory of Laplace's equation applied to the\ncortex to locally penalize unresolved boundaries between tightly folded sulci.\nUsing an ex vivo MRI dataset of human medial temporal lobe specimens, we\ndemonstrate that our approach outperforms baseline segmentation networks, both\nquantitatively and qualitatively.\n","authors":["Sadhana Ravikumar","Ranjit Ittyerah","Sydney Lim","Long Xie","Sandhitsu Das","Pulkit Khandelwal","Laura E. M. Wisse","Madigan L. Bedard","John L. Robinson","Terry Schuck","Murray Grossman","John Q. Trojanowski","Edward B. Lee","M. Dylan Tisdall","Karthik Prabhakaran","John A. Detre","David J. Irwin","Winifred Trotman","Gabor Mizsei","Emilio Artacho-Pérula","Maria Mercedes Iñiguez de Onzono Martin","Maria del Mar Arroyo Jiménez","Monica Muñoz","Francisco Javier Molina Romero","Maria del Pilar Marcos Rabal","Sandra Cebada-Sánchez","José Carlos Delgado González","Carlos de la Rosa-Prieto","Marta Córcoles Parada","David A. Wolk","Ricardo Insausti","Paul A. Yushkevich"],"pdf_url":"https://arxiv.org/pdf/2303.00795v2.pdf","comment":"Accepted at the 28th biennial international conference on Information\n  Processing in Medical Imaging (IPMI 2023)"},{"id":"http://arxiv.org/abs/2303.02025v1","updated":"2023-03-03T15:44:00Z","published":"2023-03-03T15:44:00Z","title":"MAEVI: Motion Aware Event-Based Video Frame Interpolation","summary":"  Utilization of event-based cameras is expected to improve the visual quality\nof video frame interpolation solutions. We introduce a learning-based method to\nexploit moving region boundaries in a video sequence to increase the overall\ninterpolation quality.Event cameras allow us to determine moving areas\nprecisely; and hence, better video frame interpolation quality can be achieved\nby emphasizing these regions using an appropriate loss function. The results\nshow a notable average \\textit{PSNR} improvement of $1.3$ dB for the tested\ndata sets, as well as subjectively more pleasing visual results with less\nghosting and blurry artifacts.\n","authors":["Ahmet Akman","Onur Selim Kılıç","A. Aydın Alatan"],"pdf_url":"https://arxiv.org/pdf/2303.02025v1.pdf","comment":"Submitted to International Conference on Image Processing (ICIP) 2023"},{"id":"http://arxiv.org/abs/2006.16867v2","updated":"2023-03-03T15:36:34Z","published":"2020-06-30T14:56:05Z","title":"Boosting Deep Neural Networks with Geometrical Prior Knowledge: A Survey","summary":"  Deep Neural Networks achieve state-of-the-art results in many different\nproblem settings by exploiting vast amounts of training data. However,\ncollecting, storing and - in the case of supervised learning - labelling the\ndata is expensive and time-consuming. Additionally, assessing the networks'\ngeneralization abilities or predicting how the inferred output changes under\ninput transformations is complicated since the networks are usually treated as\na black box. Both of these problems can be mitigated by incorporating prior\nknowledge into the neural network. One promising approach, inspired by the\nsuccess of convolutional neural networks in computer vision tasks, is to\nincorporate knowledge about symmetric geometrical transformations of the\nproblem to solve that affect the output in a predictable way. This promises an\nincreased data efficiency and more interpretable network outputs. In this\nsurvey, we try to give a concise overview about different approaches that\nincorporate geometrical prior knowledge into neural networks. Additionally, we\nconnect those methods to 3D object detection for autonomous driving, where we\nexpect promising results when applying those methods.\n","authors":["Matthias Rath","Alexandru Paul Condurache"],"pdf_url":"https://arxiv.org/pdf/2006.16867v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02001v1","updated":"2023-03-03T15:14:36Z","published":"2023-03-03T15:14:36Z","title":"Zero-shot Object Counting","summary":"  Class-agnostic object counting aims to count object instances of an arbitrary\nclass at test time. It is challenging but also enables many potential\napplications. Current methods require human-annotated exemplars as inputs which\nare often unavailable for novel categories, especially for autonomous systems.\nThus, we propose zero-shot object counting (ZSC), a new setting where only the\nclass name is available during test time. Such a counting system does not\nrequire human annotators in the loop and can operate automatically. Starting\nfrom a class name, we propose a method that can accurately identify the optimal\npatches which can then be used as counting exemplars. Specifically, we first\nconstruct a class prototype to select the patches that are likely to contain\nthe objects of interest, namely class-relevant patches. Furthermore, we\nintroduce a model that can quantitatively measure how suitable an arbitrary\npatch is as a counting exemplar. By applying this model to all the candidate\npatches, we can select the most suitable patches as exemplars for counting.\nExperimental results on a recent class-agnostic counting dataset, FSC-147,\nvalidate the effectiveness of our method. Code is available at\nhttps://github.com/cvlab-stonybrook/zero-shot-counting\n","authors":["Jingyi Xu","Hieu Le","Vu Nguyen","Viresh Ranjan","Dimitris Samaras"],"pdf_url":"https://arxiv.org/pdf/2303.02001v1.pdf","comment":"CVPR 2023, Code is available (soon) at:\n  https://github.com/cvlab-stonybrook/zero-shot-counting"},{"id":"http://arxiv.org/abs/2303.02000v1","updated":"2023-03-03T15:13:11Z","published":"2023-03-03T15:13:11Z","title":"BSH-Det3D: Improving 3D Object Detection with BEV Shape Heatmap","summary":"  The progress of LiDAR-based 3D object detection has significantly enhanced\ndevelopments in autonomous driving and robotics. However, due to the\nlimitations of LiDAR sensors, object shapes suffer from deterioration in\noccluded and distant areas, which creates a fundamental challenge to 3D\nperception. Existing methods estimate specific 3D shapes and achieve remarkable\nperformance. However, these methods rely on extensive computation and memory,\ncausing imbalances between accuracy and real-time performance. To tackle this\nchallenge, we propose a novel LiDAR-based 3D object detection model named\nBSH-Det3D, which applies an effective way to enhance spatial features by\nestimating complete shapes from a bird's eye view (BEV). Specifically, we\ndesign the Pillar-based Shape Completion (PSC) module to predict the\nprobability of occupancy whether a pillar contains object shapes. The PSC\nmodule generates a BEV shape heatmap for each scene. After integrating with\nheatmaps, BSH-Det3D can provide additional information in shape deterioration\nareas and generate high-quality 3D proposals. We also design an attention-based\ndensification fusion module (ADF) to adaptively associate the sparse features\nwith heatmaps and raw points. The ADF module integrates the advantages of\npoints and shapes knowledge with negligible overheads. Extensive experiments on\nthe KITTI benchmark achieve state-of-the-art (SOTA) performance in terms of\naccuracy and speed, demonstrating the efficiency and flexibility of BSH-Det3D.\nThe source code is available on https://github.com/mystorm16/BSH-Det3D.\n","authors":["You Shen","Yunzhou Zhang","Yanmin Wu","Zhenyu Wang","Linghao Yang","Sonya Coleman","Dermot Kerr"],"pdf_url":"https://arxiv.org/pdf/2303.02000v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01999v1","updated":"2023-03-03T15:11:36Z","published":"2023-03-03T15:11:36Z","title":"Unsupervised 3D Shape Reconstruction by Part Retrieval and Assembly","summary":"  Representing a 3D shape with a set of primitives can aid perception of\nstructure, improve robotic object manipulation, and enable editing,\nstylization, and compression of 3D shapes. Existing methods either use simple\nparametric primitives or learn a generative shape space of parts. Both have\nlimitations: parametric primitives lead to coarse approximations, while learned\nparts offer too little control over the decomposition. We instead propose to\ndecompose shapes using a library of 3D parts provided by the user, giving full\ncontrol over the choice of parts. The library can contain parts with\nhigh-quality geometry that are suitable for a given category, resulting in\nmeaningful decompositions with clean geometry. The type of decomposition can\nalso be controlled through the choice of parts in the library. Our method works\nvia a self-supervised approach that iteratively retrieves parts from the\nlibrary and refines their placements. We show that this approach gives higher\nreconstruction accuracy and more desirable decompositions than existing\napproaches. Additionally, we show how the decomposition can be controlled\nthrough the part library by using different part libraries to reconstruct the\nsame shapes.\n","authors":["Xianghao Xu","Paul Guerrero","Matthew Fisher","Siddhartha Chaudhuri","Daniel Ritchie"],"pdf_url":"https://arxiv.org/pdf/2303.01999v1.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2303.01991v1","updated":"2023-03-03T15:00:12Z","published":"2023-03-03T15:00:12Z","title":"Unified Perception: Efficient Video Panoptic Segmentation with Minimal\n  Annotation Costs","summary":"  Depth-aware video panoptic segmentation is a promising approach to camera\nbased scene understanding. However, the current state-of-the-art methods\nrequire costly video annotations and use a complex training pipeline compared\nto their image-based equivalents. In this paper, we present a new approach\ntitled Unified Perception that achieves state-of-the-art performance without\nrequiring video-based training. Our method employs a simple two-stage cascaded\ntracking algorithm that (re)uses object embeddings computed in an image-based\nnetwork. Experimental results on the Cityscapes-DVPS dataset demonstrate that\nour method achieves an overall DVPQ of 57.1, surpassing state-of-the-art\nmethods. Furthermore, we show that our tracking strategies are effective for\nlong-term object association on KITTI-STEP, achieving an STQ of 59.1 which\nexceeded the performance of state-of-the-art methods that employ the same\nbackbone network.\n","authors":["Kurt Stolle","Gijs Dubbelman"],"pdf_url":"https://arxiv.org/pdf/2303.01991v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10764v2","updated":"2023-03-03T14:36:30Z","published":"2023-02-14T13:41:57Z","title":"On The Coherence of Quantitative Evaluation of Visual Explanations","summary":"  Recent years have shown an increased development of methods for justifying\nthe predictions of neural networks through visual explanations. These\nexplanations usually take the form of heatmaps which assign a saliency (or\nrelevance) value to each pixel of the input image that expresses how relevant\nthe pixel is for the prediction of a label.\n  Complementing this development, evaluation methods have been proposed to\nassess the \"goodness\" of such explanations. On the one hand, some of these\nmethods rely on synthetic datasets. However, this introduces the weakness of\nhaving limited guarantees regarding their applicability on more realistic\nsettings. On the other hand, some methods rely on metrics for objective\nevaluation. However the level to which some of these evaluation methods perform\nwith respect to each other is uncertain.\n  Taking this into account, we conduct a comprehensive study on a subset of the\nImageNet-1k validation set where we evaluate a number of different\ncommonly-used explanation methods following a set of evaluation methods. We\ncomplement our study with sanity checks on the studied evaluation methods as a\nmeans to investigate their reliability and the impact of characteristics of the\nexplanations on the evaluation methods.\n  Results of our study suggest that there is a lack of coherency on the grading\nprovided by some of the considered evaluation methods. Moreover, we have\nidentified some characteristics of the explanations, e.g. sparsity, which can\nhave a significant effect on the performance.\n","authors":["Benjamin Vandersmissen","Jose Oramas"],"pdf_url":"https://arxiv.org/pdf/2302.10764v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01959v1","updated":"2023-03-03T14:32:48Z","published":"2023-03-03T14:32:48Z","title":"PointCert: Point Cloud Classification with Deterministic Certified\n  Robustness Guarantees","summary":"  Point cloud classification is an essential component in many\nsecurity-critical applications such as autonomous driving and augmented\nreality. However, point cloud classifiers are vulnerable to adversarially\nperturbed point clouds. Existing certified defenses against adversarial point\nclouds suffer from a key limitation: their certified robustness guarantees are\nprobabilistic, i.e., they produce an incorrect certified robustness guarantee\nwith some probability. In this work, we propose a general framework, namely\nPointCert, that can transform an arbitrary point cloud classifier to be\ncertifiably robust against adversarial point clouds with deterministic\nguarantees. PointCert certifiably predicts the same label for a point cloud\nwhen the number of arbitrarily added, deleted, and/or modified points is less\nthan a threshold. Moreover, we propose multiple methods to optimize the\ncertified robustness guarantees of PointCert in three application scenarios. We\nsystematically evaluate PointCert on ModelNet and ScanObjectNN benchmark\ndatasets. Our results show that PointCert substantially outperforms\nstate-of-the-art certified defenses even though their robustness guarantees are\nprobabilistic.\n","authors":["Jinghuai Zhang","Jinyuan Jia","Hongbin Liu","Neil Zhenqiang Gong"],"pdf_url":"https://arxiv.org/pdf/2303.01959v1.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2203.14402v5","updated":"2023-03-03T14:20:23Z","published":"2022-03-27T21:54:36Z","title":"UV Volumes for Real-time Rendering of Editable Free-view Human\n  Performance","summary":"  Neural volume rendering enables photo-realistic renderings of a human\nperformer in free-view, a critical task in immersive VR/AR applications. But\nthe practice is severely limited by high computational costs in the rendering\nprocess. To solve this problem, we propose the UV Volumes, a new approach that\ncan render an editable free-view video of a human performer in real-time. It\nseparates the high-frequency (i.e., non-smooth) human appearance from the 3D\nvolume, and encodes them into 2D neural texture stacks (NTS). The smooth UV\nvolumes allow much smaller and shallower neural networks to obtain densities\nand texture coordinates in 3D while capturing detailed appearance in 2D NTS.\nFor editability, the mapping between the parameterized human model and the\nsmooth texture coordinates allows us a better generalization on novel poses and\nshapes. Furthermore, the use of NTS enables interesting applications, e.g.,\nretexturing. Extensive experiments on CMU Panoptic, ZJU Mocap, and H36M\ndatasets show that our model can render 960 x 540 images in 30FPS on average\nwith comparable photo-realism to state-of-the-art methods. The project and\nsupplementary materials are available at https://fanegg.github.io/UV-Volumes.\n","authors":["Yue Chen","Xuan Wang","Xingyu Chen","Qi Zhang","Xiaoyu Li","Yu Guo","Jue Wang","Fei Wang"],"pdf_url":"https://arxiv.org/pdf/2203.14402v5.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2303.01943v1","updated":"2023-03-03T14:15:48Z","published":"2023-03-03T14:15:48Z","title":"Spring: A High-Resolution High-Detail Dataset and Benchmark for Scene\n  Flow, Optical Flow and Stereo","summary":"  While recent methods for motion and stereo estimation recover an\nunprecedented amount of details, such highly detailed structures are neither\nadequately reflected in the data of existing benchmarks nor their evaluation\nmethodology. Hence, we introduce Spring $-$ a large, high-resolution,\nhigh-detail, computer-generated benchmark for scene flow, optical flow, and\nstereo. Based on rendered scenes from the open-source Blender movie \"Spring\",\nit provides photo-realistic HD datasets with state-of-the-art visual effects\nand ground truth training data. Furthermore, we provide a website to upload,\nanalyze and compare results. Using a novel evaluation methodology based on a\nsuper-resolved UHD ground truth, our Spring benchmark can assess the quality of\nfine structures and provides further detailed performance statistics on\ndifferent image regions. Regarding the number of ground truth frames, Spring is\n60$\\times$ larger than the only scene flow benchmark, KITTI 2015, and\n15$\\times$ larger than the well-established MPI Sintel optical flow benchmark.\nInitial results for recent methods on our benchmark show that estimating fine\ndetails is indeed challenging, as their accuracy leaves significant room for\nimprovement. The Spring benchmark and the corresponding datasets are available\nat http://spring-benchmark.org.\n","authors":["Lukas Mehl","Jenny Schmalfuss","Azin Jahedi","Yaroslava Nalivayko","Andrés Bruhn"],"pdf_url":"https://arxiv.org/pdf/2303.01943v1.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2303.01939v1","updated":"2023-03-03T14:10:47Z","published":"2023-03-03T14:10:47Z","title":"Retinal Image Restoration using Transformer and Cycle-Consistent\n  Generative Adversarial Network","summary":"  Medical imaging plays a significant role in detecting and treating various\ndiseases. However, these images often happen to be of too poor quality, leading\nto decreased efficiency, extra expenses, and even incorrect diagnoses.\nTherefore, we propose a retinal image enhancement method using a vision\ntransformer and convolutional neural network. It builds a cycle-consistent\ngenerative adversarial network that relies on unpaired datasets. It consists of\ntwo generators that translate images from one domain to another (e.g., low- to\nhigh-quality and vice versa), playing an adversarial game with two\ndiscriminators. Generators produce indistinguishable images for discriminators\nthat predict the original images from generated ones. Generators are a\ncombination of vision transformer (ViT) encoder and convolutional neural\nnetwork (CNN) decoder. Discriminators include traditional CNN encoders. The\nresulting improved images have been tested quantitatively using such evaluation\nmetrics as peak signal-to-noise ratio (PSNR), structural similarity index\nmeasure (SSIM), and qualitatively, i.e., vessel segmentation. The proposed\nmethod successfully reduces the adverse effects of blurring, noise,\nillumination disturbances, and color distortions while significantly preserving\nstructural and color information. Experimental results show the superiority of\nthe proposed method. Our testing PSNR is 31.138 dB for the first and 27.798 dB\nfor the second dataset. Testing SSIM is 0.919 and 0.904, respectively.\n","authors":["Alnur Alimanov","Md Baharul Islam"],"pdf_url":"https://arxiv.org/pdf/2303.01939v1.pdf","comment":"4 pages, 3 figures, The International Symposium on Intelligent Signal\n  Processing and Communication Systems (ISPACS2022)"},{"id":"http://arxiv.org/abs/2203.04571v2","updated":"2023-03-03T14:09:50Z","published":"2022-03-09T08:29:21Z","title":"A Neuro-vector-symbolic Architecture for Solving Raven's Progressive\n  Matrices","summary":"  Neither deep neural networks nor symbolic AI alone has approached the kind of\nintelligence expressed in humans. This is mainly because neural networks are\nnot able to decompose joint representations to obtain distinct objects (the\nso-called binding problem), while symbolic AI suffers from exhaustive rule\nsearches, among other problems. These two problems are still pronounced in\nneuro-symbolic AI which aims to combine the best of the two paradigms. Here, we\nshow that the two problems can be addressed with our proposed\nneuro-vector-symbolic architecture (NVSA) by exploiting its powerful operators\non high-dimensional distributed representations that serve as a common language\nbetween neural networks and symbolic AI. The efficacy of NVSA is demonstrated\nby solving the Raven's progressive matrices datasets. Compared to\nstate-of-the-art deep neural network and neuro-symbolic approaches, end-to-end\ntraining of NVSA achieves a new record of 87.7% average accuracy in RAVEN, and\n88.1% in I-RAVEN datasets. Moreover, compared to the symbolic reasoning within\nthe neuro-symbolic approaches, the probabilistic reasoning of NVSA with less\nexpensive operations on the distributed representations is two orders of\nmagnitude faster. Our code is available at\nhttps://github.com/IBM/neuro-vector-symbolic-architectures.\n","authors":["Michael Hersche","Mustafa Zeqiri","Luca Benini","Abu Sebastian","Abbas Rahimi"],"pdf_url":"https://arxiv.org/pdf/2203.04571v2.pdf","comment":"Updated version with additional NVSA end-to-end training,\n  generalization experiments, and PGM experiments"},{"id":"http://arxiv.org/abs/2301.09255v2","updated":"2023-03-03T14:09:15Z","published":"2023-01-23T03:41:02Z","title":"Combined Use of Federated Learning and Image Encryption for\n  Privacy-Preserving Image Classification with Vision Transformer","summary":"  In recent years, privacy-preserving methods for deep learning have become an\nurgent problem. Accordingly, we propose the combined use of federated learning\n(FL) and encrypted images for privacy-preserving image classification under the\nuse of the vision transformer (ViT). The proposed method allows us not only to\ntrain models over multiple participants without directly sharing their raw data\nbut to also protect the privacy of test (query) images for the first time. In\naddition, it can also maintain the same accuracy as normally trained models. In\nan experiment, the proposed method was demonstrated to well work without any\nperformance degradation on the CIFAR-10 and CIFAR-100 datasets.\n","authors":["Teru Nagamori","Hitoshi Kiya"],"pdf_url":"https://arxiv.org/pdf/2301.09255v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01932v1","updated":"2023-03-03T14:02:50Z","published":"2023-03-03T14:02:50Z","title":"MobileBrick: Building LEGO for 3D Reconstruction on Mobile Devices","summary":"  High-quality 3D ground-truth shapes are critical for 3D object reconstruction\nevaluation. However, it is difficult to create a replica of an object in\nreality, and even 3D reconstructions generated by 3D scanners have artefacts\nthat cause biases in evaluation. To address this issue, we introduce a novel\nmulti-view RGBD dataset captured using a mobile device, which includes highly\nprecise 3D ground-truth annotations for 153 object models featuring a diverse\nset of 3D structures. We obtain precise 3D ground-truth shape without relying\non high-end 3D scanners by utilising LEGO models with known geometry as the 3D\nstructures for image capture. The distinct data modality offered by\nhigh-resolution RGB images and low-resolution depth maps captured on a mobile\ndevice, when combined with precise 3D geometry annotations, presents a unique\nopportunity for future research on high-fidelity 3D reconstruction.\nFurthermore, we evaluate a range of 3D reconstruction algorithms on the\nproposed dataset. Project page: http://code.active.vision/MobileBrick/\n","authors":["Kejie Li","Jia-Wang Bian","Robert Castle","Philip H. S. Torr","Victor Adrian Prisacariu"],"pdf_url":"https://arxiv.org/pdf/2303.01932v1.pdf","comment":"To be appeared at CVPR 2023"},{"id":"http://arxiv.org/abs/2211.11505v3","updated":"2023-03-03T13:57:21Z","published":"2022-11-21T14:43:16Z","title":"Local-to-Global Registration for Bundle-Adjusting Neural Radiance Fields","summary":"  Neural Radiance Fields (NeRF) have achieved photorealistic novel views\nsynthesis; however, the requirement of accurate camera poses limits its\napplication. Despite analysis-by-synthesis extensions for jointly learning\nneural 3D representations and registering camera frames exist, they are\nsusceptible to suboptimal solutions if poorly initialized. We propose L2G-NeRF,\na Local-to-Global registration method for bundle-adjusting Neural Radiance\nFields: first, a pixel-wise flexible alignment, followed by a frame-wise\nconstrained parametric alignment. Pixel-wise local alignment is learned in an\nunsupervised way via a deep network which optimizes photometric reconstruction\nerrors. Frame-wise global alignment is performed using differentiable parameter\nestimation solvers on the pixel-wise correspondences to find a global\ntransformation. Experiments on synthetic and real-world data show that our\nmethod outperforms the current state-of-the-art in terms of high-fidelity\nreconstruction and resolving large camera pose misalignment. Our module is an\neasy-to-use plugin that can be applied to NeRF variants and other neural field\napplications. The Code and supplementary materials are available at\nhttps://rover-xingyu.github.io/L2G-NeRF/.\n","authors":["Yue Chen","Xingyu Chen","Xuan Wang","Qi Zhang","Yu Guo","Ying Shan","Fei Wang"],"pdf_url":"https://arxiv.org/pdf/2211.11505v3.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2303.01920v1","updated":"2023-03-03T13:45:13Z","published":"2023-03-03T13:45:13Z","title":"Robust Detection Outcome: A Metric for Pathology Detection in Medical\n  Images","summary":"  Detection of pathologies is a fundamental task in medical imaging and the\nevaluation of algorithms that can perform this task automatically is crucial.\nHowever, current object detection metrics for natural images do not reflect the\nspecific clinical requirements in pathology detection sufficiently. To tackle\nthis problem, we propose Robust Detection Outcome (RoDeO); a novel metric for\nevaluating algorithms for pathology detection in medical images, especially in\nchest X-rays. RoDeO evaluates different errors directly and individually, and\nreflects clinical needs better than current metrics. Extensive evaluation on\nthe ChestX-ray8 dataset shows the superiority of our metrics compared to\nexisting ones. We released the code at https://github.com/FeliMe/RoDeO and\npublished RoDeO as pip package (rodeometric).\n","authors":["Felix Meissen","Philip Müller","Georgios Kaissis","Daniel Rueckert"],"pdf_url":"https://arxiv.org/pdf/2303.01920v1.pdf","comment":"Accepted at MIDL 2023"},{"id":"http://arxiv.org/abs/2303.01917v1","updated":"2023-03-03T13:36:55Z","published":"2023-03-03T13:36:55Z","title":"PPCR: Learning Pyramid Pixel Context Recalibration Module for Medical\n  Image Classification","summary":"  Spatial attention mechanism has been widely incorporated into deep\nconvolutional neural networks (CNNs) via long-range dependency capturing,\nsignificantly lifting the performance in computer vision, but it may perform\npoorly in medical imaging. Unfortunately, existing efforts are often unaware\nthat long-range dependency capturing has limitations in highlighting subtle\nlesion regions, neglecting to exploit the potential of multi-scale pixel\ncontext information to improve the representational capability of CNNs. In this\npaper, we propose a practical yet lightweight architectural unit, Pyramid Pixel\nContext Recalibration (PPCR) module, which exploits multi-scale pixel context\ninformation to recalibrate pixel position in a pixel-independent manner\nadaptively. PPCR first designs a cross-channel pyramid pooling to aggregate\nmulti-scale pixel context information, then eliminates the inconsistency among\nthem by the well-designed pixel normalization, and finally estimates per pixel\nattention weight via a pixel context integration. PPCR can be flexibly plugged\ninto modern CNNs with negligible overhead. Extensive experiments on five\nmedical image datasets and CIFAR benchmarks empirically demonstrate the\nsuperiority and generalization of PPCR over state-of-the-art attention methods.\nThe in-depth analyses explain the inherent behavior of PPCR in the\ndecision-making process, improving the interpretability of CNNs.\n","authors":["Xiaoqing Zhangand Zunjie Xiao","Xiao Wu","Jiansheng Fang","Junyong Shen","Yan Hu","Risa Higashita","Jiang Liu"],"pdf_url":"https://arxiv.org/pdf/2303.01917v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2303.01913v1","updated":"2023-03-03T13:27:00Z","published":"2023-03-03T13:27:00Z","title":"Bespoke: A Block-Level Neural Network Optimization Framework for\n  Low-Cost Deployment","summary":"  As deep learning models become popular, there is a lot of need for deploying\nthem to diverse device environments. Because it is costly to develop and\noptimize a neural network for every single environment, there is a line of\nresearch to search neural networks for multiple target environments\nefficiently. However, existing works for such a situation still suffer from\nrequiring many GPUs and expensive costs. Motivated by this, we propose a novel\nneural network optimization framework named Bespoke for low-cost deployment.\nOur framework searches for a lightweight model by replacing parts of an\noriginal model with randomly selected alternatives, each of which comes from a\npretrained neural network or the original model. In the practical sense,\nBespoke has two significant merits. One is that it requires near zero cost for\ndesigning the search space of neural networks. The other merit is that it\nexploits the sub-networks of public pretrained neural networks, so the total\ncost is minimal compared to the existing works. We conduct experiments\nexploring Bespoke's the merits, and the results show that it finds efficient\nmodels for multiple targets with meager cost.\n","authors":["Jong-Ryul Lee","Yong-Hyuk Moon"],"pdf_url":"https://arxiv.org/pdf/2303.01913v1.pdf","comment":"Accepted in AAAI-2023"},{"id":"http://arxiv.org/abs/2303.01906v1","updated":"2023-03-03T13:07:14Z","published":"2023-03-03T13:07:14Z","title":"Generalized Semantic Segmentation by Self-Supervised Source Domain\n  Projection and Multi-Level Contrastive Learning","summary":"  Deep networks trained on the source domain show degraded performance when\ntested on unseen target domain data. To enhance the model's generalization\nability, most existing domain generalization methods learn domain invariant\nfeatures by suppressing domain sensitive features. Different from them, we\npropose a Domain Projection and Contrastive Learning (DPCL) approach for\ngeneralized semantic segmentation, which includes two modules: Self-supervised\nSource Domain Projection (SSDP) and Multi-level Contrastive Learning (MLCL).\nSSDP aims to reduce domain gap by projecting data to the source domain, while\nMLCL is a learning scheme to learn discriminative and generalizable features on\nthe projected data. During test time, we first project the target data by SSDP\nto mitigate domain shift, then generate the segmentation results by the learned\nsegmentation network based on MLCL. At test time, we can update the projected\ndata by minimizing our proposed pixel-to-pixel contrastive loss to obtain\nbetter results. Extensive experiments for semantic segmentation demonstrate the\nfavorable generalization capability of our method on benchmark datasets.\n","authors":["Liwei Yang","Xiang Gu","Jian Sun"],"pdf_url":"https://arxiv.org/pdf/2303.01906v1.pdf","comment":"13 pages, 9 figures, accepted at AAAI 2023 (Oral Presentation)"},{"id":"http://arxiv.org/abs/2303.01904v1","updated":"2023-03-03T13:05:30Z","published":"2023-03-03T13:05:30Z","title":"EcoTTA: Memory-Efficient Continual Test-time Adaptation via\n  Self-distilled Regularization","summary":"  This paper presents a simple yet effective approach that improves continual\ntest-time adaptation (TTA) in a memory-efficient manner. TTA may primarily be\nconducted on edge devices with limited memory, so reducing memory is crucial\nbut has been overlooked in previous TTA studies. In addition, long-term\nadaptation often leads to catastrophic forgetting and error accumulation, which\nhinders applying TTA in real-world deployments. Our approach consists of two\ncomponents to address these issues. First, we present lightweight meta networks\nthat can adapt the frozen original networks to the target domain. This novel\narchitecture minimizes memory consumption by decreasing the size of\nintermediate activations required for backpropagation. Second, our novel\nself-distilled regularization controls the output of the meta networks not to\ndeviate significantly from the output of the frozen original networks, thereby\npreserving well-trained knowledge from the source domain. Without additional\nmemory, this regularization prevents error accumulation and catastrophic\nforgetting, resulting in stable performance even in long-term test-time\nadaptation. We demonstrate that our simple yet effective strategy outperforms\nother state-of-the-art methods on various benchmarks for image classification\nand semantic segmentation tasks. Notably, our proposed method with ResNet-50\nand WideResNet-40 takes 86% and 80% less memory than the recent\nstate-of-the-art method, CoTTA.\n","authors":["Junha Song","Jungsoo Lee","In So Kweon","Sungha Choi"],"pdf_url":"https://arxiv.org/pdf/2303.01904v1.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2303.01903v1","updated":"2023-03-03T13:05:15Z","published":"2023-03-03T13:05:15Z","title":"Prompting Large Language Models with Answer Heuristics for\n  Knowledge-based Visual Question Answering","summary":"  Knowledge-based visual question answering (VQA) requires external knowledge\nbeyond the image to answer the question. Early studies retrieve required\nknowledge from explicit knowledge bases (KBs), which often introduces\nirrelevant information to the question, hence restricting the performance of\ntheir models. Recent works have sought to use a large language model (i.e.,\nGPT-3) as an implicit knowledge engine to acquire the necessary knowledge for\nanswering. Despite the encouraging results achieved by these methods, we argue\nthat they have not fully activated the capacity of GPT-3 as the provided input\ninformation is insufficient. In this paper, we present Prophet -- a\nconceptually simple framework designed to prompt GPT-3 with answer heuristics\nfor knowledge-based VQA. Specifically, we first train a vanilla VQA model on a\nspecific knowledge-based VQA dataset without external knowledge. After that, we\nextract two types of complementary answer heuristics from the model: answer\ncandidates and answer-aware examples. Finally, the two types of answer\nheuristics are encoded into the prompts to enable GPT-3 to better comprehend\nthe task thus enhancing its capacity. Prophet significantly outperforms all\nexisting state-of-the-art methods on two challenging knowledge-based VQA\ndatasets, OK-VQA and A-OKVQA, delivering 61.1% and 55.7% accuracies on their\ntesting sets, respectively.\n","authors":["Zhenwei Shao","Zhou Yu","Meng Wang","Jun Yu"],"pdf_url":"https://arxiv.org/pdf/2303.01903v1.pdf","comment":"Accepted at CVPR 2023, code available at\n  https://github.com/MILVLG/prophet"},{"id":"http://arxiv.org/abs/2303.01899v1","updated":"2023-03-03T12:52:01Z","published":"2023-03-03T12:52:01Z","title":"Quantifying the LiDAR Sim-to-Real Domain Shift: A Detailed Investigation\n  Using Object Detectors and Analyzing Point Clouds at Target-Level","summary":"  LiDAR object detection algorithms based on neural networks for autonomous\ndriving require large amounts of data for training, validation, and testing. As\nreal-world data collection and labeling are time-consuming and expensive,\nsimulation-based synthetic data generation is a viable alternative. However,\nusing simulated data for the training of neural networks leads to a domain\nshift of training and testing data due to differences in scenes, scenarios, and\ndistributions. In this work, we quantify the sim-to-real domain shift by means\nof LiDAR object detectors trained with a new scenario-identical real-world and\nsimulated dataset. In addition, we answer the questions of how well the\nsimulated data resembles the real-world data and how well object detectors\ntrained on simulated data perform on real-world data. Further, we analyze point\nclouds at the target-level by comparing real-world and simulated point clouds\nwithin the 3D bounding boxes of the targets. Our experiments show that a\nsignificant sim-to-real domain shift exists even for our scenario-identical\ndatasets. This domain shift amounts to an average precision reduction of around\n14 % for object detectors trained with simulated data. Additional experiments\nreveal that this domain shift can be lowered by introducing a simple noise\nmodel in simulation. We further show that a simple downsampling method to model\nreal-world physics does not influence the performance of the object detectors.\n","authors":["Sebastian Huch","Luca Scalerandi","Esteban Rivera","Markus Lienkamp"],"pdf_url":"https://arxiv.org/pdf/2303.01899v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.13976v3","updated":"2023-03-03T12:50:12Z","published":"2022-11-25T09:38:22Z","title":"Expanding Small-Scale Datasets with Guided Imagination","summary":"  The power of DNNs depends heavily on the quantity and quality of training\ndata. However, collecting and annotating data on a large scale is often costly\nand time-consuming, which severely hinders the application of DNNs. To address\nthis issue, we explore a new task, termed as dataset expansion, which seeks to\nexpand a ready-to-use small dataset by automatically creating new labeled\nsamples. To this end, we present a Guided Imagination Framework (GIF) that\nleverages cutting-edge generative models (e.g., DALL-E2, Stable Diffusion (SD))\nto ``imagine'' and create informative new data from the input seed data.\nSpecifically, GIF conducts data imagination by optimizing the latent features\nof the seed data in the semantically meaningful space of the prior model, which\nare used to create photo-realistic images with new content. To guide the\nimagination towards creating informative samples for model training, we\nintroduce two key criteria, i.e., class-maintained information boosting and\nsample diversity promotion. The two criteria are verified to be essential for\neffective dataset expansion: GIF-SD obtains 13.5\\% higher model accuracy on\nnatural image datasets than unguided expansion with SD. With these essential\ncriteria, GIF expands datasets effectively in various small-data scenarios,\nboosting model accuracy by 36.9\\% on average over six natural image datasets\nand by 13.5\\% on average over three medical datasets. The source code will be\nreleased: \\url{https://github.com/Vanint/DatasetExpansion}.\n","authors":["Yifan Zhang","Daquan Zhou","Bryan Hooi","Kai Wang","Jiashi Feng"],"pdf_url":"https://arxiv.org/pdf/2211.13976v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01894v1","updated":"2023-03-03T12:47:30Z","published":"2023-03-03T12:47:30Z","title":"T360RRD: A dataset for 360 degree rotated rectangular box table\n  detection","summary":"  To address the problem of scarcity and high annotation costs of rotated image\ntable detection datasets, this chapter proposes a method for building a rotated\nimage table detection dataset. Based on the ICDAR2019MTD modern table detection\ndataset, we refer to the annotation format of the DOTA dataset to create the\nTRR360D rotated table detection dataset, as shown in Table 4.1. The training\nset contains 600 rotated images and 977 annotated instances, and the test set\ncontains 240 rotated images and 499 annotated instances. The DOTA\\_360\nevaluation metric is defined, and this dataset is available for future\nresearchers to study rotated table detection algorithms and promote the\ndevelopment of table detection technology. The TRR360D rotated table detection\ndataset was created by constraining the starting point and annotation\ndirection, and is publicly available at\n\\url{https://github.com/vansin/TRR360D}.\n","authors":["Wenxing Hu","Minglei Tong"],"pdf_url":"https://arxiv.org/pdf/2303.01894v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.01868v2","updated":"2023-03-03T12:41:10Z","published":"2022-04-04T22:11:49Z","title":"Truck Axle Detection with Convolutional Neural Networks","summary":"  Axle count in trucks is important to the classification of vehicles and to\nthe operation of road systems. It is used in the determination of service fees\nand in the impact on the pavement. Although axle count can be achieved with\ntraditional methods, such as manual labor, it is increasingly possible to count\naxles using deep learning and computer vision methods. This paper aims to\ncompare three deep-learning object detection algorithms, YOLO, Faster R-CNN,\nand SSD, for the detection of truck axles. A dataset was built to provide\ntraining and testing examples for the neural networks. The training was done on\ndifferent base models, to increase training time efficiency and to compare\nresults. We evaluated results based on five metrics: precision, recall, mAP,\nF1-score, and FPS count. Results indicate that YOLO and SSD have similar\naccuracy and performance, with more than 96\\% mAP for both models. Datasets and\ncodes are publicly available for download.\n","authors":["Leandro Arab Marcomini","André Luiz Cunha"],"pdf_url":"https://arxiv.org/pdf/2204.01868v2.pdf","comment":"Code and dataset available for donwload, links provided"},{"id":"http://arxiv.org/abs/2303.01884v1","updated":"2023-03-03T12:30:09Z","published":"2023-03-03T12:30:09Z","title":"AutoMatch: A Large-scale Audio Beat Matching Benchmark for Boosting Deep\n  Learning Assistant Video Editing","summary":"  The explosion of short videos has dramatically reshaped the manners people\nsocialize, yielding a new trend for daily sharing and access to the latest\ninformation. These rich video resources, on the one hand, benefited from the\npopularization of portable devices with cameras, but on the other, they can not\nbe independent of the valuable editing work contributed by numerous video\ncreators. In this paper, we investigate a novel and practical problem, namely\naudio beat matching (ABM), which aims to recommend the proper transition time\nstamps based on the background music. This technique helps to ease the\nlabor-intensive work during video editing, saving energy for creators so that\nthey can focus more on the creativity of video content. We formally define the\nABM problem and its evaluation protocol. Meanwhile, a large-scale audio\ndataset, i.e., the AutoMatch with over 87k finely annotated background music,\nis presented to facilitate this newly opened research direction. To further lay\nsolid foundations for the following study, we also propose a novel model termed\nBeatX to tackle this challenging task. Alongside, we creatively present the\nconcept of label scope, which eliminates the data imbalance issues and assigns\nadaptive weights for the ground truth during the training procedure in one\nstop. Though plentiful short video platforms have flourished for a long time,\nthe relevant research concerning this scenario is not sufficient, and to the\nbest of our knowledge, AutoMatch is the first large-scale dataset to tackle the\naudio beat matching problem. We hope the released dataset and our competitive\nbaseline can encourage more attention to this line of research. The dataset and\ncodes will be made publicly available.\n","authors":["Sen Pei","Jingya Yu","Qi Chen","Wozhou He"],"pdf_url":"https://arxiv.org/pdf/2303.01884v1.pdf","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2303.01871v1","updated":"2023-03-03T12:05:41Z","published":"2023-03-03T12:05:41Z","title":"Attention-based Saliency Maps Improve Interpretability of Pneumothorax\n  Classification","summary":"  Purpose: To investigate chest radiograph (CXR) classification performance of\nvision transformers (ViT) and interpretability of attention-based saliency\nusing the example of pneumothorax classification.\n  Materials and Methods: In this retrospective study, ViTs were fine-tuned for\nlung disease classification using four public data sets: CheXpert, Chest X-Ray\n14, MIMIC CXR, and VinBigData. Saliency maps were generated using transformer\nmultimodal explainability and gradient-weighted class activation mapping\n(GradCAM). Classification performance was evaluated on the Chest X-Ray 14,\nVinBigData, and SIIM-ACR data sets using the area under the receiver operating\ncharacteristic curve analysis (AUC) and compared with convolutional neural\nnetworks (CNNs). The explainability methods were evaluated with\npositive/negative perturbation, sensitivity-n, effective heat ratio,\nintra-architecture repeatability and interarchitecture reproducibility. In the\nuser study, three radiologists classified 160 CXRs with/without saliency maps\nfor pneumothorax and rated their usefulness.\n  Results: ViTs had comparable CXR classification AUCs compared with\nstate-of-the-art CNNs 0.95 (95% CI: 0.943, 0.950) versus 0.83 (95%, CI 0.826,\n0.842) on Chest X-Ray 14, 0.84 (95% CI: 0.769, 0.912) versus 0.83 (95% CI:\n0.760, 0.895) on VinBigData, and 0.85 (95% CI: 0.847, 0.861) versus 0.87 (95%\nCI: 0.868, 0.882) on SIIM ACR. Both saliency map methods unveiled a strong bias\ntoward pneumothorax tubes in the models. Radiologists found 47% of the\nattention-based saliency maps useful and 39% of GradCAM. The attention-based\nmethods outperformed GradCAM on all metrics.\n  Conclusion: ViTs performed similarly to CNNs in CXR classification, and their\nattention-based saliency maps were more useful to radiologists and outperformed\nGradCAM.\n","authors":["Alessandro Wollek","Robert Graf","Saša Čečatka","Nicola Fink","Theresa Willem","Bastian O. Sabel","Tobias Lasser"],"pdf_url":"https://arxiv.org/pdf/2303.01871v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01870v1","updated":"2023-03-03T11:53:01Z","published":"2023-03-03T11:53:01Z","title":"Revisiting Adversarial Training for ImageNet: Architectures, Training\n  and Generalization across Threat Models","summary":"  While adversarial training has been extensively studied for ResNet\narchitectures and low resolution datasets like CIFAR, much less is known for\nImageNet. Given the recent debate about whether transformers are more robust\nthan convnets, we revisit adversarial training on ImageNet comparing ViTs and\nConvNeXts. Extensive experiments show that minor changes in architecture, most\nnotably replacing PatchStem with ConvStem, and training scheme have a\nsignificant impact on the achieved robustness. These changes not only increase\nrobustness in the seen $\\ell_\\infty$-threat model, but even more so improve\ngeneralization to unseen $\\ell_1/\\ell_2$-robustness. Our modified ConvNeXt,\nConvNeXt + ConvStem, yields the most robust models across different ranges of\nmodel parameters and FLOPs.\n","authors":["Naman D Singh","Francesco Croce","Matthias Hein"],"pdf_url":"https://arxiv.org/pdf/2303.01870v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01869v1","updated":"2023-03-03T11:52:21Z","published":"2023-03-03T11:52:21Z","title":"Intrinsic Physical Concepts Discovery with Object-Centric Predictive\n  Models","summary":"  The ability to discover abstract physical concepts and understand how they\nwork in the world through observing lies at the core of human intelligence. The\nacquisition of this ability is based on compositionally perceiving the\nenvironment in terms of objects and relations in an unsupervised manner. Recent\napproaches learn object-centric representations and capture visually observable\nconcepts of objects, e.g., shape, size, and location. In this paper, we take a\nstep forward and try to discover and represent intrinsic physical concepts such\nas mass and charge. We introduce the \\uppercase{phy}sical \\uppercase{c}oncepts\n\\uppercase{i}nference \\uppercase{ne}twork (PHYCINE), a system that infers\nphysical concepts in different abstract levels without supervision. The key\ninsights underlining PHYCINE are two-fold, commonsense knowledge emerges with\nprediction, and physical concepts of different abstract levels should be\nreasoned in a bottom-up fashion. Empirical evaluation demonstrates that\nvariables inferred by our system work in accordance with the properties of the\ncorresponding physical concepts. We also show that object representations\ncontaining the discovered physical concepts variables could help achieve better\nperformance in causal reasoning tasks, i.e., ComPhy.\n","authors":["Qu Tang","XiangYu Zhu","Zhen Lei","ZhaoXiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.01869v1.pdf","comment":"Accepted to Computer Vision and Pattern Recognition (CVPR)2023"},{"id":"http://arxiv.org/abs/2303.00304v2","updated":"2023-03-03T11:12:20Z","published":"2023-03-01T08:00:46Z","title":"Renderable Neural Radiance Map for Visual Navigation","summary":"  We propose a novel type of map for visual navigation, a renderable neural\nradiance map (RNR-Map), which is designed to contain the overall visual\ninformation of a 3D environment. The RNR-Map has a grid form and consists of\nlatent codes at each pixel. These latent codes are embedded from image\nobservations, and can be converted to the neural radiance field which enables\nimage rendering given a camera pose. The recorded latent codes implicitly\ncontain visual information about the environment, which makes the RNR-Map\nvisually descriptive. This visual information in RNR-Map can be a useful\nguideline for visual localization and navigation. We develop localization and\nnavigation frameworks that can effectively utilize the RNR-Map. We evaluate the\nproposed frameworks on camera tracking, visual localization, and image-goal\nnavigation. Experimental results show that the RNR-Map-based localization\nframework can find the target location based on a single query image with fast\nspeed and competitive accuracy compared to other baselines. Also, this\nlocalization framework is robust to environmental changes, and even finds the\nmost visually similar places when a query image from a different environment is\ngiven. The proposed navigation framework outperforms the existing image-goal\nnavigation methods in difficult scenarios, under odometry and actuation noises.\nThe navigation framework shows 65.7% success rate in curved scenarios of the\nNRNS dataset, which is an improvement of 18.6% over the current\nstate-of-the-art.\n","authors":["Obin Kwon","Jeongho Park","Songhwai Oh"],"pdf_url":"https://arxiv.org/pdf/2303.00304v2.pdf","comment":"Preprint version, CVPR 2023 accepted. Project Site:\n  https://obin-hero.github.io/RNRmap/. This will be replaced by a camera-ready\n  version with some minor revisions"},{"id":"http://arxiv.org/abs/2210.10352v3","updated":"2023-03-03T10:51:40Z","published":"2022-10-19T07:40:47Z","title":"Temporal Action Segmentation: An Analysis of Modern Techniques","summary":"  Temporal action segmentation (TAS) from videos aims at densely identifying\nvideo frames in minutes-long videos with multiple action classes. As a\nlong-range video understanding task, researchers have developed an extended\ncollection of methods and examined their performance using various benchmarks.\nDespite the rapid growth of TAS techniques in recent years, no systematic\nsurvey has been conducted in these sectors. In this survey, we analyze and\nsummarize the most significant contributions and trends to this endeavor. In\nparticular, we first examine the task definition, common benchmarks, types of\nsupervision, and prevalent evaluation measures. In addition, we systematically\ninvestigate two essential techniques of this topic, i.e., frame representation,\nand temporal modeling, which have been studied extensively in the literature.\nWe then conduct a thorough review of existing TAS works categorized by their\nlevels of supervision and conclude our survey by identifying and emphasizing\nseveral research gaps. In addition, we have curated a list of TAS resources,\nwhich is available at\nhttps://github.com/atlas-eccv22/awesome-temporal-action-segmentation.\n","authors":["Guodong Ding","Fadime Sener","Angela Yao"],"pdf_url":"https://arxiv.org/pdf/2210.10352v3.pdf","comment":"20 pages, 7 figures, 10 tables"},{"id":"http://arxiv.org/abs/2303.01276v2","updated":"2023-03-03T10:47:41Z","published":"2023-03-02T14:02:16Z","title":"Conflict-Based Cross-View Consistency for Semi-Supervised Semantic\n  Segmentation","summary":"  Semi-supervised semantic segmentation has recently gained increasing research\ninterest as it can reduce the requirement for large-scale fully-annotated\ntraining data by effectively exploiting large amounts of unlabelled data. The\ncurrent methods often suffer from the confirmation bias from the\npseudo-labelling process, which can be alleviated by the co-training framework.\nThe current co-training-based semi-supervised semantic segmentation methods\nrely on hand-crafted perturbations to prevent the different sub-nets from\ncollapsing into each other, but these artificial perturbations cannot lead to\nthe optimal solution. In this work, we propose a new conflict-based cross-view\nconsistency (CCVC) method based on a two-branch co-training framework for\nsemi-supervised semantic segmentation. Our work aims at enforcing the two\nsub-nets to learn informative features from irrelevant views. In particular, we\nfirst propose a new cross-view consistency (CVC) strategy that encourages the\ntwo sub-nets to learn distinct features from the same input by introducing a\nfeature discrepancy loss, while these distinct features are expected to\ngenerate consistent prediction scores of the input. The CVC strategy helps to\nprevent the two sub-nets from stepping into the collapse. In addition, we\nfurther propose a conflict-based pseudo-labelling (CPL) method to guarantee the\nmodel will learn more useful information from conflicting predictions, which\nwill lead to a stable training process. We validate our new semi-supervised\nsemantic segmentation approach on the widely used benchmark datasets PASCAL VOC\n2012 and Cityscapes, where our method achieves new state-of-the-art\nperformance.\n","authors":["Zicheng Wang","Zhen Zhao","Luping Zhou","Dong Xu","Xiaoxia Xing","Xiangyu Kong"],"pdf_url":"https://arxiv.org/pdf/2303.01276v2.pdf","comment":"Update experiment results in Table 2"},{"id":"http://arxiv.org/abs/2303.01837v1","updated":"2023-03-03T10:39:25Z","published":"2023-03-03T10:39:25Z","title":"A Hybrid Approach to Full-Scale Reconstruction of Renal Arterial Network","summary":"  The renal vasculature, acting as a resource distribution network, plays an\nimportant role in both the physiology and pathophysiology of the kidney.\nHowever, no imaging techniques allow an assessment of the structure and\nfunction of the renal vasculature due to limited spatial and temporal\nresolution. To develop realistic computer simulations of renal function, and to\ndevelop new image-based diagnostic methods based on artificial intelligence, it\nis necessary to have a realistic full-scale model of the renal vasculature. We\npropose a hybrid framework to build subject-specific models of the renal\nvascular network by using semi-automated segmentation of large arteries and\nestimation of cortex area from a micro-CT scan as a starting point, and by\nadopting the Global Constructive Optimization algorithm for generating smaller\nvessels. Our results show a statistical correspondence between the\nreconstructed data and existing anatomical data obtained from a rat kidney with\nrespect to morphometric and hemodynamic parameters.\n","authors":["Peidi Xu","Niels-Henrik Holstein-Rathlou","Stinne Byrholdt Søgaard","Carsten Gundlach","Charlotte Mehlin Sørensen","Kenny Erleben","Olga Sosnovtseva","Sune Darkner"],"pdf_url":"https://arxiv.org/pdf/2303.01837v1.pdf","comment":"19 pages, 5 figures (excluding references and supplementary)\n  submitted to Communications Biology"},{"id":"http://arxiv.org/abs/2208.05881v2","updated":"2023-03-03T10:37:13Z","published":"2022-08-11T15:34:27Z","title":"Uncertainty-Aware Blob Detection with an Application to Integrated-Light\n  Stellar Population Recoveries","summary":"  Context. Blob detection is a common problem in astronomy. One example is in\nstellar population modelling, where the distribution of stellar ages and\nmetallicities in a galaxy is inferred from observations. In this context, blobs\nmay correspond to stars born in-situ versus those accreted from satellites, and\nthe task of blob detection is to disentangle these components. A difficulty\narises when the distributions come with significant uncertainties, as is the\ncase for stellar population recoveries inferred from modelling spectra of\nunresolved stellar systems. There is currently no satisfactory method for blob\ndetection with uncertainties. Aims. We introduce a method for uncertainty-aware\nblob detection developed in the context of stellar population modelling of\nintegrated-light spectra of stellar systems. Methods. We develop theory and\ncomputational tools for an uncertainty-aware version of the classic\nLaplacian-of-Gaussians method for blob detection, which we call ULoG. This\nidentifies significant blobs considering a variety of scales. As a prerequisite\nto apply ULoG to stellar population modelling, we introduce a method for\nefficient computation of uncertainties for spectral modelling. This method is\nbased on the truncated Singular Value Decomposition and Markov Chain Monte\nCarlo sampling (SVD-MCMC). Results. We apply the methods to data of the star\ncluster M54. We show that the SVD-MCMC inferences match those from standard\nMCMC, but are a factor 5-10 faster to compute. We apply ULoG to the inferred\nM54 age/metallicity distributions, identifying between 2 or 3 significant,\ndistinct populations amongst its stars.\n","authors":["Fabian Parzer","Prashin Jethwa","Alina Boecker","Mayte Alfaro-Cuello","Otmar Scherzer","Glenn van de Ven"],"pdf_url":"https://arxiv.org/pdf/2208.05881v2.pdf","comment":"Revision submitted to A&A, comments welcome"},{"id":"http://arxiv.org/abs/2210.00841v2","updated":"2023-03-03T10:37:00Z","published":"2022-10-03T11:57:30Z","title":"Spatial Entropy as an Inductive Bias for Vision Transformers","summary":"  Recent work on Vision Transformers (VTs) showed that introducing a local\ninductive bias in the VT architecture helps reducing the number of samples\nnecessary for training. However, the architecture modifications lead to a loss\nof generality of the Transformer backbone, partially contradicting the push\ntowards the development of uniform architectures, shared, e.g., by both the\nComputer Vision and the Natural Language Processing areas. In this work, we\npropose a different and complementary direction, in which a local bias is\nintroduced using an auxiliary self-supervised task, performed jointly with\nstandard supervised training. Specifically, we exploit the observation that the\nattention maps of VTs, when trained with self-supervision, can contain a\nsemantic segmentation structure which does not spontaneously emerge when\ntraining is supervised. Thus, we explicitly encourage the emergence of this\nspatial clustering as a form of training regularization. In more detail, we\nexploit the assumption that, in a given image, objects usually correspond to\nfew connected regions, and we propose a spatial formulation of the information\nentropy to quantify this object-based inductive bias. By minimizing the\nproposed spatial entropy, we include an additional self-supervised signal\nduring training. Using extensive experiments, we show that the proposed\nregularization leads to equivalent or better results than other VT proposals\nwhich include a local bias by changing the basic Transformer architecture, and\nit can drastically boost the VT final accuracy when using small-medium training\nsets. The code is available at https://github.com/helia95/SAR.\n","authors":["Yahui Liu","Enver Sangineto","Yajing Chen","Linchao Bao","Haoxian Zhang","Nicu Sebe","Bruno Lepri","Marco De Nadai"],"pdf_url":"https://arxiv.org/pdf/2210.00841v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2206.04636"},{"id":"http://arxiv.org/abs/2302.08785v2","updated":"2023-03-03T10:07:50Z","published":"2023-02-17T09:52:36Z","title":"Few-shot 3D LiDAR Semantic Segmentation for Autonomous Driving","summary":"  In autonomous driving, the novel objects and lack of annotations challenge\nthe traditional 3D LiDAR semantic segmentation based on deep learning. Few-shot\nlearning is a feasible way to solve these issues. However, currently few-shot\nsemantic segmentation methods focus on camera data, and most of them only\npredict the novel classes without considering the base classes. This setting\ncannot be directly applied to autonomous driving due to safety concerns. Thus,\nwe propose a few-shot 3D LiDAR semantic segmentation method that predicts both\nnovel classes and base classes simultaneously. Our method tries to solve the\nbackground ambiguity problem in generalized few-shot semantic segmentation. We\nfirst review the original cross-entropy and knowledge distillation losses, then\npropose a new loss function that incorporates the background information to\nachieve 3D LiDAR few-shot semantic segmentation. Extensive experiments on\nSemanticKITTI demonstrate the effectiveness of our method.\n","authors":["Jilin Mei","Junbao Zhou","Yu Hu"],"pdf_url":"https://arxiv.org/pdf/2302.08785v2.pdf","comment":"Accepted by ICRA 2023"},{"id":"http://arxiv.org/abs/2303.01819v1","updated":"2023-03-03T09:59:42Z","published":"2023-03-03T09:59:42Z","title":"Exploring Machine Learning Privacy/Utility trade-off from a\n  hyperparameters Lens","summary":"  Machine Learning (ML) architectures have been applied to several applications\nthat involve sensitive data, where a guarantee of users' data privacy is\nrequired. Differentially Private Stochastic Gradient Descent (DPSGD) is the\nstate-of-the-art method to train privacy-preserving models. However, DPSGD\ncomes at a considerable accuracy loss leading to sub-optimal privacy/utility\ntrade-offs. Towards investigating new ground for better privacy-utility\ntrade-off, this work questions; (i) if models' hyperparameters have any\ninherent impact on ML models' privacy-preserving properties, and (ii) if\nmodels' hyperparameters have any impact on the privacy/utility trade-off of\ndifferentially private models. We propose a comprehensive design space\nexploration of different hyperparameters such as the choice of activation\nfunctions, the learning rate and the use of batch normalization. Interestingly,\nwe found that utility can be improved by using Bounded RELU as activation\nfunctions with the same privacy-preserving characteristics. With a drop-in\nreplacement of the activation function, we achieve new state-of-the-art\naccuracy on MNIST (96.02\\%), FashionMnist (84.76\\%), and CIFAR-10 (44.42\\%)\nwithout any modification of the learning procedure fundamentals of DPSGD.\n","authors":["Ayoub Arous","Amira Guesmi","Muhammad Abdullah Hanif","Ihsen Alouani","Muhammad Shafique"],"pdf_url":"https://arxiv.org/pdf/2303.01819v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01818v1","updated":"2023-03-03T09:59:25Z","published":"2023-03-03T09:59:25Z","title":"Word-As-Image for Semantic Typography","summary":"  A word-as-image is a semantic typography technique where a word illustration\npresents a visualization of the meaning of the word, while also preserving its\nreadability. We present a method to create word-as-image illustrations\nautomatically. This task is highly challenging as it requires semantic\nunderstanding of the word and a creative idea of where and how to depict these\nsemantics in a visually pleasing and legible manner. We rely on the remarkable\nability of recent large pretrained language-vision models to distill textual\nconcepts visually. We target simple, concise, black-and-white designs that\nconvey the semantics clearly. We deliberately do not change the color or\ntexture of the letters and do not use embellishments. Our method optimizes the\noutline of each letter to convey the desired concept, guided by a pretrained\nStable Diffusion model. We incorporate additional loss terms to ensure the\nlegibility of the text and the preservation of the style of the font. We show\nhigh quality and engaging results on numerous examples and compare to\nalternative techniques.\n","authors":["Shir Iluz","Yael Vinker","Amir Hertz","Daniel Berio","Daniel Cohen-Or","Ariel Shamir"],"pdf_url":"https://arxiv.org/pdf/2303.01818v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01806v1","updated":"2023-03-03T09:25:39Z","published":"2023-03-03T09:25:39Z","title":"When does Privileged Information Explain Away Label Noise?","summary":"  Leveraging privileged information (PI), or features available during training\nbut not at test time, has recently been shown to be an effective method for\naddressing label noise. However, the reasons for its effectiveness are not well\nunderstood. In this study, we investigate the role played by different\nproperties of the PI in explaining away label noise. Through experiments on\nmultiple datasets with real PI (CIFAR-N/H) and a new large-scale benchmark\nImageNet-PI, we find that PI is most helpful when it allows networks to easily\ndistinguish clean from noisy data, while enabling a learning shortcut to\nmemorize the noisy examples. Interestingly, when PI becomes too predictive of\nthe target label, PI methods often perform worse than their no-PI baselines.\nBased on these findings, we propose several enhancements to the\nstate-of-the-art PI methods and demonstrate the potential of PI as a means of\ntackling label noise. Finally, we show how we can easily combine the resulting\nPI approaches with existing no-PI techniques designed to deal with label noise.\n","authors":["Guillermo Ortiz-Jimenez","Mark Collier","Anant Nawalgaria","Alexander D'Amour","Jesse Berent","Rodolphe Jenatton","Effrosyni Kokiopoulou"],"pdf_url":"https://arxiv.org/pdf/2303.01806v1.pdf","comment":"22 pages, 14 figures, 7 tables"},{"id":"http://arxiv.org/abs/2303.01804v1","updated":"2023-03-03T09:24:29Z","published":"2023-03-03T09:24:29Z","title":"Are All Point Clouds Suitable for Completion? Weakly Supervised Quality\n  Evaluation Network for Point Cloud Completion","summary":"  In the practical application of point cloud completion tasks, real data\nquality is usually much worse than the CAD datasets used for training. A small\namount of noisy data will usually significantly impact the overall system's\naccuracy. In this paper, we propose a quality evaluation network to score the\npoint clouds and help judge the quality of the point cloud before applying the\ncompletion model. We believe our scoring method can help researchers select\nmore appropriate point clouds for subsequent completion and reconstruction and\navoid manual parameter adjustment. Moreover, our evaluation model is fast and\nstraightforward and can be directly inserted into any model's training or use\nprocess to facilitate the automatic selection and post-processing of point\nclouds. We propose a complete dataset construction and model evaluation method\nbased on ShapeNet. We verify our network using detection and flow estimation\ntasks on KITTI, a real-world dataset for autonomous driving. The experimental\nresults show that our model can effectively distinguish the quality of point\nclouds and help in practical tasks.\n","authors":["Jieqi Shi","Peiliang Li","Xiaozhi Chen","Shaojie Shen"],"pdf_url":"https://arxiv.org/pdf/2303.01804v1.pdf","comment":"ICRA 2023"},{"id":"http://arxiv.org/abs/2303.01803v1","updated":"2023-03-03T09:19:08Z","published":"2023-03-03T09:19:08Z","title":"Confidence-driven Bounding Box Localization for Small Object Detection","summary":"  Despite advancements in generic object detection, there remains a performance\ngap in detecting small objects compared to normal-scale objects. We for the\nfirst time observe that existing bounding box regression methods tend to\nproduce distorted gradients for small objects and result in less accurate\nlocalization. To address this issue, we present a novel Confidence-driven\nBounding Box Localization (C-BBL) method to rectify the gradients. C-BBL\nquantizes continuous labels into grids and formulates two-hot ground truth\nlabels. In prediction, the bounding box head generates a confidence\ndistribution over the grids. Unlike the bounding box regression paradigms in\nconventional detectors, we introduce a classification-based localization\nobjective through cross entropy between ground truth and predicted confidence\ndistribution, generating confidence-driven gradients. Additionally, C-BBL\ndescribes a uncertainty loss based on distribution entropy in labels and\npredictions to further reduce the uncertainty in small object localization. The\nmethod is evaluated on multiple detectors using three object detection\nbenchmarks and consistently improves baseline detectors, achieving\nstate-of-the-art performance. We also demonstrate the generalizability of C-BBL\nto different label systems and effectiveness for high resolution detection,\nwhich validates its prospect as a general solution.\n","authors":["Huixin Sun","Baochang Zhang","Yanjing Li","Xianbin Cao"],"pdf_url":"https://arxiv.org/pdf/2303.01803v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.00380v2","updated":"2023-03-03T09:09:01Z","published":"2022-05-01T02:20:43Z","title":"Geometric Graph Representation with Learnable Graph Structure and\n  Adaptive AU Constraint for Micro-Expression Recognition","summary":"  Micro-expression recognition (MER) is valuable because micro-expressions\n(MEs) can reveal genuine emotions. Most works take image sequences as input and\ncannot effectively explore ME information because subtle ME-related motions are\neasily submerged in unrelated information. Instead, the facial landmark is a\nlow-dimensional and compact modality, which achieves lower computational cost\nand potentially concentrates on ME-related movement features. However, the\ndiscriminability of facial landmarks for MER is unclear. Thus, this paper\nexplores the contribution of facial landmarks and proposes a novel framework to\nefficiently recognize MEs. Firstly, a geometric two-stream graph network is\nconstructed to aggregate the low-order and high-order geometric movement\ninformation from facial landmarks to obtain discriminative ME representation.\nSecondly, a self-learning fashion is introduced to automatically model the\ndynamic relationship between nodes even long-distance nodes. Furthermore, an\nadaptive action unit loss is proposed to reasonably build the strong\ncorrelation between landmarks, facial action units and MEs. Notably, this work\nprovides a novel idea with much higher efficiency to promote MER, only\nutilizing graph-based geometric features. The experimental results demonstrate\nthat the proposed method achieves competitive performance with a significantly\nreduced computational cost. Furthermore, facial landmarks significantly\ncontribute to MER and are worth further study for high-efficient ME analysis.\n","authors":["Jinsheng Wei","Wei Peng","Guanming Lu","Yante Li","Jingjie Yan","Guoying Zhao"],"pdf_url":"https://arxiv.org/pdf/2205.00380v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01788v1","updated":"2023-03-03T08:54:06Z","published":"2023-03-03T08:54:06Z","title":"Visual Exemplar Driven Task-Prompting for Unified Perception in\n  Autonomous Driving","summary":"  Multi-task learning has emerged as a powerful paradigm to solve a range of\ntasks simultaneously with good efficiency in both computation resources and\ninference time. However, these algorithms are designed for different tasks\nmostly not within the scope of autonomous driving, thus making it hard to\ncompare multi-task methods in autonomous driving. Aiming to enable the\ncomprehensive evaluation of present multi-task learning methods in autonomous\ndriving, we extensively investigate the performance of popular multi-task\nmethods on the large-scale driving dataset, which covers four common perception\ntasks, i.e., object detection, semantic segmentation, drivable area\nsegmentation, and lane detection. We provide an in-depth analysis of current\nmulti-task learning methods under different common settings and find out that\nthe existing methods make progress but there is still a large performance gap\ncompared with single-task baselines. To alleviate this dilemma in autonomous\ndriving, we present an effective multi-task framework, VE-Prompt, which\nintroduces visual exemplars via task-specific prompting to guide the model\ntoward learning high-quality task-specific representations. Specifically, we\ngenerate visual exemplars based on bounding boxes and color-based markers,\nwhich provide accurate visual appearances of target categories and further\nmitigate the performance gap. Furthermore, we bridge transformer-based encoders\nand convolutional layers for efficient and accurate unified perception in\nautonomous driving. Comprehensive experimental results on the diverse\nself-driving dataset BDD100K show that the VE-Prompt improves the multi-task\nbaseline and further surpasses single-task models.\n","authors":["Xiwen Liang","Minzhe Niu","Jianhua Han","Hang Xu","Chunjing Xu","Xiaodan Liang"],"pdf_url":"https://arxiv.org/pdf/2303.01788v1.pdf","comment":"Accepted at CVPR 2023"},{"id":"http://arxiv.org/abs/2303.01786v1","updated":"2023-03-03T08:53:00Z","published":"2023-03-03T08:53:00Z","title":"3D Multi-Object Tracking Based on Uncertainty-Guided Data Association","summary":"  In the existing literature, most 3D multi-object tracking algorithms based on\nthe tracking-by-detection framework employed deterministic tracks and\ndetections for similarity calculation in the data association stage. Namely,\nthe inherent uncertainties existing in tracks and detections are overlooked. In\nthis work, we discard the commonly used deterministic tracks and deterministic\ndetections for data association, instead, we propose to model tracks and\ndetections as random vectors in which uncertainties are taken into account.\nThen, based on the Jensen-Shannon divergence, the similarity between two\nmultidimensional distributions, i.e. track and detection, is evaluated for data\nassociation purposes. Lastly, the level of track uncertainty is incorporated in\nour cost function design to guide the data association process. Comparative\nexperiments have been conducted on two typical datasets, KITTI and nuScenes,\nand the results indicated that our proposed method outperformed the compared\nstate-of-the-art 3D tracking algorithms. For the benefit of the community, our\ncode has been made available at https://github.com/hejiawei2023/UG3DMOT.\n","authors":["Jiawei He","Chunyun Fu","Xiyang Wang"],"pdf_url":"https://arxiv.org/pdf/2303.01786v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2303.01781v1","updated":"2023-03-03T08:44:20Z","published":"2023-03-03T08:44:20Z","title":"Meme Sentiment Analysis Enhanced with Multimodal Spatial Encoding and\n  Facial Embedding","summary":"  Internet memes are characterised by the interspersing of text amongst visual\nelements. State-of-the-art multimodal meme classifiers do not account for the\nrelative positions of these elements across the two modalities, despite the\nlatent meaning associated with where text and visual elements are placed.\nAgainst two meme sentiment classification datasets, we systematically show\nperformance gains from incorporating the spatial position of visual objects,\nfaces, and text clusters extracted from memes. In addition, we also present\nfacial embedding as an impactful enhancement to image representation in a\nmultimodal meme classifier. Finally, we show that incorporating this spatial\ninformation allows our fully automated approaches to outperform their\ncorresponding baselines that rely on additional human validation of\nOCR-extracted text.\n","authors":["Muzhaffar Hazman","Susan McKeever","Josephine Griffith"],"pdf_url":"https://arxiv.org/pdf/2303.01781v1.pdf","comment":"Published as chapter in ISBN:978-3-031-26438-2"},{"id":"http://arxiv.org/abs/2212.07065v2","updated":"2023-03-03T08:37:38Z","published":"2022-12-14T07:21:45Z","title":"CLIPSep: Learning Text-queried Sound Separation with Noisy Unlabeled\n  Videos","summary":"  Recent years have seen progress beyond domain-specific sound separation for\nspeech or music towards universal sound separation for arbitrary sounds. Prior\nwork on universal sound separation has investigated separating a target sound\nout of an audio mixture given a text query. Such text-queried sound separation\nsystems provide a natural and scalable interface for specifying arbitrary\ntarget sounds. However, supervised text-queried sound separation systems\nrequire costly labeled audio-text pairs for training. Moreover, the audio\nprovided in existing datasets is often recorded in a controlled environment,\ncausing a considerable generalization gap to noisy audio in the wild. In this\nwork, we aim to approach text-queried universal sound separation by using only\nunlabeled data. We propose to leverage the visual modality as a bridge to learn\nthe desired audio-textual correspondence. The proposed CLIPSep model first\nencodes the input query into a query vector using the contrastive\nlanguage-image pretraining (CLIP) model, and the query vector is then used to\ncondition an audio separation model to separate out the target sound. While the\nmodel is trained on image-audio pairs extracted from unlabeled videos, at test\ntime we can instead query the model with text inputs in a zero-shot setting,\nthanks to the joint language-image embedding learned by the CLIP model.\nFurther, videos in the wild often contain off-screen sounds and background\nnoise that may hinder the model from learning the desired audio-textual\ncorrespondence. To address this problem, we further propose an approach called\nnoise invariant training for training a query-based sound separation model on\nnoisy data. Experimental results show that the proposed models successfully\nlearn text-queried universal sound separation using only noisy unlabeled\nvideos, even achieving competitive performance against a supervised model in\nsome settings.\n","authors":["Hao-Wen Dong","Naoya Takahashi","Yuki Mitsufuji","Julian McAuley","Taylor Berg-Kirkpatrick"],"pdf_url":"https://arxiv.org/pdf/2212.07065v2.pdf","comment":"Accepted by ICLR 2023. Audio samples can be found at\n  https://sony.github.io/CLIPSep/"},{"id":"http://arxiv.org/abs/2303.01777v1","updated":"2023-03-03T08:36:19Z","published":"2023-03-03T08:36:19Z","title":"Benchmarking White Blood Cell Classification Under Domain Shift","summary":"  Recognizing the types of white blood cells (WBCs) in microscopic images of\nhuman blood smears is a fundamental task in the fields of pathology and\nhematology. Although previous studies have made significant contributions to\nthe development of methods and datasets, few papers have investigated\nbenchmarks or baselines that others can easily refer to. For instance, we\nobserved notable variations in the reported accuracies of the same\nConvolutional Neural Network (CNN) model across different studies, yet no\npublic implementation exists to reproduce these results. In this paper, we\nestablish a benchmark for WBC recognition. Our results indicate that CNN-based\nmodels achieve high accuracy when trained and tested under similar imaging\nconditions. However, their performance drops significantly when tested under\ndifferent conditions. Moreover, the ResNet classifier, which has been widely\nemployed in previous work, exhibits an unreasonably poor generalization ability\nunder domain shifts due to batch normalization. We investigate this issue and\nsuggest some alternative normalization techniques that can mitigate it. We make\nfully-reproducible code publicly\navailable\\footnote{\\url{https://github.com/apple2373/wbc-benchmark}}.\n","authors":["Satoshi Tsutsui","Zhengyang Su","Bihan Wen"],"pdf_url":"https://arxiv.org/pdf/2303.01777v1.pdf","comment":"Accepted to the International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP) 2023"},{"id":"http://arxiv.org/abs/2303.01776v1","updated":"2023-03-03T08:34:28Z","published":"2023-03-03T08:34:28Z","title":"Prior Information based Decomposition and Reconstruction Learning for\n  Micro-Expression Recognition","summary":"  Micro-expression recognition (MER) draws intensive research interest as\nmicro-expressions (MEs) can infer genuine emotions. Prior information can guide\nthe model to learn discriminative ME features effectively. However, most works\nfocus on researching the general models with a stronger representation ability\nto adaptively aggregate ME movement information in a holistic way, which may\nignore the prior information and properties of MEs. To solve this issue, driven\nby the prior information that the category of ME can be inferred by the\nrelationship between the actions of facial different components, this work\ndesigns a novel model that can conform to this prior information and learn ME\nmovement features in an interpretable way. Specifically, this paper proposes a\nDecomposition and Reconstruction-based Graph Representation Learning (DeRe-GRL)\nmodel to effectively learn high-level ME features. DeRe-GRL includes two\nmodules: Action Decomposition Module (ADM) and Relation Reconstruction Module\n(RRM), where ADM learns action features of facial key components and RRM\nexplores the relationship between these action features. Based on facial key\ncomponents, ADM divides the geometric movement features extracted by the graph\nmodel-based backbone into several sub-features, and learns the map matrix to\nmap these sub-features into multiple action features; then, RRM learns weights\nto weight all action features to build the relationship between action\nfeatures. The experimental results demonstrate the effectiveness of the\nproposed modules, and the proposed method achieves competitive performance.\n","authors":["Jinsheng Wei","Haoyu Chen","Guanming Lu","Jingjie Yan","Yue Xie","Guoying Zhao"],"pdf_url":"https://arxiv.org/pdf/2303.01776v1.pdf","comment":"The article has been accepted by IEICE TRANS. Information and Systems"},{"id":"http://arxiv.org/abs/2209.03102v3","updated":"2023-03-03T08:16:08Z","published":"2022-09-07T12:29:29Z","title":"MSMDFusion: Fusing LiDAR and Camera at Multiple Scales with Multi-Depth\n  Seeds for 3D Object Detection","summary":"  Fusing LiDAR and camera information is essential for achieving accurate and\nreliable 3D object detection in autonomous driving systems. This is challenging\ndue to the difficulty of combining multi-granularity geometric and semantic\nfeatures from two drastically different modalities. Recent approaches aim at\nexploring the semantic densities of camera features through lifting points in\n2D camera images (referred to as seeds) into 3D space, and then incorporate 2D\nsemantics via cross-modal interaction or fusion techniques. However, depth\ninformation is under-investigated in these approaches when lifting points into\n3D space, thus 2D semantics can not be reliably fused with 3D points. Moreover,\ntheir multi-modal fusion strategy, which is implemented as concatenation or\nattention, either can not effectively fuse 2D and 3D information or is unable\nto perform fine-grained interactions in the voxel space. To this end, we\npropose a novel framework with better utilization of the depth information and\nfine-grained cross-modal interaction between LiDAR and camera, which consists\nof two important components. First, a Multi-Depth Unprojection (MDU) method\nwith depth-aware designs is used to enhance the depth quality of the lifted\npoints at each interaction level. Second, a Gated Modality-Aware Convolution\n(GMA-Conv) block is applied to modulate voxels involved with the camera\nmodality in a fine-grained manner and then aggregate multi-modal features into\na unified space. Together they provide the detection head with more\ncomprehensive features from LiDAR and camera. On the nuScenes test benchmark,\nour proposed method, abbreviated as MSMDFusion, achieves state-of-the-art 3D\nobject detection results with 71.5% mAP and 74.0% NDS, and strong tracking\nresults with 74.0% AMOTA without using test-time-augmentation and ensemble\ntechniques. The code is available at https://github.com/SxJyJay/MSMDFusion.\n","authors":["Yang Jiao","Zequn Jie","Shaoxiang Chen","Jingjing Chen","Lin Ma","Yu-Gang Jiang"],"pdf_url":"https://arxiv.org/pdf/2209.03102v3.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2303.01765v1","updated":"2023-03-03T08:08:04Z","published":"2023-03-03T08:08:04Z","title":"Diverse 3D Hand Gesture Prediction from Body Dynamics by Bilateral Hand\n  Disentanglement","summary":"  Predicting natural and diverse 3D hand gestures from the upper body dynamics\nis a practical yet challenging task in virtual avatar creation. Previous works\nusually overlook the asymmetric motions between two hands and generate two\nhands in a holistic manner, leading to unnatural results. In this work, we\nintroduce a novel bilateral hand disentanglement based two-stage 3D hand\ngeneration method to achieve natural and diverse 3D hand prediction from body\ndynamics. In the first stage, we intend to generate natural hand gestures by\ntwo hand-disentanglement branches. Considering the asymmetric gestures and\nmotions of two hands, we introduce a Spatial-Residual Memory (SRM) module to\nmodel spatial interaction between the body and each hand by residual learning.\nTo enhance the coordination of two hand motions wrt. body dynamics\nholistically, we then present a Temporal-Motion Memory (TMM) module. TMM can\neffectively model the temporal association between body dynamics and two hand\nmotions. The second stage is built upon the insight that 3D hand predictions\nshould be non-deterministic given the sequential body postures. Thus, we\nfurther diversify our 3D hand predictions based on the initial output from the\nstage one. Concretely, we propose a Prototypical-Memory Sampling Strategy (PSS)\nto generate the non-deterministic hand gestures by gradient-based Markov Chain\nMonte Carlo (MCMC) sampling. Extensive experiments demonstrate that our method\noutperforms the state-of-the-art models on the B2H dataset and our newly\ncollected TED Hands dataset.\n","authors":["Xingqun Qi","Chen Liu","Muyi Sun","Lincheng Li","Changjie Fan","Xin Yu"],"pdf_url":"https://arxiv.org/pdf/2303.01765v1.pdf","comment":"To appear in CVPR 2023"},{"id":"http://arxiv.org/abs/2302.08175v3","updated":"2023-03-03T07:45:52Z","published":"2023-02-16T09:44:55Z","title":"A numerical approximation method for the Fisher-Rao distance between\n  multivariate normal distributions","summary":"  We present a simple method to approximate Rao's distance between multivariate\nnormal distributions based on discretizing curves joining normal distributions\nand approximating Rao distances between successive nearby normal distributions\non the curve by Jeffreys divergence. We consider experimentally the linear\ninterpolation curves in the ordinary, natural and expectation parameterizations\nof the normal distributions, and compare these curves with a curve derived from\nthe Calvo and Oller's isometric embedding of the Fisher-Rao $d$-variate normal\nmanifold into the cone of $(d+1)\\times (d+1)$ symmetric positive-definite\nmatrices [Journal of multivariate analysis 35.2 (1990): 223-242]. We report on\nour experiments and assess the quality of our approximation technique by\ncomparing the numerical approximations with lower and upper bounds. Finally, we\npresent some information-geometric properties of the Calvo and Oller's\nisometric embedding.\n","authors":["Frank Nielsen"],"pdf_url":"https://arxiv.org/pdf/2302.08175v3.pdf","comment":"24 pages, 12 figures, 3 tables"},{"id":"http://arxiv.org/abs/2211.12698v2","updated":"2023-03-03T07:24:23Z","published":"2022-11-23T04:24:21Z","title":"Rega-Net:Retina Gabor Attention for Deep Convolutional Neural Networks","summary":"  Extensive research works demonstrate that the attention mechanism in\nconvolutional neural networks (CNNs) effectively improves accuracy.\nNevertheless, few works design attention mechanisms using large receptive\nfields. In this work, we propose a novel attention method named Rega-net to\nincrease CNN accuracy by enlarging the receptive field. Inspired by the\nmechanism of the human retina, we design convolutional kernels to resemble the\nnon-uniformly distributed structure of the human retina. Then, we sample\nvariable-resolution values in the Gabor function distribution and fill these\nvalues in retina-like kernels. This distribution allows essential features to\nbe more visible in the center position of the receptive field. We further\ndesign an attention module including these retina-like kernels. Experiments\ndemonstrate that our Rega-Net achieves 79.96% top-1 accuracy on ImageNet-1K\nclassification and 43.1% mAP on COCO2017 object detection. The mAP of the\nRega-Net increased by up to 3.5% compared to baseline networks.\n","authors":["Chun Bao","Jie Cao","Yaqian Ning","Yang Cheng","Qun Hao"],"pdf_url":"https://arxiv.org/pdf/2211.12698v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14924v2","updated":"2023-03-03T07:23:20Z","published":"2022-11-27T19:50:37Z","title":"Post-Processing Temporal Action Detection","summary":"  Existing Temporal Action Detection (TAD) methods typically take a\npre-processing step in converting an input varying-length video into a\nfixed-length snippet representation sequence, before temporal boundary\nestimation and action classification. This pre-processing step would temporally\ndownsample the video, reducing the inference resolution and hampering the\ndetection performance in the original temporal resolution. In essence, this is\ndue to a temporal quantization error introduced during the resolution\ndownsampling and recovery. This could negatively impact the TAD performance,\nbut is largely ignored by existing methods. To address this problem, in this\nwork we introduce a novel model-agnostic post-processing method without model\nredesign and retraining. Specifically, we model the start and end points of\naction instances with a Gaussian distribution for enabling temporal boundary\ninference at a sub-snippet level. We further introduce an efficient\nTaylor-expansion based approximation, dubbed as Gaussian Approximated\nPost-processing (GAP). Extensive experiments demonstrate that our GAP can\nconsistently improve a wide variety of pre-trained off-the-shelf TAD models on\nthe challenging ActivityNet (+0.2% -0.7% in average mAP) and THUMOS (+0.2%\n-0.5% in average mAP) benchmarks. Such performance gains are already\nsignificant and highly comparable to those achieved by novel model designs.\nAlso, GAP can be integrated with model training for further performance gain.\nImportantly, GAP enables lower temporal resolutions for more efficient\ninference, facilitating low-resource applications. The code will be available\nin https://github.com/sauradip/GAP\n","authors":["Sauradip Nag","Xiatian Zhu","Yi-Zhe Song","Tao Xiang"],"pdf_url":"https://arxiv.org/pdf/2211.14924v2.pdf","comment":"CVPR 2023; Code available at https://github.com/sauradip/GAP"},{"id":"http://arxiv.org/abs/2303.01748v1","updated":"2023-03-03T07:20:58Z","published":"2023-03-03T07:20:58Z","title":"Generative Diffusions in Augmented Spaces: A Complete Recipe","summary":"  Score-based Generative Models (SGMs) have achieved state-of-the-art synthesis\nresults on diverse tasks. However, the current design space of the forward\ndiffusion process is largely unexplored and often relies on physical intuition\nor simplifying assumptions. Leveraging results from the design of scalable\nBayesian posterior samplers, we present a complete recipe for constructing\nforward processes in SGMs, all of which are guaranteed to converge to the\ntarget distribution of interest. We show that several existing SGMs can be cast\nas specific instantiations of this parameterization. Furthermore, building on\nthis recipe, we construct a novel SGM: Phase Space Langevin Diffusion (PSLD),\nwhich performs score-based modeling in a space augmented with auxiliary\nvariables akin to a physical phase space. We show that PSLD outperforms\ncompeting baselines in terms of sample quality and the speed-vs-quality\ntradeoff across different samplers on various standard image synthesis\nbenchmarks. Moreover, we show that PSLD achieves sample quality comparable to\nstate-of-the-art SGMs (FID: 2.10 on unconditional CIFAR-10 generation),\nproviding an attractive alternative as an SGM backbone for further development.\nWe will publish our code and model checkpoints for reproducibility at\nhttps://github.com/mandt-lab/PSLD.\n","authors":["Kushagra Pandey","Stephan Mandt"],"pdf_url":"https://arxiv.org/pdf/2303.01748v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.12277v2","updated":"2023-03-03T07:18:47Z","published":"2022-11-22T13:49:10Z","title":"Semantic Guided Level-Category Hybrid Prediction Network for\n  Hierarchical Image Classification","summary":"  Hierarchical classification (HC) assigns each object with multiple labels\norganized into a hierarchical structure. The existing deep learning based HC\nmethods usually predict an instance starting from the root node until a leaf\nnode is reached. However, in the real world, images interfered by noise,\nocclusion, blur, or low resolution may not provide sufficient information for\nthe classification at subordinate levels. To address this issue, we propose a\nnovel semantic guided level-category hybrid prediction network (SGLCHPN) that\ncan jointly perform the level and category prediction in an end-to-end manner.\nSGLCHPN comprises two modules: a visual transformer that extracts feature\nvectors from the input images, and a semantic guided cross-attention module\nthat uses categories word embeddings as queries to guide learning\ncategory-specific representations. In order to evaluate the proposed method, we\nconstruct two new datasets in which images are at a broad range of quality and\nthus are labeled to different levels (depths) in the hierarchy according to\ntheir individual quality. Experimental results demonstrate the effectiveness of\nour proposed HC method.\n","authors":["Peng Wang","Jingzhou Chen","Yuntao Qian"],"pdf_url":"https://arxiv.org/pdf/2211.12277v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.01671v2","updated":"2023-03-03T07:18:31Z","published":"2022-11-03T09:28:45Z","title":"Visually Adversarial Attacks and Defenses in the physical world: A\n  Survey","summary":"  Although Deep Neural Networks (DNNs) have been widely applied in various\nreal-world scenarios, they are vulnerable to adversarial examples. The current\nadversarial attacks in computer vision can be divided into digital attacks and\nphysical attacks according to their different attack forms. Compared with\ndigital attacks, which generate perturbations in the digital pixels, physical\nattacks are more practical in the real world. Owing to the serious security\nproblem caused by physically adversarial examples, many works have been\nproposed to evaluate the physically adversarial robustness of DNNs in the past\nyears. In this paper, we summarize a survey versus the current physically\nadversarial attacks and physically adversarial defenses in computer vision. To\nestablish a taxonomy, we organize the current physical attacks from attack\ntasks, attack forms, and attack methods, respectively. Thus, readers can have a\nsystematic knowledge of this topic from different aspects. For the physical\ndefenses, we establish the taxonomy from pre-processing, in-processing, and\npost-processing for the DNN models to achieve full coverage of the adversarial\ndefenses. Based on the above survey, we finally discuss the challenges of this\nresearch field and further outlook on the future direction.\n","authors":["Xingxing Wei","Bangzheng Pu","Jiefan Lu","Baoyuan Wu"],"pdf_url":"https://arxiv.org/pdf/2211.01671v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01743v1","updated":"2023-03-03T07:10:02Z","published":"2023-03-03T07:10:02Z","title":"A Laplace-inspired Distribution on SO(3) for Probabilistic Rotation\n  Estimation","summary":"  Estimating the 3DoF rotation from a single RGB image is an important yet\nchallenging problem. Probabilistic rotation regression has raised more and more\nattention with the benefit of expressing uncertainty information along with the\nprediction. Though modeling noise using Gaussian-resembling Bingham\ndistribution and matrix Fisher distribution is natural, they are shown to be\nsensitive to outliers for the nature of quadratic punishment to deviations. In\nthis paper, we draw inspiration from multivariate Laplace distribution and\npropose a novel Rotation Laplace distribution on SO(3). Rotation Laplace\ndistribution is robust to the disturbance of outliers and enforces much\ngradient to the low-error region, resulting in a better convergence. Our\nextensive experiments show that our proposed distribution achieves\nstate-of-the-art performance for rotation regression tasks over both\nprobabilistic and non-probabilistic baselines. Our project page is at\nhttps://pku-epic.github.io/RotationLaplace.\n","authors":["Yingda Yin","Yang Wang","He Wang","Baoquan Chen"],"pdf_url":"https://arxiv.org/pdf/2303.01743v1.pdf","comment":"ICLR 2023 Spotlight (notable-top-25%)"},{"id":"http://arxiv.org/abs/2211.13974v3","updated":"2023-03-03T07:06:43Z","published":"2022-11-25T09:35:46Z","title":"ILSGAN: Independent Layer Synthesis for Unsupervised\n  Foreground-Background Segmentation","summary":"  Unsupervised foreground-background segmentation aims at extracting salient\nobjects from cluttered backgrounds, where Generative Adversarial Network (GAN)\napproaches, especially layered GANs, show great promise. However, without human\nannotations, they are typically prone to produce foreground and background\nlayers with non-negligible semantic and visual confusion, dubbed \"information\nleakage\", resulting in notable degeneration of the generated segmentation mask.\nTo alleviate this issue, we propose a simple-yet-effective explicit layer\nindependence modeling approach, termed Independent Layer Synthesis GAN\n(ILSGAN), pursuing independent foreground-background layer generation by\nencouraging their discrepancy. Specifically, it targets minimizing the mutual\ninformation between visible and invisible regions of the foreground and\nbackground to spur interlayer independence. Through in-depth theoretical and\nexperimental analyses, we justify that explicit layer independence modeling is\ncritical to suppressing information leakage and contributes to impressive\nsegmentation performance gains. Also, our ILSGAN achieves strong\nstate-of-the-art generation quality and segmentation performance on complex\nreal-world data.\n","authors":["Qiran Zou","Yu Yang","Wing Yin Cheung","Chang Liu","Xiangyang Ji"],"pdf_url":"https://arxiv.org/pdf/2211.13974v3.pdf","comment":"Accepted by AAAI 2023 (Oral)"},{"id":"http://arxiv.org/abs/2303.01740v1","updated":"2023-03-03T06:57:22Z","published":"2023-03-03T06:57:22Z","title":"DeepfakeMAE: Facial Part Consistency Aware Masked Autoencoder for\n  Deepfake Video Detection","summary":"  Deepfake techniques have been used maliciously, resulting in strong research\ninterests in developing Deepfake detection methods. Deepfake often manipulates\nthe video content by tampering with some facial parts. However, this\nmanipulation usually breaks the consistency among facial parts, e.g., Deepfake\nmay change smiling lips to upset, but the eyes are still smiling. Existing\nworks propose to spot inconsistency on some specific facial parts (e.g., lips),\nbut they may perform poorly if new Deepfake techniques focus on the specific\nfacial parts used by the detector. Thus, this paper proposes a new Deepfake\ndetection model, DeepfakeMAE, which can utilize the consistencies among all\nfacial parts. Specifically, given a real face image, we first pretrain a masked\nautoencoder to learn facial part consistency by randomly masking some facial\nparts and reconstructing missing areas based on the remaining facial parts.\nFurthermore, to maximize the discrepancy between real and fake videos, we\npropose a novel model with dual networks that utilize the pretrained encoder\nand decoder, respectively. 1) The pretrained encoder is finetuned for capturing\nthe overall information of the given video. 2) The pretrained decoder is\nutilized for distinguishing real and fake videos based on the motivation that\nDeepfakeMAE's reconstruction should be more similar to a real face image than a\nfake one. Our extensive experiments on standard benchmarks demonstrate that\nDeepfakeMAE is highly effective and especially outperforms the previous\nstate-of-the-art method by 3.1% AUC on average in cross-dataset detection.\n","authors":["Juan Hu","Xin Liao","Difei Gao","Satoshi Tsutsui","Zheng Qin","Mike Zheng Shou"],"pdf_url":"https://arxiv.org/pdf/2303.01740v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.11184v2","updated":"2023-03-03T06:51:27Z","published":"2023-02-22T07:39:09Z","title":"A residual dense vision transformer for medical image super-resolution\n  with segmentation-based perceptual loss fine-tuning","summary":"  Super-resolution plays an essential role in medical imaging because it\nprovides an alternative way to achieve high spatial resolutions and image\nquality with no extra acquisition costs. In the past few decades, the rapid\ndevelopment of deep neural networks has promoted super-resolution performance\nwith novel network architectures, loss functions and evaluation metrics.\nSpecifically, vision transformers dominate a broad range of computer vision\ntasks, but challenges still exist when applying them to low-level medical image\nprocessing tasks. This paper proposes an efficient vision transformer with\nresidual dense connections and local feature fusion to achieve efficient\nsingle-image super-resolution (SISR) of medical modalities. Moreover, we\nimplement a general-purpose perceptual loss with manual control for image\nquality improvements of desired aspects by incorporating prior knowledge of\nmedical image segmentation. Compared with state-of-the-art methods on four\npublic medical image datasets, the proposed method achieves the best PSNR\nscores of 6 modalities among seven modalities. It leads to an average\nimprovement of $+0.09$ dB PSNR with only 38\\% parameters of SwinIR. On the\nother hand, the segmentation-based perceptual loss increases $+0.14$ dB PSNR on\naverage for SOTA methods, including CNNs and vision transformers. Additionally,\nwe conduct comprehensive ablation studies to discuss potential factors for the\nsuperior performance of vision transformers over CNNs and the impacts of\nnetwork and loss function components. The code will be released on GitHub with\nthe paper published.\n","authors":["Jin Zhu","Guang Yang","Pietro Lio"],"pdf_url":"https://arxiv.org/pdf/2302.11184v2.pdf","comment":"Preprint submitted to Medical Image Analysis and under review"},{"id":"http://arxiv.org/abs/2303.01736v1","updated":"2023-03-03T06:32:55Z","published":"2023-03-03T06:32:55Z","title":"Multi-Plane Neural Radiance Fields for Novel View Synthesis","summary":"  Novel view synthesis is a long-standing problem that revolves around\nrendering frames of scenes from novel camera viewpoints. Volumetric approaches\nprovide a solution for modeling occlusions through the explicit 3D\nrepresentation of the camera frustum. Multi-plane Images (MPI) are volumetric\nmethods that represent the scene using front-parallel planes at distinct depths\nbut suffer from depth discretization leading to a 2.D scene representation.\nAnother line of approach relies on implicit 3D scene representations. Neural\nRadiance Fields (NeRF) utilize neural networks for encapsulating the continuous\n3D scene structure within the network weights achieving photorealistic\nsynthesis results, however, methods are constrained to per-scene optimization\nsettings which are inefficient in practice. Multi-plane Neural Radiance Fields\n(MINE) open the door for combining implicit and explicit scene representations.\nIt enables continuous 3D scene representations, especially in the depth\ndimension, while utilizing the input image features to avoid per-scene\noptimization. The main drawback of the current literature work in this domain\nis being constrained to single-view input, limiting the synthesis ability to\nnarrow viewpoint ranges. In this work, we thoroughly examine the performance,\ngeneralization, and efficiency of single-view multi-plane neural radiance\nfields. In addition, we propose a new multiplane NeRF architecture that accepts\nmultiple views to improve the synthesis results and expand the viewing range.\nFeatures from the input source frames are effectively fused through a proposed\nattention-aware fusion module to highlight important information from different\nviewpoints. Experiments show the effectiveness of attention-based fusion and\nthe promising outcomes of our proposed method when compared to multi-view NeRF\nand MPI techniques.\n","authors":["Youssef Abdelkareem","Shady Shehata","Fakhri Karray"],"pdf_url":"https://arxiv.org/pdf/2303.01736v1.pdf","comment":"ICDIPV 2023"},{"id":"http://arxiv.org/abs/2303.01734v1","updated":"2023-03-03T06:28:05Z","published":"2023-03-03T06:28:05Z","title":"AdvART: Adversarial Art for Camouflaged Object Detection Attacks","summary":"  A majority of existing physical attacks in the real world result in\nconspicuous and eye-catching patterns for generated patches, which made them\nidentifiable/detectable by humans. To overcome this limitation, recent work has\nproposed several approaches that aim at generating naturalistic patches using\ngenerative adversarial networks (GANs), which may not catch human's attention.\nHowever, these approaches are computationally intensive and do not always\nconverge to natural looking patterns. In this paper, we propose a novel\nlightweight framework that systematically generates naturalistic adversarial\npatches without using GANs. To illustrate the proposed approach, we generate\nadversarial art (AdvART), which are patches generated to look like artistic\npaintings while maintaining high attack efficiency. In fact, we redefine the\noptimization problem by introducing a new similarity objective. Specifically,\nwe leverage similarity metrics to construct a similarity loss that is added to\nthe optimized objective function. This component guides the patch to follow a\npredefined artistic patterns while maximizing the victim model's loss function.\nOur patch achieves high success rates with $12.53\\%$ mean average precision\n(mAP) on YOLOv4tiny for INRIA dataset.\n","authors":["Amira Guesmi","Ioan Marius Bilasco","Muhammad Shafique","Ihsen Alouani"],"pdf_url":"https://arxiv.org/pdf/2303.01734v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01732v1","updated":"2023-03-03T06:27:15Z","published":"2023-03-03T06:27:15Z","title":"One-class Damage Detector Using Fully-Convolutional Data Description for\n  Prognostics","summary":"  It is important for infrastructure managers to maintain a high standard to\nensure user satisfaction during a lifecycle of infrastructures. Surveillance\ncameras and visual inspections have enabled progress toward automating the\ndetection of anomalous features and assessing the occurrence of the\ndeterioration. Frequently, collecting damage data constraints time consuming\nand repeated inspections. One-class damage detection approach has a merit that\nonly the normal images enables us to optimize the parameters. Simultaneously,\nthe visual explanation using the heat map enable us to understand the localized\nanomalous feature. We propose a civil-purpose application to automate one-class\ndamage detection using the fully-convolutional data description (FCDD). We also\nvisualize the explanation of the damage feature using the up-sampling-based\nactivation map with the Gaussian up-sampling from the receptive field of the\nfully convolutional network (FCN). We demonstrate it in experimental studies:\nconcrete damage and steel corrosion and mention its usefulness and future\nworks.\n","authors":["Takato Yasuno","Masahiro Okano","Riku Ogata","Junichiro Fujii"],"pdf_url":"https://arxiv.org/pdf/2303.01732v1.pdf","comment":"5 pages, 13 figures, 3 tables"},{"id":"http://arxiv.org/abs/2303.01105v2","updated":"2023-03-03T05:39:15Z","published":"2023-03-02T09:37:56Z","title":"Evidence-empowered Transfer Learning for Alzheimer's Disease","summary":"  Transfer learning has been widely utilized to mitigate the data scarcity\nproblem in the field of Alzheimer's disease (AD). Conventional transfer\nlearning relies on re-using models trained on AD-irrelevant tasks such as\nnatural image classification. However, it often leads to negative transfer due\nto the discrepancy between the non-medical source and target medical domains.\nTo address this, we present evidence-empowered transfer learning for AD\ndiagnosis. Unlike conventional approaches, we leverage an AD-relevant auxiliary\ntask, namely morphological change prediction, without requiring additional MRI\ndata. In this auxiliary task, the diagnosis model learns the evidential and\ntransferable knowledge from morphological features in MRI scans. Experimental\nresults demonstrate that our framework is not only effective in improving\ndetection performance regardless of model capacity, but also more\ndata-efficient and faithful.\n","authors":["Kai Tzu-iunn Ong","Hana Kim","Minjin Kim","Jinseong Jang","Beomseok Sohn","Yoon Seong Choi","Dosik Hwang","Seong Jae Hwang","Jinyoung Yeo"],"pdf_url":"https://arxiv.org/pdf/2303.01105v2.pdf","comment":"Accepted to IEEE International Symposium on Biomedical Imaging (ISBI)\n  2023"},{"id":"http://arxiv.org/abs/2207.12534v3","updated":"2023-03-03T05:39:11Z","published":"2022-07-25T21:15:47Z","title":"Trainability Preserving Neural Pruning","summary":"  Many recent works have shown trainability plays a central role in neural\nnetwork pruning -- unattended broken trainability can lead to severe\nunder-performance and unintentionally amplify the effect of retraining learning\nrate, resulting in biased (or even misinterpreted) benchmark results. This\npaper introduces trainability preserving pruning (TPP), a scalable method to\npreserve network trainability against pruning, aiming for improved pruning\nperformance and being more robust to retraining hyper-parameters (e.g.,\nlearning rate). Specifically, we propose to penalize the gram matrix of\nconvolutional filters to decorrelate the pruned filters from the retained\nfilters. In addition to the convolutional layers, per the spirit of preserving\nthe trainability of the whole network, we also propose to regularize the batch\nnormalization parameters (scale and bias). Empirical studies on linear MLP\nnetworks show that TPP can perform on par with the oracle trainability recovery\nscheme. On nonlinear ConvNets (ResNet56/VGG19) on CIFAR10/100, TPP outperforms\nthe other counterpart approaches by an obvious margin. Moreover, results on\nImageNet-1K with ResNets suggest that TPP consistently performs more favorably\nagainst other top-performing structured pruning approaches. Code:\nhttps://github.com/MingSun-Tse/TPP.\n","authors":["Huan Wang","Yun Fu"],"pdf_url":"https://arxiv.org/pdf/2207.12534v3.pdf","comment":"ICLR'23 Camera Ready. 21 Pages. Code:\n  https://github.com/MingSun-Tse/TPP"},{"id":"http://arxiv.org/abs/2303.01710v1","updated":"2023-03-03T04:48:37Z","published":"2023-03-03T04:48:37Z","title":"BayeSeg: Bayesian Modeling for Medical Image Segmentation with\n  Interpretable Generalizability","summary":"  Due to the cross-domain distribution shift aroused from diverse medical\nimaging systems, many deep learning segmentation methods fail to perform well\non unseen data, which limits their real-world applicability. Recent works have\nshown the benefits of extracting domain-invariant representations on domain\ngeneralization. However, the interpretability of domain-invariant features\nremains a great challenge. To address this problem, we propose an interpretable\nBayesian framework (BayeSeg) through Bayesian modeling of image and label\nstatistics to enhance model generalizability for medical image segmentation.\nSpecifically, we first decompose an image into a spatial-correlated variable\nand a spatial-variant variable, assigning hierarchical Bayesian priors to\nexplicitly force them to model the domain-stable shape and domain-specific\nappearance information respectively. Then, we model the segmentation as a\nlocally smooth variable only related to the shape. Finally, we develop a\nvariational Bayesian framework to infer the posterior distributions of these\nexplainable variables. The framework is implemented with neural networks, and\nthus is referred to as deep Bayesian segmentation. Quantitative and qualitative\nexperimental results on prostate segmentation and cardiac segmentation tasks\nhave shown the effectiveness of our proposed method. Moreover, we investigated\nthe interpretability of BayeSeg by explaining the posteriors and analyzed\ncertain factors that affect the generalization ability through further ablation\nstudies. Our code will be released via https://zmiclab.github.io/projects.html,\nonce the manuscript is accepted for publication.\n","authors":["Shangqi Gao","Hangqi Zhou","Yibo Gao","Xiahai Zhuang"],"pdf_url":"https://arxiv.org/pdf/2303.01710v1.pdf","comment":"Submitted to Medical Image Analysis"},{"id":"http://arxiv.org/abs/2301.09121v2","updated":"2023-03-03T04:23:55Z","published":"2023-01-22T13:10:05Z","title":"Learning Open-vocabulary Semantic Segmentation Models From Natural\n  Language Supervision","summary":"  In this paper, we consider the problem of open-vocabulary semantic\nsegmentation (OVS), which aims to segment objects of arbitrary classes instead\nof pre-defined, closed-set categories. The main contributions are as follows:\nFirst, we propose a transformer-based model for OVS, termed as OVSegmentor,\nwhich only exploits web-crawled image-text pairs for pre-training without using\nany mask annotations. OVSegmentor assembles the image pixels into a set of\nlearnable group tokens via a slot-attention based binding module, and aligns\nthe group tokens to the corresponding caption embedding. Second, we propose two\nproxy tasks for training, namely masked entity completion and cross-image mask\nconsistency. The former aims to infer all masked entities in the caption given\nthe group tokens, that enables the model to learn fine-grained alignment\nbetween visual groups and text entities. The latter enforces consistent mask\npredictions between images that contain shared entities, which encourages the\nmodel to learn visual invariance. Third, we construct CC4M dataset for\npre-training by filtering CC12M with frequently appeared entities, which\nsignificantly improves training efficiency. Fourth, we perform zero-shot\ntransfer on three benchmark datasets, PASCAL VOC 2012, PASCAL Context, and COCO\nObject. Our model achieves superior segmentation results over the\nstate-of-the-art method by using only 3\\% data (4M vs 134M) for pre-training.\nCode and pre-trained models will be released for future research.\n","authors":["Jilan Xu","Junlin Hou","Yuejie Zhang","Rui Feng","Yi Wang","Yu Qiao","Weidi Xie"],"pdf_url":"https://arxiv.org/pdf/2301.09121v2.pdf","comment":"Accepted by CVPR2023"},{"id":"http://arxiv.org/abs/2303.01707v1","updated":"2023-03-03T04:18:09Z","published":"2023-03-03T04:18:09Z","title":"Spatio-Temporal Structure Consistency for Semi-supervised Medical Image\n  Classification","summary":"  Intelligent medical diagnosis has shown remarkable progress based on the\nlarge-scale datasets with precise annotations. However, fewer labeled images\nare available due to significantly expensive cost for annotating data by\nexperts. To fully exploit the easily available unlabeled data, we propose a\nnovel Spatio-Temporal Structure Consistent (STSC) learning framework.\nSpecifically, a gram matrix is derived to combine the spatial structure\nconsistency and temporal structure consistency together. This gram matrix\ncaptures the structural similarity among the representations of different\ntraining samples. At the spatial level, our framework explicitly enforces the\nconsistency of structural similarity among different samples under\nperturbations. At the temporal level, we consider the consistency of the\nstructural similarity in different training iterations by digging out the\nstable sub-structures in a relation graph. Experiments on two medical image\ndatasets (i.e., ISIC 2018 challenge and ChestX-ray14) show that our method\noutperforms state-of-the-art SSL methods. Furthermore, extensive qualitative\nanalysis on the Gram matrices and heatmaps by Grad-CAM are presented to\nvalidate the effectiveness of our method.\n","authors":["Wentao Lei","Lei Liu","Li Liu"],"pdf_url":"https://arxiv.org/pdf/2303.01707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00944v2","updated":"2023-03-03T03:02:45Z","published":"2023-03-02T03:40:05Z","title":"Attention-based Graph Convolution Fusing Latent Structures and Multiple\n  Features for Graph Neural Networks","summary":"  We present an attention-based spatial graph convolution (AGC) for graph\nneural networks (GNNs). Existing AGCs focus on only using node-wise features\nand utilizing one type of attention function when calculating attention\nweights. Instead, we propose two methods to improve the representational power\nof AGCs by utilizing 1) structural information in a high-dimensional space and\n2) multiple attention functions when calculating their weights. The first\nmethod computes a local structure representation of a graph in a\nhigh-dimensional space. The second method utilizes multiple attention functions\nsimultaneously in one AGC. Both approaches can be combined. We also propose a\nGNN for the classification of point clouds and that for the prediction of point\nlabels in a point cloud based on the proposed AGC. According to experiments,\nthe proposed GNNs perform better than existing methods. Our codes open at\nhttps://github.com/liyang-tuat/SFAGC.\n","authors":["Yang Li","Yuichi Tanaka"],"pdf_url":"https://arxiv.org/pdf/2303.00944v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01687v1","updated":"2023-03-03T03:00:49Z","published":"2023-03-03T03:00:49Z","title":"Differentially Private Neural Tangent Kernels for Privacy-Preserving\n  Data Generation","summary":"  Maximum mean discrepancy (MMD) is a particularly useful distance metric for\ndifferentially private data generation: when used with finite-dimensional\nfeatures it allows us to summarize and privatize the data distribution once,\nwhich we can repeatedly use during generator training without further privacy\nloss. An important question in this framework is, then, what features are\nuseful to distinguish between real and synthetic data distributions, and\nwhether those enable us to generate quality synthetic data. This work considers\nthe using the features of $\\textit{neural tangent kernels (NTKs)}$, more\nprecisely $\\textit{empirical}$ NTKs (e-NTKs). We find that, perhaps\nsurprisingly, the expressiveness of the untrained e-NTK features is comparable\nto that of the features taken from pre-trained perceptual features using public\ndata. As a result, our method improves the privacy-accuracy trade-off compared\nto other state-of-the-art methods, without relying on any public data, as\ndemonstrated on several tabular and image benchmark datasets.\n","authors":["Yilin Yang","Kamil Adamczewski","Danica J. Sutherland","Xiaoxiao Li","Mijung Park"],"pdf_url":"https://arxiv.org/pdf/2303.01687v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01686v1","updated":"2023-03-03T02:59:13Z","published":"2023-03-03T02:59:13Z","title":"Towards Domain Generalization for Multi-view 3D Object Detection in\n  Bird-Eye-View","summary":"  Multi-view 3D object detection (MV3D-Det) in Bird-Eye-View (BEV) has drawn\nextensive attention due to its low cost and high efficiency. Although new\nalgorithms for camera-only 3D object detection have been continuously proposed,\nmost of them may risk drastic performance degradation when the domain of input\nimages differs from that of training. In this paper, we first analyze the\ncauses of the domain gap for the MV3D-Det task. Based on the covariate shift\nassumption, we find that the gap mainly attributes to the feature distribution\nof BEV, which is determined by the quality of both depth estimation and 2D\nimage's feature representation. To acquire a robust depth prediction, we\npropose to decouple the depth estimation from the intrinsic parameters of the\ncamera (i.e. the focal length) through converting the prediction of metric\ndepth to that of scale-invariant depth and perform dynamic perspective\naugmentation to increase the diversity of the extrinsic parameters (i.e. the\ncamera poses) by utilizing homography. Moreover, we modify the focal length\nvalues to create multiple pseudo-domains and construct an adversarial training\nloss to encourage the feature representation to be more domain-agnostic.\nWithout bells and whistles, our approach, namely DG-BEV, successfully\nalleviates the performance drop on the unseen target domain without impairing\nthe accuracy of the source domain. Extensive experiments on various public\ndatasets, including Waymo, nuScenes, and Lyft, demonstrate the generalization\nand effectiveness of our approach. To the best of our knowledge, this is the\nfirst systematic study to explore a domain generalization method for MV3D-Det.\n","authors":["Shuo Wang","Xinhai Zhao","Hai-Ming Xu","Zehui Chen","Dameng Yu","Jiahao Chang","Zhen Yang","Feng Zhao"],"pdf_url":"https://arxiv.org/pdf/2303.01686v1.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2303.01685v1","updated":"2023-03-03T02:56:44Z","published":"2023-03-03T02:56:44Z","title":"Multi-Scale Control Signal-Aware Transformer for Motion Synthesis\n  without Phase","summary":"  Synthesizing controllable motion for a character using deep learning has been\na promising approach due to its potential to learn a compact model without\nlaborious feature engineering. To produce dynamic motion from weak control\nsignals such as desired paths, existing methods often require auxiliary\ninformation such as phases for alleviating motion ambiguity, which limits their\ngeneralisation capability. As past poses often contain useful auxiliary hints,\nin this paper, we propose a task-agnostic deep learning method, namely\nMulti-scale Control Signal-aware Transformer (MCS-T), with an attention based\nencoder-decoder architecture to discover the auxiliary information implicitly\nfor synthesizing controllable motion without explicitly requiring auxiliary\ninformation such as phase. Specifically, an encoder is devised to adaptively\nformulate the motion patterns of a character's past poses with multi-scale\nskeletons, and a decoder driven by control signals to further synthesize and\npredict the character's state by paying context-specialised attention to the\nencoded past motion patterns. As a result, it helps alleviate the issues of low\nresponsiveness and slow transition which often happen in conventional methods\nnot using auxiliary information. Both qualitative and quantitative experimental\nresults on an existing biped locomotion dataset, which involves diverse types\nof motion transitions, demonstrate the effectiveness of our method. In\nparticular, MCS-T is able to successfully generate motions comparable to those\ngenerated by the methods using auxiliary information.\n","authors":["Lintao Wang","Kun Hu","Lei Bai","Yu Ding","Wanli Ouyang","Zhiyong Wang"],"pdf_url":"https://arxiv.org/pdf/2303.01685v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01681v1","updated":"2023-03-03T02:52:28Z","published":"2023-03-03T02:52:28Z","title":"Dense Pixel-to-Pixel Harmonization via Continuous Image Representation","summary":"  High-resolution (HR) image harmonization is of great significance in\nreal-world applications such as image synthesis and image editing. However, due\nto the high memory costs, existing dense pixel-to-pixel harmonization methods\nare mainly focusing on processing low-resolution (LR) images. Some recent works\nresort to combining with color-to-color transformations but are either limited\nto certain resolutions or heavily depend on hand-crafted image filters. In this\nwork, we explore leveraging the implicit neural representation (INR) and\npropose a novel image Harmonization method based on Implicit neural Networks\n(HINet), which to the best of our knowledge, is the first dense pixel-to-pixel\nmethod applicable to HR images without any hand-crafted filter design. Inspired\nby the Retinex theory, we decouple the MLPs into two parts to respectively\ncapture the content and environment of composite images. A Low-Resolution Image\nPrior (LRIP) network is designed to alleviate the Boundary Inconsistency\nproblem, and we also propose new designs for the training and inference\nprocess. Extensive experiments have demonstrated the effectiveness of our\nmethod compared with state-of-the-art methods. Furthermore, some interesting\nand practical applications of the proposed method are explored. Our code will\nbe available at https://github.com/WindVChen/INR-Harmonization.\n","authors":["Jianqi Chen","Yilan Zhang","Zhengxia Zou","Keyan Chen","Zhenwei Shi"],"pdf_url":"https://arxiv.org/pdf/2303.01681v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01678v1","updated":"2023-03-03T02:46:15Z","published":"2023-03-03T02:46:15Z","title":"Nonlinear ill-posed problem in low-dose dental cone-beam computed\n  tomography","summary":"  This paper describes the mathematical structure of the ill-posed nonlinear\ninverse problem of low-dose dental cone-beam computed tomography (CBCT) and\nexplains the advantages of a deep learning-based approach to the reconstruction\nof computed tomography images over conventional regularization methods. This\npaper explains the underlying reasons why dental CBCT is more ill-posed than\nstandard computed tomography. Despite this severe ill-posedness, the demand for\ndental CBCT systems is rapidly growing because of their cost competitiveness\nand low radiation dose. We then describe the limitations of existing methods in\nthe accurate restoration of the morphological structures of teeth using dental\nCBCT data severely damaged by metal implants. We further discuss the usefulness\nof panoramic images generated from CBCT data for accurate tooth segmentation.\nWe also discuss the possibility of utilizing radiation-free intra-oral scan\ndata as prior information in CBCT image reconstruction to compensate for the\ndamage to data caused by metal implants.\n","authors":["Hyoung Suk Park","Chang Min Hyun","Jin Keun Seo"],"pdf_url":"https://arxiv.org/pdf/2303.01678v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01669v1","updated":"2023-03-03T02:07:40Z","published":"2023-03-03T02:07:40Z","title":"Learning Common Rationale to Improve Self-Supervised Representation for\n  Fine-Grained Visual Recognition Problems","summary":"  Self-supervised learning (SSL) strategies have demonstrated remarkable\nperformance in various recognition tasks. However, both our preliminary\ninvestigation and recent studies suggest that they may be less effective in\nlearning representations for fine-grained visual recognition (FGVR) since many\nfeatures helpful for optimizing SSL objectives are not suitable for\ncharacterizing the subtle differences in FGVR. To overcome this issue, we\npropose learning an additional screening mechanism to identify discriminative\nclues commonly seen across instances and classes, dubbed as common rationales\nin this paper. Intuitively, common rationales tend to correspond to the\ndiscriminative patterns from the key parts of foreground objects. We show that\na common rationale detector can be learned by simply exploiting the GradCAM\ninduced from the SSL objective without using any pre-trained object parts or\nsaliency detectors, making it seamlessly to be integrated with the existing SSL\nprocess. Specifically, we fit the GradCAM with a branch with limited fitting\ncapacity, which allows the branch to capture the common rationales and discard\nthe less common discriminative patterns. At the test stage, the branch\ngenerates a set of spatial weights to selectively aggregate features\nrepresenting an instance. Extensive experimental results on four visual tasks\ndemonstrate that the proposed method can lead to a significant improvement in\ndifferent evaluation settings.\n","authors":["Yangyang Shu","Anton van den Hengel","Lingqiao Liu"],"pdf_url":"https://arxiv.org/pdf/2303.01669v1.pdf","comment":"To Appear at CVPR 2023"},{"id":"http://arxiv.org/abs/2302.06683v2","updated":"2023-03-03T01:34:34Z","published":"2023-02-13T20:50:34Z","title":"Enhancing Multivariate Time Series Classifiers through Self-Attention\n  and Relative Positioning Infusion","summary":"  Time Series Classification (TSC) is an important and challenging task for\nmany visual computing applications. Despite the extensive range of methods\ndeveloped for TSC, relatively few utilized Deep Neural Networks (DNNs). In this\npaper, we propose two novel attention blocks (Global Temporal Attention and\nTemporal Pseudo-Gaussian augmented Self-Attention) that can enhance deep\nlearning-based TSC approaches, even when such approaches are designed and\noptimized for a specific dataset or task. We validate this claim by evaluating\nmultiple state-of-the-art deep learning-based TSC models on the University of\nEast Anglia (UEA) benchmark, a standardized collection of 30 Multivariate Time\nSeries Classification (MTSC) datasets. We show that adding the proposed\nattention blocks improves base models' average accuracy by up to 3.6%.\nAdditionally, the proposed TPS block uses a new injection module to include the\nrelative positional information in transformers. As a standalone unit with less\ncomputational complexity, it enables TPS to perform better than most of the\nstate-of-the-art DNN-based TSC methods. The source codes for our experimental\nsetups and proposed attention blocks are made publicly available.\n","authors":["Mehryar Abbasi","Parvaneh Saeedi"],"pdf_url":"https://arxiv.org/pdf/2302.06683v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.07214v3","updated":"2023-03-03T01:18:39Z","published":"2022-11-14T09:11:14Z","title":"Robust Collaborative 3D Object Detection in Presence of Pose Errors","summary":"  Collaborative 3D object detection exploits information exchange among\nmultiple agents to enhance accuracy of object detection in presence of sensor\nimpairments such as occlusion. However, in practice, pose estimation errors due\nto imperfect localization would cause spatial message misalignment and\nsignificantly reduce the performance of collaboration. To alleviate adverse\nimpacts of pose errors, we propose CoAlign, a novel hybrid collaboration\nframework that is robust to unknown pose errors. The proposed solution relies\non a novel agent-object pose graph modeling to enhance pose consistency among\ncollaborating agents. Furthermore, we adopt a multi-scale data fusion strategy\nto aggregate intermediate features at multiple spatial resolutions. Comparing\nwith previous works, which require ground-truth pose for training supervision,\nour proposed CoAlign is more practical since it doesn't require any\nground-truth pose supervision in the training and makes no specific assumptions\non pose errors. Extensive evaluation of the proposed method is carried out on\nmultiple datasets, certifying that CoAlign significantly reduce relative\nlocalization error and achieving the state of art detection performance when\npose errors exist. Code are made available for the use of the research\ncommunity at https://github.com/yifanlu0227/CoAlign.\n","authors":["Yifan Lu","Quanhao Li","Baoan Liu","Mehrdad Dianati","Chen Feng","Siheng Chen","Yanfeng Wang"],"pdf_url":"https://arxiv.org/pdf/2211.07214v3.pdf","comment":"Accepted by ICRA2023. This version updates the final results with\n  data augmentation and correct AP calculations(sort the detections of all\n  samples by confidence)"},{"id":"http://arxiv.org/abs/2212.05845v2","updated":"2023-03-03T01:14:19Z","published":"2022-12-12T12:18:24Z","title":"CbwLoss: Constrained Bidirectional Weighted Loss for Self-supervised\n  Learning of Depth and Pose","summary":"  Photometric differences are widely used as supervision signals to train\nneural networks for estimating depth and camera pose from unlabeled monocular\nvideos. However, this approach is detrimental for model optimization because\nocclusions and moving objects in a scene violate the underlying static scenario\nassumption. In addition, pixels in textureless regions or less discriminative\npixels hinder model training. To solve these problems, in this paper, we deal\nwith moving objects and occlusions utilizing the difference of the flow fields\nand depth structure generated by affine transformation and view synthesis,\nrespectively. Secondly, we mitigate the effect of textureless regions on model\noptimization by measuring differences between features with more semantic and\ncontextual information without adding networks. In addition, although the\nbidirectionality component is used in each sub-objective function, a pair of\nimages are reasoned about only once, which helps reduce overhead. Extensive\nexperiments and visual analysis demonstrate the effectiveness of the proposed\nmethod, which outperform existing state-of-the-art self-supervised methods\nunder the same conditions and without introducing additional auxiliary\ninformation.\n","authors":["Fei Wang","Jun Cheng","Penglei Liu"],"pdf_url":"https://arxiv.org/pdf/2212.05845v2.pdf","comment":"accepted by the Transactions on Intelligent Transportation Systems on\n  February 20, 2023"},{"id":"http://arxiv.org/abs/2303.01656v1","updated":"2023-03-03T01:12:57Z","published":"2023-03-03T01:12:57Z","title":"Feature Completion Transformer for Occluded Person Re-identification","summary":"  Occluded person re-identification (Re-ID) is a challenging problem due to the\ndestruction of occluders. Most existing methods focus on visible human body\nparts through some prior information. However, when complementary occlusions\noccur, features in occluded regions can interfere with matching, which affects\nperformance severely. In this paper, different from most previous works that\ndiscard the occluded region, we propose a Feature Completion Transformer\n(FCFormer) to implicitly complement the semantic information of occluded parts\nin the feature space. Specifically, Occlusion Instance Augmentation (OIA) is\nproposed to simulates real and diverse occlusion situations on the holistic\nimage. These augmented images not only enrich the amount of occlusion samples\nin the training set, but also form pairs with the holistic images.\nSubsequently, a dual-stream architecture with a shared encoder is proposed to\nlearn paired discriminative features from pairs of inputs. Without additional\nsemantic information, an occluded-holistic feature sample-label pair can be\nautomatically created. Then, Feature Completion Decoder (FCD) is designed to\ncomplement the features of occluded regions by using learnable tokens to\naggregate possible information from self-generated occluded features. Finally,\nwe propose the Cross Hard Triplet (CHT) loss to further bridge the gap between\ncomplementing features and extracting features under the same ID. In addition,\nFeature Completion Consistency (FC$^2$) loss is introduced to help the\ngenerated completion feature distribution to be closer to the real holistic\nfeature distribution. Extensive experiments over five challenging datasets\ndemonstrate that the proposed FCFormer achieves superior performance and\noutperforms the state-of-the-art methods by significant margins on occluded\ndatasets.\n","authors":["Tao Wang","Hong Liu","Wenhao Li","Miaoju Ban","Tuanyu Guo","Yidi Li"],"pdf_url":"https://arxiv.org/pdf/2303.01656v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2301.05403v2","updated":"2023-03-03T17:33:39Z","published":"2023-01-13T06:24:33Z","title":"Knowledge Enhancement for Contrastive Multi-Behavior Recommendation","summary":"  A well-designed recommender system can accurately capture the attributes of\nusers and items, reflecting the unique preferences of individuals. Traditional\nrecommendation techniques usually focus on modeling the singular type of\nbehaviors between users and items. However, in many practical recommendation\nscenarios (e.g., social media, e-commerce), there exist multi-typed interactive\nbehaviors in user-item relationships, such as click, tag-as-favorite, and\npurchase in online shopping platforms. Thus, how to make full use of\nmulti-behavior information for recommendation is of great importance to the\nexisting system, which presents challenges in two aspects that need to be\nexplored: (1) Utilizing users' personalized preferences to capture\nmulti-behavioral dependencies; (2) Dealing with the insufficient recommendation\ncaused by sparse supervision signal for target behavior. In this work, we\npropose a Knowledge Enhancement Multi-Behavior Contrastive Learning\nRecommendation (KMCLR) framework, including two Contrastive Learning tasks and\nthree functional modules to tackle the above challenges, respectively. In\nparticular, we design the multi-behavior learning module to extract users'\npersonalized behavior information for user-embedding enhancement, and utilize\nknowledge graph in the knowledge enhancement module to derive more robust\nknowledge-aware representations for items. In addition, in the optimization\nstage, we model the coarse-grained commonalities and the fine-grained\ndifferences between multi-behavior of users to further improve the\nrecommendation effect. Extensive experiments and ablation tests on the three\nreal-world datasets indicate our KMCLR outperforms various state-of-the-art\nrecommendation methods and verify the effectiveness of our method.\n","authors":["Hongrui Xuan","Yi Liu","Bohan Li","Hongzhi Yin"],"pdf_url":"https://arxiv.org/pdf/2301.05403v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01994v1","updated":"2023-03-03T15:06:03Z","published":"2023-03-03T15:06:03Z","title":"Discovery and Recognition of Formula Concepts using Machine Learning","summary":"  Citation-based Information Retrieval (IR) methods for scientific documents\nhave proven effective for IR applications, such as Plagiarism Detection or\nLiterature Recommender Systems in academic disciplines that use many\nreferences. In science, technology, engineering, and mathematics, researchers\noften employ mathematical concepts through formula notation to refer to prior\nknowledge. Our long-term goal is to generalize citation-based IR methods and\napply this generalized method to both classical references and mathematical\nconcepts. In this paper, we suggest how mathematical formulas could be cited\nand define a Formula Concept Retrieval task with two subtasks: Formula Concept\nDiscovery (FCD) and Formula Concept Recognition (FCR). While FCD aims at the\ndefinition and exploration of a 'Formula Concept' that names bundled equivalent\nrepresentations of a formula, FCR is designed to match a given formula to a\nprior assigned unique mathematical concept identifier. We present machine\nlearning-based approaches to address the FCD and FCR tasks. We then evaluate\nthese approaches on a standardized test collection (NTCIR arXiv dataset). Our\nFCD approach yields a precision of 68% for retrieving equivalent\nrepresentations of frequent formulas and a recall of 72% for extracting the\nformula name from the surrounding text. FCD and FCR enable the citation of\nformulas within mathematical documents and facilitate semantic search and\nquestion answering as well as document similarity assessments for plagiarism\ndetection or recommender systems.\n","authors":["Philipp Scharpf","Moritz Schubotz","Howard S. Cohl","Corinna Breitinger","Bela Gipp"],"pdf_url":"https://arxiv.org/pdf/2303.01994v1.pdf","comment":"Accepted by Scientometrics (Springer) journal"},{"id":"http://arxiv.org/abs/2211.15823v2","updated":"2023-03-03T22:03:36Z","published":"2022-11-28T23:18:10Z","title":"Personalized Reward Learning with Interaction-Grounded Learning (IGL)","summary":"  In an era of countless content offerings, recommender systems alleviate\ninformation overload by providing users with personalized content suggestions.\nDue to the scarcity of explicit user feedback, modern recommender systems\ntypically optimize for the same fixed combination of implicit feedback signals\nacross all users. However, this approach disregards a growing body of work\nhighlighting that (i) implicit signals can be used by users in diverse ways,\nsignaling anything from satisfaction to active dislike, and (ii) different\nusers communicate preferences in different ways. We propose applying the recent\nInteraction Grounded Learning (IGL) paradigm to address the challenge of\nlearning representations of diverse user communication modalities. Rather than\nrequiring a fixed, human-designed reward function, IGL is able to learn\npersonalized reward functions for different users and then optimize directly\nfor the latent user satisfaction. We demonstrate the success of IGL with\nexperiments using simulations as well as with real-world production traces.\n","authors":["Jessica Maghakian","Paul Mineiro","Kishan Panaganti","Mark Rucker","Akanksha Saran","Cheng Tan"],"pdf_url":"https://arxiv.org/pdf/2211.15823v2.pdf","comment":"ICLR 2023"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2303.02141v1","updated":"2023-03-03T18:47:21Z","published":"2023-03-03T18:47:21Z","title":"Sparsity May Cry: Let Us Fail (Current) Sparse Neural Networks Together!","summary":"  Sparse Neural Networks (SNNs) have received voluminous attention\npredominantly due to growing computational and memory footprints of\nconsistently exploding parameter count in large-scale models. Similar to their\ndense counterparts, recent SNNs generalize just as well and are equipped with\nnumerous favorable benefits (e.g., low complexity, high scalability, and\nrobustness), sometimes even better than the original dense networks. As\nresearch effort is focused on developing increasingly sophisticated sparse\nalgorithms, it is startling that a comprehensive benchmark to evaluate the\neffectiveness of these algorithms has been highly overlooked. In absence of a\ncarefully crafted evaluation benchmark, most if not all, sparse algorithms are\nevaluated against fairly simple and naive tasks (eg. CIFAR, ImageNet, GLUE,\netc.), which can potentially camouflage many advantages as well unexpected\npredicaments of SNNs. In pursuit of a more general evaluation and unveiling the\ntrue potential of sparse algorithms, we introduce \"Sparsity May Cry\" Benchmark\n(SMC-Bench), a collection of carefully-curated 4 diverse tasks with 10\ndatasets, that accounts for capturing a wide range of domain-specific and\nsophisticated knowledge. Our systemic evaluation of the most representative\nsparse algorithms reveals an important obscured observation: the\nstate-of-the-art magnitude- and/or gradient-based sparse algorithms seemingly\nfail to perform on SMC-Bench when applied out-of-the-box, sometimes at\nsignificantly trivial sparsity as low as 5%. By incorporating these\nwell-thought and diverse tasks, SMC-Bench is designed to favor and encourage\nthe development of more scalable and generalizable sparse algorithms.\n","authors":["Shiwei Liu","Tianlong Chen","Zhenyu Zhang","Xuxi Chen","Tianjin Huang","Ajay Jaiswal","Zhangyang Wang"],"pdf_url":"https://arxiv.org/pdf/2303.02141v1.pdf","comment":"We open-source SMC-Bench to assist researchers in building\n  next-generation sparse algorithms that scale and generalize:\n  https://github.com/VITA-Group/SMC-Bench"},{"id":"http://arxiv.org/abs/2208.04933v3","updated":"2023-03-03T18:35:28Z","published":"2022-08-09T17:57:43Z","title":"Simplified State Space Layers for Sequence Modeling","summary":"  Models using structured state space sequence (S4) layers have achieved\nstate-of-the-art performance on long-range sequence modeling tasks. An S4 layer\ncombines linear state space models (SSMs), the HiPPO framework, and deep\nlearning to achieve high performance. We build on the design of the S4 layer\nand introduce a new state space layer, the S5 layer. Whereas an S4 layer uses\nmany independent single-input, single-output SSMs, the S5 layer uses one\nmulti-input, multi-output SSM. We establish a connection between S5 and S4, and\nuse this to develop the initialization and parameterization used by the S5\nmodel. The result is a state space layer that can leverage efficient and widely\nimplemented parallel scans, allowing S5 to match the computational efficiency\nof S4, while also achieving state-of-the-art performance on several long-range\nsequence modeling tasks. S5 averages 87.4% on the long range arena benchmark,\nand 98.5% on the most difficult Path-X task.\n","authors":["Jimmy T. H. Smith","Andrew Warrington","Scott W. Linderman"],"pdf_url":"https://arxiv.org/pdf/2208.04933v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02135v1","updated":"2023-03-03T18:29:47Z","published":"2023-03-03T18:29:47Z","title":"Eventual Discounting Temporal Logic Counterfactual Experience Replay","summary":"  Linear temporal logic (LTL) offers a simplified way of specifying tasks for\npolicy optimization that may otherwise be difficult to describe with scalar\nreward functions. However, the standard RL framework can be too myopic to find\nmaximally LTL satisfying policies. This paper makes two contributions. First,\nwe develop a new value-function based proxy, using a technique we call eventual\ndiscounting, under which one can find policies that satisfy the LTL\nspecification with highest achievable probability. Second, we develop a new\nexperience replay method for generating off-policy data from on-policy rollouts\nvia counterfactual reasoning on different ways of satisfying the LTL\nspecification. Our experiments, conducted in both discrete and continuous\nstate-action spaces, confirm the effectiveness of our counterfactual experience\nreplay approach.\n","authors":["Cameron Voloshin","Abhinav Verma","Yisong Yue"],"pdf_url":"https://arxiv.org/pdf/2303.02135v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.12633v2","updated":"2023-03-03T18:29:38Z","published":"2022-12-24T02:13:26Z","title":"Inclusive Artificial Intelligence","summary":"  Prevailing methods for assessing and comparing generative AIs incentivize\nresponses that serve a hypothetical representative individual. Evaluating\nmodels in these terms presumes homogeneous preferences across the population\nand engenders selection of agglomerative AIs, which fail to represent the\ndiverse range of interests across individuals. We propose an alternative\nevaluation method that instead prioritizes inclusive AIs, which provably retain\nthe requisite knowledge not only for subsequent response customization to\nparticular segments of the population but also for utility-maximizing\ndecisions.\n","authors":["Dilip Arumugam","Shi Dong","Benjamin Van Roy"],"pdf_url":"https://arxiv.org/pdf/2212.12633v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02131v1","updated":"2023-03-03T18:23:20Z","published":"2023-03-03T18:23:20Z","title":"Spacetime-Efficient Low-Depth Quantum State Preparation with\n  Applications","summary":"  We propose a novel deterministic method for preparing arbitrary quantum\nstates, and we show that it requires asymptotically fewer quantum resources\nthan previous methods. When our protocol is compiled into CNOT and arbitrary\nsingle-qubit gates, it prepares an $N$-dimensional state in depth $O(\\log(N))$\nand spacetime allocation (a metric that accounts for the fact that oftentimes\nsome ancilla qubits need not be active for the entire protocol) $O(N)$, which\nare both optimal and not simultaneously achieved by previous methods. When\ncompiled into the $\\{\\mathrm{H,S,T,CNOT}\\}$ gate set, it prepares an arbitrary\nstate up to error $\\epsilon$ in depth $O(\\log(N/\\epsilon))$ and spacetime\nallocation $O(N\\log(\\log(N)/\\epsilon))$, improving over\n$O(\\log(N)\\log(N/\\epsilon))$ and $O(N\\log(N/\\epsilon))$, respectively. We\nillustrate how the reduced spacetime allocation of our protocol enables rapid\npreparation of many disjoint states with only constant-factor ancilla overhead\n-- $O(N)$ ancilla qubits are reused efficiently to prepare a product state of\n$w$ $N$-dimensional states in depth $O(w + \\log(N))$ rather than $O(w\\log(N))$,\nachieving effectively constant depth per state. We highlight several\napplications where this ability would be useful, including quantum machine\nlearning, Hamiltonian simulation, and solving linear systems of equations. We\nprovide quantum circuit descriptions of our protocol along with detailed\npseudocode.\n","authors":["Kaiwen Gui","Alexander M. Dalzell","Alessandro Achille","Martin Suchara","Frederic T. Chong"],"pdf_url":"https://arxiv.org/pdf/2303.02131v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13122v3","updated":"2023-03-03T18:18:14Z","published":"2023-01-30T18:00:28Z","title":"Towards Adversarial Realism and Robust Learning for IoT Intrusion\n  Detection and Classification","summary":"  The Internet of Things (IoT) faces tremendous security challenges. Machine\nlearning models can be used to tackle the growing number of cyber-attack\nvariations targeting IoT systems, but the increasing threat posed by\nadversarial attacks restates the need for reliable defense strategies. This\nwork describes the types of constraints required for a realistic adversarial\ncyber-attack example and proposes a methodology for a trustworthy adversarial\nrobustness analysis with a realistic adversarial evasion attack vector. The\nproposed methodology was used to evaluate three supervised algorithms, Random\nForest (RF), Extreme Gradient Boosting (XGB), and Light Gradient Boosting\nMachine (LGBM), and one unsupervised algorithm, Isolation Forest (IFOR).\nConstrained adversarial examples were generated with the Adaptative\nPerturbation Pattern Method (A2PM), and evasion attacks were performed against\nmodels created with regular and adversarial training. Even though RF was the\nleast affected in binary classification, XGB consistently achieved the highest\naccuracy in multi-class classification. The obtained results evidence the\ninherent susceptibility of tree-based algorithms and ensembles to adversarial\nevasion attacks and demonstrates the benefits of adversarial training and a\nsecurity by design approach for a more robust IoT network intrusion detection\nand cyber-attack classification.\n","authors":["João Vitorino","Isabel Praça","Eva Maia"],"pdf_url":"https://arxiv.org/pdf/2301.13122v3.pdf","comment":"19 pages, 5 tables, 7 figures, Annals of Telecommunications journal"},{"id":"http://arxiv.org/abs/2303.02123v1","updated":"2023-03-03T18:08:12Z","published":"2023-03-03T18:08:12Z","title":"Skeletal Point Representations with Geometric Deep Learning","summary":"  Skeletonization has been a popular shape analysis technique that models both\nthe interior and exterior of an object. Existing template-based calculations of\nskeletal models from anatomical structures are a time-consuming manual process.\nRecently, learning-based methods have been used to extract skeletons from 3D\nshapes. In this work, we propose novel additional geometric terms for\ncalculating skeletal structures of objects. The results are similar to\ntraditional fitted s-reps but but are produced much more quickly. Evaluation on\nreal clinical data shows that the learned model predicts accurate skeletal\nrepresentations and shows the impact of proposed geometric losses along with\nusing s-reps as weak supervision.\n","authors":["Ninad Khargonkar","Beatriz Paniagua","Jared Vicory"],"pdf_url":"https://arxiv.org/pdf/2303.02123v1.pdf","comment":"5 pages, 5 figures, 2 tables. Accepted to IEEE International\n  Symposium on Biomedical Imaging (ISBI) 2023"},{"id":"http://arxiv.org/abs/2303.02118v1","updated":"2023-03-03T18:03:49Z","published":"2023-03-03T18:03:49Z","title":"Statistical-Computational Tradeoffs in Mixed Sparse Linear Regression","summary":"  We consider the problem of mixed sparse linear regression with two\ncomponents, where two real $k$-sparse signals $\\beta_1, \\beta_2$ are to be\nrecovered from $n$ unlabelled noisy linear measurements. The sparsity is\nallowed to be sublinear in the dimension, and additive noise is assumed to be\nindependent Gaussian with variance $\\sigma^2$. Prior work has shown that the\nproblem suffers from a $\\frac{k}{SNR^2}$-to-$\\frac{k^2}{SNR^2}$\nstatistical-to-computational gap, resembling other computationally challenging\nhigh-dimensional inference problems such as Sparse PCA and Robust Sparse Mean\nEstimation; here $SNR$ is the signal-to-noise ratio. We establish the existence\nof a more extensive computational barrier for this problem through the method\nof low-degree polynomials, but show that the problem is computationally hard\nonly in a very narrow symmetric parameter regime. We identify a smooth\ninformation-computation tradeoff between the sample complexity $n$ and runtime\nfor any randomized algorithm in this hard regime. Via a simple reduction, this\nprovides novel rigorous evidence for the existence of a computational barrier\nto solving exact support recovery in sparse phase retrieval with sample\ncomplexity $n = \\tilde{o}(k^2)$. Our second contribution is to analyze a simple\nthresholding algorithm which, outside of the narrow regime where the problem is\nhard, solves the associated mixed regression detection problem in $O(np)$ time\nwith square-root the number of samples and matches the sample complexity\nrequired for (non-mixed) sparse linear regression; this allows the recovery\nproblem to be subsequently solved by state-of-the-art techniques from the dense\ncase. As a special case of our results, we show that this simple algorithm is\norder-optimal among a large family of algorithms in solving exact signed\nsupport recovery in sparse linear regression.\n","authors":["Gabriel Arpino","Ramji Venkataramanan"],"pdf_url":"https://arxiv.org/pdf/2303.02118v1.pdf","comment":"60 pages"},{"id":"http://arxiv.org/abs/2303.02115v1","updated":"2023-03-03T17:57:11Z","published":"2023-03-03T17:57:11Z","title":"Nature's Cost Function: Simulating Physics by Minimizing the Action","summary":"  In physics, there is a scalar function called the action which behaves like a\ncost function. When minimized, it yields the \"path of least action\" which\nrepresents the path a physical system will take through space and time. This\nfunction is crucial in theoretical physics and is usually minimized\nanalytically to obtain equations of motion for various problems. In this paper,\nwe propose a different approach: instead of minimizing the action analytically,\nwe discretize it and then minimize it directly with gradient descent. We use\nthis approach to obtain dynamics for six different physical systems and show\nthat they are nearly identical to ground-truth dynamics. We discuss failure\nmodes such as the unconstrained energy effect and show how to address them.\nFinally, we use the discretized action to construct a simple but novel quantum\nsimulation.\n","authors":["Tim Strang","Isabella Caruso","Sam Greydanus"],"pdf_url":"https://arxiv.org/pdf/2303.02115v1.pdf","comment":"Code at: github.com/greydanus/ncf. 4 pages, 4 figures (additional\n  figures and pages in Appendix)"},{"id":"http://arxiv.org/abs/2303.02114v1","updated":"2023-03-03T17:57:04Z","published":"2023-03-03T17:57:04Z","title":"Lag selection and estimation of stable parameters for multiple\n  autoregressive processes through convex programming","summary":"  Motivated by a variety of applications, high-dimensional time series have\nbecome an active topic of research. In particular, several methods and\nfinite-sample theories for individual stable autoregressive processes with\nknown lag have become available very recently. We, instead, consider multiple\nstable autoregressive processes that share an unknown lag. We use information\nacross the different processes to simultaneously select the lag and estimate\nthe parameters. We prove that the estimated process is stable, and we establish\nrates for the forecasting error that can outmatch the known rate in our\nsetting. Our insights on the lag selection and the stability are also of\ninterest for the case of individual autoregressive processes.\n","authors":["Somnath Chakraborty","Johannes Lederer","Rainer von Sachs"],"pdf_url":"https://arxiv.org/pdf/2303.02114v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02110v1","updated":"2023-03-03T17:51:08Z","published":"2023-03-03T17:51:08Z","title":"Need for Objective Task-based Evaluation of Deep Learning-Based\n  Denoising Methods: A Study in the Context of Myocardial Perfusion SPECT","summary":"  Artificial intelligence-based methods have generated substantial interest in\nnuclear medicine. An area of significant interest has been using deep-learning\n(DL)-based approaches for denoising images acquired with lower doses, shorter\nacquisition times, or both. Objective evaluation of these approaches is\nessential for clinical application. DL-based approaches for denoising\nnuclear-medicine images have typically been evaluated using fidelity-based\nfigures of merit (FoMs) such as RMSE and SSIM. However, these images are\nacquired for clinical tasks and thus should be evaluated based on their\nperformance in these tasks. Our objectives were to (1) investigate whether\nevaluation with these FoMs is consistent with objective clinical-task-based\nevaluation; (2) provide a theoretical analysis for determining the impact of\ndenoising on signal-detection tasks; (3) demonstrate the utility of virtual\nclinical trials (VCTs) to evaluate DL-based methods. A VCT to evaluate a\nDL-based method for denoising myocardial perfusion SPECT (MPS) images was\nconducted. The impact of DL-based denoising was evaluated using fidelity-based\nFoMs and AUC, which quantified performance on detecting perfusion defects in\nMPS images as obtained using a model observer with anthropomorphic channels.\nBased on fidelity-based FoMs, denoising using the considered DL-based method\nled to significantly superior performance. However, based on ROC analysis,\ndenoising did not improve, and in fact, often degraded detection-task\nperformance. The results motivate the need for objective task-based evaluation\nof DL-based denoising approaches. Further, this study shows how VCTs provide a\nmechanism to conduct such evaluations using VCTs. Finally, our theoretical\ntreatment reveals insights into the reasons for the limited performance of the\ndenoising approach.\n","authors":["Zitong Yu","Md Ashequr Rahman","Richard Laforest","Thomas H. Schindler","Robert J. Gropler","Richard L. Wahl","Barry A. Siegel","Abhinav K. Jha"],"pdf_url":"https://arxiv.org/pdf/2303.02110v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02101v1","updated":"2023-03-03T17:35:42Z","published":"2023-03-03T17:35:42Z","title":"Configurable calorimeter simulation for AI applications","summary":"  A configurable calorimeter simulation for AI (COCOA) applications is\npresented, based on the \\textsc{Geant4} toolkit and interfaced with the\n\\textsc{Pythia} event generator. This open-source project is aimed to support\nthe development of machine learning algorithms in high energy physics that rely\non realistic particle shower descriptions, such as reconstruction, fast\nsimulation, and low-level analysis. Specifications such as the granularity and\nmaterial of its nearly hermetic geometry are user-configurable. The tool is\nsupplemented with simple event processing including topological clustering, jet\nalgorithms, and a nearest-neighbors graph construction. Formatting is also\nprovided to visualise events using the Phoenix event display software.\n","authors":["Francesco Armando Di Bello","Anton Charkin-Gorbulin","Kyle Cranmer","Etienne Dreyer","Sanmay Ganguly","Eilam Gross","Lukas Heinrich","Lorenzo Santi","Marumi Kado","Nilotpal Kakati","Patrick Rieck","Matteo Tusoni"],"pdf_url":"https://arxiv.org/pdf/2303.02101v1.pdf","comment":"9 pages, 11 figures"},{"id":"http://arxiv.org/abs/2301.05403v2","updated":"2023-03-03T17:33:39Z","published":"2023-01-13T06:24:33Z","title":"Knowledge Enhancement for Contrastive Multi-Behavior Recommendation","summary":"  A well-designed recommender system can accurately capture the attributes of\nusers and items, reflecting the unique preferences of individuals. Traditional\nrecommendation techniques usually focus on modeling the singular type of\nbehaviors between users and items. However, in many practical recommendation\nscenarios (e.g., social media, e-commerce), there exist multi-typed interactive\nbehaviors in user-item relationships, such as click, tag-as-favorite, and\npurchase in online shopping platforms. Thus, how to make full use of\nmulti-behavior information for recommendation is of great importance to the\nexisting system, which presents challenges in two aspects that need to be\nexplored: (1) Utilizing users' personalized preferences to capture\nmulti-behavioral dependencies; (2) Dealing with the insufficient recommendation\ncaused by sparse supervision signal for target behavior. In this work, we\npropose a Knowledge Enhancement Multi-Behavior Contrastive Learning\nRecommendation (KMCLR) framework, including two Contrastive Learning tasks and\nthree functional modules to tackle the above challenges, respectively. In\nparticular, we design the multi-behavior learning module to extract users'\npersonalized behavior information for user-embedding enhancement, and utilize\nknowledge graph in the knowledge enhancement module to derive more robust\nknowledge-aware representations for items. In addition, in the optimization\nstage, we model the coarse-grained commonalities and the fine-grained\ndifferences between multi-behavior of users to further improve the\nrecommendation effect. Extensive experiments and ablation tests on the three\nreal-world datasets indicate our KMCLR outperforms various state-of-the-art\nrecommendation methods and verify the effectiveness of our method.\n","authors":["Hongrui Xuan","Yi Liu","Bohan Li","Hongzhi Yin"],"pdf_url":"https://arxiv.org/pdf/2301.05403v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.07512v3","updated":"2023-03-03T17:30:31Z","published":"2022-03-14T21:42:21Z","title":"Don't fear the unlabelled: safe semi-supervised learning via simple\n  debiasing","summary":"  Semi-supervised learning (SSL) provides an effective means of leveraging\nunlabelled data to improve a model performance. Even though the domain has\nreceived a considerable amount of attention in the past years, most methods\npresent the common drawback of lacking theoretical guarantees. Our starting\npoint is to notice that the estimate of the risk that most discriminative SSL\nmethods minimise is biased, even asymptotically. This bias impedes the use of\nstandard statistical learning theory and can hurt empirical performance. We\npropose a simple way of removing the bias. Our debiasing approach is\nstraightforward to implement and applicable to most deep SSL methods. We\nprovide simple theoretical guarantees on the trustworthiness of these modified\nmethods, without having to rely on the strong assumptions on the data\ndistribution that SSL theory usually requires. In particular, we provide\ngeneralisation error bounds for the proposed methods. We evaluate debiased\nversions of different existing SSL methods, such as the Pseudo-label method and\nFixmatch, and show that debiasing can compete with classic deep SSL techniques\nin various settings by providing better calibrated models. Additionally, we\nprovide a theoretical explanation of the intuition of the popular SSL methods.\n","authors":["Hugo Schmutz","Olivier Humbert","Pierre-Alexandre Mattei"],"pdf_url":"https://arxiv.org/pdf/2203.07512v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02095v1","updated":"2023-03-03T17:24:39Z","published":"2023-03-03T17:24:39Z","title":"Data-Efficient Training of CNNs and Transformers with Coresets: A\n  Stability Perspective","summary":"  Coreset selection is among the most effective ways to reduce the training\ntime of CNNs, however, only limited is known on how the resultant models will\nbehave under variations of the coreset size, and choice of datasets and models.\nMoreover, given the recent paradigm shift towards transformer-based models, it\nis still an open question how coreset selection would impact their performance.\nThere are several similar intriguing questions that need to be answered for a\nwide acceptance of coreset selection methods, and this paper attempts to answer\nsome of these. We present a systematic benchmarking setup and perform a\nrigorous comparison of different coreset selection methods on CNNs and\ntransformers. Our investigation reveals that under certain circumstances,\nrandom selection of subsets is more robust and stable when compared with the\nSOTA selection methods. We demonstrate that the conventional concept of uniform\nsubset sampling across the various classes of the data is not the appropriate\nchoice. Rather samples should be adaptively chosen based on the complexity of\nthe data distribution for each class. Transformers are generally pretrained on\nlarge datasets, and we show that for certain target datasets, it helps to keep\ntheir performance stable at even very small coreset sizes. We further show that\nwhen no pretraining is done or when the pretrained transformer models are used\nwith non-natural images (e.g. medical data), CNNs tend to generalize better\nthan transformers at even very small coreset sizes. Lastly, we demonstrate that\nin the absence of the right pretraining, CNNs are better at learning the\nsemantic coherence between spatially distant objects within an image, and these\ntend to outperform transformers at almost all choices of the coreset size.\n","authors":["Animesh Gupta","Irtiza Hassan","Dilip K. Prasad","Deepak K. Gupta"],"pdf_url":"https://arxiv.org/pdf/2303.02095v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.16140v2","updated":"2023-03-03T17:19:40Z","published":"2022-10-28T14:10:24Z","title":"Localized Randomized Smoothing for Collective Robustness Certification","summary":"  Models for image segmentation, node classification and many other tasks map a\nsingle input to multiple labels. By perturbing this single shared input (e.g.\nthe image) an adversary can manipulate several predictions (e.g. misclassify\nseveral pixels). Collective robustness certification is the task of provably\nbounding the number of robust predictions under this threat model. The only\ndedicated method that goes beyond certifying each output independently is\nlimited to strictly local models, where each prediction is associated with a\nsmall receptive field. We propose a more general collective robustness\ncertificate for all types of models. We further show that this approach is\nbeneficial for the larger class of softly local models, where each output is\ndependent on the entire input but assigns different levels of importance to\ndifferent input regions (e.g. based on their proximity in the image). The\ncertificate is based on our novel localized randomized smoothing approach,\nwhere the random perturbation strength for different input regions is\nproportional to their importance for the outputs. Localized smoothing\nPareto-dominates existing certificates on both image segmentation and node\nclassification tasks, simultaneously offering higher accuracy and stronger\ncertificates.\n","authors":["Jan Schuchardt","Tom Wollschläger","Aleksandar Bojchevski","Stephan Günnemann"],"pdf_url":"https://arxiv.org/pdf/2210.16140v2.pdf","comment":"Accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2011.01929v4","updated":"2023-03-03T17:12:51Z","published":"2020-11-03T18:58:51Z","title":"The Complexity of Gradient Descent: CLS = PPAD $\\cap$ PLS","summary":"  We study search problems that can be solved by performing Gradient Descent on\na bounded convex polytopal domain and show that this class is equal to the\nintersection of two well-known classes: PPAD and PLS. As our main underlying\ntechnical contribution, we show that computing a Karush-Kuhn-Tucker (KKT) point\nof a continuously differentiable function over the domain $[0,1]^2$ is PPAD\n$\\cap$ PLS-complete. This is the first non-artificial problem to be shown\ncomplete for this class. Our results also imply that the class CLS (Continuous\nLocal Search) - which was defined by Daskalakis and Papadimitriou as a more\n\"natural\" counterpart to PPAD $\\cap$ PLS and contains many interesting problems\n- is itself equal to PPAD $\\cap$ PLS.\n","authors":["John Fearnley","Paul W. Goldberg","Alexandros Hollender","Rahul Savani"],"pdf_url":"https://arxiv.org/pdf/2011.01929v4.pdf","comment":"Journal version"},{"id":"http://arxiv.org/abs/2303.02075v1","updated":"2023-03-03T16:48:38Z","published":"2023-03-03T16:48:38Z","title":"Adaptive Interventions for Global Health: A Case Study of Malaria","summary":"  Malaria can be prevented, diagnosed, and treated; however, every year, there\nare more than 200 million cases and 200.000 preventable deaths. Malaria remains\na pressing public health concern in low- and middle-income countries,\nespecially in sub-Saharan Africa. We describe how by means of mobile health\napplications, machine-learning-based adaptive interventions can strengthen\nmalaria surveillance and treatment adherence, increase testing, measure\nprovider skills and quality of care, improve public health by supporting\nfront-line workers and patients (e.g., by capacity building and encouraging\nbehavioral changes, like using bed nets), reduce test stockouts in pharmacies\nand clinics and informing public health for policy intervention.\n","authors":["África Periáñez","Andrew Trister","Madhav Nekkar","Ana Fernández del Río","Pedro L. Alonso"],"pdf_url":"https://arxiv.org/pdf/2303.02075v1.pdf","comment":"Accepted for ICLR 2023 Workshop on Machine Learning and Global Health"},{"id":"http://arxiv.org/abs/2303.02073v1","updated":"2023-03-03T16:44:33Z","published":"2023-03-03T16:44:33Z","title":"How To Guide Your Learner: Imitation Learning with Active Adaptive\n  Expert Involvement","summary":"  Imitation learning aims to mimic the behavior of experts without explicit\nreward signals. Passive imitation learning methods which use static expert\ndatasets typically suffer from compounding error, low sample efficiency, and\nhigh hyper-parameter sensitivity. In contrast, active imitation learning\nmethods solicit expert interventions to address the limitations. However,\nrecent active imitation learning methods are designed based on human intuitions\nor empirical experience without theoretical guarantee. In this paper, we\npropose a novel active imitation learning framework based on a teacher-student\ninteraction model, in which the teacher's goal is to identify the best teaching\nbehavior and actively affect the student's learning process. By solving the\noptimization objective of this framework, we propose a practical\nimplementation, naming it AdapMen. Theoretical analysis shows that AdapMen can\nimprove the error bound and avoid compounding error under mild conditions.\nExperiments on the MetaDrive benchmark and Atari 2600 games validate our\ntheoretical analysis and show that our method achieves near-expert performance\nwith much less expert involvement and total sampling steps than previous\nmethods. The code is available at https://github.com/liuxhym/AdapMen.\n","authors":["Xu-Hui Liu","Feng Xu","Xinyu Zhang","Tianyuan Liu","Shengyi Jiang","Ruifeng Chen","Zongzhang Zhang","Yang Yu"],"pdf_url":"https://arxiv.org/pdf/2303.02073v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.03802v2","updated":"2023-03-03T16:36:06Z","published":"2022-10-07T20:13:50Z","title":"Conservative Bayesian Model-Based Value Expansion for Offline Policy\n  Optimization","summary":"  Offline reinforcement learning (RL) addresses the problem of learning a\nperformant policy from a fixed batch of data collected by following some\nbehavior policy. Model-based approaches are particularly appealing in the\noffline setting since they can extract more learning signals from the logged\ndataset by learning a model of the environment. However, the performance of\nexisting model-based approaches falls short of model-free counterparts, due to\nthe compounding of estimation errors in the learned model. Driven by this\nobservation, we argue that it is critical for a model-based method to\nunderstand when to trust the model and when to rely on model-free estimates,\nand how to act conservatively w.r.t. both. To this end, we derive an elegant\nand simple methodology called conservative Bayesian model-based value expansion\nfor offline policy optimization (CBOP), that trades off model-free and\nmodel-based estimates during the policy evaluation step according to their\nepistemic uncertainties, and facilitates conservatism by taking a lower bound\non the Bayesian posterior value estimate. On the standard D4RL continuous\ncontrol tasks, we find that our method significantly outperforms previous\nmodel-based approaches: e.g., MOPO by $116.4$%, MOReL by $23.2$% and COMBO by\n$23.7$%. Further, CBOP achieves state-of-the-art performance on $11$ out of\n$18$ benchmark datasets while doing on par on the remaining datasets.\n","authors":["Jihwan Jeong","Xiaoyu Wang","Michael Gimelfarb","Hyunwoo Kim","Baher Abdulhai","Scott Sanner"],"pdf_url":"https://arxiv.org/pdf/2210.03802v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.12240v4","updated":"2023-03-03T16:34:22Z","published":"2022-01-28T16:51:54Z","title":"Continuous Deep Equilibrium Models: Training Neural ODEs faster by\n  integrating them to Infinity","summary":"  Implicit models separate the definition of a layer from the description of\nits solution process. While implicit layers allow features such as depth to\nadapt to new scenarios and inputs automatically, this adaptivity makes its\ncomputational expense challenging to predict. In this manuscript, we increase\nthe \"implicitness\" of the DEQ by redefining the method in terms of an infinite\ntime neural ODE, which paradoxically decreases the training cost over a\nstandard neural ODE by 2-4x. Additionally, we address the question: is there a\nway to simultaneously achieve the robustness of implicit layers while allowing\nthe reduced computational expense of an explicit layer? To solve this, we\ndevelop Skip and Skip Reg. DEQ, an implicit-explicit (IMEX) layer that\nsimultaneously trains an explicit prediction followed by an implicit\ncorrection. We show that training this explicit predictor is free and even\ndecreases the training time by 1.11-3.19x. Together, this manuscript shows how\nbridging the dichotomy of implicit and explicit deep learning can combine the\nadvantages of both techniques.\n","authors":["Avik Pal","Alan Edelman","Christopher Rackauckas"],"pdf_url":"https://arxiv.org/pdf/2201.12240v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02063v1","updated":"2023-03-03T16:32:37Z","published":"2023-03-03T16:32:37Z","title":"Physics-Informed Deep Learning For Traffic State Estimation: A Survey\n  and the Outlook","summary":"  For its robust predictive power (compared to pure physics-based models) and\nsample-efficient training (compared to pure deep learning models),\nphysics-informed deep learning (PIDL), a paradigm hybridizing physics-based\nmodels and deep neural networks (DNN), has been booming in science and\nengineering fields. One key challenge of applying PIDL to various domains and\nproblems lies in the design of a computational graph that integrates physics\nand DNNs. In other words, how physics are encoded into DNNs and how the physics\nand data components are represented. In this paper, we provide a variety of\narchitecture designs of PIDL computational graphs and how these structures are\ncustomized to traffic state estimation (TSE), a central problem in\ntransportation engineering. When observation data, problem type, and goal vary,\nwe demonstrate potential architectures of PIDL computational graphs and compare\nthese variants using the same real-world dataset.\n","authors":["Xuan Di","Rongye Shi","Zhaobin Mo","Yongjie Fu"],"pdf_url":"https://arxiv.org/pdf/2303.02063v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02060v1","updated":"2023-03-03T16:29:12Z","published":"2023-03-03T16:29:12Z","title":"Spectral learning of Bernoulli linear dynamical systems models for\n  decision-making","summary":"  Latent linear dynamical systems with Bernoulli observations provide a\npowerful modeling framework for identifying the temporal dynamics underlying\nbinary time series data, which arise in a variety of contexts such as binary\ndecision-making and discrete stochastic processes such as binned neural spike\ntrains. Here, we develop a spectral learning method for fast, efficient fitting\nof Bernoulli latent linear dynamical system (LDS) models. Our approach extends\ntraditional subspace identification methods to the Bernoulli setting via a\ntransformation of the first and second sample moments. This results in a\nrobust, fixed-cost estimator that avoids the hazards of local optima and the\nlong computation time of iterative fitting procedures like the\nexpectation-maximization (EM) algorithm. In regimes where data is limited or\nassumptions about the statistical structure of the data are not met, we\ndemonstrate that the spectral estimate provides a good initialization for\nLaplace-EM fitting. Finally, we show that the estimator provides substantial\nbenefits to real world settings by analyzing data from mice performing a\nsensory decision-making task.\n","authors":["Iris R. Stone","Yotam Sagiv","Il Memming Park","Jonathan W. Pillow"],"pdf_url":"https://arxiv.org/pdf/2303.02060v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02048v1","updated":"2023-03-03T16:17:30Z","published":"2023-03-03T16:17:30Z","title":"Asymptotic Bayes risk of semi-supervised multitask learning on Gaussian\n  mixture","summary":"  The article considers semi-supervised multitask learning on a Gaussian\nmixture model (GMM). Using methods from statistical physics, we compute the\nasymptotic Bayes risk of each task in the regime of large datasets in high\ndimension, from which we analyze the role of task similarity in learning and\nevaluate the performance gain when tasks are learned together rather than\nseparately. In the supervised case, we derive a simple algorithm that attains\nthe Bayes optimal performance.\n","authors":["Minh-Toan Nguyen","Romain Couillet"],"pdf_url":"https://arxiv.org/pdf/2303.02048v1.pdf","comment":"AISTATS 2023"},{"id":"http://arxiv.org/abs/2303.02047v1","updated":"2023-03-03T16:16:11Z","published":"2023-03-03T16:16:11Z","title":"On the complexity of PAC learning in Hilbert spaces","summary":"  We study the problem of binary classification from the point of view of\nlearning convex polyhedra in Hilbert spaces, to which one can reduce any binary\nclassification problem. The problem of learning convex polyhedra in\nfinite-dimensional spaces is sufficiently well studied in the literature. We\ngeneralize this problem to that in a Hilbert space and propose an algorithm for\nlearning a polyhedron which correctly classifies at least $1- \\varepsilon$ of\nthe distribution, with a probability of at least $1 - \\delta,$ where\n$\\varepsilon$ and $\\delta$ are given parameters. Also, as a corollary, we\nimprove some previous bounds for polyhedral classification in\nfinite-dimensional spaces.\n","authors":["Sergei Chubanov"],"pdf_url":"https://arxiv.org/pdf/2303.02047v1.pdf","comment":"16 pages, 2 figures, to appear in the proceedings of the AAAI-2023\n  conference"},{"id":"http://arxiv.org/abs/2303.02045v1","updated":"2023-03-03T16:12:59Z","published":"2023-03-03T16:12:59Z","title":"Uncertainty Estimation by Fisher Information-based Evidential Deep\n  Learning","summary":"  Uncertainty estimation is a key factor that makes deep learning reliable in\npractical applications. Recently proposed evidential neural networks explicitly\naccount for different uncertainties by treating the network's outputs as\nevidence to parameterize the Dirichlet distribution, and achieve impressive\nperformance in uncertainty estimation. However, for high data uncertainty\nsamples but annotated with the one-hot label, the evidence-learning process for\nthose mislabeled classes is over-penalized and remains hindered. To address\nthis problem, we propose a novel method, \\textit{Fisher Information-based\nEvidential Deep Learning} ($\\mathcal{I}$-EDL). In particular, we introduce\nFisher Information Matrix (FIM) to measure the informativeness of evidence\ncarried by each sample, according to which we can dynamically reweight the\nobjective loss terms to make the network more focus on the representation\nlearning of uncertain classes. The generalization ability of our network is\nfurther improved by optimizing the PAC-Bayesian bound. As demonstrated\nempirically, our proposed method consistently outperforms traditional\nEDL-related algorithms in multiple uncertainty estimation tasks, especially in\nthe more challenging few-shot classification settings.\n","authors":["Danruo Deng","Guangyong Chen","Yang Yu","Furui Liu","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2303.02045v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.01214v2","updated":"2023-03-03T16:10:26Z","published":"2022-12-31T11:14:45Z","title":"Comparison of tree-based ensemble algorithms for merging satellite and\n  earth-observed precipitation data at the daily time scale","summary":"  Merging satellite products and ground-based measurements is often required\nfor obtaining precipitation datasets that simultaneously cover large regions\nwith high density and are more accurate than pure satellite precipitation\nproducts. Machine and statistical learning regression algorithms are regularly\nutilized in this endeavour. At the same time, tree-based ensemble algorithms\nare adopted in various fields for solving regression problems with high\naccuracy and low computational cost. Still, information on which tree-based\nensemble algorithm to select for correcting satellite precipitation products\nfor the contiguous United States (US) at the daily time scale is missing from\nthe literature. In this study, we worked towards filling this methodological\ngap by conducting an extensive comparison between three algorithms of the\ncategory of interest, specifically between random forests, gradient boosting\nmachines (gbm) and extreme gradient boosting (XGBoost). We used daily data from\nthe PERSIANN (Precipitation Estimation from Remotely Sensed Information using\nArtificial Neural Networks) and the IMERG (Integrated Multi-satellitE\nRetrievals for GPM) gridded datasets. We also used earth-observed precipitation\ndata from the Global Historical Climatology Network daily (GHCNd) database. The\nexperiments referred to the entire contiguous US and additionally included the\napplication of the linear regression algorithm for benchmarking purposes. The\nresults suggest that XGBoost is the best-performing tree-based ensemble\nalgorithm among those compared...\n","authors":["Georgia Papacharalampous","Hristos Tyralis","Anastasios Doulamis","Nikolaos Doulamis"],"pdf_url":"https://arxiv.org/pdf/2301.01214v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.07182v5","updated":"2023-03-03T16:09:32Z","published":"2022-10-13T17:03:36Z","title":"PDEBENCH: An Extensive Benchmark for Scientific Machine Learning","summary":"  Machine learning-based modeling of physical systems has experienced increased\ninterest in recent years. Despite some impressive progress, there is still a\nlack of benchmarks for Scientific ML that are easy to use but still challenging\nand representative of a wide range of problems. We introduce PDEBench, a\nbenchmark suite of time-dependent simulation tasks based on Partial\nDifferential Equations (PDEs). PDEBench comprises both code and data to\nbenchmark the performance of novel machine learning models against both\nclassical numerical simulations and machine learning baselines. Our proposed\nset of benchmark problems contribute the following unique features: (1) A much\nwider range of PDEs compared to existing benchmarks, ranging from relatively\ncommon examples to more realistic and difficult problems; (2) much larger\nready-to-use datasets compared to prior work, comprising multiple simulation\nruns across a larger number of initial and boundary conditions and PDE\nparameters; (3) more extensible source codes with user-friendly APIs for data\ngeneration and baseline results with popular machine learning models (FNO,\nU-Net, PINN, Gradient-Based Inverse Method). PDEBench allows researchers to\nextend the benchmark freely for their own purposes using a standardized API and\nto compare the performance of new models to existing baseline methods. We also\npropose new evaluation metrics with the aim to provide a more holistic\nunderstanding of learning methods in the context of Scientific ML. With those\nmetrics we identify tasks which are challenging for recent ML methods and\npropose these tasks as future challenges for the community. The code is\navailable at https://github.com/pdebench/PDEBench.\n","authors":["Makoto Takamoto","Timothy Praditia","Raphael Leiteritz","Dan MacKinlay","Francesco Alesiani","Dirk Pflüger","Mathias Niepert"],"pdf_url":"https://arxiv.org/pdf/2210.07182v5.pdf","comment":"16 pages (main body) + 34 pages (supplemental material), accepted for\n  publication in NeurIPS 2022 Track Datasets and Benchmarks"},{"id":"http://arxiv.org/abs/1909.03354v7","updated":"2023-03-03T16:04:31Z","published":"2019-09-08T00:01:37Z","title":"Deep Weakly-Supervised Learning Methods for Classification and\n  Localization in Histology Images: A Survey","summary":"  Using deep learning models to diagnose cancer from histology data presents\nseveral challenges. Cancer grading and localization of regions of interest\n(ROIs) in these images normally relies on both image- and pixel-level labels,\nthe latter requiring a costly annotation process. Deep weakly-supervised object\nlocalization (WSOL) methods provide different strategies for low-cost training\nof deep learning models. Using only image-class annotations, these methods can\nbe trained to classify an image, and yield class activation maps (CAMs) for ROI\nlocalization. This paper provides a review of state-of-art DL methods for WSOL.\nWe propose a taxonomy where these methods are divided into bottom-up and\ntop-down methods according to the information flow in models. Although the\nlatter have seen limited progress, recent bottom-up methods are currently\ndriving much progress with deep WSOL methods. Early works focused on designing\ndifferent spatial pooling functions. However, these methods reached limited\nlocalization accuracy, and unveiled a major limitation -- the under-activation\nof CAMs which leads to high false negative localization. Subsequent works aimed\nto alleviate this issue and recover complete object. Representative methods\nfrom our taxonomy are evaluated and compared in terms of classification and\nlocalization accuracy on two challenging histology datasets. Overall, the\nresults indicate poor localization performance, particularly for generic\nmethods that were initially designed to process natural images. Methods\ndesigned to address the challenges of histology data yielded good results.\nHowever, all methods suffer from high false positive/negative localization.\nFour key challenges are identified for the application of deep WSOL methods in\nhistology -- under/over activation of CAMs, sensitivity to thresholding, and\nmodel selection.\n","authors":["Jérôme Rony","Soufiane Belharbi","Jose Dolz","Ismail Ben Ayed","Luke McCaffrey","Eric Granger"],"pdf_url":"https://arxiv.org/pdf/1909.03354v7.pdf","comment":"Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA) https://melba-journal.org/2023:004"},{"id":"http://arxiv.org/abs/2302.10784v2","updated":"2023-03-03T16:01:49Z","published":"2023-01-23T08:56:11Z","title":"Utilizing Domain Knowledge: Robust Machine Learning for Building Energy\n  Prediction with Small, Inconsistent Datasets","summary":"  The demand for a huge amount of data for machine learning (ML) applications\nis currently a bottleneck in an empirically dominated field. We propose a\nmethod to combine prior knowledge with data-driven methods to significantly\nreduce their data dependency. In this study, component-based machine learning\n(CBML) as the knowledge-encoded data-driven method is examined in the context\nof energy-efficient building engineering. It encodes the abstraction of\nbuilding structural knowledge as semantic information in the model\norganization. We design a case experiment to understand the efficacy of\nknowledge-encoded ML in sparse data input (1% - 0.0125% sampling rate). The\nresult reveals its three advanced features compared with pure ML methods: 1.\nSignificant improvement in the robustness of ML to extremely small-size and\ninconsistent datasets; 2. Efficient data utilization from different entities'\nrecord collections; 3. Characteristics of accepting incomplete data with high\ninterpretability and reduced training time. All these features provide a\npromising path to alleviating the deployment bottleneck of data-intensive\nmethods and contribute to efficient real-world data usage. Moreover, four\nnecessary prerequisites are summarized in this study that ensures the target\nscenario benefits by combining prior knowledge and ML generalization.\n","authors":["Xia Chen","Manav Mahan Singh","Philipp Geyer"],"pdf_url":"https://arxiv.org/pdf/2302.10784v2.pdf","comment":"9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2301.01252v2","updated":"2023-03-03T16:01:28Z","published":"2022-12-17T09:39:39Z","title":"Comparison of machine learning algorithms for merging gridded satellite\n  and earth-observed precipitation data","summary":"  Gridded satellite precipitation datasets are useful in hydrological\napplications as they cover large regions with high density. However, they are\nnot accurate in the sense that they do not agree with ground-based\nmeasurements. An established means for improving their accuracy is to correct\nthem by adopting machine learning algorithms. This correction takes the form of\na regression problem, in which the ground-based measurements have the role of\nthe dependent variable and the satellite data are the predictor variables,\ntogether with topography factors (e.g., elevation). Most studies of this kind\ninvolve a limited number of machine learning algorithms, and are conducted for\na small region and for a limited time period. Thus, the results obtained\nthrough them are of local importance and do not provide more general guidance\nand best practices. To provide results that are generalizable and to contribute\nto the delivery of best practices, we here compare eight state-of-the-art\nmachine learning algorithms in correcting satellite precipitation data for the\nentire contiguous United States and for a 15-year period. We use monthly data\nfrom the PERSIANN (Precipitation Estimation from Remotely Sensed Information\nusing Artificial Neural Networks) gridded dataset, together with monthly\nearth-observed precipitation data from the Global Historical Climatology\nNetwork monthly database, version 2 (GHCNm). The results suggest that extreme\ngradient boosting (XGBoost) and random forests are the most accurate in terms\nof the squared error scoring function. The remaining algorithms can be ordered\nas follows from the best to the worst: Bayesian regularized feed-forward neural\nnetworks, multivariate adaptive polynomial splines (poly-MARS), gradient\nboosting machines (gbm), multivariate adaptive regression splines (MARS),\nfeed-forward neural networks, linear regression.\n","authors":["Georgia Papacharalampous","Hristos Tyralis","Anastasios Doulamis","Nikolaos Doulamis"],"pdf_url":"https://arxiv.org/pdf/2301.01252v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.01525v2","updated":"2023-03-03T16:00:35Z","published":"2022-10-04T11:06:38Z","title":"Handling Sparse Rewards in Reinforcement Learning Using Model Predictive\n  Control","summary":"  Reinforcement learning (RL) has recently proven great success in various\ndomains. Yet, the design of the reward function requires detailed domain\nexpertise and tedious fine-tuning to ensure that agents are able to learn the\ndesired behaviour. Using a sparse reward conveniently mitigates these\nchallenges. However, the sparse reward represents a challenge on its own, often\nresulting in unsuccessful training of the agent. In this paper, we therefore\naddress the sparse reward problem in RL. Our goal is to find an effective\nalternative to reward shaping, without using costly human demonstrations, that\nwould also be applicable to a wide range of domains. Hence, we propose to use\nmodel predictive control~(MPC) as an experience source for training RL agents\nin sparse reward environments. Without the need for reward shaping, we\nsuccessfully apply our approach in the field of mobile robot navigation both in\nsimulation and real-world experiments with a Kuboki Turtlebot 2. We furthermore\ndemonstrate great improvement over pure RL algorithms in terms of success rate\nas well as number of collisions and timeouts. Our experiments show that MPC as\nan experience source improves the agent's learning process for a given task in\nthe case of sparse rewards.\n","authors":["Murad Dawood","Nils Dengler","Jorge de Heuvel","Maren Bennewitz"],"pdf_url":"https://arxiv.org/pdf/2210.01525v2.pdf","comment":"Accepted for ICRA2023"},{"id":"http://arxiv.org/abs/2210.02083v2","updated":"2023-03-03T15:58:47Z","published":"2022-10-05T08:23:05Z","title":"Multi-View Independent Component Analysis with Shared and Individual\n  Sources","summary":"  Independent component analysis (ICA) is a blind source separation method for\nlinear disentanglement of independent latent sources from observed data. We\ninvestigate the special setting of noisy linear ICA where the observations are\nsplit among different views, each receiving a mixture of shared and individual\nsources. We prove that the corresponding linear structure is identifiable, and\nthe source distribution can be recovered. To computationally estimate the\nsources, we optimize a constrained form of the joint log-likelihood of the\nobserved data among all views. We also show empirically that our objective\nrecovers the sources also in the case when the measurements are corrupted by\nnoise. Furthermore, we propose a model selection procedure for recovering the\nnumber of shared sources which we verify empirically. Finally, we apply the\nproposed model in a challenging real-life application, where the estimated\nshared sources from two large transcriptome datasets (observed data) provided\nby two different labs (two different views) lead to recovering (shared) sources\nutilized for finding a plausible representation of the underlying graph\nstructure.\n","authors":["Teodora Pandeva","Patrick Forré"],"pdf_url":"https://arxiv.org/pdf/2210.02083v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02034v1","updated":"2023-03-03T15:52:06Z","published":"2023-03-03T15:52:06Z","title":"Linear CNNs Discover the Statistical Structure of the Dataset Using Only\n  the Most Dominant Frequencies","summary":"  Our theoretical understanding of the inner workings of general convolutional\nneural networks (CNN) is limited. We here present a new stepping stone towards\nsuch understanding in the form of a theory of learning in linear CNNs. By\nanalyzing the gradient descent equations, we discover that using convolutions\nleads to a mismatch between the dataset structure and the network structure. We\nshow that linear CNNs discover the statistical structure of the dataset with\nnon-linear, stage-like transitions, and that the speed of discovery changes\ndepending on this structural mismatch. Moreover, we find that the mismatch lies\nat the heart of what we call the 'dominant frequency bias', where linear CNNs\narrive at these discoveries using only the dominant frequencies of the\ndifferent structural parts present in the dataset. Our findings can help\nexplain several characteristics of general CNNs, such as their shortcut\nlearning and their tendency to rely on texture instead of shape.\n","authors":["Hannah Pinson","Joeri Lenaerts","Vincent Ginis"],"pdf_url":"https://arxiv.org/pdf/2303.02034v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02033v1","updated":"2023-03-03T15:52:01Z","published":"2023-03-03T15:52:01Z","title":"Single-photon Image Super-resolution via Self-supervised Learning","summary":"  Single-Photon Image Super-Resolution (SPISR) aims to recover a\nhigh-resolution volumetric photon counting cube from a noisy low-resolution one\nby computational imaging algorithms. In real-world scenarios, pairs of training\nsamples are often expensive or impossible to obtain. By extending Equivariant\nImaging (EI) to volumetric single-photon data, we propose a self-supervised\nlearning framework for the SPISR task. Particularly, using the Poisson unbiased\nKullback-Leibler risk estimator and equivariance, our method is able to learn\nfrom noisy measurements without ground truths. Comprehensive experiments on\nsimulated and real-world dataset demonstrate that the proposed method achieves\ncomparable performance with supervised learning and outperforms\ninterpolation-based methods.\n","authors":["Yiwei Chen","Chen Jiang","Yu Pan"],"pdf_url":"https://arxiv.org/pdf/2303.02033v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2112.02731v4","updated":"2023-03-03T15:44:10Z","published":"2021-12-06T01:44:08Z","title":"Detecting DeFi Securities Violations from Token Smart Contract Code","summary":"  Decentralized Finance (DeFi) is a system of financial products and services\nbuilt and delivered through smart contracts on various blockchains. In the past\nyear, DeFi has gained popularity and market capitalization. However, it has\nalso been connected to crime, in particular, various types of securities\nviolations. The lack of Know Your Customer requirements in DeFi poses\nchallenges to governments trying to mitigate potential offending in this space.\nThis study aims to uncover whether this problem is suited to a machine learning\napproach, namely, whether we can identify DeFi projects potentially engaging in\nsecurities violations based on their tokens' smart contract code. We adapt\nprior work on detecting specific types of securities violations across\nEthereum, building classifiers based on features extracted from DeFi projects'\ntokens' smart contract code. The final logistic regression model achieves a\n98.9% F-1 score; the final random forest classifier achieves a 98.6% F1-score.\nFrom further feature-level analysis, we find a single feature makes this a\nhighly detectable problem. The high reliance on a single feature means that, at\nthis stage, a complex machine learning model may not be necessary or desirable\nfor this problem. However, this may change as DeFi securities violations become\nmore sophisticated. Another contribution of our study is a new dataset,\ncomprised of (a) a verified ground truth dataset for tokens involved in\nsecurities violations and (b) a set of legitimate tokens from a reputable DeFi\naggregator. This paper further discusses the potential use of a model like ours\nby prosecutors in enforcement efforts and connects it to the wider legal\ncontext.\n","authors":["Arianna Trozze","Bennett Kleinberg","Toby Davies"],"pdf_url":"https://arxiv.org/pdf/2112.02731v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02023v1","updated":"2023-03-03T15:43:14Z","published":"2023-03-03T15:43:14Z","title":"Graph-level representations using ensemble-based readout functions","summary":"  Graph machine learning models have been successfully deployed in a variety of\napplication areas. One of the most prominent types of models - Graph Neural\nNetworks (GNNs) - provides an elegant way of extracting expressive node-level\nrepresentation vectors, which can be used to solve node-related problems, such\nas classifying users in a social network. However, many tasks require\nrepresentations at the level of the whole graph, e.g., molecular applications.\nIn order to convert node-level representations into a graph-level vector, a\nso-called readout function must be applied. In this work, we study existing\nreadout methods, including simple non-trainable ones, as well as complex,\nparametrized models. We introduce a concept of ensemble-based readout functions\nthat combine either representations or predictions. Our experiments show that\nsuch ensembles allow for better performance than simple single readouts or\nsimilar performance as the complex, parametrized ones, but at a fraction of the\nmodel complexity.\n","authors":["Jakub Binkowski","Albert Sawczyn","Denis Janiak","Piotr Bielak","Tomasz Kajdanowicz"],"pdf_url":"https://arxiv.org/pdf/2303.02023v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2006.16867v2","updated":"2023-03-03T15:36:34Z","published":"2020-06-30T14:56:05Z","title":"Boosting Deep Neural Networks with Geometrical Prior Knowledge: A Survey","summary":"  Deep Neural Networks achieve state-of-the-art results in many different\nproblem settings by exploiting vast amounts of training data. However,\ncollecting, storing and - in the case of supervised learning - labelling the\ndata is expensive and time-consuming. Additionally, assessing the networks'\ngeneralization abilities or predicting how the inferred output changes under\ninput transformations is complicated since the networks are usually treated as\na black box. Both of these problems can be mitigated by incorporating prior\nknowledge into the neural network. One promising approach, inspired by the\nsuccess of convolutional neural networks in computer vision tasks, is to\nincorporate knowledge about symmetric geometrical transformations of the\nproblem to solve that affect the output in a predictable way. This promises an\nincreased data efficiency and more interpretable network outputs. In this\nsurvey, we try to give a concise overview about different approaches that\nincorporate geometrical prior knowledge into neural networks. Additionally, we\nconnect those methods to 3D object detection for autonomous driving, where we\nexpect promising results when applying those methods.\n","authors":["Matthias Rath","Alexandru Paul Condurache"],"pdf_url":"https://arxiv.org/pdf/2006.16867v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02014v1","updated":"2023-03-03T15:29:19Z","published":"2023-03-03T15:29:19Z","title":"Summary Statistic Privacy in Data Sharing","summary":"  Data sharing between different parties has become increasingly common across\nindustry and academia. An important class of privacy concerns that arises in\ndata sharing scenarios regards the underlying distribution of data. For\nexample, the total traffic volume of data from a networking company can reveal\nthe scale of its business, which may be considered a trade secret.\nUnfortunately, existing privacy frameworks (e.g., differential privacy,\nanonymization) do not adequately address such concerns. In this paper, we\npropose summary statistic privacy, a framework for analyzing and protecting\nthese summary statistic privacy concerns. We propose a class of quantization\nmechanisms that can be tailored to various data distributions and statistical\nsecrets, and analyze their privacy-distortion trade-offs under our framework.\nWe prove corresponding lower bounds on the privacy-utility tradeoff, which\nmatch the tradeoffs of the quantization mechanism under certain regimes, up to\nsmall constant factors. Finally, we demonstrate that the proposed quantization\nmechanisms achieve better privacy-distortion tradeoffs than alternative privacy\nmechanisms on real-world datasets.\n","authors":["Zinan Lin","Shuaiqi Wang","Vyas Sekar","Giulia Fanti"],"pdf_url":"https://arxiv.org/pdf/2303.02014v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02011v1","updated":"2023-03-03T15:27:16Z","published":"2023-03-03T15:27:16Z","title":"Diagnosing Model Performance Under Distribution Shift","summary":"  Prediction models can perform poorly when deployed to target distributions\ndifferent from the training distribution. To understand these operational\nfailure modes, we develop a method, called DIstribution Shift DEcomposition\n(DISDE), to attribute a drop in performance to different types of distribution\nshifts. Our approach decomposes the performance drop into terms for 1) an\nincrease in harder but frequently seen examples from training, 2) changes in\nthe relationship between features and outcomes, and 3) poor performance on\nexamples infrequent or unseen during training. These terms are defined by\nfixing a distribution on $X$ while varying the conditional distribution of $Y\n\\mid X$ between training and target, or by fixing the conditional distribution\nof $Y \\mid X$ while varying the distribution on $X$. In order to do this, we\ndefine a hypothetical distribution on $X$ consisting of values common in both\ntraining and target, over which it is easy to compare $Y \\mid X$ and thus\npredictive performance. We estimate performance on this hypothetical\ndistribution via reweighting methods. Empirically, we show how our method can\n1) inform potential modeling improvements across distribution shifts for\nemployment prediction on tabular census data, and 2) help to explain why\ncertain domain adaptation methods fail to improve model performance for\nsatellite image classification.\n","authors":[" Tiffany"," Cai","Hongseok Namkoong","Steve Yadlowsky"],"pdf_url":"https://arxiv.org/pdf/2303.02011v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.13475v2","updated":"2023-03-03T15:11:15Z","published":"2022-06-27T17:36:50Z","title":"Thermodynamics of Interpretation","summary":"  Over the past few years, different types of data-driven Artificial\nIntelligence (AI) techniques have been widely adopted in various domains of\nscience for generating predictive models. However, because of their black-box\nnature, it is crucial to establish trust in these models before accepting them\nas accurate. One way of achieving this goal is through the implementation of a\npost-hoc interpretation scheme that can put forward the reasons behind a\nblack-box model's prediction. In this work, we propose a classical\nthermodynamics inspired approach for this purpose: Thermodynamically\nExplainable Representations of AI and other black-box Paradigms (TERP). TERP\nworks by constructing a linear, local surrogate model that approximates the\nbehaviour of the black-box model within a small neighborhood around the\ninstance being explained. By employing a simple forward feature selection\nalgorithm, TERP assigns an interpretability score to all the possible surrogate\nmodels. Compared to existing methods, TERP improves interpretability by\nselecting an optimal interpretation from these models by drawing simple\nparallels with classical thermodynamics. To validate TERP as a generally\napplicable method, we successfully demonstrate how it can be used to obtain\ninterpretations of a wide range of black-box model architectures including deep\nlearning Autoencoders, Recurrent neural networks and Convolutional neural\nnetworks applied to different domains including molecular simulations, image,\nand text classification respectively.\n","authors":["Shams Mehdi","Pratyush Tiwary"],"pdf_url":"https://arxiv.org/pdf/2206.13475v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.15419v3","updated":"2023-03-03T15:10:57Z","published":"2022-05-30T20:33:46Z","title":"Fool SHAP with Stealthily Biased Sampling","summary":"  SHAP explanations aim at identifying which features contribute the most to\nthe difference in model prediction at a specific input versus a background\ndistribution. Recent studies have shown that they can be manipulated by\nmalicious adversaries to produce arbitrary desired explanations. However,\nexisting attacks focus solely on altering the black-box model itself. In this\npaper, we propose a complementary family of attacks that leave the model intact\nand manipulate SHAP explanations using stealthily biased sampling of the data\npoints used to approximate expectations w.r.t the background distribution. In\nthe context of fairness audit, we show that our attack can reduce the\nimportance of a sensitive feature when explaining the difference in outcomes\nbetween groups while remaining undetected. More precisely, experiments\nperformed on real-world datasets showed that our attack could yield up to a\n90\\% relative decrease in amplitude of the sensitive feature attribution. These\nresults highlight the manipulability of SHAP explanations and encourage\nauditors to treat them with skepticism.\n","authors":["Gabriel Laberge","Ulrich Aïvodji","Satoshi Hara","Mario Marchand.","Foutse Khomh"],"pdf_url":"https://arxiv.org/pdf/2205.15419v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01994v1","updated":"2023-03-03T15:06:03Z","published":"2023-03-03T15:06:03Z","title":"Discovery and Recognition of Formula Concepts using Machine Learning","summary":"  Citation-based Information Retrieval (IR) methods for scientific documents\nhave proven effective for IR applications, such as Plagiarism Detection or\nLiterature Recommender Systems in academic disciplines that use many\nreferences. In science, technology, engineering, and mathematics, researchers\noften employ mathematical concepts through formula notation to refer to prior\nknowledge. Our long-term goal is to generalize citation-based IR methods and\napply this generalized method to both classical references and mathematical\nconcepts. In this paper, we suggest how mathematical formulas could be cited\nand define a Formula Concept Retrieval task with two subtasks: Formula Concept\nDiscovery (FCD) and Formula Concept Recognition (FCR). While FCD aims at the\ndefinition and exploration of a 'Formula Concept' that names bundled equivalent\nrepresentations of a formula, FCR is designed to match a given formula to a\nprior assigned unique mathematical concept identifier. We present machine\nlearning-based approaches to address the FCD and FCR tasks. We then evaluate\nthese approaches on a standardized test collection (NTCIR arXiv dataset). Our\nFCD approach yields a precision of 68% for retrieving equivalent\nrepresentations of frequent formulas and a recall of 72% for extracting the\nformula name from the surrounding text. FCD and FCR enable the citation of\nformulas within mathematical documents and facilitate semantic search and\nquestion answering as well as document similarity assessments for plagiarism\ndetection or recommender systems.\n","authors":["Philipp Scharpf","Moritz Schubotz","Howard S. Cohl","Corinna Breitinger","Bela Gipp"],"pdf_url":"https://arxiv.org/pdf/2303.01994v1.pdf","comment":"Accepted by Scientometrics (Springer) journal"},{"id":"http://arxiv.org/abs/2206.02607v3","updated":"2023-03-03T15:03:34Z","published":"2022-06-06T13:27:21Z","title":"CROM: Continuous Reduced-Order Modeling of PDEs Using Implicit Neural\n  Representations","summary":"  The long runtime of high-fidelity partial differential equation (PDE) solvers\nmakes them unsuitable for time-critical applications. We propose to accelerate\nPDE solvers using reduced-order modeling (ROM). Whereas prior ROM approaches\nreduce the dimensionality of discretized vector fields, our continuous\nreduced-order modeling (CROM) approach builds a low-dimensional embedding of\nthe continuous vector fields themselves, not their discretization. We represent\nthis reduced manifold using continuously differentiable neural fields, which\nmay train on any and all available numerical solutions of the continuous\nsystem, even when they are obtained using diverse methods or discretizations.\nWe validate our approach on an extensive range of PDEs with training data from\nvoxel grids, meshes, and point clouds. Compared to prior\ndiscretization-dependent ROM methods, such as linear subspace proper orthogonal\ndecomposition (POD) and nonlinear manifold neural-network-based autoencoders,\nCROM features higher accuracy, lower memory consumption, dynamically adaptive\nresolutions, and applicability to any discretization. For equal latent space\ndimension, CROM exhibits 79$\\times$ and 49$\\times$ better accuracy, and\n39$\\times$ and 132$\\times$ smaller memory footprint, than POD and autoencoder\nmethods, respectively. Experiments demonstrate 109$\\times$ and 89$\\times$\nwall-clock speedups over unreduced models on CPUs and GPUs, respectively.\nVideos and codes are available on the project page: https://crom-pde.github.io\n","authors":["Peter Yichen Chen","Jinxu Xiang","Dong Heon Cho","Yue Chang","G A Pershing","Henrique Teles Maia","Maurizio M. Chiaramonte","Kevin Carlberg","Eitan Grinspun"],"pdf_url":"https://arxiv.org/pdf/2206.02607v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01986v1","updated":"2023-03-03T14:55:44Z","published":"2023-03-03T14:55:44Z","title":"Towards Democratizing Joint-Embedding Self-Supervised Learning","summary":"  Joint Embedding Self-Supervised Learning (JE-SSL) has seen rapid developments\nin recent years, due to its promise to effectively leverage large unlabeled\ndata. The development of JE-SSL methods was driven primarily by the search for\never increasing downstream classification accuracies, using huge computational\nresources, and typically built upon insights and intuitions inherited from a\nclose parent JE-SSL method. This has led unwittingly to numerous pre-conceived\nideas that carried over across methods e.g. that SimCLR requires very large\nmini batches to yield competitive accuracies; that strong and computationally\nslow data augmentations are required. In this work, we debunk several such\nill-formed a priori ideas in the hope to unleash the full potential of JE-SSL\nfree of unnecessary limitations. In fact, when carefully evaluating\nperformances across different downstream tasks and properly optimizing\nhyper-parameters of the methods, we most often -- if not always -- see that\nthese widespread misconceptions do not hold. For example we show that it is\npossible to train SimCLR to learn useful representations, while using a single\nimage patch as negative example, and simple Gaussian noise as the only data\naugmentation for the positive pair. Along these lines, in the hope to\ndemocratize JE-SSL and to allow researchers to easily make more extensive\nevaluations of their methods, we introduce an optimized PyTorch library for\nSSL.\n","authors":["Florian Bordes","Randall Balestriero","Pascal Vincent"],"pdf_url":"https://arxiv.org/pdf/2303.01986v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.04994v2","updated":"2023-03-03T14:40:23Z","published":"2022-10-10T19:59:40Z","title":"Sampling-based inference for large linear models, with application to\n  linearised Laplace","summary":"  Large-scale linear models are ubiquitous throughout machine learning, with\ncontemporary application as surrogate models for neural network uncertainty\nquantification; that is, the linearised Laplace method. Alas, the computational\ncost associated with Bayesian linear models constrains this method's\napplication to small networks, small output spaces and small datasets. We\naddress this limitation by introducing a scalable sample-based Bayesian\ninference method for conjugate Gaussian multi-output linear models, together\nwith a matching method for hyperparameter (regularisation) selection.\nFurthermore, we use a classic feature normalisation method (the g-prior) to\nresolve a previously highlighted pathology of the linearised Laplace method.\nTogether, these contributions allow us to perform linearised neural network\ninference with ResNet-18 on CIFAR100 (11M parameters, 100 output dimensions x\n50k datapoints) and with a U-Net on a high-resolution tomographic\nreconstruction task (2M parameters, 251k output dimensions).\n","authors":["Javier Antorán","Shreyas Padhy","Riccardo Barbano","Eric Nalisnick","David Janz","José Miguel Hernández-Lobato"],"pdf_url":"https://arxiv.org/pdf/2210.04994v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01960v1","updated":"2023-03-03T14:34:25Z","published":"2023-03-03T14:34:25Z","title":"Intelligent O-RAN Traffic Steering for URLLC Through Deep Reinforcement\n  Learning","summary":"  The goal of Next-Generation Networks is to improve upon the current\nnetworking paradigm, especially in providing higher data rates, near-real-time\nlatencies, and near-perfect quality of service. However, existing radio access\nnetwork (RAN) architectures lack sufficient flexibility and intelligence to\nmeet those demands. Open RAN (O-RAN) is a promising paradigm for building a\nvirtualized and intelligent RAN architecture. This paper presents a Machine\nLearning (ML)-based Traffic Steering (TS) scheme to predict network congestion\nand then proactively steer O-RAN traffic to avoid it and reduce the expected\nqueuing delay. To achieve this, we propose an optimized setup focusing on\nsafeguarding both latency and reliability to serve URLLC applications. The\nproposed solution consists of a two-tiered ML strategy based on Naive Bayes\nClassifier and deep Q-learning. Our solution is evaluated against traditional\nreactive TS approaches that are offered as xApps in O-RAN and shows an average\nof 15.81 percent decrease in queuing delay across all deployed SFCs.\n","authors":["Ibrahim Tamim","Sam Aleyadeh","Abdallah Shami"],"pdf_url":"https://arxiv.org/pdf/2303.01960v1.pdf","comment":"7 pages, 5 figures, accepted for publication in IEEE International\n  Conference on Communications 2023"},{"id":"http://arxiv.org/abs/2301.09507v3","updated":"2023-03-03T14:30:23Z","published":"2023-01-23T16:01:26Z","title":"Characterizing Polarization in Social Networks using the Signed\n  Relational Latent Distance Model","summary":"  Graph representation learning has become a prominent tool for the\ncharacterization and understanding of the structure of networks in general and\nsocial networks in particular. Typically, these representation learning\napproaches embed the networks into a low-dimensional space in which the role of\neach individual can be characterized in terms of their latent position. A major\ncurrent concern in social networks is the emergence of polarization and filter\nbubbles promoting a mindset of \"us-versus-them\" that may be defined by extreme\npositions believed to ultimately lead to political violence and the erosion of\ndemocracy. Such polarized networks are typically characterized in terms of\nsigned links reflecting likes and dislikes. We propose the latent Signed\nrelational Latent dIstance Model (SLIM) utilizing for the first time the\nSkellam distribution as a likelihood function for signed networks and extend\nthe modeling to the characterization of distinct extreme positions by\nconstraining the embedding space to polytopes. On four real social signed\nnetworks of polarization, we demonstrate that the model extracts\nlow-dimensional characterizations that well predict friendships and animosity\nwhile providing interpretable visualizations defined by extreme positions when\nendowing the model with an embedding space restricted to polytopes.\n","authors":["Nikolaos Nakis","Abdulkadir Çelikkanat","Louis Boucherie","Christian Djurhuus","Felix Burmester","Daniel Mathias Holmelund","Monika Frolcová","Morten Mørup"],"pdf_url":"https://arxiv.org/pdf/2301.09507v3.pdf","comment":"CAMERA READY version - Proceedings of the 26th International\n  Conference on Artificial Intelligence and Statistics (AISTATS) 2023,\n  Valencia, Spain. PMLR: Volume 206. Copyright 2023 by the author(s)"},{"id":"http://arxiv.org/abs/2303.01954v1","updated":"2023-03-03T14:28:45Z","published":"2023-03-03T14:28:45Z","title":"Synthetic Data Generator for Adaptive Interventions in Global Health","summary":"  Artificial Intelligence and digital health have the potential to transform\nglobal health. However, having access to representative data to test and\nvalidate algorithms in realistic production environments is essential. We\nintroduce HealthSyn, an open-source synthetic data generator of user behavior\nfor testing reinforcement learning algorithms in the context of mobile health\ninterventions. The generator utilizes Markov processes to generate diverse user\nactions, with individual user behavioral patterns that can change in reaction\nto personalized interventions (i.e., reminders, recommendations, and\nincentives). These actions are translated into actual logs using an ML-purposed\ndata schema specific to the mobile health application functionality included\nwith HealthKit, and open-source SDK. The logs can be fed to pipelines to obtain\nuser metrics. The generated data, which is based on real-world behaviors and\nsimulation techniques, can be used to develop, test, and evaluate, both ML\nalgorithms in research and end-to-end operational RL-based intervention\ndelivery frameworks.\n","authors":["Aditya Rastogi","Juan Francisco Garamendi","Ana Fernández del Río","Anna Guitart","Moiz Hassan Khan","Dexian Tang","África Periáñez"],"pdf_url":"https://arxiv.org/pdf/2303.01954v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.10677v2","updated":"2023-03-03T14:18:34Z","published":"2023-01-25T16:31:05Z","title":"Imitating Human Behaviour with Diffusion Models","summary":"  Diffusion models have emerged as powerful generative models in the\ntext-to-image domain. This paper studies their application as\nobservation-to-action models for imitating human behaviour in sequential\nenvironments. Human behaviour is stochastic and multimodal, with structured\ncorrelations between action dimensions. Meanwhile, standard modelling choices\nin behaviour cloning are limited in their expressiveness and may introduce bias\ninto the cloned policy. We begin by pointing out the limitations of these\nchoices. We then propose that diffusion models are an excellent fit for\nimitating human behaviour, since they learn an expressive distribution over the\njoint action space. We introduce several innovations to make diffusion models\nsuitable for sequential environments; designing suitable architectures,\ninvestigating the role of guidance, and developing reliable sampling\nstrategies. Experimentally, diffusion models closely match human demonstrations\nin a simulated robotic control task and a modern 3D gaming environment.\n","authors":["Tim Pearce","Tabish Rashid","Anssi Kanervisto","Dave Bignell","Mingfei Sun","Raluca Georgescu","Sergio Valcarcel Macua","Shan Zheng Tan","Ida Momennejad","Katja Hofmann","Sam Devlin"],"pdf_url":"https://arxiv.org/pdf/2301.10677v2.pdf","comment":"Published in ICLR 2023"},{"id":"http://arxiv.org/abs/2203.04571v2","updated":"2023-03-03T14:09:50Z","published":"2022-03-09T08:29:21Z","title":"A Neuro-vector-symbolic Architecture for Solving Raven's Progressive\n  Matrices","summary":"  Neither deep neural networks nor symbolic AI alone has approached the kind of\nintelligence expressed in humans. This is mainly because neural networks are\nnot able to decompose joint representations to obtain distinct objects (the\nso-called binding problem), while symbolic AI suffers from exhaustive rule\nsearches, among other problems. These two problems are still pronounced in\nneuro-symbolic AI which aims to combine the best of the two paradigms. Here, we\nshow that the two problems can be addressed with our proposed\nneuro-vector-symbolic architecture (NVSA) by exploiting its powerful operators\non high-dimensional distributed representations that serve as a common language\nbetween neural networks and symbolic AI. The efficacy of NVSA is demonstrated\nby solving the Raven's progressive matrices datasets. Compared to\nstate-of-the-art deep neural network and neuro-symbolic approaches, end-to-end\ntraining of NVSA achieves a new record of 87.7% average accuracy in RAVEN, and\n88.1% in I-RAVEN datasets. Moreover, compared to the symbolic reasoning within\nthe neuro-symbolic approaches, the probabilistic reasoning of NVSA with less\nexpensive operations on the distributed representations is two orders of\nmagnitude faster. Our code is available at\nhttps://github.com/IBM/neuro-vector-symbolic-architectures.\n","authors":["Michael Hersche","Mustafa Zeqiri","Luca Benini","Abu Sebastian","Abbas Rahimi"],"pdf_url":"https://arxiv.org/pdf/2203.04571v2.pdf","comment":"Updated version with additional NVSA end-to-end training,\n  generalization experiments, and PGM experiments"},{"id":"http://arxiv.org/abs/2301.09255v2","updated":"2023-03-03T14:09:15Z","published":"2023-01-23T03:41:02Z","title":"Combined Use of Federated Learning and Image Encryption for\n  Privacy-Preserving Image Classification with Vision Transformer","summary":"  In recent years, privacy-preserving methods for deep learning have become an\nurgent problem. Accordingly, we propose the combined use of federated learning\n(FL) and encrypted images for privacy-preserving image classification under the\nuse of the vision transformer (ViT). The proposed method allows us not only to\ntrain models over multiple participants without directly sharing their raw data\nbut to also protect the privacy of test (query) images for the first time. In\naddition, it can also maintain the same accuracy as normally trained models. In\nan experiment, the proposed method was demonstrated to well work without any\nperformance degradation on the CIFAR-10 and CIFAR-100 datasets.\n","authors":["Teru Nagamori","Hitoshi Kiya"],"pdf_url":"https://arxiv.org/pdf/2301.09255v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01936v1","updated":"2023-03-03T14:05:59Z","published":"2023-03-03T14:05:59Z","title":"Multi-Agent Adversarial Training Using Diffusion Learning","summary":"  This work focuses on adversarial learning over graphs. We propose a general\nadversarial training framework for multi-agent systems using diffusion\nlearning. We analyze the convergence properties of the proposed scheme for\nconvex optimization problems, and illustrate its enhanced robustness to\nadversarial attacks.\n","authors":["Ying Cao","Elsa Rizk","Stefan Vlaski","Ali H. Sayed"],"pdf_url":"https://arxiv.org/pdf/2303.01936v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01932v1","updated":"2023-03-03T14:02:50Z","published":"2023-03-03T14:02:50Z","title":"MobileBrick: Building LEGO for 3D Reconstruction on Mobile Devices","summary":"  High-quality 3D ground-truth shapes are critical for 3D object reconstruction\nevaluation. However, it is difficult to create a replica of an object in\nreality, and even 3D reconstructions generated by 3D scanners have artefacts\nthat cause biases in evaluation. To address this issue, we introduce a novel\nmulti-view RGBD dataset captured using a mobile device, which includes highly\nprecise 3D ground-truth annotations for 153 object models featuring a diverse\nset of 3D structures. We obtain precise 3D ground-truth shape without relying\non high-end 3D scanners by utilising LEGO models with known geometry as the 3D\nstructures for image capture. The distinct data modality offered by\nhigh-resolution RGB images and low-resolution depth maps captured on a mobile\ndevice, when combined with precise 3D geometry annotations, presents a unique\nopportunity for future research on high-fidelity 3D reconstruction.\nFurthermore, we evaluate a range of 3D reconstruction algorithms on the\nproposed dataset. Project page: http://code.active.vision/MobileBrick/\n","authors":["Kejie Li","Jia-Wang Bian","Robert Castle","Philip H. S. Torr","Victor Adrian Prisacariu"],"pdf_url":"https://arxiv.org/pdf/2303.01932v1.pdf","comment":"To be appeared at CVPR 2023"},{"id":"http://arxiv.org/abs/2303.01930v1","updated":"2023-03-03T13:58:24Z","published":"2023-03-03T13:58:24Z","title":"A toolkit of dilemmas: Beyond debiasing and fairness formulas for\n  responsible AI/ML","summary":"  Approaches to fair and ethical AI have recently fell under the scrutiny of\nthe emerging, chiefly qualitative, field of critical data studies, placing\nemphasis on the lack of sensitivity to context and complex social phenomena of\nsuch interventions. We employ some of these lessons to introduce a tripartite\ndecision-making toolkit, informed by dilemmas encountered in the pursuit of\nresponsible AI/ML. These are: (a) the opportunity dilemma between the\navailability of data shaping problem statements vs problem statements shaping\ndata; (b) the trade-off between scalability and contextualizability (too much\ndata versus too specific data); and (c) the epistemic positioning between the\npragmatic technical objectivism and the reflexive relativism in acknowledging\nthe social. This paper advocates for a situated reasoning and creative\nengagement with the dilemmas surrounding responsible algorithmic/data-driven\nsystems, and going beyond the formulaic bias elimination and ethics\noperationalization narratives found in the fair-AI literature.\n","authors":["Andrés Domínguez Hernández","Vassilis Galanos"],"pdf_url":"https://arxiv.org/pdf/2303.01930v1.pdf","comment":"4 pages, 1 table. Accepted in IEEE International Symposium on\n  Technology and Society 2022"},{"id":"http://arxiv.org/abs/2303.01928v1","updated":"2023-03-03T13:53:36Z","published":"2023-03-03T13:53:36Z","title":"FairShap: A Data Re-weighting Approach for Algorithmic Fairness based on\n  Shapley Values","summary":"  In this paper, we propose FairShap, a novel and interpretable pre-processing\n(re-weighting) method for fair algorithmic decision-making through data\nvaluation. FairShap is based on the Shapley Value, a well-known mathematical\nframework from game theory to achieve a fair allocation of resources. Our\napproach is easily interpretable, as it measures the contribution of each\ntraining data point to a predefined fairness metric. We empirically validate\nFairShap on several state-of-the-art datasets of different nature, with\ndifferent training scenarios and models. The proposed approach outperforms\nother methods, yielding significantly fairer models with similar levels of\naccuracy. In addition, we illustrate FairShap's interpretability by means of\nhistograms and latent space visualizations. We believe this work represents a\npromising direction in interpretable, model-agnostic approaches to algorithmic\nfairness.\n","authors":["Adrian Arnaiz-Rodriguez","Francisco Escolano","Nuria Oliver"],"pdf_url":"https://arxiv.org/pdf/2303.01928v1.pdf","comment":"11 pages, 7 figures, 1 appendix"},{"id":"http://arxiv.org/abs/2303.01926v1","updated":"2023-03-03T13:51:17Z","published":"2023-03-03T13:51:17Z","title":"RAFEN -- Regularized Alignment Framework for Embeddings of Nodes","summary":"  Learning representations of nodes has been a crucial area of the graph\nmachine learning research area. A well-defined node embedding model should\nreflect both node features and the graph structure in the final embedding. In\nthe case of dynamic graphs, this problem becomes even more complex as both\nfeatures and structure may change over time. The embeddings of particular nodes\nshould remain comparable during the evolution of the graph, what can be\nachieved by applying an alignment procedure. This step was often applied in\nexisting works after the node embedding was already computed. In this paper, we\nintroduce a framework -- RAFEN -- that allows to enrich any existing node\nembedding method using the aforementioned alignment term and learning aligned\nnode embedding during training time. We propose several variants of our\nframework and demonstrate its performance on six real-world datasets. RAFEN\nachieves on-par or better performance than existing approaches without\nrequiring additional processing steps.\n","authors":["Kamil Tagowski","Piotr Bielak","Jakub Binkowski","Tomasz Kajdanowicz"],"pdf_url":"https://arxiv.org/pdf/2303.01926v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01925v1","updated":"2023-03-03T13:51:04Z","published":"2023-03-03T13:51:04Z","title":"Learning Energy Conserving Dynamics Efficiently with Hamiltonian\n  Gaussian Processes","summary":"  Hamiltonian mechanics is one of the cornerstones of natural sciences.\nRecently there has been significant interest in learning Hamiltonian systems in\na free-form way directly from trajectory data. Previous methods have tackled\nthe problem of learning from many short, low-noise trajectories, but learning\nfrom a small number of long, noisy trajectories, whilst accounting for model\nuncertainty has not been addressed. In this work, we present a Gaussian process\nmodel for Hamiltonian systems with efficient decoupled parameterisation, and\nintroduce an energy-conserving shooting method that allows robust inference\nfrom both short and long trajectories. We demonstrate the method's success in\nlearning Hamiltonian systems in various data settings.\n","authors":["Magnus Ross","Markus Heinonen"],"pdf_url":"https://arxiv.org/pdf/2303.01925v1.pdf","comment":"Accepted in TMLR (March 2023)"},{"id":"http://arxiv.org/abs/2209.07850v5","updated":"2023-03-03T13:49:10Z","published":"2022-09-16T10:43:10Z","title":"FairGBM: Gradient Boosting with Fairness Constraints","summary":"  Tabular data is prevalent in many high-stakes domains, such as financial\nservices or public policy. Gradient Boosted Decision Trees (GBDT) are popular\nin these settings due to their scalability, performance, and low training cost.\nWhile fairness in these domains is a foremost concern, existing in-processing\nFair ML methods are either incompatible with GBDT, or incur in significant\nperformance losses while taking considerably longer to train. We present\nFairGBM, a dual ascent learning framework for training GBDT under fairness\nconstraints, with little to no impact on predictive performance when compared\nto unconstrained GBDT. Since observational fairness metrics are\nnon-differentiable, we propose smooth convex error rate proxies for common\nfairness criteria, enabling gradient-based optimization using a\n``proxy-Lagrangian'' formulation. Our implementation shows an order of\nmagnitude speedup in training time relative to related work, a pivotal aspect\nto foster the widespread adoption of FairGBM by real-world practitioners.\n","authors":["André F Cruz","Catarina Belém","Sérgio Jesus","João Bravo","Pedro Saleiro","Pedro Bizarro"],"pdf_url":"https://arxiv.org/pdf/2209.07850v5.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01923v1","updated":"2023-03-03T13:48:35Z","published":"2023-03-03T13:48:35Z","title":"Bayesian CART models for insurance claims frequency","summary":"  Accuracy and interpretability of a (non-life) insurance pricing model are\nessential qualities to ensure fair and transparent premiums for policy-holders,\nthat reflect their risk. In recent years, the classification and regression\ntrees (CARTs) and their ensembles have gained popularity in the actuarial\nliterature, since they offer good prediction performance and are relatively\neasily interpretable. In this paper, we introduce Bayesian CART models for\ninsurance pricing, with a particular focus on claims frequency modelling.\nAdditionally to the common Poisson and negative binomial (NB) distributions\nused for claims frequency, we implement Bayesian CART for the zero-inflated\nPoisson (ZIP) distribution to address the difficulty arising from the\nimbalanced insurance claims data. To this end, we introduce a general MCMC\nalgorithm using data augmentation methods for posterior tree exploration. We\nalso introduce the deviance information criterion (DIC) for the tree model\nselection. The proposed models are able to identify trees which can better\nclassify the policy-holders into risk groups. Some simulations and real\ninsurance data will be discussed to illustrate the applicability of these\nmodels.\n","authors":["Yaojun Zhang","Lanpeng Ji","Georgios Aivaliotis","Charles Taylor"],"pdf_url":"https://arxiv.org/pdf/2303.01923v1.pdf","comment":"42 pages"},{"id":"http://arxiv.org/abs/2303.01913v1","updated":"2023-03-03T13:27:00Z","published":"2023-03-03T13:27:00Z","title":"Bespoke: A Block-Level Neural Network Optimization Framework for\n  Low-Cost Deployment","summary":"  As deep learning models become popular, there is a lot of need for deploying\nthem to diverse device environments. Because it is costly to develop and\noptimize a neural network for every single environment, there is a line of\nresearch to search neural networks for multiple target environments\nefficiently. However, existing works for such a situation still suffer from\nrequiring many GPUs and expensive costs. Motivated by this, we propose a novel\nneural network optimization framework named Bespoke for low-cost deployment.\nOur framework searches for a lightweight model by replacing parts of an\noriginal model with randomly selected alternatives, each of which comes from a\npretrained neural network or the original model. In the practical sense,\nBespoke has two significant merits. One is that it requires near zero cost for\ndesigning the search space of neural networks. The other merit is that it\nexploits the sub-networks of public pretrained neural networks, so the total\ncost is minimal compared to the existing works. We conduct experiments\nexploring Bespoke's the merits, and the results show that it finds efficient\nmodels for multiple targets with meager cost.\n","authors":["Jong-Ryul Lee","Yong-Hyuk Moon"],"pdf_url":"https://arxiv.org/pdf/2303.01913v1.pdf","comment":"Accepted in AAAI-2023"},{"id":"http://arxiv.org/abs/2302.14004v2","updated":"2023-03-03T13:22:21Z","published":"2023-02-27T17:48:08Z","title":"Optimistic Planning by Regularized Dynamic Programming","summary":"  We propose a new method for optimistic planning in infinite-horizon\ndiscounted Markov decision processes based on the idea of adding regularization\nto the updates of an otherwise standard approximate value iteration procedure.\nThis technique allows us to avoid contraction and monotonicity arguments that\nare typically required by existing analyses of approximate dynamic programming\nmethods, and in particular to use approximate transition functions estimated\nvia least-squares procedures in MDPs with linear function approximation. We use\nour method to provide a computationally efficient algorithm for learning\nnear-optimal policies in discounted linear kernel MDPs from a single stream of\nexperience, and show that it achieves near-optimal statistical guarantees.\n","authors":["Antoine Moulin","Gergely Neu"],"pdf_url":"https://arxiv.org/pdf/2302.14004v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.02385v2","updated":"2023-03-03T13:16:25Z","published":"2022-04-05T17:45:09Z","title":"Learning Speech Emotion Representations in the Quaternion Domain","summary":"  The modeling of human emotion expression in speech signals is an important,\nyet challenging task. The high resource demand of speech emotion recognition\nmodels, combined with the the general scarcity of emotion-labelled data are\nobstacles to the development and application of effective solutions in this\nfield. In this paper, we present an approach to jointly circumvent these\ndifficulties. Our method, named RH-emo, is a novel semi-supervised architecture\naimed at extracting quaternion embeddings from real-valued monoaural\nspectrograms, enabling the use of quaternion-valued networks for speech emotion\nrecognition tasks. RH-emo is a hybrid real/quaternion autoencoder network that\nconsists of a real-valued encoder in parallel to a real-valued emotion\nclassifier and a quaternion-valued decoder. On the one hand, the classifier\npermits to optimize each latent axis of the embeddings for the classification\nof a specific emotion-related characteristic: valence, arousal, dominance and\noverall emotion. On the other hand, the quaternion reconstruction enables the\nlatent dimension to develop intra-channel correlations that are required for an\neffective representation as a quaternion entity. We test our approach on speech\nemotion recognition tasks using four popular datasets: Iemocap, Ravdess, EmoDb\nand Tess, comparing the performance of three well-established real-valued CNN\narchitectures (AlexNet, ResNet-50, VGG) and their quaternion-valued equivalent\nfed with the embeddings created with RH-emo. We obtain a consistent improvement\nin the test accuracy for all datasets, while drastically reducing the\nresources' demand of models. Moreover, we performed additional experiments and\nablation studies that confirm the effectiveness of our approach. The RH-emo\nrepository is available at: https://github.com/ispamm/rhemo.\n","authors":["Eric Guizzo","Tillman Weyde","Simone Scardapane","Danilo Comminiello"],"pdf_url":"https://arxiv.org/pdf/2204.02385v2.pdf","comment":"Accepted for Publication in IEEE/ACM Transactions on Audio, Speech\n  and Language Processing"},{"id":"http://arxiv.org/abs/2303.01903v1","updated":"2023-03-03T13:05:15Z","published":"2023-03-03T13:05:15Z","title":"Prompting Large Language Models with Answer Heuristics for\n  Knowledge-based Visual Question Answering","summary":"  Knowledge-based visual question answering (VQA) requires external knowledge\nbeyond the image to answer the question. Early studies retrieve required\nknowledge from explicit knowledge bases (KBs), which often introduces\nirrelevant information to the question, hence restricting the performance of\ntheir models. Recent works have sought to use a large language model (i.e.,\nGPT-3) as an implicit knowledge engine to acquire the necessary knowledge for\nanswering. Despite the encouraging results achieved by these methods, we argue\nthat they have not fully activated the capacity of GPT-3 as the provided input\ninformation is insufficient. In this paper, we present Prophet -- a\nconceptually simple framework designed to prompt GPT-3 with answer heuristics\nfor knowledge-based VQA. Specifically, we first train a vanilla VQA model on a\nspecific knowledge-based VQA dataset without external knowledge. After that, we\nextract two types of complementary answer heuristics from the model: answer\ncandidates and answer-aware examples. Finally, the two types of answer\nheuristics are encoded into the prompts to enable GPT-3 to better comprehend\nthe task thus enhancing its capacity. Prophet significantly outperforms all\nexisting state-of-the-art methods on two challenging knowledge-based VQA\ndatasets, OK-VQA and A-OKVQA, delivering 61.1% and 55.7% accuracies on their\ntesting sets, respectively.\n","authors":["Zhenwei Shao","Zhou Yu","Meng Wang","Jun Yu"],"pdf_url":"https://arxiv.org/pdf/2303.01903v1.pdf","comment":"Accepted at CVPR 2023, code available at\n  https://github.com/MILVLG/prophet"},{"id":"http://arxiv.org/abs/2211.13976v3","updated":"2023-03-03T12:50:12Z","published":"2022-11-25T09:38:22Z","title":"Expanding Small-Scale Datasets with Guided Imagination","summary":"  The power of DNNs depends heavily on the quantity and quality of training\ndata. However, collecting and annotating data on a large scale is often costly\nand time-consuming, which severely hinders the application of DNNs. To address\nthis issue, we explore a new task, termed as dataset expansion, which seeks to\nexpand a ready-to-use small dataset by automatically creating new labeled\nsamples. To this end, we present a Guided Imagination Framework (GIF) that\nleverages cutting-edge generative models (e.g., DALL-E2, Stable Diffusion (SD))\nto ``imagine'' and create informative new data from the input seed data.\nSpecifically, GIF conducts data imagination by optimizing the latent features\nof the seed data in the semantically meaningful space of the prior model, which\nare used to create photo-realistic images with new content. To guide the\nimagination towards creating informative samples for model training, we\nintroduce two key criteria, i.e., class-maintained information boosting and\nsample diversity promotion. The two criteria are verified to be essential for\neffective dataset expansion: GIF-SD obtains 13.5\\% higher model accuracy on\nnatural image datasets than unguided expansion with SD. With these essential\ncriteria, GIF expands datasets effectively in various small-data scenarios,\nboosting model accuracy by 36.9\\% on average over six natural image datasets\nand by 13.5\\% on average over three medical datasets. The source code will be\nreleased: \\url{https://github.com/Vanint/DatasetExpansion}.\n","authors":["Yifan Zhang","Daquan Zhou","Bryan Hooi","Kai Wang","Jiashi Feng"],"pdf_url":"https://arxiv.org/pdf/2211.13976v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.10605v2","updated":"2023-03-03T12:50:07Z","published":"2022-08-22T21:23:13Z","title":"SoK: Explainable Machine Learning for Computer Security Applications","summary":"  Explainable Artificial Intelligence (XAI) aims to improve the transparency of\nmachine learning (ML) pipelines. We systematize the increasingly growing (but\nfragmented) microcosm of studies that develop and utilize XAI methods for\ndefensive and offensive cybersecurity tasks. We identify 3 cybersecurity\nstakeholders, i.e., model users, designers, and adversaries, who utilize XAI\nfor 4 distinct objectives within an ML pipeline, namely 1) XAI-enabled user\nassistance, 2) XAI-enabled model verification, 3) explanation verification &\nrobustness, and 4) offensive use of explanations. Our analysis of the\nliterature indicates that many of the XAI applications are designed with little\nunderstanding of how they might be integrated into analyst workflows -- user\nstudies for explanation evaluation are conducted in only 14% of the cases. The\nsecurity literature sometimes also fails to disentangle the role of the various\nstakeholders, e.g., by providing explanations to model users and designers\nwhile also exposing them to adversaries. Additionally, the role of model\ndesigners is particularly minimized in the security literature. To this end, we\npresent an illustrative tutorial for model designers, demonstrating how XAI can\nhelp with model verification. We also discuss scenarios where interpretability\nby design may be a better alternative. The systematization and the tutorial\nenable us to challenge several assumptions, and present open problems that can\nhelp shape the future of XAI research within cybersecurity.\n","authors":["Azqa Nadeem","Daniël Vos","Clinton Cao","Luca Pajola","Simon Dieck","Robert Baumgartner","Sicco Verwer"],"pdf_url":"https://arxiv.org/pdf/2208.10605v2.pdf","comment":"13 pages. Accepted at Euro S&P"},{"id":"http://arxiv.org/abs/2303.01886v1","updated":"2023-03-03T12:33:29Z","published":"2023-03-03T12:33:29Z","title":"Machine learning using magnetic stochastic synapses","summary":"  The impressive performance of artificial neural networks has come at the cost\nof high energy usage and CO$_2$ emissions. Unconventional computing\narchitectures, with magnetic systems as a candidate, have potential as\nalternative energy-efficient hardware, but, still face challenges, such as\nstochastic behaviour, in implementation. Here, we present a methodology for\nexploiting the traditionally detrimental stochastic effects in magnetic\ndomain-wall motion in nanowires. We demonstrate functional binary stochastic\nsynapses alongside a gradient learning rule that allows their training with\napplicability to a range of stochastic systems. The rule, utilising the mean\nand variance of the neuronal output distribution, finds a trade-off between\nsynaptic stochasticity and energy efficiency depending on the number of\nmeasurements of each synapse. For single measurements, the rule results in\nbinary synapses with minimal stochasticity, sacrificing potential performance\nfor robustness. For multiple measurements, synaptic distributions are broad,\napproximating better-performing continuous synapses. This observation allows us\nto choose design principles depending on the desired performance and the\ndevice's operational speed and energy cost. We verify performance on physical\nhardware, showing it is comparable to a standard neural network.\n","authors":["Matthew O. A. Ellis","Alex Welbourne","Stephan J. Kyle","Paul W. Fry","Dan A. Allwood","Thomas J. Hayward","Eleni Vasilaki"],"pdf_url":"https://arxiv.org/pdf/2303.01886v1.pdf","comment":"15 pages, 4 figures"},{"id":"http://arxiv.org/abs/2302.03266v3","updated":"2023-03-03T12:26:48Z","published":"2023-02-07T05:32:11Z","title":"Learning to Count Isomorphisms with Graph Neural Networks","summary":"  Subgraph isomorphism counting is an important problem on graphs, as many\ngraph-based tasks exploit recurring subgraph patterns. Classical methods\nusually boil down to a backtracking framework that needs to navigate a huge\nsearch space with prohibitive computational costs. Some recent studies resort\nto graph neural networks (GNNs) to learn a low-dimensional representation for\nboth the query and input graphs, in order to predict the number of subgraph\nisomorphisms on the input graph. However, typical GNNs employ a node-centric\nmessage passing scheme that receives and aggregates messages on nodes, which is\ninadequate in complex structure matching for isomorphism counting. Moreover, on\nan input graph, the space of possible query graphs is enormous, and different\nparts of the input graph will be triggered to match different queries. Thus,\nexpecting a fixed representation of the input graph to match diversely\nstructured query graphs is unrealistic. In this paper, we propose a novel GNN\ncalled Count-GNN for subgraph isomorphism counting, to deal with the above\nchallenges. At the edge level, given that an edge is an atomic unit of encoding\ngraph structures, we propose an edge-centric message passing scheme, where\nmessages on edges are propagated and aggregated based on the edge adjacency to\npreserve fine-grained structural information. At the graph level, we modulate\nthe input graph representation conditioned on the query, so that the input\ngraph can be adapted to each query individually to improve their matching.\nFinally, we conduct extensive experiments on a number of benchmark datasets to\ndemonstrate the superior performance of Count-GNN.\n","authors":["Xingtong Yu","Zemin Liu","Yuan Fang","Xinming Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.03266v3.pdf","comment":"AAAI-23 main track"},{"id":"http://arxiv.org/abs/2208.09322v2","updated":"2023-03-03T12:25:11Z","published":"2022-08-19T13:09:32Z","title":"Entropy Augmented Reinforcement Learning","summary":"  Deep reinforcement learning was instigated with the presence of trust region\nmethods, being scalable and efficient. However, the pessimism of such\nalgorithms, among which it forces to constrain in a trust region by all means,\nhas been proven to suppress the exploration and harm the performance.\nExploratory algorithm such as SAC, while utilizes the entropy to encourage\nexploration, implicitly optimizing another objective yet. We first observed\nthis inconsistency, and therefore put forward an analogous augmentation\ntechnique, which combines well with the on-policy algorithms, when a value\ncritic is involved. Surprisingly, the proposed method consistently satisfies\nthe soft policy improvement theorem, while being more extensible. As the\nanalysis advises, it is crucial to control the temperature coefficient to\nbalance the exploration and exploitation. Empirical tests on MuJoCo benchmark\ntasks show that the agent is heartened towards higher reward regions, and\nenjoys a finer performance. Furthermore, we verify the exploration bonus of our\nmethod on a set of custom environments.\n","authors":["Jianfei Ma"],"pdf_url":"https://arxiv.org/pdf/2208.09322v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.09186v5","updated":"2023-03-03T12:18:39Z","published":"2022-10-17T15:38:41Z","title":"Implicit models, latent compression, intrinsic biases, and cheap lunches\n  in community detection","summary":"  The task of community detection, which aims to partition a network into\nclusters of nodes to summarize its large-scale structure, has spawned the\ndevelopment of many competing algorithms with varying objectives. Some\ncommunity detection methods are inferential, explicitly deriving the clustering\nobjective through a probabilistic generative model, while other methods are\ndescriptive, dividing a network according to an objective motivated by a\nparticular application, making it challenging to compare these methods on the\nsame scale. Here we present a solution to this problem that associates any\ncommunity detection objective, inferential or descriptive, with its\ncorresponding implicit network generative model. This allows us to compute the\ndescription length of a network and its partition under arbitrary objectives,\nproviding a principled measure to compare the performance of different\nalgorithms without the need for \"ground truth\" labels. Our approach also gives\naccess to instances of the community detection problem that are optimal to any\ngiven algorithm, and in this way reveals intrinsic biases in popular\ndescriptive methods, explaining their tendency to overfit. Using our framework,\nwe compare a number of community detection methods on artificial networks, and\non a corpus of over 500 structurally diverse empirical networks. We find that\nmore expressive community detection methods exhibit consistently superior\ncompression performance on structured data instances, without having degraded\nperformance on a minority of situations where more specialized algorithms\nperform optimally. Our results undermine the implications of the \"no free\nlunch\" theorem for community detection, both conceptually and in practice,\nsince it is confined to unstructured data instances, unlike relevant community\ndetection problems which are structured by requirement.\n","authors":["Tiago P. Peixoto","Alec Kirkley"],"pdf_url":"https://arxiv.org/pdf/2210.09186v5.pdf","comment":"27 pages, 17 figures"},{"id":"http://arxiv.org/abs/2302.11716v3","updated":"2023-03-03T11:57:27Z","published":"2023-02-23T00:45:14Z","title":"VRA: Out-of-Distribution Detection with variational rectified\n  activations","summary":"  Detecting out-of-distribution (OOD) data is critical to building reliable\nmachine learning systems in the open world. Among the existing OOD detection\nmethods, ReAct is famous for its simplicity and efficiency, and has good\ntheoretical analysis. The gap between ID data and OOD data is enlarged by\nclipping the larger activation value. But the question is, is this operation\noptimal? Is there a better way to expand the spacing between ID samples and OOD\nsamples in theory? Driven by these questions, we view the optimal activation\nfunction modification from the perspective of functional extremum and propose\nthe Variational Recified Acitvations (VRA) method. In order to make our method\neasy to practice, we further propose several VRA variants. To verify the\neffectiveness of our method, we conduct experiments on many benchmark datasets.\nExperimental results demonstrate that our method outperforms existing\nstate-of-the-art approaches. Meanwhile, our method is easy to implement and\ndoes not require additional OOD data or fine-tuning process. We can realize OOD\ndetection in only one forward pass.\n","authors":["Mingyu Xu","Zheng Lian"],"pdf_url":"https://arxiv.org/pdf/2302.11716v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01870v1","updated":"2023-03-03T11:53:01Z","published":"2023-03-03T11:53:01Z","title":"Revisiting Adversarial Training for ImageNet: Architectures, Training\n  and Generalization across Threat Models","summary":"  While adversarial training has been extensively studied for ResNet\narchitectures and low resolution datasets like CIFAR, much less is known for\nImageNet. Given the recent debate about whether transformers are more robust\nthan convnets, we revisit adversarial training on ImageNet comparing ViTs and\nConvNeXts. Extensive experiments show that minor changes in architecture, most\nnotably replacing PatchStem with ConvStem, and training scheme have a\nsignificant impact on the achieved robustness. These changes not only increase\nrobustness in the seen $\\ell_\\infty$-threat model, but even more so improve\ngeneralization to unseen $\\ell_1/\\ell_2$-robustness. Our modified ConvNeXt,\nConvNeXt + ConvStem, yields the most robust models across different ranges of\nmodel parameters and FLOPs.\n","authors":["Naman D Singh","Francesco Croce","Matthias Hein"],"pdf_url":"https://arxiv.org/pdf/2303.01870v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14714v2","updated":"2023-03-03T11:35:34Z","published":"2023-02-28T16:26:23Z","title":"Minimizing the Outage Probability in a Markov Decision Process","summary":"  Standard Markov decision process (MDP) and reinforcement learning algorithms\noptimize the policy with respect to the expected gain. We propose an algorithm\nwhich enables to optimize an alternative objective: the probability that the\ngain is greater than a given value. The algorithm can be seen as an extension\nof the value iteration algorithm. We also show how the proposed algorithm could\nbe generalized to use neural networks, similarly to the deep Q learning\nextension of Q learning.\n","authors":["Vincent Corlay","Jean-Christophe Sibel"],"pdf_url":"https://arxiv.org/pdf/2302.14714v2.pdf","comment":"Accepted at the Information Theory Workshop (ITW) 2023"},{"id":"http://arxiv.org/abs/2303.01861v1","updated":"2023-03-03T11:31:55Z","published":"2023-03-03T11:31:55Z","title":"Diffusion Models are Minimax Optimal Distribution Estimators","summary":"  While efficient distribution learning is no doubt behind the groundbreaking\nsuccess of diffusion modeling, its theoretical guarantees are quite limited. In\nthis paper, we provide the first rigorous analysis on approximation and\ngeneralization abilities of diffusion modeling for well-known function spaces.\nThe highlight of this paper is that when the true density function belongs to\nthe Besov space and the empirical score matching loss is properly minimized,\nthe generated data distribution achieves the nearly minimax optimal estimation\nrates in the total variation distance and in the Wasserstein distance of order\none. Furthermore, we extend our theory to demonstrate how diffusion models\nadapt to low-dimensional data distributions. We expect these results advance\ntheoretical understandings of diffusion modeling and its ability to generate\nverisimilar outputs.\n","authors":["Kazusato Oko","Shunta Akiyama","Taiji Suzuki"],"pdf_url":"https://arxiv.org/pdf/2303.01861v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01859v1","updated":"2023-03-03T11:25:33Z","published":"2023-03-03T11:25:33Z","title":"POPGym: Benchmarking Partially Observable Reinforcement Learning","summary":"  Real world applications of Reinforcement Learning (RL) are often partially\nobservable, thus requiring memory. Despite this, partial observability is still\nlargely ignored by contemporary RL benchmarks and libraries. We introduce\nPartially Observable Process Gym (POPGym), a two-part library containing (1) a\ndiverse collection of 15 partially observable environments, each with multiple\ndifficulties and (2) implementations of 13 memory model baselines -- the most\nin a single RL library. Existing partially observable benchmarks tend to fixate\non 3D visual navigation, which is computationally expensive and only one type\nof POMDP. In contrast, POPGym environments are diverse, produce smaller\nobservations, use less memory, and often converge within two hours of training\non a consumer-grade GPU. We implement our high-level memory API and memory\nbaselines on top of the popular RLlib framework, providing plug-and-play\ncompatibility with various training algorithms, exploration strategies, and\ndistributed training paradigms. Using POPGym, we execute the largest comparison\nacross RL memory models to date. POPGym is available at\nhttps://github.com/proroklab/popgym.\n","authors":["Steven Morad","Ryan Kortvelesy","Matteo Bettini","Stephan Liwicki","Amanda Prorok"],"pdf_url":"https://arxiv.org/pdf/2303.01859v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.01901v2","updated":"2023-03-03T11:11:28Z","published":"2022-08-03T08:05:02Z","title":"Asynchronous Federated Learning for Edge-assisted Vehicular Networks","summary":"  Vehicular networks enable vehicles support real-time vehicular applications\nthrough training data. Due to the limited computing capability, vehicles\nusually transmit data to a road side unit (RSU) at the network edge to process\ndata. However, vehicles are usually reluctant to share data with each other due\nto the privacy issue. For the traditional federated learning (FL), vehicles\ntrain the data locally to obtain a local model and then upload the local model\nto the RSU to update the global model, thus the data privacy can be protected\nthrough sharing model parameters instead of data. The traditional FL updates\nthe global model synchronously, i.e., the RSU needs to wait for all vehicles to\nupload their models for the global model updating. However, vehicles may\nusually drive out of the coverage of the RSU before they obtain their local\nmodels through training, which reduces the accuracy of the global model. It is\nnecessary to propose an asynchronous federated learning (AFL) to solve this\nproblem, where the RSU updates the global model once it receives a local model\nfrom a vehicle. However, the amount of data, computing capability and vehicle\nmobility may affect the accuracy of the global model. In this paper, we jointly\nconsider the amount of data, computing capability and vehicle mobility to\ndesign an AFL scheme to improve the accuracy of the global model. Extensive\nsimulation experiments have demonstrated that our scheme outperforms the FL\nscheme\n","authors":["Siyuan Wang","Qiong Wu","Qiang Fan","Pingyi Fan","Jiangzhou Wang"],"pdf_url":"https://arxiv.org/pdf/2208.01901v2.pdf","comment":"This paper has been accepted by ICC 2023"},{"id":"http://arxiv.org/abs/2211.15363v2","updated":"2023-03-03T11:10:16Z","published":"2022-11-28T14:38:45Z","title":"On the Security Vulnerabilities of Text-to-SQL Models","summary":"  Although it has been demonstrated that Natural Language Processing (NLP)\nalgorithms are vulnerable to deliberate attacks, the question of whether such\nweaknesses can lead to software security threats is under-explored. To bridge\nthis gap, we conducted vulnerability tests on Text-to-SQL systems that are\ncommonly used to create natural language interfaces to databases. We showed\nthat the Text-to-SQL modules within six commercial applications can be\nmanipulated to produce malicious code, potentially leading to data breaches and\nDenial of Service attacks. This is the first demonstration that NLP models can\nbe exploited as attack vectors in the wild. In addition, experiments using four\nopen-source language models verified that straightforward backdoor attacks on\nText-to-SQL systems achieve a 100% success rate without affecting their\nperformance. The aim of this work is to draw the community's attention to\npotential software security issues associated with NLP algorithms and encourage\nexploration of methods to mitigate against them.\n","authors":["Xutan Peng","Yipeng Zhang","Jingfeng Yang","Mark Stevenson"],"pdf_url":"https://arxiv.org/pdf/2211.15363v2.pdf","comment":"Added demonstrations on four more online systems"},{"id":"http://arxiv.org/abs/2303.01844v1","updated":"2023-03-03T10:57:04Z","published":"2023-03-03T10:57:04Z","title":"Learning Permutation-Invariant Embeddings for Description Logic Concepts","summary":"  Concept learning deals with learning description logic concepts from a\nbackground knowledge and input examples. The goal is to learn a concept that\ncovers all positive examples, while not covering any negative examples. This\nnon-trivial task is often formulated as a search problem within an infinite\nquasi-ordered concept space. Although state-of-the-art models have been\nsuccessfully applied to tackle this problem, their large-scale applications\nhave been severely hindered due to their excessive exploration incurring\nimpractical runtimes. Here, we propose a remedy for this limitation. We\nreformulate the learning problem as a multi-label classification problem and\npropose a neural embedding model (NERO) that learns permutation-invariant\nembeddings for sets of examples tailored towards predicting $F_1$ scores of\npre-selected description logic concepts. By ranking such concepts in descending\norder of predicted scores, a possible goal concept can be detected within few\nretrieval operations, i.e., no excessive exploration. Importantly, top-ranked\nconcepts can be used to start the search procedure of state-of-the-art symbolic\nmodels in multiple advantageous regions of a concept space, rather than\nstarting it in the most general concept $\\top$. Our experiments on 5 benchmark\ndatasets with 770 learning problems firmly suggest that NERO significantly\n(p-value <1%) outperforms the state-of-the-art models in terms of $F_1$ score,\nthe number of explored concepts, and the total runtime. We provide an\nopen-source implementation of our approach.\n","authors":["Caglar Demir","Axel-Cyrille Ngonga Ngomo"],"pdf_url":"https://arxiv.org/pdf/2303.01844v1.pdf","comment":"Accepted at IDA 2023"},{"id":"http://arxiv.org/abs/2303.01841v1","updated":"2023-03-03T10:49:09Z","published":"2023-03-03T10:49:09Z","title":"Anamnesic Neural Differential Equations with Orthogonal Polynomial\n  Projections","summary":"  Neural ordinary differential equations (Neural ODEs) are an effective\nframework for learning dynamical systems from irregularly sampled time series\ndata. These models provide a continuous-time latent representation of the\nunderlying dynamical system where new observations at arbitrary time points can\nbe used to update the latent representation of the dynamical system. Existing\nparameterizations for the dynamics functions of Neural ODEs limit the ability\nof the model to retain global information about the time series; specifically,\na piece-wise integration of the latent process between observations can result\nin a loss of memory on the dynamic patterns of previously observed data points.\nWe propose PolyODE, a Neural ODE that models the latent continuous-time process\nas a projection onto a basis of orthogonal polynomials. This formulation\nenforces long-range memory and preserves a global representation of the\nunderlying dynamical system. Our construction is backed by favourable\ntheoretical guarantees and in a series of experiments, we demonstrate that it\noutperforms previous works in the reconstruction of past and future data, and\nin downstream prediction tasks.\n","authors":["Edward De Brouwer","Rahul G. Krishnan"],"pdf_url":"https://arxiv.org/pdf/2303.01841v1.pdf","comment":"Accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2210.00841v2","updated":"2023-03-03T10:37:00Z","published":"2022-10-03T11:57:30Z","title":"Spatial Entropy as an Inductive Bias for Vision Transformers","summary":"  Recent work on Vision Transformers (VTs) showed that introducing a local\ninductive bias in the VT architecture helps reducing the number of samples\nnecessary for training. However, the architecture modifications lead to a loss\nof generality of the Transformer backbone, partially contradicting the push\ntowards the development of uniform architectures, shared, e.g., by both the\nComputer Vision and the Natural Language Processing areas. In this work, we\npropose a different and complementary direction, in which a local bias is\nintroduced using an auxiliary self-supervised task, performed jointly with\nstandard supervised training. Specifically, we exploit the observation that the\nattention maps of VTs, when trained with self-supervision, can contain a\nsemantic segmentation structure which does not spontaneously emerge when\ntraining is supervised. Thus, we explicitly encourage the emergence of this\nspatial clustering as a form of training regularization. In more detail, we\nexploit the assumption that, in a given image, objects usually correspond to\nfew connected regions, and we propose a spatial formulation of the information\nentropy to quantify this object-based inductive bias. By minimizing the\nproposed spatial entropy, we include an additional self-supervised signal\nduring training. Using extensive experiments, we show that the proposed\nregularization leads to equivalent or better results than other VT proposals\nwhich include a local bias by changing the basic Transformer architecture, and\nit can drastically boost the VT final accuracy when using small-medium training\nsets. The code is available at https://github.com/helia95/SAR.\n","authors":["Yahui Liu","Enver Sangineto","Yajing Chen","Linchao Bao","Haoxian Zhang","Nicu Sebe","Bruno Lepri","Marco De Nadai"],"pdf_url":"https://arxiv.org/pdf/2210.00841v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2206.04636"},{"id":"http://arxiv.org/abs/2303.01826v1","updated":"2023-03-03T10:20:45Z","published":"2023-03-03T10:20:45Z","title":"TopSpark: A Timestep Optimization Methodology for Energy-Efficient\n  Spiking Neural Networks on Autonomous Mobile Agents","summary":"  Autonomous mobile agents require low-power/energy-efficient machine learning\n(ML) algorithms to complete their ML-based tasks while adapting to diverse\nenvironments, as mobile agents are usually powered by batteries. These\nrequirements can be fulfilled by Spiking Neural Networks (SNNs) as they offer\nlow power/energy processing due to their sparse computations and efficient\nonline learning with bio-inspired learning mechanisms for adapting to different\nenvironments. Recent works studied that the energy consumption of SNNs can be\noptimized by reducing the computation time of each neuron for processing a\nsequence of spikes (timestep). However, state-of-the-art techniques rely on\nintensive design searches to determine fixed timestep settings for only\ninference, thereby hindering SNNs from achieving further energy efficiency\ngains in both training and inference. These techniques also restrict SNNs from\nperforming efficient online learning at run time. Toward this, we propose\nTopSpark, a novel methodology that leverages adaptive timestep reduction to\nenable energy-efficient SNN processing in both training and inference, while\nkeeping its accuracy close to the accuracy of SNNs without timestep reduction.\nThe ideas of TopSpark include analyzing the impact of different timesteps on\nthe accuracy; identifying neuron parameters that have a significant impact on\naccuracy in different timesteps; employing parameter enhancements that make\nSNNs effectively perform learning and inference using less spiking activity;\nand developing a strategy to trade-off accuracy, latency, and energy to meet\nthe design requirements. The results show that, TopSpark saves the SNN latency\nby 3.9x as well as energy consumption by 3.5x for training and 3.3x for\ninference on average, across different network sizes, learning rules, and\nworkloads, while maintaining the accuracy within 2% of SNNs without timestep\nreduction.\n","authors":["Rachmad Vidya Wicaksana Putra","Muhammad Shafique"],"pdf_url":"https://arxiv.org/pdf/2303.01826v1.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2205.09546v5","updated":"2023-03-03T10:02:16Z","published":"2022-05-19T13:16:09Z","title":"Deterministic training of generative autoencoders using invertible\n  layers","summary":"  In this work, we provide a deterministic alternative to the stochastic\nvariational training of generative autoencoders. We refer to these new\ngenerative autoencoders as AutoEncoders within Flows (AEF), since the encoder\nand decoder are defined as affine layers of an overall invertible architecture.\nThis results in a deterministic encoding of the data, as opposed to the\nstochastic encoding of VAEs. The paper introduces two related families of AEFs.\nThe first family relies on a partition of the ambient space and is trained by\nexact maximum-likelihood. The second family exploits a deterministic expansion\nof the ambient space and is trained by maximizing the log-probability in this\nextended space. This latter case leaves complete freedom in the choice of\nencoder, decoder and prior architectures, making it a drop-in replacement for\nthe training of existing VAEs and VAE-style models. We show that these AEFs can\nhave strikingly higher performance than architecturally identical VAEs in terms\nof log-likelihood and sample quality, especially for low dimensional latent\nspaces. Importantly, we show that AEF samples are substantially sharper than\nVAE samples.\n","authors":["Gianluigi Silvestri","Daan Roos","Luca Ambrogioni"],"pdf_url":"https://arxiv.org/pdf/2205.09546v5.pdf","comment":"International Conference on Learning Representations 2023"},{"id":"http://arxiv.org/abs/2303.01819v1","updated":"2023-03-03T09:59:42Z","published":"2023-03-03T09:59:42Z","title":"Exploring Machine Learning Privacy/Utility trade-off from a\n  hyperparameters Lens","summary":"  Machine Learning (ML) architectures have been applied to several applications\nthat involve sensitive data, where a guarantee of users' data privacy is\nrequired. Differentially Private Stochastic Gradient Descent (DPSGD) is the\nstate-of-the-art method to train privacy-preserving models. However, DPSGD\ncomes at a considerable accuracy loss leading to sub-optimal privacy/utility\ntrade-offs. Towards investigating new ground for better privacy-utility\ntrade-off, this work questions; (i) if models' hyperparameters have any\ninherent impact on ML models' privacy-preserving properties, and (ii) if\nmodels' hyperparameters have any impact on the privacy/utility trade-off of\ndifferentially private models. We propose a comprehensive design space\nexploration of different hyperparameters such as the choice of activation\nfunctions, the learning rate and the use of batch normalization. Interestingly,\nwe found that utility can be improved by using Bounded RELU as activation\nfunctions with the same privacy-preserving characteristics. With a drop-in\nreplacement of the activation function, we achieve new state-of-the-art\naccuracy on MNIST (96.02\\%), FashionMnist (84.76\\%), and CIFAR-10 (44.42\\%)\nwithout any modification of the learning procedure fundamentals of DPSGD.\n","authors":["Ayoub Arous","Amira Guesmi","Muhammad Abdullah Hanif","Ihsen Alouani","Muhammad Shafique"],"pdf_url":"https://arxiv.org/pdf/2303.01819v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13693v2","updated":"2023-03-03T09:45:57Z","published":"2023-02-27T11:53:03Z","title":"Learning Topology-Specific Experts for Molecular Property Prediction","summary":"  Recently, graph neural networks (GNNs) have been successfully applied to\npredicting molecular properties, which is one of the most classical\ncheminformatics tasks with various applications. Despite their effectiveness,\nwe empirically observe that training a single GNN model for diverse molecules\nwith distinct structural patterns limits its prediction performance. In this\npaper, motivated by this observation, we propose TopExpert to leverage\ntopology-specific prediction models (referred to as experts), each of which is\nresponsible for each molecular group sharing similar topological semantics.\nThat is, each expert learns topology-specific discriminative features while\nbeing trained with its corresponding topological group. To tackle the key\nchallenge of grouping molecules by their topological patterns, we introduce a\nclustering-based gating module that assigns an input molecule into one of the\nclusters and further optimizes the gating module with two different types of\nself-supervision: topological semantics induced by GNNs and molecular\nscaffolds, respectively. Extensive experiments demonstrate that TopExpert has\nboosted the performance for molecular property prediction and also achieved\nbetter generalization for new molecules with unseen scaffolds than baselines.\nThe code is available at https://github.com/kimsu55/ToxExpert.\n","authors":["Su Kim","Dongha Lee","SeongKu Kang","Seonghyeon Lee","Hwanjo Yu"],"pdf_url":"https://arxiv.org/pdf/2302.13693v2.pdf","comment":"11 pages with 8 figures"},{"id":"http://arxiv.org/abs/2302.14471v2","updated":"2023-03-03T09:33:37Z","published":"2023-02-28T10:29:42Z","title":"Safe peeling for l0-regularized least-squares with supplementary\n  material","summary":"  We introduce a new methodology dubbed ``safe peeling'' to accelerate the\nresolution of L0-regularized least-squares problems via a Branch-and-Bound\n(BnB) algorithm. Our procedure enables to tighten the convex relaxation\nconsidered at each node of the BnB decision tree and therefore potentially\nallows for more aggressive pruning. Numerical simulations show that our\nproposed methodology leads to significant gains in terms of number of nodes\nexplored and overall solving time.s show that our proposed methodology leads to\nsignificant gains in terms of number of nodes explored and overall solving\ntime.\n","authors":["Théo Guyard","Gilles Monnoyer","Clément Elvira","Cédric Herzet"],"pdf_url":"https://arxiv.org/pdf/2302.14471v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01807v1","updated":"2023-03-03T09:27:34Z","published":"2023-03-03T09:27:34Z","title":"Unsupervised Recycled FPGA Detection Using Symmetry Analysis","summary":"  Recently, recycled field-programmable gate arrays (FPGAs) pose a significant\nhardware security problem due to the proliferation of the semiconductor supply\nchain. Ring oscillator (RO) based frequency analyzing technique is one of the\npopular methods, where most studies used the known fresh FPGAs (KFFs) in\nmachine learning-based detection, which is not a realistic approach. In this\npaper, we present a novel recycled FPGA detection method by examining the\nsymmetry information of the RO frequency using unsupervised anomaly detection\nmethod. Due to the symmetrical array structure of the FPGA, some adjacent logic\nblocks on an FPGA have comparable RO frequencies, hence our method simply\nanalyzes the RO frequencies of those blocks to determine how similar they are.\nThe proposed approach efficiently categorizes recycled FPGAs by utilizing\ndirect density ratio estimation through outliers detection. Experiments using\nXilinx Artix-7 FPGAs demonstrate that the proposed method accurately classifies\nrecycled FPGAs from 10 fresh FPGAs by x fewer computations compared with the\nconventional method.\n","authors":["Tanvir Ahmad Tarique","Foisal Ahmed","Maksim Jenihhin","Liakot Ali"],"pdf_url":"https://arxiv.org/pdf/2303.01807v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01806v1","updated":"2023-03-03T09:25:39Z","published":"2023-03-03T09:25:39Z","title":"When does Privileged Information Explain Away Label Noise?","summary":"  Leveraging privileged information (PI), or features available during training\nbut not at test time, has recently been shown to be an effective method for\naddressing label noise. However, the reasons for its effectiveness are not well\nunderstood. In this study, we investigate the role played by different\nproperties of the PI in explaining away label noise. Through experiments on\nmultiple datasets with real PI (CIFAR-N/H) and a new large-scale benchmark\nImageNet-PI, we find that PI is most helpful when it allows networks to easily\ndistinguish clean from noisy data, while enabling a learning shortcut to\nmemorize the noisy examples. Interestingly, when PI becomes too predictive of\nthe target label, PI methods often perform worse than their no-PI baselines.\nBased on these findings, we propose several enhancements to the\nstate-of-the-art PI methods and demonstrate the potential of PI as a means of\ntackling label noise. Finally, we show how we can easily combine the resulting\nPI approaches with existing no-PI techniques designed to deal with label noise.\n","authors":["Guillermo Ortiz-Jimenez","Mark Collier","Anant Nawalgaria","Alexander D'Amour","Jesse Berent","Rodolphe Jenatton","Effrosyni Kokiopoulou"],"pdf_url":"https://arxiv.org/pdf/2303.01806v1.pdf","comment":"22 pages, 14 figures, 7 tables"},{"id":"http://arxiv.org/abs/2303.01801v1","updated":"2023-03-03T09:17:53Z","published":"2023-03-03T09:17:53Z","title":"Reservoir computing based on solitary-like waves dynamics of film flows:\n  a proof of concept","summary":"  Several theoretical works have shown that solitons -- waves that\nself-maintain constant shape and velocity as they propagate -- can be used as a\nphysical computational reservoir, a concept where machine learning algorithms\ndesigned for digital computers are replaced by analog physical systems that\nexhibit nonlinear dynamical behaviour. Here we propose and experimentally\nvalidate a novel reservoir computing (RC) system that for the first time\nemploys solitary-like (SL) waves propagating on the surface of a liquid film\nflowing over an inclined surface. We demonstrate the ability of the SL wave RC\nsystem (SLRC) to forecast chaotic time series and to successfully pass\nessential benchmark tests, including a memory capacity test and a Mackey-Glass\nmodel test.\n","authors":["Ivan S. Maksymov","Andrey Pototsky"],"pdf_url":"https://arxiv.org/pdf/2303.01801v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.12342v2","updated":"2023-03-03T09:13:28Z","published":"2022-06-24T15:27:58Z","title":"FEATHERS: Federated Architecture and Hyperparameter Search","summary":"  Deep neural architectures have profound impact on achieved performance in\nmany of today's AI tasks, yet, their design still heavily relies on human prior\nknowledge and experience. Neural architecture search (NAS) together with\nhyperparameter optimization (HO) helps to reduce this dependence. However,\nstate of the art NAS and HO rapidly become infeasible with increasing amount of\ndata being stored in a distributed fashion, typically violating data privacy\nregulations such as GDPR and CCPA. As a remedy, we introduce FEATHERS -\n$\\textbf{FE}$derated $\\textbf{A}$rchi$\\textbf{T}$ecture and\n$\\textbf{H}$yp$\\textbf{ER}$parameter $\\textbf{S}$earch, a method that not only\noptimizes both neural architectures and optimization-related hyperparameters\njointly in distributed data settings, but further adheres to data privacy\nthrough the use of differential privacy (DP). We show that FEATHERS efficiently\noptimizes architectural and optimization-related hyperparameters alike, while\ndemonstrating convergence on classification tasks at no detriment to model\nperformance when complying with privacy constraints.\n","authors":["Jonas Seng","Pooja Prasad","Devendra Singh Dhami","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2206.12342v2.pdf","comment":"Main paper: 8 pages, References: 2 pages, Supplement: 4.5 pages, Main\n  paper: 3 figures, 2 tables, 1 algorithm, Supplement: 2 figure, 4 algorithms,\n  extended previous version by Differential Privacy, theoretical results and\n  more experiments"},{"id":"http://arxiv.org/abs/2303.01792v1","updated":"2023-03-03T09:06:35Z","published":"2023-03-03T09:06:35Z","title":"Graph-based Extreme Feature Selection for Multi-class Classification\n  Tasks","summary":"  When processing high-dimensional datasets, a common pre-processing step is\nfeature selection. Filter-based feature selection algorithms are not tailored\nto a specific classification method, but rather rank the relevance of each\nfeature with respect to the target and the task. This work focuses on a\ngraph-based, filter feature selection method that is suited for multi-class\nclassifications tasks. We aim to drastically reduce the number of selected\nfeatures, in order to create a sketch of the original data that codes valuable\ninformation for the classification task. The proposed graph-based algorithm is\nconstructed by combing the Jeffries-Matusita distance with a non-linear\ndimension reduction method, diffusion maps. Feature elimination is performed\nbased on the distribution of the features in the low-dimensional space. Then, a\nvery small number of feature that have complementary separation strengths, are\nselected. Moreover, the low-dimensional embedding allows to visualize the\nfeature space. Experimental results are provided for public datasets and\ncompared with known filter-based feature selection techniques.\n","authors":["Shir Friedman","Gonen Singer","Neta Rabin"],"pdf_url":"https://arxiv.org/pdf/2303.01792v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00515v3","updated":"2023-03-03T08:50:59Z","published":"2023-02-28T04:37:26Z","title":"Interpretable Water Level Forecaster with Spatiotemporal Causal\n  Attention Mechanisms","summary":"  Forecasting the water level of the Han river is important to control traffic\nand avoid natural disasters. There are many variables related to the Han river\nand they are intricately connected. In this work, we propose a novel\ntransformer that exploits the causal relationship based on the prior knowledge\namong the variables and forecasts the four bridges of the Han river: Cheongdam,\nJamsu, Hangang, and Haengju. Our proposed model considers both spatial and\ntemporal causation by formalizing the causal structure as a multilayer network\nand using masking methods. Due to this approach, we can have interpretability\nthat consistent with prior knowledge. In real data analysis, we use the Han\nriver dataset from 2016 to 2021 and compare the proposed model with deep\nlearning models.\n","authors":["Sunghcul Hong","Yunjin Choi","Jong-June Jeon"],"pdf_url":"https://arxiv.org/pdf/2303.00515v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.01900v2","updated":"2023-03-03T08:43:23Z","published":"2022-03-03T18:25:33Z","title":"Sparse Bayesian Optimization","summary":"  Bayesian optimization (BO) is a powerful approach to sample-efficient\noptimization of black-box objective functions. However, the application of BO\nto areas such as recommendation systems often requires taking the\ninterpretability and simplicity of the configurations into consideration, a\nsetting that has not been previously studied in the BO literature. To make BO\nuseful for this setting, we present several regularization-based approaches\nthat allow us to discover sparse and more interpretable configurations. We\npropose a novel differentiable relaxation based on homotopy continuation that\nmakes it possible to target sparsity by working directly with $L_0$\nregularization. We identify failure modes for regularized BO and develop a\nhyperparameter-free method, sparsity exploring Bayesian optimization (SEBO)\nthat seeks to simultaneously maximize a target objective and sparsity. SEBO and\nmethods based on fixed regularization are evaluated on synthetic and real-world\nproblems, and we show that we are able to efficiently optimize for sparsity.\n","authors":["Sulin Liu","Qing Feng","David Eriksson","Benjamin Letham","Eytan Bakshy"],"pdf_url":"https://arxiv.org/pdf/2203.01900v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01778v1","updated":"2023-03-03T08:36:35Z","published":"2023-03-03T08:36:35Z","title":"FedML Parrot: A Scalable Federated Learning System via\n  Heterogeneity-aware Scheduling on Sequential and Hierarchical Training","summary":"  Federated Learning (FL) enables collaborations among clients for train\nmachine learning models while protecting their data privacy. Existing FL\nsimulation platforms that are designed from the perspectives of traditional\ndistributed training, suffer from laborious code migration between simulation\nand production, low efficiency, low GPU utility, low scalability with high\nhardware requirements and difficulty of simulating stateful clients. In this\nwork, we firstly demystify the challenges and bottlenecks of simulating FL, and\ndesign a new FL system named as FedML \\texttt{Parrot}. It improves the training\nefficiency, remarkably relaxes the requirements on the hardware, and supports\nefficient large-scale FL experiments with stateful clients by: (1) sequential\ntraining clients on devices; (2) decomposing original aggregation into local\nand global aggregation on devices and server respectively; (3) scheduling tasks\nto mitigate straggler problems and enhance computing utility; (4) distributed\nclient state manager to support various FL algorithms. Besides, built upon our\ngeneric APIs and communication interfaces, users can seamlessly transform the\nsimulation into the real-world deployment without modifying codes. We evaluate\n\\texttt{Parrot} through extensive experiments for training diverse models on\nvarious FL datasets to demonstrate that \\texttt{Parrot} can achieve simulating\nover 1000 clients (stateful or stateless) with flexible GPU devices setting ($4\n\\sim 32$) and high GPU utility, 1.2 $\\sim$ 4 times faster than FedScale, and 10\n$\\sim$ 100 times memory saving than FedML. And we verify that \\texttt{Parrot}\nworks well with homogeneous and heterogeneous devices in three different\nclusters. Two FL algorithms with stateful clients and four algorithms with\nstateless clients are simulated to verify the wide adaptability of\n\\texttt{Parrot} to different algorithms.\n","authors":["Zhenheng Tang","Xiaowen Chu","Ryan Yide Ran","Sunwoo Lee","Shaohuai Shi","Yonggang Zhang","Yuxin Wang","Alex Qiaozhong Liang","Salman Avestimehr","Chaoyang He"],"pdf_url":"https://arxiv.org/pdf/2303.01778v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01775v1","updated":"2023-03-03T08:33:15Z","published":"2023-03-03T08:33:15Z","title":"Continual Causal Inference with Incremental Observational Data","summary":"  The era of big data has witnessed an increasing availability of observational\ndata from mobile and social networking, online advertising, web mining,\nhealthcare, education, public policy, marketing campaigns, and so on, which\nfacilitates the development of causal effect estimation. Although significant\nadvances have been made to overcome the challenges in the academic area, such\nas missing counterfactual outcomes and selection bias, they only focus on\nsource-specific and stationary observational data, which is unrealistic in most\nindustrial applications. In this paper, we investigate a new industrial problem\nof causal effect estimation from incrementally available observational data and\npresent three new evaluation criteria accordingly, including extensibility,\nadaptability, and accessibility. We propose a Continual Causal Effect\nRepresentation Learning method for estimating causal effects with observational\ndata, which are incrementally available from non-stationary data distributions.\nInstead of having access to all seen observational data, our method only stores\na limited subset of feature representations learned from previous data.\nCombining selective and balanced representation learning, feature\nrepresentation distillation, and feature transformation, our method achieves\nthe continual causal effect estimation for new data without compromising the\nestimation capability for original data. Extensive experiments demonstrate the\nsignificance of continual causal effect estimation and the effectiveness of our\nmethod.\n","authors":["Zhixuan Chu","Ruopeng Li","Stephen Rathbun","Sheng Li"],"pdf_url":"https://arxiv.org/pdf/2303.01775v1.pdf","comment":"The 39th IEEE International Conference on Data Engineering (ICDE\n  2023). arXiv admin note: text overlap with arXiv:2301.01026"},{"id":"http://arxiv.org/abs/2303.01774v1","updated":"2023-03-03T08:31:42Z","published":"2023-03-03T08:31:42Z","title":"Bayesian Optimization over High-Dimensional Combinatorial Spaces via\n  Dictionary-based Embeddings","summary":"  We consider the problem of optimizing expensive black-box functions over\nhigh-dimensional combinatorial spaces which arises in many science,\nengineering, and ML applications. We use Bayesian Optimization (BO) and propose\na novel surrogate modeling approach for efficiently handling a large number of\nbinary and categorical parameters. The key idea is to select a number of\ndiscrete structures from the input space (the dictionary) and use them to\ndefine an ordinal embedding for high-dimensional combinatorial structures. This\nallows us to use existing Gaussian process models for continuous spaces. We\ndevelop a principled approach based on binary wavelets to construct\ndictionaries for binary spaces, and propose a randomized construction method\nthat generalizes to categorical spaces. We provide theoretical justification to\nsupport the effectiveness of the dictionary-based embeddings. Our experiments\non diverse real-world benchmarks demonstrate the effectiveness of our proposed\nsurrogate modeling approach over state-of-the-art BO methods.\n","authors":["Aryan Deshwal","Sebastian Ament","Maximilian Balandat","Eytan Bakshy","Janardhan Rao Doppa","David Eriksson"],"pdf_url":"https://arxiv.org/pdf/2303.01774v1.pdf","comment":"Appearing in AISTATS 2023"},{"id":"http://arxiv.org/abs/2303.01772v1","updated":"2023-03-03T08:26:22Z","published":"2023-03-03T08:26:22Z","title":"Approximating Energy Market Clearing and Bidding With Model-Based\n  Reinforcement Learning","summary":"  Energy markets can provide incentives for undesired behavior of market\nparticipants. Multi-agent Reinforcement learning (MARL) is a promising new\napproach to determine the expected behavior of energy market participants.\nHowever, reinforcement learning requires many interactions with the system to\nconverge, and the power system environment often consists of extensive\ncomputations, e.g., optimal power flow (OPF) calculation for market clearing.\nTo tackle this complexity, we provide a model of the energy market to a basic\nMARL algorithm, in form of a learned OPF approximation and explicit market\nrules. The learned OPF surrogate model makes an explicit solving of the OPF\ncompletely unnecessary. Our experiments demonstrate that the model additionally\nreduces training time by about one order of magnitude, but at the cost of a\nslightly worse approximation of the Nash equilibrium. Potential applications of\nour method are market design, more realistic modeling of market participants,\nand analysis of manipulative behavior.\n","authors":["Thomas Wolgast","Astrid Nieße"],"pdf_url":"https://arxiv.org/pdf/2303.01772v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01770v1","updated":"2023-03-03T08:22:51Z","published":"2023-03-03T08:22:51Z","title":"Quantized Radio Map Estimation Using Tensor and Deep Generative Models","summary":"  Spectrum cartography (SC), also known as radio map estimation (RME), aims at\ncrafting multi-domain (e.g., frequency and space) radio power propagation maps\nfrom limited sensor measurements. While early methods often lacked theoretical\nsupport, recent works have demonstrated that radio maps can be provably\nrecovered using low-dimensional models -- such as the block-term tensor\ndecomposition (BTD) model and certain deep generative models (DGMs) -- of the\nhigh-dimensional multi-domain radio signals. However, these existing provable\nSC approaches assume that sensors send real-valued (full-resolution)\nmeasurements to the fusion center, which is unrealistic. This work puts forth a\nquantized SC framework that generalizes the BTD and DGM-based SC to scenarios\nwhere heavily quantized sensor measurements are used. A maximum likelihood\nestimation (MLE)-based SC framework under a Gaussian quantizer is proposed.\nRecoverability of the radio map using the MLE criterion are characterized under\nrealistic conditions, e.g., imperfect radio map modeling and noisy\nmeasurements. Simulations and real-data experiments are used to showcase the\neffectiveness of the proposed approach.\n","authors":["Subash Timilsina","Sagar Shrestha","Xiao Fu"],"pdf_url":"https://arxiv.org/pdf/2303.01770v1.pdf","comment":"16 pages, 9 figures"},{"id":"http://arxiv.org/abs/2303.01768v1","updated":"2023-03-03T08:17:57Z","published":"2023-03-03T08:17:57Z","title":"Toward Risk-based Optimistic Exploration for Cooperative Multi-Agent\n  Reinforcement Learning","summary":"  The multi-agent setting is intricate and unpredictable since the behaviors of\nmultiple agents influence one another. To address this environmental\nuncertainty, distributional reinforcement learning algorithms that incorporate\nuncertainty via distributional output have been integrated with multi-agent\nreinforcement learning (MARL) methods, achieving state-of-the-art performance.\nHowever, distributional MARL algorithms still rely on the traditional\n$\\epsilon$-greedy, which does not take cooperative strategy into account. In\nthis paper, we present a risk-based exploration that leads to collaboratively\noptimistic behavior by shifting the sampling region of distribution. Initially,\nwe take expectations from the upper quantiles of state-action values for\nexploration, which are optimistic actions, and gradually shift the sampling\nregion of quantiles to the full distribution for exploitation. By ensuring that\neach agent is exposed to the same level of risk, we can force them to take\ncooperatively optimistic actions. Our method shows remarkable performance in\nmulti-agent settings requiring cooperative exploration based on quantile\nregression appropriately controlling the level of risk.\n","authors":["Jihwan Oh","Joonkee Kim","Minchan Jeong","Se-Young Yun"],"pdf_url":"https://arxiv.org/pdf/2303.01768v1.pdf","comment":"AAMAS2023 camera-ready version. First two authors contributed equally"},{"id":"http://arxiv.org/abs/2303.01767v1","updated":"2023-03-03T08:17:47Z","published":"2023-03-03T08:17:47Z","title":"Implicit Stochastic Gradient Descent for Training Physics-informed\n  Neural Networks","summary":"  Physics-informed neural networks (PINNs) have effectively been demonstrated\nin solving forward and inverse differential equation problems, but they are\nstill trapped in training failures when the target functions to be approximated\nexhibit high-frequency or multi-scale features. In this paper, we propose to\nemploy implicit stochastic gradient descent (ISGD) method to train PINNs for\nimproving the stability of training process. We heuristically analyze how ISGD\novercome stiffness in the gradient flow dynamics of PINNs, especially for\nproblems with multi-scale solutions. We theoretically prove that for two-layer\nfully connected neural networks with large hidden nodes, randomly initialized\nISGD converges to a globally optimal solution for the quadratic loss function.\nEmpirical results demonstrate that ISGD works well in practice and compares\nfavorably to other gradient-based optimization methods such as SGD and Adam,\nwhile can also effectively address the numerical stiffness in training dynamics\nvia gradient descent.\n","authors":["Ye Li","Song-Can Chen","Sheng-Jun Huang"],"pdf_url":"https://arxiv.org/pdf/2303.01767v1.pdf","comment":"17 pages, published as a conference paper at AAAI23"},{"id":"http://arxiv.org/abs/2211.07138v2","updated":"2023-03-03T08:12:59Z","published":"2022-11-14T06:37:01Z","title":"Watermarking in Secure Federated Learning: A Verification Framework\n  Based on Client-Side Backdooring","summary":"  Federated learning (FL) allows multiple participants to collaboratively build\ndeep learning (DL) models without directly sharing data. Consequently, the\nissue of copyright protection in FL becomes important since unreliable\nparticipants may gain access to the jointly trained model. Application of\nhomomorphic encryption (HE) in secure FL framework prevents the central server\nfrom accessing plaintext models. Thus, it is no longer feasible to embed the\nwatermark at the central server using existing watermarking schemes. In this\npaper, we propose a novel client-side FL watermarking scheme to tackle the\ncopyright protection issue in secure FL with HE. To our best knowledge, it is\nthe first scheme to embed the watermark to models under the Secure FL\nenvironment. We design a black-box watermarking scheme based on client-side\nbackdooring to embed a pre-designed trigger set into an FL model by a\ngradient-enhanced embedding method. Additionally, we propose a trigger set\nconstruction mechanism to ensure the watermark cannot be forged. Experimental\nresults demonstrate that our proposed scheme delivers outstanding protection\nperformance and robustness against various watermark removal attacks and\nambiguity attack.\n","authors":["Wenyuan Yang","Shuo Shao","Yue Yang","Xiyao Liu","Ximeng Liu","Zhihua Xia","Gerald Schaefer","Hui Fang"],"pdf_url":"https://arxiv.org/pdf/2211.07138v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01758v1","updated":"2023-03-03T07:46:35Z","published":"2023-03-03T07:46:35Z","title":"SottoVoce: An Ultrasound Imaging-Based Silent Speech Interaction Using\n  Deep Neural Networks","summary":"  The availability of digital devices operated by voice is expanding rapidly.\nHowever, the applications of voice interfaces are still restricted. For\nexample, speaking in public places becomes an annoyance to the surrounding\npeople, and secret information should not be uttered. Environmental noise may\nreduce the accuracy of speech recognition. To address these limitations, a\nsystem to detect a user's unvoiced utterance is proposed. From internal\ninformation observed by an ultrasonic imaging sensor attached to the underside\nof the jaw, our proposed system recognizes the utterance contents without the\nuser's uttering voice. Our proposed deep neural network model is used to obtain\nacoustic features from a sequence of ultrasound images. We confirmed that audio\nsignals generated by our system can control the existing smart speakers. We\nalso observed that a user can adjust their oral movement to learn and improve\nthe accuracy of their voice recognition.\n","authors":["Naoki Kimura","Michinari Kono","Jun Rekimoto"],"pdf_url":"https://arxiv.org/pdf/2303.01758v1.pdf","comment":"ACM CHI 2019 paper"},{"id":"http://arxiv.org/abs/2302.08175v3","updated":"2023-03-03T07:45:52Z","published":"2023-02-16T09:44:55Z","title":"A numerical approximation method for the Fisher-Rao distance between\n  multivariate normal distributions","summary":"  We present a simple method to approximate Rao's distance between multivariate\nnormal distributions based on discretizing curves joining normal distributions\nand approximating Rao distances between successive nearby normal distributions\non the curve by Jeffreys divergence. We consider experimentally the linear\ninterpolation curves in the ordinary, natural and expectation parameterizations\nof the normal distributions, and compare these curves with a curve derived from\nthe Calvo and Oller's isometric embedding of the Fisher-Rao $d$-variate normal\nmanifold into the cone of $(d+1)\\times (d+1)$ symmetric positive-definite\nmatrices [Journal of multivariate analysis 35.2 (1990): 223-242]. We report on\nour experiments and assess the quality of our approximation technique by\ncomparing the numerical approximations with lower and upper bounds. Finally, we\npresent some information-geometric properties of the Calvo and Oller's\nisometric embedding.\n","authors":["Frank Nielsen"],"pdf_url":"https://arxiv.org/pdf/2302.08175v3.pdf","comment":"24 pages, 12 figures, 3 tables"},{"id":"http://arxiv.org/abs/2210.12458v2","updated":"2023-03-03T07:38:26Z","published":"2022-10-22T14:36:38Z","title":"Faster and more diverse de novo molecular optimization with double-loop\n  reinforcement learning using augmented SMILES","summary":"  Using generative deep learning models and reinforcement learning together can\neffectively generate new molecules with desired properties. By employing a\nmulti-objective scoring function, thousands of high-scoring molecules can be\ngenerated, making this approach useful for drug discovery and material science.\nHowever, the application of these methods can be hindered by computationally\nexpensive or time-consuming scoring procedures, particularly when a large\nnumber of function calls are required as feedback in the reinforcement learning\noptimization. Here, we propose the use of double-loop reinforcement learning\nwith simplified molecular line entry system (SMILES) augmentation to improve\nthe efficiency and speed of the optimization. By adding an inner loop that\naugments the generated SMILES strings to non-canonical SMILES for use in\nadditional reinforcement learning rounds, we can both reuse the scoring\ncalculations on the molecular level, thereby speeding up the learning process,\nas well as offer additional protection against mode collapse. We find that\nemploying between 5 and 10 augmentation repetitions is optimal for the scoring\nfunctions tested and is further associated with an increased diversity in the\ngenerated compounds, improved reproducibility of the sampling runs and the\ngeneration of molecules of higher similarity to known ligands.\n","authors":["Esben Jannik Bjerrum","Christian Margreitter","Thomas Blaschke","Raquel López-Ríos de Castro"],"pdf_url":"https://arxiv.org/pdf/2210.12458v2.pdf","comment":"25 pages and 18 Figures. Supplementary material included"},{"id":"http://arxiv.org/abs/2303.01751v1","updated":"2023-03-03T07:24:38Z","published":"2023-03-03T07:24:38Z","title":"Deep Momentum Multi-Marginal Schrödinger Bridge","summary":"  Reconstructing population dynamics using only samples from distributions at\ncoarse time intervals is a crucial challenge. Recent data-driven approaches\nsuch as flow-based models or Schr\\\"odinger Bridge models have demonstrated\nappealing performance, yet the inferred sample trajectories either fail to\naccount for the underlying stochasticity or are unnecessarily rigid. In this\narticle, we propose $\\underline{D}$eep $\\underline{M}$omentum Multi-Marginal\n$\\underline{S}$chr\\\"odinger $\\underline{B}$ridge(DMSB), a novel computational\nframework that learns the smooth measure-valued spline for stochastic systems\nwithout violating the position marginal constraints across time. We first\nextend the scalable mean matching objective used in the state space SB\nalgorithm into the phase space. We next carefully craft a multi-constraint\noptimization training method based on Bregman Iteration that enables effective\nphase space means matching training for the high-dimensional dataset. We\ndemonstrate that the resulting training algorithm significantly outperforms\nbaselines on both synthetic datasets and a real-world single-cell RNA sequence\ndataset.\n","authors":["Tianrong Chen","Guan-Horng Liu","Molei Tao","Evangelos A. Theodorou"],"pdf_url":"https://arxiv.org/pdf/2303.01751v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01748v1","updated":"2023-03-03T07:20:58Z","published":"2023-03-03T07:20:58Z","title":"Generative Diffusions in Augmented Spaces: A Complete Recipe","summary":"  Score-based Generative Models (SGMs) have achieved state-of-the-art synthesis\nresults on diverse tasks. However, the current design space of the forward\ndiffusion process is largely unexplored and often relies on physical intuition\nor simplifying assumptions. Leveraging results from the design of scalable\nBayesian posterior samplers, we present a complete recipe for constructing\nforward processes in SGMs, all of which are guaranteed to converge to the\ntarget distribution of interest. We show that several existing SGMs can be cast\nas specific instantiations of this parameterization. Furthermore, building on\nthis recipe, we construct a novel SGM: Phase Space Langevin Diffusion (PSLD),\nwhich performs score-based modeling in a space augmented with auxiliary\nvariables akin to a physical phase space. We show that PSLD outperforms\ncompeting baselines in terms of sample quality and the speed-vs-quality\ntradeoff across different samplers on various standard image synthesis\nbenchmarks. Moreover, we show that PSLD achieves sample quality comparable to\nstate-of-the-art SGMs (FID: 2.10 on unconditional CIFAR-10 generation),\nproviding an attractive alternative as an SGM backbone for further development.\nWe will publish our code and model checkpoints for reproducibility at\nhttps://github.com/mandt-lab/PSLD.\n","authors":["Kushagra Pandey","Stephan Mandt"],"pdf_url":"https://arxiv.org/pdf/2303.01748v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01745v1","updated":"2023-03-03T07:17:09Z","published":"2023-03-03T07:17:09Z","title":"Queue Scheduling with Adversarial Bandit Learning","summary":"  In this paper, we study scheduling of a queueing system with zero knowledge\nof instantaneous network conditions. We consider a one-hop single-server\nqueueing system consisting of $K$ queues, each with time-varying and\nnon-stationary arrival and service rates. Our scheduling approach builds on an\ninnovative combination of adversarial bandit learning and Lyapunov drift\nminimization, without knowledge of the instantaneous network state (the arrival\nand service rates) of each queue. We then present two novel algorithms\n\\texttt{SoftMW} (SoftMaxWeight) and \\texttt{SSMW} (Sliding-window\nSoftMaxWeight), both capable of stabilizing systems that can be stablized by\nsome (possibly unknown) sequence of randomized policies whose time-variation\nsatisfies a mild condition. We further generalize our results to the setting\nwhere arrivals and departures only have bounded moments instead of being\ndeterministically bounded and propose \\texttt{SoftMW+} and \\texttt{SSMW+} that\nare capable of stabilizing the system. As a building block of our new\nalgorithms, we also extend the classical \\texttt{EXP3.S} (Auer et al., 2002)\nalgorithm for multi-armed bandits to handle unboundedly large feedback signals,\nwhich can be of independent interest.\n","authors":["Jiatai Huang","Leana Golubchik","Longbo Huang"],"pdf_url":"https://arxiv.org/pdf/2303.01745v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2112.15319v3","updated":"2023-03-03T07:11:25Z","published":"2021-12-31T06:34:32Z","title":"A Critical Review of Inductive Logic Programming Techniques for\n  Explainable AI","summary":"  Despite recent advances in modern machine learning algorithms, the opaqueness\nof their underlying mechanisms continues to be an obstacle in adoption. To\ninstill confidence and trust in artificial intelligence systems, Explainable\nArtificial Intelligence has emerged as a response to improving modern machine\nlearning algorithms' explainability. Inductive Logic Programming (ILP), a\nsubfield of symbolic artificial intelligence, plays a promising role in\ngenerating interpretable explanations because of its intuitive logic-driven\nframework. ILP effectively leverages abductive reasoning to generate\nexplainable first-order clausal theories from examples and background\nknowledge. However, several challenges in developing methods inspired by ILP\nneed to be addressed for their successful application in practice. For example,\nexisting ILP systems often have a vast solution space, and the induced\nsolutions are very sensitive to noises and disturbances. This survey paper\nsummarizes the recent advances in ILP and a discussion of statistical\nrelational learning and neural-symbolic algorithms, which offer synergistic\nviews to ILP. Following a critical review of the recent advances, we delineate\nobserved challenges and highlight potential avenues of further ILP-motivated\nresearch toward developing self-explanatory artificial intelligence systems.\n","authors":["Zheng Zhang","Liangliang Xu","Levent Yilmaz","Bo Liu"],"pdf_url":"https://arxiv.org/pdf/2112.15319v3.pdf","comment":"arXiv admin note: text overlap with arXiv:1907.10952 by other authors"},{"id":"http://arxiv.org/abs/2303.01739v1","updated":"2023-03-03T06:54:01Z","published":"2023-03-03T06:54:01Z","title":"Study of Distractors in Neural Models of Code","summary":"  Finding important features that contribute to the prediction of neural models\nis an active area of research in explainable AI. Neural models are opaque and\nfinding such features sheds light on a better understanding of their\npredictions. In contrast, in this work, we present an inverse perspective of\ndistractor features: features that cast doubt about the prediction by affecting\nthe model's confidence in its prediction. Understanding distractors provide a\ncomplementary view of the features' relevance in the predictions of neural\nmodels. In this paper, we apply a reduction-based technique to find distractors\nand provide our preliminary results of their impacts and types. Our experiments\nacross various tasks, models, and datasets of code reveal that the removal of\ntokens can have a significant impact on the confidence of models in their\npredictions and the categories of tokens can also play a vital role in the\nmodel's confidence. Our study aims to enhance the transparency of models by\nemphasizing those tokens that significantly influence the confidence of the\nmodels.\n","authors":["Md Rafiqul Islam Rabin","Aftab Hussain","Sahil Suneja","Mohammad Amin Alipour"],"pdf_url":"https://arxiv.org/pdf/2303.01739v1.pdf","comment":"The 1st International Workshop on Interpretability and Robustness in\n  Neural Software Engineering, Co-located with ICSE (InteNSE'23)"},{"id":"http://arxiv.org/abs/2302.11184v2","updated":"2023-03-03T06:51:27Z","published":"2023-02-22T07:39:09Z","title":"A residual dense vision transformer for medical image super-resolution\n  with segmentation-based perceptual loss fine-tuning","summary":"  Super-resolution plays an essential role in medical imaging because it\nprovides an alternative way to achieve high spatial resolutions and image\nquality with no extra acquisition costs. In the past few decades, the rapid\ndevelopment of deep neural networks has promoted super-resolution performance\nwith novel network architectures, loss functions and evaluation metrics.\nSpecifically, vision transformers dominate a broad range of computer vision\ntasks, but challenges still exist when applying them to low-level medical image\nprocessing tasks. This paper proposes an efficient vision transformer with\nresidual dense connections and local feature fusion to achieve efficient\nsingle-image super-resolution (SISR) of medical modalities. Moreover, we\nimplement a general-purpose perceptual loss with manual control for image\nquality improvements of desired aspects by incorporating prior knowledge of\nmedical image segmentation. Compared with state-of-the-art methods on four\npublic medical image datasets, the proposed method achieves the best PSNR\nscores of 6 modalities among seven modalities. It leads to an average\nimprovement of $+0.09$ dB PSNR with only 38\\% parameters of SwinIR. On the\nother hand, the segmentation-based perceptual loss increases $+0.14$ dB PSNR on\naverage for SOTA methods, including CNNs and vision transformers. Additionally,\nwe conduct comprehensive ablation studies to discuss potential factors for the\nsuperior performance of vision transformers over CNNs and the impacts of\nnetwork and loss function components. The code will be released on GitHub with\nthe paper published.\n","authors":["Jin Zhu","Guang Yang","Pietro Lio"],"pdf_url":"https://arxiv.org/pdf/2302.11184v2.pdf","comment":"Preprint submitted to Medical Image Analysis and under review"},{"id":"http://arxiv.org/abs/2303.01728v1","updated":"2023-03-03T06:24:04Z","published":"2023-03-03T06:24:04Z","title":"Guarded Policy Optimization with Imperfect Online Demonstrations","summary":"  The Teacher-Student Framework (TSF) is a reinforcement learning setting where\na teacher agent guards the training of a student agent by intervening and\nproviding online demonstrations. Assuming optimal, the teacher policy has the\nperfect timing and capability to intervene in the learning process of the\nstudent agent, providing safety guarantee and exploration guidance.\nNevertheless, in many real-world settings it is expensive or even impossible to\nobtain a well-performing teacher policy. In this work, we relax the assumption\nof a well-performing teacher and develop a new method that can incorporate\narbitrary teacher policies with modest or inferior performance. We instantiate\nan Off-Policy Reinforcement Learning algorithm, termed Teacher-Student Shared\nControl (TS2C), which incorporates teacher intervention based on\ntrajectory-based value estimation. Theoretical analysis validates that the\nproposed TS2C algorithm attains efficient exploration and substantial safety\nguarantee without being affected by the teacher's own performance. Experiments\non various continuous control tasks show that our method can exploit teacher\npolicies at different performance levels while maintaining a low training cost.\nMoreover, the student policy surpasses the imperfect teacher policy in terms of\nhigher accumulated reward in held-out testing environments. Code is available\nat https://metadriverse.github.io/TS2C.\n","authors":["Zhenghai Xue","Zhenghao Peng","Quanyi Li","Zhihan Liu","Bolei Zhou"],"pdf_url":"https://arxiv.org/pdf/2303.01728v1.pdf","comment":"Accepted at ICLR 2023 (top 25%)"},{"id":"http://arxiv.org/abs/2207.00594v2","updated":"2023-03-03T06:15:49Z","published":"2022-07-01T15:32:56Z","title":"Time-aware Dynamic Graph Embedding for Asynchronous Structural Evolution","summary":"  Dynamic graphs refer to graphs whose structure dynamically changes over time.\nDespite the benefits of learning vertex representations (i.e., embeddings) for\ndynamic graphs, existing works merely view a dynamic graph as a sequence of\nchanges within the vertex connections, neglecting the crucial asynchronous\nnature of such dynamics where the evolution of each local structure starts at\ndifferent times and lasts for various durations. To maintain asynchronous\nstructural evolutions within the graph, we innovatively formulate dynamic\ngraphs as temporal edge sequences associated with joining time of vertices\n(ToV) and timespan of edges (ToE). Then, a time-aware Transformer is proposed\nto embed vertices' dynamic connections and ToEs into the learned vertex\nrepresentations. Meanwhile, we treat each edge sequence as a whole and embed\nits ToV of the first vertex to further encode the time-sensitive information.\nExtensive evaluations on several datasets show that our approach outperforms\nthe state-of-the-art in a wide range of graph mining tasks. At the same time,\nit is very efficient and scalable for embedding large-scale dynamic graphs.\n","authors":["Yu Yang","Hongzhi Yin","Jiannong Cao","Tong Chen","Quoc Viet Hung Nguyen","Xiaofang Zhou","Lei Chen"],"pdf_url":"https://arxiv.org/pdf/2207.00594v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2103.15532v2","updated":"2023-03-03T06:15:27Z","published":"2021-03-29T12:02:47Z","title":"Learning on heterogeneous graphs using high-order relations","summary":"  A heterogeneous graph consists of different vertices and edges types.\nLearning on heterogeneous graphs typically employs meta-paths to deal with the\nheterogeneity by reducing the graph to a homogeneous network, guide random\nwalks or capture semantics. These methods are however sensitive to the choice\nof meta-paths, with suboptimal paths leading to poor performance. In this\npaper, we propose an approach for learning on heterogeneous graphs without\nusing meta-paths. Specifically, we decompose a heterogeneous graph into\ndifferent homogeneous relation-type graphs, which are then combined to create\nhigher-order relation-type representations. These representations preserve the\nheterogeneity of edges and retain their edge directions while capturing the\ninteraction of different vertex types multiple hops apart. This is then\ncomplemented with attention mechanisms to distinguish the importance of the\nrelation-type based neighbors and the relation-types themselves. Experiments\ndemonstrate that our model generally outperforms other state-of-the-art\nbaselines in the vertex classification task on three commonly studied\nheterogeneous graph datasets.\n","authors":["See Hian Lee","Feng Ji","Wee Peng Tay"],"pdf_url":"https://arxiv.org/pdf/2103.15532v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01724v1","updated":"2023-03-03T06:04:42Z","published":"2023-03-03T06:04:42Z","title":"Node-Specific Space Selection via Localized Geometric Hyperbolicity in\n  Graph Neural Networks","summary":"  Many graph neural networks have been developed to learn graph representations\nin either Euclidean or hyperbolic space, with all nodes' representations\nembedded in a single space. However, a graph can have hyperbolic and Euclidean\ngeometries at different regions of the graph. Thus, it is sub-optimal to\nindifferently embed an entire graph into a single space. In this paper, we\nexplore and analyze two notions of local hyperbolicity, describing the\nunderlying local geometry: geometric (Gromov) and model-based, to determine the\npreferred space of embedding for each node. The two hyperbolicities'\ndistributions are aligned using the Wasserstein metric such that the calculated\ngeometric hyperbolicity guides the choice of the learned model hyperbolicity.\nAs such our model Joint Space Graph Neural Network (JSGNN) can leverage both\nEuclidean and hyperbolic spaces during learning by allowing node-specific\ngeometry space selection. We evaluate our model on both node classification and\nlink prediction tasks and observe promising performance compared to baseline\nmodels.\n","authors":["See Hian Lee","Feng Ji","Wee Peng Tay"],"pdf_url":"https://arxiv.org/pdf/2303.01724v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.11329v2","updated":"2023-03-03T05:44:48Z","published":"2023-02-22T12:25:07Z","title":"HINormer: Representation Learning On Heterogeneous Information Networks\n  with Graph Transformer","summary":"  Recent studies have highlighted the limitations of message-passing based\ngraph neural networks (GNNs), e.g., limited model expressiveness,\nover-smoothing, over-squashing, etc. To alleviate these issues, Graph\nTransformers (GTs) have been proposed which work in the paradigm that allows\nmessage passing to a larger coverage even across the whole graph. Hinging on\nthe global range attention mechanism, GTs have shown a superpower for\nrepresentation learning on homogeneous graphs. However, the investigation of\nGTs on heterogeneous information networks (HINs) is still under-exploited. In\nparticular, on account of the existence of heterogeneity, HINs show distinct\ndata characteristics and thus require different treatment. To bridge this gap,\nin this paper we investigate the representation learning on HINs with Graph\nTransformer, and propose a novel model named HINormer, which capitalizes on a\nlarger-range aggregation mechanism for node representation learning. In\nparticular, assisted by two major modules, i.e., a local structure encoder and\na heterogeneous relation encoder, HINormer can capture both the structural and\nheterogeneous information of nodes on HINs for comprehensive node\nrepresentations. We conduct extensive experiments on four HIN benchmark\ndatasets, which demonstrate that our proposed model can outperform the\nstate-of-the-art.\n","authors":["Qiheng Mao","Zemin Liu","Chenghao Liu","Jianling Sun"],"pdf_url":"https://arxiv.org/pdf/2302.11329v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.07261v2","updated":"2023-03-03T05:40:21Z","published":"2023-02-14T18:57:04Z","title":"Where to Diffuse, How to Diffuse, and How to Get Back: Automated\n  Learning for Multivariate Diffusions","summary":"  Diffusion-based generative models (DBGMs) perturb data to a target noise\ndistribution and reverse this process to generate samples. The choice of\nnoising process, or inference diffusion process, affects both likelihoods and\nsample quality. For example, extending the inference process with auxiliary\nvariables leads to improved sample quality. While there are many such\nmultivariate diffusions to explore, each new one requires significant\nmodel-specific analysis, hindering rapid prototyping and evaluation. In this\nwork, we study Multivariate Diffusion Models (MDMs). For any number of\nauxiliary variables, we provide a recipe for maximizing a lower-bound on the\nMDMs likelihood without requiring any model-specific analysis. We then\ndemonstrate how to parameterize the diffusion for a specified target noise\ndistribution; these two points together enable optimizing the inference\ndiffusion process. Optimizing the diffusion expands easy experimentation from\njust a few well-known processes to an automatic search over all linear\ndiffusions. To demonstrate these ideas, we introduce two new specific\ndiffusions as well as learn a diffusion process on the MNIST, CIFAR10, and\nImageNet32 datasets. We show learned MDMs match or surpass bits-per-dims (BPDs)\nrelative to fixed choices of diffusions for a given dataset and model\narchitecture.\n","authors":["Raghav Singhal","Mark Goldstein","Rajesh Ranganath"],"pdf_url":"https://arxiv.org/pdf/2302.07261v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01105v2","updated":"2023-03-03T05:39:15Z","published":"2023-03-02T09:37:56Z","title":"Evidence-empowered Transfer Learning for Alzheimer's Disease","summary":"  Transfer learning has been widely utilized to mitigate the data scarcity\nproblem in the field of Alzheimer's disease (AD). Conventional transfer\nlearning relies on re-using models trained on AD-irrelevant tasks such as\nnatural image classification. However, it often leads to negative transfer due\nto the discrepancy between the non-medical source and target medical domains.\nTo address this, we present evidence-empowered transfer learning for AD\ndiagnosis. Unlike conventional approaches, we leverage an AD-relevant auxiliary\ntask, namely morphological change prediction, without requiring additional MRI\ndata. In this auxiliary task, the diagnosis model learns the evidential and\ntransferable knowledge from morphological features in MRI scans. Experimental\nresults demonstrate that our framework is not only effective in improving\ndetection performance regardless of model capacity, but also more\ndata-efficient and faithful.\n","authors":["Kai Tzu-iunn Ong","Hana Kim","Minjin Kim","Jinseong Jang","Beomseok Sohn","Yoon Seong Choi","Dosik Hwang","Seong Jae Hwang","Jinyoung Yeo"],"pdf_url":"https://arxiv.org/pdf/2303.01105v2.pdf","comment":"Accepted to IEEE International Symposium on Biomedical Imaging (ISBI)\n  2023"},{"id":"http://arxiv.org/abs/2207.12534v3","updated":"2023-03-03T05:39:11Z","published":"2022-07-25T21:15:47Z","title":"Trainability Preserving Neural Pruning","summary":"  Many recent works have shown trainability plays a central role in neural\nnetwork pruning -- unattended broken trainability can lead to severe\nunder-performance and unintentionally amplify the effect of retraining learning\nrate, resulting in biased (or even misinterpreted) benchmark results. This\npaper introduces trainability preserving pruning (TPP), a scalable method to\npreserve network trainability against pruning, aiming for improved pruning\nperformance and being more robust to retraining hyper-parameters (e.g.,\nlearning rate). Specifically, we propose to penalize the gram matrix of\nconvolutional filters to decorrelate the pruned filters from the retained\nfilters. In addition to the convolutional layers, per the spirit of preserving\nthe trainability of the whole network, we also propose to regularize the batch\nnormalization parameters (scale and bias). Empirical studies on linear MLP\nnetworks show that TPP can perform on par with the oracle trainability recovery\nscheme. On nonlinear ConvNets (ResNet56/VGG19) on CIFAR10/100, TPP outperforms\nthe other counterpart approaches by an obvious margin. Moreover, results on\nImageNet-1K with ResNets suggest that TPP consistently performs more favorably\nagainst other top-performing structured pruning approaches. Code:\nhttps://github.com/MingSun-Tse/TPP.\n","authors":["Huan Wang","Yun Fu"],"pdf_url":"https://arxiv.org/pdf/2207.12534v3.pdf","comment":"ICLR'23 Camera Ready. 21 Pages. Code:\n  https://github.com/MingSun-Tse/TPP"},{"id":"http://arxiv.org/abs/2303.01713v1","updated":"2023-03-03T05:07:02Z","published":"2023-03-03T05:07:02Z","title":"Convex Bounds on the Softmax Function with Applications to Robustness\n  Verification","summary":"  The softmax function is a ubiquitous component at the output of neural\nnetworks and increasingly in intermediate layers as well. This paper provides\nconvex lower bounds and concave upper bounds on the softmax function, which are\ncompatible with convex optimization formulations for characterizing neural\nnetworks and other ML models. We derive bounds using both a natural\nexponential-reciprocal decomposition of the softmax as well as an alternative\ndecomposition in terms of the log-sum-exp function. The new bounds are provably\nand/or numerically tighter than linear bounds obtained in previous work on\nrobustness verification of transformers. As illustrations of the utility of the\nbounds, we apply them to verification of transformers as well as of the\nrobustness of predictive uncertainty estimates of deep ensembles.\n","authors":["Dennis Wei","Haoze Wu","Min Wu","Pin-Yu Chen","Clark Barrett","Eitan Farchi"],"pdf_url":"https://arxiv.org/pdf/2303.01713v1.pdf","comment":"AISTATS 2023"},{"id":"http://arxiv.org/abs/2303.01711v1","updated":"2023-03-03T04:59:03Z","published":"2023-03-03T04:59:03Z","title":"NovPhy: A Testbed for Physical Reasoning in Open-world Environments","summary":"  Due to the emergence of AI systems that interact with the physical\nenvironment, there is an increased interest in incorporating physical reasoning\ncapabilities into those AI systems. But is it enough to only have physical\nreasoning capabilities to operate in a real physical environment? In the real\nworld, we constantly face novel situations we have not encountered before. As\nhumans, we are competent at successfully adapting to those situations.\nSimilarly, an agent needs to have the ability to function under the impact of\nnovelties in order to properly operate in an open-world physical environment.\nTo facilitate the development of such AI systems, we propose a new testbed,\nNovPhy, that requires an agent to reason about physical scenarios in the\npresence of novelties and take actions accordingly. The testbed consists of\ntasks that require agents to detect and adapt to novelties in physical\nscenarios. To create tasks in the testbed, we develop eight novelties\nrepresenting a diverse novelty space and apply them to five commonly\nencountered scenarios in a physical environment. According to our testbed\ndesign, we evaluate two capabilities of an agent: the performance on a novelty\nwhen it is applied to different physical scenarios and the performance on a\nphysical scenario when different novelties are applied to it. We conduct a\nthorough evaluation with human players, learning agents, and heuristic agents.\nOur evaluation shows that humans' performance is far beyond the agents'\nperformance. Some agents, even with good normal task performance, perform\nsignificantly worse when there is a novelty, and the agents that can adapt to\nnovelties typically adapt slower than humans. We promote the development of\nintelligent agents capable of performing at the human level or above when\noperating in open-world physical environments. Testbed website:\nhttps://github.com/phy-q/novphy\n","authors":["Chathura Gamage","Vimukthini Pinto","Cheng Xue","Peng Zhang","Ekaterina Nikonova","Matthew Stephenson","Jochen Renz"],"pdf_url":"https://arxiv.org/pdf/2303.01711v1.pdf","comment":"Testbed website: https://github.com/phy-q/novphy"},{"id":"http://arxiv.org/abs/2301.10871v2","updated":"2023-03-03T04:54:25Z","published":"2023-01-25T23:32:32Z","title":"Qualitative Analysis of a Graph Transformer Approach to Addressing Hate\n  Speech: Adapting to Dynamically Changing Content","summary":"  Our work advances an approach for predicting hate speech in social media,\ndrawing out the critical need to consider the discussions that follow a post to\nsuccessfully detect when hateful discourse may arise. Using graph transformer\nnetworks, coupled with modelling attention and BERT-level natural language\nprocessing, our approach can capture context and anticipate upcoming\nanti-social behaviour. In this paper, we offer a detailed qualitative analysis\nof this solution for hate speech detection in social networks, leading to\ninsights into where the method has the most impressive outcomes in comparison\nwith competitors and identifying scenarios where there are challenges to\nachieving ideal performance. Included is an exploration of the kinds of posts\nthat permeate social media today, including the use of hateful images. This\nsuggests avenues for extending our model to be more comprehensive. A key\ninsight is that the focus on reasoning about the concept of context positions\nus well to be able to support multi-modal analysis of online posts. We conclude\nwith a reflection on how the problem we are addressing relates especially well\nto the theme of dynamic change, a critical concern for all AI solutions for\nsocial impact. We also comment briefly on how mental health well-being can be\nadvanced with our work, through curated content attuned to the extent of hate\nin posts.\n","authors":["Liam Hebert","Hong Yi Chen","Robin Cohen","Lukasz Golab"],"pdf_url":"https://arxiv.org/pdf/2301.10871v2.pdf","comment":"Accepted at AAAI 2023 AI for Social Good"},{"id":"http://arxiv.org/abs/2207.14502v3","updated":"2023-03-03T04:50:46Z","published":"2022-07-29T06:43:28Z","title":"Language Models Can Teach Themselves to Program Better","summary":"  Recent Language Models (LMs) achieve breakthrough performance in code\ngeneration when trained on human-authored problems, even solving some\ncompetitive-programming problems. Self-play has proven useful in games such as\nGo, and thus it is natural to ask whether LMs can generate their own\ninstructive programming problems to improve their performance. We show that it\nis possible for an LM to synthesize programming problems and solutions, which\nare filtered for correctness by a Python interpreter. The LM's performance is\nthen seen to improve when it is fine-tuned on its own synthetic problems and\nverified solutions; thus the model 'improves itself' using the Python\ninterpreter. Problems are specified formally as programming puzzles [Schuster\net al., 2021], a code-based problem format where solutions can easily be\nverified for correctness by execution. In experiments on publicly-available\nLMs, test accuracy more than doubles. This work demonstrates the potential for\ncode LMs, with an interpreter, to generate instructive problems and improve\ntheir own performance.\n","authors":["Patrick Haluptzok","Matthew Bowers","Adam Tauman Kalai"],"pdf_url":"https://arxiv.org/pdf/2207.14502v3.pdf","comment":"22 pages, 14 figures"},{"id":"http://arxiv.org/abs/2111.07684v3","updated":"2023-03-03T04:49:16Z","published":"2021-11-15T11:37:47Z","title":"AutoGMap: Learning to Map Large-scale Sparse Graphs on Memristive\n  Crossbars","summary":"  The sparse representation of graphs has shown great potential for\naccelerating the computation of graph applications (e.g., Social Networks,\nKnowledge Graphs) on traditional computing architectures (CPU, GPU, or TPU).\nBut the exploration of large-scale sparse graph computing on\nprocessing-in-memory (PIM) platforms (typically with memristive crossbars) is\nstill in its infancy. To implement the computation or storage of large-scale or\nbatch graphs on memristive crossbars, a natural assumption is that a\nlarge-scale crossbar is demanded, but with low utilization. Some recent works\nquestion this assumption, to avoid the waste of storage and computational\nresource, the fixed-size or progressively scheduled ''block partition'' schemes\nare proposed. However, these methods are coarse-grained or static, and are not\neffectively sparsity-aware. This work proposes the dynamic sparsity-aware\nmapping scheme generating method that models the problem with a sequential\ndecision-making model, and optimizes it by reinforcement learning (RL)\nalgorithm (REINFORCE). Our generating model (LSTM, combined with the\ndynamic-fill scheme) generates remarkable mapping performance on a small-scale\ngraph/matrix data (complete mapping costs 43% area of the original matrix) and\ntwo large-scale matrix data (costing 22.5% area on qh882 and 17.1% area on\nqh1484). Our method may be extended to sparse graph computing on other PIM\narchitectures, not limited to the memristive device-based platforms.\n","authors":["Bo Lyu","Shengbo Wang","Shiping Wen","Kaibo Shi","Yin Yang","Lingfang Zeng","Tingwen Huang"],"pdf_url":"https://arxiv.org/pdf/2111.07684v3.pdf","comment":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible"},{"id":"http://arxiv.org/abs/2303.01709v1","updated":"2023-03-03T04:39:53Z","published":"2023-03-03T04:39:53Z","title":"Streaming Algorithms for Learning with Experts: Deterministic Versus\n  Robust","summary":"  In the online learning with experts problem, an algorithm must make a\nprediction about an outcome on each of $T$ days (or times), given a set of $n$\nexperts who make predictions on each day (or time). The algorithm is given\nfeedback on the outcomes of each day, including the cost of its prediction and\nthe cost of the expert predictions, and the goal is to make a prediction with\nthe minimum cost, specifically compared to the best expert in the set. Recent\nwork by Srinivas, Woodruff, Xu, and Zhou (STOC 2022) introduced the study of\nthe online learning with experts problem under memory constraints.\n  However, often the predictions made by experts or algorithms at some time\ninfluence future outcomes, so that the input is adaptively chosen. Whereas\ndeterministic algorithms would be robust to adaptive inputs, existing\nalgorithms all crucially use randomization to sample a small number of experts.\n  In this paper, we study deterministic and robust algorithms for the experts\nproblem. We first show a space lower bound of\n$\\widetilde{\\Omega}\\left(\\frac{nM}{RT}\\right)$ for any deterministic algorithm\nthat achieves regret $R$ when the best expert makes $M$ mistakes. Our result\nshows that the natural deterministic algorithm, which iterates through pools of\nexperts until each expert in the pool has erred, is optimal up to\npolylogarithmic factors. On the positive side, we give a randomized algorithm\nthat is robust to adaptive inputs that uses\n$\\widetilde{O}\\left(\\frac{n}{R\\sqrt{T}}\\right)$ space for $M=O\\left(\\frac{R^2\nT}{\\log^2 n}\\right)$, thereby showing a smooth space-regret trade-off.\n","authors":["David P. Woodruff","Fred Zhang","Samson Zhou"],"pdf_url":"https://arxiv.org/pdf/2303.01709v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.01342v3","updated":"2023-03-03T04:34:17Z","published":"2022-06-02T23:52:35Z","title":"Understanding the Role of Nonlinearity in Training Dynamics of\n  Contrastive Learning","summary":"  While the empirical success of self-supervised learning (SSL) heavily relies\non the usage of deep nonlinear models, existing theoretical works on SSL\nunderstanding still focus on linear ones. In this paper, we study the role of\nnonlinearity in the training dynamics of contrastive learning (CL) on one and\ntwo-layer nonlinear networks with homogeneous activation $h(x) = h'(x)x$. We\nhave two major theoretical discoveries. First, the presence of nonlinearity can\nlead to many local optima even in 1-layer setting, each corresponding to\ncertain patterns from the data distribution, while with linear activation, only\none major pattern can be learned. This suggests that models with lots of\nparameters can be regarded as a \\emph{brute-force} way to find these local\noptima induced by nonlinearity. Second, in the 2-layer case, linear activation\nis proven not capable of learning specialized weights into diverse patterns,\ndemonstrating the importance of nonlinearity. In addition, for 2-layer setting,\nwe also discover \\emph{global modulation}: those local patterns discriminative\nfrom the perspective of global-level patterns are prioritized to learn, further\ncharacterizing the learning process. Simulation verifies our theoretical\nfindings.\n","authors":["Yuandong Tian"],"pdf_url":"https://arxiv.org/pdf/2206.01342v3.pdf","comment":"ICLR'23 camera ready"},{"id":"http://arxiv.org/abs/2303.01704v1","updated":"2023-03-03T04:12:04Z","published":"2023-03-03T04:12:04Z","title":"Model Explanation Disparities as a Fairness Diagnostic","summary":"  In recent years, there has been a flurry of research focusing on the fairness\nof machine learning models, and in particular on quantifying and eliminating\nbias against subgroups. One prominent line of work generalizes the notion of\nsubgroups beyond simple discrete classes by introducing the notion of a \"rich\nsubgroup,\" and seeks to train models that are calibrated or equalize error\nrates with respect to these richer subgroup classes. Largely orthogonally,\nthere has been growing recognition of the importance of understanding how\nsubgroups of the dataset are being treated relative to the rest of the dataset.\nIt can easily be shown that certain training features may be significantly more\nimportant (or less important) on a discrete subgroup compared to the whole\ndataset with this difference being called Feature Importance Disparity (FID).\nHowever, there are an exponentially large number of rich subgroups defined by a\nstructured class of functions over protected features (such as race, gender,\nage, etc.) and there are many ways that feature importance can be defined. In\nthis paper, we develop two approaches to efficiently search the rich subgroup\nspace and find feature/subgroup pairs with large FID that fit within a\nspecified subgroup size. The first approach considers feature importance\nmetrics which are separable and models a two-player, zero-sum game to reduce\nthe computation of subgroups with high FID of constrained size to a\ncost-sensitive classification problem. The second approach considers\nnon-separable importance metrics and uses heuristic optimization techniques to\nconverge on the subgroups. Both of these approaches were tested on 4 different\ndatasets with multiple importance notions and found feature/subgroup pairs that\nhad high FID, often by orders of magnitude, and yield interesting discussions\nabout the reliability and fairness of the datasets.\n","authors":["Peter W. Chang","Leor Fishman","Seth Neel"],"pdf_url":"https://arxiv.org/pdf/2303.01704v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01693v1","updated":"2023-03-03T03:17:53Z","published":"2023-03-03T03:17:53Z","title":"Cross-domain Transfer Learning and State Inference for Soft Robots via a\n  Semi-supervised Sequential Variational Bayes Framework","summary":"  Recently, data-driven models such as deep neural networks have shown to be\npromising tools for modelling and state inference in soft robots. However,\nvoluminous amounts of data are necessary for deep models to perform\neffectively, which requires exhaustive and quality data collection,\nparticularly of state labels. Consequently, obtaining labelled state data for\nsoft robotic systems is challenged for various reasons, including difficulty in\nthe sensorization of soft robots and the inconvenience of collecting data in\nunstructured environments. To address this challenge, in this paper, we propose\na semi-supervised sequential variational Bayes (DSVB) framework for transfer\nlearning and state inference in soft robots with missing state labels on\ncertain robot configurations. Considering that soft robots may exhibit distinct\ndynamics under different robot configurations, a feature space transfer\nstrategy is also incorporated to promote the adaptation of latent features\nacross multiple configurations. Unlike existing transfer learning approaches,\nour proposed DSVB employs a recurrent neural network to model the nonlinear\ndynamics and temporal coherence in soft robot data. The proposed framework is\nvalidated on multiple setup configurations of a pneumatic-based soft robot\nfinger. Experimental results on four transfer scenarios demonstrate that DSVB\nperforms effective transfer learning and accurate state inference amidst\nmissing state labels.\n","authors":["Shageenderan Sapai","Junn Yong Loo","Ze Yang Ding","Chee Pin Tan","Raphael CW Phan","Vishnu Monn Baskaran","Surya Girinatha Nurzaman"],"pdf_url":"https://arxiv.org/pdf/2303.01693v1.pdf","comment":"Accepted at the International Conference on Robotics and Automation\n  (ICRA) 2023"},{"id":"http://arxiv.org/abs/2303.01692v1","updated":"2023-03-03T03:16:54Z","published":"2023-03-03T03:16:54Z","title":"Enhancing Fairness in AI-based Travel Demand Forecasting Models","summary":"  Artificial Intelligence (AI) and machine learning have been increasingly\nadopted for forecasting real-time travel demand. These AI-based travel demand\nforecasting models, though generate highly-accurate predictions, may produce\nprediction biases and thus raise fairness issues. Using such models for\ndecision-making, we may develop transportation policies that could exacerbate\nsocial inequalities. However, limited studies have been focused on addressing\nthe fairness issues of AI-based travel demand forecasting models. Therefore, in\nthis study, we propose a novel methodology to develop fairness-aware travel\ndemand forecasting models, which are highly accurate and fair. Specifically, we\nadd a fairness regularization term, i.e., the correlation between prediction\naccuracy and the protected attribute such as race or income, into the loss\nfunction of the travel demand forecasting model. We include an interactive\nweight coefficient to both accuracy loss term and fairness loss term. The\ntravel demand forecasting models can thus simultaneously account for prediction\naccuracy and fairness. An empirical analysis is conducted using real-world\nridesourcing-trip data in Chicago. Results show that our proposed methodology\neffectively addresses the accuracy-fairness trade-off. It can significantly\nenhance fairness for multiple protected attributes (i.e., race, education, age\nand income) by only sacrificing a small accuracy drop. This study provides\ntransportation professionals a new type of decision-support tool to achieve\nfair and accurate travel demand forecasting.\n","authors":["Xiaojian Zhang","Qian Ke","Xilei Zhao"],"pdf_url":"https://arxiv.org/pdf/2303.01692v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01687v1","updated":"2023-03-03T03:00:49Z","published":"2023-03-03T03:00:49Z","title":"Differentially Private Neural Tangent Kernels for Privacy-Preserving\n  Data Generation","summary":"  Maximum mean discrepancy (MMD) is a particularly useful distance metric for\ndifferentially private data generation: when used with finite-dimensional\nfeatures it allows us to summarize and privatize the data distribution once,\nwhich we can repeatedly use during generator training without further privacy\nloss. An important question in this framework is, then, what features are\nuseful to distinguish between real and synthetic data distributions, and\nwhether those enable us to generate quality synthetic data. This work considers\nthe using the features of $\\textit{neural tangent kernels (NTKs)}$, more\nprecisely $\\textit{empirical}$ NTKs (e-NTKs). We find that, perhaps\nsurprisingly, the expressiveness of the untrained e-NTK features is comparable\nto that of the features taken from pre-trained perceptual features using public\ndata. As a result, our method improves the privacy-accuracy trade-off compared\nto other state-of-the-art methods, without relying on any public data, as\ndemonstrated on several tabular and image benchmark datasets.\n","authors":["Yilin Yang","Kamil Adamczewski","Danica J. Sutherland","Xiaoxiao Li","Mijung Park"],"pdf_url":"https://arxiv.org/pdf/2303.01687v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01684v1","updated":"2023-03-03T02:56:05Z","published":"2023-03-03T02:56:05Z","title":"BO-Muse: A human expert and AI teaming framework for accelerated\n  experimental design","summary":"  In this paper we introduce BO-Muse, a new approach to human-AI teaming for\nthe optimization of expensive black-box functions. Inspired by the intrinsic\ndifficulty of extracting expert knowledge and distilling it back into AI models\nand by observations of human behaviour in real-world experimental design, our\nalgorithm lets the human expert take the lead in the experimental process. The\nhuman expert can use their domain expertise to its full potential, while the AI\nplays the role of a muse, injecting novelty and searching for areas of weakness\nto break the human out of over-exploitation induced by cognitive entrenchment.\nWith mild assumptions, we show that our algorithm converges sub-linearly, at a\nrate faster than the AI or human alone. We validate our algorithm using\nsynthetic data and with human experts performing real-world experiments.\n","authors":["Sunil Gupta","Alistair Shilton","Arun Kumar A V","Shannon Ryan","Majid Abdolshah","Hung Le","Santu Rana","Julian Berk","Mahad Rashid","Svetha Venkatesh"],"pdf_url":"https://arxiv.org/pdf/2303.01684v1.pdf","comment":"34 Pages, 7 Figures and 5 Tables"},{"id":"http://arxiv.org/abs/2303.01682v1","updated":"2023-03-03T02:53:56Z","published":"2023-03-03T02:53:56Z","title":"Neural-BO: A Black-box Optimization Algorithm using Deep Neural Networks","summary":"  Bayesian Optimization (BO) is an effective approach for global optimization\nof black-box functions when function evaluations are expensive. Most prior\nworks use Gaussian processes to model the black-box function, however, the use\nof kernels in Gaussian processes leads to two problems: first, the kernel-based\nmethods scale poorly with the number of data points and second, kernel methods\nare usually not effective on complex structured high dimensional data due to\ncurse of dimensionality. Therefore, we propose a novel black-box optimization\nalgorithm where the black-box function is modeled using a neural network. Our\nalgorithm does not need a Bayesian neural network to estimate predictive\nuncertainty and is therefore computationally favorable. We analyze the\ntheoretical behavior of our algorithm in terms of regret bound using advances\nin NTK theory showing its efficient convergence. We perform experiments with\nboth synthetic and real-world optimization tasks and show that our algorithm is\nmore sample efficient compared to existing methods.\n","authors":["Dat Phan-Trong","Hung Tran-The","Sunil Gupta"],"pdf_url":"https://arxiv.org/pdf/2303.01682v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2010.00827 by other authors"},{"id":"http://arxiv.org/abs/2303.00320v2","updated":"2023-03-03T02:46:09Z","published":"2023-03-01T08:33:16Z","title":"TimeMAE: Self-Supervised Representations of Time Series with Decoupled\n  Masked Autoencoders","summary":"  Enhancing the expressive capacity of deep learning-based time series models\nwith self-supervised pre-training has become ever-increasingly prevalent in\ntime series classification. Even though numerous efforts have been devoted to\ndeveloping self-supervised models for time series data, we argue that the\ncurrent methods are not sufficient to learn optimal time series representations\ndue to solely unidirectional encoding over sparse point-wise input units. In\nthis work, we propose TimeMAE, a novel self-supervised paradigm for learning\ntransferrable time series representations based on transformer networks. The\ndistinct characteristics of the TimeMAE lie in processing each time series into\na sequence of non-overlapping sub-series via window-slicing partitioning,\nfollowed by random masking strategies over the semantic units of localized\nsub-series. Such a simple yet effective setting can help us achieve the goal of\nkilling three birds with one stone, i.e., (1) learning enriched contextual\nrepresentations of time series with a bidirectional encoding scheme; (2)\nincreasing the information density of basic semantic units; (3) efficiently\nencoding representations of time series using transformer networks.\nNevertheless, it is a non-trivial to perform reconstructing task over such a\nnovel formulated modeling paradigm. To solve the discrepancy issue incurred by\nnewly injected masked embeddings, we design a decoupled autoencoder\narchitecture, which learns the representations of visible (unmasked) positions\nand masked ones with two different encoder modules, respectively. Furthermore,\nwe construct two types of informative targets to accomplish the corresponding\npretext tasks. One is to create a tokenizer module that assigns a codeword to\neach masked region, allowing the masked codeword classification (MCC) task to\nbe completed effectively...\n","authors":["Mingyue Cheng","Qi Liu","Zhiding Liu","Hao Zhang","Rujiao Zhang","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2303.00320v2.pdf","comment":"Submitted to IEEE TRANSACTIONS ON KNOWLEDGE AND DATA\n  ENGINEERING(TKDE), under review"},{"id":"http://arxiv.org/abs/2303.01673v1","updated":"2023-03-03T02:24:06Z","published":"2023-03-03T02:24:06Z","title":"Near Optimal Memory-Regret Tradeoff for Online Learning","summary":"  In the experts problem, on each of $T$ days, an agent needs to follow the\nadvice of one of $n$ ``experts''. After each day, the loss associated with each\nexpert's advice is revealed. A fundamental result in learning theory says that\nthe agent can achieve vanishing regret, i.e. their cumulative loss is within\n$o(T)$ of the cumulative loss of the best-in-hindsight expert.\n  Can the agent perform well without sufficient space to remember all the\nexperts? We extend a nascent line of research on this question in two\ndirections:\n  $\\bullet$ We give a new algorithm against the oblivious adversary, improving\nover the memory-regret tradeoff obtained by [PZ23], and nearly matching the\nlower bound of [SWXZ22].\n  $\\bullet$ We also consider an adaptive adversary who can observe past experts\nchosen by the agent. In this setting we give both a new algorithm and a novel\nlower bound, proving that roughly $\\sqrt{n}$ memory is both necessary and\nsufficient for obtaining $o(T)$ regret.\n","authors":["Binghui Peng","Aviad Rubinstein"],"pdf_url":"https://arxiv.org/pdf/2303.01673v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01289v2","updated":"2023-03-03T02:21:48Z","published":"2023-03-02T14:11:54Z","title":"Rethinking the Effect of Data Augmentation in Adversarial Contrastive\n  Learning","summary":"  Recent works have shown that self-supervised learning can achieve remarkable\nrobustness when integrated with adversarial training (AT). However, the\nrobustness gap between supervised AT (sup-AT) and self-supervised AT (self-AT)\nremains significant. Motivated by this observation, we revisit existing self-AT\nmethods and discover an inherent dilemma that affects self-AT robustness:\neither strong or weak data augmentations are harmful to self-AT, and a medium\nstrength is insufficient to bridge the gap. To resolve this dilemma, we propose\na simple remedy named DYNACL (Dynamic Adversarial Contrastive Learning). In\nparticular, we propose an augmentation schedule that gradually anneals from a\nstrong augmentation to a weak one to benefit from both extreme cases. Besides,\nwe adopt a fast post-processing stage for adapting it to downstream tasks.\nThrough extensive experiments, we show that DYNACL can improve state-of-the-art\nself-AT robustness by 8.84% under Auto-Attack on the CIFAR-10 dataset, and can\neven outperform vanilla supervised adversarial training for the first time. Our\ncode is available at \\url{https://github.com/PKU-ML/DYNACL}.\n","authors":["Rundong Luo","Yifei Wang","Yisen Wang"],"pdf_url":"https://arxiv.org/pdf/2303.01289v2.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.01671v1","updated":"2023-03-03T02:18:55Z","published":"2023-03-03T02:18:55Z","title":"Tile Networks: Learning Optimal Geometric Layout for Whole-page\n  Recommendation","summary":"  Finding optimal configurations in a geometric space is a key challenge in\nmany technological disciplines. Current approaches either rely heavily on human\ndomain expertise and are difficult to scale. In this paper we show it is\npossible to solve configuration optimization problems for whole-page\nrecommendation using reinforcement learning. The proposed \\textit{Tile\nNetworks} is a neural architecture that optimizes 2D geometric configurations\nby arranging items on proper positions. Empirical results on real dataset\ndemonstrate its superior performance compared to traditional learning to rank\napproaches and recent deep models.\n","authors":["Shuai Xiao","Zaifan Jiang","Shuang Yang"],"pdf_url":"https://arxiv.org/pdf/2303.01671v1.pdf","comment":"Published at Proceedings of the 25th International Conference on\n  Artificial Intelligence and Statistics (AISTATS) 2022"},{"id":"http://arxiv.org/abs/2303.00870v2","updated":"2023-03-03T02:09:06Z","published":"2023-03-01T23:53:01Z","title":"Implementing Active Learning in Cybersecurity: Detecting Anomalies in\n  Redacted Emails","summary":"  Research on email anomaly detection has typically relied on specially\nprepared datasets that may not adequately reflect the type of data that occurs\nin industry settings. In our research, at a major financial services company,\nprivacy concerns prevented inspection of the bodies of emails and attachment\ndetails (although subject headings and attachment filenames were available).\nThis made labeling possible anomalies in the resulting redacted emails more\ndifficult. Another source of difficulty is the high volume of emails combined\nwith the scarcity of resources making machine learning (ML) a necessity, but\nalso creating a need for more efficient human training of ML models. Active\nlearning (AL) has been proposed as a way to make human training of ML models\nmore efficient. However, the implementation of Active Learning methods is a\nhuman-centered AI challenge due to potential human analyst uncertainty, and the\nlabeling task can be further complicated in domains such as the cybersecurity\ndomain (or healthcare, aviation, etc.) where mistakes in labeling can have\nhighly adverse consequences. In this paper we present research results\nconcerning the application of Active Learning to anomaly detection in redacted\nemails, comparing the utility of different methods for implementing active\nlearning in this context. We evaluate different AL strategies and their impact\non resulting model performance. We also examine how ratings of confidence that\nexperts have in their labels can inform AL. The results obtained are discussed\nin terms of their implications for AL methodology and for the role of experts\nin model-assisted email anomaly screening.\n","authors":["Mu-Huan Chung","Lu Wang","Sharon Li","Yuhong Yang","Calvin Giang","Khilan Jerath","Abhay Raman","David Lie","Mark Chignell"],"pdf_url":"https://arxiv.org/pdf/2303.00870v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01669v1","updated":"2023-03-03T02:07:40Z","published":"2023-03-03T02:07:40Z","title":"Learning Common Rationale to Improve Self-Supervised Representation for\n  Fine-Grained Visual Recognition Problems","summary":"  Self-supervised learning (SSL) strategies have demonstrated remarkable\nperformance in various recognition tasks. However, both our preliminary\ninvestigation and recent studies suggest that they may be less effective in\nlearning representations for fine-grained visual recognition (FGVR) since many\nfeatures helpful for optimizing SSL objectives are not suitable for\ncharacterizing the subtle differences in FGVR. To overcome this issue, we\npropose learning an additional screening mechanism to identify discriminative\nclues commonly seen across instances and classes, dubbed as common rationales\nin this paper. Intuitively, common rationales tend to correspond to the\ndiscriminative patterns from the key parts of foreground objects. We show that\na common rationale detector can be learned by simply exploiting the GradCAM\ninduced from the SSL objective without using any pre-trained object parts or\nsaliency detectors, making it seamlessly to be integrated with the existing SSL\nprocess. Specifically, we fit the GradCAM with a branch with limited fitting\ncapacity, which allows the branch to capture the common rationales and discard\nthe less common discriminative patterns. At the test stage, the branch\ngenerates a set of spatial weights to selectively aggregate features\nrepresenting an instance. Extensive experimental results on four visual tasks\ndemonstrate that the proposed method can lead to a significant improvement in\ndifferent evaluation settings.\n","authors":["Yangyang Shu","Anton van den Hengel","Lingqiao Liu"],"pdf_url":"https://arxiv.org/pdf/2303.01669v1.pdf","comment":"To Appear at CVPR 2023"},{"id":"http://arxiv.org/abs/2303.01668v1","updated":"2023-03-03T02:04:14Z","published":"2023-03-03T02:04:14Z","title":"RePreM: Representation Pre-training with Masked Model for Reinforcement\n  Learning","summary":"  Inspired by the recent success of sequence modeling in RL and the use of\nmasked language model for pre-training, we propose a masked model for\npre-training in RL, RePreM (Representation Pre-training with Masked Model),\nwhich trains the encoder combined with transformer blocks to predict the masked\nstates or actions in a trajectory. RePreM is simple but effective compared to\nexisting representation pre-training methods in RL. It avoids algorithmic\nsophistication (such as data augmentation or estimating multiple models) with\nsequence modeling and generates a representation that captures long-term\ndynamics well. Empirically, we demonstrate the effectiveness of RePreM in\nvarious tasks, including dynamic prediction, transfer learning, and\nsample-efficient RL with both value-based and actor-critic methods. Moreover,\nwe show that RePreM scales well with dataset size, dataset quality, and the\nscale of the encoder, which indicates its potential towards big RL models.\n","authors":["Yuanying Cai","Chuheng Zhang","Wei Shen","Xuyun Zhang","Wenjie Ruan","Longbo Huang"],"pdf_url":"https://arxiv.org/pdf/2303.01668v1.pdf","comment":"Accepted by AAAI-23"},{"id":"http://arxiv.org/abs/2303.01664v1","updated":"2023-03-03T01:57:16Z","published":"2023-03-03T01:57:16Z","title":"Miipher: A Robust Speech Restoration Model Integrating Self-Supervised\n  Speech and Text Representations","summary":"  Speech restoration (SR) is a task of converting degraded speech signals into\nhigh-quality ones. In this study, we propose a robust SR model called Miipher,\nand apply Miipher to a new SR application: increasing the amount of\nhigh-quality training data for speech generation by converting speech samples\ncollected from the Web to studio-quality. To make our SR model robust against\nvarious degradation, we use (i) a speech representation extracted from w2v-BERT\nfor the input feature, and (ii) a text representation extracted from\ntranscripts via PnG-BERT as a linguistic conditioning feature. Experiments show\nthat Miipher (i) is robust against various audio degradation and (ii) enable us\nto train a high-quality text-to-speech (TTS) model from restored speech samples\ncollected from the Web. Audio samples are available at our demo page:\ngoogle.github.io/df-conformer/miipher/\n","authors":["Yuma Koizumi","Heiga Zen","Shigeki Karita","Yifan Ding","Kohei Yatabe","Nobuyuki Morioka","Yu Zhang","Wei Han","Ankur Bapna","Michiel Bacchiani"],"pdf_url":"https://arxiv.org/pdf/2303.01664v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2203.15952v4","updated":"2023-03-03T01:52:28Z","published":"2022-03-29T23:57:15Z","title":"4-bit Conformer with Native Quantization Aware Training for Speech\n  Recognition","summary":"  Reducing the latency and model size has always been a significant research\nproblem for live Automatic Speech Recognition (ASR) application scenarios.\nAlong this direction, model quantization has become an increasingly popular\napproach to compress neural networks and reduce computation cost. Most of the\nexisting practical ASR systems apply post-training 8-bit quantization. To\nachieve a higher compression rate without introducing additional performance\nregression, in this study, we propose to develop 4-bit ASR models with native\nquantization aware training, which leverages native integer operations to\neffectively optimize both training and inference. We conducted two experiments\non state-of-the-art Conformer-based ASR models to evaluate our proposed\nquantization technique. First, we explored the impact of different precisions\nfor both weight and activation quantization on the LibriSpeech dataset, and\nobtained a lossless 4-bit Conformer model with 5.8x size reduction compared to\nthe float32 model. Following this, we for the first time investigated and\nrevealed the viability of 4-bit quantization on a practical ASR system that is\ntrained with large-scale datasets, and produced a lossless Conformer ASR model\nwith mixed 4-bit and 8-bit weights that has 5x size reduction compared to the\nfloat32 model.\n","authors":["Shaojin Ding","Phoenix Meadowlark","Yanzhang He","Lukasz Lew","Shivani Agrawal","Oleg Rybakov"],"pdf_url":"https://arxiv.org/pdf/2203.15952v4.pdf","comment":"Published at INTERSPEECH 2022"},{"id":"http://arxiv.org/abs/2303.01661v1","updated":"2023-03-03T01:47:32Z","published":"2023-03-03T01:47:32Z","title":"Longwave infrared multispectral image sensor system using\n  aluminum-germanium plasmonic filter arrays","summary":"  A multispectral camera records image data in various wavelengths across the\nelectromagnetic spectrum to acquire additional information that a conventional\ncamera fails to capture. With the advent of high-resolution image sensors and\ncolour filter technologies, multispectral imagers in the visible wavelengths\nhave become popular with increasing commercial viability in the last decade.\nHowever, multispectral imaging in longwave infrared (LWIR: 8 to 14 microns) is\nstill an emerging area due to the limited availability of optical materials,\nfilter technologies, and high-resolution sensors. Images from LWIR\nmultispectral cameras can capture emission spectra of objects to extract\nadditional information that a human eye fails to capture and thus have\nimportant applications in precision agriculture, forestry, medicine, and object\nidentification. In this work, we experimentally demonstrate an LWIR\nmultispectral image sensor with three wavelength bands using optical elements\nmade of an aluminum-based plasmonic filter array sandwiched in germanium. To\nrealize the multispectral sensor, the filter arrays are then integrated into a\n3D printed wheel stacked on a low-resolution monochrome thermal sensor. Our\nprototype device is calibrated using a blackbody and its thermal output has\nbeen enhanced with computer vision methods. By applying a state-of-the-art deep\nlearning method, we have also reconstructed multispectral images to a better\nspatial resolution. Scientifically, our work demonstrates a versatile spectral\nthermography technique for detecting target signatures in the LWIR range and\nother advanced spectral analyses.\n","authors":["Noor E Karishma Shaik","Bryce Widdicombe","Dechuan Sun","Sam E John","Dongryeol Ryu","Ampalavanapillai Nirmalathas","Ranjith R Unnithan"],"pdf_url":"https://arxiv.org/pdf/2303.01661v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.00935v2","updated":"2023-03-03T01:35:27Z","published":"2023-03-02T03:16:21Z","title":"Learning to Detect Slip through Tactile Measures of the Contact Force\n  Field and its Entropy","summary":"  Detection of slip during object grasping and manipulation plays a vital role\nin object handling. Existing solutions largely depend on visual information to\ndevise a strategy for grasping. Nonetheless, in order to achieve proficiency\nakin to humans and achieve consistent grasping and manipulation of unfamiliar\nobjects, the incorporation of artificial tactile sensing has become a necessity\nin robotic systems. In this work, we propose a novel physics-informed,\ndata-driven method to detect slip continuously in real time. The GelSight Mini,\nan optical tactile sensor, is mounted on custom grippers to acquire tactile\nreadings. Our work leverages the inhomogeneity of tactile sensor readings\nduring slip events to develop distinctive features and formulates slip\ndetection as a classification problem. To evaluate our approach, we test\nmultiple data-driven models on 10 common objects under different loading\nconditions, textures, and materials. Our results show that the best\nclassification algorithm achieves an average accuracy of 99%. We demonstrate\nthe application of this work in a dynamic robotic manipulation task in which\nreal-time slip detection and prevention algorithm is implemented.\n","authors":["Xiaohai Hu","Aparajit Venkatesh","Guiliang Zheng","Xu Chen"],"pdf_url":"https://arxiv.org/pdf/2303.00935v2.pdf","comment":"8 pages, 7 figures, to be submitted"},{"id":"http://arxiv.org/abs/2302.13203v2","updated":"2023-03-03T00:52:20Z","published":"2023-02-26T01:15:32Z","title":"A Finite Sample Complexity Bound for Distributionally Robust Q-learning","summary":"  We consider a reinforcement learning setting in which the deployment\nenvironment is different from the training environment. Applying a robust\nMarkov decision processes formulation, we extend the distributionally robust\n$Q$-learning framework studied in Liu et al. [2022]. Further, we improve the\ndesign and analysis of their multi-level Monte Carlo estimator. Assuming access\nto a simulator, we prove that the worst-case expected sample complexity of our\nalgorithm to learn the optimal robust $Q$-function within an $\\epsilon$ error\nin the sup norm is upper bounded by $\\tilde\nO(|S||A|(1-\\gamma)^{-5}\\epsilon^{-2}p_{\\wedge}^{-6}\\delta^{-4})$, where\n$\\gamma$ is the discount rate, $p_{\\wedge}$ is the non-zero minimal support\nprobability of the transition kernels and $\\delta$ is the uncertainty size.\nThis is the first sample complexity result for the model-free robust RL\nproblem. Simulation studies further validate our theoretical results.\n","authors":["Shengbo Wang","Nian Si","Jose Blanchet","Zhengyuan Zhou"],"pdf_url":"https://arxiv.org/pdf/2302.13203v2.pdf","comment":"Accepted by AISTATS 2023"},{"id":"http://arxiv.org/abs/2212.07477v2","updated":"2023-03-03T00:49:42Z","published":"2022-12-14T19:54:46Z","title":"Guiding continuous operator learning through Physics-based boundary\n  constraints","summary":"  Boundary conditions (BCs) are important groups of physics-enforced\nconstraints that are necessary for solutions of Partial Differential Equations\n(PDEs) to satisfy at specific spatial locations. These constraints carry\nimportant physical meaning, and guarantee the existence and the uniqueness of\nthe PDE solution. Current neural-network based approaches that aim to solve\nPDEs rely only on training data to help the model learn BCs implicitly. There\nis no guarantee of BC satisfaction by these models during evaluation. In this\nwork, we propose Boundary enforcing Operator Network (BOON) that enables the BC\nsatisfaction of neural operators by making structural changes to the operator\nkernel. We provide our refinement procedure, and demonstrate the satisfaction\nof physics-based BCs, e.g. Dirichlet, Neumann, and periodic by the solutions\nobtained by BOON. Numerical experiments based on multiple PDEs with a wide\nvariety of applications indicate that the proposed approach ensures\nsatisfaction of BCs, and leads to more accurate solutions over the entire\ndomain. The proposed correction method exhibits a (2X-20X) improvement over a\ngiven operator model in relative $L^2$ error (0.000084 relative $L^2$ error for\nBurgers' equation).\n","authors":["Nadim Saad","Gaurav Gupta","Shima Alizadeh","Danielle C. Maddix"],"pdf_url":"https://arxiv.org/pdf/2212.07477v2.pdf","comment":"Nadim and Gaurav contributed equally in this work. 31 pages, 7\n  figures, 16 tables"},{"id":"http://arxiv.org/abs/2210.05523v4","updated":"2023-03-03T00:44:24Z","published":"2022-10-11T15:15:09Z","title":"An efficient neural-network and finite-difference hybrid method for\n  elliptic interface problems with applications","summary":"  A new and efficient neural-network and finite-difference hybrid method is\ndeveloped for solving Poisson equation in a regular domain with jump\ndiscontinuities on embedded irregular interfaces. Since the solution has low\nregularity across the interface, when applying finite difference discretization\nto this problem, an additional treatment accounting for the jump\ndiscontinuities must be employed. Here, we aim to elevate such an extra effort\nto ease our implementation by machine learning methodology. The key idea is to\ndecompose the solution into singular and regular parts. The neural network\nlearning machinery incorporating the given jump conditions finds the singular\nsolution, while the standard five-point Laplacian discretization is used to\nobtain the regular solution with associated boundary conditions. Regardless of\nthe interface geometry, these two tasks only require supervised learning for\nfunction approximation and a fast direct solver for Poisson equation, making\nthe hybrid method easy to implement and efficient. The two- and\nthree-dimensional numerical results show that the present hybrid method\npreserves second-order accuracy for the solution and its derivatives, and it is\ncomparable with the traditional immersed interface method in the literature. As\nan application, we solve the Stokes equations with singular forces to\ndemonstrate the robustness of the present method.\n","authors":["Wei-Fan Hu","Te-Sheng Lin","Yu-Hau Tseng","Ming-Chih Lai"],"pdf_url":"https://arxiv.org/pdf/2210.05523v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01645v1","updated":"2023-03-03T00:38:01Z","published":"2023-03-03T00:38:01Z","title":"APIContext2Com: Code Comment Generation by Incorporating Pre-Defined API\n  Documentation","summary":"  Code comments are significantly helpful in comprehending software programs\nand also aid developers to save a great deal of time in software maintenance.\nCode comment generation aims to automatically predict comments in natural\nlanguage given a code snippet. Several works investigate the effect of\nintegrating external knowledge on the quality of generated comments. In this\nstudy, we propose a solution, namely APIContext2Com, to improve the\neffectiveness of generated comments by incorporating the pre-defined\nApplication Programming Interface (API) context. The API context includes the\ndefinition and description of the pre-defined APIs that are used within the\ncode snippets. As the detailed API information expresses the functionality of a\ncode snippet, it can be helpful in better generating the code summary. We\nintroduce a seq-2-seq encoder-decoder neural network model with different sets\nof multiple encoders to effectively transform distinct inputs into target\ncomments. A ranking mechanism is also developed to exclude non-informative\nAPIs, so that we can filter out unrelated APIs. We evaluate our approach using\nthe Java dataset from CodeSearchNet. The findings reveal that the proposed\nmodel improves the best baseline by 1.88 (8.24 %), 2.16 (17.58 %), 1.38 (18.3\n%), 0.73 (14.17 %), 1.58 (14.98 %) and 1.9 (6.92 %) for BLEU1, BLEU2, BLEU3,\nBLEU4, METEOR, ROUGE-L respectively. Human evaluation and ablation studies\nconfirm the quality of the generated comments and the effect of architecture\nand ranking APIs.\n","authors":["Ramin Shahbazi","Fatemeh Fard"],"pdf_url":"https://arxiv.org/pdf/2303.01645v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.00801v5","updated":"2023-03-03T00:27:34Z","published":"2022-06-02T00:01:27Z","title":"Indeterminacy in Generative Models: Characterization and Strong\n  Identifiability","summary":"  Most modern probabilistic generative models, such as the variational\nautoencoder (VAE), have certain indeterminacies that are unresolvable even with\nan infinite amount of data. Different tasks tolerate different indeterminacies,\nhowever recent applications have indicated the need for strongly identifiable\nmodels, in which an observation corresponds to a unique latent code. Progress\nhas been made towards reducing model indeterminacies while maintaining\nflexibility, and recent work excludes many--but not all--indeterminacies. In\nthis work, we motivate model-identifiability in terms of task-identifiability,\nthen construct a theoretical framework for analyzing the indeterminacies of\nlatent variable models, which enables their precise characterization in terms\nof the generator function and prior distribution spaces. We reveal that strong\nidentifiability is possible even with highly flexible nonlinear generators, and\ngive two such examples. One is a straightforward modification of iVAE\n(arXiv:1907.04809 [stat.ML]); the other uses triangular monotonic maps, leading\nto novel connections between optimal transport and identifiability.\n","authors":["Quanhan Xi","Benjamin Bloem-Reddy"],"pdf_url":"https://arxiv.org/pdf/2206.00801v5.pdf","comment":"AISTATS 2023 (title corrected from v4)"},{"id":"http://arxiv.org/abs/2302.12388v3","updated":"2023-03-03T00:20:30Z","published":"2023-02-24T01:29:21Z","title":"TrafFormer: A Transformer Model for Predicting Long-term Traffic","summary":"  Traffic prediction is a flourishing research field due to its importance in\nhuman mobility in the urban space. Despite this, existing studies only focus on\nshort-term prediction of up to few hours in advance, with most being up to one\nhour only. Long-term traffic prediction can enable more comprehensive,\ninformed, and proactive measures against traffic congestion and is therefore an\nimportant task to explore. In this paper, we explore the task of long-term\ntraffic prediction; where we predict traffic up to 24 hours in advance. We note\nthe weaknesses of existing models--which are based on recurrent structures--for\nlong-term traffic prediction and propose a modified Transformer model\n\"TrafFormer\". Experiments comparing our model with existing hybrid neural\nnetwork models show the superiority of our model.\n","authors":["David Alexander Tedjopurnomo","Farhana M. Choudhury","A. K. Qin"],"pdf_url":"https://arxiv.org/pdf/2302.12388v3.pdf","comment":"14 pages, 6 figures"},{"id":"http://arxiv.org/abs/2303.01640v1","updated":"2023-03-03T00:14:32Z","published":"2023-03-03T00:14:32Z","title":"Hierarchical Graph Neural Networks for Particle Track Reconstruction","summary":"  We introduce a novel variant of GNN for particle tracking called Hierarchical\nGraph Neural Network (HGNN). The architecture creates a set of higher-level\nrepresentations which correspond to tracks and assigns spacepoints to these\ntracks, allowing disconnected spacepoints to be assigned to the same track, as\nwell as multiple tracks to share the same spacepoint. We propose a novel\nlearnable pooling algorithm called GMPool to generate these higher-level\nrepresentations called \"super-nodes\", as well as a new loss function designed\nfor tracking problems and HGNN specifically. On a standard tracking problem, we\nshow that, compared with previous ML-based tracking algorithms, the HGNN has\nbetter tracking efficiency performance, better robustness against inefficient\ninput graphs, and better convergence compared with traditional GNNs.\n","authors":["Ryan Liu","Paolo Calafiura","Steven Farrell","Xiangyang Ju","Daniel Thomas Murnane","Tuan Minh Pham"],"pdf_url":"https://arxiv.org/pdf/2303.01640v1.pdf","comment":"7 pages, 5 figures, submitted to the 21st International Workshop on\n  Advanced Computing and Analysis Techniques in Physics Research"}],"Multimedia":[{"id":"http://arxiv.org/abs/2210.16470v2","updated":"2023-03-03T18:15:34Z","published":"2022-10-29T02:53:10Z","title":"Improving Audio Captioning Using Semantic Similarity Metrics","summary":"  Audio captioning quality metrics which are typically borrowed from the\nmachine translation and image captioning areas measure the degree of overlap\nbetween predicted tokens and gold reference tokens. In this work, we consider a\nmetric measuring semantic similarities between predicted and reference captions\ninstead of measuring exact word overlap. We first evaluate its ability to\ncapture similarities among captions corresponding to the same audio file and\ncompare it to other established metrics. We then propose a fine-tuning method\nto directly optimize the metric by backpropagating through a sentence embedding\nextractor and audio captioning network. Such fine-tuning results in an\nimprovement in predicted captions as measured by both traditional metrics and\nthe proposed semantic similarity captioning metric.\n","authors":["Rehana Mahfuz","Yinyi Guo","Erik Visser"],"pdf_url":"https://arxiv.org/pdf/2210.16470v2.pdf","comment":"Accepted at ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.01884v1","updated":"2023-03-03T12:30:09Z","published":"2023-03-03T12:30:09Z","title":"AutoMatch: A Large-scale Audio Beat Matching Benchmark for Boosting Deep\n  Learning Assistant Video Editing","summary":"  The explosion of short videos has dramatically reshaped the manners people\nsocialize, yielding a new trend for daily sharing and access to the latest\ninformation. These rich video resources, on the one hand, benefited from the\npopularization of portable devices with cameras, but on the other, they can not\nbe independent of the valuable editing work contributed by numerous video\ncreators. In this paper, we investigate a novel and practical problem, namely\naudio beat matching (ABM), which aims to recommend the proper transition time\nstamps based on the background music. This technique helps to ease the\nlabor-intensive work during video editing, saving energy for creators so that\nthey can focus more on the creativity of video content. We formally define the\nABM problem and its evaluation protocol. Meanwhile, a large-scale audio\ndataset, i.e., the AutoMatch with over 87k finely annotated background music,\nis presented to facilitate this newly opened research direction. To further lay\nsolid foundations for the following study, we also propose a novel model termed\nBeatX to tackle this challenging task. Alongside, we creatively present the\nconcept of label scope, which eliminates the data imbalance issues and assigns\nadaptive weights for the ground truth during the training procedure in one\nstop. Though plentiful short video platforms have flourished for a long time,\nthe relevant research concerning this scenario is not sufficient, and to the\nbest of our knowledge, AutoMatch is the first large-scale dataset to tackle the\naudio beat matching problem. We hope the released dataset and our competitive\nbaseline can encourage more attention to this line of research. The dataset and\ncodes will be made publicly available.\n","authors":["Sen Pei","Jingya Yu","Qi Chen","Wozhou He"],"pdf_url":"https://arxiv.org/pdf/2303.01884v1.pdf","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2303.01740v1","updated":"2023-03-03T06:57:22Z","published":"2023-03-03T06:57:22Z","title":"DeepfakeMAE: Facial Part Consistency Aware Masked Autoencoder for\n  Deepfake Video Detection","summary":"  Deepfake techniques have been used maliciously, resulting in strong research\ninterests in developing Deepfake detection methods. Deepfake often manipulates\nthe video content by tampering with some facial parts. However, this\nmanipulation usually breaks the consistency among facial parts, e.g., Deepfake\nmay change smiling lips to upset, but the eyes are still smiling. Existing\nworks propose to spot inconsistency on some specific facial parts (e.g., lips),\nbut they may perform poorly if new Deepfake techniques focus on the specific\nfacial parts used by the detector. Thus, this paper proposes a new Deepfake\ndetection model, DeepfakeMAE, which can utilize the consistencies among all\nfacial parts. Specifically, given a real face image, we first pretrain a masked\nautoencoder to learn facial part consistency by randomly masking some facial\nparts and reconstructing missing areas based on the remaining facial parts.\nFurthermore, to maximize the discrepancy between real and fake videos, we\npropose a novel model with dual networks that utilize the pretrained encoder\nand decoder, respectively. 1) The pretrained encoder is finetuned for capturing\nthe overall information of the given video. 2) The pretrained decoder is\nutilized for distinguishing real and fake videos based on the motivation that\nDeepfakeMAE's reconstruction should be more similar to a real face image than a\nfake one. Our extensive experiments on standard benchmarks demonstrate that\nDeepfakeMAE is highly effective and especially outperforms the previous\nstate-of-the-art method by 3.1% AUC on average in cross-dataset detection.\n","authors":["Juan Hu","Xin Liao","Difei Gao","Satoshi Tsutsui","Zheng Qin","Mike Zheng Shou"],"pdf_url":"https://arxiv.org/pdf/2303.01740v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14472v3","updated":"2023-03-03T02:15:32Z","published":"2023-02-28T10:30:16Z","title":"TV-watching partner robot: Analysis of User's Experience","summary":"  Watching TV not only provides news information but also gives an opportunity\nfor different generations to communicate. With the proliferation of\nsmartphones, PC, and the Internet, increase the opportunities for communication\nin front of the television is also likely to diminish. This has led to some\nproblems further from face-to-face such as a lack of self-control and\ninsufficient development of communication skills. This paper proposes a\nTV-watching companion robot with open-domain chat ability. The robot contains\ntwo modes: TV-watching mode and conversation mode. In TV-watching mode, the\nrobot first extracts keywords from the TV program and then generates the\ndisclosure utterances based on the extracted keywords as if enjoying the TV\nprogram. In the conversation mode, the robot generates question utterances with\nkeywords in the same way and then employs a topics-based dialog management\nmethod consisting of multiple dialog engines for rich conversations related to\nthe TV program. We conduct the initial experiments and the result shows that\nall participants from the three groups enjoyed talking with the robot, and the\nquestion about their interests in the robot was rated 6.5/7-levels. This\nindicates that the proposed conversational features of TV-watching Companion\nRobot have the potential to make our daily lives more enjoyable. Under the\nanalysis of the initial experiments, we achieve further experiments with more\nparticipants by dividing them into two groups: a control group without a robot\nand an intervention group with a robot. The results show that people prefer to\ntalk to robots because the robot will bring more enjoyable, relaxed, and\ninteresting.\n","authors":["Donghuo Zeng","Jianming Wu","Gen Hattori","Yasuhiro Takishima"],"pdf_url":"https://arxiv.org/pdf/2302.14472v3.pdf","comment":"15 pages, 3 figures, 11 tables"},{"id":"http://arxiv.org/abs/2303.01665v1","updated":"2023-03-03T02:00:49Z","published":"2023-03-03T02:00:49Z","title":"LooperGP: A Loopable Sequence Model for Live Coding Performance using\n  GuitarPro Tablature","summary":"  Despite their impressive offline results, deep learning models for symbolic\nmusic generation are not widely used in live performances due to a deficit of\nmusically meaningful control parameters and a lack of structured musical form\nin their outputs. To address these issues we introduce LooperGP, a method for\nsteering a Transformer-XL model towards generating loopable musical phrases of\na specified number of bars and time signature, enabling a tool for live coding\nperformances. We show that by training LooperGP on a dataset of 93,681 musical\nloops extracted from the DadaGP dataset, we are able to steer its generative\noutput towards generating 3x as many loopable phrases as our baseline. In a\nsubjective listening test conducted by 31 participants, LooperGP loops achieved\npositive median ratings in originality, musical coherence and loop smoothness,\ndemonstrating its potential as a performance tool.\n","authors":["Sara Adkins","Pedro Sarmento","Mathieu Barthet"],"pdf_url":"https://arxiv.org/pdf/2303.01665v1.pdf","comment":"The Version of Record of this contribution is published in\n  Proceedings of EvoMUSART: International Conference on Computational\n  Intelligence in Music, Sound, Art and Design (Part of EvoStar) 2023"},{"id":"http://arxiv.org/abs/2207.04213v2","updated":"2023-03-03T21:01:32Z","published":"2022-07-09T07:27:46Z","title":"Dual-Path Cross-Modal Attention for better Audio-Visual Speech\n  Extraction","summary":"  Audio-visual target speech extraction, which aims to extract a certain\nspeaker's speech from the noisy mixture by looking at lip movements, has made\nsignificant progress combining time-domain speech separation models and visual\nfeature extractors (CNN). One problem of fusing audio and video information is\nthat they have different time resolutions. Most current research upsamples the\nvisual features along the time dimension so that audio and video features are\nable to align in time. However, we believe that lip movement should mostly\ncontain long-term, or phone-level information. Based on this assumption, we\npropose a new way to fuse audio-visual features. We observe that for DPRNN\n\\cite{dprnn}, the interchunk dimension's time resolution could be very close to\nthe time resolution of video frames. Like \\cite{sepformer}, the LSTM in DPRNN\nis replaced by intra-chunk and inter-chunk self-attention, but in the proposed\nalgorithm, inter-chunk attention incorporates the visual features as an\nadditional feature stream. This prevents the upsampling of visual cues,\nresulting in more efficient audio-visual fusion. The result shows we achieve\nsuperior results compared with other time-domain based audio-visual fusion\nmodels.\n","authors":["Zhongweiyang Xu","Xulin Fan","Mark Hasegawa-Johnson"],"pdf_url":"https://arxiv.org/pdf/2207.04213v2.pdf","comment":"Paper Accepted by ICASSP2023"},{"id":"http://arxiv.org/abs/2212.07065v2","updated":"2023-03-03T08:37:38Z","published":"2022-12-14T07:21:45Z","title":"CLIPSep: Learning Text-queried Sound Separation with Noisy Unlabeled\n  Videos","summary":"  Recent years have seen progress beyond domain-specific sound separation for\nspeech or music towards universal sound separation for arbitrary sounds. Prior\nwork on universal sound separation has investigated separating a target sound\nout of an audio mixture given a text query. Such text-queried sound separation\nsystems provide a natural and scalable interface for specifying arbitrary\ntarget sounds. However, supervised text-queried sound separation systems\nrequire costly labeled audio-text pairs for training. Moreover, the audio\nprovided in existing datasets is often recorded in a controlled environment,\ncausing a considerable generalization gap to noisy audio in the wild. In this\nwork, we aim to approach text-queried universal sound separation by using only\nunlabeled data. We propose to leverage the visual modality as a bridge to learn\nthe desired audio-textual correspondence. The proposed CLIPSep model first\nencodes the input query into a query vector using the contrastive\nlanguage-image pretraining (CLIP) model, and the query vector is then used to\ncondition an audio separation model to separate out the target sound. While the\nmodel is trained on image-audio pairs extracted from unlabeled videos, at test\ntime we can instead query the model with text inputs in a zero-shot setting,\nthanks to the joint language-image embedding learned by the CLIP model.\nFurther, videos in the wild often contain off-screen sounds and background\nnoise that may hinder the model from learning the desired audio-textual\ncorrespondence. To address this problem, we further propose an approach called\nnoise invariant training for training a query-based sound separation model on\nnoisy data. Experimental results show that the proposed models successfully\nlearn text-queried universal sound separation using only noisy unlabeled\nvideos, even achieving competitive performance against a supervised model in\nsome settings.\n","authors":["Hao-Wen Dong","Naoya Takahashi","Yuki Mitsufuji","Julian McAuley","Taylor Berg-Kirkpatrick"],"pdf_url":"https://arxiv.org/pdf/2212.07065v2.pdf","comment":"Accepted by ICLR 2023. Audio samples can be found at\n  https://sony.github.io/CLIPSep/"}]},"2023-03-06T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2303.03363v1","updated":"2023-03-06T18:49:09Z","published":"2023-03-06T18:49:09Z","title":"Enhancing Activity Prediction Models in Drug Discovery with the Ability\n  to Understand Human Language","summary":"  Activity and property prediction models are the central workhorses in drug\ndiscovery and materials sciences, but currently they have to be trained or\nfine-tuned for new tasks. Without training or fine-tuning, scientific language\nmodels could be used for such low-data tasks through their announced zero- and\nfew-shot capabilities. However, their predictive quality at activity prediction\nis lacking. In this work, we envision a novel type of activity prediction model\nthat is able to adapt to new prediction tasks at inference time, via\nunderstanding textual information describing the task. To this end, we propose\na new architecture with separate modules for chemical and natural language\ninputs, and a contrastive pre-training objective on data from large biochemical\ndatabases. In extensive experiments, we show that our method CLAMP yields\nimproved predictive performance on few-shot learning benchmarks and zero-shot\nproblems in drug discovery. We attribute the advances of our method to the\nmodularized architecture and to our pre-training objective.\n","authors":["Philipp Seidl","Andreu Vall","Sepp Hochreiter","Günter Klambauer"],"pdf_url":"https://arxiv.org/pdf/2303.03363v1.pdf","comment":"15 pages + 18 pages appendix"},{"id":"http://arxiv.org/abs/2203.05642v3","updated":"2023-03-06T17:57:00Z","published":"2022-03-10T21:11:37Z","title":"Parameter-Free Attentive Scoring for Speaker Verification","summary":"  This paper presents a novel study of parameter-free attentive scoring for\nspeaker verification. Parameter-free scoring provides the flexibility of\ncomparing speaker representations without the need of an accompanying\nparametric scoring model. Inspired by the attention component in Transformer\nneural networks, we propose a variant of the scaled dot product attention\nmechanism to compare enrollment and test segment representations. In addition,\nthis work explores the effect on performance of (i) different types of\nnormalization, (ii) independent versus tied query/key estimation, (iii) varying\nthe number of key-value pairs and (iv) pooling multiple enrollment utterance\nstatistics. Experimental results for a 4 task average show that a simple\nparameter-free attentive scoring mechanism can improve the average EER by 10%\nover the best cosine similarity baseline.\n","authors":["Jason Pelecanos","Quan Wang","Yiling Huang","Ignacio Lopez Moreno"],"pdf_url":"https://arxiv.org/pdf/2203.05642v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03290v1","updated":"2023-03-06T17:06:50Z","published":"2023-03-06T17:06:50Z","title":"AmQA: Amharic Question Answering Dataset","summary":"  Question Answering (QA) returns concise answers or answer lists from natural\nlanguage text given a context document. Many resources go into curating QA\ndatasets to advance robust models' development. There is a surge of QA datasets\nfor languages like English, however, this is not true for Amharic. Amharic, the\nofficial language of Ethiopia, is the second most spoken Semitic language in\nthe world. There is no published or publicly available Amharic QA dataset.\nHence, to foster the research in Amharic QA, we present the first Amharic QA\n(AmQA) dataset. We crowdsourced 2628 question-answer pairs over 378 Wikipedia\narticles. Additionally, we run an XLMR Large-based baseline model to spark\nopen-domain QA research interest. The best-performing baseline achieves an\nF-score of 69.58 and 71.74 in reader-retriever QA and reading comprehension\nsettings respectively.\n","authors":["Tilahun Abedissa","Ricardo Usbeck","Yaregal Assabie"],"pdf_url":"https://arxiv.org/pdf/2303.03290v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03283v1","updated":"2023-03-06T16:53:12Z","published":"2023-03-06T16:53:12Z","title":"The AI Ghostwriter Effect: Users Do Not Perceive Ownership of\n  AI-Generated Text But Self-Declare as Authors","summary":"  Human-AI interaction in text production increases complexity in authorship.\nIn two empirical studies (n1 = 30 & n2 = 96), we investigate authorship and\nownership in human-AI collaboration for personalized language generation\nmodels. We show an AI Ghostwriter Effect: Users do not consider themselves the\nowners and authors of AI-generated text but refrain from publicly declaring AI\nauthorship. The degree of personalization did not impact the AI Ghostwriter\nEffect, and control over the model increased participants' sense of ownership.\nWe also found that the discrepancy between the sense of ownership and the\nauthorship declaration is stronger in interactions with a human ghostwriter and\nthat people use similar rationalizations for authorship in AI ghostwriters and\nhuman ghostwriters. We discuss how our findings relate to psychological\nownership and human-AI interaction to lay the foundations for adapting\nauthorship frameworks and user interfaces in AI in text-generation tasks.\n","authors":["Fiona Draxler","Anna Werner","Florian Lehmann","Matthias Hoppe","Albrecht Schmidt","Daniel Buschek","Robin Welsch"],"pdf_url":"https://arxiv.org/pdf/2303.03283v1.pdf","comment":"Pre-print; currently under review"},{"id":"http://arxiv.org/abs/2303.03278v1","updated":"2023-03-06T16:49:27Z","published":"2023-03-06T16:49:27Z","title":"Faithfulness-Aware Decoding Strategies for Abstractive Summarization","summary":"  Despite significant progress in understanding and improving faithfulness in\nabstractive summarization, the question of how decoding strategies affect\nfaithfulness is less studied. We present a systematic study of the effect of\ngeneration techniques such as beam search and nucleus sampling on faithfulness\nin abstractive summarization. We find a consistent trend where beam search with\nlarge beam sizes produces the most faithful summaries while nucleus sampling\ngenerates the least faithful ones. We propose two faithfulness-aware generation\nmethods to further improve faithfulness over current generation techniques: (1)\nranking candidates generated by beam search using automatic faithfulness\nmetrics and (2) incorporating lookahead heuristics that produce a faithfulness\nscore on the future summary. We show that both generation methods significantly\nimprove faithfulness across two datasets as evaluated by four automatic\nfaithfulness metrics and human evaluation. To reduce computational cost, we\ndemonstrate a simple distillation approach that allows the model to generate\nfaithful summaries with just greedy decoding. Our code is publicly available at\nhttps://github.com/amazon-science/faithful-summarization-generation\n","authors":["David Wan","Mengwen Liu","Kathleen McKeown","Markus Dreyer","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2303.03278v1.pdf","comment":"EACL 2023 (17 pages)"},{"id":"http://arxiv.org/abs/2207.04154v4","updated":"2023-03-06T16:37:49Z","published":"2022-07-08T23:42:56Z","title":"TalkToModel: Explaining Machine Learning Models with Interactive Natural\n  Language Conversations","summary":"  Machine Learning (ML) models are increasingly used to make critical decisions\nin real-world applications, yet they have become more complex, making them\nharder to understand. To this end, researchers have proposed several techniques\nto explain model predictions. However, practitioners struggle to use these\nexplainability techniques because they often do not know which one to choose\nand how to interpret the results of the explanations. In this work, we address\nthese challenges by introducing TalkToModel: an interactive dialogue system for\nexplaining machine learning models through conversations. Specifically,\nTalkToModel comprises of three key components: 1) a natural language interface\nfor engaging in conversations, making ML model explainability highly\naccessible, 2) a dialogue engine that adapts to any tabular model and dataset,\ninterprets natural language, maps it to appropriate explanations, and generates\ntext responses, and 3) an execution component that constructs the explanations.\nWe carried out extensive quantitative and human subject evaluations of\nTalkToModel. Overall, we found the conversational system understands user\ninputs on novel datasets and models with high accuracy, demonstrating the\nsystem's capacity to generalize to new situations. In real-world evaluations\nwith humans, 73% of healthcare workers (e.g., doctors and nurses) agreed they\nwould use TalkToModel over baseline point-and-click systems for explainability\nin a disease prediction task, and 85% of ML professionals agreed TalkToModel\nwas easier to use for computing explanations. Our findings demonstrate that\nTalkToModel is more effective for model explainability than existing systems,\nintroducing a new category of explainability tools for practitioners. Code &\ndemo released here: https://github.com/dylan-slack/TalkToModel.\n","authors":["Dylan Slack","Satyapriya Krishna","Himabindu Lakkaraju","Sameer Singh"],"pdf_url":"https://arxiv.org/pdf/2207.04154v4.pdf","comment":"Pre-print; comments welcome! Reach out to dslack@uci.edu v3 update\n  title and abstract"},{"id":"http://arxiv.org/abs/2302.05698v2","updated":"2023-03-06T15:24:56Z","published":"2023-02-11T14:02:08Z","title":"Compositional Exemplars for In-context Learning","summary":"  Large pretrained language models (LMs) have shown impressive In-Context\nLearning (ICL) ability, where the model learns to do an unseen task via a\nprompt consisting of input-output examples as the demonstration, without any\nparameter updates. The performance of ICL is highly dominated by the quality of\nthe selected in-context examples. However, previous selection methods are\nmostly based on simple heuristics, leading to sub-optimal performance. In this\nwork, we formulate in-context example selection as a subset selection problem.\nWe propose CEIL (Compositional Exemplars for In-context Learning), which is\ninstantiated by Determinantal Point Processes (DPPs) to model the interaction\nbetween the given input and in-context examples, and optimized through a\ncarefully-designed contrastive learning objective to obtain preference from\nLMs. We validate CEIL on 12 classification and generation datasets from 7\ndistinct NLP tasks, including sentiment analysis, paraphrase detection, natural\nlanguage inference, commonsense reasoning, open-domain question answering, code\ngeneration, and semantic parsing. Extensive experiments demonstrate not only\nthe state-of-the-art performance but also the transferability and\ncompositionality of CEIL, shedding new light on effective and efficient\nin-context learning. Our code is released at\nhttps://github.com/HKUNLP/icl-ceil.\n","authors":["Jiacheng Ye","Zhiyong Wu","Jiangtao Feng","Tao Yu","Lingpeng Kong"],"pdf_url":"https://arxiv.org/pdf/2302.05698v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03199v1","updated":"2023-03-06T14:58:42Z","published":"2023-03-06T14:58:42Z","title":"Choice Over Control: How Users Write with Large Language Models using\n  Diegetic and Non-Diegetic Prompting","summary":"  We propose a conceptual perspective on prompts for Large Language Models\n(LLMs) that distinguishes between (1) diegetic prompts (part of the narrative,\ne.g. \"Once upon a time, I saw a fox...\"), and (2) non-diegetic prompts\n(external, e.g. \"Write about the adventures of the fox.\"). With this lens, we\nstudy how 129 crowd workers on Prolific write short texts with different user\ninterfaces (1 vs 3 suggestions, with/out non-diegetic prompts; implemented with\nGPT-3): When the interface offered multiple suggestions and provided an option\nfor non-diegetic prompting, participants preferred choosing from multiple\nsuggestions over controlling them via non-diegetic prompts. When participants\nprovided non-diegetic prompts it was to ask for inspiration, topics or facts.\nSingle suggestions in particular were guided both with diegetic and\nnon-diegetic information. This work informs human-AI interaction with\ngenerative models by revealing that (1) writing non-diegetic prompts requires\neffort, (2) people combine diegetic and non-diegetic prompting, and (3) they\nuse their draft (i.e. diegetic information) and suggestion timing to\nstrategically guide LLMs.\n","authors":["Hai Dang","Sven Goller","Florian Lehmann","Daniel Buschek"],"pdf_url":"https://arxiv.org/pdf/2303.03199v1.pdf","comment":"17 pages, 9 figures, 3 tables, ACM CHI 2023"},{"id":"http://arxiv.org/abs/2303.03171v1","updated":"2023-03-06T14:39:54Z","published":"2023-03-06T14:39:54Z","title":"Neighborhood Contrastive Transformer for Change Captioning","summary":"  Change captioning is to describe the semantic change between a pair of\nsimilar images in natural language. It is more challenging than general image\ncaptioning, because it requires capturing fine-grained change information while\nbeing immune to irrelevant viewpoint changes, and solving syntax ambiguity in\nchange descriptions. In this paper, we propose a neighborhood contrastive\ntransformer to improve the model's perceiving ability for various changes under\ndifferent scenes and cognition ability for complex syntax structure.\nConcretely, we first design a neighboring feature aggregating to integrate\nneighboring context into each feature, which helps quickly locate the\ninconspicuous changes under the guidance of conspicuous referents. Then, we\ndevise a common feature distilling to compare two images at neighborhood level\nand extract common properties from each image, so as to learn effective\ncontrastive information between them. Finally, we introduce the explicit\ndependencies between words to calibrate the transformer decoder, which helps\nbetter understand complex syntax structure during training. Extensive\nexperimental results demonstrate that the proposed method achieves the\nstate-of-the-art performance on three public datasets with different change\nscenarios. The code is available at https://github.com/tuyunbin/NCT.\n","authors":["Yunbin Tu","Liang Li","Li Su","Ke Lu","Qingming Huang"],"pdf_url":"https://arxiv.org/pdf/2303.03171v1.pdf","comment":"Accepted by IEEE TMM"},{"id":"http://arxiv.org/abs/2303.03144v1","updated":"2023-03-06T13:59:37Z","published":"2023-03-06T13:59:37Z","title":"IPA-CLIP: Integrating Phonetic Priors into Vision and Language\n  Pretraining","summary":"  Recently, large-scale Vision and Language (V\\&L) pretraining has become the\nstandard backbone of many multimedia systems. While it has shown remarkable\nperformance even in unseen situations, it often performs in ways not intuitive\nto humans. Particularly, they usually do not consider the pronunciation of the\ninput, which humans would utilize to understand language, especially when it\ncomes to unknown words. Thus, this paper inserts phonetic prior into\nContrastive Language-Image Pretraining (CLIP), one of the V\\&L pretrained\nmodels, to make it consider the pronunciation similarity among its\npronunciation inputs. To achieve this, we first propose a phoneme embedding\nthat utilizes the phoneme relationships provided by the International Phonetic\nAlphabet (IPA) chart as a phonetic prior. Next, by distilling the frozen CLIP\ntext encoder, we train a pronunciation encoder employing the IPA-based\nembedding. The proposed model named IPA-CLIP comprises this pronunciation\nencoder and the original CLIP encoders (image and text). Quantitative\nevaluation reveals that the phoneme distribution on the embedding space\nrepresents phonetic relationships more accurately when using the proposed\nphoneme embedding. Furthermore, in some multimodal retrieval tasks, we confirm\nthat the proposed pronunciation encoder enhances the performance of the text\nencoder and that the pronunciation encoder handles nonsense words in a more\nphonetic manner than the text encoder. Finally, qualitative evaluation verifies\nthe correlation between the pronunciation encoder and human perception\nregarding pronunciation similarity.\n","authors":["Chihaya Matsuhira","Marc A. Kastner","Takahiro Komamizu","Takatsugu Hirayama","Keisuke Doman","Yasutomo Kawanishi","Ichiro Ide"],"pdf_url":"https://arxiv.org/pdf/2303.03144v1.pdf","comment":"11 pages, 8 figures, 5 Tables"},{"id":"http://arxiv.org/abs/2303.03124v1","updated":"2023-03-06T13:37:59Z","published":"2023-03-06T13:37:59Z","title":"IFAN: An Explainability-Focused Interaction Framework for Humans and NLP\n  Models","summary":"  Interpretability and human oversight are fundamental pillars of deploying\ncomplex NLP models into real-world applications. However, applying\nexplainability and human-in-the-loop methods requires technical proficiency.\nDespite existing toolkits for model understanding and analysis, options to\nintegrate human feedback are still limited. We propose IFAN, a framework for\nreal-time explanation-based interaction with NLP models. Through IFAN's\ninterface, users can provide feedback to selected model explanations, which is\nthen integrated through adapter layers to align the model with human rationale.\nWe show the system to be effective in debiasing a hate speech classifier with\nminimal performance loss. IFAN also offers a visual admin system and API to\nmanage models (and datasets) as well as control access rights. A demo is live\nat https://ifan.ml/\n","authors":["Edoardo Mosca","Daryna Dementieva","Tohid Ebrahim Ajdari","Maximilian Kummeth","Kirill Gringauz","Georg Groh"],"pdf_url":"https://arxiv.org/pdf/2303.03124v1.pdf","comment":"ACL Demo 2023 Submission"},{"id":"http://arxiv.org/abs/2303.03103v1","updated":"2023-03-06T13:15:25Z","published":"2023-03-06T13:15:25Z","title":"Towards Zero-Shot Functional Compositionality of Language Models","summary":"  Large Pre-trained Language Models (PLM) have become the most desirable\nstarting point in the field of NLP, as they have become remarkably good at\nsolving many individual tasks. Despite such success, in this paper, we argue\nthat current paradigms of working with PLMs are neglecting a critical aspect of\nmodeling human intelligence: functional compositionality. Functional\ncompositionality - the ability to compose learned tasks - has been a\nlong-standing challenge in the field of AI (and many other fields) as it is\nconsidered one of the hallmarks of human intelligence. An illustrative example\nof such is cross-lingual summarization, where a bilingual person\n(English-French) could directly summarize an English document into French\nsentences without having to translate the English document or summary into\nFrench explicitly. We discuss why this matter is an important open problem that\nrequires further attention from the field. Then, we show that current PLMs\n(e.g., GPT-2 and T5) don't have functional compositionality yet and it is far\nfrom human-level generalizability. Finally, we suggest several research\ndirections that could push the field towards zero-shot functional\ncompositionality of language models.\n","authors":["Hangyeol Yu","Myeongho Jeong","Jamin Shin","Hyeongdon Moon","Juneyoung Park","Seungtaek Choi"],"pdf_url":"https://arxiv.org/pdf/2303.03103v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03053v1","updated":"2023-03-06T11:54:58Z","published":"2023-03-06T11:54:58Z","title":"Crowdsourcing on Sensitive Data with Privacy-Preserving Text Rewriting","summary":"  Most tasks in NLP require labeled data. Data labeling is often done on\ncrowdsourcing platforms due to scalability reasons. However, publishing data on\npublic platforms can only be done if no privacy-relevant information is\nincluded. Textual data often contains sensitive information like person names\nor locations. In this work, we investigate how removing personally identifiable\ninformation (PII) as well as applying differential privacy (DP) rewriting can\nenable text with privacy-relevant information to be used for crowdsourcing. We\nfind that DP-rewriting before crowdsourcing can preserve privacy while still\nleading to good label quality for certain tasks and data. PII-removal led to\ngood label quality in all examined tasks, however, there are no privacy\nguarantees given.\n","authors":["Nina Mouhammad","Johannes Daxenberger","Benjamin Schiller","Ivan Habernal"],"pdf_url":"https://arxiv.org/pdf/2303.03053v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03032v1","updated":"2023-03-06T11:02:47Z","published":"2023-03-06T11:02:47Z","title":"DeCap: Decoding CLIP Latents for Zero-Shot Captioning via Text-Only\n  Training","summary":"  Large-scale pre-trained multi-modal models (e.g., CLIP) demonstrate strong\nzero-shot transfer capability in many discriminative tasks. Their adaptation to\nzero-shot image-conditioned text generation tasks has drawn increasing\ninterest. Prior arts approach to zero-shot captioning by either utilizing the\nexisting large language models (e.g., GPT-2) or pre-training the\nencoder-decoder network in an end-to-end manner. In this work, we propose a\nsimple framework, named DeCap, for zero-shot captioning. We introduce a\nlightweight visual-aware language decoder. This decoder is both data-efficient\nand computation-efficient: 1) it only requires the text data for training,\neasing the burden on the collection of paired data. 2) it does not require\nend-to-end training. When trained with text-only data, the decoder takes the\ntext embedding extracted from the off-the-shelf CLIP encoder as a prefix\nembedding. The challenge is that the decoder is trained on the text corpus but\nat the inference stage, it needs to generate captions based on visual inputs.\nThe modality gap issue is widely observed in multi-modal contrastive models\nthat prevents us from directly taking the visual embedding as the prefix\nembedding. We propose a training-free mechanism to reduce the modality gap. We\nproject the visual embedding into the CLIP text embedding space, while the\nprojected embedding retains the information of the visual input. Taking the\nprojected embedding as the prefix embedding, the decoder generates high-quality\ndescriptions that match the visual input. The experiments show that DeCap\noutperforms other zero-shot captioning methods and unpaired captioning methods\non the typical image captioning benchmarks, i.e., MSCOCO and NoCaps.\n","authors":["Wei Li","Linchao Zhu","Longyin Wen","Yi Yang"],"pdf_url":"https://arxiv.org/pdf/2303.03032v1.pdf","comment":"Accepted by ICLR 2023. Code is available at\n  https://github.com/dhg-wei/DeCap"},{"id":"http://arxiv.org/abs/2303.03019v1","updated":"2023-03-06T10:45:24Z","published":"2023-03-06T10:45:24Z","title":"NxPlain: Web-based Tool for Discovery of Latent Concepts","summary":"  The proliferation of deep neural networks in various domains has seen an\nincreased need for the interpretability of these models, especially in\nscenarios where fairness and trust are as important as model performance. A lot\nof independent work is being carried out to: i) analyze what linguistic and\nnon-linguistic knowledge is learned within these models, and ii) highlight the\nsalient parts of the input. We present NxPlain, a web application that provides\nan explanation of a model's prediction using latent concepts. NxPlain discovers\nlatent concepts learned in a deep NLP model, provides an interpretation of the\nknowledge learned in the model, and explains its predictions based on the used\nconcepts. The application allows users to browse through the latent concepts in\nan intuitive order, letting them efficiently scan through the most salient\nconcepts with a global corpus level view and a local sentence-level view. Our\ntool is useful for debugging, unraveling model bias, and for highlighting\nspurious correlations in a model. A hosted demo is available here:\nhttps://nxplain.qcri.org.\n","authors":["Fahim Dalvi","Nadir Durrani","Hassan Sajjad","Tamim Jaban","Musab Husaini","Ummar Abbas"],"pdf_url":"https://arxiv.org/pdf/2303.03019v1.pdf","comment":"EACL 2023"},{"id":"http://arxiv.org/abs/2303.03004v1","updated":"2023-03-06T10:08:51Z","published":"2023-03-06T10:08:51Z","title":"xCodeEval: A Large Scale Multilingual Multitask Benchmark for Code\n  Understanding, Generation, Translation and Retrieval","summary":"  The ability to solve problems is a hallmark of intelligence and has been an\nenduring goal in AI. AI systems that can create programs as solutions to\nproblems or assist developers in writing programs can increase productivity and\nmake programming more accessible. Recently, pre-trained large language models\nhave shown impressive abilities in generating new codes from natural language\ndescriptions, repairing buggy codes, translating codes between languages, and\nretrieving relevant code segments. However, the evaluation of these models has\noften been performed in a scattered way on only one or two specific tasks, in a\nfew languages, at a partial granularity (e.g., function) level and in many\ncases without proper training data. Even more concerning is that in most cases\nthe evaluation of generated codes has been done in terms of mere lexical\noverlap rather than actual execution whereas semantic similarity (or\nequivalence) of two code segments depends only on their ``execution\nsimilarity'', i.e., being able to get the same output for a given input.\n","authors":["Mohammad Abdullah Matin Khan","M Saiful Bari","Xuan Long Do","Weishi Wang","Md Rizwan Parvez","Shafiq Joty"],"pdf_url":"https://arxiv.org/pdf/2303.03004v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02995v1","updated":"2023-03-06T09:44:01Z","published":"2023-03-06T09:44:01Z","title":"HiCLIP: Contrastive Language-Image Pretraining with Hierarchy-aware\n  Attention","summary":"  The success of large-scale contrastive vision-language pretraining (CLIP) has\nbenefited both visual recognition and multimodal content understanding. The\nconcise design brings CLIP the advantage in inference efficiency against other\nvision-language models with heavier cross-attention fusion layers, making it a\npopular choice for a wide spectrum of downstream tasks. However, CLIP does not\nexplicitly capture the hierarchical nature of high-level and fine-grained\nsemantics conveyed in images and texts, which is arguably critical to\nvision-language understanding and reasoning. To this end, we equip both the\nvisual and language branches in CLIP with hierarchy-aware attentions, namely\nHierarchy-aware CLIP (HiCLIP), to progressively discover semantic hierarchies\nlayer-by-layer from both images and texts in an unsupervised manner. As a\nresult, such hierarchical aggregation significantly improves the cross-modal\nalignment. To demonstrate the advantages of HiCLIP, we conduct qualitative\nanalysis on its unsupervised hierarchy induction during inference, as well as\nextensive quantitative experiments on both visual recognition and\nvision-language downstream tasks.\n","authors":["Shijie Geng","Jianbo Yuan","Yu Tian","Yuxiao Chen","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.02995v1.pdf","comment":"Accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2302.03494v7","updated":"2023-03-06T09:34:38Z","published":"2023-02-06T04:21:59Z","title":"A Categorical Archive of ChatGPT Failures","summary":"  Large language models have been demonstrated to be valuable in different\nfields. ChatGPT, developed by OpenAI, has been trained using massive amounts of\ndata and simulates human conversation by comprehending context and generating\nappropriate responses. It has garnered significant attention due to its ability\nto effectively answer a broad range of human inquiries, with fluent and\ncomprehensive answers surpassing prior public chatbots in both security and\nusefulness. However, a comprehensive analysis of ChatGPT's failures is lacking,\nwhich is the focus of this study. Eleven categories of failures, including\nreasoning, factual errors, math, coding, and bias, are presented and discussed.\nThe risks, limitations, and societal implications of ChatGPT are also\nhighlighted. The goal of this study is to assist researchers and developers in\nenhancing future language models and chatbots.\n","authors":["Ali Borji"],"pdf_url":"https://arxiv.org/pdf/2302.03494v7.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01912v2","updated":"2023-03-06T09:29:40Z","published":"2023-03-03T13:24:17Z","title":"Ancient Chinese Word Segmentation and Part-of-Speech Tagging Using\n  Distant Supervision","summary":"  Ancient Chinese word segmentation (WSG) and part-of-speech tagging (POS) are\nimportant to study ancient Chinese, but the amount of ancient Chinese WSG and\nPOS tagging data is still rare. In this paper, we propose a novel augmentation\nmethod of ancient Chinese WSG and POS tagging data using distant supervision\nover parallel corpus. However, there are still mislabeled and unlabeled ancient\nChinese words inevitably in distant supervision. To address this problem, we\ntake advantage of the memorization effects of deep neural networks and a small\namount of annotated data to get a model with much knowledge and a little noise,\nand then we use this model to relabel the ancient Chinese sentences in parallel\ncorpus. Experiments show that the model trained over the relabeled data\noutperforms the model trained over the data generated from distant supervision\nand the annotated data. Our code is available at\nhttps://github.com/farlit/ACDS.\n","authors":["Shuo Feng","Piji Li"],"pdf_url":"https://arxiv.org/pdf/2303.01912v2.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2202.07646v3","updated":"2023-03-06T06:28:18Z","published":"2022-02-15T18:48:31Z","title":"Quantifying Memorization Across Neural Language Models","summary":"  Large language models (LMs) have been shown to memorize parts of their\ntraining data, and when prompted appropriately, they will emit the memorized\ntraining data verbatim. This is undesirable because memorization violates\nprivacy (exposing user data), degrades utility (repeated easy-to-memorize text\nis often low quality), and hurts fairness (some texts are memorized over\nothers).\n  We describe three log-linear relationships that quantify the degree to which\nLMs emit memorized training data. Memorization significantly grows as we\nincrease (1) the capacity of a model, (2) the number of times an example has\nbeen duplicated, and (3) the number of tokens of context used to prompt the\nmodel. Surprisingly, we find the situation becomes more complicated when\ngeneralizing these results across model families. On the whole, we find that\nmemorization in LMs is more prevalent than previously believed and will likely\nget worse as models continues to scale, at least without active mitigations.\n","authors":["Nicholas Carlini","Daphne Ippolito","Matthew Jagielski","Katherine Lee","Florian Tramer","Chiyuan Zhang"],"pdf_url":"https://arxiv.org/pdf/2202.07646v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02915v1","updated":"2023-03-06T06:20:55Z","published":"2023-03-06T06:20:55Z","title":"GlobalNER: Incorporating Non-local Information into Named Entity\n  Recognition","summary":"  Nowadays, many Natural Language Processing (NLP) tasks see the demand for\nincorporating knowledge external to the local information to further improve\nthe performance. However, there is little related work on Named Entity\nRecognition (NER), which is one of the foundations of NLP. Specifically, no\nstudies were conducted on the query generation and re-ranking for retrieving\nthe related information for the purpose of improving NER. This work\ndemonstrates the effectiveness of a DNN-based query generation method and a\nmention-aware re-ranking architecture based on BERTScore particularly for NER.\nIn the end, a state-of-the-art performance of 61.56 micro-f1 score on WNUT17\ndataset is achieved.\n","authors":["Chiao-Wei Hsu","Keh-Yih Su"],"pdf_url":"https://arxiv.org/pdf/2303.02915v1.pdf","comment":"13 pages, 5 figures"},{"id":"http://arxiv.org/abs/2303.02913v1","updated":"2023-03-06T06:20:25Z","published":"2023-03-06T06:20:25Z","title":"OpenICL: An Open-Source Framework for In-context Learning","summary":"  In recent years, In-context Learning (ICL) has gained increasing attention\nand emerged as the new paradigm for large language model (LLM) evaluation.\nUnlike traditional fine-tuning methods, ICL instead adapts the pre-trained\nmodels to unseen tasks without any parameter updates. However, the\nimplementation of ICL is sophisticated due to the diverse retrieval and\ninference methods involved, as well as the varying pre-processing requirements\nfor different models, datasets, and tasks. A unified and flexible framework for\nICL is urgently needed to ease the implementation of the aforementioned\ncomponents. To facilitate ICL research, we introduce OpenICL, an open-source\ntoolkit for ICL and LLM evaluation. OpenICL is research-friendly with a highly\nflexible architecture that users can easily combine different components to\nsuit their needs. It also provides various state-of-the-art retrieval and\ninference methods to streamline the process of adapting ICL to cutting-edge\nresearch. The effectiveness of OpenICL has been validated on a wide range of\nNLP tasks, including classification, QA, machine translation, and semantic\nparsing. As a side-product, we found OpenICL to be an efficient yet robust tool\nfor LLMs evaluation. OpenICL is released at\nhttps://github.com/Shark-NLP/OpenICL\n","authors":["Zhenyu Wu","YaoXiang Wang","Jiacheng Ye","Jiangtao Feng","Jingjing Xu","Yu Qiao","Zhiyong Wu"],"pdf_url":"https://arxiv.org/pdf/2303.02913v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02909v1","updated":"2023-03-06T06:04:46Z","published":"2023-03-06T06:04:46Z","title":"Dynamic Prompting: A Unified Framework for Prompt Tuning","summary":"  It has been demonstrated that prompt tuning is highly effective in\nefficiently eliciting knowledge from language models (LMs). However, the prompt\ntuning still lags behind fine-tuning, especially when the LMs are small.\nP-tuning v2 (Liu et al., 2021b) makes it comparable with finetuning by adding\ncontinuous prompts for every layer of the pre-trained model. However,\nprepending fixed soft prompts for all instances, regardless of their\ndiscrepancy, is doubtful. In particular, the inserted prompt position, length,\nand the representations of prompts for diversified instances through different\ntasks could all affect the prompt tuning performance. To fill this gap, we\npropose dynamic prompting (DP): the position, length, and prompt representation\ncan all be dynamically optimized with respect to different tasks and instances.\nWe conduct comprehensive experiments on the SuperGlue benchmark to validate our\nhypothesis and demonstrate substantial improvements. We also derive a unified\nframework for supporting our dynamic prompting strategy. In particular, we use\na simple learning network and Gumble- Softmax for learning instance-dependent\nguidance. Experimental results show that simple instance-level position-aware\nsoft prompts can improve the classification accuracy of up to 6 points on\naverage on five datasets, reducing its gap with fine-tuning. Besides, we also\nprove its universal usefulness under full-data, few-shot, and multitask\nregimes. Combining them together can even further unleash the power of DP,\nnarrowing the distance between finetuning.\n","authors":["Xianjun Yang","Wei Cheng","Xujiang Zhao","Linda Petzold","Haifeng Chen"],"pdf_url":"https://arxiv.org/pdf/2303.02909v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2303.02861v1","updated":"2023-03-06T03:25:59Z","published":"2023-03-06T03:25:59Z","title":"Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning","summary":"  Prompt tuning, in which a base pretrained model is adapted to each task via\nconditioning on learned prompt vectors, has emerged as a promising approach for\nefficiently adapting large language models to multiple downstream tasks.\nHowever, existing methods typically learn soft prompt vectors from scratch, and\nit has not been clear how to exploit the rich cross-task knowledge with prompt\nvectors in a multitask learning setting. We propose multitask prompt tuning\n(MPT), which first learns a single transferable prompt by distilling knowledge\nfrom multiple task-specific source prompts. We then learn multiplicative low\nrank updates to this shared prompt to efficiently adapt it to each downstream\ntarget task. Extensive experiments on 23 NLP datasets demonstrate that our\nproposed approach outperforms the state-of-the-art methods, including the full\nfinetuning baseline in some cases, despite only tuning 0.035% as many\ntask-specific parameters.\n","authors":["Zhen Wang","Rameswar Panda","Leonid Karlinsky","Rogerio Feris","Huan Sun","Yoon Kim"],"pdf_url":"https://arxiv.org/pdf/2303.02861v1.pdf","comment":"ICLR 2023. Project page: https://zhenwang9102.github.io/mpt.html"},{"id":"http://arxiv.org/abs/2303.02860v1","updated":"2023-03-06T03:25:43Z","published":"2023-03-06T03:25:43Z","title":"A Multi-Grained Self-Interpretable Symbolic-Neural Model For\n  Single/Multi-Labeled Text Classification","summary":"  Deep neural networks based on layer-stacking architectures have historically\nsuffered from poor inherent interpretability. Meanwhile, symbolic probabilistic\nmodels function with clear interpretability, but how to combine them with\nneural networks to enhance their performance remains to be explored. In this\npaper, we try to marry these two systems for text classification via a\nstructured language model. We propose a Symbolic-Neural model that can learn to\nexplicitly predict class labels of text spans from a constituency tree without\nrequiring any access to span-level gold labels. As the structured language\nmodel learns to predict constituency trees in a self-supervised manner, only\nraw texts and sentence-level labels are required as training data, which makes\nit essentially a general constituent-level self-interpretable classification\nmodel. Our experiments demonstrate that our approach could achieve good\nprediction accuracy in downstream tasks. Meanwhile, the predicted span labels\nare consistent with human rationales to a certain degree.\n","authors":["Xiang Hu","Xinyu Kong","Kewei Tu"],"pdf_url":"https://arxiv.org/pdf/2303.02860v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.02846v1","updated":"2023-03-06T02:52:37Z","published":"2023-03-06T02:52:37Z","title":"Reducing Spurious Correlations for Aspect-Based Sentiment Analysis with\n  Variational Information Bottleneck and Contrastive Learning","summary":"  The literature on aspect-based sentiment analysis (ABSA) has been overwhelmed\nby deep neural networks, yielding state-of-the-art results for ABSA. However,\nthese deep models are susceptible to learning spurious correlations between\ninput features and output labels, which in general suffer from poor robustness\nand generalization. In this paper, we propose a novel Contrastive Variational\nInformation Bottleneck framework (called CVIB) to reduce spurious correlations\nfor ABSA. The proposed CVIB framework is composed of an original network and a\nself-pruned network, and these two networks are optimized simultaneously via\ncontrastive learning. Concretely, we employ the Variational Information\nBottleneck (VIB) principle to learn an informative and compressed network\n(self-pruned network) from the original network, which discards the superfluous\npatterns or spurious correlations between input features and prediction labels.\nThen, self-pruning contrastive learning is devised to pull together\nsemantically similar positive pairs and push away dissimilar pairs, where the\nrepresentations of the anchor learned by the original and self-pruned networks\nrespectively are regarded as a positive pair while the representations of two\ndifferent sentences within a mini-batch are treated as a negative pair.\nExtensive experiments on five benchmark ABSA datasets demonstrate that our CVIB\nmethod achieves better performance than the strong competitors in terms of\noverall prediction performance, robustness, and generalization.\n","authors":["Mingshan Chang","Min Yang","Qingshan Jiang","Ruifeng Xu"],"pdf_url":"https://arxiv.org/pdf/2303.02846v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02841v1","updated":"2023-03-06T02:24:48Z","published":"2023-03-06T02:24:48Z","title":"Model-Agnostic Meta-Learning for Natural Language Understanding Tasks in\n  Finance","summary":"  Natural language understanding(NLU) is challenging for finance due to the\nlack of annotated data and the specialized language in that domain. As a\nresult, researchers have proposed to use pre-trained language model and\nmulti-task learning to learn robust representations. However, aggressive\nfine-tuning often causes over-fitting and multi-task learning may favor tasks\nwith significantly larger amounts data, etc. To address these problems, in this\npaper, we investigate model-agnostic meta-learning algorithm(MAML) in\nlow-resource financial NLU tasks. Our contribution includes: 1. we explore the\nperformance of MAML method with multiple types of tasks: GLUE datasets, SNLI,\nSci-Tail and Financial PhraseBank; 2. we study the performance of MAML method\nwith multiple single-type tasks: a real scenario stock price prediction problem\nwith twitter text data. Our models achieve the state-of-the-art performance\naccording to the experimental results, which demonstrate that our method can\nadapt fast and well to low-resource situations.\n","authors":["Bixing Yan","Shaoling Chen","Yuxuan He","Zhihan Li"],"pdf_url":"https://arxiv.org/pdf/2303.02841v1.pdf","comment":"13 pages, 6 figures, 8 tables"},{"id":"http://arxiv.org/abs/2302.10866v2","updated":"2023-03-06T01:26:15Z","published":"2023-02-21T18:29:25Z","title":"Hyena Hierarchy: Towards Larger Convolutional Language Models","summary":"  Recent advances in deep learning have relied heavily on the use of large\nTransformers due to their ability to learn at scale. However, the core building\nblock of Transformers, the attention operator, exhibits quadratic cost in\nsequence length, limiting the amount of context accessible. Existing\nsubquadratic methods based on low-rank and sparse approximations need to be\ncombined with dense attention layers to match Transformers, indicating a gap in\ncapability. In this work, we propose Hyena, a subquadratic drop-in replacement\nfor attention constructed by interleaving implicitly parametrized long\nconvolutions and data-controlled gating. In recall and reasoning tasks on\nsequences of thousands to hundreds of thousands of tokens, Hyena improves\naccuracy by more than 50 points over operators relying on state-spaces and\nother implicit and explicit methods, matching attention-based models. We set a\nnew state-of-the-art for dense-attention-free architectures on language\nmodeling in standard datasets (WikiText103 and The Pile), reaching Transformer\nquality with a 20% reduction in training compute required at sequence length\n2K. Hyena operators are twice as fast as highly optimized attention at sequence\nlength 8K, and 100x faster at sequence length 64K.\n","authors":["Michael Poli","Stefano Massaroli","Eric Nguyen","Daniel Y. Fu","Tri Dao","Stephen Baccus","Yoshua Bengio","Stefano Ermon","Christopher Ré"],"pdf_url":"https://arxiv.org/pdf/2302.10866v2.pdf","comment":"Additional results (PG-19, LAMBADA)"},{"id":"http://arxiv.org/abs/2205.10475v2","updated":"2023-03-06T00:49:01Z","published":"2022-05-21T00:58:22Z","title":"DeepStruct: Pretraining of Language Models for Structure Prediction","summary":"  We introduce a method for improving the structural understanding abilities of\nlanguage models. Unlike previous approaches that finetune the models with\ntask-specific augmentation, we pretrain language models on a collection of\ntask-agnostic corpora to generate structures from text. Our structure\npretraining enables zero-shot transfer of the learned knowledge that models\nhave about the structure tasks. We study the performance of this approach on 28\ndatasets, spanning 10 structure prediction tasks including open information\nextraction, joint entity and relation extraction, named entity recognition,\nrelation classification, semantic role labeling, event extraction, coreference\nresolution, factual probe, intent detection, and dialogue state tracking. We\nfurther enhance the pretraining with the task-specific training sets. We show\nthat a 10B parameter language model transfers non-trivially to most tasks and\nobtains state-of-the-art performance on 21 of 28 datasets that we evaluate.\n","authors":["Chenguang Wang","Xiao Liu","Zui Chen","Haoyun Hong","Jie Tang","Dawn Song"],"pdf_url":"https://arxiv.org/pdf/2205.10475v2.pdf","comment":"ACL 2022"},{"id":"http://arxiv.org/abs/2303.03548v1","updated":"2023-03-06T23:16:24Z","published":"2023-03-06T23:16:24Z","title":"Large Language Models as Zero-Shot Human Models for Human-Robot\n  Interaction","summary":"  Human models play a crucial role in human-robot interaction (HRI), enabling\nrobots to consider the impact of their actions on people and plan their\nbehavior accordingly. However, crafting good human models is challenging;\ncapturing context-dependent human behavior requires significant prior knowledge\nand/or large amounts of interaction data, both of which are difficult to\nobtain. In this work, we explore the potential of large-language models (LLMs)\n-- which have consumed vast amounts of human-generated text data -- to act as\nzero-shot human models for HRI. Our experiments on three social datasets yield\npromising results; the LLMs are able to achieve performance comparable to\npurpose-built models. That said, we also discuss current limitations, such as\nsensitivity to prompts and spatial/numerical reasoning mishaps. Based on our\nfindings, we demonstrate how LLM-based human models can be integrated into a\nsocial robot's planning process and applied in HRI scenarios. Specifically, we\npresent one case study on a simulated trust-based table-clearing task and\nreplicate past results that relied on custom models. Next, we conduct a new\nrobot utensil-passing experiment (n = 65) where preliminary results show that\nplanning with a LLM-based human model can achieve gains over a basic myopic\nplan. In summary, our results show that LLMs offer a promising (but incomplete)\napproach to human modeling for HRI.\n","authors":["Bowen Zhang","Harold Soh"],"pdf_url":"https://arxiv.org/pdf/2303.03548v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2303.03542v1","updated":"2023-03-06T22:59:02Z","published":"2023-03-06T22:59:02Z","title":"Multi-resolution Interpretation and Diagnostics Tool for Natural\n  Language Classifiers","summary":"  Developing explainability methods for Natural Language Processing (NLP)\nmodels is a challenging task, for two main reasons. First, the high\ndimensionality of the data (large number of tokens) results in low coverage and\nin turn small contributions for the top tokens, compared to the overall model\nperformance. Second, owing to their textual nature, the input variables, after\nappropriate transformations, are effectively binary (presence or absence of a\ntoken in an observation), making the input-output relationship difficult to\nunderstand. Common NLP interpretation techniques do not have flexibility in\nresolution, because they usually operate at word-level and provide fully local\n(message level) or fully global (over all messages) summaries. The goal of this\npaper is to create more flexible model explainability summaries by segments of\nobservation or clusters of words that are semantically related to each other.\nIn addition, we introduce a root cause analysis method for NLP models, by\nanalyzing representative False Positive and False Negative examples from\ndifferent segments. At the end, we illustrate, using a Yelp review data set\nwith three segments (Restaurant, Hotel, and Beauty), that exploiting\ngroup/cluster structures in words and/or messages can aid in the interpretation\nof decisions made by NLP models and can be utilized to assess the model's\nsensitivity or bias towards gender, syntax, and word meanings.\n","authors":["Peyman Jalali","Nengfeng Zhou","Yufei Yu"],"pdf_url":"https://arxiv.org/pdf/2303.03542v1.pdf","comment":"16 pages, 0 figure"},{"id":"http://arxiv.org/abs/2211.02011v4","updated":"2023-03-06T22:28:30Z","published":"2022-11-03T17:26:44Z","title":"Inverse scaling can become U-shaped","summary":"  Scaling up language models has been empirically shown to improve performance\nand unlock emergent abilities. Conversely, observing worse performance as a\nfunction of scale (\"inverse scaling\") would indicate that scaling encourages\nbehaviors that are misaligned with human preferences. The Inverse Scaling Prize\n(McKenzie et al. 2022) identified eleven such inverse scaling tasks, evaluated\non models of up to 280B parameters and up to 500 zettaFLOPs of training\ncompute. This paper takes a closer look at these inverse scaling tasks. We\nevaluate models of up to 540B parameters, trained on five times more compute\nthan those evaluated in the Inverse Scaling Prize. With this increased range of\nmodel sizes and training compute, only four out of the eleven tasks remain\ninverse scaling. Six out of the eleven tasks exhibit what we call \"U-shaped\nscaling\" -- performance decreases up to a certain model size, and then\nincreases again up to the largest model evaluated (the one remaining task\ndisplays positive scaling). U-shaped scaling suggests that the inverse scaling\ntrend observed in McKenzie et al. (2022) may not continue to hold for larger\nmodels, and adds further support to the claim that sufficiently large models\nunlock emergent abilities.\n","authors":["Jason Wei","Najoung Kim","Yi Tay","Quoc V. Le"],"pdf_url":"https://arxiv.org/pdf/2211.02011v4.pdf","comment":"v4 reports correct results on Round 2 tasks and includes results for\n  additional one-shot evaluation"},{"id":"http://arxiv.org/abs/2302.09051v2","updated":"2023-03-06T21:46:08Z","published":"2023-02-17T18:31:31Z","title":"Complex QA and language models hybrid architectures, Survey","summary":"  This paper provides a survey of the state of the art of hybrid language\nmodels architectures and strategies for \"complex\" question-answering (QA, CQA,\nCPS). Very large language models are good at leveraging public data on standard\nproblems but once you want to tackle more specific complex questions or\nproblems you may need specific architecture, knowledge, skills, tasks, methods,\nsensitive data, performance, human approval and versatile feedback... This\nsurvey extends findings from the robust community edited research papers BIG,\nBLOOM and HELM which open source, benchmark and analyze limits and challenges\nof large language models in terms of tasks complexity and strict evaluation on\naccuracy (e.g. fairness, robustness, toxicity, ...). It identifies the key\nelements used with Large Language Models (LLM) to solve complex questions or\nproblems. Recent projects like ChatGPT and GALACTICA have allowed\nnon-specialists to grasp the great potential as well as the equally strong\nlimitations of language models in complex QA. Hybridizing these models with\ndifferent components could allow to overcome these different limits and go much\nfurther. We discuss some challenges associated with complex QA, including\ndomain adaptation, decomposition and efficient multi-step QA, long form QA,\nnon-factoid QA, safety and multi-sensitivity data protection, multimodal\nsearch, hallucinations, QA explainability and truthfulness, time dimension.\nTherefore we review current solutions and promising strategies, using elements\nsuch as hybrid LLM architectures, human-in-the-loop reinforcement learning,\nprompting adaptation, neuro-symbolic and structured knowledge grounding,\nprogram synthesis, and others. We analyze existing solutions and provide an\noverview of the current research and trends in the area of complex QA.\n","authors":["Xavier Daull","Patrice Bellot","Emmanuel Bruno","Vincent Martin","Elisabeth Murisasco"],"pdf_url":"https://arxiv.org/pdf/2302.09051v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03510v1","updated":"2023-03-06T21:36:19Z","published":"2023-03-06T21:36:19Z","title":"Guilt Detection in Text: A Step Towards Understanding Complex Emotions","summary":"  We introduce a novel Natural Language Processing (NLP) task called Guilt\ndetection, which focuses on detecting guilt in text. We identify guilt as a\ncomplex and vital emotion that has not been previously studied in NLP, and we\naim to provide a more fine-grained analysis of it. To address the lack of\npublicly available corpora for guilt detection, we created VIC, a dataset\ncontaining 4622 texts from three existing emotion detection datasets that we\nbinarized into guilt and no-guilt classes. We experimented with traditional\nmachine learning methods using bag-of-words and term frequency-inverse document\nfrequency features, achieving a 72% f1 score with the highest-performing model.\nOur study provides a first step towards understanding guilt in text and opens\nthe door for future research in this area.\n","authors":["Abdul Gafar Manuel Meque","Nisar Hussain","Grigori Sidorov","Alexander Gelbukh"],"pdf_url":"https://arxiv.org/pdf/2303.03510v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03487v1","updated":"2023-03-06T20:35:51Z","published":"2023-03-06T20:35:51Z","title":"Two-stage Pipeline for Multilingual Dialect Detection","summary":"  Dialect Identification is a crucial task for localizing various Large\nLanguage Models. This paper outlines our approach to the VarDial 2023 shared\ntask. Here we have to identify three or two dialects from three languages each\nwhich results in a 9-way classification for Track-1 and 6-way classification\nfor Track-2 respectively. Our proposed approach consists of a two-stage system\nand outperforms other participants' systems and previous works in this domain.\nWe achieve a score of 58.54% for Track-1 and 85.61% for Track-2. Our codebase\nis available publicly (https://github.com/ankit-vaidya19/EACL_VarDial2023).\n","authors":["Ankit Vaidya","Aditya Kane"],"pdf_url":"https://arxiv.org/pdf/2303.03487v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03480v1","updated":"2023-03-06T20:19:19Z","published":"2023-03-06T20:19:19Z","title":"Can an Embodied Agent Find Your \"Cat-shaped Mug\"? LLM-Based Zero-Shot\n  Object Navigation","summary":"  We present LGX, a novel algorithm for Object Goal Navigation in a\n\"language-driven, zero-shot manner\", where an embodied agent navigates to an\narbitrarily described target object in a previously unexplored environment. Our\napproach leverages the capabilities of Large Language Models (LLMs) for making\nnavigational decisions by mapping the LLMs implicit knowledge about the\nsemantic context of the environment into sequential inputs for robot motion\nplanning. Simultaneously, we also conduct generalized target object detection\nusing a pre-trained Vision-Language grounding model. We achieve\nstate-of-the-art zero-shot object navigation results on RoboTHOR with a success\nrate (SR) improvement of over 27% over the current baseline of the OWL-ViT CLIP\non Wheels (OWL CoW). Furthermore, we study the usage of LLMs for robot\nnavigation and present an analysis of the various semantic factors affecting\nmodel output. Finally, we showcase the benefits of our approach via real-world\nexperiments that indicate the superior performance of LGX when navigating to\nand detecting visually unique objects.\n","authors":["Vishnu Sashank Dorbala","James F. Mullen Jr.","Dinesh Manocha"],"pdf_url":"https://arxiv.org/pdf/2303.03480v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2207.00056v3","updated":"2023-03-06T19:39:18Z","published":"2022-06-30T18:42:06Z","title":"MultiViz: Towards Visualizing and Understanding Multimodal Models","summary":"  The promise of multimodal models for real-world applications has inspired\nresearch in visualizing and understanding their internal mechanics with the end\ngoal of empowering stakeholders to visualize model behavior, perform model\ndebugging, and promote trust in machine learning models. However, modern\nmultimodal models are typically black-box neural networks, which makes it\nchallenging to understand their internal mechanics. How can we visualize the\ninternal modeling of multimodal interactions in these models? Our paper aims to\nfill this gap by proposing MultiViz, a method for analyzing the behavior of\nmultimodal models by scaffolding the problem of interpretability into 4 stages:\n(1) unimodal importance: how each modality contributes towards downstream\nmodeling and prediction, (2) cross-modal interactions: how different modalities\nrelate with each other, (3) multimodal representations: how unimodal and\ncross-modal interactions are represented in decision-level features, and (4)\nmultimodal prediction: how decision-level features are composed to make a\nprediction. MultiViz is designed to operate on diverse modalities, models,\ntasks, and research areas. Through experiments on 8 trained models across 6\nreal-world tasks, we show that the complementary stages in MultiViz together\nenable users to (1) simulate model predictions, (2) assign interpretable\nconcepts to features, (3) perform error analysis on model misclassifications,\nand (4) use insights from error analysis to debug models. MultiViz is publicly\navailable, will be regularly updated with new interpretation tools and metrics,\nand welcomes inputs from the community.\n","authors":["Paul Pu Liang","Yiwei Lyu","Gunjan Chhablani","Nihal Jain","Zihao Deng","Xingbo Wang","Louis-Philippe Morency","Ruslan Salakhutdinov"],"pdf_url":"https://arxiv.org/pdf/2207.00056v3.pdf","comment":"ICLR 2023. Code available at: https://github.com/pliang279/MultiViz"},{"id":"http://arxiv.org/abs/2303.03457v1","updated":"2023-03-06T19:29:20Z","published":"2023-03-06T19:29:20Z","title":"Spelling convention sensitivity in neural language models","summary":"  We examine whether large neural language models, trained on very large\ncollections of varied English text, learn the potentially long-distance\ndependency of British versus American spelling conventions, i.e., whether\nspelling is consistently one or the other within model-generated strings. In\ncontrast to long-distance dependencies in non-surface underlying structure\n(e.g., syntax), spelling consistency is easier to measure both in LMs and the\ntext corpora used to train them, which can provide additional insight into\ncertain observed model behaviors. Using a set of probe words unique to either\nBritish or American English, we first establish that training corpora exhibit\nsubstantial (though not total) consistency. A large T5 language model does\nappear to internalize this consistency, though only with respect to observed\nlexical items (not nonce words with British/American spelling patterns). We\nfurther experiment with correcting for biases in the training data by\nfine-tuning T5 on synthetic data that has been debiased, and find that\nfinetuned T5 remains only somewhat sensitive to spelling consistency. Further\nexperiments show GPT2 to be similarly limited.\n","authors":["Elizabeth Nielsen","Christo Kirov","Brian Roark"],"pdf_url":"https://arxiv.org/pdf/2303.03457v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03919v1","updated":"2023-03-06T04:22:33Z","published":"2023-03-06T04:22:33Z","title":"Data Portraits: Recording Foundation Model Training Data","summary":"  Foundation models are trained on increasingly immense and opaque datasets.\nEven while these models are now key in AI system building, it can be difficult\nto answer the straightforward question: has the model already encountered a\ngiven example during training? We therefore propose a widespread adoption of\nData Portraits: artifacts that record training data and allow for downstream\ninspection. First we outline the properties of such an artifact and discuss how\nexisting solutions can be used to increase transparency. We then propose and\nimplement a solution based on data sketching, stressing fast and space\nefficient querying. Using our tool, we document a popular large language\nmodeling corpus (the Pile) and show that our solution enables answering\nquestions about test set leakage and model plagiarism. Our tool is lightweight\nand fast, costing only 3% of the dataset size in overhead. We release a demo of\nour tools at dataportraits.org and call on dataset and model creators to\nrelease Data Portraits as a complement to current documentation practices.\n","authors":["Marc Marone","Benjamin Van Durme"],"pdf_url":"https://arxiv.org/pdf/2303.03919v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2303.03373v1","updated":"2023-03-06T18:56:26Z","published":"2023-03-06T18:56:26Z","title":"Detecting Human-Object Contact in Images","summary":"  Humans constantly contact objects to move and perform tasks. Thus, detecting\nhuman-object contact is important for building human-centered artificial\nintelligence. However, there exists no robust method to detect contact between\nthe body and the scene from an image, and there exists no dataset to learn such\na detector. We fill this gap with HOT (\"Human-Object conTact\"), a new dataset\nof human-object contacts for images. To build HOT, we use two data sources: (1)\nWe use the PROX dataset of 3D human meshes moving in 3D scenes, and\nautomatically annotate 2D image areas for contact via 3D mesh proximity and\nprojection. (2) We use the V-COCO, HAKE and Watch-n-Patch datasets, and ask\ntrained annotators to draw polygons for the 2D image areas where contact takes\nplace. We also annotate the involved body part of the human body. We use our\nHOT dataset to train a new contact detector, which takes a single color image\nas input, and outputs 2D contact heatmaps as well as the body-part labels that\nare in contact. This is a new and challenging task that extends current\nfoot-ground or hand-object contact detectors to the full generality of the\nwhole body. The detector uses a part-attention branch to guide contact\nestimation through the context of the surrounding body parts and scene. We\nevaluate our detector extensively, and quantitative results show that our model\noutperforms baselines, and that all components contribute to better\nperformance. Results on images from an online repository show reasonable\ndetections and generalizability.\n","authors":["Yixin Chen","Sai Kumar Dwivedi","Michael J. Black","Dimitrios Tzionas"],"pdf_url":"https://arxiv.org/pdf/2303.03373v1.pdf","comment":"Accepted at CVPR 2023"},{"id":"http://arxiv.org/abs/2303.03369v1","updated":"2023-03-06T18:54:46Z","published":"2023-03-06T18:54:46Z","title":"Multimodal Prompting with Missing Modalities for Visual Recognition","summary":"  In this paper, we tackle two challenges in multimodal learning for visual\nrecognition: 1) when missing-modality occurs either during training or testing\nin real-world situations; and 2) when the computation resources are not\navailable to finetune on heavy transformer models. To this end, we propose to\nutilize prompt learning and mitigate the above two challenges together.\nSpecifically, our modality-missing-aware prompts can be plugged into multimodal\ntransformers to handle general missing-modality cases, while only requiring\nless than 1% learnable parameters compared to training the entire model. We\nfurther explore the effect of different prompt configurations and analyze the\nrobustness to missing modality. Extensive experiments are conducted to show the\neffectiveness of our prompt learning framework that improves the performance\nunder various missing-modality cases, while alleviating the requirement of\nheavy model re-training. Code is available.\n","authors":["Yi-Lun Lee","Yi-Hsuan Tsai","Wei-Chen Chiu","Chen-Yu Lee"],"pdf_url":"https://arxiv.org/pdf/2303.03369v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2303.03366v1","updated":"2023-03-06T18:50:06Z","published":"2023-03-06T18:50:06Z","title":"Referring Multi-Object Tracking","summary":"  Existing referring understanding tasks tend to involve the detection of a\nsingle text-referred object. In this paper, we propose a new and general\nreferring understanding task, termed referring multi-object tracking (RMOT).\nIts core idea is to employ a language expression as a semantic cue to guide the\nprediction of multi-object tracking. To the best of our knowledge, it is the\nfirst work to achieve an arbitrary number of referent object predictions in\nvideos. To push forward RMOT, we construct one benchmark with scalable\nexpressions based on KITTI, named Refer-KITTI. Specifically, it provides 18\nvideos with 818 expressions, and each expression in a video is annotated with\nan average of 10.7 objects. Further, we develop a transformer-based\narchitecture TransRMOT to tackle the new task in an online manner, which\nachieves impressive detection performance and outperforms other counterparts.\n","authors":["Dongming Wu","Wencheng Han","Tiancai Wang","Xingping Dong","Xiangyu Zhang","Jianbing Shen"],"pdf_url":"https://arxiv.org/pdf/2303.03366v1.pdf","comment":"CVPR2023"},{"id":"http://arxiv.org/abs/2303.03364v1","updated":"2023-03-06T18:49:39Z","published":"2023-03-06T18:49:39Z","title":"Leveraging Scene Embeddings for Gradient-Based Motion Planning in Latent\n  Space","summary":"  Motion planning framed as optimisation in structured latent spaces has\nrecently emerged as competitive with traditional methods in terms of planning\nsuccess while significantly outperforming them in terms of computational speed.\nHowever, the real-world applicability of recent work in this domain remains\nlimited by the need to express obstacle information directly in state-space,\ninvolving simple geometric primitives. In this work we address this challenge\nby leveraging learned scene embeddings together with a generative model of the\nrobot manipulator to drive the optimisation process. In addition, we introduce\nan approach for efficient collision checking which directly regularises the\noptimisation undertaken for planning. Using simulated as well as real-world\nexperiments, we demonstrate that our approach, AMP-LS, is able to successfully\nplan in novel, complex scenes while outperforming traditional planning\nbaselines in terms of computation speed by an order of magnitude. We show that\nthe resulting system is fast enough to enable closed-loop planning in\nreal-world dynamic scenes.\n","authors":["Jun Yamada","Chia-Man Hung","Jack Collins","Ioannis Havoutis","Ingmar Posner"],"pdf_url":"https://arxiv.org/pdf/2303.03364v1.pdf","comment":"Project website: https://amp-ls.github.io/"},{"id":"http://arxiv.org/abs/2303.03361v1","updated":"2023-03-06T18:48:18Z","published":"2023-03-06T18:48:18Z","title":"Nerflets: Local Radiance Fields for Efficient Structure-Aware 3D Scene\n  Representation from 2D Supervisio","summary":"  We address efficient and structure-aware 3D scene representation from images.\nNerflets are our key contribution -- a set of local neural radiance fields that\ntogether represent a scene. Each nerflet maintains its own spatial position,\norientation, and extent, within which it contributes to panoptic, density, and\nradiance reconstructions. By leveraging only photometric and inferred panoptic\nimage supervision, we can directly and jointly optimize the parameters of a set\nof nerflets so as to form a decomposed representation of the scene, where each\nobject instance is represented by a group of nerflets. During experiments with\nindoor and outdoor environments, we find that nerflets: (1) fit and approximate\nthe scene more efficiently than traditional global NeRFs, (2) allow the\nextraction of panoptic and photometric renderings from arbitrary views, and (3)\nenable tasks rare for NeRFs, such as 3D panoptic segmentation and interactive\nediting.\n","authors":["Xiaoshuai Zhang","Abhijit Kundu","Thomas Funkhouser","Leonidas Guibas","Hao Su","Kyle Genova"],"pdf_url":"https://arxiv.org/pdf/2303.03361v1.pdf","comment":"accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2209.12152v3","updated":"2023-03-06T18:28:18Z","published":"2022-09-25T05:21:59Z","title":"All are Worth Words: A ViT Backbone for Diffusion Models","summary":"  Vision transformers (ViT) have shown promise in various vision tasks while\nthe U-Net based on a convolutional neural network (CNN) remains dominant in\ndiffusion models. We design a simple and general ViT-based architecture (named\nU-ViT) for image generation with diffusion models. U-ViT is characterized by\ntreating all inputs including the time, condition and noisy image patches as\ntokens and employing long skip connections between shallow and deep layers. We\nevaluate U-ViT in unconditional and class-conditional image generation, as well\nas text-to-image generation tasks, where U-ViT is comparable if not superior to\na CNN-based U-Net of a similar size. In particular, latent diffusion models\nwith U-ViT achieve record-breaking FID scores of 2.29 in class-conditional\nimage generation on ImageNet 256x256, and 5.48 in text-to-image generation on\nMS-COCO, among methods without accessing large external datasets during the\ntraining of generative models. Our results suggest that, for diffusion-based\nimage modeling, the long skip connection is crucial while the down-sampling and\nup-sampling operators in CNN-based U-Net are not always necessary. We believe\nthat U-ViT can provide insights for future research on backbones in diffusion\nmodels and benefit generative modeling on large scale cross-modality datasets.\n","authors":["Fan Bao","Shen Nie","Kaiwen Xue","Yue Cao","Chongxuan Li","Hang Su","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2209.12152v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03341v1","updated":"2023-03-06T18:21:16Z","published":"2023-03-06T18:21:16Z","title":"Deep Age-Invariant Fingerprint Segmentation System","summary":"  Fingerprint-based identification systems achieve higher accuracy when a slap\ncontaining multiple fingerprints of a subject is used instead of a single\nfingerprint. However, segmenting or auto-localizing all fingerprints in a slap\nimage is a challenging task due to the different orientations of fingerprints,\nnoisy backgrounds, and the smaller size of fingertip components. The presence\nof slap images in a real-world dataset where one or more fingerprints are\nrotated makes it challenging for a biometric recognition system to localize and\nlabel the fingerprints automatically. Improper fingerprint localization and\nfinger labeling errors lead to poor matching performance. In this paper, we\nintroduce a method to generate arbitrary angled bounding boxes using a deep\nlearning-based algorithm that precisely localizes and labels fingerprints from\nboth axis-aligned and over-rotated slap images. We built a fingerprint\nsegmentation model named CRFSEG (Clarkson Rotated Fingerprint segmentation\nModel) by updating the previously proposed CFSEG model which was based on\ntraditional Faster R-CNN architecture [21]. CRFSEG improves upon the Faster\nR-CNN algorithm with arbitrarily angled bounding boxes that allow the CRFSEG to\nperform better in challenging slap images. After training the CRFSEG algorithm\non a new dataset containing slap images collected from both adult and children\nsubjects, our results suggest that the CRFSEG model was invariant across\ndifferent age groups and can handle over-rotated slap images successfully. In\nthe Combined dataset containing both normal and rotated images of adult and\nchildren subjects, we achieved a matching accuracy of 97.17%, which\noutperformed state-of-the-art VeriFinger (94.25%) and NFSEG segmentation\nsystems (80.58%).\n","authors":["M. G. Sarwar Murshed","Keivan Bahmani","Stephanie Schuckers","Faraz Hussain"],"pdf_url":"https://arxiv.org/pdf/2303.03341v1.pdf","comment":"20 Pages, 14 figures, Journal"},{"id":"http://arxiv.org/abs/2302.03956v2","updated":"2023-03-06T18:12:46Z","published":"2023-02-08T09:26:22Z","title":"Neural Congealing: Aligning Images to a Joint Semantic Atlas","summary":"  We present Neural Congealing -- a zero-shot self-supervised framework for\ndetecting and jointly aligning semantically-common content across a given set\nof images. Our approach harnesses the power of pre-trained DINO-ViT features to\nlearn: (i) a joint semantic atlas -- a 2D grid that captures the mode of\nDINO-ViT features in the input set, and (ii) dense mappings from the unified\natlas to each of the input images. We derive a new robust self-supervised\nframework that optimizes the atlas representation and mappings per image set,\nrequiring only a few real-world images as input without any additional input\ninformation (e.g., segmentation masks). Notably, we design our losses and\ntraining paradigm to account only for the shared content under severe\nvariations in appearance, pose, background clutter or other distracting\nobjects. We demonstrate results on a plethora of challenging image sets\nincluding sets of mixed domains (e.g., aligning images depicting sculpture and\nartwork of cats), sets depicting related yet different object categories (e.g.,\ndogs and tigers), or domains for which large-scale training data is scarce\n(e.g., coffee mugs). We thoroughly evaluate our method and show that our\ntest-time optimization approach performs favorably compared to a\nstate-of-the-art method that requires extensive training on large-scale\ndatasets.\n","authors":["Dolev Ofri-Amar","Michal Geyer","Yoni Kasten","Tali Dekel"],"pdf_url":"https://arxiv.org/pdf/2302.03956v2.pdf","comment":"Project page: https://neural-congealing.github.io/"},{"id":"http://arxiv.org/abs/2303.03323v1","updated":"2023-03-06T17:48:32Z","published":"2023-03-06T17:48:32Z","title":"CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive\n  Learning","summary":"  Multimodal contrastive pretraining has been utilized to train multimodal\nrepresentation models, like CLIP, on vast amounts of paired image-text data.\nHowever, previous studies have highlighted the susceptibility of such models to\nbackdoor attacks. Specifically, when training on backdoored examples, CLIP\nlearns spurious correlations between the embedded backdoor trigger and the\ntarget label, aligning their representations in the joint embedding space. With\ninjecting only a few poisoned examples e.g., 75 examples in the 3M pretraining\ndata, the model's behavior can be significantly manipulated, thus making it\nhard to detect or unlearn such correlations. To address this issue, we propose\nCleanCLIP, a finetuning framework that weakens the learned spurious\nassociations introduced by backdoor attacks by re-aligning the representations\nfor individual modalities independently. CleanCLIP can be employed for both\nunsupervised finetuning on paired image-text data and for supervised finetuning\non labeled image data. We demonstrate that unsupervised finetuning with a\ncombination of multimodal contrastive and unimodal self-supervised objectives\nfor individual modalities can significantly reduce the impact of the backdoor\nattack. Additionally, supervised finetuning on task-specific labeled data of\nthe individual modality, such as image data, removes the backdoor trigger from\nthe CLIP vision encoder. Empirically, we show that CleanCLIP maintains model\nperformance on benign examples while mitigating the impact of a range of\nbackdoor attacks on multimodal contrastive learning.\n","authors":["Hritik Bansal","Nishad Singhi","Yu Yang","Fan Yin","Aditya Grover","Kai-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2303.03323v1.pdf","comment":"20 pages, 7 figures, 8 tables"},{"id":"http://arxiv.org/abs/2303.03315v1","updated":"2023-03-06T17:38:03Z","published":"2023-03-06T17:38:03Z","title":"MACARONS: Mapping And Coverage Anticipation with RGB Online\n  Self-Supervision","summary":"  We introduce a method that simultaneously learns to explore new large\nenvironments and to reconstruct them in 3D from color images only. This is\nclosely related to the Next Best View problem (NBV), where one has to identify\nwhere to move the camera next to improve the coverage of an unknown scene.\nHowever, most of the current NBV methods rely on depth sensors, need 3D\nsupervision and/or do not scale to large scenes. Our method requires only a\ncolor camera and no 3D supervision. It simultaneously learns in a\nself-supervised fashion to predict a \"volume occupancy field\" from color images\nand, from this field, to predict the NBV. Thanks to this approach, our method\nperforms well on new scenes as it is not biased towards any training 3D data.\nWe demonstrate this on a recent dataset made of various 3D scenes and show it\nperforms even better than recent methods requiring a depth sensor, which is not\na realistic assumption for outdoor scenes captured with a flying drone.\n","authors":["Antoine Guédon","Tom Monnier","Pascal Monasse","Vincent Lepetit"],"pdf_url":"https://arxiv.org/pdf/2303.03315v1.pdf","comment":"To appear at CVPR 2023. Project Webpage:\n  https://imagine.enpc.fr/~guedona/MACARONS/"},{"id":"http://arxiv.org/abs/2303.03307v1","updated":"2023-03-06T17:26:30Z","published":"2023-03-06T17:26:30Z","title":"Learning Efficient Coding of Natural Images with Maximum Manifold\n  Capacity Representations","summary":"  Self-supervised Learning (SSL) provides a strategy for constructing useful\nrepresentations of images without relying on hand-assigned labels. Many such\nmethods aim to map distinct views of the same scene or object to nearby points\nin the representation space, while employing some constraint to prevent\nrepresentational collapse. Here we recast the problem in terms of efficient\ncoding by adopting manifold capacity, a measure that quantifies the quality of\na representation based on the number of linearly separable object manifolds it\ncan support, as the efficiency metric to optimize. Specifically, we adapt the\nmanifold capacity for use as an objective function in a contrastive learning\nframework, yielding a Maximum Manifold Capacity Representation (MMCR). We apply\nthis method to unlabeled images, each augmented by a set of basic\ntransformations, and find that it learns meaningful features using the standard\nlinear evaluation protocol. Specifically, we find that MMCRs support\nperformance on object recognition comparable to or surpassing that of recently\ndeveloped SSL frameworks, while providing more robustness to adversarial\nattacks. Empirical analyses reveal differences between MMCRs and\nrepresentations learned by other SSL frameworks, and suggest a mechanism by\nwhich manifold compression gives rise to class separability.\n","authors":["Thomas Yerxa","Yilun Kuang","Eero Simoncelli","SueYeon Chung"],"pdf_url":"https://arxiv.org/pdf/2303.03307v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.08672v2","updated":"2023-03-06T17:22:50Z","published":"2022-08-18T07:11:34Z","title":"RRWaveNet: A Compact End-to-End Multi-Scale Residual CNN for Robust PPG\n  Respiratory Rate Estimation","summary":"  Respiratory rate (RR) is an important biomarker as RR changes can reflect\nsevere medical events such as heart disease, lung disease, and sleep disorders.\nUnfortunately, standard manual RR counting is prone to human error and cannot\nbe performed continuously. This study proposes a method for continuously\nestimating RR, RRWaveNet. The method is a compact end-to-end deep learning\nmodel which does not require feature engineering and can use low-cost raw\nphotoplethysmography (PPG) as input signal. RRWaveNet was tested\nsubject-independently and compared to baseline in four datasets (BIDMC,\nCapnoBase, WESAD, and SensAI) and using three window sizes (16, 32, and 64\nseconds). RRWaveNet outperformed current state-of-the-art methods with mean\nabsolute errors at optimal window size of 1.66 \\pm 1.01, 1.59 \\pm 1.08, 1.92\n\\pm 0.96 and 1.23 \\pm 0.61 breaths per minute for each dataset. In remote\nmonitoring settings, such as in the WESAD and SensAI datasets, we apply\ntransfer learning to improve the performance using two other ICU datasets as\npretraining datasets, reducing the MAE by up to 21$\\%$. This shows that this\nmodel allows accurate and practical estimation of RR on affordable and wearable\ndevices. Our study also shows feasibility of remote RR monitoring in the\ncontext of telemedicine and at home.\n","authors":["Pongpanut Osathitporn","Guntitat Sawadwuthikul","Punnawish Thuwajit","Kawisara Ueafuea","Thee Mateepithaktham","Narin Kunaseth","Tanut Choksatchawathi","Proadpran Punyabukkana","Emmanuel Mignot","Theerawit Wilaiprasitporn"],"pdf_url":"https://arxiv.org/pdf/2208.08672v2.pdf","comment":"11 pages, 8 figures"},{"id":"http://arxiv.org/abs/2303.03301v1","updated":"2023-03-06T17:19:28Z","published":"2023-03-06T17:19:28Z","title":"Exploring Deep Models for Practical Gait Recognition","summary":"  Gait recognition is a rapidly advancing vision technique for person\nidentification from a distance. Prior studies predominantly employed relatively\nsmall and shallow neural networks to extract subtle gait features, achieving\nimpressive successes in indoor settings. Nevertheless, experiments revealed\nthat these existing methods mostly produce unsatisfactory results when applied\nto newly released in-the-wild gait datasets. This paper presents a unified\nperspective to explore how to construct deep models for state-of-the-art\noutdoor gait recognition, including the classical CNN-based and emerging\nTransformer-based architectures. Consequently, we emphasize the importance of\nsuitable network capacity, explicit temporal modeling, and deep transformer\nstructure for discriminative gait representation learning. Our proposed\nCNN-based DeepGaitV2 series and Transformer-based SwinGait series exhibit\nsignificant performance gains in outdoor scenarios, \\textit{e.g.}, about +30\\%\nrank-1 accuracy compared with many state-of-the-art methods on the challenging\nGREW dataset. This work is expected to further boost the research and\napplication of gait recognition. Code will be available at\nhttps://github.com/ShiqiYu/OpenGait.\n","authors":["Chao Fan","Saihui Hou","Yongzhen Huang","Shiqi Yu"],"pdf_url":"https://arxiv.org/pdf/2303.03301v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03281v1","updated":"2023-03-06T16:52:11Z","published":"2023-03-06T16:52:11Z","title":"Visual Place Recognition: A Tutorial","summary":"  Localization is an essential capability for mobile robots. A rapidly growing\nfield of research in this area is Visual Place Recognition (VPR), which is the\nability to recognize previously seen places in the world based solely on\nimages. This present work is the first tutorial paper on visual place\nrecognition. It unifies the terminology of VPR and complements prior research\nin two important directions: 1) It provides a systematic introduction for\nnewcomers to the field, covering topics such as the formulation of the VPR\nproblem, a general-purpose algorithmic pipeline, an evaluation methodology for\nVPR approaches, and the major challenges for VPR and how they may be addressed.\n2) As a contribution for researchers acquainted with the VPR problem, it\nexamines the intricacies of different VPR problem types regarding input, data\nprocessing, and output. The tutorial also discusses the subtleties behind the\nevaluation of VPR algorithms, e.g., the evaluation of a VPR system that has to\nfind all matching database images per query, as opposed to just a single match.\nPractical code examples in Python illustrate to prospective practitioners and\nresearchers how VPR is implemented and evaluated.\n","authors":["Stefan Schubert","Peer Neubert","Sourav Garg","Michael Milford","Tobias Fischer"],"pdf_url":"https://arxiv.org/pdf/2303.03281v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2303.01818v2","updated":"2023-03-06T16:34:15Z","published":"2023-03-03T09:59:25Z","title":"Word-As-Image for Semantic Typography","summary":"  A word-as-image is a semantic typography technique where a word illustration\npresents a visualization of the meaning of the word, while also preserving its\nreadability. We present a method to create word-as-image illustrations\nautomatically. This task is highly challenging as it requires semantic\nunderstanding of the word and a creative idea of where and how to depict these\nsemantics in a visually pleasing and legible manner. We rely on the remarkable\nability of recent large pretrained language-vision models to distill textual\nconcepts visually. We target simple, concise, black-and-white designs that\nconvey the semantics clearly. We deliberately do not change the color or\ntexture of the letters and do not use embellishments. Our method optimizes the\noutline of each letter to convey the desired concept, guided by a pretrained\nStable Diffusion model. We incorporate additional loss terms to ensure the\nlegibility of the text and the preservation of the style of the font. We show\nhigh quality and engaging results on numerous examples and compare to\nalternative techniques.\n","authors":["Shir Iluz","Yael Vinker","Amir Hertz","Daniel Berio","Daniel Cohen-Or","Ariel Shamir"],"pdf_url":"https://arxiv.org/pdf/2303.01818v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.06930v2","updated":"2023-03-06T16:23:09Z","published":"2022-11-13T15:41:50Z","title":"PaintNet: Unstructured Multi-Path Learning from 3D Point Clouds for\n  Robotic Spray Painting","summary":"  Popular industrial robotic problems such as spray painting and welding\nrequire (i) conditioning on free-shape 3D objects and (ii) planning of multiple\ntrajectories to solve the task. Yet, existing solutions make strong assumptions\non the form of input surfaces and the nature of output paths, resulting in\nlimited approaches unable to cope with real-data variability. By leveraging on\nrecent advances in 3D deep learning, we introduce a novel framework capable of\ndealing with arbitrary 3D surfaces, and handling a variable number of unordered\noutput paths (i.e. unstructured). Our approach focuses on predicting smaller\npath segments, which can be later concatenated to reconstruct long-horizon\npaths. We extensively validate the proposed method in the context of robotic\nspray painting by releasing PaintNet, the first public dataset of expert\ndemonstrations on free-shape 3D objects collected in a real industrial\nscenario. A thorough experimental analysis demonstrates the capabilities of our\nmodel to promptly predict smooth output paths that cover up to 95% of the\nsurface of previously unseen object instances. Furthermore, we show how models\nlearned from PaintNet capture relevant features which serve as a reliable\nstarting point to improve data and time efficiency when dealing with new object\ncategories.\n","authors":["Gabriele Tiboni","Raffaello Camoriano","Tatiana Tommasi"],"pdf_url":"https://arxiv.org/pdf/2211.06930v2.pdf","comment":"Project website at https://gabrieletiboni.github.io/paintnet"},{"id":"http://arxiv.org/abs/2206.02307v2","updated":"2023-03-06T16:08:39Z","published":"2022-06-06T01:30:03Z","title":"Bootstrapping Semi-supervised Medical Image Segmentation with\n  Anatomical-aware Contrastive Distillation","summary":"  Contrastive learning has shown great promise over annotation scarcity\nproblems in the context of medical image segmentation. Existing approaches\ntypically assume a balanced class distribution for both labeled and unlabeled\nmedical images. However, medical image data in reality is commonly imbalanced\n(i.e., multi-class label imbalance), which naturally yields blurry contours and\nusually incorrectly labels rare objects. Moreover, it remains unclear whether\nall negative samples are equally negative. In this work, we present ACTION, an\nAnatomical-aware ConTrastive dIstillatiON framework, for semi-supervised\nmedical image segmentation. Specifically, we first develop an iterative\ncontrastive distillation algorithm by softly labeling the negatives rather than\nbinary supervision between positive and negative pairs. We also capture more\nsemantically similar features from the randomly chosen negative set compared to\nthe positives to enforce the diversity of the sampled data. Second, we raise a\nmore important question: Can we really handle imbalanced samples to yield\nbetter performance? Hence, the key innovation in ACTION is to learn global\nsemantic relationship across the entire dataset and local anatomical features\namong the neighbouring pixels with minimal additional memory footprint. During\nthe training, we introduce anatomical contrast by actively sampling a sparse\nset of hard negative pixels, which can generate smoother segmentation\nboundaries and more accurate predictions. Extensive experiments across two\nbenchmark datasets and different unlabeled settings show that ACTION\nsignificantly outperforms the current state-of-the-art semi-supervised methods.\n","authors":["Chenyu You","Weicheng Dai","Yifei Min","Lawrence Staib","James S. Duncan"],"pdf_url":"https://arxiv.org/pdf/2206.02307v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03242v1","updated":"2023-03-06T16:01:30Z","published":"2023-03-06T16:01:30Z","title":"Evaluating the Fairness of Deep Learning Uncertainty Estimates in\n  Medical Image Analysis","summary":"  Although deep learning (DL) models have shown great success in many medical\nimage analysis tasks, deployment of the resulting models into real clinical\ncontexts requires: (1) that they exhibit robustness and fairness across\ndifferent sub-populations, and (2) that the confidence in DL model predictions\nbe accurately expressed in the form of uncertainties. Unfortunately, recent\nstudies have indeed shown significant biases in DL models across demographic\nsubgroups (e.g., race, sex, age) in the context of medical image analysis,\nindicating a lack of fairness in the models. Although several methods have been\nproposed in the ML literature to mitigate a lack of fairness in DL models, they\nfocus entirely on the absolute performance between groups without considering\ntheir effect on uncertainty estimation. In this work, we present the first\nexploration of the effect of popular fairness models on overcoming biases\nacross subgroups in medical image analysis in terms of bottom-line performance,\nand their effects on uncertainty quantification. We perform extensive\nexperiments on three different clinically relevant tasks: (i) skin lesion\nclassification, (ii) brain tumour segmentation, and (iii) Alzheimer's disease\nclinical score regression. Our results indicate that popular ML methods, such\nas data-balancing and distributionally robust optimization, succeed in\nmitigating fairness issues in terms of the model performances for some of the\ntasks. However, this can come at the cost of poor uncertainty estimates\nassociated with the model predictions. This tradeoff must be mitigated if\nfairness models are to be adopted in medical image analysis.\n","authors":["Raghav Mehta","Changjian Shui","Tal Arbel"],"pdf_url":"https://arxiv.org/pdf/2303.03242v1.pdf","comment":"Paper accepted at MIDL 2023"},{"id":"http://arxiv.org/abs/2303.03231v1","updated":"2023-03-06T15:48:33Z","published":"2023-03-06T15:48:33Z","title":"StyO: Stylize Your Face in Only One-Shot","summary":"  This paper focuses on face stylization with a single artistic target.\nExisting works for this task often fail to retain the source content while\nachieving geometry variation. Here, we present a novel StyO model, ie. Stylize\nthe face in only One-shot, to solve the above problem. In particular, StyO\nexploits a disentanglement and recombination strategy. It first disentangles\nthe content and style of source and target images into identifiers, which are\nthen recombined in a cross manner to derive the stylized face image. In this\nway, StyO decomposes complex images into independent and specific attributes,\nand simplifies one-shot face stylization as the combination of different\nattributes from input images, thus producing results better matching face\ngeometry of target image and content of source one. StyO is implemented with\nlatent diffusion models (LDM) and composed of two key modules: 1) Identifier\nDisentanglement Learner (IDL) for disentanglement phase. It represents\nidentifiers as contrastive text prompts, ie. positive and negative\ndescriptions. And it introduces a novel triple reconstruction loss to fine-tune\nthe pre-trained LDM for encoding style and content into corresponding\nidentifiers; 2) Fine-grained Content Controller (FCC) for the recombination\nphase. It recombines disentangled identifiers from IDL to form an augmented\ntext prompt for generating stylized faces. In addition, FCC also constrains the\ncross-attention maps of latent and text features to preserve source face\ndetails in results. The extensive evaluation shows that StyO produces\nhigh-quality images on numerous paintings of various styles and outperforms the\ncurrent state-of-the-art. Code will be released upon acceptance.\n","authors":["Bonan Li","Zicheng Zhang","Xuecheng Nie","Congying Han","Yinhan Hu","Tiande Guo"],"pdf_url":"https://arxiv.org/pdf/2303.03231v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01592v2","updated":"2023-03-06T15:48:03Z","published":"2023-03-02T21:31:35Z","title":"Joint cortical registration of geometry and function using\n  semi-supervised learning","summary":"  Brain surface-based image registration, an important component of brain image\nanalysis, establishes spatial correspondence between cortical surfaces.\nExisting iterative and learning-based approaches focus on accurate registration\nof folding patterns of the cerebral cortex, and assume that geometry predicts\nfunction and thus functional areas will also be well aligned. However,\nstructure/functional variability of anatomically corresponding areas across\nsubjects has been widely reported. In this work, we introduce a learning-based\ncortical registration framework, JOSA, which jointly aligns folding patterns\nand functional maps while simultaneously learning an optimal atlas. We\ndemonstrate that JOSA can substantially improve registration performance in\nboth anatomical and functional domains over existing methods. By employing a\nsemi-supervised training strategy, the proposed framework obviates the need for\nfunctional data during inference, enabling its use in broad neuroscientific\ndomains where functional data may not be observed.\n","authors":["Jian Li","Greta Tuckute","Evelina Fedorenko","Brian L. Edlow","Bruce Fischl","Adrian V. Dalca"],"pdf_url":"https://arxiv.org/pdf/2303.01592v2.pdf","comment":"* co-senior authors with equal contribution"},{"id":"http://arxiv.org/abs/2210.04613v2","updated":"2023-03-06T15:45:44Z","published":"2022-10-03T13:34:11Z","title":"Enhancing Fine-Grained 3D Object Recognition using Hybrid Multi-Modal\n  Vision Transformer-CNN Models","summary":"  Robots operating in human-centered environments, such as retail stores,\nrestaurants, and households, are often required to distinguish between similar\nobjects in different contexts with a high degree of accuracy. However,\nfine-grained object recognition remains a challenge in robotics due to the high\nintra-category and low inter-category dissimilarities. In addition, the limited\nnumber of fine-grained 3D datasets poses a significant problem in addressing\nthis issue effectively. In this paper, we propose a hybrid multi-modal Vision\nTransformer (ViT) and Convolutional Neural Networks (CNN) approach to improve\nthe performance of fine-grained visual classification (FGVC). To address the\nshortage of FGVC 3D datasets, we generated two synthetic datasets. The first\ndataset consists of 20 categories related to restaurants with a total of 100\ninstances, while the second dataset contains 120 shoe instances. Our approach\nwas evaluated on both datasets, and the results indicate that it outperforms\nboth CNN-only and ViT-only baselines, achieving a recognition accuracy of 94.50\n% and 93.51 % on the restaurant and shoe datasets, respectively. Additionally,\nwe have made our FGVC RGB-D datasets available to the research community to\nenable further experimentation and advancement. Furthermore, we successfully\nintegrated our proposed method with a robot framework and demonstrated its\npotential as a fine-grained perception tool in both simulated and real-world\nrobotic scenarios.\n","authors":["Songsong Xiong","Georgios Tziafas","Hamidreza Kasaei"],"pdf_url":"https://arxiv.org/pdf/2210.04613v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.02928v2","updated":"2023-03-06T15:26:24Z","published":"2022-03-06T10:14:09Z","title":"Evaluation of Interpretability Methods and Perturbation Artifacts in\n  Deep Neural Networks","summary":"  Despite excellent performance of deep neural networks (DNNs) in image\nclassification, detection, and prediction, characterizing how DNNs make a given\ndecision remains an open problem, resulting in a number of interpretability\nmethods. Post-hoc interpretability methods primarily aim to quantify the\nimportance of input features with respect to the class probabilities. However,\ndue to the lack of ground truth and the existence of interpretability methods\nwith diverse operating characteristics, evaluating these methods is a crucial\nchallenge. A popular approach to evaluate interpretability methods is to\nperturb input features deemed important for a given prediction and observe the\ndecrease in accuracy. However, perturbation itself may introduce artifacts,\nsince perturbed images may be out-of-distribution (OOD). In this paper, we have\nconducted computational experiments to estimate the contribution of\nperturbation artifacts and developed a method to estimate the fidelity of\ninterpretability methods. We demonstrate that, while perturbation artifacts\nindeed exist, we can minimize and characterize their impact on fidelity\nestimation by utilizing model accuracy curves from perturbing input features\naccording to the Most Import First (MIF) and Least Import First (LIF) orders.\nUsing the ResNet-50 trained on the ImageNet, we demonstrate the proposed\nfidelity estimation of four popular post-hoc interpretability methods.\n","authors":["Lennart Brocki","Neo Christopher Chung"],"pdf_url":"https://arxiv.org/pdf/2203.02928v2.pdf","comment":"26 pages, 9 figures"},{"id":"http://arxiv.org/abs/2303.03212v1","updated":"2023-03-06T15:14:16Z","published":"2023-03-06T15:14:16Z","title":"Combination of Single and Multi-frame Image Super-resolution: An\n  Analytical Perspective","summary":"  Super-resolution is the process of obtaining a high-resolution image from one\nor more low-resolution images. Single image super-resolution (SISR) and\nmulti-frame super-resolution (MFSR) methods have been evolved almost\nindependently for years. A neglected study in this field is the theoretical\nanalysis of finding the optimum combination of SISR and MFSR. To fill this gap,\nwe propose a novel theoretical analysis based on the iterative shrinkage and\nthresholding algorithm. We implement and compare several approaches for\ncombining SISR and MFSR, and simulation results support the finding of our\ntheoretical analysis, both quantitatively and qualitatively.\n","authors":["Mohammad Mahdi Afrasiabi","Reshad Hosseini","Aliazam Abbasfar"],"pdf_url":"https://arxiv.org/pdf/2303.03212v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03202v1","updated":"2023-03-06T15:02:12Z","published":"2023-03-06T15:02:12Z","title":"Continuous Sign Language Recognition with Correlation Network","summary":"  Human body trajectories are a salient cue to identify actions in the video.\nSuch body trajectories are mainly conveyed by hands and face across consecutive\nframes in sign language. However, current methods in continuous sign language\nrecognition (CSLR) usually process frames independently, thus failing to\ncapture cross-frame trajectories to effectively identify a sign. To handle this\nlimitation, we propose correlation network (CorrNet) to explicitly capture and\nleverage body trajectories across frames to identify signs. In specific, a\ncorrelation module is first proposed to dynamically compute correlation maps\nbetween the current frame and adjacent frames to identify trajectories of all\nspatial patches. An identification module is then presented to dynamically\nemphasize the body trajectories within these correlation maps. As a result, the\ngenerated features are able to gain an overview of local temporal movements to\nidentify a sign. Thanks to its special attention on body trajectories, CorrNet\nachieves new state-of-the-art accuracy on four large-scale datasets, i.e.,\nPHOENIX14, PHOENIX14-T, CSL-Daily, and CSL. A comprehensive comparison with\nprevious spatial-temporal reasoning methods verifies the effectiveness of\nCorrNet. Visualizations demonstrate the effects of CorrNet on emphasizing human\nbody trajectories across adjacent frames.\n","authors":["Lianyu Hu","Liqing Gao","Zekang Liu","Wei Feng"],"pdf_url":"https://arxiv.org/pdf/2303.03202v1.pdf","comment":"CVPR2023, code: https://github.com/hulianyuyy/CorrNet. arXiv admin\n  note: text overlap with arXiv:2211.17081"},{"id":"http://arxiv.org/abs/2201.12733v4","updated":"2023-03-06T14:58:48Z","published":"2022-01-30T05:41:50Z","title":"TPC: Transformation-Specific Smoothing for Point Cloud Models","summary":"  Point cloud models with neural network architectures have achieved great\nsuccess and have been widely used in safety-critical applications, such as\nLidar-based recognition systems in autonomous vehicles. However, such models\nare shown vulnerable to adversarial attacks which aim to apply stealthy\nsemantic transformations such as rotation and tapering to mislead model\npredictions. In this paper, we propose a transformation-specific smoothing\nframework TPC, which provides tight and scalable robustness guarantees for\npoint cloud models against semantic transformation attacks. We first categorize\ncommon 3D transformations into three categories: additive (e.g., shearing),\ncomposable (e.g., rotation), and indirectly composable (e.g., tapering), and we\npresent generic robustness certification strategies for all categories\nrespectively. We then specify unique certification protocols for a range of\nspecific semantic transformations and their compositions. Extensive experiments\non several common 3D transformations show that TPC significantly outperforms\nthe state of the art. For example, our framework boosts the certified accuracy\nagainst twisting transformation along z-axis (within 20$^\\circ$) from 20.3$\\%$\nto 83.8$\\%$. Codes and models are available at\nhttps://github.com/Qianhewu/Point-Cloud-Smoothing.\n","authors":["Wenda Chu","Linyi Li","Bo Li"],"pdf_url":"https://arxiv.org/pdf/2201.12733v4.pdf","comment":"Accepted as a conference paper at ICML 2022"},{"id":"http://arxiv.org/abs/2103.09108v4","updated":"2023-03-06T14:50:44Z","published":"2021-03-16T14:42:01Z","title":"Is it enough to optimize CNN architectures on ImageNet?","summary":"  Classification performance based on ImageNet is the de-facto standard metric\nfor CNN development. In this work we challenge the notion that CNN architecture\ndesign solely based on ImageNet leads to generally effective convolutional\nneural network (CNN) architectures that perform well on a diverse set of\ndatasets and application domains. To this end, we investigate and ultimately\nimprove ImageNet as a basis for deriving such architectures. We conduct an\nextensive empirical study for which we train $500$ CNN architectures, sampled\nfrom the broad AnyNetX design space, on ImageNet as well as $8$ additional well\nknown image classification benchmark datasets from a diverse array of\napplication domains. We observe that the performances of the architectures are\nhighly dataset dependent. Some datasets even exhibit a negative error\ncorrelation with ImageNet across all architectures. We show how to\nsignificantly increase these correlations by utilizing ImageNet subsets\nrestricted to fewer classes. These contributions can have a profound impact on\nthe way we design future CNN architectures and help alleviate the tilt we see\ncurrently in our community with respect to over-reliance on one dataset.\n","authors":["Lukas Tuggener","Jürgen Schmidhuber","Thilo Stadelmann"],"pdf_url":"https://arxiv.org/pdf/2103.09108v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03178v1","updated":"2023-03-06T14:47:38Z","published":"2023-03-06T14:47:38Z","title":"A System for Generalized 3D Multi-Object Search","summary":"  Searching for objects is a fundamental skill for robots. As such, we expect\nobject search to eventually become an off-the-shelf capability for robots,\nsimilar to e.g., object detection and SLAM. In contrast, however, no system for\n3D object search exists that generalizes across real robots and environments.\nIn this paper, building upon a recent theoretical framework that exploited the\noctree structure for representing belief in 3D, we present GenMOS (Generalized\nMulti-Object Search), the first general-purpose system for multi-object search\n(MOS) in a 3D region that is robot-independent and environment-agnostic. GenMOS\ntakes as input point cloud observations of the local region, object detection\nresults, and localization of the robot's view pose, and outputs a 6D viewpoint\nto move to through online planning. In particular, GenMOS uses point cloud\nobservations in three ways: (1) to simulate occlusion; (2) to inform occupancy\nand initialize octree belief; and (3) to sample a belief-dependent graph of\nview positions that avoid obstacles. We evaluate our system both in simulation\nand on two real robot platforms. Our system enables, for example, a Boston\nDynamics Spot robot to find a toy cat hidden underneath a couch in under one\nminute. We further integrate 3D local search with 2D global search to handle\nlarger areas, demonstrating the resulting system in a 25m$^2$ lobby area.\n","authors":["Kaiyu Zheng","Anirudha Paul","Stefanie Tellex"],"pdf_url":"https://arxiv.org/pdf/2303.03178v1.pdf","comment":"8 pages, 9 figures, 1 table. IEEE Conference on Robotics and\n  Automation (ICRA) 2023"},{"id":"http://arxiv.org/abs/2303.03171v1","updated":"2023-03-06T14:39:54Z","published":"2023-03-06T14:39:54Z","title":"Neighborhood Contrastive Transformer for Change Captioning","summary":"  Change captioning is to describe the semantic change between a pair of\nsimilar images in natural language. It is more challenging than general image\ncaptioning, because it requires capturing fine-grained change information while\nbeing immune to irrelevant viewpoint changes, and solving syntax ambiguity in\nchange descriptions. In this paper, we propose a neighborhood contrastive\ntransformer to improve the model's perceiving ability for various changes under\ndifferent scenes and cognition ability for complex syntax structure.\nConcretely, we first design a neighboring feature aggregating to integrate\nneighboring context into each feature, which helps quickly locate the\ninconspicuous changes under the guidance of conspicuous referents. Then, we\ndevise a common feature distilling to compare two images at neighborhood level\nand extract common properties from each image, so as to learn effective\ncontrastive information between them. Finally, we introduce the explicit\ndependencies between words to calibrate the transformer decoder, which helps\nbetter understand complex syntax structure during training. Extensive\nexperimental results demonstrate that the proposed method achieves the\nstate-of-the-art performance on three public datasets with different change\nscenarios. The code is available at https://github.com/tuyunbin/NCT.\n","authors":["Yunbin Tu","Liang Li","Li Su","Ke Lu","Qingming Huang"],"pdf_url":"https://arxiv.org/pdf/2303.03171v1.pdf","comment":"Accepted by IEEE TMM"},{"id":"http://arxiv.org/abs/2209.09616v5","updated":"2023-03-06T14:37:29Z","published":"2022-09-19T09:16:07Z","title":"Provably Uncertainty-Guided Universal Domain Adaptation","summary":"  Universal domain adaptation (UniDA) aims to transfer the knowledge of common\nclasses from source domain to target domain without any prior knowledge on the\nlabel set, which requires to distinguish the unknown samples from the known\nones in the target domain. A main challenge of UniDA is that the unequal label\nspaces of both domains causes the misalignment between two domains.To address\nthe above challenging problems, we propose a new uncertainty-guided UniDA\nframework. Firstly, we introduce an empirical estimation of the probability of\na target sample belonging to the unknown class with exploiting the distribution\nof target samples. Then, based on the estimation, we propose a novel neighbors\nsearching method in the linear subspace with a $\\delta$-filter to estimate the\nuncertainty score of a target sample and discover unknown samples. It fully\nutilizes the relationship between a target sample and its neighbors in source\ndomain to avoid the influence of domain misalignment. Secondly, this paper well\nbalances the confidence of predictions for both known and unknown samples\nthrough an uncertainty-guided margin loss based on the predictions of\ndiscovered unknown samples, which can reduce the gap between intra-class\nvariance of known classes with respect to the unknown class. Finally,\nexperiments on three public datasets demonstrate that our method significantly\noutperforms existing state-of-the-art methods.\n","authors":["Yifan Wang","Lin Zhang","Ran Song","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2209.09616v5.pdf","comment":"13 pages. arXiv admin note: text overlap with arXiv:2207.09280"},{"id":"http://arxiv.org/abs/2211.11635v2","updated":"2023-03-06T14:34:03Z","published":"2022-11-21T16:49:47Z","title":"Understanding and Improving Visual Prompting: A Label-Mapping\n  Perspective","summary":"  We revisit and advance visual prompting (VP), an input prompting technique\nfor vision tasks. VP can reprogram a fixed, pre-trained source model to\naccomplish downstream tasks in the target domain by simply incorporating\nuniversal prompts (in terms of input perturbation patterns) into downstream\ndata points. Yet, it remains elusive why VP stays effective even given a\nruleless label mapping (LM) between the source classes and the target classes.\nInspired by the above, we ask: How is LM interrelated with VP? And how to\nexploit such a relationship to improve its accuracy on target tasks? We peer\ninto the influence of LM on VP and provide an affirmative answer that a better\n'quality' of LM (assessed by mapping precision and explanation) can\nconsistently improve the effectiveness of VP. This is in contrast to the prior\nart where the factor of LM was missing. To optimize LM, we propose a new VP\nframework, termed ILM-VP (iterative label mapping-based visual prompting),\nwhich automatically re-maps the source labels to the target labels and\nprogressively improves the target task accuracy of VP. Further, when using a\ncontrastive language-image pretrained (CLIP) model, we propose to integrate an\nLM process to assist the text prompt selection of CLIP and to improve the\ntarget task accuracy. Extensive experiments demonstrate that our proposal\nsignificantly outperforms state-of-the-art VP methods. As highlighted below, we\nshow that when reprogramming an ImageNet-pretrained ResNet-18 to 13 target\ntasks, our method outperforms baselines by a substantial margin, e.g., 7.9% and\n6.7% accuracy improvements in transfer learning to the target Flowers102 and\nCIFAR100 datasets. Besides, our proposal on CLIP-based VP provides 13.7% and\n7.1% accuracy improvements on Flowers102 and DTD respectively. Our code is\navailable at https://github.com/OPTML-Group/ILM-VP.\n","authors":["Aochuan Chen","Yuguang Yao","Pin-Yu Chen","Yihua Zhang","Sijia Liu"],"pdf_url":"https://arxiv.org/pdf/2211.11635v2.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2303.03166v1","updated":"2023-03-06T14:26:56Z","published":"2023-03-06T14:26:56Z","title":"Faster Learning of Temporal Action Proposal via Sparse Multilevel\n  Boundary Generator","summary":"  Temporal action localization in videos presents significant challenges in the\nfield of computer vision. While the boundary-sensitive method has been widely\nadopted, its limitations include incomplete use of intermediate and global\ninformation, as well as an inefficient proposal feature generator. To address\nthese challenges, we propose a novel framework, Sparse Multilevel Boundary\nGenerator (SMBG), which enhances the boundary-sensitive method with boundary\nclassification and action completeness regression. SMBG features a multi-level\nboundary module that enables faster processing by gathering boundary\ninformation at different lengths. Additionally, we introduce a sparse\nextraction confidence head that distinguishes information inside and outside\nthe action, further optimizing the proposal feature generator. To improve the\nsynergy between multiple branches and balance positive and negative samples, we\npropose a global guidance loss. Our method is evaluated on two popular\nbenchmarks, ActivityNet-1.3 and THUMOS14, and is shown to achieve\nstate-of-the-art performance, with a better inference speed (2.47xBSN++,\n2.12xDBG). These results demonstrate that SMBG provides a more efficient and\nsimple solution for generating temporal action proposals. Our proposed\nframework has the potential to advance the field of computer vision and enhance\nthe accuracy and speed of temporal action localization in video analysis.The\ncode and models are made available at\n\\url{https://github.com/zhouyang-001/SMBG-for-temporal-action-proposal}.\n","authors":["Qing Song","Yang Zhou","Mengjie Hu","Chun Liu"],"pdf_url":"https://arxiv.org/pdf/2303.03166v1.pdf","comment":"18 pages, 5 figures"},{"id":"http://arxiv.org/abs/2303.03131v1","updated":"2023-03-06T13:49:15Z","published":"2023-03-06T13:49:15Z","title":"Video Question Answering Using CLIP-Guided Visual-Text Attention","summary":"  Cross-modal learning of video and text plays a key role in Video Question\nAnswering (VideoQA). In this paper, we propose a visual-text attention\nmechanism to utilize the Contrastive Language-Image Pre-training (CLIP) trained\non lots of general domain language-image pairs to guide the cross-modal\nlearning for VideoQA. Specifically, we first extract video features using a\nTimeSformer and text features using a BERT from the target application domain,\nand utilize CLIP to extract a pair of visual-text features from the\ngeneral-knowledge domain through the domain-specific learning. We then propose\na Cross-domain Learning to extract the attention information between visual and\nlinguistic features across the target domain and general domain. The set of\nCLIP-guided visual-text features are integrated to predict the answer. The\nproposed method is evaluated on MSVD-QA and MSRVTT-QA datasets, and outperforms\nstate-of-the-art methods.\n","authors":["Shuhong Ye","Weikai Kong","Chenglin Yao","Jianfeng Ren","Xudong Jiang"],"pdf_url":"https://arxiv.org/pdf/2303.03131v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03127v1","updated":"2023-03-06T13:39:41Z","published":"2023-03-06T13:39:41Z","title":"ST-KeyS: Self-Supervised Transformer for Keyword Spotting in Historical\n  Handwritten Documents","summary":"  Keyword spotting (KWS) in historical documents is an important tool for the\ninitial exploration of digitized collections. Nowadays, the most efficient KWS\nmethods are relying on machine learning techniques that require a large amount\nof annotated training data. However, in the case of historical manuscripts,\nthere is a lack of annotated corpus for training. To handle the data scarcity\nissue, we investigate the merits of the self-supervised learning to extract\nuseful representations of the input data without relying on human annotations\nand then using these representations in the downstream task. We propose\nST-KeyS, a masked auto-encoder model based on vision transformers where the\npretraining stage is based on the mask-and-predict paradigm, without the need\nof labeled data. In the fine-tuning stage, the pre-trained encoder is\nintegrated into a siamese neural network model that is fine-tuned to improve\nfeature embedding from the input images. We further improve the image\nrepresentation using pyramidal histogram of characters (PHOC) embedding to\ncreate and exploit an intermediate representation of images based on text\nattributes. In an exhaustive experimental evaluation on three widely used\nbenchmark datasets (Botany, Alvermann Konzilsprotokolle and George Washington),\nthe proposed approach outperforms state-of-the-art methods trained on the same\ndatasets.\n","authors":["Sana Khamekhem Jemni","Sourour Ammar","Mohamed Ali Souibgui","Yousri Kessentini","Abbas Cheddad"],"pdf_url":"https://arxiv.org/pdf/2303.03127v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.10772v3","updated":"2023-03-06T13:36:16Z","published":"2022-11-19T19:06:22Z","title":"DeepSolo: Let Transformer Decoder with Explicit Points Solo for Text\n  Spotting","summary":"  End-to-end text spotting aims to integrate scene text detection and\nrecognition into a unified framework. Dealing with the relationship between the\ntwo sub-tasks plays a pivotal role in designing effective spotters. Although\nTransformer-based methods eliminate the heuristic post-processing, they still\nsuffer from the synergy issue between the sub-tasks and low training\nefficiency. In this paper, we present DeepSolo, a simple DETR-like baseline\nthat lets a single Decoder with Explicit Points Solo for text detection and\nrecognition simultaneously. Technically, for each text instance, we represent\nthe character sequence as ordered points and model them with learnable explicit\npoint queries. After passing a single decoder, the point queries have encoded\nrequisite text semantics and locations, thus can be further decoded to the\ncenter line, boundary, script, and confidence of text via very simple\nprediction heads in parallel. Besides, we also introduce a text-matching\ncriterion to deliver more accurate supervisory signals, thus enabling more\nefficient training. Quantitative experiments on public benchmarks demonstrate\nthat DeepSolo outperforms previous state-of-the-art methods and achieves better\ntraining efficiency. In addition, DeepSolo is also compatible with line\nannotations, which require much less annotation cost than polygons. The code is\navailable at https://github.com/ViTAE-Transformer/DeepSolo.\n","authors":["Maoyuan Ye","Jing Zhang","Shanshan Zhao","Juhua Liu","Tongliang Liu","Bo Du","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2211.10772v3.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2301.05499v2","updated":"2023-03-06T13:35:22Z","published":"2023-01-13T12:01:18Z","title":"CLIP the Gap: A Single Domain Generalization Approach for Object\n  Detection","summary":"  Single Domain Generalization (SDG) tackles the problem of training a model on\na single source domain so that it generalizes to any unseen target domain.\nWhile this has been well studied for image classification, the literature on\nSDG object detection remains almost non-existent. To address the challenges of\nsimultaneously learning robust object localization and representation, we\npropose to leverage a pre-trained vision-language model to introduce semantic\ndomain concepts via textual prompts. We achieve this via a semantic\naugmentation strategy acting on the features extracted by the detector\nbackbone, as well as a text-based classification loss. Our experiments evidence\nthe benefits of our approach, outperforming by 10% the only existing SDG object\ndetection method, Single-DGOD [49], on their own diverse weather-driving\nbenchmark.\n","authors":["Vidit Vidit","Martin Engilberge","Mathieu Salzmann"],"pdf_url":"https://arxiv.org/pdf/2301.05499v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03101v1","updated":"2023-03-06T13:14:10Z","published":"2023-03-06T13:14:10Z","title":"CRIN: Rotation-Invariant Point Cloud Analysis and Rotation Estimation\n  via Centrifugal Reference Frame","summary":"  Various recent methods attempt to implement rotation-invariant 3D deep\nlearning by replacing the input coordinates of points with relative distances\nand angles. Due to the incompleteness of these low-level features, they have to\nundertake the expense of losing global information. In this paper, we propose\nthe CRIN, namely Centrifugal Rotation-Invariant Network. CRIN directly takes\nthe coordinates of points as input and transforms local points into\nrotation-invariant representations via centrifugal reference frames. Aided by\ncentrifugal reference frames, each point corresponds to a discrete rotation so\nthat the information of rotations can be implicitly stored in point features.\nUnfortunately, discrete points are far from describing the whole rotation\nspace. We further introduce a continuous distribution for 3D rotations based on\npoints. Furthermore, we propose an attention-based down-sampling strategy to\nsample points invariant to rotations. A relation module is adopted at last for\nreinforcing the long-range dependencies between sampled points and predicts the\nanchor point for unsupervised rotation estimation. Extensive experiments show\nthat our method achieves rotation invariance, accurately estimates the object\nrotation, and obtains state-of-the-art results on rotation-augmented\nclassification and part segmentation. Ablation studies validate the\neffectiveness of the network design.\n","authors":["Yujing Lou","Zelin Ye","Yang You","Nianjuan Jiang","Jiangbo Lu","Weiming Wang","Lizhuang Ma","Cewu Lu"],"pdf_url":"https://arxiv.org/pdf/2303.03101v1.pdf","comment":"AAAI 2023"},{"id":"http://arxiv.org/abs/2303.03056v1","updated":"2023-03-06T11:59:13Z","published":"2023-03-06T11:59:13Z","title":"MOISST: Multi-modal Optimization of Implicit Scene for SpatioTemporal\n  calibration","summary":"  With the recent advances in autonomous driving and the decreasing cost of\nLiDARs, the use of multi-modal sensor systems is on the rise. However, in order\nto make use of the information provided by a variety of complimentary sensors,\nit is necessary to accurately calibrate them. We take advantage of recent\nadvances in computer graphics and implicit volumetric scene representation to\ntackle the problem of multi-sensor spatial and temporal calibration. Thanks to\na new formulation of the implicit model optimization, we are able to jointly\noptimize calibration parameters along with scene representation based on\nradiometric and geometric measurements. Our method enables accurate and robust\ncalibration from data captured in uncontrolled and unstructured urban\nenvironments, making our solution more scalable than existing calibration\nsolutions. We demonstrate the accuracy and robustness of our method in urban\nscenes typically encountered in autonomous driving scenarios.\n","authors":["Quentin Herau","Nathan Piasco","Moussab Bennehar","Luis Roldão","Dzmitry Tsishkou","Cyrille Migniot","Pascal Vasseur","Cédric Demonceaux"],"pdf_url":"https://arxiv.org/pdf/2303.03056v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03052v1","updated":"2023-03-06T11:51:28Z","published":"2023-03-06T11:51:28Z","title":"Masked Images Are Counterfactual Samples for Robust Fine-tuning","summary":"  Deep learning models are challenged by the distribution shift between the\ntraining data and test data. Recently, the large models pre-trained on diverse\ndata demonstrate unprecedented robustness to various distribution shifts.\nHowever, fine-tuning on these models can lead to a trade-off between\nin-distribution (ID) performance and out-of-distribution (OOD) robustness.\nExisting methods for tackling this trade-off do not explicitly address the OOD\nrobustness problem. In this paper, based on causal analysis on the\naforementioned problems, we propose a novel fine-tuning method, which use\nmasked images as counterfactual samples that help improving the robustness of\nthe fine-tuning model. Specifically, we mask either the semantics-related or\nsemantics-unrelated patches of the images based on class activation map to\nbreak the spurious correlation, and refill the masked patches with patches from\nother images. The resulting counterfactual samples are used in feature-based\ndistillation with the pre-trained model. Extensive experiments verify that\nregularizing the fine-tuning with the proposed masked images can achieve a\nbetter trade-off between ID and OOD, surpassing previous methods on the OOD\nperformance. Our code will be publicly available.\n","authors":["Yao Xiao","Ziyi Tang","Pengxu Wei","Cong Liu","Liang Lin"],"pdf_url":"https://arxiv.org/pdf/2303.03052v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2212.02931v2","updated":"2023-03-06T11:48:02Z","published":"2022-12-06T12:40:45Z","title":"Leveraging Different Learning Styles for Improved Knowledge Distillation","summary":"  Learning style refers to a type of training mechanism adopted by an\nindividual to gain new knowledge. As suggested by the VARK model, humans have\ndifferent learning preferences like visual, auditory, etc., for acquiring and\neffectively processing information. Inspired by this concept, our work explores\nthe idea of mixed information sharing with model compression in the context of\nKnowledge Distillation (KD) and Mutual Learning (ML). Unlike conventional\ntechniques that share the same type of knowledge with all networks, we propose\nto train individual networks with different forms of information to enhance the\nlearning process. We formulate a combined KD and ML framework with one teacher\nand two student networks that share or exchange information in the form of\npredictions and feature maps. Our comprehensive experiments with benchmark\nclassification and segmentation datasets demonstrate that with 15% compression,\nthe ensemble performance of networks trained with diverse forms of knowledge\noutperforms the conventional techniques both quantitatively and qualitatively.\n","authors":["Usma Niyaz","Deepti R. Bathula"],"pdf_url":"https://arxiv.org/pdf/2212.02931v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03050v1","updated":"2023-03-06T11:46:58Z","published":"2023-03-06T11:46:58Z","title":"MABNet: Master Assistant Buddy Network with Hybrid Learning for Image\n  Retrieval","summary":"  Image retrieval has garnered growing interest in recent times. The current\napproaches are either supervised or self-supervised. These methods do not\nexploit the benefits of hybrid learning using both supervision and\nself-supervision. We present a novel Master Assistant Buddy Network (MABNet)\nfor image retrieval which incorporates both learning mechanisms. MABNet\nconsists of master and assistant blocks, both learning independently through\nsupervision and collectively via self-supervision. The master guides the\nassistant by providing its knowledge base as a reference for self-supervision\nand the assistant reports its knowledge back to the master by weight transfer.\nWe perform extensive experiments on public datasets with and without\npost-processing.\n","authors":["Rohit Agarwal","Gyanendra Das","Saksham Aggarwal","Alexander Horsch","Dilip K. Prasad"],"pdf_url":"https://arxiv.org/pdf/2303.03050v1.pdf","comment":"Accepted at International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP) 2023"},{"id":"http://arxiv.org/abs/2212.05729v3","updated":"2023-03-06T11:44:24Z","published":"2022-12-12T06:38:35Z","title":"ROIFormer: Semantic-Aware Region of Interest Transformer for Efficient\n  Self-Supervised Monocular Depth Estimation","summary":"  The exploration of mutual-benefit cross-domains has shown great potential\ntoward accurate self-supervised depth estimation. In this work, we revisit\nfeature fusion between depth and semantic information and propose an efficient\nlocal adaptive attention method for geometric aware representation enhancement.\nInstead of building global connections or deforming attention across the\nfeature space without restraint, we bound the spatial interaction within a\nlearnable region of interest. In particular, we leverage geometric cues from\nsemantic information to learn local adaptive bounding boxes to guide\nunsupervised feature aggregation. The local areas preclude most irrelevant\nreference points from attention space, yielding more selective feature learning\nand faster convergence. We naturally extend the paradigm into a multi-head and\nhierarchic way to enable the information distillation in different semantic\nlevels and improve the feature discriminative ability for fine-grained depth\nestimation. Extensive experiments on the KITTI dataset show that our proposed\nmethod establishes a new state-of-the-art in self-supervised monocular depth\nestimation task, demonstrating the effectiveness of our approach over former\nTransformer variants.\n","authors":["Daitao Xing","Jinglin Shen","Chiuman Ho","Anthony Tzes"],"pdf_url":"https://arxiv.org/pdf/2212.05729v3.pdf","comment":"Camera Ready for AAAI 2023"},{"id":"http://arxiv.org/abs/2206.05751v3","updated":"2023-03-06T11:18:59Z","published":"2022-06-12T14:45:11Z","title":"Consistent Attack: Universal Adversarial Perturbation on Embodied Vision\n  Navigation","summary":"  Embodied agents in vision navigation coupled with deep neural networks have\nattracted increasing attention. However, deep neural networks have been shown\nvulnerable to malicious adversarial noises, which may potentially cause\ncatastrophic failures in Embodied Vision Navigation. Among different\nadversarial noises, universal adversarial perturbations (UAP), i.e., a constant\nimage-agnostic perturbation applied on every input frame of the agent, play a\ncritical role in Embodied Vision Navigation since they are\ncomputation-efficient and application-practical during the attack. However,\nexisting UAP methods ignore the system dynamics of Embodied Vision Navigation\nand might be sub-optimal. In order to extend UAP to the sequential decision\nsetting, we formulate the disturbed environment under the universal noise\n$\\delta$, as a $\\delta$-disturbed Markov Decision Process ($\\delta$-MDP). Based\non the formulation, we analyze the properties of $\\delta$-MDP and propose two\nnovel Consistent Attack methods, named Reward UAP and Trajectory UAP, for\nattacking Embodied agents, which consider the dynamic of the MDP and calculate\nuniversal noises by estimating the disturbed distribution and the disturbed Q\nfunction. For various victim models, our Consistent Attack can cause a\nsignificant drop in their performance in the PointGoal task in Habitat with\ndifferent datasets and different scenes. Extensive experimental results\nindicate that there exist serious potential risks for applying Embodied Vision\nNavigation methods to the real world.\n","authors":["Chengyang Ying","You Qiaoben","Xinning Zhou","Hang Su","Wenbo Ding","Jianyong Ai"],"pdf_url":"https://arxiv.org/pdf/2206.05751v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03041v1","updated":"2023-03-06T11:13:23Z","published":"2023-03-06T11:13:23Z","title":"Automatic detection of aerial survey ground control points based on\n  Yolov5-OBB","summary":"  The use of ground control points (GCPs) for georeferencing is the most common\nstrategy in unmanned aerial vehicle (UAV) photogrammetry, but at the same time\ntheir collection represents the most time-consuming and expensive part of UAV\ncampaigns. Recently, deep learning has been rapidly developed in the field of\nsmall object detection. In this letter, to automatically extract coordinates\ninformation of ground control points (GCPs) by detecting GCP-markers in UAV\nimages, we propose a solution that uses a deep learning-based architecture,\nYOLOv5-OBB, combined with a confidence threshold filtering algorithm and an\noptimal ranking algorithm. We applied our proposed method to a dataset\ncollected by DJI Phantom 4 Pro drone and obtained good detection performance\nwith the mean Average Precision (AP) of 0.832 and the highest AP of 0.982 for\nthe cross-type GCP-markers. The proposed method can be a promising tool for\nfuture implementation of the end-to-end aerial triangulation process.\n","authors":["Cheng Chuanxiang","Yang Jia","Wang Chao","Zheng Zhi","Li Xiaopeng","Dong Di","Chang Mengxia","Zhuang Zhiheng"],"pdf_url":"https://arxiv.org/pdf/2303.03041v1.pdf","comment":"6 pages, 4 figures"},{"id":"http://arxiv.org/abs/2303.03037v1","updated":"2023-03-06T11:07:11Z","published":"2023-03-06T11:07:11Z","title":"EvCenterNet: Uncertainty Estimation for Object Detection using\n  Evidential Learning","summary":"  Uncertainty estimation is crucial in safety-critical settings such as\nautomated driving as it provides valuable information for several downstream\ntasks including high-level decision-making and path planning. In this work, we\npropose EvCenterNet, a novel uncertainty-aware 2D object detection framework\nutilizing evidential learning to directly estimate both classification and\nregression uncertainties. To employ evidential learning for object detection,\nwe devise a combination of evidential and focal loss functions for the sparse\nheatmap inputs. We introduce class-balanced weighting for regression and\nheatmap prediction to tackle the class imbalance encountered by evidential\nlearning. Moreover, we propose a learning scheme to actively utilize the\npredicted heatmap uncertainties to improve the detection performance by\nfocusing on the most uncertain points. We train our model on the KITTI dataset\nand evaluate it on challenging out-of-distribution datasets including BDD100K\nand nuImages. Our experiments demonstrate that our approach improves the\nprecision and minimizes the execution time loss in relation to the base model.\n","authors":["Monish R. Nallapareddy","Kshitij Sirohi","Paulo L. J. Drews-Jr","Wolfram Burgard","Chih-Hong Cheng","Abhinav Valada"],"pdf_url":"https://arxiv.org/pdf/2303.03037v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03032v1","updated":"2023-03-06T11:02:47Z","published":"2023-03-06T11:02:47Z","title":"DeCap: Decoding CLIP Latents for Zero-Shot Captioning via Text-Only\n  Training","summary":"  Large-scale pre-trained multi-modal models (e.g., CLIP) demonstrate strong\nzero-shot transfer capability in many discriminative tasks. Their adaptation to\nzero-shot image-conditioned text generation tasks has drawn increasing\ninterest. Prior arts approach to zero-shot captioning by either utilizing the\nexisting large language models (e.g., GPT-2) or pre-training the\nencoder-decoder network in an end-to-end manner. In this work, we propose a\nsimple framework, named DeCap, for zero-shot captioning. We introduce a\nlightweight visual-aware language decoder. This decoder is both data-efficient\nand computation-efficient: 1) it only requires the text data for training,\neasing the burden on the collection of paired data. 2) it does not require\nend-to-end training. When trained with text-only data, the decoder takes the\ntext embedding extracted from the off-the-shelf CLIP encoder as a prefix\nembedding. The challenge is that the decoder is trained on the text corpus but\nat the inference stage, it needs to generate captions based on visual inputs.\nThe modality gap issue is widely observed in multi-modal contrastive models\nthat prevents us from directly taking the visual embedding as the prefix\nembedding. We propose a training-free mechanism to reduce the modality gap. We\nproject the visual embedding into the CLIP text embedding space, while the\nprojected embedding retains the information of the visual input. Taking the\nprojected embedding as the prefix embedding, the decoder generates high-quality\ndescriptions that match the visual input. The experiments show that DeCap\noutperforms other zero-shot captioning methods and unpaired captioning methods\non the typical image captioning benchmarks, i.e., MSCOCO and NoCaps.\n","authors":["Wei Li","Linchao Zhu","Longyin Wen","Yi Yang"],"pdf_url":"https://arxiv.org/pdf/2303.03032v1.pdf","comment":"Accepted by ICLR 2023. Code is available at\n  https://github.com/dhg-wei/DeCap"},{"id":"http://arxiv.org/abs/2303.03028v1","updated":"2023-03-06T10:59:45Z","published":"2023-03-06T10:59:45Z","title":"RQAT-INR: Improved Implicit Neural Image Compression","summary":"  Deep variational autoencoders for image and video compression have gained\nsignificant attraction in the recent years, due to their potential to offer\ncompetitive or better compression rates compared to the decades long\ntraditional codecs such as AVC, HEVC or VVC. However, because of complexity and\nenergy consumption, these approaches are still far away from practical usage in\nindustry. More recently, implicit neural representation (INR) based codecs have\nemerged, and have lower complexity and energy usage to classical approaches at\ndecoding. However, their performances are not in par at the moment with\nstate-of-the-art methods. In this research, we first show that INR based image\ncodec has a lower complexity than VAE based approaches, then we propose several\nimprovements for INR-based image codec and outperformed baseline model by a\nlarge margin.\n","authors":["Bharath Bhushan Damodaran","Muhammet Balcilar","Franck Galpin","Pierre Hellier"],"pdf_url":"https://arxiv.org/pdf/2303.03028v1.pdf","comment":"Accepted as oral at Data compression conference 2023"},{"id":"http://arxiv.org/abs/2303.03023v1","updated":"2023-03-06T10:50:25Z","published":"2023-03-06T10:50:25Z","title":"Guiding Energy-based Models via Contrastive Latent Variables","summary":"  An energy-based model (EBM) is a popular generative framework that offers\nboth explicit density and architectural flexibility, but training them is\ndifficult since it is often unstable and time-consuming. In recent years,\nvarious training techniques have been developed, e.g., better divergence\nmeasures or stabilization in MCMC sampling, but there often exists a large gap\nbetween EBMs and other generative frameworks like GANs in terms of generation\nquality. In this paper, we propose a novel and effective framework for\nimproving EBMs via contrastive representation learning (CRL). To be specific,\nwe consider representations learned by contrastive methods as the true\nunderlying latent variable. This contrastive latent variable could guide EBMs\nto understand the data structure better, so it can improve and accelerate EBM\ntraining significantly. To enable the joint training of EBM and CRL, we also\ndesign a new class of latent-variable EBMs for learning the joint density of\ndata and the contrastive latent variable. Our experimental results demonstrate\nthat our scheme achieves lower FID scores, compared to prior-art EBM methods\n(e.g., additionally using variational autoencoders or diffusion techniques),\neven with significantly faster and more memory-efficient training. We also show\nconditional and compositional generation abilities of our latent-variable EBMs\nas their additional benefits, even without explicit conditional training. The\ncode is available at https://github.com/hankook/CLEL.\n","authors":["Hankook Lee","Jongheon Jeong","Sejun Park","Jinwoo Shin"],"pdf_url":"https://arxiv.org/pdf/2303.03023v1.pdf","comment":"Accepted to ICLR 2023 (Spotlight). The code is available at\n  https://github.com/hankook/CLEL"},{"id":"http://arxiv.org/abs/2012.01321v6","updated":"2023-03-06T10:41:29Z","published":"2020-12-02T16:49:51Z","title":"Red Blood Cell Segmentation with Overlapping Cell Separation and\n  Classification on Imbalanced Dataset","summary":"  Automated red blood cell (RBC) classification on blood smear images helps\nhematologists to analyze RBC lab results in a reduced time and cost. However,\noverlapping cells can cause incorrect predicted results, and so they have to be\nseparated into multiple single RBCs before classifying. To classify multiple\nclasses with deep learning, imbalance problems are common in medical imaging\nbecause normal samples are always higher than rare disease samples. This paper\npresents a new method to segment and classify RBCs from blood smear images,\nspecifically to tackle cell overlapping and data imbalance problems. Focusing\non overlapping cell separation, our segmentation process first estimates\nellipses to represent RBCs. The method detects the concave points and then\nfinds the ellipses using directed ellipse fitting. The accuracy from 20 blood\nsmear images was 0.889. Classification requires balanced training datasets.\nHowever, some RBC types are rare. The imbalance ratio of this dataset was\n34.538 for 12 RBC classes from 20,875 individual RBC samples. The use of\nmachine learning for RBC classification with an imbalanced dataset is hence\nmore challenging than many other applications. We analyzed techniques to deal\nwith this problem. The best accuracy and F1-score were 0.921 and 0.8679,\nrespectively, using EfficientNet-B1 with augmentation. Experimental results\nshowed that the weight balancing technique with augmentation had the potential\nto deal with imbalance problems by improving the F1-score on minority classes,\nwhile data augmentation significantly improved the overall classification\nperformance.\n","authors":["Korranat Naruenatthanaset","Thanarat H. Chalidabhongse","Duangdao Palasuwan","Nantheera Anantrasirichai","Attakorn Palasuwan"],"pdf_url":"https://arxiv.org/pdf/2012.01321v6.pdf","comment":"This work has been submitted to Intelligent Systems with Applications\n  (ISWA) for possible publication. Copyright may be transferred without notice,\n  after which this version may no longer be accessible"},{"id":"http://arxiv.org/abs/2207.05921v2","updated":"2023-03-06T10:11:53Z","published":"2022-07-13T02:01:07Z","title":"Texture-guided Saliency Distilling for Unsupervised Salient Object\n  Detection","summary":"  Deep Learning-based Unsupervised Salient Object Detection (USOD) mainly\nrelies on the noisy saliency pseudo labels that have been generated from\ntraditional handcraft methods or pre-trained networks. To cope with the noisy\nlabels problem, a class of methods focus on only easy samples with reliable\nlabels but ignore valuable knowledge in hard samples. In this paper, we propose\na novel USOD method to mine rich and accurate saliency knowledge from both easy\nand hard samples. First, we propose a Confidence-aware Saliency Distilling\n(CSD) strategy that scores samples conditioned on samples' confidences, which\nguides the model to distill saliency knowledge from easy samples to hard\nsamples progressively. Second, we propose a Boundary-aware Texture Matching\n(BTM) strategy to refine the boundaries of noisy labels by matching the\ntextures around the predicted boundary. Extensive experiments on RGB, RGB-D,\nRGB-T, and video SOD benchmarks prove that our method achieves state-of-the-art\nUSOD performance.\n","authors":["Huajun Zhou","Bo Qiao","Lingxiao Yang","Jianhuang Lai","Xiaohua Xie"],"pdf_url":"https://arxiv.org/pdf/2207.05921v2.pdf","comment":"8 pages, accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2303.03003v1","updated":"2023-03-06T10:04:50Z","published":"2023-03-06T10:04:50Z","title":"Efficient Large-scale Scene Representation with a Hybrid of\n  High-resolution Grid and Plane Features","summary":"  Existing neural radiance fields (NeRF) methods for large-scale scene modeling\nrequire days of training using multiple GPUs, hindering their applications in\nscenarios with limited computing resources. Despite fast optimization NeRF\nvariants have been proposed based on the explicit dense or hash grid features,\ntheir effectivenesses are mainly demonstrated in object-scale scene\nrepresentation. In this paper, we point out that the low feature resolution in\nexplicit representation is the bottleneck for large-scale unbounded scene\nrepresentation. To address this problem, we introduce a new and efficient\nhybrid feature representation for NeRF that fuses the 3D hash-grids and\nhigh-resolution 2D dense plane features. Compared with the dense-grid\nrepresentation, the resolution of a dense 2D plane can be scaled up more\nefficiently. Based on this hybrid representation, we propose a fast\noptimization NeRF variant, called GP-NeRF, that achieves better rendering\nresults while maintaining a compact model size. Extensive experiments on\nmultiple large-scale unbounded scene datasets show that our model can converge\nin 1.5 hours using a single GPU while achieving results comparable to or even\nbetter than the existing method that requires about one day's training with 8\nGPUs.\n","authors":["Yuqi Zhang","Guanying Chen","Shuguang Cui"],"pdf_url":"https://arxiv.org/pdf/2303.03003v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00722v2","updated":"2023-03-06T10:03:01Z","published":"2022-10-03T05:38:20Z","title":"GenDexGrasp: Generalizable Dexterous Grasping","summary":"  Generating dexterous grasping has been a long-standing and challenging\nrobotic task. Despite recent progress, existing methods primarily suffer from\ntwo issues. First, most prior arts focus on a specific type of robot hand,\nlacking the generalizable capability of handling unseen ones. Second, prior\narts oftentimes fail to rapidly generate diverse grasps with a high success\nrate. To jointly tackle these challenges with a unified solution, we propose\nGenDexGrasp, a novel hand-agnostic grasping algorithm for generalizable\ngrasping. GenDexGrasp is trained on our proposed large-scale multi-hand\ngrasping dataset MultiDex synthesized with force closure optimization. By\nleveraging the contact map as a hand-agnostic intermediate representation,\nGenDexGrasp efficiently generates diverse and plausible grasping poses with a\nhigh success rate and can transfer among diverse multi-fingered robotic hands.\nCompared with previous methods, GenDexGrasp achieves a three-way trade-off\namong success rate, inference speed, and diversity. Code is available at\nhttps://github.com/tengyu-liu/GenDexGrasp.\n","authors":["Puhao Li","Tengyu Liu","Yuyang Li","Yiran Geng","Yixin Zhu","Yaodong Yang","Siyuan Huang"],"pdf_url":"https://arxiv.org/pdf/2210.00722v2.pdf","comment":"Accepted to ICRA 2023 (camera-ready version)"},{"id":"http://arxiv.org/abs/2207.04242v2","updated":"2023-03-06T09:54:55Z","published":"2022-07-09T10:35:44Z","title":"PI-Trans: Parallel-ConvMLP and Implicit-Transformation Based GAN for\n  Cross-View Image Translation","summary":"  For semantic-guided cross-view image translation, it is crucial to learn\nwhere to sample pixels from the source view image and where to reallocate them\nguided by the target view semantic map, especially when there is little overlap\nor drastic view difference between the source and target images. Hence, one not\nonly needs to encode the long-range dependencies among pixels in both the\nsource view image and target view semantic map but also needs to translate\nthese learned dependencies. To this end, we propose a novel generative\nadversarial network, PI-Trans, which mainly consists of a novel\nParallel-ConvMLP module and an Implicit Transformation module at multiple\nsemantic levels. Extensive experimental results show that PI-Trans achieves the\nbest qualitative and quantitative performance by a large margin compared to the\nstate-of-the-art methods on two challenging datasets. The source code is\navailable at https://github.com/Amazingren/PI-Trans.\n","authors":["Bin Ren","Hao Tang","Yiming Wang","Xia Li","Wei Wang","Nicu Sebe"],"pdf_url":"https://arxiv.org/pdf/2207.04242v2.pdf","comment":"5 pages, 5 figures"},{"id":"http://arxiv.org/abs/2303.02998v1","updated":"2023-03-06T09:54:15Z","published":"2023-03-06T09:54:15Z","title":"Pseudo-label Correction and Learning For Semi-Supervised Object\n  Detection","summary":"  Pseudo-Labeling has emerged as a simple yet effective technique for\nsemi-supervised object detection (SSOD). However, the inevitable noise problem\nin pseudo-labels significantly degrades the performance of SSOD methods. Recent\nadvances effectively alleviate the classification noise in SSOD, while the\nlocalization noise which is a non-negligible part of SSOD is not\nwell-addressed. In this paper, we analyse the localization noise from the\ngeneration and learning phases, and propose two strategies, namely pseudo-label\ncorrection and noise-unaware learning. For pseudo-label correction, we\nintroduce a multi-round refining method and a multi-vote weighting method. The\nformer iteratively refines the pseudo boxes to improve the stability of\npredictions, while the latter smoothly self-corrects pseudo boxes by weighing\nthe scores of surrounding jittered boxes. For noise-unaware learning, we\nintroduce a loss weight function that is negatively correlated with the\nIntersection over Union (IoU) in the regression task, which pulls the predicted\nboxes closer to the object and improves localization accuracy. Our proposed\nmethod, Pseudo-label Correction and Learning (PCL), is extensively evaluated on\nthe MS COCO and PASCAL VOC benchmarks. On MS COCO, PCL outperforms the\nsupervised baseline by 12.16, 12.11, and 9.57 mAP and the recent SOTA\n(SoftTeacher) by 3.90, 2.54, and 2.43 mAP under 1\\%, 5\\%, and 10\\% labeling\nratios, respectively. On PASCAL VOC, PCL improves the supervised baseline by\n5.64 mAP and the recent SOTA (Unbiased Teacherv2) by 1.04 mAP on AP$^{50}$.\n","authors":["Yulin He","Wei Chen","Ke Liang","Yusong Tan","Zhengfa Liang","Yulan Guo"],"pdf_url":"https://arxiv.org/pdf/2303.02998v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.14465v3","updated":"2023-03-06T09:45:11Z","published":"2022-07-29T04:10:04Z","title":"Fine-grained Retrieval Prompt Tuning","summary":"  Fine-grained object retrieval aims to learn discriminative representation to\nretrieve visually similar objects. However, existing top-performing works\nusually impose pairwise similarities on the semantic embedding spaces or design\na localization sub-network to continually fine-tune the entire model in limited\ndata scenarios, thus resulting in convergence to suboptimal solutions. In this\npaper, we develop Fine-grained Retrieval Prompt Tuning (FRPT), which steers a\nfrozen pre-trained model to perform the fine-grained retrieval task from the\nperspectives of sample prompting and feature adaptation. Specifically, FRPT\nonly needs to learn fewer parameters in the prompt and adaptation instead of\nfine-tuning the entire model, thus solving the issue of convergence to\nsuboptimal solutions caused by fine-tuning the entire model. Technically, a\ndiscriminative perturbation prompt (DPP) is introduced and deemed as a sample\nprompting process, which amplifies and even exaggerates some discriminative\nelements contributing to category prediction via a content-aware inhomogeneous\nsampling operation. In this way, DPP can make the fine-grained retrieval task\naided by the perturbation prompts close to the solved task during the original\npre-training. Thereby, it preserves the generalization and discrimination of\nrepresentation extracted from input samples. Besides, a category-specific\nawareness head is proposed and regarded as feature adaptation, which removes\nthe species discrepancies in features extracted by the pre-trained model using\ncategory-guided instance normalization. And thus, it makes the optimized\nfeatures only include the discrepancies among subcategories. Extensive\nexperiments demonstrate that our FRPT with fewer learnable parameters achieves\nthe state-of-the-art performance on three widely-used fine-grained datasets.\n","authors":["Shijie Wang","Jianlong Chang","Zhihui Wang","Haojie Li","Wanli Ouyang","Qi Tian"],"pdf_url":"https://arxiv.org/pdf/2207.14465v3.pdf","comment":"Accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2303.02995v1","updated":"2023-03-06T09:44:01Z","published":"2023-03-06T09:44:01Z","title":"HiCLIP: Contrastive Language-Image Pretraining with Hierarchy-aware\n  Attention","summary":"  The success of large-scale contrastive vision-language pretraining (CLIP) has\nbenefited both visual recognition and multimodal content understanding. The\nconcise design brings CLIP the advantage in inference efficiency against other\nvision-language models with heavier cross-attention fusion layers, making it a\npopular choice for a wide spectrum of downstream tasks. However, CLIP does not\nexplicitly capture the hierarchical nature of high-level and fine-grained\nsemantics conveyed in images and texts, which is arguably critical to\nvision-language understanding and reasoning. To this end, we equip both the\nvisual and language branches in CLIP with hierarchy-aware attentions, namely\nHierarchy-aware CLIP (HiCLIP), to progressively discover semantic hierarchies\nlayer-by-layer from both images and texts in an unsupervised manner. As a\nresult, such hierarchical aggregation significantly improves the cross-modal\nalignment. To demonstrate the advantages of HiCLIP, we conduct qualitative\nanalysis on its unsupervised hierarchy induction during inference, as well as\nextensive quantitative experiments on both visual recognition and\nvision-language downstream tasks.\n","authors":["Shijie Geng","Jianbo Yuan","Yu Tian","Yuxiao Chen","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.02995v1.pdf","comment":"Accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.02994v1","updated":"2023-03-06T09:41:40Z","published":"2023-03-06T09:41:40Z","title":"Fighting noise and imbalance in Action Unit detection problems","summary":"  Action Unit (AU) detection aims at automatically caracterizing facial\nexpressions with the muscular activations they involve. Its main interest is to\nprovide a low-level face representation that can be used to assist higher level\naffective computing tasks learning. Yet, it is a challenging task. Indeed, the\navailable databases display limited face variability and are imbalanced toward\nneutral expressions. Furthermore, as AU involve subtle face movements they are\ndifficult to annotate so that some of the few provided datapoints may be\nmislabeled. In this work, we aim at exploiting label smoothing ability to\nmitigate noisy examples impact by reducing confidence [1]. However, applying\nlabel smoothing as it is may aggravate imbalance-based pre-existing\nunder-confidence issue and degrade performance. To circumvent this issue, we\npropose Robin Hood Label Smoothing (RHLS). RHLS principle is to restrain label\nsmoothing confidence reduction to the majority class. In that extent, it\nalleviates both the imbalance-based over-confidence issue and the negative\nimpact of noisy majority class examples. From an experimental standpoint, we\nshow that RHLS provides a free performance improvement in AU detection. In\nparticular, by applying it on top of a modern multi-task baseline we get\npromising results on BP4D and outperform state-of-the-art methods on DISFA.\n","authors":["Gauthier Tallec","Arnaud Dapogny","Kevin Bailly"],"pdf_url":"https://arxiv.org/pdf/2303.02994v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.09098v2","updated":"2023-03-06T09:33:17Z","published":"2022-12-18T14:51:46Z","title":"Mask-FPAN: Semi-Supervised Face Parsing in the Wild With De-Occlusion\n  and UV GAN","summary":"  Fine-grained semantic segmentation of a person's face and head, including\nfacial parts and head components, has progressed a great deal in recent years.\nHowever, it remains a challenging task, whereby considering ambiguous\nocclusions and large pose variations are particularly difficult. To overcome\nthese difficulties, we propose a novel framework termed Mask-FPAN. It uses a\nde-occlusion module that learns to parse occluded faces in a semi-supervised\nway. In particular, face landmark localization, face occlusionstimations, and\ndetected head poses are taken into account. A 3D morphable face model combined\nwith the UV GAN improves the robustness of 2D face parsing. In addition, we\nintroduce two new datasets named FaceOccMask-HQ and CelebAMaskOcc-HQ for face\nparing work. The proposed Mask-FPAN framework addresses the face parsing\nproblem in the wild and shows significant performance improvements with MIOU\nfrom 0.7353 to 0.9013 compared to the state-of-the-art on challenging face\ndatasets.\n","authors":["Lei Li","Tianfang Zhang","Stefan Oehmcke","Fabian Gieseke","Christian Igel"],"pdf_url":"https://arxiv.org/pdf/2212.09098v2.pdf","comment":"renew later"},{"id":"http://arxiv.org/abs/2303.02984v1","updated":"2023-03-06T09:23:14Z","published":"2023-03-06T09:23:14Z","title":"Learning multi-scale local conditional probability models of images","summary":"  Deep neural networks can learn powerful prior probability models for images,\nas evidenced by the high-quality generations obtained with recent score-based\ndiffusion methods. But the means by which these networks capture complex global\nstatistical structure, apparently without suffering from the curse of\ndimensionality, remain a mystery. To study this, we incorporate diffusion\nmethods into a multi-scale decomposition, reducing dimensionality by assuming a\nstationary local Markov model for wavelet coefficients conditioned on\ncoarser-scale coefficients. We instantiate this model using convolutional\nneural networks (CNNs) with local receptive fields, which enforce both the\nstationarity and Markov properties. Global structures are captured using a CNN\nwith receptive fields covering the entire (but small) low-pass image. We test\nthis model on a dataset of face images, which are highly non-stationary and\ncontain large-scale geometric structures. Remarkably, denoising,\nsuper-resolution, and image synthesis results all demonstrate that these\nstructures can be captured with significantly smaller conditioning\nneighborhoods than required by a Markov model implemented in the pixel domain.\nOur results show that score estimation for large complex images can be reduced\nto low-dimensional Markov conditional models across scales, alleviating the\ncurse of dimensionality.\n","authors":["Zahra Kadkhodaie","Florentin Guth","Stéphane Mallat","Eero P Simoncelli"],"pdf_url":"https://arxiv.org/pdf/2303.02984v1.pdf","comment":"16 pages, 8 figures"},{"id":"http://arxiv.org/abs/2303.02982v1","updated":"2023-03-06T09:17:47Z","published":"2023-03-06T09:17:47Z","title":"CLIP-guided Prototype Modulating for Few-shot Action Recognition","summary":"  Learning from large-scale contrastive language-image pre-training like CLIP\nhas shown remarkable success in a wide range of downstream tasks recently, but\nit is still under-explored on the challenging few-shot action recognition\n(FSAR) task. In this work, we aim to transfer the powerful multimodal knowledge\nof CLIP to alleviate the inaccurate prototype estimation issue due to data\nscarcity, which is a critical problem in low-shot regimes. To this end, we\npresent a CLIP-guided prototype modulating framework called CLIP-FSAR, which\nconsists of two key components: a video-text contrastive objective and a\nprototype modulation. Specifically, the former bridges the task discrepancy\nbetween CLIP and the few-shot video task by contrasting videos and\ncorresponding class text descriptions. The latter leverages the transferable\ntextual concepts from CLIP to adaptively refine visual prototypes with a\ntemporal Transformer. By this means, CLIP-FSAR can take full advantage of the\nrich semantic priors in CLIP to obtain reliable prototypes and achieve accurate\nfew-shot classification. Extensive experiments on five commonly used benchmarks\ndemonstrate the effectiveness of our proposed method, and CLIP-FSAR\nsignificantly outperforms existing state-of-the-art methods under various\nsettings. The source code and models will be publicly available at\nhttps://github.com/alibaba-mmai-research/CLIP-FSAR.\n","authors":["Xiang Wang","Shiwei Zhang","Jun Cen","Changxin Gao","Yingya Zhang","Deli Zhao","Nong Sang"],"pdf_url":"https://arxiv.org/pdf/2303.02982v1.pdf","comment":"This work has been submitted to the Springer for possible\n  publication. Copyright may be transferred without notice, after which this\n  version may no longer be accessible"},{"id":"http://arxiv.org/abs/2303.02978v1","updated":"2023-03-06T09:10:55Z","published":"2023-03-06T09:10:55Z","title":"System for 3D Acquisition and 3D Reconstruction using Structured Light\n  for Sewer Line Inspection","summary":"  The assessment of sewer pipe systems is a highly important, but at the same\ntime cumbersome and error-prone task. We introduce an innovative system based\non single-shot structured light modules that facilitates the detection and\nclassification of spatial defects like jutting intrusions, spallings, or\nmisaligned joints. This system creates highly accurate 3D measurements with\nsub-millimeter resolution of pipe surfaces and fuses them into a holistic 3D\nmodel. The benefit of such a holistic 3D model is twofold: on the one hand, it\nfacilitates the accurate manual sewer pipe assessment, on the other, it\nsimplifies the detection of defects in downstream automatic systems as it\nendows the input with highly accurate depth information. In this work, we\nprovide an extensive overview of the system and give valuable insights into our\ndesign choices.\n","authors":["Johannes Künzel","Darko Vehar","Rico Nestler","Karl-Heinz Franke","Anna Hilsmann","Peter Eisert"],"pdf_url":"https://arxiv.org/pdf/2303.02978v1.pdf","comment":"10 pages, published at VISAPP 2023, Lisbon, Portugal"},{"id":"http://arxiv.org/abs/2202.00446v2","updated":"2023-03-06T09:06:49Z","published":"2022-02-01T14:58:21Z","title":"Multi-Order Networks for Action Unit Detection","summary":"  Action Units (AU) are muscular activations used to describe facial\nexpressions. Therefore accurate AU recognition unlocks unbiaised face\nrepresentation which can improve face-based affective computing applications.\nFrom a learning standpoint AU detection is a multi-task problem with strong\ninter-task dependencies. To solve such problem, most approaches either rely on\nweight sharing, or add explicit dependency modelling by decomposing the joint\ntask distribution using Bayes chain rule. If the latter strategy yields\ncomprehensive inter-task relationships modelling, it requires imposing an\narbitrary order into an unordered task set. Crucially, this ordering choice has\nbeen identified as a source of performance variations. In this paper, we\npresent Multi-Order Network (MONET), a multi-task method with joint task order\noptimization. MONET uses a differentiable order selection to jointly learn\ntask-wise modules with their optimal chaining order. Furthermore, we introduce\nwarmup and order dropout to enhance order selection by encouraging order\nexploration. Experimentally, we first demonstrate MONET capacity to retrieve\nthe optimal order in a toy environment. Second, we validate MONET architecture\nby showing that MONET outperforms existing multi-task baselines on multiple\nattribute detection problems chosen for their wide range of dependency\nsettings. More importantly, we demonstrate that MONET significantly extends\nstate-of-the-art performance in AU detection.\n","authors":["Gauthier Tallec","Arnaud Dapogny","Kevin Bailly"],"pdf_url":"https://arxiv.org/pdf/2202.00446v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02975v1","updated":"2023-03-06T09:06:49Z","published":"2023-03-06T09:06:49Z","title":"Histogram-based Deep Learning for Automotive Radar","summary":"  There are various automotive applications that rely on correctly interpreting\npoint cloud data recorded with radar sensors. We present a deep learning\napproach for histogram-based processing of such point clouds. Compared to\nexisting methods, the design of our approach is extremely simple: it boils down\nto computing a point cloud histogram and passing it through a multi-layer\nperceptron. Our approach matches and surpasses state-of-the-art approaches on\nthe task of automotive radar object type classification. It is also robust to\nnoise that often corrupts radar measurements, and can deal with missing\nfeatures of single radar reflections. Finally, the design of our approach makes\nit more interpretable than existing methods, allowing insightful analysis of\nits decisions.\n","authors":["Maxim Tatarchenko","Kilian Rambach"],"pdf_url":"https://arxiv.org/pdf/2303.02975v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.06961v2","updated":"2023-03-06T09:01:36Z","published":"2023-02-14T10:40:20Z","title":"Bilateral-Fuser: A Novel Multi-cue Fusion Architecture with\n  Anatomical-aware Tokens for Fovea Localization","summary":"  Accurate localization of the fovea is a crucial initial step in analyzing\nretinal diseases since it helps prevent irreversible vision loss. Although\ncurrent deep learning-based methods achieve better performance than traditional\nmethods, they still face challenges such as inadequate utilization of\nanatomical landmarks, sensitivity to diseased retinal images, and various image\nconditions. In this paper, we propose a novel transformer-based architecture\n(Bilateral-Fuser) for multi-cue fusion. The Bilateral-Fuser explicitly\nincorporates long-range connections and global features using retina and vessel\ndistributions to achieve robust fovea localization. We introduce a spatial\nattention mechanism in the dual-stream encoder to extract and fuse self-learned\nanatomical information. This design focuses more on features distributed along\nblood vessels and significantly reduces computational costs by reducing token\nnumbers. Our comprehensive experiments demonstrate that the proposed\narchitecture achieves state-of-the-art performance on two public datasets and\none large-scale private dataset. Moreover, we show that the Bilateral-Fuser is\nmore robust on both normal and diseased retina images and has better\ngeneralization capacity in cross-dataset experiments.\n","authors":["Sifan Song","Jinfeng Wang","Zilong Wang","Shaopeng Wang","Jionglong Su","Xiaowei Ding","Kang Dang"],"pdf_url":"https://arxiv.org/pdf/2302.06961v2.pdf","comment":"This paper is prepared for IEEE Transactions on Medical Imaging"},{"id":"http://arxiv.org/abs/2303.02081v2","updated":"2023-03-06T08:58:43Z","published":"2023-03-03T16:55:44Z","title":"Unproportional mosaicing","summary":"  Data shift is a gap between data distribution used for training and data\ndistribution encountered in the real-world. Data augmentations help narrow the\ngap by generating new data samples, increasing data variability, and data space\ncoverage. We present a new data augmentation: Unproportional mosaicing\n(Unprop). Our augmentation randomly splits an image into various-sized blocks\nand swaps its content (pixels) while maintaining block sizes. Our method\nachieves a lower error rate when combined with other state-of-the-art\naugmentations.\n","authors":["Vojtech Molek","Petr Hurtik","Pavel Vlasanek","David Adamczyk"],"pdf_url":"https://arxiv.org/pdf/2303.02081v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02970v1","updated":"2023-03-06T08:54:18Z","published":"2023-03-06T08:54:18Z","title":"Rethinking Confidence Calibration for Failure Prediction","summary":"  Reliable confidence estimation for the predictions is important in many\nsafety-critical applications. However, modern deep neural networks are often\noverconfident for their incorrect predictions. Recently, many calibration\nmethods have been proposed to alleviate the overconfidence problem. With\ncalibrated confidence, a primary and practical purpose is to detect\nmisclassification errors by filtering out low-confidence predictions (known as\nfailure prediction). In this paper, we find a general, widely-existed but\nactually-neglected phenomenon that most confidence calibration methods are\nuseless or harmful for failure prediction. We investigate this problem and\nreveal that popular confidence calibration methods often lead to worse\nconfidence separation between correct and incorrect samples, making it more\ndifficult to decide whether to trust a prediction or not. Finally, inspired by\nthe natural connection between flat minima and confidence separation, we\npropose a simple hypothesis: flat minima is beneficial for failure prediction.\nWe verify this hypothesis via extensive experiments and further boost the\nperformance by combining two different flat minima techniques. Our code is\navailable at https://github.com/Impression2805/FMFP\n","authors":["Fei Zhu","Zhen Cheng","Xu-Yao Zhang","Cheng-Lin Liu"],"pdf_url":"https://arxiv.org/pdf/2303.02970v1.pdf","comment":"Accepted to ECCV 2022. Code is available at\n  https://github.com/Impression2805/FMFP"},{"id":"http://arxiv.org/abs/2303.02968v1","updated":"2023-03-06T08:53:22Z","published":"2023-03-06T08:53:22Z","title":"DwinFormer: Dual Window Transformers for End-to-End Monocular Depth\n  Estimation","summary":"  Depth estimation from a single image is of paramount importance in the realm\nof computer vision, with a multitude of applications. Conventional methods\nsuffer from the trade-off between consistency and fine-grained details due to\nthe local-receptive field limiting their practicality. This lack of long-range\ndependency inherently comes from the convolutional neural network part of the\narchitecture. In this paper, a dual window transformer-based network, namely\nDwinFormer, is proposed, which utilizes both local and global features for\nend-to-end monocular depth estimation. The DwinFormer consists of dual window\nself-attention and cross-attention transformers, Dwin-SAT and Dwin-CAT,\nrespectively. The Dwin-SAT seamlessly extracts intricate, locally aware\nfeatures while concurrently capturing global context. It harnesses the power of\nlocal and global window attention to adeptly capture both short-range and\nlong-range dependencies, obviating the need for complex and computationally\nexpensive operations, such as attention masking or window shifting. Moreover,\nDwin-SAT introduces inductive biases which provide desirable properties, such\nas translational equvariance and less dependence on large-scale data.\nFurthermore, conventional decoding methods often rely on skip connections which\nmay result in semantic discrepancies and a lack of global context when fusing\nencoder and decoder features. In contrast, the Dwin-CAT employs both local and\nglobal window cross-attention to seamlessly fuse encoder and decoder features\nwith both fine-grained local and contextually aware global information,\neffectively amending semantic gap. Empirical evidence obtained through\nextensive experimentation on the NYU-Depth-V2 and KITTI datasets demonstrates\nthe superiority of the proposed method, consistently outperforming existing\napproaches across both indoor and outdoor environments.\n","authors":["Md Awsafur Rahman","Shaikh Anowarul Fattah"],"pdf_url":"https://arxiv.org/pdf/2303.02968v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02967v1","updated":"2023-03-06T08:51:01Z","published":"2023-03-06T08:51:01Z","title":"Automated Peripancreatic Vessel Segmentation and Labeling Based on\n  Iterative Trunk Growth and Weakly Supervised Mechanism","summary":"  Peripancreatic vessel segmentation and anatomical labeling play extremely\nimportant roles to assist the early diagnosis, surgery planning and prognosis\nfor patients with pancreatic tumors. However, most current techniques cannot\nachieve satisfactory segmentation performance for peripancreatic veins and\nusually make predictions with poor integrity and connectivity. Besides,\nunsupervised labeling algorithms cannot deal with complex anatomical variation\nwhile fully supervised methods require a large number of voxel-wise annotations\nfor training, which is very labor-intensive and time-consuming. To address\nthese problems, we propose our Automated Peripancreatic vEssel Segmentation and\nlAbeling (APESA) framework, to not only highly improve the segmentation\nperformance for peripancreatic veins, but also efficiently identify the\nperipancreatic artery branches. There are two core modules in our proposed\nAPESA framework: iterative trunk growth module (ITGM) for vein segmentation and\nweakly supervised labeling mechanism (WSLM) for artery branch identification.\nOur proposed ITGM is composed of a series of trunk growth modules, each of\nwhich chooses the most reliable trunk of a basic vessel prediction by the\nlargest connected constraint, and seeks for the possible growth branches by\nbranch proposal network. Our designed iterative process guides the raw trunk to\nbe more complete and fully connected. Our proposed WSLM consists of an\nunsupervised rule-based preprocessing for generating pseudo branch annotations,\nand an anatomical labeling network to learn the branch distribution voxel by\nvoxel. We achieve Dice of 94.01% for vein segmentation on our collected\ndataset, which boosts the accuracy by nearly 10% compared with the\nstate-of-the-art methods. Additionally, we also achieve Dice of 97.01% on\nsegmentation and competitive performance on anatomical labeling for\nperipancreatic arteries.\n","authors":["Liwen Zou","Zhenghua Cai","Liang Mao","Ziwei Nie","Yudong Qiu","Xiaoping Yang"],"pdf_url":"https://arxiv.org/pdf/2303.02967v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02961v1","updated":"2023-03-06T08:32:50Z","published":"2023-03-06T08:32:50Z","title":"Models See Hallucinations: Evaluating the Factuality in Video Captioning","summary":"  Video captioning aims to describe events in a video with natural language. In\nrecent years, many works have focused on improving captioning models'\nperformance. However, like other text generation tasks, it risks introducing\nfactual errors not supported by the input video. These factual errors can\nseriously affect the quality of the generated text, sometimes making it\ncompletely unusable. Although factual consistency has received much research\nattention in text-to-text tasks (e.g., summarization), it is less studied in\nthe context of vision-based text generation. In this work, we conduct a\ndetailed human evaluation of the factuality in video captioning and collect two\nannotated factuality datasets. We find that 57.0% of the model-generated\nsentences have factual errors, indicating it is a severe problem in this field.\nHowever, existing evaluation metrics are mainly based on n-gram matching and\nshow little correlation with human factuality annotation. We further propose a\nweakly-supervised, model-based factuality metric FactVC, which outperforms\nprevious metrics on factuality evaluation of video captioning. The datasets and\nmetrics will be released to promote future research for video captioning.\n","authors":["Hui Liu","Xiaojun Wan"],"pdf_url":"https://arxiv.org/pdf/2303.02961v1.pdf","comment":"17 pages"},{"id":"http://arxiv.org/abs/2303.02959v1","updated":"2023-03-06T08:19:15Z","published":"2023-03-06T08:19:15Z","title":"Butterfly: Multiple Reference Frames Feature Propagation Mechanism for\n  Neural Video Compression","summary":"  Using more reference frames can significantly improve the compression\nefficiency in neural video compression. However, in low-latency scenarios, most\nexisting neural video compression frameworks usually use the previous one frame\nas reference. Or a few frameworks which use the previous multiple frames as\nreference only adopt a simple multi-reference frames propagation mechanism. In\nthis paper, we present a more reasonable multi-reference frames propagation\nmechanism for neural video compression, called butterfly multi-reference frame\npropagation mechanism (Butterfly), which allows a more effective feature fusion\nof multi-reference frames. By this, we can generate more accurate temporal\ncontext conditional prior for Contextual Coding Module. Besides, when the\nnumber of decoded frames does not meet the required number of reference frames,\nwe duplicate the nearest reference frame to achieve the requirement, which is\nbetter than duplicating the furthest one. Experiment results show that our\nmethod can significantly outperform the previous state-of-the-art (SOTA), and\nour neural codec can achieve -7.6% bitrate save on HEVC Class D dataset when\ncompares with our base single-reference frame model with the same compression\nconfiguration.\n","authors":["Feng Wang","Haihang Ruan","Fei Xiong","Jiayu Yang","Litian Li","Ronggang Wang"],"pdf_url":"https://arxiv.org/pdf/2303.02959v1.pdf","comment":"Accepted by DCC 2023"},{"id":"http://arxiv.org/abs/2303.02954v1","updated":"2023-03-06T07:54:37Z","published":"2023-03-06T07:54:37Z","title":"Centroid Distance Distillation for Effective Rehearsal in Continual\n  Learning","summary":"  Rehearsal, retraining on a stored small data subset of old tasks, has been\nproven effective in solving catastrophic forgetting in continual learning.\nHowever, due to the sampled data may have a large bias towards the original\ndataset, retraining them is susceptible to driving continual domain drift of\nold tasks in feature space, resulting in forgetting. In this paper, we focus on\ntackling the continual domain drift problem with centroid distance\ndistillation. First, we propose a centroid caching mechanism for sampling data\npoints based on constructed centroids to reduce the sample bias in rehearsal.\nThen, we present a centroid distance distillation that only stores the centroid\ndistance to reduce the continual domain drift. The experiments on four\ncontinual learning datasets show the superiority of the proposed method, and\nthe continual domain drift can be reduced.\n","authors":["Daofeng Liu","Fan Lyu","Linyan Li","Zhenping Xia","Fuyuan Hu"],"pdf_url":"https://arxiv.org/pdf/2303.02954v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.08024v2","updated":"2023-03-06T07:38:08Z","published":"2022-11-15T10:15:21Z","title":"NAR-Former: Neural Architecture Representation Learning towards Holistic\n  Attributes Prediction","summary":"  With the wide and deep adoption of deep learning models in real applications,\nthere is an increasing need to model and learn the representations of the\nneural networks themselves. These models can be used to estimate attributes of\ndifferent neural network architectures such as the accuracy and latency,\nwithout running the actual training or inference tasks. In this paper, we\npropose a neural architecture representation model that can be used to estimate\nthese attributes holistically. Specifically, we first propose a simple and\neffective tokenizer to encode both the operation and topology information of a\nneural network into a single sequence. Then, we design a multi-stage fusion\ntransformer to build a compact vector representation from the converted\nsequence. For efficient model training, we further propose an information flow\nconsistency augmentation and correspondingly design an architecture consistency\nloss, which brings more benefits with less augmentation samples compared with\nprevious random augmentation strategies. Experiment results on NAS-Bench-101,\nNAS-Bench-201, DARTS search space and NNLQP show that our proposed framework\ncan be used to predict the aforementioned latency and accuracy attributes of\nboth cell architectures and whole deep neural networks, and achieves promising\nperformance.\n","authors":["Yun Yi","Haokui Zhang","Wenze Hu","Nannan Wang","Xiaoyu Wang"],"pdf_url":"https://arxiv.org/pdf/2211.08024v2.pdf","comment":"9 pages, 4 figures, 7 tables. Accepted by Computer Vision and Pattern\n  Recognition (CVPR)2023. The code will be released soon"},{"id":"http://arxiv.org/abs/2211.11425v2","updated":"2023-03-06T07:37:49Z","published":"2022-11-21T13:12:07Z","title":"Data Leakage and Evaluation Issues in Micro-Expression Analysis","summary":"  Micro-expressions have drawn increasing interest lately due to various\npotential applications. The task is, however, difficult as it incorporates many\nchallenges from the fields of computer vision, machine learning and emotional\nsciences. Due to the spontaneous and subtle characteristics of\nmicro-expressions, the available training and testing data are limited, which\nmake evaluation complex. We show that data leakage and fragmented evaluation\nprotocols are issues among the micro-expression literature. We find that fixing\ndata leaks can drastically reduce model performance, in some cases even making\nthe models perform similarly to a random classifier. To this end, we go through\ncommon pitfalls, propose a new standardized evaluation protocol using facial\naction units with over 2000 micro-expression samples, and provide an open\nsource library that implements the evaluation protocols in a standardized\nmanner. Code is publicly available in \\url{https://github.com/tvaranka/meb}.\n","authors":["Tuomas Varanka","Yante Li","Wei Peng","Guoying Zhao"],"pdf_url":"https://arxiv.org/pdf/2211.11425v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02944v1","updated":"2023-03-06T07:31:01Z","published":"2023-03-06T07:31:01Z","title":"CTG-Net: An Efficient Cascaded Framework Driven by Terminal Guidance\n  Mechanism for Dilated Pancreatic Duct Segmentation","summary":"  Pancreatic duct dilation indicates a high risk of various pancreatic\ndiseases. Segmentation of dilated pancreatic ducts on computed tomography (CT)\nimages shows the potential to assist the early diagnosis, surgical planning and\nprognosis. Because of the ducts' tiny sizes, slender tubular structures and the\nsurrounding distractions, most current researches on pancreatic duct\nsegmentation achieve low accuracy and always have segmentation errors on the\nterminal parts of the ducts. To address these problems, we propose a terminal\nguidance mechanism called cascaded terminal guidance network (CTG-Net).\nFirstly, a terminal attention mechanism is established on the skeletons\nextracted from the coarse predictions. Then, to get fine terminal segmentation,\na subnetwork is designed for jointly learning the local intensity from the\noriginal images, feature cues from coarse predictions and global anatomy\ninformation from the pancreas distance transform maps. Finally, a terminal\ndistraction attention module which explicitly learns the distribution of the\nterminal distraction is proposed to reduce the false positive and false\nnegative predictions. We also propose a new metric called tDice to measure the\nterminal segmentation accuracy for targets with tubular structures and two\nsegmentation metrics for distractions. We collect our dilated pancreatic duct\nsegmentation dataset with 150 CT scans from patients with 5 types of pancreatic\ntumors. Experimental results on our dataset show that our proposed approach\nboosts dilated pancreatic duct segmentation accuracy by nearly 20% compared\nwith the existing results, and achieves more than 9% improvement for the\nterminal segmentation accuracy compared with the state-of-the-art methods.\n","authors":["Liwen Zou","Zhenghua Cai","Yudong Qiu","Luying Gui","Liang Mao","Xiaoping Yang"],"pdf_url":"https://arxiv.org/pdf/2303.02944v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02943v1","updated":"2023-03-06T07:30:53Z","published":"2023-03-06T07:30:53Z","title":"Adaptive Texture Filtering for Single-Domain Generalized Segmentation","summary":"  Domain generalization in semantic segmentation aims to alleviate the\nperformance degradation on unseen domains through learning domain-invariant\nfeatures. Existing methods diversify images in the source domain by adding\ncomplex or even abnormal textures to reduce the sensitivity to domain specific\nfeatures. However, these approaches depend heavily on the richness of the\ntexture bank, and training them can be time-consuming. In contrast to importing\ntextures arbitrarily or augmenting styles randomly, we focus on the single\nsource domain itself to achieve generalization. In this paper, we present a\nnovel adaptive texture filtering mechanism to suppress the influence of texture\nwithout using augmentation, thus eliminating the interference of\ndomain-specific features. Further, we design a hierarchical guidance\ngeneralization network equipped with structure-guided enhancement modules,\nwhich purpose is to learn the domain-invariant generalized knowledge. Extensive\nexperiments together with ablation studies on widely-used datasets are\nconducted to verify the effectiveness of the proposed model, and reveal its\nsuperiority over other state-of-the-art alternatives.\n","authors":["Xinhui Li","Mingjia Li","Yaxing Wang","Chuan-Xian Ren","Xiaojie Guo"],"pdf_url":"https://arxiv.org/pdf/2303.02943v1.pdf","comment":"Accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2303.02936v1","updated":"2023-03-06T07:10:07Z","published":"2023-03-06T07:10:07Z","title":"UniHCP: A Unified Model for Human-Centric Perceptions","summary":"  Human-centric perceptions (e.g., pose estimation, human parsing, pedestrian\ndetection, person re-identification, etc.) play a key role in industrial\napplications of visual models. While specific human-centric tasks have their\nown relevant semantic aspect to focus on, they also share the same underlying\nsemantic structure of the human body. However, few works have attempted to\nexploit such homogeneity and design a general-propose model for human-centric\ntasks. In this work, we revisit a broad range of human-centric tasks and unify\nthem in a minimalist manner. We propose UniHCP, a Unified Model for\nHuman-Centric Perceptions, which unifies a wide range of human-centric tasks in\na simplified end-to-end manner with the plain vision transformer architecture.\nWith large-scale joint training on 33 human-centric datasets, UniHCP can\noutperform strong baselines on several in-domain and downstream tasks by direct\nevaluation. When adapted to a specific task, UniHCP achieves new SOTAs on a\nwide range of human-centric tasks, e.g., 69.8 mIoU on CIHP for human parsing,\n86.18 mA on PA-100K for attribute prediction, 90.3 mAP on Market1501 for ReID,\nand 85.8 JI on CrowdHuman for pedestrian detection, performing better than\nspecialized models tailored for each task.\n","authors":["Yuanzheng Ci","Yizhou Wang","Meilin Chen","Shixiang Tang","Lei Bai","Feng Zhu","Rui Zhao","Fengwei Yu","Donglian Qi","Wanli Ouyang"],"pdf_url":"https://arxiv.org/pdf/2303.02936v1.pdf","comment":"Accepted for publication at the IEEE/CVF Conference on Computer\n  Vision and Pattern Recognition 2023 (CVPR 2023)"},{"id":"http://arxiv.org/abs/2303.02930v1","updated":"2023-03-06T06:52:00Z","published":"2023-03-06T06:52:00Z","title":"Scapegoat Generation for Privacy Protection from Deepfake","summary":"  To protect privacy and prevent malicious use of deepfake, current studies\npropose methods that interfere with the generation process, such as detection\nand destruction approaches. However, these methods suffer from sub-optimal\ngeneralization performance to unseen models and add undesirable noise to the\noriginal image. To address these problems, we propose a new problem formulation\nfor deepfake prevention: generating a ``scapegoat image'' by modifying the\nstyle of the original input in a way that is recognizable as an avatar by the\nuser, but impossible to reconstruct the real face. Even in the case of\nmalicious deepfake, the privacy of the users is still protected. To achieve\nthis, we introduce an optimization-based editing method that utilizes GAN\ninversion to discourage deepfake models from generating similar scapegoats. We\nvalidate the effectiveness of our proposed method through quantitative and user\nstudies.\n","authors":["Gido Kato","Yoshihiro Fukuhara","Mariko Isogawa","Hideki Tsunashima","Hirokatsu Kataoka","Shigeo Morishima"],"pdf_url":"https://arxiv.org/pdf/2303.02930v1.pdf","comment":"5 pages, 5 figures"},{"id":"http://arxiv.org/abs/2203.09287v2","updated":"2023-03-06T06:50:31Z","published":"2022-03-17T12:30:17Z","title":"HybridCap: Inertia-aid Monocular Capture of Challenging Human Motions","summary":"  Monocular 3D motion capture (mocap) is beneficial to many applications. The\nuse of a single camera, however, often fails to handle occlusions of different\nbody parts and hence it is limited to capture relatively simple movements. We\npresent a light-weight, hybrid mocap technique called HybridCap that augments\nthe camera with only 4 Inertial Measurement Units (IMUs) in a\nlearning-and-optimization framework. We first employ a weakly-supervised and\nhierarchical motion inference module based on cooperative Gated Recurrent Unit\n(GRU) blocks that serve as limb, body and root trackers as well as an inverse\nkinematics solver. Our network effectively narrows the search space of\nplausible motions via coarse-to-fine pose estimation and manages to tackle\nchallenging movements with high efficiency. We further develop a hybrid\noptimization scheme that combines inertial feedback and visual cues to improve\ntracking accuracy. Extensive experiments on various datasets demonstrate\nHybridCap can robustly handle challenging movements ranging from fitness\nactions to Latin dance. It also achieves real-time performance up to 60 fps\nwith state-of-the-art accuracy.\n","authors":["Han Liang","Yannan He","Chengfeng Zhao","Mutian Li","Jingya Wang","Jingyi Yu","Lan Xu"],"pdf_url":"https://arxiv.org/pdf/2203.09287v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02922v1","updated":"2023-03-06T06:40:13Z","published":"2023-03-06T06:40:13Z","title":"SurfNN: Joint Reconstruction of Multiple Cortical Surfaces from Magnetic\n  Resonance Images","summary":"  To achieve fast, robust, and accurate reconstruction of the human cortical\nsurfaces from 3D magnetic resonance images (MRIs), we develop a novel deep\nlearning-based framework, referred to as SurfNN, to reconstruct simultaneously\nboth inner (between white matter and gray matter) and outer (pial) surfaces\nfrom MRIs. Different from existing deep learning-based cortical surface\nreconstruction methods that either reconstruct the cortical surfaces separately\nor neglect the interdependence between the inner and outer surfaces, SurfNN\nreconstructs both the inner and outer cortical surfaces jointly by training a\nsingle network to predict a midthickness surface that lies at the center of the\ninner and outer cortical surfaces. The input of SurfNN consists of a 3D MRI and\nan initialization of the midthickness surface that is represented both\nimplicitly as a 3D distance map and explicitly as a triangular mesh with\nspherical topology, and its output includes both the inner and outer cortical\nsurfaces, as well as the midthickness surface. The method has been evaluated on\na large-scale MRI dataset and demonstrated competitive cortical surface\nreconstruction performance.\n","authors":["Hao Zheng","Hongming Li","Yong Fan"],"pdf_url":"https://arxiv.org/pdf/2303.02922v1.pdf","comment":"ISBI 2023"},{"id":"http://arxiv.org/abs/2210.04432v2","updated":"2023-03-06T06:29:13Z","published":"2022-10-10T04:36:50Z","title":"Spectral Geometric Verification: Re-Ranking Point Cloud Retrieval for\n  Metric Localization","summary":"  In large-scale metric localization, an incorrect result during retrieval will\nlead to an incorrect pose estimate or loop closure. Re-ranking methods propose\nto take into account all the top retrieval candidates and re-order them to\nincrease the likelihood of the top candidate being correct. However,\nstate-of-the-art re-ranking methods are inefficient when re-ranking many\npotential candidates due to their need for resource intensive point cloud\nregistration between the query and each candidate. In this work, we propose an\nefficient spectral method for geometric verification (named SpectralGV) that\ndoes not require registration. We demonstrate how the optimal inter-cluster\nscore of the correspondence compatibility graph of two point clouds represents\na robust fitness score measuring their spatial consistency. This score takes\ninto account the subtle geometric differences between structurally similar\npoint clouds and therefore can be used to identify the correct candidate among\npotential matches retrieved by global similarity search. SpectralGV is\ndeterministic, robust to outlier correspondences, and can be computed in\nparallel for all potential candidates. We conduct extensive experiments on 5\nlarge-scale datasets to demonstrate that SpectralGV outperforms other\nstate-of-the-art re-ranking methods and show that it consistently improves the\nrecall and pose estimation of 3 state-of-the-art metric localization\narchitectures while having a negligible effect on their runtime. The\nopen-source implementation and trained models are available at:\nhttps://github.com/csiro-robotics/SpectralGV.\n","authors":["Kavisha Vidanapathirana","Peyman Moghadam","Sridha Sridharan","Clinton Fookes"],"pdf_url":"https://arxiv.org/pdf/2210.04432v2.pdf","comment":"Accepted for publication in IEEE RA-L (2023)"},{"id":"http://arxiv.org/abs/2302.14589v2","updated":"2023-03-06T06:27:07Z","published":"2023-02-28T14:16:32Z","title":"Focus On Details: Online Multi-object Tracking with Diverse Fine-grained\n  Representation","summary":"  Discriminative representation is essential to keep a unique identifier for\neach target in Multiple object tracking (MOT). Some recent MOT methods extract\nfeatures of the bounding box region or the center point as identity embeddings.\nHowever, when targets are occluded, these coarse-grained global representations\nbecome unreliable. To this end, we propose exploring diverse fine-grained\nrepresentation, which describes appearance comprehensively from global and\nlocal perspectives. This fine-grained representation requires high feature\nresolution and precise semantic information. To effectively alleviate the\nsemantic misalignment caused by indiscriminate contextual information\naggregation, Flow Alignment FPN (FAFPN) is proposed for multi-scale feature\nalignment aggregation. It generates semantic flow among feature maps from\ndifferent resolutions to transform their pixel positions. Furthermore, we\npresent a Multi-head Part Mask Generator (MPMG) to extract fine-grained\nrepresentation based on the aligned feature maps. Multiple parallel branches of\nMPMG allow it to focus on different parts of targets to generate local masks\nwithout label supervision. The diverse details in target masks facilitate\nfine-grained representation. Eventually, benefiting from a Shuffle-Group\nSampling (SGS) training strategy with positive and negative samples balanced,\nwe achieve state-of-the-art performance on MOT17 and MOT20 test sets. Even on\nDanceTrack, where the appearance of targets is extremely similar, our method\nsignificantly outperforms ByteTrack by 5.0% on HOTA and 5.6% on IDF1. Extensive\nexperiments have proved that diverse fine-grained representation makes Re-ID\ngreat again in MOT.\n","authors":["Hao Ren","Shoudong Han","Huilin Ding","Ziwen Zhang","Hongwei Wang","Faquan Wang"],"pdf_url":"https://arxiv.org/pdf/2302.14589v2.pdf","comment":"CVPR2023"},{"id":"http://arxiv.org/abs/2303.02906v1","updated":"2023-03-06T05:52:13Z","published":"2023-03-06T05:52:13Z","title":"MotionVideoGAN: A Novel Video Generator Based on the Motion Space\n  Learned from Image Pairs","summary":"  Video generation has achieved rapid progress benefiting from high-quality\nrenderings provided by powerful image generators. We regard the video synthesis\ntask as generating a sequence of images sharing the same contents but varying\nin motions. However, most previous video synthesis frameworks based on\npre-trained image generators treat content and motion generation separately,\nleading to unrealistic generated videos. Therefore, we design a novel framework\nto build the motion space, aiming to achieve content consistency and fast\nconvergence for video generation. We present MotionVideoGAN, a novel video\ngenerator synthesizing videos based on the motion space learned by pre-trained\nimage pair generators. Firstly, we propose an image pair generator named\nMotionStyleGAN to generate image pairs sharing the same contents and producing\nvarious motions. Then we manage to acquire motion codes to edit one image in\nthe generated image pairs and keep the other unchanged. The motion codes help\nus edit images within the motion space since the edited image shares the same\ncontents with the other unchanged one in image pairs. Finally, we introduce a\nlatent code generator to produce latent code sequences using motion codes for\nvideo generation. Our approach achieves state-of-the-art performance on the\nmost complex video dataset ever used for unconditional video generation\nevaluation, UCF101.\n","authors":["Jingyuan Zhu","Huimin Ma","Jiansheng Chen","Jian Yuan"],"pdf_url":"https://arxiv.org/pdf/2303.02906v1.pdf","comment":"Accepted by IEEE Transactions on Multimedia as a regular paper"},{"id":"http://arxiv.org/abs/2206.03452v2","updated":"2023-03-06T05:51:33Z","published":"2022-06-07T17:17:07Z","title":"Can CNNs Be More Robust Than Transformers?","summary":"  The recent success of Vision Transformers is shaking the long dominance of\nConvolutional Neural Networks (CNNs) in image recognition for a decade.\nSpecifically, in terms of robustness on out-of-distribution samples, recent\nresearch finds that Transformers are inherently more robust than CNNs,\nregardless of different training setups. Moreover, it is believed that such\nsuperiority of Transformers should largely be credited to their\nself-attention-like architectures per se. In this paper, we question that\nbelief by closely examining the design of Transformers. Our findings lead to\nthree highly effective architecture designs for boosting robustness, yet simple\nenough to be implemented in several lines of code, namely a) patchifying input\nimages, b) enlarging kernel size, and c) reducing activation layers and\nnormalization layers. Bringing these components together, we are able to build\npure CNN architectures without any attention-like operations that are as robust\nas, or even more robust than, Transformers. We hope this work can help the\ncommunity better understand the design of robust neural architectures. The code\nis publicly available at https://github.com/UCSC-VLAA/RobustCNN.\n","authors":["Zeyu Wang","Yutong Bai","Yuyin Zhou","Cihang Xie"],"pdf_url":"https://arxiv.org/pdf/2206.03452v2.pdf","comment":"ICLR2023. Code is available at https://github.com/UCSC-VLAA/RobustCNN"},{"id":"http://arxiv.org/abs/2210.15858v3","updated":"2023-03-06T05:00:57Z","published":"2022-10-28T02:56:47Z","title":"Vox-Fusion: Dense Tracking and Mapping with Voxel-based Neural Implicit\n  Representation","summary":"  In this work, we present a dense tracking and mapping system named\nVox-Fusion, which seamlessly fuses neural implicit representations with\ntraditional volumetric fusion methods. Our approach is inspired by the recently\ndeveloped implicit mapping and positioning system and further extends the idea\nso that it can be freely applied to practical scenarios. Specifically, we\nleverage a voxel-based neural implicit surface representation to encode and\noptimize the scene inside each voxel. Furthermore, we adopt an octree-based\nstructure to divide the scene and support dynamic expansion, enabling our\nsystem to track and map arbitrary scenes without knowing the environment like\nin previous works. Moreover, we proposed a high-performance multi-process\nframework to speed up the method, thus supporting some applications that\nrequire real-time performance. The evaluation results show that our methods can\nachieve better accuracy and completeness than previous methods. We also show\nthat our Vox-Fusion can be used in augmented reality and virtual reality\napplications. Our source code is publicly available at\nhttps://github.com/zju3dv/Vox-Fusion.\n","authors":["Xingrui Yang","Hai Li","Hongjia Zhai","Yuhang Ming","Yuqian Liu","Guofeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2210.15858v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.06323v3","updated":"2023-03-06T05:00:50Z","published":"2022-10-12T15:42:40Z","title":"AISFormer: Amodal Instance Segmentation with Transformer","summary":"  Amodal Instance Segmentation (AIS) aims to segment the region of both visible\nand possible occluded parts of an object instance. While Mask R-CNN-based AIS\napproaches have shown promising results, they are unable to model high-level\nfeatures coherence due to the limited receptive field. The most recent\ntransformer-based models show impressive performance on vision tasks, even\nbetter than Convolution Neural Networks (CNN). In this work, we present\nAISFormer, an AIS framework, with a Transformer-based mask head. AISFormer\nexplicitly models the complex coherence between occluder, visible, amodal, and\ninvisible masks within an object's regions of interest by treating them as\nlearnable queries. Specifically, AISFormer contains four modules: (i) feature\nencoding: extract ROI and learn both short-range and long-range visual\nfeatures. (ii) mask transformer decoding: generate the occluder, visible, and\namodal mask query embeddings by a transformer decoder (iii) invisible mask\nembedding: model the coherence between the amodal and visible masks, and (iv)\nmask predicting: estimate output masks including occluder, visible, amodal and\ninvisible. We conduct extensive experiments and ablation studies on three\nchallenging benchmarks i.e. KINS, D2SA, and COCOA-cls to evaluate the\neffectiveness of AISFormer. The code is available at:\nhttps://github.com/UARK-AICV/AISFormer\n","authors":["Minh Tran","Khoa Vo","Kashu Yamazaki","Arthur Fernandes","Michael Kidd","Ngan Le"],"pdf_url":"https://arxiv.org/pdf/2210.06323v3.pdf","comment":"Accepted to BMVC2022"},{"id":"http://arxiv.org/abs/2303.02885v1","updated":"2023-03-06T04:32:34Z","published":"2023-03-06T04:32:34Z","title":"Improving Transformer-based Image Matching by Cascaded Capturing\n  Spatially Informative Keypoints","summary":"  Learning robust local image feature matching is a fundamental low-level\nvision task, which has been widely explored in the past few years. Recently,\ndetector-free local feature matchers based on transformers have shown promising\nresults, which largely outperform pure Convolutional Neural Network (CNN) based\nones. But correlations produced by transformer-based methods are spatially\nlimited to the center of source views' coarse patches, because of the costly\nattention learning. In this work, we rethink this issue and find that such\nmatching formulation degrades pose estimation, especially for low-resolution\nimages. So we propose a transformer-based cascade matching model -- Cascade\nfeature Matching TRansformer (CasMTR), to efficiently learn dense feature\ncorrelations, which allows us to choose more reliable matching pairs for the\nrelative pose estimation. Instead of re-training a new detector, we use a\nsimple yet effective Non-Maximum Suppression (NMS) post-process to filter\nkeypoints through the confidence map, and largely improve the matching\nprecision. CasMTR achieves state-of-the-art performance in indoor and outdoor\npose estimation as well as visual localization. Moreover, thorough ablations\nshow the efficacy of the proposed components and techniques.\n","authors":["Chenjie Cao","Yanwei Fu"],"pdf_url":"https://arxiv.org/pdf/2303.02885v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02881v1","updated":"2023-03-06T04:17:29Z","published":"2023-03-06T04:17:29Z","title":"KBNet: Kernel Basis Network for Image Restoration","summary":"  How to aggregate spatial information plays an essential role in\nlearning-based image restoration. Most existing CNN-based networks adopt static\nconvolutional kernels to encode spatial information, which cannot aggregate\nspatial information adaptively. Recent transformer-based architectures achieve\nadaptive spatial aggregation. But they lack desirable inductive biases of\nconvolutions and require heavy computational costs. In this paper, we propose a\nkernel basis attention (KBA) module, which introduces learnable kernel bases to\nmodel representative image patterns for spatial information aggregation.\nDifferent kernel bases are trained to model different local structures. At each\nspatial location, they are linearly and adaptively fused by predicted\npixel-wise coefficients to obtain aggregation weights. Based on the KBA module,\nwe further design a multi-axis feature fusion (MFF) block to encode and fuse\nchannel-wise, spatial-invariant, and pixel-adaptive features for image\nrestoration. Our model, named kernel basis network (KBNet), achieves\nstate-of-the-art performances on more than ten benchmarks over image denoising,\nderaining, and deblurring tasks while requiring less computational cost than\nprevious SOTA methods.\n","authors":["Yi Zhang","Dasong Li","Xiaoyu Shi","Dailan He","Kangning Song","Xiaogang Wang","Hongwei Qin","Hongsheng Li"],"pdf_url":"https://arxiv.org/pdf/2303.02881v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02880v1","updated":"2023-03-06T04:15:29Z","published":"2023-03-06T04:15:29Z","title":"Spatiotemporal Capsule Neural Network for Vehicle Trajectory Prediction","summary":"  Through advancement of the Vehicle-to-Everything (V2X) network, road safety,\nenergy consumption, and traffic efficiency can be significantly improved. An\naccurate vehicle trajectory prediction benefits communication traffic\nmanagement and network resource allocation for the real-time application of the\nV2X network. Recurrent neural networks and their variants have been reported in\nrecent research to predict vehicle mobility. However, the spatial attribute of\nvehicle movement behavior has been overlooked, resulting in incomplete\ninformation utilization. To bridge this gap, we put forward for the first time\na hierarchical trajectory prediction structure using the capsule neural network\n(CapsNet) with three sequential components. First, the geographic information\nis transformed into a grid map presentation, describing vehicle mobility\ndistribution spatially and temporally. Second, CapsNet serves as the core model\nto embed local temporal and global spatial correlation through hierarchical\ncapsules. Finally, extensive experiments conducted on actual taxi mobility data\ncollected in Porto city (Portugal) and Singapore show that the proposed method\noutperforms the state-of-the-art methods.\n","authors":["Yan Qin","Yong Liang Guan","Chau Yuen"],"pdf_url":"https://arxiv.org/pdf/2303.02880v1.pdf","comment":"IEEE TVT has accepted this paper"},{"id":"http://arxiv.org/abs/2303.02879v1","updated":"2023-03-06T04:14:04Z","published":"2023-03-06T04:14:04Z","title":"A Review of Deep Learning-Powered Mesh Reconstruction Methods","summary":"  With the recent advances in hardware and rendering techniques, 3D models have\nemerged everywhere in our life. Yet creating 3D shapes is arduous and requires\nsignificant professional knowledge. Meanwhile, Deep learning has enabled\nhigh-quality 3D shape reconstruction from various sources, making it a viable\napproach to acquiring 3D shapes with minimal effort. Importantly, to be used in\ncommon 3D applications, the reconstructed shapes need to be represented as\npolygonal meshes, which is a challenge for neural networks due to the\nirregularity of mesh tessellations. In this survey, we provide a comprehensive\nreview of mesh reconstruction methods that are powered by machine learning. We\nfirst describe various representations for 3D shapes in the deep learning\ncontext. Then we review the development of 3D mesh reconstruction methods from\nvoxels, point clouds, single images, and multi-view images. Finally, we\nidentify several challenges in this field and propose potential future\ndirections.\n","authors":["Zhiqin Chen"],"pdf_url":"https://arxiv.org/pdf/2303.02879v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.10907v2","updated":"2023-03-06T03:54:48Z","published":"2022-09-22T10:29:17Z","title":"DRKF: Distilled Rotated Kernel Fusion for Efficient Rotation Invariant\n  Descriptors in Local Feature Matching","summary":"  The performance of local feature descriptors degrades in the presence of\nlarge rotation variations. To address this issue, we present an efficient\napproach to learning rotation invariant descriptors. Specifically, we propose\nRotated Kernel Fusion (RKF) which imposes rotations on each convolution kernel\nand improves the inherent nature of CNN. Since RKF can be processed by the\nsubsequent re-parameterization, no extra computational costs will be introduced\nin the inference stage. Moreover, we present Multi-oriented Feature Aggregation\n(MOFA) which ensembles features extracted from multiple rotated versions of\ninput images and can provide auxiliary information for the training of RKF by\nleveraging the knowledge distillation strategy. We refer to the distilled RKF\nmodel as DRKF. Besides the evaluation on a rotation-augmented version of the\npublic dataset HPatches, we also contribute a new dataset named DiverseBEV\nwhich consists of bird's eye view images with large viewpoint changes and\ncamera rotations. Extensive experiments show that our method can outperform\nother state-of-the-art techniques when exposed to large rotation variations.\n","authors":["Ranran Huang","Jiancheng Cai","Chao Li","Zhuoyuan Wu","Xinmin Liu","Zhenhua Chai"],"pdf_url":"https://arxiv.org/pdf/2209.10907v2.pdf","comment":"8 pages, 7 figures"},{"id":"http://arxiv.org/abs/2303.01904v2","updated":"2023-03-06T03:51:39Z","published":"2023-03-03T13:05:30Z","title":"EcoTTA: Memory-Efficient Continual Test-time Adaptation via\n  Self-distilled Regularization","summary":"  This paper presents a simple yet effective approach that improves continual\ntest-time adaptation (TTA) in a memory-efficient manner. TTA may primarily be\nconducted on edge devices with limited memory, so reducing memory is crucial\nbut has been overlooked in previous TTA studies. In addition, long-term\nadaptation often leads to catastrophic forgetting and error accumulation, which\nhinders applying TTA in real-world deployments. Our approach consists of two\ncomponents to address these issues. First, we present lightweight meta networks\nthat can adapt the frozen original networks to the target domain. This novel\narchitecture minimizes memory consumption by decreasing the size of\nintermediate activations required for backpropagation. Second, our novel\nself-distilled regularization controls the output of the meta networks not to\ndeviate significantly from the output of the frozen original networks, thereby\npreserving well-trained knowledge from the source domain. Without additional\nmemory, this regularization prevents error accumulation and catastrophic\nforgetting, resulting in stable performance even in long-term test-time\nadaptation. We demonstrate that our simple yet effective strategy outperforms\nother state-of-the-art methods on various benchmarks for image classification\nand semantic segmentation tasks. Notably, our proposed method with ResNet-50\nand WideResNet-40 takes 86% and 80% less memory than the recent\nstate-of-the-art method, CoTTA.\n","authors":["Junha Song","Jungsoo Lee","In So Kweon","Sungha Choi"],"pdf_url":"https://arxiv.org/pdf/2303.01904v2.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2303.02869v1","updated":"2023-03-06T03:37:43Z","published":"2023-03-06T03:37:43Z","title":"Enhancing Border Security and Countering Terrorism Through Computer\n  Vision: a Field of Artificial Intelligence","summary":"  Border security had been a persistent problem in international border\nespecially when it get to the issue of preventing illegal movement of weapons,\ncontraband, drugs, and combating issue of illegal or undocumented immigrant\nwhile at the same time ensuring that lawful trade, economic prosperity coupled\nwith national sovereignty across the border is maintained. In this research\nwork, we used open source computer vision (Open CV) and adaboost algorithm to\ndevelop a model which can detect a moving object a far off, classify it,\nautomatically snap full image and face of the individual separately, and then\nrun a background check on them against worldwide databases while making a\nprediction about an individual being a potential threat, intending immigrant,\npotential terrorists or extremist and then raise sound alarm. Our model can be\ndeployed on any camera device and be mounted at any international border. There\nare two stages involved, we first developed a model based on open CV computer\nvision algorithm, with the ability to detect human movement from afar, it will\nautomatically snap both the face and the full image of the person separately,\nand the second stage is the automatic triggering of background check against\nthe moving object. This ensures it check the moving object against several\ndatabases worldwide and is able to determine the admissibility of the person\nafar off. If the individual is inadmissible, it will automatically alert the\nborder officials with the image of the person and other details, and if the\nbypass the border officials, the system is able to detect and alert the\nauthority with his images and other details. All these operations will be done\nafar off by the AI powered camera before the individual reach the border\n","authors":["Tosin Ige","Abosede Kolade","Olukunle Kolade"],"pdf_url":"https://arxiv.org/pdf/2303.02869v1.pdf","comment":"10 pages, 8 figures, Conference publication"},{"id":"http://arxiv.org/abs/2303.02867v1","updated":"2023-03-06T03:36:06Z","published":"2023-03-06T03:36:06Z","title":"Dual Feedback Attention Framework via Boundary-Aware Auxiliary and\n  Progressive Semantic Optimization for Salient Object Detection in Optical\n  Remote Sensing Imagery","summary":"  Salient object detection in optical remote sensing image (ORSI-SOD) has\ngradually attracted attention thanks to the development of deep learning (DL)\nand salient object detection in natural scene image (NSI-SOD). However, NSI and\nORSI are different in many aspects, such as large coverage, complex background,\nand large differences in target types and scales. Therefore, a new dedicated\nmethod is needed for ORSI-SOD. In addition, existing methods do not pay\nsufficient attention to the boundary of the object, and the completeness of the\nfinal saliency map still needs improvement. To address these issues, we propose\na novel method called Dual Feedback Attention Framework via Boundary-Aware\nAuxiliary and Progressive Semantic Optimization (DFA-BASO). First, Boundary\nProtection Calibration (BPC) module is proposed to reduce the loss of edge\nposition information during forward propagation and suppress noise in low-level\nfeatures. Second, a Dual Feature Feedback Complementary (DFFC) module is\nproposed based on BPC module. It aggregates boundary-semantic dual features and\nprovides effective feedback to coordinate features across different layers.\nFinally, a Strong Semantic Feedback Refinement (SSFR) module is proposed to\nobtain more complete saliency maps. This module further refines feature\nrepresentation and eliminates feature differences through a unique feedback\nmechanism. Extensive experiments on two public datasets show that DFA-BASO\noutperforms 15 state-of-the-art methods. Furthermore, this paper strongly\ndemonstrates the true contribution of DFA-BASO to ORSI-SOD by in-depth analysis\nof the visualization figure. All codes can be found at\nhttps://github.com/YUHsss/DFA-BASO.\n","authors":["Dejun Feng","Hongyu Chen","Suning Liu","Xingyu Shen","Ziyang Liao","Yakun Xie","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2303.02867v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02862v1","updated":"2023-03-06T03:27:17Z","published":"2023-03-06T03:27:17Z","title":"EvHandPose: Event-based 3D Hand Pose Estimation with Sparse Supervision","summary":"  Event camera shows great potential in 3D hand pose estimation, especially\naddressing the challenges of fast motion and high dynamic range in a low-power\nway. However, due to the asynchronous differential imaging mechanism, it is\nchallenging to design event representation to encode hand motion information\nespecially when the hands are not moving (causing motion ambiguity), and it is\ninfeasible to fully annotate the temporally dense event stream. In this paper,\nwe propose EvHandPose with novel hand flow representations in Event-to-Pose\nmodule for accurate hand pose estimation and alleviating the motion ambiguity\nissue. To solve the problem under sparse annotation, we design contrast\nmaximization and edge constraints in Pose-to-IWE (Image with Warped Events)\nmodule and formulate EvHandPose in a self-supervision framework. We further\nbuild EvRealHands, the first large-scale real-world event-based hand pose\ndataset on several challenging scenes to bridge the domain gap due to relying\non synthetic data and facilitate future research. Experiments on EvRealHands\ndemonstrate that EvHandPose outperforms previous event-based method under all\nevaluation scenes with 15 $\\sim$ 20 mm lower MPJPE and achieves accurate and\nstable hand pose estimation in fast motion and strong light scenes compared\nwith RGB-based methods. Furthermore, EvHandPose demonstrates 3D hand pose\nestimation at 120 fps or higher.\n","authors":["Jianping Jiang","Jiahe Li","Baowen Zhang","Xiaoming Deng","Boxin Shi"],"pdf_url":"https://arxiv.org/pdf/2303.02862v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02110v2","updated":"2023-03-06T03:26:43Z","published":"2023-03-03T17:51:08Z","title":"Need for Objective Task-based Evaluation of Deep Learning-Based\n  Denoising Methods: A Study in the Context of Myocardial Perfusion SPECT","summary":"  Artificial intelligence-based methods have generated substantial interest in\nnuclear medicine. An area of significant interest has been using deep-learning\n(DL)-based approaches for denoising images acquired with lower doses, shorter\nacquisition times, or both. Objective evaluation of these approaches is\nessential for clinical application. DL-based approaches for denoising\nnuclear-medicine images have typically been evaluated using fidelity-based\nfigures of merit (FoMs) such as RMSE and SSIM. However, these images are\nacquired for clinical tasks and thus should be evaluated based on their\nperformance in these tasks. Our objectives were to (1) investigate whether\nevaluation with these FoMs is consistent with objective clinical-task-based\nevaluation; (2) provide a theoretical analysis for determining the impact of\ndenoising on signal-detection tasks; (3) demonstrate the utility of virtual\nclinical trials (VCTs) to evaluate DL-based methods. A VCT to evaluate a\nDL-based method for denoising myocardial perfusion SPECT (MPS) images was\nconducted. The impact of DL-based denoising was evaluated using fidelity-based\nFoMs and AUC, which quantified performance on detecting perfusion defects in\nMPS images as obtained using a model observer with anthropomorphic channels.\nBased on fidelity-based FoMs, denoising using the considered DL-based method\nled to significantly superior performance. However, based on ROC analysis,\ndenoising did not improve, and in fact, often degraded detection-task\nperformance. The results motivate the need for objective task-based evaluation\nof DL-based denoising approaches. Further, this study shows how VCTs provide a\nmechanism to conduct such evaluations using VCTs. Finally, our theoretical\ntreatment reveals insights into the reasons for the limited performance of the\ndenoising approach.\n","authors":["Zitong Yu","Md Ashequr Rahman","Richard Laforest","Thomas H. Schindler","Robert J. Gropler","Richard L. Wahl","Barry A. Siegel","Abhinav K. Jha"],"pdf_url":"https://arxiv.org/pdf/2303.02110v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02857v1","updated":"2023-03-06T03:17:48Z","published":"2023-03-06T03:17:48Z","title":"Weakly Supervised Realtime Dynamic Background Subtraction","summary":"  Background subtraction is a fundamental task in computer vision with numerous\nreal-world applications, ranging from object tracking to video surveillance.\nDynamic backgrounds poses a significant challenge here. Supervised deep\nlearning-based techniques are currently considered state-of-the-art for this\ntask. However, these methods require pixel-wise ground-truth labels, which can\nbe time-consuming and expensive. In this work, we propose a weakly supervised\nframework that can perform background subtraction without requiring per-pixel\nground-truth labels. Our framework is trained on a moving object-free sequence\nof images and comprises two networks. The first network is an autoencoder that\ngenerates background images and prepares dynamic background images for training\nthe second network. The dynamic background images are obtained by thresholding\nthe background-subtracted images. The second network is a U-Net that uses the\nsame object-free video for training and the dynamic background images as\npixel-wise ground-truth labels. During the test phase, the input images are\nprocessed by the autoencoder and U-Net, which generate background and dynamic\nbackground images, respectively. The dynamic background image helps remove\ndynamic motion from the background-subtracted image, enabling us to obtain a\nforeground image that is free of dynamic artifacts. To demonstrate the\neffectiveness of our method, we conducted experiments on selected categories of\nthe CDnet 2014 dataset and the I2R dataset. Our method outperformed all\ntop-ranked unsupervised methods. We also achieved better results than one of\nthe two existing weakly supervised methods, and our performance was similar to\nthe other. Our proposed method is online, real-time, efficient, and requires\nminimal frame-level annotation, making it suitable for a wide range of\nreal-world applications.\n","authors":["Fateme Bahri","Nilanjan Ray"],"pdf_url":"https://arxiv.org/pdf/2303.02857v1.pdf","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2205.07062v2","updated":"2023-03-06T03:00:48Z","published":"2022-05-14T13:36:27Z","title":"An Interpretable MRI Reconstruction Network with Two-grid-cycle\n  Correction and Geometric Prior Distillation","summary":"  Although existing deep learning compressed-sensing-based Magnetic Resonance\nImaging (CS-MRI) methods have achieved considerably impressive performance,\nexplainability and generalizability continue to be challenging for such methods\nsince the transition from mathematical analysis to network design not always\nnatural enough, often most of them are not flexible enough to handle\nmulti-sampling-ratio reconstruction assignments. {In this work, to tackle\nexplainability and generalizability, we propose a unifying deep unfolding\nmulti-sampling-ratio interpretable CS-MRI framework.} The combined approach\noffers more generalizability than previous works whereas deep learning gains\nexplainability through a geometric prior module. Inspired by the multigrid\nalgorithm, we first embed the CS-MRI-based optimization algorithm into\ncorrection-distillation scheme that consists of three ingredients:\npre-relaxation module, correction module and geometric prior distillation\nmodule. Furthermore, we employ a condition module to learn adaptively\nstep-length and noise level, which enables the proposed framework to jointly\ntrain multi-ratio tasks through a single model. { The proposed model not only\ncompensates for the lost contextual information of reconstructed image which is\nrefined from low frequency error in geometric characteristic k-space}, but also\nintegrates the theoretical guarantee of model-based methods and the superior\nreconstruction performances of deep learning-based methods. Therefore, it can\ngive us a novel perspective to design biomedical imaging networks. { Numerical\nexperiments show that our framework outperforms state-of-the-art methods in\nterms of qualitative and quantitative evaluations.} {Our method achieves 3.18\ndB improvement at low CS ratio 10\\% and average 1.42 dB improvement over other\ncomparison methods on brain dataset using Cartesian sampling mask.\n","authors":["Xiaohong Fan","Yin Yang","Ke Chen","Jianping Zhang","Ke Dong"],"pdf_url":"https://arxiv.org/pdf/2205.07062v2.pdf","comment":"14 pages, accepted to Biomedical Signal Processing and Control,March,\n  2023"},{"id":"http://arxiv.org/abs/2301.01970v3","updated":"2023-03-06T02:55:57Z","published":"2023-01-05T09:11:16Z","title":"CAT: LoCalization and IdentificAtion Cascade Detection Transformer for\n  Open-World Object Detection","summary":"  Open-world object detection (OWOD), as a more general and challenging goal,\nrequires the model trained from data on known objects to detect both known and\nunknown objects and incrementally learn to identify these unknown objects. The\nexisting works which employ standard detection framework and fixed\npseudo-labelling mechanism (PLM) have the following problems: (i) The inclusion\nof detecting unknown objects substantially reduces the model's ability to\ndetect known ones. (ii) The PLM does not adequately utilize the priori\nknowledge of inputs. (iii) The fixed selection manner of PLM cannot guarantee\nthat the model is trained in the right direction. We observe that humans\nsubconsciously prefer to focus on all foreground objects and then identify each\none in detail, rather than localize and identify a single object\nsimultaneously, for alleviating the confusion. This motivates us to propose a\nnovel solution called CAT: LoCalization and IdentificAtion Cascade Detection\nTransformer which decouples the detection process via the shared decoder in the\ncascade decoding way. In the meanwhile, we propose the self-adaptive\npseudo-labelling mechanism which combines the model-driven with input-driven\nPLM and self-adaptively generates robust pseudo-labels for unknown objects,\nsignificantly improving the ability of CAT to retrieve unknown objects.\nComprehensive experiments on two benchmark datasets, i.e., MS-COCO and PASCAL\nVOC, show that our model outperforms the state-of-the-art in terms of all\nmetrics in the task of OWOD, incremental object detection (IOD) and open-set\ndetection.\n","authors":["Shuailei Ma","Yuefeng Wang","Jiaqi Fan","Ying Wei","Thomas H. Li","Hongli Liu","Fanbing Lv"],"pdf_url":"https://arxiv.org/pdf/2301.01970v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.05631v2","updated":"2023-03-06T02:31:54Z","published":"2022-11-02T15:39:19Z","title":"Backdoor Defense via Suppressing Model Shortcuts","summary":"  Recent studies have demonstrated that deep neural networks (DNNs) are\nvulnerable to backdoor attacks during the training process. Specifically, the\nadversaries intend to embed hidden backdoors in DNNs so that malicious model\npredictions can be activated through pre-defined trigger patterns. In this\npaper, we explore the backdoor mechanism from the angle of the model structure.\nWe select the skip connection for discussions, inspired by the understanding\nthat it helps the learning of model `shortcuts' where backdoor triggers are\nusually easier to be learned. Specifically, we demonstrate that the attack\nsuccess rate (ASR) decreases significantly when reducing the outputs of some\nkey skip connections. Based on this observation, we design a simple yet\neffective backdoor removal method by suppressing the skip connections in\ncritical layers selected by our method. We also implement fine-tuning on these\nlayers to recover high benign accuracy and to further reduce ASR. Extensive\nexperiments on benchmark datasets verify the effectiveness of our method.\n","authors":["Sheng Yang","Yiming Li","Yong Jiang","Shu-Tao Xia"],"pdf_url":"https://arxiv.org/pdf/2211.05631v2.pdf","comment":"This paper is accepted by ICASSP 2023. 5 pages"},{"id":"http://arxiv.org/abs/2211.01806v2","updated":"2023-03-06T02:26:40Z","published":"2022-11-02T16:03:43Z","title":"BATT: Backdoor Attack with Transformation-based Triggers","summary":"  Deep neural networks (DNNs) are vulnerable to backdoor attacks. The backdoor\nadversaries intend to maliciously control the predictions of attacked DNNs by\ninjecting hidden backdoors that can be activated by adversary-specified trigger\npatterns during the training process. One recent research revealed that most of\nthe existing attacks failed in the real physical world since the trigger\ncontained in the digitized test samples may be different from that of the one\nused for training. Accordingly, users can adopt spatial transformations as the\nimage pre-processing to deactivate hidden backdoors. In this paper, we explore\nthe previous findings from another side. We exploit classical spatial\ntransformations (i.e. rotation and translation) with the specific parameter as\ntrigger patterns to design a simple yet effective poisoning-based backdoor\nattack. For example, only images rotated to a particular angle can activate the\nembedded backdoor of attacked DNNs. Extensive experiments are conducted,\nverifying the effectiveness of our attack under both digital and physical\nsettings and its resistance to existing backdoor defenses.\n","authors":["Tong Xu","Yiming Li","Yong Jiang","Shu-Tao Xia"],"pdf_url":"https://arxiv.org/pdf/2211.01806v2.pdf","comment":"This paper is accepted by ICASSP 2023. 5 pages"},{"id":"http://arxiv.org/abs/2211.05638v2","updated":"2023-03-06T02:20:32Z","published":"2022-11-02T17:05:45Z","title":"Untargeted Backdoor Attack against Object Detection","summary":"  Recent studies revealed that deep neural networks (DNNs) are exposed to\nbackdoor threats when training with third-party resources (such as training\nsamples or backbones). The backdoored model has promising performance in\npredicting benign samples, whereas its predictions can be maliciously\nmanipulated by adversaries based on activating its backdoors with pre-defined\ntrigger patterns. Currently, most of the existing backdoor attacks were\nconducted on the image classification under the targeted manner. In this paper,\nwe reveal that these threats could also happen in object detection, posing\nthreatening risks to many mission-critical applications ($e.g.$, pedestrian\ndetection and intelligent surveillance systems). Specifically, we design a\nsimple yet effective poison-only backdoor attack in an untargeted manner, based\non task characteristics. We show that, once the backdoor is embedded into the\ntarget model by our attack, it can trick the model to lose detection of any\nobject stamped with our trigger patterns. We conduct extensive experiments on\nthe benchmark dataset, showing its effectiveness in both digital and\nphysical-world settings and its resistance to potential defenses.\n","authors":["Chengxiao Luo","Yiming Li","Yong Jiang","Shu-Tao Xia"],"pdf_url":"https://arxiv.org/pdf/2211.05638v2.pdf","comment":"This paper is accepted by ICASSP 2023. 5 pages"},{"id":"http://arxiv.org/abs/2303.01869v2","updated":"2023-03-06T02:15:57Z","published":"2023-03-03T11:52:21Z","title":"Intrinsic Physical Concepts Discovery with Object-Centric Predictive\n  Models","summary":"  The ability to discover abstract physical concepts and understand how they\nwork in the world through observing lies at the core of human intelligence. The\nacquisition of this ability is based on compositionally perceiving the\nenvironment in terms of objects and relations in an unsupervised manner. Recent\napproaches learn object-centric representations and capture visually observable\nconcepts of objects, e.g., shape, size, and location. In this paper, we take a\nstep forward and try to discover and represent intrinsic physical concepts such\nas mass and charge. We introduce the PHYsical Concepts Inference NEtwork\n(PHYCINE), a system that infers physical concepts in different abstract levels\nwithout supervision. The key insights underlining PHYCINE are two-fold,\ncommonsense knowledge emerges with prediction, and physical concepts of\ndifferent abstract levels should be reasoned in a bottom-up fashion. Empirical\nevaluation demonstrates that variables inferred by our system work in\naccordance with the properties of the corresponding physical concepts. We also\nshow that object representations containing the discovered physical concepts\nvariables could help achieve better performance in causal reasoning tasks,\ni.e., ComPhy.\n","authors":["Qu Tang","XiangYu Zhu","Zhen Lei","ZhaoXiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.01869v2.pdf","comment":"Accepted to Computer Vision and Pattern Recognition (CVPR)2023"},{"id":"http://arxiv.org/abs/2303.02835v1","updated":"2023-03-06T02:05:14Z","published":"2023-03-06T02:05:14Z","title":"Traffic Scene Parsing through the TSP6K Dataset","summary":"  Traffic scene parsing is one of the most important tasks to achieve\nintelligent cities. So far, little effort has been spent on constructing\ndatasets specifically for the task of traffic scene parsing. To fill this gap,\nhere we introduce the TSP6K dataset, containing 6,000 urban traffic images and\nspanning hundreds of street scenes under various weather conditions. In\ncontrast to most previous traffic scene datasets collected from a driving\nplatform, the images in our dataset are from the shooting platform high-hanging\non the street. Such traffic images can capture more crowded street scenes with\nseveral times more traffic participants than the driving scenes. Each image in\nthe TSP6K dataset is provided with high-quality pixel-level and instance-level\nannotations. We perform a detailed analysis for the dataset and comprehensively\nevaluate the state-of-the-art scene parsing methods. Considering the vast\ndifference in instance sizes, we propose a detail refining decoder, which\nrecovers the details of different semantic regions in traffic scenes.\nExperiments have shown its effectiveness in parsing high-hanging traffic\nscenes. Code and dataset will be made publicly available.\n","authors":["Peng-Tao Jiang","Yuqi Yang","Yang Cao","Qibin Hou","Ming-Ming Cheng","Chunhua Shen"],"pdf_url":"https://arxiv.org/pdf/2303.02835v1.pdf","comment":"11 pages, 7 figures"},{"id":"http://arxiv.org/abs/2209.08723v2","updated":"2023-03-06T02:00:56Z","published":"2022-09-19T02:47:48Z","title":"Ensembles of Compact, Region-specific & Regularized Spiking Neural\n  Networks for Scalable Place Recognition","summary":"  Spiking neural networks have significant potential utility in robotics due to\ntheir high energy efficiency on specialized hardware, but proof-of-concept\nimplementations have not yet typically achieved competitive performance or\ncapability with conventional approaches. In this paper, we tackle one of the\nkey practical challenges of scalability by introducing a novel modular ensemble\nnetwork approach, where compact, localized spiking networks each learn and are\nsolely responsible for recognizing places in a local region of the environment\nonly. This modular approach creates a highly scalable system. However, it comes\nwith a high-performance cost where a lack of global regularization at\ndeployment time leads to hyperactive neurons that erroneously respond to places\noutside their learned region. Our second contribution introduces a\nregularization approach that detects and removes these problematic hyperactive\nneurons during the initial environmental learning phase. We evaluate this new\nscalable modular system on benchmark localization datasets Nordland and Oxford\nRobotCar, with comparisons to standard techniques NetVLAD, DenseVLAD, and SAD,\nand a previous spiking neural network system. Our system substantially\noutperforms the previous SNN system on its small dataset, but also maintains\nperformance on 27 times larger benchmark datasets where the operation of the\nprevious system is computationally infeasible, and performs competitively with\nthe conventional localization systems.\n","authors":["Somayeh Hussaini","Michael Milford","Tobias Fischer"],"pdf_url":"https://arxiv.org/pdf/2209.08723v2.pdf","comment":"8 pages, 6 figures, accepted to the IEEE International Conference on\n  Robotics and Automation (ICRA) 2023"},{"id":"http://arxiv.org/abs/2303.01894v2","updated":"2023-03-06T01:49:30Z","published":"2023-03-03T12:47:30Z","title":"T360RRD: A dataset for 360 degree rotated rectangular box table\n  detection","summary":"  To address the problem of scarcity and high annotation costs of rotated image\ntable detection datasets, this paper proposes a method for building a rotated\nimage table detection dataset. Based on the ICDAR2019MTD modern table detection\ndataset, we refer to the annotation format of the DOTA dataset to create the\nTRR360D rotated table detection dataset. The training set contains 600 rotated\nimages and 977 annotated instances, and the test set contains 240 rotated\nimages and 499 annotated instances. The AP50(T<90) evaluation metric is\ndefined, and this dataset is available for future researchers to study rotated\ntable detection algorithms and promote the development of table detection\ntechnology. The TRR360D rotated table detection dataset was created by\nconstraining the starting point and annotation direction, and is publicly\navailable at https://github.com/vansin/TRR360D.\n","authors":["Wenxing Hu","Minglei Tong"],"pdf_url":"https://arxiv.org/pdf/2303.01894v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02828v1","updated":"2023-03-06T01:45:32Z","published":"2023-03-06T01:45:32Z","title":"Robust Autoencoders for Collective Corruption Removal","summary":"  Robust PCA is a standard tool for learning a linear subspace in the presence\nof sparse corruption or rare outliers. What about robustly learning manifolds\nthat are more realistic models for natural data, such as images? There have\nbeen several recent attempts to generalize robust PCA to manifold settings. In\nthis paper, we propose $\\ell_1$- and scaling-invariant $\\ell_1/\\ell_2$-robust\nautoencoders based on a surprisingly compact formulation built on the intuition\nthat deep autoencoders perform manifold learning. We demonstrate on several\nstandard image datasets that the proposed formulation significantly outperforms\nall previous methods in collectively removing sparse corruption, without clean\nimages for training. Moreover, we also show that the learned manifold\nstructures can be generalized to unseen data samples effectively.\n","authors":["Taihui Li","Hengkang Wang","Peng Le","XianE Tang","Ju Sun"],"pdf_url":"https://arxiv.org/pdf/2303.02828v1.pdf","comment":"This paper has been accepted to ICASSP2023"},{"id":"http://arxiv.org/abs/2211.07740v3","updated":"2023-03-06T01:35:21Z","published":"2022-11-14T20:35:11Z","title":"Denoising diffusion models for out-of-distribution detection","summary":"  Out-of-distribution detection is crucial to the safe deployment of machine\nlearning systems. Currently, unsupervised out-of-distribution detection is\ndominated by generative-based approaches that make use of estimates of the\nlikelihood or other measurements from a generative model. Reconstruction-based\nmethods offer an alternative approach, in which a measure of reconstruction\nerror is used to determine if a sample is out-of-distribution. However,\nreconstruction-based approaches are less favoured, as they require careful\ntuning of the model's information bottleneck - such as the size of the latent\ndimension - to produce good results. In this work, we exploit the view of\ndenoising diffusion probabilistic models (DDPM) as denoising autoencoders where\nthe bottleneck is controlled externally, by means of the amount of noise\napplied. We propose to use DDPMs to reconstruct an input that has been noised\nto a range of noise levels, and use the resulting multi-dimensional\nreconstruction error to classify out-of-distribution inputs. We validate our\napproach both on standard computer-vision datasets and on higher dimension\nmedical datasets. Our approach outperforms not only reconstruction-based\nmethods, but also state-of-the-art generative-based approaches.\n","authors":["Mark S. Graham","Walter H. L. Pinaya","Petru-Daniel Tudosiu","Parashkev Nachev","Sebastien Ourselin","M. Jorge Cardoso"],"pdf_url":"https://arxiv.org/pdf/2211.07740v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02814v1","updated":"2023-03-06T01:01:56Z","published":"2023-03-06T01:01:56Z","title":"Visual Analytics of Neuron Vulnerability to Adversarial Attacks on\n  Convolutional Neural Networks","summary":"  Adversarial attacks on a convolutional neural network (CNN) -- injecting\nhuman-imperceptible perturbations into an input image -- could fool a\nhigh-performance CNN into making incorrect predictions. The success of\nadversarial attacks raises serious concerns about the robustness of CNNs, and\nprevents them from being used in safety-critical applications, such as medical\ndiagnosis and autonomous driving. Our work introduces a visual analytics\napproach to understanding adversarial attacks by answering two questions: (1)\nwhich neurons are more vulnerable to attacks and (2) which image features do\nthese vulnerable neurons capture during the prediction? For the first question,\nwe introduce multiple perturbation-based measures to break down the attacking\nmagnitude into individual CNN neurons and rank the neurons by their\nvulnerability levels. For the second, we identify image features (e.g., cat\nears) that highly stimulate a user-selected neuron to augment and validate the\nneuron's responsibility. Furthermore, we support an interactive exploration of\na large number of neurons by aiding with hierarchical clustering based on the\nneurons' roles in the prediction. To this end, a visual analytics system is\ndesigned to incorporate visual reasoning for interpreting adversarial attacks.\nWe validate the effectiveness of our system through multiple case studies as\nwell as feedback from domain experts.\n","authors":["Yiran Li","Junpeng Wang","Takanori Fujiwara","Kwan-Liu Ma"],"pdf_url":"https://arxiv.org/pdf/2303.02814v1.pdf","comment":"Accepted by the Special Issue on Human-Centered Explainable AI, ACM\n  Transactions on Interactive Intelligent Systems"},{"id":"http://arxiv.org/abs/2102.04615v2","updated":"2023-03-06T00:29:14Z","published":"2021-02-09T02:50:29Z","title":"Benford's law: what does it say on adversarial images?","summary":"  Convolutional neural networks (CNNs) are fragile to small perturbations in\nthe input images. These networks are thus prone to malicious attacks that\nperturb the inputs to force a misclassification. Such slightly manipulated\nimages aimed at deceiving the classifier are known as adversarial images. In\nthis work, we investigate statistical differences between natural images and\nadversarial ones. More precisely, we show that employing a proper image\ntransformation and for a class of adversarial attacks, the distribution of the\nleading digit of the pixels in adversarial images deviates from Benford's law.\nThe stronger the attack, the more distant the resulting distribution is from\nBenford's law. Our analysis provides a detailed investigation of this new\napproach that can serve as a basis for alternative adversarial example\ndetection methods that do not need to modify the original CNN classifier\nneither work on the raw high-dimensional pixels as features to defend against\nattacks.\n","authors":["João G. Zago","Fabio L. Baldissera","Eric A. Antonelo","Rodrigo T. Saad"],"pdf_url":"https://arxiv.org/pdf/2102.04615v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.04220v3","updated":"2023-03-06T00:22:57Z","published":"2022-07-09T08:01:11Z","title":"Rethinking Persistent Homology for Visual Recognition","summary":"  Persistent topological properties of an image serve as an additional\ndescriptor providing an insight that might not be discovered by traditional\nneural networks. The existing research in this area focuses primarily on\nefficiently integrating topological properties of the data in the learning\nprocess in order to enhance the performance. However, there is no existing\nstudy to demonstrate all possible scenarios where introducing topological\nproperties can boost or harm the performance. This paper performs a detailed\nanalysis of the effectiveness of topological properties for image\nclassification in various training scenarios, defined by: the number of\ntraining samples, the complexity of the training data and the complexity of the\nbackbone network. We identify the scenarios that benefit the most from\ntopological features, e.g., training simple networks on small datasets.\nAdditionally, we discuss the problem of topological consistency of the datasets\nwhich is one of the major bottlenecks for using topological features for\nclassification. We further demonstrate how the topological inconsistency can\nharm the performance for certain scenarios.\n","authors":["Ekaterina Khramtsova","Guido Zuccon","Xi Wang","Mahsa Baktashmotlagh"],"pdf_url":"https://arxiv.org/pdf/2207.04220v3.pdf","comment":"ICML 2022 Workshop on Topology, Algebra, and Geometry in Machine\n  Learning"},{"id":"http://arxiv.org/abs/2303.03555v1","updated":"2023-03-06T23:50:24Z","published":"2023-03-06T23:50:24Z","title":"Hyperspectral Compressive Wavefront Sensing","summary":"  Presented is a novel way to combine snapshot compressive imaging and lateral\nshearing interferometry in order to capture the spatio-spectral phase of an\nultrashort laser pulse in a single shot. A deep unrolling algorithm is utilised\nfor the snapshot compressive imaging reconstruction due to its parameter\nefficiency and superior speed relative to other methods, potentially allowing\nfor online reconstruction. The algorithm's regularisation term is represented\nusing neural network with 3D convolutional layers, to exploit the\nspatio-spectral correlations that exist in laser wavefronts. Compressed sensing\nis not typically applied to modulated signals, but we demonstrate its success\nhere. Furthermore, we train a neural network to predict the wavefronts from a\nlateral shearing interferogram in terms of Zernike polynomials, which again\nincreases the speed of our technique without sacrificing fidelity. This method\nis supported with simulation-based results. While applied to the example of\nlateral shearing interferometry, the methods presented here are generally\napplicable to a wide range of signals, including Shack-Hartmann-type sensors.\nThe results may be of interest beyond the context of laser wavefront\ncharacterization, including within quantitative phase imaging.\n","authors":["Sunny Howard","Jannik Esslinger","Robin H. W. Wang","Peter Norreys","Andreas Doepp"],"pdf_url":"https://arxiv.org/pdf/2303.03555v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.00182v3","updated":"2023-03-06T23:30:28Z","published":"2022-02-01T02:06:54Z","title":"Semi-supervised 3D Object Detection via Temporal Graph Neural Networks","summary":"  3D object detection plays an important role in autonomous driving and other\nrobotics applications. However, these detectors usually require training on\nlarge amounts of annotated data that is expensive and time-consuming to\ncollect. Instead, we propose leveraging large amounts of unlabeled point cloud\nvideos by semi-supervised learning of 3D object detectors via temporal graph\nneural networks. Our insight is that temporal smoothing can create more\naccurate detection results on unlabeled data, and these smoothed detections can\nthen be used to retrain the detector. We learn to perform this temporal\nreasoning with a graph neural network, where edges represent the relationship\nbetween candidate detections in different time frames. After semi-supervised\nlearning, our method achieves state-of-the-art detection performance on the\nchallenging nuScenes and H3D benchmarks, compared to baselines trained on the\nsame amount of labeled data. Project and code are released at\nhttps://www.jianrenw.com/SOD-TGNN/.\n","authors":["Jianren Wang","Haiming Gang","Siddharth Ancha","Yi-Ting Chen","David Held"],"pdf_url":"https://arxiv.org/pdf/2202.00182v3.pdf","comment":"3DV 2021"},{"id":"http://arxiv.org/abs/2209.14860v2","updated":"2023-03-06T23:19:17Z","published":"2022-09-29T15:24:47Z","title":"Bridging the Gap to Real-World Object-Centric Learning","summary":"  Humans naturally decompose their environment into entities at the appropriate\nlevel of abstraction to act in the world. Allowing machine learning algorithms\nto derive this decomposition in an unsupervised way has become an important\nline of research. However, current methods are restricted to simulated data or\nrequire additional information in the form of motion or depth in order to\nsuccessfully discover objects. In this work, we overcome this limitation by\nshowing that reconstructing features from models trained in a self-supervised\nmanner is a sufficient training signal for object-centric representations to\narise in a fully unsupervised way. Our approach, DINOSAUR, significantly\nout-performs existing image-based object-centric learning models on simulated\ndata and is the first unsupervised object-centric model that scales to\nreal-world datasets such as COCO and PASCAL VOC. DINOSAUR is conceptually\nsimple and shows competitive performance compared to more involved pipelines\nfrom the computer vision literature.\n","authors":["Maximilian Seitzer","Max Horn","Andrii Zadaianchuk","Dominik Zietlow","Tianjun Xiao","Carl-Johann Simon-Gabriel","Tong He","Zheng Zhang","Bernhard Schölkopf","Thomas Brox","Francesco Locatello"],"pdf_url":"https://arxiv.org/pdf/2209.14860v2.pdf","comment":"ICLR 2023 camera-ready version"},{"id":"http://arxiv.org/abs/2303.03508v1","updated":"2023-03-06T21:29:45Z","published":"2023-03-06T21:29:45Z","title":"Memory Maps for Video Object Detection and Tracking on UAVs","summary":"  This paper introduces a novel approach to video object detection detection\nand tracking on Unmanned Aerial Vehicles (UAVs). By incorporating metadata, the\nproposed approach creates a memory map of object locations in actual world\ncoordinates, providing a more robust and interpretable representation of object\nlocations in both, image space and the real world. We use this representation\nto boost confidences, resulting in improved performance for several temporal\ncomputer vision tasks, such as video object detection, short and long-term\nsingle and multi-object tracking, and video anomaly detection. These findings\nconfirm the benefits of metadata in enhancing the capabilities of UAVs in the\nfield of temporal computer vision and pave the way for further advancements in\nthis area.\n","authors":["Benjamin Kiefer","Yitong Quan","Andreas Zell"],"pdf_url":"https://arxiv.org/pdf/2303.03508v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.12458v3","updated":"2023-03-06T21:26:26Z","published":"2022-06-24T18:30:26Z","title":"Bag of Tricks for Long-Tail Visual Recognition of Animal Species in\n  Camera-Trap Images","summary":"  Camera traps are a method for monitoring wildlife and they collect a large\nnumber of pictures. The number of images collected of each species usually\nfollows a long-tail distribution, i.e., a few classes have a large number of\ninstances, while a lot of species have just a small percentage. Although in\nmost cases these rare species are the ones of interest to ecologists, they are\noften neglected when using deep-learning models because these models require a\nlarge number of images for the training. In this work, a simple and effective\nframework called Square-Root Sampling Branch (SSB) is proposed, which combines\ntwo classification branches that are trained using square-root sampling and\ninstance sampling to improve long-tail visual recognition, and this is compared\nto state-of-the-art methods for handling this task: square-root sampling,\nclass-balanced focal loss, and balanced group softmax. To achieve a more\ngeneral conclusion, the methods for handling long-tail visual recognition were\nsystematically evaluated in four families of computer vision models (ResNet,\nMobileNetV3, EfficientNetV2, and Swin Transformer) and four camera-trap\ndatasets with different characteristics. Initially, a robust baseline with the\nmost recent training tricks was prepared and, then, the methods for improving\nlong-tail recognition were applied. Our experiments show that square-root\nsampling was the method that most improved the performance for minority classes\nby around 15%; however, this was at the cost of reducing the majority classes'\naccuracy by at least 3%. Our proposed framework (SSB) demonstrated itself to be\ncompetitive with the other methods and achieved the best or the second-best\nresults for most of the cases for the tail classes; but, unlike the square-root\nsampling, the loss in the performance of the head classes was minimal, thus\nachieving the best trade-off among all the evaluated methods.\n","authors":["Fagner Cunha","Eulanda M. dos Santos","Juan G. Colonna"],"pdf_url":"https://arxiv.org/pdf/2206.12458v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.01565v4","updated":"2023-03-06T21:16:01Z","published":"2022-01-05T12:10:42Z","title":"User Evaluation of Culture-to-Culture Image Translation with Generative\n  Adversarial Nets","summary":"  The article introduces the concept of image ``culturization,\" i.e., defined\nas the process of altering the ``brushstroke of cultural features\" that make\nobjects perceived as belonging to a given culture while preserving their\nfunctionalities. First, we defined a pipeline for translating objects' images\nfrom a source to a target cultural domain based on state-of-the-art Generative\nAdversarial Networks. Then, we gathered data through an online questionnaire to\ntest four hypotheses concerning the impact of images belonging to different\ncultural domains on Italian participants. As expected, results depend on\nindividual tastes and preferences: however, they align with our conjecture that\nsome people, during the interaction with an intelligent system, will prefer to\nbe shown images modified to match their cultural background.\n","authors":["Giulia Zaino","Carmine Tommaso Recchiuto","Antonio Sgorbissa"],"pdf_url":"https://arxiv.org/pdf/2201.01565v4.pdf","comment":"40 pages (bibliography excluded), 5 figures, 6 Tables"},{"id":"http://arxiv.org/abs/2302.03573v2","updated":"2023-03-06T21:03:39Z","published":"2023-02-07T16:37:19Z","title":"Local Neural Descriptor Fields: Locally Conditioned Object\n  Representations for Manipulation","summary":"  A robot operating in a household environment will see a wide range of unique\nand unfamiliar objects. While a system could train on many of these, it is\ninfeasible to predict all the objects a robot will see. In this paper, we\npresent a method to generalize object manipulation skills acquired from a\nlimited number of demonstrations, to novel objects from unseen shape\ncategories. Our approach, Local Neural Descriptor Fields (L-NDF), utilizes\nneural descriptors defined on the local geometry of the object to effectively\ntransfer manipulation demonstrations to novel objects at test time. In doing\nso, we leverage the local geometry shared between objects to produce a more\ngeneral manipulation framework. We illustrate the efficacy of our approach in\nmanipulating novel objects in novel poses -- both in simulation and in the real\nworld.\n","authors":["Ethan Chun","Yilun Du","Anthony Simeonov","Tomas Lozano-Perez","Leslie Kaelbling"],"pdf_url":"https://arxiv.org/pdf/2302.03573v2.pdf","comment":"ICRA 2023, Project Page: https://elchun.github.io/lndf/"},{"id":"http://arxiv.org/abs/2104.02206v6","updated":"2023-03-06T20:32:23Z","published":"2021-04-06T00:53:01Z","title":"Tuned Compositional Feature Replays for Efficient Stream Learning","summary":"  Our brains extract durable, generalizable knowledge from transient\nexperiences of the world. Artificial neural networks come nowhere close: when\ntasked with learning to classify objects by training on non-repeating video\nframes in temporal order (online stream learning), models that learn well from\nshuffled datasets catastrophically forget old knowledge upon learning new\nstimuli. We propose a new continual learning algorithm, Compositional Replay\nUsing Memory Blocks (CRUMB), which mitigates forgetting by replaying feature\nmaps reconstructed by recombining generic parts. Just as crumbs together form a\nloaf of bread, we concatenate trainable and re-usable \"memory block\" vectors to\ncompositionally reconstruct feature map tensors in convolutional neural\nnetworks. CRUMB stores the indices of memory blocks used to reconstruct new\nstimuli, enabling replay of specific memories during later tasks. CRUMB's\nmemory blocks are tuned to enhance replay: a single feature map stored,\nreconstructed, and replayed by CRUMB mitigates forgetting during video stream\nlearning more effectively than an entire image, even though it occupies only\n3.6% as much memory. We stress-tested CRUMB alongside 13 competing methods on 5\nchallenging datasets. To address the limited number of existing online stream\nlearning datasets, we introduce 2 new benchmarks by adapting existing datasets\nfor stream learning. With about 4% of the memory and 20% of the runtime, CRUMB\nmitigates catastrophic forgetting more effectively than the prior\nstate-of-the-art. Our code is available at\nhttps://github.com/MorganBDT/crumb.git.\n","authors":["Morgan B. Talbot","Rushikesh Zawar","Rohil Badkundri","Mengmi Zhang","Gabriel Kreiman"],"pdf_url":"https://arxiv.org/pdf/2104.02206v6.pdf","comment":"Copyright 2023 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works"},{"id":"http://arxiv.org/abs/2303.03471v1","updated":"2023-03-06T19:53:50Z","published":"2023-03-06T19:53:50Z","title":"Refining 3D Human Texture Estimation from a Single Image","summary":"  Estimating 3D human texture from a single image is essential in graphics and\nvision. It requires learning a mapping function from input images of humans\nwith diverse poses into the parametric (UV) space and reasonably hallucinating\ninvisible parts. To achieve a high-quality 3D human texture estimation, we\npropose a framework that adaptively samples the input by a deformable\nconvolution where offsets are learned via a deep neural network. Additionally,\nwe describe a novel cycle consistency loss that improves view generalization.\nWe further propose to train our framework with an uncertainty-based pixel-level\nimage reconstruction loss, which enhances color fidelity. We compare our method\nagainst the state-of-the-art approaches and show significant qualitative and\nquantitative improvements.\n","authors":["Said Fahri Altindis","Adil Meric","Yusuf Dalva","Ugur Gudukbay","Aysegul Dundar"],"pdf_url":"https://arxiv.org/pdf/2303.03471v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.04500v2","updated":"2023-03-06T19:44:59Z","published":"2022-12-08T18:59:59Z","title":"Masked Video Distillation: Rethinking Masked Feature Modeling for\n  Self-supervised Video Representation Learning","summary":"  Benefiting from masked visual modeling, self-supervised video representation\nlearning has achieved remarkable progress. However, existing methods focus on\nlearning representations from scratch through reconstructing low-level features\nlike raw pixel RGB values. In this paper, we propose masked video distillation\n(MVD), a simple yet effective two-stage masked feature modeling framework for\nvideo representation learning: firstly we pretrain an image (or video) model by\nrecovering low-level features of masked patches, then we use the resulting\nfeatures as targets for masked feature modeling. For the choice of teacher\nmodels, we observe that students taught by video teachers perform better on\ntemporally-heavy video tasks, while image teachers transfer stronger spatial\nrepresentations for spatially-heavy video tasks. Visualization analysis also\nindicates different teachers produce different learned patterns for students.\nMotivated by this observation, we design a spatial-temporal co-teaching method\nfor MVD. Specifically, we distill student models from both video teachers and\nimage teachers by masked feature modeling. Extensive experimental results\ndemonstrate that video transformers pretrained with spatial-temporal\nco-teaching outperform models distilled with a single teacher on a multitude of\nvideo datasets. Our MVD with vanilla ViT achieves state-of-the-art performance\ncompared with previous supervised or self-supervised methods on several\nchallenging video downstream tasks. For example, with the ViT-Large model, our\nMVD achieves 86.4% and 76.7% Top-1 accuracy on Kinetics-400 and\nSomething-Something-v2, outperforming VideoMAE by 1.2% and 2.4% respectively.\nWhen a larger ViT-Huge model is adopted, MVD achieves the state-of-the-art\nperformance with 77.3% Top-1 accuracy on Something-Something-v2 and 41.1 mAP on\nAVA v2.2. Code will be available at \\url{https://github.com/ruiwang2021/mvd}.\n","authors":["Rui Wang","Dongdong Chen","Zuxuan Wu","Yinpeng Chen","Xiyang Dai","Mengchen Liu","Lu Yuan","Yu-Gang Jiang"],"pdf_url":"https://arxiv.org/pdf/2212.04500v2.pdf","comment":"CVPR 2023, code will be available at\n  https://github.com/ruiwang2021/mvd"},{"id":"http://arxiv.org/abs/2207.00056v3","updated":"2023-03-06T19:39:18Z","published":"2022-06-30T18:42:06Z","title":"MultiViz: Towards Visualizing and Understanding Multimodal Models","summary":"  The promise of multimodal models for real-world applications has inspired\nresearch in visualizing and understanding their internal mechanics with the end\ngoal of empowering stakeholders to visualize model behavior, perform model\ndebugging, and promote trust in machine learning models. However, modern\nmultimodal models are typically black-box neural networks, which makes it\nchallenging to understand their internal mechanics. How can we visualize the\ninternal modeling of multimodal interactions in these models? Our paper aims to\nfill this gap by proposing MultiViz, a method for analyzing the behavior of\nmultimodal models by scaffolding the problem of interpretability into 4 stages:\n(1) unimodal importance: how each modality contributes towards downstream\nmodeling and prediction, (2) cross-modal interactions: how different modalities\nrelate with each other, (3) multimodal representations: how unimodal and\ncross-modal interactions are represented in decision-level features, and (4)\nmultimodal prediction: how decision-level features are composed to make a\nprediction. MultiViz is designed to operate on diverse modalities, models,\ntasks, and research areas. Through experiments on 8 trained models across 6\nreal-world tasks, we show that the complementary stages in MultiViz together\nenable users to (1) simulate model predictions, (2) assign interpretable\nconcepts to features, (3) perform error analysis on model misclassifications,\nand (4) use insights from error analysis to debug models. MultiViz is publicly\navailable, will be regularly updated with new interpretation tools and metrics,\nand welcomes inputs from the community.\n","authors":["Paul Pu Liang","Yiwei Lyu","Gunjan Chhablani","Nihal Jain","Zihao Deng","Xingbo Wang","Louis-Philippe Morency","Ruslan Salakhutdinov"],"pdf_url":"https://arxiv.org/pdf/2207.00056v3.pdf","comment":"ICLR 2023. Code available at: https://github.com/pliang279/MultiViz"},{"id":"http://arxiv.org/abs/2303.03462v1","updated":"2023-03-06T19:37:01Z","published":"2023-03-06T19:37:01Z","title":"Towards Composable Distributions of Latent Space Augmentations","summary":"  We propose a composable framework for latent space image augmentation that\nallows for easy combination of multiple augmentations. Image augmentation has\nbeen shown to be an effective technique for improving the performance of a wide\nvariety of image classification and generation tasks. Our framework is based on\nthe Variational Autoencoder architecture and uses a novel approach for\naugmentation via linear transformation within the latent space itself. We\nexplore losses and augmentation latent geometry to enforce the transformations\nto be composable and involuntary, thus allowing the transformations to be\nreadily combined or inverted. Finally, we show these properties are better\nperforming with certain pairs of augmentations, but we can transfer the latent\nspace to other sets of augmentations to modify performance, effectively\nconstraining the VAE's bottleneck to preserve the variance of specific\naugmentations and features of the image which we care about. We demonstrate the\neffectiveness of our approach with initial results on the MNIST dataset against\nboth a standard VAE and a Conditional VAE. This latent augmentation method\nallows for much greater control and geometric interpretability of the latent\nspace, making it a valuable tool for researchers and practitioners in the\nfield.\n","authors":["Omead Pooladzandi","Jeffrey Jiang","Sunay Bhat","Gregory Pottie"],"pdf_url":"https://arxiv.org/pdf/2303.03462v1.pdf","comment":"Accepted at 2023 Information Theory and Applications Workshop (Feb,\n  San Diego)"},{"id":"http://arxiv.org/abs/2303.03458v1","updated":"2023-03-06T19:30:43Z","published":"2023-03-06T19:30:43Z","title":"Learning Differential Invariants of Planar Curves","summary":"  We propose a learning paradigm for the numerical approximation of\ndifferential invariants of planar curves. Deep neural-networks' (DNNs)\nuniversal approximation properties are utilized to estimate geometric measures.\nThe proposed framework is shown to be a preferable alternative to axiomatic\nconstructions. Specifically, we show that DNNs can learn to overcome\ninstabilities and sampling artifacts and produce consistent signatures for\ncurves subject to a given group of transformations in the plane. We compare the\nproposed schemes to alternative state-of-the-art axiomatic constructions of\ndifferential invariants. We evaluate our models qualitatively and\nquantitatively and propose a benchmark dataset to evaluate approximation models\nof differential invariants of planar curves.\n","authors":["Roy Velich","Ron Kimmel"],"pdf_url":"https://arxiv.org/pdf/2303.03458v1.pdf","comment":"SSVM 2023. arXiv admin note: substantial text overlap with\n  arXiv:2202.05922"},{"id":"http://arxiv.org/abs/2303.03432v1","updated":"2023-03-06T19:00:59Z","published":"2023-03-06T19:00:59Z","title":"Polar Prediction of Natural Videos","summary":"  Observer motion and continuous deformations of objects and surfaces imbue\nnatural videos with distinct temporal structures, enabling partial prediction\nof future frames from past ones. Conventional methods first estimate local\nmotion, or optic flow, and then use it to predict future frames by warping or\ncopying content. Here, we explore a more direct methodology, in which each\nframe is mapped into a learned representation space where the structure of\ntemporal evolution is more readily accessible. Motivated by the geometry of the\nFourier shift theorem and its group-theoretic generalization, we formulate a\nsimple architecture that represents video frames in learned local polar\ncoordinates. Specifically, we construct networks in which pairs of\nconvolutional channel coefficients are treated as complex-valued, and are\noptimized to evolve with slowly varying amplitudes and linearly advancing\nphases. We train these models on next-frame prediction in natural videos, and\ncompare their performance with that of conventional methods using optic flow as\nwell as predictive neural networks. We find that the polar predictor achieves\nbetter performance while remaining interpretable and fast, thereby\ndemonstrating the potential of a flow-free video processing methodology that is\ntrained end-to-end to predict natural video content.\n","authors":["Pierre-Étienne H. Fiquet","Eero P. Simoncelli"],"pdf_url":"https://arxiv.org/pdf/2303.03432v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03405v1","updated":"2023-03-06T16:57:45Z","published":"2023-03-06T16:57:45Z","title":"Neural Style Transfer for Vector Graphics","summary":"  Neural style transfer draws researchers' attention, but the interest focuses\non bitmap images. Various models have been developed for bitmap image\ngeneration both online and offline with arbitrary and pre-trained styles.\nHowever, the style transfer between vector images has not almost been\nconsidered. Our research shows that applying standard content and style losses\ninsignificantly changes the vector image drawing style because the structure of\nvector primitives differs a lot from pixels. To handle this problem, we\nintroduce new loss functions. We also develop a new method based on\ndifferentiable rasterization that uses these loss functions and can change the\ncolor and shape parameters of the content image corresponding to the drawing of\nthe style image. Qualitative experiments demonstrate the effectiveness of the\nproposed VectorNST method compared with the state-of-the-art neural style\ntransfer approaches for bitmap images and the only existing approach for\nstylizing vector images, DiffVG. Although the proposed model does not achieve\nthe quality and smoothness of style transfer between bitmap images, we consider\nour work an important early step in this area. VectorNST code and demo service\nare available at https://github.com/IzhanVarsky/VectorNST.\n","authors":["Valeria Efimova","Artyom Chebykin","Ivan Jarsky","Evgenii Prosvirnin","Andrey Filchenkov"],"pdf_url":"https://arxiv.org/pdf/2303.03405v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01592v2","updated":"2023-03-06T15:48:03Z","published":"2023-03-02T21:31:35Z","title":"Joint cortical registration of geometry and function using\n  semi-supervised learning","summary":"  Brain surface-based image registration, an important component of brain image\nanalysis, establishes spatial correspondence between cortical surfaces.\nExisting iterative and learning-based approaches focus on accurate registration\nof folding patterns of the cerebral cortex, and assume that geometry predicts\nfunction and thus functional areas will also be well aligned. However,\nstructure/functional variability of anatomically corresponding areas across\nsubjects has been widely reported. In this work, we introduce a learning-based\ncortical registration framework, JOSA, which jointly aligns folding patterns\nand functional maps while simultaneously learning an optimal atlas. We\ndemonstrate that JOSA can substantially improve registration performance in\nboth anatomical and functional domains over existing methods. By employing a\nsemi-supervised training strategy, the proposed framework obviates the need for\nfunctional data during inference, enabling its use in broad neuroscientific\ndomains where functional data may not be observed.\n","authors":["Jian Li","Greta Tuckute","Evelina Fedorenko","Brian L. Edlow","Bruce Fischl","Adrian V. Dalca"],"pdf_url":"https://arxiv.org/pdf/2303.01592v2.pdf","comment":"B. Fischl and A. V. Dalca are co-senior authors with equal\n  contributions"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2303.03321v1","updated":"2023-03-06T17:48:27Z","published":"2023-03-06T17:48:27Z","title":"Implementation of a noisy hyperlink removal system: A semantic and\n  relatedness approach","summary":"  As the volume of data on the web grows, the web structure graph, which is a\ngraph representation of the web, continues to evolve. The structure of this\ngraph has gradually shifted from content-based to non-content-based.\nFurthermore, spam data, such as noisy hyperlinks, in the web structure graph\nadversely affect the speed and efficiency of information retrieval and link\nmining algorithms. Previous works in this area have focused on removing noisy\nhyperlinks using structural and string approaches. However, these approaches\nmay incorrectly remove useful links or be unable to detect noisy hyperlinks in\ncertain circumstances. In this paper, a data collection of hyperlinks is\ninitially constructed using an interactive crawler. The semantic and\nrelatedness structure of the hyperlinks is then studied through semantic web\napproaches and tools such as the DBpedia ontology. Finally, the removal process\nof noisy hyperlinks is carried out using a reasoner on the DBpedia ontology.\nOur experiments demonstrate the accuracy and ability of semantic web\ntechnologies to remove noisy hyperlinks\n","authors":["Kazem Taghandiki","Elnaz Rezaei Ehsan"],"pdf_url":"https://arxiv.org/pdf/2303.03321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03290v1","updated":"2023-03-06T17:06:50Z","published":"2023-03-06T17:06:50Z","title":"AmQA: Amharic Question Answering Dataset","summary":"  Question Answering (QA) returns concise answers or answer lists from natural\nlanguage text given a context document. Many resources go into curating QA\ndatasets to advance robust models' development. There is a surge of QA datasets\nfor languages like English, however, this is not true for Amharic. Amharic, the\nofficial language of Ethiopia, is the second most spoken Semitic language in\nthe world. There is no published or publicly available Amharic QA dataset.\nHence, to foster the research in Amharic QA, we present the first Amharic QA\n(AmQA) dataset. We crowdsourced 2628 question-answer pairs over 378 Wikipedia\narticles. Additionally, we run an XLMR Large-based baseline model to spark\nopen-domain QA research interest. The best-performing baseline achieves an\nF-score of 69.58 and 71.74 in reader-retriever QA and reading comprehension\nsettings respectively.\n","authors":["Tilahun Abedissa","Ricardo Usbeck","Yaregal Assabie"],"pdf_url":"https://arxiv.org/pdf/2303.03290v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03229v1","updated":"2023-03-06T15:47:45Z","published":"2023-03-06T15:47:45Z","title":"LongEval-Retrieval: French-English Dynamic Test Collection for\n  Continuous Web Search Evaluation","summary":"  LongEval-Retrieval is a Web document retrieval benchmark that focuses on\ncontinuous retrieval evaluation. This test collection is intended to be used to\nstudy the temporal persistence of Information Retrieval systems and will be\nused as the test collection in the Longitudinal Evaluation of Model Performance\nTrack (LongEval) at CLEF 2023. This benchmark simulates an evolving information\nsystem environment - such as the one a Web search engine operates in - where\nthe document collection, the query distribution, and relevance all move\ncontinuously, while following the Cranfield paradigm for offline evaluation. To\ndo that, we introduce the concept of a dynamic test collection that is composed\nof successive sub-collections each representing the state of an information\nsystem at a given time step. In LongEval-Retrieval, each sub-collection\ncontains a set of queries, documents, and soft relevance assessments built from\nclick models. The data comes from Qwant, a privacy-preserving Web search engine\nthat primarily focuses on the French market. LongEval-Retrieval also provides a\n'mirror' collection: it is initially constructed in the French language to\nbenefit from the majority of Qwant's traffic, before being translated to\nEnglish. This paper presents the creation process of LongEval-Retrieval and\nprovides baseline runs and analysis.\n","authors":["Petra Galuščáková","Romain Deveaud","Gabriela Gonzalez-Saez","Philippe Mulhem","Lorraine Goeuriot","Florina Piroi","Martin Popel"],"pdf_url":"https://arxiv.org/pdf/2303.03229v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03050v1","updated":"2023-03-06T11:46:58Z","published":"2023-03-06T11:46:58Z","title":"MABNet: Master Assistant Buddy Network with Hybrid Learning for Image\n  Retrieval","summary":"  Image retrieval has garnered growing interest in recent times. The current\napproaches are either supervised or self-supervised. These methods do not\nexploit the benefits of hybrid learning using both supervision and\nself-supervision. We present a novel Master Assistant Buddy Network (MABNet)\nfor image retrieval which incorporates both learning mechanisms. MABNet\nconsists of master and assistant blocks, both learning independently through\nsupervision and collectively via self-supervision. The master guides the\nassistant by providing its knowledge base as a reference for self-supervision\nand the assistant reports its knowledge back to the master by weight transfer.\nWe perform extensive experiments on public datasets with and without\npost-processing.\n","authors":["Rohit Agarwal","Gyanendra Das","Saksham Aggarwal","Alexander Horsch","Dilip K. Prasad"],"pdf_url":"https://arxiv.org/pdf/2303.03050v1.pdf","comment":"Accepted at International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP) 2023"},{"id":"http://arxiv.org/abs/2303.02916v1","updated":"2023-03-06T06:21:20Z","published":"2023-03-06T06:21:20Z","title":"Privacy-Preserving Fair Item Ranking","summary":"  Users worldwide access massive amounts of curated data in the form of\nrankings on a daily basis. The societal impact of this ease of access has been\nstudied and work has been done to propose and enforce various notions of\nfairness in rankings. Current computational methods for fair item ranking rely\non disclosing user data to a centralized server, which gives rise to privacy\nconcerns for the users. This work is the first to advance research at the\nconjunction of producer (item) fairness and consumer (user) privacy in rankings\nby exploring the incorporation of privacy-preserving techniques; specifically,\ndifferential privacy and secure multi-party computation. Our work extends the\nequity of amortized attention ranking mechanism to be privacy-preserving, and\nwe evaluate its effects with respect to privacy, fairness, and ranking quality.\nOur results using real-world datasets show that we are able to effectively\npreserve the privacy of users and mitigate unfairness of items without making\nadditional sacrifices to the quality of rankings in comparison to the ranking\nmechanism in the clear.\n","authors":["Jia Ao Sun","Sikha Pentyala","Martine De Cock","Golnoosh Farnadi"],"pdf_url":"https://arxiv.org/pdf/2303.02916v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02867v1","updated":"2023-03-06T03:36:06Z","published":"2023-03-06T03:36:06Z","title":"Dual Feedback Attention Framework via Boundary-Aware Auxiliary and\n  Progressive Semantic Optimization for Salient Object Detection in Optical\n  Remote Sensing Imagery","summary":"  Salient object detection in optical remote sensing image (ORSI-SOD) has\ngradually attracted attention thanks to the development of deep learning (DL)\nand salient object detection in natural scene image (NSI-SOD). However, NSI and\nORSI are different in many aspects, such as large coverage, complex background,\nand large differences in target types and scales. Therefore, a new dedicated\nmethod is needed for ORSI-SOD. In addition, existing methods do not pay\nsufficient attention to the boundary of the object, and the completeness of the\nfinal saliency map still needs improvement. To address these issues, we propose\na novel method called Dual Feedback Attention Framework via Boundary-Aware\nAuxiliary and Progressive Semantic Optimization (DFA-BASO). First, Boundary\nProtection Calibration (BPC) module is proposed to reduce the loss of edge\nposition information during forward propagation and suppress noise in low-level\nfeatures. Second, a Dual Feature Feedback Complementary (DFFC) module is\nproposed based on BPC module. It aggregates boundary-semantic dual features and\nprovides effective feedback to coordinate features across different layers.\nFinally, a Strong Semantic Feedback Refinement (SSFR) module is proposed to\nobtain more complete saliency maps. This module further refines feature\nrepresentation and eliminates feature differences through a unique feedback\nmechanism. Extensive experiments on two public datasets show that DFA-BASO\noutperforms 15 state-of-the-art methods. Furthermore, this paper strongly\ndemonstrates the true contribution of DFA-BASO to ORSI-SOD by in-depth analysis\nof the visualization figure. All codes can be found at\nhttps://github.com/YUHsss/DFA-BASO.\n","authors":["Dejun Feng","Hongyu Chen","Suning Liu","Xingyu Shen","Ziyang Liao","Yakun Xie","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2303.02867v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02851v1","updated":"2023-03-06T03:10:38Z","published":"2023-03-06T03:10:38Z","title":"A Survey on Incremental Update for Neural Recommender Systems","summary":"  Recommender Systems (RS) aim to provide personalized suggestions of items for\nusers against consumer over-choice. Although extensive research has been\nconducted to address different aspects and challenges of RS, there still exists\na gap between academic research and industrial applications. Specifically, most\nof the existing models still work in an offline manner, in which the\nrecommender is trained on a large static training set and evaluated on a very\nrestrictive testing set in a one-time process. RS will stay unchanged until the\nnext batch retrain is performed. We frame such RS as Batch Update Recommender\nSystems (BURS). In reality, they have to face the challenges where RS are\nexpected to be instantly updated with new data streaming in, and generate\nupdated recommendations for current user activities based on the newly arrived\ndata. We frame such RS as Incremental Update Recommender Systems (IURS).\n  In this article, we offer a systematic survey of incremental update for\nneural recommender systems. We begin the survey by introducing key concepts and\nformulating the task of IURS. We then illustrate the challenges in IURS\ncompared with traditional BURS. Afterwards, we detail the introduction of\nexisting literature and evaluation issues. We conclude the survey by outlining\nsome prominent open research issues in this area.\n","authors":["Peiyan Zhang","Sunghun Kim"],"pdf_url":"https://arxiv.org/pdf/2303.02851v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2110.11248v2","updated":"2023-03-06T21:47:50Z","published":"2021-10-21T16:17:40Z","title":"Learning to Recommend Using Non-Uniform Data","summary":"  Learning user preferences for products based on their past purchases or\nreviews is at the cornerstone of modern recommendation engines. One\ncomplication in this learning task is that some users are more likely to\npurchase products or review them, and some products are more likely to be\npurchased or reviewed by the users. This non-uniform pattern degrades the power\nof many existing recommendation algorithms, as they assume that the observed\ndata are sampled uniformly at random among user-product pairs. In addition,\nexisting literature on modeling non-uniformity either assume user interests are\nindependent of the products, or lack theoretical understanding. In this paper,\nwe first model the user-product preferences as a partially observed matrix with\nnon-uniform observation pattern. Next, building on the literature about\nlow-rank matrix estimation, we introduce a new weighted trace-norm penalized\nregression to predict unobserved values of the matrix. We then prove an upper\nbound for the prediction error of our proposed approach. Our upper bound is a\nfunction of a number of parameters that are based on a certain weight matrix\nthat depends on the joint distribution of users and products. Utilizing this\nobservation, we introduce a new optimization problem to select a weight matrix\nthat minimizes the upper bound on the prediction error. The final product is a\nnew estimator, NU-Recommend, that outperforms existing methods in both\nsynthetic and real datasets. Our approach aims at accurate predictions for all\nusers while prioritizing fairness. To achieve this, we employ a bias-variance\ntradeoff mechanism that ensures good overall prediction performance without\ncompromising the predictive accuracy for less active users.\n","authors":["Wanning Chen","Mohsen Bayati"],"pdf_url":"https://arxiv.org/pdf/2110.11248v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.09051v2","updated":"2023-03-06T21:46:08Z","published":"2023-02-17T18:31:31Z","title":"Complex QA and language models hybrid architectures, Survey","summary":"  This paper provides a survey of the state of the art of hybrid language\nmodels architectures and strategies for \"complex\" question-answering (QA, CQA,\nCPS). Very large language models are good at leveraging public data on standard\nproblems but once you want to tackle more specific complex questions or\nproblems you may need specific architecture, knowledge, skills, tasks, methods,\nsensitive data, performance, human approval and versatile feedback... This\nsurvey extends findings from the robust community edited research papers BIG,\nBLOOM and HELM which open source, benchmark and analyze limits and challenges\nof large language models in terms of tasks complexity and strict evaluation on\naccuracy (e.g. fairness, robustness, toxicity, ...). It identifies the key\nelements used with Large Language Models (LLM) to solve complex questions or\nproblems. Recent projects like ChatGPT and GALACTICA have allowed\nnon-specialists to grasp the great potential as well as the equally strong\nlimitations of language models in complex QA. Hybridizing these models with\ndifferent components could allow to overcome these different limits and go much\nfurther. We discuss some challenges associated with complex QA, including\ndomain adaptation, decomposition and efficient multi-step QA, long form QA,\nnon-factoid QA, safety and multi-sensitivity data protection, multimodal\nsearch, hallucinations, QA explainability and truthfulness, time dimension.\nTherefore we review current solutions and promising strategies, using elements\nsuch as hybrid LLM architectures, human-in-the-loop reinforcement learning,\nprompting adaptation, neuro-symbolic and structured knowledge grounding,\nprogram synthesis, and others. We analyze existing solutions and provide an\noverview of the current research and trends in the area of complex QA.\n","authors":["Xavier Daull","Patrice Bellot","Emmanuel Bruno","Vincent Martin","Elisabeth Murisasco"],"pdf_url":"https://arxiv.org/pdf/2302.09051v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03445v1","updated":"2023-03-06T19:08:51Z","published":"2023-03-06T19:08:51Z","title":"How Auditing Methodologies Can Impact Our Understanding of YouTube's\n  Recommendation Systems","summary":"  Data generated by audits of social media websites have formed the basis of\nour understanding of the biases presented in algorithmic content recommendation\nsystems. As legislators around the world are beginning to consider regulating\nthe algorithmic systems that drive online platforms, it is critical to ensure\nthe correctness of these inferred biases. However, as we will show in this\npaper, doing so is a challenging task for a variety of reasons related to the\ncomplexity of configuration parameters associated with the audits that gather\ndata from a specific platform.\n  Focusing specifically on YouTube, we show that conducting audits to make\ninferences about YouTube's recommendation systems is more methodologically\nchallenging than one might expect. There are many methodological decisions that\nneed to be considered in order to obtain scientifically valid results, and each\nof these decisions incur costs. For example, should an auditor use (expensive\nto obtain) logged-in YouTube accounts while gathering recommendations from the\nalgorithm to obtain more accurate inferences? We explore the impact of this and\nmany other decisions and make some startling discoveries about the\nmethodological choices that impact YouTube's recommendations. Taken all\ntogether, our research suggests auditing configuration compromises that YouTube\nauditors and researchers can use to reduce audit overhead, both economically\nand computationally, without sacrificing accuracy of their inferences.\nSimilarly, we also identify several configuration parameters that have a\nsignificant impact on the accuracy of measured inferences and should be\ncarefully considered.\n","authors":["Sarmad Chandio","Daniyal Pirwani Dar","Rishab Nithyanand"],"pdf_url":"https://arxiv.org/pdf/2303.03445v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2303.03384v1","updated":"2023-03-06T18:59:19Z","published":"2023-03-06T18:59:19Z","title":"Restoration-Degradation Beyond Linear Diffusions: A Non-Asymptotic\n  Analysis For DDIM-Type Samplers","summary":"  We develop a framework for non-asymptotic analysis of deterministic samplers\nused for diffusion generative modeling. Several recent works have analyzed\nstochastic samplers using tools like Girsanov's theorem and a chain rule\nvariant of the interpolation argument. Unfortunately, these techniques give\nvacuous bounds when applied to deterministic samplers. We give a new\noperational interpretation for deterministic sampling by showing that one step\nalong the probability flow ODE can be expressed as two steps: 1) a restoration\nstep that runs gradient ascent on the conditional log-likelihood at some\ninfinitesimally previous time, and 2) a degradation step that runs the forward\nprocess using noise pointing back towards the current iterate. This perspective\nallows us to extend denoising diffusion implicit models to general, non-linear\nforward processes. We then develop the first polynomial convergence bounds for\nthese samplers under mild conditions on the data distribution.\n","authors":["Sitan Chen","Giannis Daras","Alexandros G. Dimakis"],"pdf_url":"https://arxiv.org/pdf/2303.03384v1.pdf","comment":"29 pages"},{"id":"http://arxiv.org/abs/2303.03382v1","updated":"2023-03-06T18:59:13Z","published":"2023-03-06T18:59:13Z","title":"Globally Optimal Training of Neural Networks with Threshold Activation\n  Functions","summary":"  Threshold activation functions are highly preferable in neural networks due\nto their efficiency in hardware implementations. Moreover, their mode of\noperation is more interpretable and resembles that of biological neurons.\nHowever, traditional gradient based algorithms such as Gradient Descent cannot\nbe used to train the parameters of neural networks with threshold activations\nsince the activation function has zero gradient except at a single\nnon-differentiable point. To this end, we study weight decay regularized\ntraining problems of deep neural networks with threshold activations. We first\nshow that regularized deep threshold network training problems can be\nequivalently formulated as a standard convex optimization problem, which\nparallels the LASSO method, provided that the last hidden layer width exceeds a\ncertain threshold. We also derive a simplified convex optimization formulation\nwhen the dataset can be shattered at a certain layer of the network. We\ncorroborate our theoretical results with various numerical experiments.\n","authors":["Tolga Ergen","Halil Ibrahim Gulluk","Jonathan Lacotte","Mert Pilanci"],"pdf_url":"https://arxiv.org/pdf/2303.03382v1.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2303.03381v1","updated":"2023-03-06T18:59:09Z","published":"2023-03-06T18:59:09Z","title":"Learning Humanoid Locomotion with Transformers","summary":"  We present a sim-to-real learning-based approach for real-world humanoid\nlocomotion. Our controller is a causal Transformer trained by autoregressive\nprediction of future actions from the history of observations and actions. We\nhypothesize that the observation-action history contains useful information\nabout the world that a powerful Transformer model can use to adapt its behavior\nin-context, without updating its weights. We do not use state estimation,\ndynamics models, trajectory optimization, reference trajectories, or\npre-computed gait libraries. Our controller is trained with large-scale\nmodel-free reinforcement learning on an ensemble of randomized environments in\nsimulation and deployed to the real world in a zero-shot fashion. We evaluate\nour approach in high-fidelity simulation and successfully deploy it to the real\nrobot as well. To the best of our knowledge, this is the first demonstration of\na fully learning-based method for real-world full-sized humanoid locomotion.\n","authors":["Ilija Radosavovic","Tete Xiao","Bike Zhang","Trevor Darrell","Jitendra Malik","Koushil Sreenath"],"pdf_url":"https://arxiv.org/pdf/2303.03381v1.pdf","comment":"Project page: https://humanoid-transformer.github.io"},{"id":"http://arxiv.org/abs/2303.03379v1","updated":"2023-03-06T18:58:13Z","published":"2023-03-06T18:58:13Z","title":"SUREL+: Moving from Walks to Sets for Scalable Subgraph-based Graph\n  Representation Learning","summary":"  Subgraph-based graph representation learning (SGRL) has recently emerged as a\npowerful tool in many prediction tasks on graphs due to its advantages in model\nexpressiveness and generalization ability. Most previous SGRL models face\ncomputational issues associated with the high cost of extracting subgraphs for\neach training or testing query. Recently, SUREL has been proposed as a new\nframework to accelerate SGRL, which samples random walks offline and joins\nthese walks as subgraphs online for prediction. Due to the reusability of\nsampled walks across different queries, SUREL achieves state-of-the-art\nperformance in both scalability and prediction accuracy. However, SUREL still\nsuffers from high computational overhead caused by node redundancy in sampled\nwalks. In this work, we propose a novel framework SUREL+ that upgrades SUREL by\nusing node sets instead of walks to represent subgraphs. This set-based\nrepresentation avoids node duplication by definition, but the sizes of node\nsets can be irregular. To address this issue, we design a dedicated sparse data\nstructure to efficiently store and fast index node sets, and provide a\nspecialized operator to join them in parallel batches. SUREL+ is modularized to\nsupport multiple types of set samplers, structural features, and neural\nencoders to complement the loss of structural information due to the reduction\nfrom walks to sets. Extensive experiments have been performed to validate\nSUREL+ in the prediction tasks of links, relation types, and higher-order\npatterns. SUREL+ achieves 3-11$\\times$ speedups of SUREL while maintaining\ncomparable or even better prediction performance; compared to other SGRL\nbaselines, SUREL+ achieves $\\sim$20$\\times$ speedups and significantly improves\nthe prediction accuracy.\n","authors":["Haoteng Yin","Muhan Zhang","Jianguo Wang","Pan Li"],"pdf_url":"https://arxiv.org/pdf/2303.03379v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03378v1","updated":"2023-03-06T18:58:06Z","published":"2023-03-06T18:58:06Z","title":"PaLM-E: An Embodied Multimodal Language Model","summary":"  Large language models excel at a wide range of complex tasks. However,\nenabling general inference in the real world, e.g., for robotics problems,\nraises the challenge of grounding. We propose embodied language models to\ndirectly incorporate real-world continuous sensor modalities into language\nmodels and thereby establish the link between words and percepts. Input to our\nembodied language model are multi-modal sentences that interleave visual,\ncontinuous state estimation, and textual input encodings. We train these\nencodings end-to-end, in conjunction with a pre-trained large language model,\nfor multiple embodied tasks including sequential robotic manipulation planning,\nvisual question answering, and captioning. Our evaluations show that PaLM-E, a\nsingle large embodied multimodal model, can address a variety of embodied\nreasoning tasks, from a variety of observation modalities, on multiple\nembodiments, and further, exhibits positive transfer: the model benefits from\ndiverse joint training across internet-scale language, vision, and\nvisual-language domains. Our largest model, PaLM-E-562B with 562B parameters,\nin addition to being trained on robotics tasks, is a visual-language generalist\nwith state-of-the-art performance on OK-VQA, and retains generalist language\ncapabilities with increasing scale.\n","authors":["Danny Driess","Fei Xia","Mehdi S. M. Sajjadi","Corey Lynch","Aakanksha Chowdhery","Brian Ichter","Ayzaan Wahid","Jonathan Tompson","Quan Vuong","Tianhe Yu","Wenlong Huang","Yevgen Chebotar","Pierre Sermanet","Daniel Duckworth","Sergey Levine","Vincent Vanhoucke","Karol Hausman","Marc Toussaint","Klaus Greff","Andy Zeng","Igor Mordatch","Pete Florence"],"pdf_url":"https://arxiv.org/pdf/2303.03378v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.16750v2","updated":"2023-03-06T18:57:42Z","published":"2022-11-30T05:33:29Z","title":"Score-based Continuous-time Discrete Diffusion Models","summary":"  Score-based modeling through stochastic differential equations (SDEs) has\nprovided a new perspective on diffusion models, and demonstrated superior\nperformance on continuous data. However, the gradient of the log-likelihood\nfunction, i.e., the score function, is not properly defined for discrete\nspaces. This makes it non-trivial to adapt \\textcolor{\\cdiff}{the score-based\nmodeling} to categorical data. In this paper, we extend diffusion models to\ndiscrete variables by introducing a stochastic jump process where the reverse\nprocess denoises via a continuous-time Markov chain. This formulation admits an\nanalytical simulation during backward sampling. To learn the reverse process,\nwe extend score matching to general categorical data and show that an unbiased\nestimator can be obtained via simple matching of the conditional marginal\ndistributions. We demonstrate the effectiveness of the proposed method on a set\nof synthetic and real-world music and image benchmarks.\n","authors":["Haoran Sun","Lijun Yu","Bo Dai","Dale Schuurmans","Hanjun Dai"],"pdf_url":"https://arxiv.org/pdf/2211.16750v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03376v1","updated":"2023-03-06T18:57:41Z","published":"2023-03-06T18:57:41Z","title":"MAESTRO: Open-Ended Environment Design for Multi-Agent Reinforcement\n  Learning","summary":"  Open-ended learning methods that automatically generate a curriculum of\nincreasingly challenging tasks serve as a promising avenue toward generally\ncapable reinforcement learning agents. Existing methods adapt curricula\nindependently over either environment parameters (in single-agent settings) or\nco-player policies (in multi-agent settings). However, the strengths and\nweaknesses of co-players can manifest themselves differently depending on\nenvironmental features. It is thus crucial to consider the dependency between\nthe environment and co-player when shaping a curriculum in multi-agent domains.\nIn this work, we use this insight and extend Unsupervised Environment Design\n(UED) to multi-agent environments. We then introduce Multi-Agent Environment\nDesign Strategist for Open-Ended Learning (MAESTRO), the first multi-agent UED\napproach for two-player zero-sum settings. MAESTRO efficiently produces\nadversarial, joint curricula over both environments and co-players and attains\nminimax-regret guarantees at Nash equilibrium. Our experiments show that\nMAESTRO outperforms a number of strong baselines on competitive two-player\ngames, spanning discrete and continuous control settings.\n","authors":["Mikayel Samvelyan","Akbir Khan","Michael Dennis","Minqi Jiang","Jack Parker-Holder","Jakob Foerster","Roberta Raileanu","Tim Rocktäschel"],"pdf_url":"https://arxiv.org/pdf/2303.03376v1.pdf","comment":"International Conference on Learning Representations (ICLR) 2023"},{"id":"http://arxiv.org/abs/2211.05952v3","updated":"2023-03-06T18:56:44Z","published":"2022-11-11T01:59:12Z","title":"Efficient Domain Coverage for Vehicles with Second-Order Dynamics via\n  Multi-Agent Reinforcement Learning","summary":"  Collaborative autonomous multi-agent systems covering a specified area have\nmany potential applications, such as UAV search and rescue, forest fire\nfighting, and real-time high-resolution monitoring. Traditional approaches for\nsuch coverage problems involve designing a model-based control policy based on\nsensor data. However, designing model-based controllers is challenging, and the\nstate-of-the-art classical control policy still exhibits a large degree of\nsub-optimality. In this paper, we present a reinforcement learning (RL)\napproach for the multi-agent efficient domain coverage problem involving agents\nwith second-order dynamics. Our approach is based on the Multi-Agent Proximal\nPolicy Optimization Algorithm (MAPPO). Our proposed network architecture\nincludes the incorporation of LSTM and self-attention, which allows the trained\npolicy to adapt to a variable number of agents. Our trained policy\nsignificantly outperforms the state-of-the-art classical control policy. We\ndemonstrate our proposed method in a variety of simulated experiments.\n","authors":["Xinyu Zhao","Razvan C. Fetecau","Mo Chen"],"pdf_url":"https://arxiv.org/pdf/2211.05952v3.pdf","comment":"This version is submitted to IEEE / RSJ International Conference on\n  Intelligent Robots and Systems, 2023"},{"id":"http://arxiv.org/abs/2303.03374v1","updated":"2023-03-06T18:56:39Z","published":"2023-03-06T18:56:39Z","title":"To Stay or Not to Stay in the Pre-train Basin: Insights on Ensembling in\n  Transfer Learning","summary":"  Transfer learning and ensembling are two popular techniques for improving the\nperformance and robustness of neural networks. Due to the high cost of\npre-training, ensembles of models fine-tuned from a single pre-trained\ncheckpoint are often used in practice. Such models end up in the same basin of\nthe loss landscape and thus have limited diversity. In this work, we study if\nit is possible to improve ensembles trained from a single pre-trained\ncheckpoint by better exploring the pre-train basin or a close vicinity outside\nof it. We show that while exploration of the pre-train basin may be beneficial\nfor the ensemble, leaving the basin results in losing the benefits of transfer\nlearning and degradation of the ensemble quality.\n","authors":["Ildus Sadrtdinov","Dmitrii Pozdeev","Dmitry Vetrov","Ekaterina Lobacheva"],"pdf_url":"https://arxiv.org/pdf/2303.03374v1.pdf","comment":"First two authors contributed equally"},{"id":"http://arxiv.org/abs/2303.03372v1","updated":"2023-03-06T18:55:58Z","published":"2023-03-06T18:55:58Z","title":"ALMOST: Adversarial Learning to Mitigate Oracle-less ML Attacks via\n  Synthesis Tuning","summary":"  Oracle-less machine learning (ML) attacks have broken various logic locking\nschemes. Regular synthesis, which is tailored for area-power-delay\noptimization, yields netlists where key-gate localities are vulnerable to\nlearning. Thus, we call for security-aware logic synthesis. We propose ALMOST,\na framework for adversarial learning to mitigate oracle-less ML attacks via\nsynthesis tuning. ALMOST uses a simulated-annealing-based synthesis recipe\ngenerator, employing adversarially trained models that can predict\nstate-of-the-art attacks' accuracies over wide ranges of recipes and key-gate\nlocalities. Experiments on ISCAS benchmarks confirm the attacks' accuracies\ndrops to around 50\\% for ALMOST-synthesized circuits, all while not undermining\ndesign optimization.\n","authors":["Animesh Basak Chowdhury","Lilas Alrahis","Luca Collini","Johann Knechtel","Ramesh Karri","Siddharth Garg","Ozgur Sinanoglu","Benjamin Tan"],"pdf_url":"https://arxiv.org/pdf/2303.03372v1.pdf","comment":"Accepted at Design Automation Conference (DAC 2023)"},{"id":"http://arxiv.org/abs/2209.14977v4","updated":"2023-03-06T18:54:56Z","published":"2022-09-29T17:45:25Z","title":"Transformer Meets Boundary Value Inverse Problems","summary":"  A Transformer-based deep direct sampling method is proposed for electrical\nimpedance tomography, a well-known severely ill-posed nonlinear boundary value\ninverse problem. A real-time reconstruction is achieved by evaluating the\nlearned inverse operator between carefully designed data and the reconstructed\nimages. An effort is made to give a specific example to a fundamental question:\nwhether and how one can benefit from the theoretical structure of a\nmathematical problem to develop task-oriented and structure-conforming deep\nneural networks? Specifically, inspired by direct sampling methods for inverse\nproblems, the 1D boundary data in different frequencies are preprocessed by a\npartial differential equation-based feature map to yield 2D harmonic extensions\nas different input channels. Then, by introducing learnable non-local kernels,\nthe direct sampling is recast to a modified attention mechanism. The new method\nachieves superior accuracy over its predecessors and contemporary operator\nlearners and shows robustness to noises in benchmarks. This research shall\nstrengthen the insights that, despite being invented for natural language\nprocessing tasks, the attention mechanism offers great flexibility to be\nmodified in conformity with the a priori mathematical knowledge, which\nultimately leads to the design of more physics-compatible neural architectures.\n","authors":["Ruchi Guo","Shuhao Cao","Long Chen"],"pdf_url":"https://arxiv.org/pdf/2209.14977v4.pdf","comment":"30 pages, 10 figures. Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.03365v1","updated":"2023-03-06T18:49:59Z","published":"2023-03-06T18:49:59Z","title":"Efficient Skill Acquisition for Complex Manipulation Tasks in Obstructed\n  Environments","summary":"  Data efficiency in robotic skill acquisition is crucial for operating robots\nin varied small-batch assembly settings. To operate in such environments,\nrobots must have robust obstacle avoidance and versatile goal conditioning\nacquired from only a few simple demonstrations. Existing approaches, however,\nfall short of these requirements. Deep reinforcement learning (RL) enables a\nrobot to learn complex manipulation tasks but is often limited to small task\nspaces in the real world due to sample inefficiency and safety concerns. Motion\nplanning (MP) can generate collision-free paths in obstructed environments, but\ncannot solve complex manipulation tasks and requires goal states often\nspecified by a user or object-specific pose estimator. In this work, we propose\na system for efficient skill acquisition that leverages an object-centric\ngenerative model (OCGM) for versatile goal identification to specify a goal for\nMP combined with RL to solve complex manipulation tasks in obstructed\nenvironments. Specifically, OCGM enables one-shot target object identification\nand re-identification in new scenes, allowing MP to guide the robot to the\ntarget object while avoiding obstacles. This is combined with a skill\ntransition network, which bridges the gap between terminal states of MP and\nfeasible start states of a sample-efficient RL policy. The experiments\ndemonstrate that our OCGM-based one-shot goal identification provides\ncompetitive accuracy to other baseline approaches and that our modular\nframework outperforms competitive baselines, including a state-of-the-art RL\nalgorithm, by a significant margin for complex manipulation tasks in obstructed\nenvironments.\n","authors":["Jun Yamada","Jack Collins","Ingmar Posner"],"pdf_url":"https://arxiv.org/pdf/2303.03365v1.pdf","comment":"8 pages, 5 figures"},{"id":"http://arxiv.org/abs/2303.03364v1","updated":"2023-03-06T18:49:39Z","published":"2023-03-06T18:49:39Z","title":"Leveraging Scene Embeddings for Gradient-Based Motion Planning in Latent\n  Space","summary":"  Motion planning framed as optimisation in structured latent spaces has\nrecently emerged as competitive with traditional methods in terms of planning\nsuccess while significantly outperforming them in terms of computational speed.\nHowever, the real-world applicability of recent work in this domain remains\nlimited by the need to express obstacle information directly in state-space,\ninvolving simple geometric primitives. In this work we address this challenge\nby leveraging learned scene embeddings together with a generative model of the\nrobot manipulator to drive the optimisation process. In addition, we introduce\nan approach for efficient collision checking which directly regularises the\noptimisation undertaken for planning. Using simulated as well as real-world\nexperiments, we demonstrate that our approach, AMP-LS, is able to successfully\nplan in novel, complex scenes while outperforming traditional planning\nbaselines in terms of computation speed by an order of magnitude. We show that\nthe resulting system is fast enough to enable closed-loop planning in\nreal-world dynamic scenes.\n","authors":["Jun Yamada","Chia-Man Hung","Jack Collins","Ioannis Havoutis","Ingmar Posner"],"pdf_url":"https://arxiv.org/pdf/2303.03364v1.pdf","comment":"Project website: https://amp-ls.github.io/"},{"id":"http://arxiv.org/abs/2303.03363v1","updated":"2023-03-06T18:49:09Z","published":"2023-03-06T18:49:09Z","title":"Enhancing Activity Prediction Models in Drug Discovery with the Ability\n  to Understand Human Language","summary":"  Activity and property prediction models are the central workhorses in drug\ndiscovery and materials sciences, but currently they have to be trained or\nfine-tuned for new tasks. Without training or fine-tuning, scientific language\nmodels could be used for such low-data tasks through their announced zero- and\nfew-shot capabilities. However, their predictive quality at activity prediction\nis lacking. In this work, we envision a novel type of activity prediction model\nthat is able to adapt to new prediction tasks at inference time, via\nunderstanding textual information describing the task. To this end, we propose\na new architecture with separate modules for chemical and natural language\ninputs, and a contrastive pre-training objective on data from large biochemical\ndatabases. In extensive experiments, we show that our method CLAMP yields\nimproved predictive performance on few-shot learning benchmarks and zero-shot\nproblems in drug discovery. We attribute the advances of our method to the\nmodularized architecture and to our pre-training objective.\n","authors":["Philipp Seidl","Andreu Vall","Sepp Hochreiter","Günter Klambauer"],"pdf_url":"https://arxiv.org/pdf/2303.03363v1.pdf","comment":"15 pages + 18 pages appendix"},{"id":"http://arxiv.org/abs/2303.03348v1","updated":"2023-03-06T18:35:16Z","published":"2023-03-06T18:35:16Z","title":"Thompson Sampling for Linear Bandit Problems with Normal-Gamma Priors","summary":"  We consider Thompson sampling for linear bandit problems with finitely many\nindependent arms, where rewards are sampled from normal distributions that are\nlinearly dependent on unknown parameter vectors and with unknown variance.\nSpecifically, with a Bayesian formulation we consider multivariate normal-gamma\npriors to represent environment uncertainty for all involved parameters. We\nshow that our chosen sampling prior is a conjugate prior to the reward model\nand derive a Bayesian regret bound for Thompson sampling under the condition\nthat the 5/2-moment of the variance distribution exist.\n","authors":["Björn Lindenberg","Karl-Olof Lindahl"],"pdf_url":"https://arxiv.org/pdf/2303.03348v1.pdf","comment":"27 pages, 2 figures"},{"id":"http://arxiv.org/abs/2209.12152v3","updated":"2023-03-06T18:28:18Z","published":"2022-09-25T05:21:59Z","title":"All are Worth Words: A ViT Backbone for Diffusion Models","summary":"  Vision transformers (ViT) have shown promise in various vision tasks while\nthe U-Net based on a convolutional neural network (CNN) remains dominant in\ndiffusion models. We design a simple and general ViT-based architecture (named\nU-ViT) for image generation with diffusion models. U-ViT is characterized by\ntreating all inputs including the time, condition and noisy image patches as\ntokens and employing long skip connections between shallow and deep layers. We\nevaluate U-ViT in unconditional and class-conditional image generation, as well\nas text-to-image generation tasks, where U-ViT is comparable if not superior to\na CNN-based U-Net of a similar size. In particular, latent diffusion models\nwith U-ViT achieve record-breaking FID scores of 2.29 in class-conditional\nimage generation on ImageNet 256x256, and 5.48 in text-to-image generation on\nMS-COCO, among methods without accessing large external datasets during the\ntraining of generative models. Our results suggest that, for diffusion-based\nimage modeling, the long skip connection is crucial while the down-sampling and\nup-sampling operators in CNN-based U-Net are not always necessary. We believe\nthat U-ViT can provide insights for future research on backbones in diffusion\nmodels and benefit generative modeling on large scale cross-modality datasets.\n","authors":["Fan Bao","Shen Nie","Kaiwen Xue","Yue Cao","Chongxuan Li","Hang Su","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2209.12152v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.07681v3","updated":"2023-03-06T18:25:52Z","published":"2022-08-16T11:42:28Z","title":"Generating a Terrain-Robustness Benchmark for Legged Locomotion: A\n  Prototype via Terrain Authoring and Active Learning","summary":"  Terrain-aware locomotion has become an emerging topic in legged robotics.\nHowever, it is hard to generate diverse, challenging, and realistic\nunstructured terrains in simulation, which limits the way researchers evaluate\ntheir locomotion policies. In this paper, we prototype the generation of a\nterrain dataset via terrain authoring and active learning, and the learned\nsamplers can stably generate diverse high-quality terrains. We expect the\ngenerated dataset to make a terrain-robustness benchmark for legged locomotion.\nThe dataset, the code implementation, and some policy evaluations are released\nat https://bit.ly/3bn4j7f.\n","authors":["Chong Zhang","Lizhi Yang"],"pdf_url":"https://arxiv.org/pdf/2208.07681v3.pdf","comment":"7 pages, 7 figures. IEEE ICRA 2023"},{"id":"http://arxiv.org/abs/2207.09572v2","updated":"2023-03-06T18:18:20Z","published":"2022-07-19T22:00:41Z","title":"Robust Multivariate Time-Series Forecasting: Adversarial Attacks and\n  Defense Mechanisms","summary":"  This work studies the threats of adversarial attack on multivariate\nprobabilistic forecasting models and viable defense mechanisms. Our studies\ndiscover a new attack pattern that negatively impact the forecasting of a\ntarget time series via making strategic, sparse (imperceptible) modifications\nto the past observations of a small number of other time series. To mitigate\nthe impact of such attack, we have developed two defense strategies. First, we\nextend a previously developed randomized smoothing technique in classification\nto multivariate forecasting scenarios. Second, we develop an adversarial\ntraining algorithm that learns to create adversarial examples and at the same\ntime optimizes the forecasting model to improve its robustness against such\nadversarial simulation. Extensive experiments on real-world datasets confirm\nthat our attack schemes are powerful and our defense algorithms are more\neffective compared with baseline defense mechanisms.\n","authors":["Linbo Liu","Youngsuk Park","Trong Nghia Hoang","Hilaf Hasson","Jun Huan"],"pdf_url":"https://arxiv.org/pdf/2207.09572v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03340v1","updated":"2023-03-06T18:13:14Z","published":"2023-03-06T18:13:14Z","title":"Symbolic Synthesis of Neural Networks","summary":"  Neural networks adapt very well to distributed and continuous\nrepresentations, but struggle to learn and generalize from small amounts of\ndata. Symbolic systems commonly achieve data efficient generalization by\nexploiting modularity to benefit from local and discrete features of a\nrepresentation. These features allow symbolic programs to be improved one\nmodule at a time and to experience combinatorial growth in the values they can\nsuccessfully process. However, it is difficult to design components that can be\nused to form symbolic abstractions and which are highly-overparametrized like\nneural networks, as the adjustment of parameters makes the semantics of modules\nunstable. I present Graph-based Symbolically Synthesized Neural Networks\n(G-SSNNs), a form of neural network whose topology and parameters are informed\nby the output of a symbolic program. I demonstrate that by developing symbolic\nabstractions at a population level, and applying gradient-based optimization to\nsuch neural models at an individual level, I can elicit reliable patterns of\nimproved generalization with small quantities of data known to contain local\nand discrete features. The paradigm embodied by G-SSNNs offers a route towards\nthe communal development of compact and composable abstractions which can be\nflexibly repurposed for a variety of tasks and high-dimensional media. In\nfuture work, I hope to pursue these benefits by exploring more ambitious G-SSNN\ndesigns based on more complex classes of symbolic programs. The code and data\nassociated with the reported results are publicly available at\nhttps://github.com/shlomenu/symbolically_synthesized_networks .\n","authors":["Eli Whitehouse"],"pdf_url":"https://arxiv.org/pdf/2303.03340v1.pdf","comment":"8 pages, 1 figure"},{"id":"http://arxiv.org/abs/2302.03917v2","updated":"2023-03-06T18:09:56Z","published":"2023-02-08T07:27:27Z","title":"Noise2Music: Text-conditioned Music Generation with Diffusion Models","summary":"  We introduce Noise2Music, where a series of diffusion models is trained to\ngenerate high-quality 30-second music clips from text prompts. Two types of\ndiffusion models, a generator model, which generates an intermediate\nrepresentation conditioned on text, and a cascader model, which generates\nhigh-fidelity audio conditioned on the intermediate representation and possibly\nthe text, are trained and utilized in succession to generate high-fidelity\nmusic. We explore two options for the intermediate representation, one using a\nspectrogram and the other using audio with lower fidelity. We find that the\ngenerated audio is not only able to faithfully reflect key elements of the text\nprompt such as genre, tempo, instruments, mood, and era, but goes beyond to\nground fine-grained semantics of the prompt. Pretrained large language models\nplay a key role in this story -- they are used to generate paired text for the\naudio of the training set and to extract embeddings of the text prompts\ningested by the diffusion models.\n  Generated examples: https://google-research.github.io/noise2music\n","authors":["Qingqing Huang","Daniel S. Park","Tao Wang","Timo I. Denk","Andy Ly","Nanxin Chen","Zhengdong Zhang","Zhishuai Zhang","Jiahui Yu","Christian Frank","Jesse Engel","Quoc V. Le","William Chan","Zhifeng Chen","Wei Han"],"pdf_url":"https://arxiv.org/pdf/2302.03917v2.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2303.03327v1","updated":"2023-03-06T17:54:33Z","published":"2023-03-06T17:54:33Z","title":"Lower Bounds for $γ$-Regret via the Decision-Estimation Coefficient","summary":"  In this note, we give a new lower bound for the $\\gamma$-regret in bandit\nproblems, the regret which arises when comparing against a benchmark that is\n$\\gamma$ times the optimal solution, i.e., $\\mathsf{Reg}_{\\gamma}(T) = \\sum_{t\n= 1}^T \\gamma \\max_{\\pi} f(\\pi) - f(\\pi_t)$. The $\\gamma$-regret arises in\nstructured bandit problems where finding an exact optimum of $f$ is\nintractable. Our lower bound is given in terms of a modification of the\nconstrained Decision-Estimation Coefficient (DEC) of~\\citet{foster2023tight}\n(and closely related to the original offset DEC of\n\\citet{foster2021statistical}), which we term the $\\gamma$-DEC. When restricted\nto the traditional regret setting where $\\gamma = 1$, our result removes the\nlogarithmic factors in the lower bound of \\citet{foster2023tight}.\n","authors":["Margalit Glasgow","Alexander Rakhlin"],"pdf_url":"https://arxiv.org/pdf/2303.03327v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03326v1","updated":"2023-03-06T17:53:42Z","published":"2023-03-06T17:53:42Z","title":"Keep It Simple: CNN Model Complexity Studies for Interference\n  Classification Tasks","summary":"  The growing number of devices using the wireless spectrum makes it important\nto find ways to minimize interference and optimize the use of the spectrum.\nDeep learning models, such as convolutional neural networks (CNNs), have been\nwidely utilized to identify, classify, or mitigate interference due to their\nability to learn from the data directly. However, there have been limited\nresearch on the complexity of such deep learning models. The major focus of\ndeep learning-based wireless classification literature has been on improving\nclassification accuracy, often at the expense of model complexity. This may not\nbe practical for many wireless devices, such as, internet of things (IoT)\ndevices, which usually have very limited computational resources and cannot\nhandle very complex models. Thus, it becomes important to account for model\ncomplexity when designing deep learning-based models for interference\nclassification. To address this, we conduct an analysis of CNN based wireless\nclassification that explores the trade-off amongst dataset size, CNN model\ncomplexity, and classification accuracy under various levels of classification\ndifficulty: namely, interference classification, heterogeneous transmitter\nclassification, and homogeneous transmitter classification. Our study, based on\nthree wireless datasets, shows that a simpler CNN model with fewer parameters\ncan perform just as well as a more complex model, providing important insights\ninto the use of CNNs in computationally constrained applications.\n","authors":["Taiwo Oyedare","Vijay K. Shah","Daniel J. Jakubisin","Jeffrey H. Reed"],"pdf_url":"https://arxiv.org/pdf/2303.03326v1.pdf","comment":"6 pages, 7 figures, 3 tables"},{"id":"http://arxiv.org/abs/2303.03324v1","updated":"2023-03-06T17:52:35Z","published":"2023-03-06T17:52:35Z","title":"Time series anomaly detection with sequence reconstruction based\n  state-space model","summary":"  Recent advances in digitization has led to availability of multivariate time\nseries data in various domains, in order to monitor operations in real time.\nIdentifying abnormal data pattern and detect potential failures in these\nscenarios are important yet rather difficult tasks. We propose a novel\nunsupervised anomaly detection method for time series data. Our approach uses\nsequence encoder and decoder to represent the mapping between time series and\nhidden state, and learns bidirectional dynamics simultaneously by leveraging\nbackward and forward temporal information in the training process. We further\nregularize the state space to place constraints on states of normal samples,\nand use Mahalanobis distance to evaluate abnormality level. Results on\nsynthetic and real-world datasets show the superiority of the proposed method.\n","authors":["Fan Wang","Keli Wang","Boyu Yao"],"pdf_url":"https://arxiv.org/pdf/2303.03324v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.13708v3","updated":"2023-03-06T17:48:32Z","published":"2022-09-27T21:47:23Z","title":"Falsification before Extrapolation in Causal Effect Estimation","summary":"  Randomized Controlled Trials (RCTs) represent a gold standard when developing\npolicy guidelines. However, RCTs are often narrow, and lack data on broader\npopulations of interest. Causal effects in these populations are often\nestimated using observational datasets, which may suffer from unobserved\nconfounding and selection bias. Given a set of observational estimates (e.g.\nfrom multiple studies), we propose a meta-algorithm that attempts to reject\nobservational estimates that are biased. We do so using validation effects,\ncausal effects that can be inferred from both RCT and observational data. After\nrejecting estimators that do not pass this test, we generate conservative\nconfidence intervals on the extrapolated causal effects for subgroups not\nobserved in the RCT. Under the assumption that at least one observational\nestimator is asymptotically normal and consistent for both the validation and\nextrapolated effects, we provide guarantees on the coverage probability of the\nintervals output by our algorithm. To facilitate hypothesis testing in settings\nwhere causal effect transportation across datasets is necessary, we give\nconditions under which a doubly-robust estimator of group average treatment\neffects is asymptotically normal, even when flexible machine learning methods\nare used for estimation of nuisance parameters. We illustrate the properties of\nour approach on semi-synthetic and real world datasets, and show that it\ncompares favorably to standard meta-analysis techniques.\n","authors":["Zeshan Hussain","Michael Oberst","Ming-Chieh Shih","David Sontag"],"pdf_url":"https://arxiv.org/pdf/2209.13708v3.pdf","comment":"Conference on Neural Information Processing Systems, 2022"},{"id":"http://arxiv.org/abs/2303.03323v1","updated":"2023-03-06T17:48:32Z","published":"2023-03-06T17:48:32Z","title":"CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive\n  Learning","summary":"  Multimodal contrastive pretraining has been utilized to train multimodal\nrepresentation models, like CLIP, on vast amounts of paired image-text data.\nHowever, previous studies have highlighted the susceptibility of such models to\nbackdoor attacks. Specifically, when training on backdoored examples, CLIP\nlearns spurious correlations between the embedded backdoor trigger and the\ntarget label, aligning their representations in the joint embedding space. With\ninjecting only a few poisoned examples e.g., 75 examples in the 3M pretraining\ndata, the model's behavior can be significantly manipulated, thus making it\nhard to detect or unlearn such correlations. To address this issue, we propose\nCleanCLIP, a finetuning framework that weakens the learned spurious\nassociations introduced by backdoor attacks by re-aligning the representations\nfor individual modalities independently. CleanCLIP can be employed for both\nunsupervised finetuning on paired image-text data and for supervised finetuning\non labeled image data. We demonstrate that unsupervised finetuning with a\ncombination of multimodal contrastive and unimodal self-supervised objectives\nfor individual modalities can significantly reduce the impact of the backdoor\nattack. Additionally, supervised finetuning on task-specific labeled data of\nthe individual modality, such as image data, removes the backdoor trigger from\nthe CLIP vision encoder. Empirically, we show that CleanCLIP maintains model\nperformance on benign examples while mitigating the impact of a range of\nbackdoor attacks on multimodal contrastive learning.\n","authors":["Hritik Bansal","Nishad Singhi","Yu Yang","Fan Yin","Aditya Grover","Kai-Wei Chang"],"pdf_url":"https://arxiv.org/pdf/2303.03323v1.pdf","comment":"20 pages, 7 figures, 8 tables"},{"id":"http://arxiv.org/abs/2303.03320v1","updated":"2023-03-06T17:47:04Z","published":"2023-03-06T17:47:04Z","title":"Learning to Backdoor Federated Learning","summary":"  In a federated learning (FL) system, malicious participants can easily embed\nbackdoors into the aggregated model while maintaining the model's performance\non the main task. To this end, various defenses, including training stage\naggregation-based defenses and post-training mitigation defenses, have been\nproposed recently. While these defenses obtain reasonable performance against\nexisting backdoor attacks, which are mainly heuristics based, we show that they\nare insufficient in the face of more advanced attacks. In particular, we\npropose a general reinforcement learning-based backdoor attack framework where\nthe attacker first trains a (non-myopic) attack policy using a simulator built\nupon its local data and common knowledge on the FL system, which is then\napplied during actual FL training. Our attack framework is both adaptive and\nflexible and achieves strong attack performance and durability even under\nstate-of-the-art defenses.\n","authors":["Henger Li","Chen Wu","Senchun Zhu","Zizhan Zheng"],"pdf_url":"https://arxiv.org/pdf/2303.03320v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.03669v3","updated":"2023-03-06T17:32:15Z","published":"2022-06-08T04:09:13Z","title":"Toward Certified Robustness Against Real-World Distribution Shifts","summary":"  We consider the problem of certifying the robustness of deep neural networks\nagainst real-world distribution shifts. To do so, we bridge the gap between\nhand-crafted specifications and realistic deployment settings by proposing a\nnovel neural-symbolic verification framework, in which we train a generative\nmodel to learn perturbations from data and define specifications with respect\nto the output of the learned model. A unique challenge arising from this\nsetting is that existing verifiers cannot tightly approximate sigmoid\nactivations, which are fundamental to many state-of-the-art generative models.\nTo address this challenge, we propose a general meta-algorithm for handling\nsigmoid activations which leverages classical notions of counter-example-guided\nabstraction refinement. The key idea is to \"lazily\" refine the abstraction of\nsigmoid functions to exclude spurious counter-examples found in the previous\nabstraction, thus guaranteeing progress in the verification process while\nkeeping the state-space small. Experiments on the MNIST and CIFAR-10 datasets\nshow that our framework significantly outperforms existing methods on a range\nof challenging distribution shifts.\n","authors":["Haoze Wu","Teruhiro Tagomori","Alexander Robey","Fengjun Yang","Nikolai Matni","George Pappas","Hamed Hassani","Corina Pasareanu","Clark Barrett"],"pdf_url":"https://arxiv.org/pdf/2206.03669v3.pdf","comment":"SatML'23. Keywords: certified robustness, distribution shift,\n  generative models, S-shaped activations, CEGAR"},{"id":"http://arxiv.org/abs/2303.01693v2","updated":"2023-03-06T17:26:25Z","published":"2023-03-03T03:17:53Z","title":"Cross-domain Transfer Learning and State Inference for Soft Robots via a\n  Semi-supervised Sequential Variational Bayes Framework","summary":"  Recently, data-driven models such as deep neural networks have shown to be\npromising tools for modelling and state inference in soft robots. However,\nvoluminous amounts of data are necessary for deep models to perform\neffectively, which requires exhaustive and quality data collection,\nparticularly of state labels. Consequently, obtaining labelled state data for\nsoft robotic systems is challenged for various reasons, including difficulty in\nthe sensorization of soft robots and the inconvenience of collecting data in\nunstructured environments. To address this challenge, in this paper, we propose\na semi-supervised sequential variational Bayes (DSVB) framework for transfer\nlearning and state inference in soft robots with missing state labels on\ncertain robot configurations. Considering that soft robots may exhibit distinct\ndynamics under different robot configurations, a feature space transfer\nstrategy is also incorporated to promote the adaptation of latent features\nacross multiple configurations. Unlike existing transfer learning approaches,\nour proposed DSVB employs a recurrent neural network to model the nonlinear\ndynamics and temporal coherence in soft robot data. The proposed framework is\nvalidated on multiple setup configurations of a pneumatic-based soft robot\nfinger. Experimental results on four transfer scenarios demonstrate that DSVB\nperforms effective transfer learning and accurate state inference amidst\nmissing state labels.\n","authors":["Shageenderan Sapai","Junn Yong Loo","Ze Yang Ding","Chee Pin Tan","Raphael CW Phan","Vishnu Monn Baskaran","Surya Girinatha Nurzaman"],"pdf_url":"https://arxiv.org/pdf/2303.01693v2.pdf","comment":"Accepted at the International Conference on Robotics and Automation\n  (ICRA) 2023"},{"id":"http://arxiv.org/abs/2208.08672v2","updated":"2023-03-06T17:22:50Z","published":"2022-08-18T07:11:34Z","title":"RRWaveNet: A Compact End-to-End Multi-Scale Residual CNN for Robust PPG\n  Respiratory Rate Estimation","summary":"  Respiratory rate (RR) is an important biomarker as RR changes can reflect\nsevere medical events such as heart disease, lung disease, and sleep disorders.\nUnfortunately, standard manual RR counting is prone to human error and cannot\nbe performed continuously. This study proposes a method for continuously\nestimating RR, RRWaveNet. The method is a compact end-to-end deep learning\nmodel which does not require feature engineering and can use low-cost raw\nphotoplethysmography (PPG) as input signal. RRWaveNet was tested\nsubject-independently and compared to baseline in four datasets (BIDMC,\nCapnoBase, WESAD, and SensAI) and using three window sizes (16, 32, and 64\nseconds). RRWaveNet outperformed current state-of-the-art methods with mean\nabsolute errors at optimal window size of 1.66 \\pm 1.01, 1.59 \\pm 1.08, 1.92\n\\pm 0.96 and 1.23 \\pm 0.61 breaths per minute for each dataset. In remote\nmonitoring settings, such as in the WESAD and SensAI datasets, we apply\ntransfer learning to improve the performance using two other ICU datasets as\npretraining datasets, reducing the MAE by up to 21$\\%$. This shows that this\nmodel allows accurate and practical estimation of RR on affordable and wearable\ndevices. Our study also shows feasibility of remote RR monitoring in the\ncontext of telemedicine and at home.\n","authors":["Pongpanut Osathitporn","Guntitat Sawadwuthikul","Punnawish Thuwajit","Kawisara Ueafuea","Thee Mateepithaktham","Narin Kunaseth","Tanut Choksatchawathi","Proadpran Punyabukkana","Emmanuel Mignot","Theerawit Wilaiprasitporn"],"pdf_url":"https://arxiv.org/pdf/2208.08672v2.pdf","comment":"11 pages, 8 figures"},{"id":"http://arxiv.org/abs/2303.03300v1","updated":"2023-03-06T17:19:23Z","published":"2023-03-06T17:19:23Z","title":"Weight Perturbation Can Help Fairness under Distribution Shift","summary":"  Fairness in machine learning has attracted increasing attention in recent\nyears. The fairness methods improving algorithmic fairness for in-distribution\ndata may not perform well under distribution shift. In this paper, we first\ntheoretically demonstrate the inherent connection between distribution shift,\ndata perturbation, and weight perturbation. Subsequently, we analyze the\nsufficient conditions to guarantee fairness (i.e., low demographic parity) for\nthe target dataset, including fairness for the source dataset, and low\nprediction difference between the source and target dataset for each sensitive\nattribute group. Motivated by these sufficient conditions, we propose robust\nfairness regularization (RFR) by considering the worst case within the weight\nperturbation ball for each sensitive attribute group. In this way, the\nmaximization problem can be simplified as two forward and two backward\npropagations for each update of model parameters. We evaluate the effectiveness\nof our proposed RFR algorithm on synthetic and real distribution shifts across\nvarious datasets. Experimental results demonstrate that RFR achieves better\nfairness-accuracy trade-off performance compared with several baselines.\n","authors":["Zhimeng Jiang","Xiaotian Han","Hongye Jin","Guanchu Wang","Na Zou","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2303.03300v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.13133v2","updated":"2023-03-06T17:18:03Z","published":"2023-01-30T18:16:16Z","title":"Falsification of Internal and External Validity in Observational Studies\n  via Conditional Moment Restrictions","summary":"  Randomized Controlled Trials (RCT)s are relied upon to assess new treatments,\nbut suffer from limited power to guide personalized treatment decisions. On the\nother hand, observational (i.e., non-experimental) studies have large and\ndiverse populations, but are prone to various biases (e.g. residual\nconfounding). To safely leverage the strengths of observational studies, we\nfocus on the problem of falsification, whereby RCTs are used to validate causal\neffect estimates learned from observational data. In particular, we show that,\ngiven data from both an RCT and an observational study, assumptions on internal\nand external validity have an observable, testable implication in the form of a\nset of Conditional Moment Restrictions (CMRs). Further, we show that expressing\nthese CMRs with respect to the causal effect, or \"causal contrast\", as opposed\nto individual counterfactual means, provides a more reliable falsification\ntest. In addition to giving guarantees on the asymptotic properties of our\ntest, we demonstrate superior power and type I error of our approach on\nsemi-synthetic and real world datasets. Our approach is interpretable, allowing\na practitioner to visualize which subgroups in the population lead to\nfalsification of an observational study.\n","authors":["Zeshan Hussain","Ming-Chieh Shih","Michael Oberst","Ilker Demirel","David Sontag"],"pdf_url":"https://arxiv.org/pdf/2301.13133v2.pdf","comment":"Artificial Intelligence and Statistics 2023"},{"id":"http://arxiv.org/abs/2303.03293v1","updated":"2023-03-06T17:09:48Z","published":"2023-03-06T17:09:48Z","title":"HiGeN: Hierarchical Multi-Resolution Graph Generative Networks","summary":"  In real world domains, most graphs naturally exhibit a hierarchical\nstructure. However, data-driven graph generation is yet to effectively capture\nsuch structures. To address this, we propose a novel approach that recursively\ngenerates community structures at multiple resolutions, with the generated\nstructures conforming to training data distribution at each level of the\nhierarchy. The graphs generation is designed as a sequence of coarse-to-fine\ngenerative models allowing for parallel generation of all sub-structures,\nresulting in a high degree of scalability. Furthermore, we model the output\ndistribution of edges with a more expressive multinomial distribution and\nderive a recursive factorization for this distribution, making it a suitable\nchoice for graph generative models. This allows for the generation of graphs\nwith integer-valued edge weights. Our method achieves state-of-the-art\nperformance in both accuracy and efficiency on multiple datasets.\n","authors":["Mahdi Karami","Jun Luo"],"pdf_url":"https://arxiv.org/pdf/2303.03293v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03284v1","updated":"2023-03-06T16:59:14Z","published":"2023-03-06T16:59:14Z","title":"The Wasserstein Believer: Learning Belief Updates for Partially\n  Observable Environments through Reliable Latent Space Models","summary":"  Partially Observable Markov Decision Processes (POMDPs) are useful tools to\nmodel environments where the full state cannot be perceived by an agent. As\nsuch the agent needs to reason taking into account the past observations and\nactions. However, simply remembering the full history is generally intractable\ndue to the exponential growth in the history space. Keeping a probability\ndistribution that models the belief over what the true state is can be used as\na sufficient statistic of the history, but its computation requires access to\nthe model of the environment and is also intractable. Current state-of-the-art\nalgorithms use Recurrent Neural Networks (RNNs) to compress the\nobservation-action history aiming to learn a sufficient statistic, but they\nlack guarantees of success and can lead to suboptimal policies. To overcome\nthis, we propose the Wasserstein-Belief-Updater (WBU), an RL algorithm that\nlearns a latent model of the POMDP and an approximation of the belief update.\nOur approach comes with theoretical guarantees on the quality of our\napproximation ensuring that our outputted beliefs allow for learning the\noptimal value function.\n","authors":["Raphael Avalos","Florent Delgrange","Ann Nowé","Guillermo A. Pérez","Diederik M. Roijers"],"pdf_url":"https://arxiv.org/pdf/2303.03284v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01704v2","updated":"2023-03-06T16:52:19Z","published":"2023-03-03T04:12:04Z","title":"Model Explanation Disparities as a Fairness Diagnostic","summary":"  In recent years, there has been a flurry of research focusing on the fairness\nof machine learning models, and in particular on quantifying and eliminating\nbias against protected subgroups. One line of work generalizes the notion of\nprotected subgroups beyond simple discrete classes by introducing the notion of\na \"rich subgroup\", and seeks to train models that are calibrated or equalize\nerror rates with respect to these richer subgroup classes. Largely\northogonally, local model explanation methods have been developed that given a\nclassifier h and test point x, attribute influence for the prediction h(x) to\nthe individual features of x. This raises a natural question: Do local model\nexplanation methods attribute different feature importance values on average\nacross different protected subgroups, and can we detect these disparities\nefficiently? If the model places high weight on a given feature in a specific\nprotected subgroup, but not on the dataset overall (or vice versa), this could\nbe a potential indicator of bias in the predictive model or the underlying data\ngenerating process, and is at the very least a useful diagnostic that signals\nthe need for a domain expert to delve deeper. In this paper, we formally\nintroduce the notion of feature importance disparity (FID) in the context of\nrich subgroups, design oracle-efficent algorithms to identify large FID\nsubgroups, and conduct a thorough empirical analysis that establishes auditing\nfor FID as an important method to investigate dataset bias. Our experiments\nshow that across 4 datasets and 4 common feature importance methods our\nalgorithms find (feature, subgroup) pairs that simultaneously: (i) have\nsubgroup feature importance that is often an order of magnitude different than\nthe importance on the dataset as a whole (ii) generalize out of sample, and\n(iii) yield interesting discussions about potential bias inherent in these\ndatasets.\n","authors":["Peter W. Chang","Leor Fishman","Seth Neel"],"pdf_url":"https://arxiv.org/pdf/2303.01704v2.pdf","comment":"13 pages, 6 figures. Appendix: 8 pages, 4 figures. Replacement info:\n  minor changes to match metadata abstract to paper abstract"},{"id":"http://arxiv.org/abs/2303.03278v1","updated":"2023-03-06T16:49:27Z","published":"2023-03-06T16:49:27Z","title":"Faithfulness-Aware Decoding Strategies for Abstractive Summarization","summary":"  Despite significant progress in understanding and improving faithfulness in\nabstractive summarization, the question of how decoding strategies affect\nfaithfulness is less studied. We present a systematic study of the effect of\ngeneration techniques such as beam search and nucleus sampling on faithfulness\nin abstractive summarization. We find a consistent trend where beam search with\nlarge beam sizes produces the most faithful summaries while nucleus sampling\ngenerates the least faithful ones. We propose two faithfulness-aware generation\nmethods to further improve faithfulness over current generation techniques: (1)\nranking candidates generated by beam search using automatic faithfulness\nmetrics and (2) incorporating lookahead heuristics that produce a faithfulness\nscore on the future summary. We show that both generation methods significantly\nimprove faithfulness across two datasets as evaluated by four automatic\nfaithfulness metrics and human evaluation. To reduce computational cost, we\ndemonstrate a simple distillation approach that allows the model to generate\nfaithful summaries with just greedy decoding. Our code is publicly available at\nhttps://github.com/amazon-science/faithful-summarization-generation\n","authors":["David Wan","Mengwen Liu","Kathleen McKeown","Markus Dreyer","Mohit Bansal"],"pdf_url":"https://arxiv.org/pdf/2303.03278v1.pdf","comment":"EACL 2023 (17 pages)"},{"id":"http://arxiv.org/abs/2303.03192v1","updated":"2023-03-06T16:47:59Z","published":"2023-03-06T16:47:59Z","title":"Deep symbolic regression for physics guided by units constraints: toward\n  the automated discovery of physical laws","summary":"  Symbolic Regression is the study of algorithms that automate the search for\nanalytic expressions that fit data. While recent advances in deep learning have\ngenerated renewed interest in such approaches, efforts have not been focused on\nphysics, where we have important additional constraints due to the units\nassociated with our data. Here we present $\\Phi$-SO, a Physical Symbolic\nOptimization framework for recovering analytical symbolic expressions from\nphysics data using deep reinforcement learning techniques by learning units\nconstraints. Our system is built, from the ground up, to propose solutions\nwhere the physical units are consistent by construction. This is useful not\nonly in eliminating physically impossible solutions, but because it restricts\nenormously the freedom of the equation generator, thus vastly improving\nperformance. The algorithm can be used to fit noiseless data, which can be\nuseful for instance when attempting to derive an analytical property of a\nphysical model, and it can also be used to obtain analytical approximations to\nnoisy data. We showcase our machinery on a panel of examples from astrophysics.\n","authors":["Wassim Tenachi","Rodrigo Ibata","Foivos I. Diakogiannis"],"pdf_url":"https://arxiv.org/pdf/2303.03192v1.pdf","comment":"16 pages, 6 figures, 2 tables. Submitted to ApJ"},{"id":"http://arxiv.org/abs/2303.03272v1","updated":"2023-03-06T16:41:57Z","published":"2023-03-06T16:41:57Z","title":"Accelerated Rates between Stochastic and Adversarial Online Convex\n  Optimization","summary":"  Stochastic and adversarial data are two widely studied settings in online\nlearning. But many optimization tasks are neither i.i.d. nor fully adversarial,\nwhich makes it of fundamental interest to get a better theoretical\nunderstanding of the world between these extremes. In this work we establish\nnovel regret bounds for online convex optimization in a setting that\ninterpolates between stochastic i.i.d. and fully adversarial losses. By\nexploiting smoothness of the expected losses, these bounds replace a dependence\non the maximum gradient length by the variance of the gradients, which was\npreviously known only for linear losses. In addition, they weaken the i.i.d.\nassumption by allowing, for example, adversarially poisoned rounds, which were\npreviously considered in the related expert and bandit settings. In the fully\ni.i.d. case, our regret bounds match the rates one would expect from results in\nstochastic acceleration, and we also recover the optimal stochastically\naccelerated rates via online-to-batch conversion. In the fully adversarial case\nour bounds gracefully deteriorate to match the minimax regret. We further\nprovide lower bounds showing that our regret upper bounds are tight for all\nintermediate regimes in terms of the stochastic variance and the adversarial\nvariation of the loss gradients.\n","authors":["Sarah Sachs","Hedi Hadiji","Tim van Erven","Cristobal Guzman"],"pdf_url":"https://arxiv.org/pdf/2303.03272v1.pdf","comment":"Extended version of 'Between Stochastic and Adversarial Online Convex\n  Optimization: Improved Regret Bounds via Smoothness' by the same authors.\n  arXiv admin note: text overlap with arXiv:2202.07554"},{"id":"http://arxiv.org/abs/2207.04154v4","updated":"2023-03-06T16:37:49Z","published":"2022-07-08T23:42:56Z","title":"TalkToModel: Explaining Machine Learning Models with Interactive Natural\n  Language Conversations","summary":"  Machine Learning (ML) models are increasingly used to make critical decisions\nin real-world applications, yet they have become more complex, making them\nharder to understand. To this end, researchers have proposed several techniques\nto explain model predictions. However, practitioners struggle to use these\nexplainability techniques because they often do not know which one to choose\nand how to interpret the results of the explanations. In this work, we address\nthese challenges by introducing TalkToModel: an interactive dialogue system for\nexplaining machine learning models through conversations. Specifically,\nTalkToModel comprises of three key components: 1) a natural language interface\nfor engaging in conversations, making ML model explainability highly\naccessible, 2) a dialogue engine that adapts to any tabular model and dataset,\ninterprets natural language, maps it to appropriate explanations, and generates\ntext responses, and 3) an execution component that constructs the explanations.\nWe carried out extensive quantitative and human subject evaluations of\nTalkToModel. Overall, we found the conversational system understands user\ninputs on novel datasets and models with high accuracy, demonstrating the\nsystem's capacity to generalize to new situations. In real-world evaluations\nwith humans, 73% of healthcare workers (e.g., doctors and nurses) agreed they\nwould use TalkToModel over baseline point-and-click systems for explainability\nin a disease prediction task, and 85% of ML professionals agreed TalkToModel\nwas easier to use for computing explanations. Our findings demonstrate that\nTalkToModel is more effective for model explainability than existing systems,\nintroducing a new category of explainability tools for practitioners. Code &\ndemo released here: https://github.com/dylan-slack/TalkToModel.\n","authors":["Dylan Slack","Satyapriya Krishna","Himabindu Lakkaraju","Sameer Singh"],"pdf_url":"https://arxiv.org/pdf/2207.04154v4.pdf","comment":"Pre-print; comments welcome! Reach out to dslack@uci.edu v3 update\n  title and abstract"},{"id":"http://arxiv.org/abs/2303.03254v1","updated":"2023-03-06T16:17:19Z","published":"2023-03-06T16:17:19Z","title":"An Online Algorithm for Chance Constrained Resource Allocation","summary":"  This paper studies the online stochastic resource allocation problem (RAP)\nwith chance constraints. The online RAP is a 0-1 integer linear programming\nproblem where the resource consumption coefficients are revealed column by\ncolumn along with the corresponding revenue coefficients. When a column is\nrevealed, the corresponding decision variables are determined instantaneously\nwithout future information. Moreover, in online applications, the resource\nconsumption coefficients are often obtained by prediction. To model their\nuncertainties, we take the chance constraints into the consideration. To the\nbest of our knowledge, this is the first time chance constraints are introduced\nin the online RAP problem. Assuming that the uncertain variables have known\nGaussian distributions, the stochastic RAP can be transformed into a\ndeterministic but nonlinear problem with integer second-order cone constraints.\nNext, we linearize this nonlinear problem and analyze the performance of\nvanilla online primal-dual algorithm for solving the linearized stochastic RAP.\nUnder mild technical assumptions, the optimality gap and constraint violation\nare both on the order of $\\sqrt{n}$. Then, to further improve the performance\nof the algorithm, several modified online primal-dual algorithms with heuristic\ncorrections are proposed. Finally, extensive numerical experiments on both\nsynthetic and real data demonstrate the applicability and effectiveness of our\nmethods.\n","authors":["Yuwei Chen","Zengde Deng","Yinzhi Zhou","Zaiyi Chen","Yujie Chen","Haoyuan Hu"],"pdf_url":"https://arxiv.org/pdf/2303.03254v1.pdf","comment":"5 pages, 5 figures. Accepted to ICASSP 2023. arXiv admin note:\n  substantial text overlap with arXiv:2203.16818"},{"id":"http://arxiv.org/abs/2206.02307v2","updated":"2023-03-06T16:08:39Z","published":"2022-06-06T01:30:03Z","title":"Bootstrapping Semi-supervised Medical Image Segmentation with\n  Anatomical-aware Contrastive Distillation","summary":"  Contrastive learning has shown great promise over annotation scarcity\nproblems in the context of medical image segmentation. Existing approaches\ntypically assume a balanced class distribution for both labeled and unlabeled\nmedical images. However, medical image data in reality is commonly imbalanced\n(i.e., multi-class label imbalance), which naturally yields blurry contours and\nusually incorrectly labels rare objects. Moreover, it remains unclear whether\nall negative samples are equally negative. In this work, we present ACTION, an\nAnatomical-aware ConTrastive dIstillatiON framework, for semi-supervised\nmedical image segmentation. Specifically, we first develop an iterative\ncontrastive distillation algorithm by softly labeling the negatives rather than\nbinary supervision between positive and negative pairs. We also capture more\nsemantically similar features from the randomly chosen negative set compared to\nthe positives to enforce the diversity of the sampled data. Second, we raise a\nmore important question: Can we really handle imbalanced samples to yield\nbetter performance? Hence, the key innovation in ACTION is to learn global\nsemantic relationship across the entire dataset and local anatomical features\namong the neighbouring pixels with minimal additional memory footprint. During\nthe training, we introduce anatomical contrast by actively sampling a sparse\nset of hard negative pixels, which can generate smoother segmentation\nboundaries and more accurate predictions. Extensive experiments across two\nbenchmark datasets and different unlabeled settings show that ACTION\nsignificantly outperforms the current state-of-the-art semi-supervised methods.\n","authors":["Chenyu You","Weicheng Dai","Yifei Min","Lawrence Staib","James S. Duncan"],"pdf_url":"https://arxiv.org/pdf/2206.02307v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.08529v2","updated":"2023-03-06T16:08:29Z","published":"2022-06-17T03:24:45Z","title":"Accelerating Shapley Explanation via Contributive Cooperator Selection","summary":"  Even though Shapley value provides an effective explanation for a DNN model\nprediction, the computation relies on the enumeration of all possible input\nfeature coalitions, which leads to the exponentially growing complexity. To\naddress this problem, we propose a novel method SHEAR to significantly\naccelerate the Shapley explanation for DNN models, where only a few coalitions\nof input features are involved in the computation. The selection of the feature\ncoalitions follows our proposed Shapley chain rule to minimize the absolute\nerror from the ground-truth Shapley values, such that the computation can be\nboth efficient and accurate. To demonstrate the effectiveness, we\ncomprehensively evaluate SHEAR across multiple metrics including the absolute\nerror from the ground-truth Shapley value, the faithfulness of the\nexplanations, and running speed. The experimental results indicate SHEAR\nconsistently outperforms state-of-the-art baseline methods across different\nevaluation metrics, which demonstrates its potentials in real-world\napplications where the computational resource is limited.\n","authors":["Guanchu Wang","Yu-Neng Chuang","Mengnan Du","Fan Yang","Quan Zhou","Pushkar Tripathi","Xuanting Cai","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2206.08529v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03242v1","updated":"2023-03-06T16:01:30Z","published":"2023-03-06T16:01:30Z","title":"Evaluating the Fairness of Deep Learning Uncertainty Estimates in\n  Medical Image Analysis","summary":"  Although deep learning (DL) models have shown great success in many medical\nimage analysis tasks, deployment of the resulting models into real clinical\ncontexts requires: (1) that they exhibit robustness and fairness across\ndifferent sub-populations, and (2) that the confidence in DL model predictions\nbe accurately expressed in the form of uncertainties. Unfortunately, recent\nstudies have indeed shown significant biases in DL models across demographic\nsubgroups (e.g., race, sex, age) in the context of medical image analysis,\nindicating a lack of fairness in the models. Although several methods have been\nproposed in the ML literature to mitigate a lack of fairness in DL models, they\nfocus entirely on the absolute performance between groups without considering\ntheir effect on uncertainty estimation. In this work, we present the first\nexploration of the effect of popular fairness models on overcoming biases\nacross subgroups in medical image analysis in terms of bottom-line performance,\nand their effects on uncertainty quantification. We perform extensive\nexperiments on three different clinically relevant tasks: (i) skin lesion\nclassification, (ii) brain tumour segmentation, and (iii) Alzheimer's disease\nclinical score regression. Our results indicate that popular ML methods, such\nas data-balancing and distributionally robust optimization, succeed in\nmitigating fairness issues in terms of the model performances for some of the\ntasks. However, this can come at the cost of poor uncertainty estimates\nassociated with the model predictions. This tradeoff must be mitigated if\nfairness models are to be adopted in medical image analysis.\n","authors":["Raghav Mehta","Changjian Shui","Tal Arbel"],"pdf_url":"https://arxiv.org/pdf/2303.03242v1.pdf","comment":"Paper accepted at MIDL 2023"},{"id":"http://arxiv.org/abs/2212.00424v2","updated":"2023-03-06T16:00:25Z","published":"2022-12-01T10:55:22Z","title":"Multi-Source Survival Domain Adaptation","summary":"  Survival analysis is the branch of statistics that studies the relation\nbetween the characteristics of living entities and their respective survival\ntimes, taking into account the partial information held by censored cases. A\ngood analysis can, for example, determine whether one medical treatment for a\ngroup of patients is better than another. With the rise of machine learning,\nsurvival analysis can be modeled as learning a function that maps studied\npatients to their survival times. To succeed with that, there are three crucial\nissues to be tackled. First, some patient data is censored: we do not know the\ntrue survival times for all patients. Second, data is scarce, which led past\nresearch to treat different illness types as domains in a multi-task setup.\nThird, there is the need for adaptation to new or extremely rare illness types,\nwhere little or no labels are available. In contrast to previous multi-task\nsetups, we want to investigate how to efficiently adapt to a new survival\ntarget domain from multiple survival source domains. For this, we introduce a\nnew survival metric and the corresponding discrepancy measure between survival\ndistributions. These allow us to define domain adaptation for survival analysis\nwhile incorporating censored data, which would otherwise have to be dropped.\nOur experiments on two cancer data sets reveal a superb performance on target\ndomains, a better treatment recommendation, and a weight matrix with a\nplausible explanation.\n","authors":["Ammar Shaker","Carolin Lawrence"],"pdf_url":"https://arxiv.org/pdf/2212.00424v2.pdf","comment":"37th AAAI Conference on Artificial Intelligence, 2023. Includes\n  Appendix"},{"id":"http://arxiv.org/abs/2303.03237v1","updated":"2023-03-06T15:53:44Z","published":"2023-03-06T15:53:44Z","title":"Convergence Rates for Non-Log-Concave Sampling and Log-Partition\n  Estimation","summary":"  Sampling from Gibbs distributions $p(x) \\propto \\exp(-V(x)/\\varepsilon)$ and\ncomputing their log-partition function are fundamental tasks in statistics,\nmachine learning, and statistical physics. However, while efficient algorithms\nare known for convex potentials $V$, the situation is much more difficult in\nthe non-convex case, where algorithms necessarily suffer from the curse of\ndimensionality in the worst case. For optimization, which can be seen as a\nlow-temperature limit of sampling, it is known that smooth functions $V$ allow\nfaster convergence rates. Specifically, for $m$-times differentiable functions\nin $d$ dimensions, the optimal rate for algorithms with $n$ function\nevaluations is known to be $O(n^{-m/d})$, where the constant can potentially\ndepend on $m, d$ and the function to be optimized. Hence, the curse of\ndimensionality can be alleviated for smooth functions at least in terms of the\nconvergence rate. Recently, it has been shown that similarly fast rates can\nalso be achieved with polynomial runtime $O(n^{3.5})$, where the exponent $3.5$\nis independent of $m$ or $d$. Hence, it is natural to ask whether similar rates\nfor sampling and log-partition computation are possible, and whether they can\nbe realized in polynomial time with an exponent independent of $m$ and $d$. We\nshow that the optimal rates for sampling and log-partition computation are\nsometimes equal and sometimes faster than for optimization. We then analyze\nvarious polynomial-time sampling algorithms, including an extension of a recent\npromising optimization approach, and find that they sometimes exhibit\ninteresting behavior but no near-optimal rates. Our results also give further\ninsights on the relation between sampling, log-partition, and optimization\nproblems.\n","authors":["David Holzmüller","Francis Bach"],"pdf_url":"https://arxiv.org/pdf/2303.03237v1.pdf","comment":"Plots can be reproduced using the code at\n  https://github.com/dholzmueller/sampling_experiments"},{"id":"http://arxiv.org/abs/2301.09604v2","updated":"2023-03-06T15:52:24Z","published":"2023-01-23T18:10:22Z","title":"FedExP: Speeding Up Federated Averaging via Extrapolation","summary":"  Federated Averaging (FedAvg) remains the most popular algorithm for Federated\nLearning (FL) optimization due to its simple implementation, stateless nature,\nand privacy guarantees combined with secure aggregation. Recent work has sought\nto generalize the vanilla averaging in FedAvg to a generalized gradient descent\nstep by treating client updates as pseudo-gradients and using a server step\nsize. While the use of a server step size has been shown to provide performance\nimprovement theoretically, the practical benefit of the server step size has\nnot been seen in most existing works. In this work, we present FedExP, a method\nto adaptively determine the server step size in FL based on dynamically varying\npseudo-gradients throughout the FL process. We begin by considering the\noverparameterized convex regime, where we reveal an interesting similarity\nbetween FedAvg and the Projection Onto Convex Sets (POCS) algorithm. We then\nshow how FedExP can be motivated as a novel extension to the extrapolation\nmechanism that is used to speed up POCS. Our theoretical analysis later also\ndiscusses the implications of FedExP in underparameterized and non-convex\nsettings. Experimental results show that FedExP consistently converges faster\nthan FedAvg and competing baselines on a range of realistic FL datasets.\n","authors":["Divyansh Jhunjhunwala","Shiqiang Wang","Gauri Joshi"],"pdf_url":"https://arxiv.org/pdf/2301.09604v2.pdf","comment":"Accepted to ICLR 2023. V2 fixes minor typos and cleans up proofs"},{"id":"http://arxiv.org/abs/2303.03227v1","updated":"2023-03-06T15:45:28Z","published":"2023-03-06T15:45:28Z","title":"Parallel Hybrid Networks: an interplay between quantum and classical\n  neural networks","summary":"  Quantum neural networks represent a new machine learning paradigm that has\nrecently attracted much attention due to its potential promise. Under certain\nconditions, these models approximate the distribution of their dataset with a\ntruncated Fourier series. The trigonometric nature of this fit could result in\nangle-embedded quantum neural networks struggling to fit the non-harmonic\nfeatures in a given dataset. Moreover, the interpretability of neural networks\nremains a challenge. In this work, we introduce a new, interpretable class of\nhybrid quantum neural networks that pass the inputs of the dataset in parallel\nto 1) a classical multi-layered perceptron and 2) a variational quantum\ncircuit, and then the outputs of the two are linearly combined. We observe that\nthe quantum neural network creates a smooth sinusoidal foundation base on the\ntraining set, and then the classical perceptrons fill the non-harmonic gaps in\nthe landscape. We demonstrate this claim on two synthetic datasets sampled from\nperiodic distributions with added protrusions as noise. The training results\nindicate that the parallel hybrid network architecture could improve the\nsolution optimality on periodic datasets with additional noise.\n","authors":["Mohammad Kordzanganeh","Daria Kosichkina","Alexey Melnikov"],"pdf_url":"https://arxiv.org/pdf/2303.03227v1.pdf","comment":"8 pages, 6 figures"},{"id":"http://arxiv.org/abs/2303.03226v1","updated":"2023-03-06T15:43:41Z","published":"2023-03-06T15:43:41Z","title":"Safe Reinforcement Learning via Probabilistic Logic Shields","summary":"  Safe Reinforcement learning (Safe RL) aims at learning optimal policies while\nstaying safe. A popular solution to Safe RL is shielding, which uses a logical\nsafety specification to prevent an RL agent from taking unsafe actions.\nHowever, traditional shielding techniques are difficult to integrate with\ncontinuous, end-to-end deep RL methods. To this end, we introduce Probabilistic\nLogic Policy Gradient (PLPG). PLPG is a model-based Safe RL technique that uses\nprobabilistic logic programming to model logical safety constraints as\ndifferentiable functions. Therefore, PLPG can be seamlessly applied to any\npolicy gradient algorithm while still providing the same convergence\nguarantees. In our experiments, we show that PLPG learns safer and more\nrewarding policies compared to other state-of-the-art shielding techniques.\n","authors":["Wen-Chi Yang","Giuseppe Marra","Gavin Rens","Luc De Raedt"],"pdf_url":"https://arxiv.org/pdf/2303.03226v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14028v3","updated":"2023-03-06T15:37:40Z","published":"2022-11-25T11:02:33Z","title":"Automata Cascades: Expressivity and Sample Complexity","summary":"  Every automaton can be decomposed into a cascade of basic prime automata.\nThis is the Prime Decomposition Theorem by Krohn and Rhodes. Guided by this\ntheory, we propose automata cascades as a structured, modular, way to describe\nautomata as complex systems made of many components, each implementing a\nspecific functionality. Any automaton can serve as a component; using specific\ncomponents allows for a fine-grained control of the expressivity of the\nresulting class of automata; using prime automata as components implies\nspecific expressivity guarantees. Moreover, specifying automata as cascades\nallows for describing the sample complexity of automata in terms of their\ncomponents. We show that the sample complexity is linear in the number of\ncomponents and the maximum complexity of a single component, modulo logarithmic\nfactors. This opens to the possibility of learning automata representing large\ndynamical systems consisting of many parts interacting with each other. It is\nin sharp contrast with the established understanding of the sample complexity\nof automata, described in terms of the overall number of states and input\nletters, which implies that it is only possible to learn automata where the\nnumber of states is linear in the amount of data available. Instead our results\nshow that one can learn automata with a number of states that is exponential in\nthe amount of data available.\n","authors":["Alessandro Ronca","Nadezda Alexandrovna Knorozova","Giuseppe De Giacomo"],"pdf_url":"https://arxiv.org/pdf/2211.14028v3.pdf","comment":"Full version with appendix of a paper with the same title that\n  appears in the proceedings of AAAI 2023"},{"id":"http://arxiv.org/abs/2203.02928v2","updated":"2023-03-06T15:26:24Z","published":"2022-03-06T10:14:09Z","title":"Evaluation of Interpretability Methods and Perturbation Artifacts in\n  Deep Neural Networks","summary":"  Despite excellent performance of deep neural networks (DNNs) in image\nclassification, detection, and prediction, characterizing how DNNs make a given\ndecision remains an open problem, resulting in a number of interpretability\nmethods. Post-hoc interpretability methods primarily aim to quantify the\nimportance of input features with respect to the class probabilities. However,\ndue to the lack of ground truth and the existence of interpretability methods\nwith diverse operating characteristics, evaluating these methods is a crucial\nchallenge. A popular approach to evaluate interpretability methods is to\nperturb input features deemed important for a given prediction and observe the\ndecrease in accuracy. However, perturbation itself may introduce artifacts,\nsince perturbed images may be out-of-distribution (OOD). In this paper, we have\nconducted computational experiments to estimate the contribution of\nperturbation artifacts and developed a method to estimate the fidelity of\ninterpretability methods. We demonstrate that, while perturbation artifacts\nindeed exist, we can minimize and characterize their impact on fidelity\nestimation by utilizing model accuracy curves from perturbing input features\naccording to the Most Import First (MIF) and Least Import First (LIF) orders.\nUsing the ResNet-50 trained on the ImageNet, we demonstrate the proposed\nfidelity estimation of four popular post-hoc interpretability methods.\n","authors":["Lennart Brocki","Neo Christopher Chung"],"pdf_url":"https://arxiv.org/pdf/2203.02928v2.pdf","comment":"26 pages, 9 figures"},{"id":"http://arxiv.org/abs/2302.05698v2","updated":"2023-03-06T15:24:56Z","published":"2023-02-11T14:02:08Z","title":"Compositional Exemplars for In-context Learning","summary":"  Large pretrained language models (LMs) have shown impressive In-Context\nLearning (ICL) ability, where the model learns to do an unseen task via a\nprompt consisting of input-output examples as the demonstration, without any\nparameter updates. The performance of ICL is highly dominated by the quality of\nthe selected in-context examples. However, previous selection methods are\nmostly based on simple heuristics, leading to sub-optimal performance. In this\nwork, we formulate in-context example selection as a subset selection problem.\nWe propose CEIL (Compositional Exemplars for In-context Learning), which is\ninstantiated by Determinantal Point Processes (DPPs) to model the interaction\nbetween the given input and in-context examples, and optimized through a\ncarefully-designed contrastive learning objective to obtain preference from\nLMs. We validate CEIL on 12 classification and generation datasets from 7\ndistinct NLP tasks, including sentiment analysis, paraphrase detection, natural\nlanguage inference, commonsense reasoning, open-domain question answering, code\ngeneration, and semantic parsing. Extensive experiments demonstrate not only\nthe state-of-the-art performance but also the transferability and\ncompositionality of CEIL, shedding new light on effective and efficient\nin-context learning. Our code is released at\nhttps://github.com/HKUNLP/icl-ceil.\n","authors":["Jiacheng Ye","Zhiyong Wu","Jiangtao Feng","Tao Yu","Lingpeng Kong"],"pdf_url":"https://arxiv.org/pdf/2302.05698v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.13924v2","updated":"2023-03-06T15:24:28Z","published":"2022-05-27T12:04:07Z","title":"Lifting the Information Ratio: An Information-Theoretic Analysis of\n  Thompson Sampling for Contextual Bandits","summary":"  We study the Bayesian regret of the renowned Thompson Sampling algorithm in\ncontextual bandits with binary losses and adversarially-selected contexts. We\nadapt the information-theoretic perspective of \\cite{RvR16} to the contextual\nsetting by considering a lifted version of the information ratio defined in\nterms of the unknown model parameter instead of the optimal action or optimal\npolicy as done in previous works on the same setting. This allows us to bound\nthe regret in terms of the entropy of the prior distribution through a\nremarkably simple proof, and with no structural assumptions on the likelihood\nor the prior. The extension to priors with infinite entropy only requires a\nLipschitz assumption on the log-likelihood. An interesting special case is that\nof logistic bandits with $d$-dimensional parameters, $K$ actions, and Lipschitz\nlogits, for which we provide a $\\widetilde{O}(\\sqrt{dKT})$ regret upper-bound\nthat does not depend on the smallest slope of the sigmoid link function.\n","authors":["Gergely Neu","Julia Olkhovskaya","Matteo Papini","Ludovic Schwartz"],"pdf_url":"https://arxiv.org/pdf/2205.13924v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2109.07340v2","updated":"2023-03-06T15:09:17Z","published":"2021-09-15T14:52:44Z","title":"Distribution-free Contextual Dynamic Pricing","summary":"  Contextual dynamic pricing aims to set personalized prices based on\nsequential interactions with customers. At each time period, a customer who is\ninterested in purchasing a product comes to the platform. The customer's\nvaluation for the product is a linear function of contexts, including product\nand customer features, plus some random market noise. The seller does not\nobserve the customer's true valuation, but instead needs to learn the valuation\nby leveraging contextual information and historical binary purchase feedbacks.\nExisting models typically assume full or partial knowledge of the random noise\ndistribution. In this paper, we consider contextual dynamic pricing with\nunknown random noise in the valuation model. Our distribution-free pricing\npolicy learns both the contextual function and the market noise simultaneously.\nA key ingredient of our method is a novel perturbed linear bandit framework,\nwhere a modified linear upper confidence bound algorithm is proposed to balance\nthe exploration of market noise and the exploitation of the current knowledge\nfor better pricing. We establish the regret upper bound and a matching lower\nbound of our policy in the perturbed linear bandit framework and prove a\nsub-linear regret bound in the considered pricing problem. Finally, we\ndemonstrate the superior performance of our policy on simulations and a\nreal-life auto-loan dataset.\n","authors":["Yiyun Luo","Will Wei Sun","and Yufeng Liu"],"pdf_url":"https://arxiv.org/pdf/2109.07340v2.pdf","comment":"Accepted by Mathematics of Operations Research"},{"id":"http://arxiv.org/abs/2201.12733v4","updated":"2023-03-06T14:58:48Z","published":"2022-01-30T05:41:50Z","title":"TPC: Transformation-Specific Smoothing for Point Cloud Models","summary":"  Point cloud models with neural network architectures have achieved great\nsuccess and have been widely used in safety-critical applications, such as\nLidar-based recognition systems in autonomous vehicles. However, such models\nare shown vulnerable to adversarial attacks which aim to apply stealthy\nsemantic transformations such as rotation and tapering to mislead model\npredictions. In this paper, we propose a transformation-specific smoothing\nframework TPC, which provides tight and scalable robustness guarantees for\npoint cloud models against semantic transformation attacks. We first categorize\ncommon 3D transformations into three categories: additive (e.g., shearing),\ncomposable (e.g., rotation), and indirectly composable (e.g., tapering), and we\npresent generic robustness certification strategies for all categories\nrespectively. We then specify unique certification protocols for a range of\nspecific semantic transformations and their compositions. Extensive experiments\non several common 3D transformations show that TPC significantly outperforms\nthe state of the art. For example, our framework boosts the certified accuracy\nagainst twisting transformation along z-axis (within 20$^\\circ$) from 20.3$\\%$\nto 83.8$\\%$. Codes and models are available at\nhttps://github.com/Qianhewu/Point-Cloud-Smoothing.\n","authors":["Wenda Chu","Linyi Li","Bo Li"],"pdf_url":"https://arxiv.org/pdf/2201.12733v4.pdf","comment":"Accepted as a conference paper at ICML 2022"},{"id":"http://arxiv.org/abs/2208.08221v2","updated":"2023-03-06T14:51:07Z","published":"2022-08-17T11:06:44Z","title":"Which Factors are associated with Open Access Publishing? A Springer\n  Nature Case Study","summary":"  Open Access (OA) facilitates access to articles. But, authors or funders\noften must pay the publishing costs preventing authors who do not receive\nfinancial support from participating in OA publishing and citation advantage\nfor OA articles. OA may exacerbate existing inequalities in the publication\nsystem rather than overcome them. To investigate this, we studied 522,411\narticles published by Springer Nature. Employing correlation and regression\nanalyses, we describe the relationship between authors affiliated with\ncountries from different income levels, their choice of publishing model, and\nthe citation impact of their papers. A machine learning classification method\nhelped us to explore the importance of different features in predicting the\npublishing model. The results show that authors eligible for APC waivers\npublish more in gold-OA journals than others. In contrast, authors eligible for\nan APC discount have the lowest ratio of OA publications, leading to the\nassumption that this discount insufficiently motivates authors to publish in\ngold-OA journals. We found a strong correlation between the journal rank and\nthe publishing model in gold-OA journals, whereas the OA option is mostly\navoided in hybrid journals. Also, results show that the countries' income\nlevel, seniority, and experience with OA publications are the most predictive\nfactors for OA publishing in hybrid journals.\n","authors":["Fakhri Momeni","Stefan Dietze","Philipp Mayr","Kristin Biesenbender","Isabella Peters"],"pdf_url":"https://arxiv.org/pdf/2208.08221v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2103.09108v4","updated":"2023-03-06T14:50:44Z","published":"2021-03-16T14:42:01Z","title":"Is it enough to optimize CNN architectures on ImageNet?","summary":"  Classification performance based on ImageNet is the de-facto standard metric\nfor CNN development. In this work we challenge the notion that CNN architecture\ndesign solely based on ImageNet leads to generally effective convolutional\nneural network (CNN) architectures that perform well on a diverse set of\ndatasets and application domains. To this end, we investigate and ultimately\nimprove ImageNet as a basis for deriving such architectures. We conduct an\nextensive empirical study for which we train $500$ CNN architectures, sampled\nfrom the broad AnyNetX design space, on ImageNet as well as $8$ additional well\nknown image classification benchmark datasets from a diverse array of\napplication domains. We observe that the performances of the architectures are\nhighly dataset dependent. Some datasets even exhibit a negative error\ncorrelation with ImageNet across all architectures. We show how to\nsignificantly increase these correlations by utilizing ImageNet subsets\nrestricted to fewer classes. These contributions can have a profound impact on\nthe way we design future CNN architectures and help alleviate the tilt we see\ncurrently in our community with respect to over-reliance on one dataset.\n","authors":["Lukas Tuggener","Jürgen Schmidhuber","Thilo Stadelmann"],"pdf_url":"https://arxiv.org/pdf/2103.09108v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03187v1","updated":"2023-03-06T14:49:59Z","published":"2023-03-06T14:49:59Z","title":"Boosting Differentiable Causal Discovery via Adaptive Sample Reweighting","summary":"  Under stringent model type and variable distribution assumptions,\ndifferentiable score-based causal discovery methods learn a directed acyclic\ngraph (DAG) from observational data by evaluating candidate graphs over an\naverage score function. Despite great success in low-dimensional linear\nsystems, it has been observed that these approaches overly exploit\neasier-to-fit samples, thus inevitably learning spurious edges. Worse still,\ninherent mostly in these methods the common homogeneity assumption can be\neasily violated, due to the widespread existence of heterogeneous data in the\nreal world, resulting in performance vulnerability when noise distributions\nvary. We propose a simple yet effective model-agnostic framework to boost\ncausal discovery performance by dynamically learning the adaptive weights for\nthe Reweighted Score function, ReScore for short, where the weights tailor\nquantitatively to the importance degree of each sample. Intuitively, we\nleverage the bilevel optimization scheme to \\wx{alternately train a standard\nDAG learner and reweight samples -- that is, upweight the samples the learner\nfails to fit and downweight the samples that the learner easily extracts the\nspurious information from. Extensive experiments on both synthetic and\nreal-world datasets are carried out to validate the effectiveness of ReScore.\nWe observe consistent and significant boosts in structure learning performance.\nFurthermore, we visualize that ReScore concurrently mitigates the influence of\nspurious edges and generalizes to heterogeneous data. Finally, we perform the\ntheoretical analysis to guarantee the structure identifiability and the weight\nadaptive properties of ReScore in linear systems. Our codes are available at\nhttps://github.com/anzhang314/ReScore.\n","authors":["An Zhang","Fangfu Liu","Wenchang Ma","Zhibo Cai","Xiang Wang","Tat-seng Chua"],"pdf_url":"https://arxiv.org/pdf/2303.03187v1.pdf","comment":"In proceedings of ICLR 2023"},{"id":"http://arxiv.org/abs/2110.11216v5","updated":"2023-03-06T14:49:13Z","published":"2021-10-21T15:50:05Z","title":"User-friendly introduction to PAC-Bayes bounds","summary":"  Aggregated predictors are obtained by making a set of basic predictors vote\naccording to some weights, that is, to some probability distribution.\n  Randomized predictors are obtained by sampling in a set of basic predictors,\naccording to some prescribed probability distribution.\n  Thus, aggregated and randomized predictors have in common that they are not\ndefined by a minimization problem, but by a probability distribution on the set\nof predictors. In statistical learning theory, there is a set of tools designed\nto understand the generalization ability of such procedures: PAC-Bayesian or\nPAC-Bayes bounds.\n  Since the original PAC-Bayes bounds of D. McAllester, these tools have been\nconsiderably improved in many directions (we will for example describe a\nsimplified version of the localization technique of O. Catoni that was missed\nby the community, and later rediscovered as \"mutual information bounds\"). Very\nrecently, PAC-Bayes bounds received a considerable attention: for example there\nwas workshop on PAC-Bayes at NIPS 2017, \"(Almost) 50 Shades of Bayesian\nLearning: PAC-Bayesian trends and insights\", organized by B. Guedj, F. Bach and\nP. Germain. One of the reason of this recent success is the successful\napplication of these bounds to neural networks by G. Dziugaite and D. Roy.\n  An elementary introduction to PAC-Bayes theory is still missing. This is an\nattempt to provide such an introduction.\n","authors":["Pierre Alquier"],"pdf_url":"https://arxiv.org/pdf/2110.11216v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03181v1","updated":"2023-03-06T14:48:30Z","published":"2023-03-06T14:48:30Z","title":"MetaPhysiCa: OOD Robustness in Physics-informed Machine Learning","summary":"  A fundamental challenge in physics-informed machine learning (PIML) is the\ndesign of robust PIML methods for out-of-distribution (OOD) forecasting tasks.\nThese OOD tasks require learning-to-learn from observations of the same (ODE)\ndynamical system with different unknown ODE parameters, and demand accurate\nforecasts even under out-of-support initial conditions and out-of-support ODE\nparameters. In this work we propose a solution for such tasks, which we define\nas a meta-learning procedure for causal structure discovery (including\ninvariant risk minimization). Using three different OOD tasks, we empirically\nobserve that the proposed approach significantly outperforms existing\nstate-of-the-art PIML and deep learning methods.\n","authors":["S Chandra Mouli","Muhammad Ashraful Alam","Bruno Ribeiro"],"pdf_url":"https://arxiv.org/pdf/2303.03181v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13941v2","updated":"2023-03-06T14:44:40Z","published":"2023-02-27T16:45:04Z","title":"A Reinforcement Learning Approach for Scheduling Problems With Improved\n  Generalization Through Order Swapping","summary":"  The scheduling of production resources (such as associating jobs to machines)\nplays a vital role for the manufacturing industry not only for saving energy\nbut also for increasing the overall efficiency. Among the different job\nscheduling problems, the JSSP is addressed in this work. JSSP falls into the\ncategory of NP-hard COP, in which solving the problem through exhaustive search\nbecomes unfeasible. Simple heuristics such as FIFO, LPT and metaheuristics such\nas Taboo search are often adopted to solve the problem by truncating the search\nspace. The viability of the methods becomes inefficient for large problem sizes\nas it is either far from the optimum or time consuming. In recent years, the\nresearch towards using DRL to solve COP has gained interest and has shown\npromising results in terms of solution quality and computational efficiency. In\nthis work, we provide an novel approach to solve the JSSP examining the\nobjectives generalization and solution effectiveness using DRL. In particular,\nwe employ the PPO algorithm that adopts the policy-gradient paradigm that is\nfound to perform well in the constrained dispatching of jobs. We incorporated\nan OSM in the environment to achieve better generalized learning of the\nproblem. The performance of the presented approach is analyzed in depth by\nusing a set of available benchmark instances and comparing our results with the\nwork of other groups.\n","authors":["Deepak Vivekanandan","Samuel Wirth","Patrick Karlbauer","Noah Klarmann"],"pdf_url":"https://arxiv.org/pdf/2302.13941v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03169v1","updated":"2023-03-06T14:31:09Z","published":"2023-03-06T14:31:09Z","title":"A Unified Algebraic Perspective on Lipschitz Neural Networks","summary":"  Important research efforts have focused on the design and training of neural\nnetworks with a controlled Lipschitz constant. The goal is to increase and\nsometimes guarantee the robustness against adversarial attacks. Recent\npromising techniques draw inspirations from different backgrounds to design\n1-Lipschitz neural networks, just to name a few: convex potential layers derive\nfrom the discretization of continuous dynamical systems,\nAlmost-Orthogonal-Layer proposes a tailored method for matrix rescaling.\nHowever, it is today important to consider the recent and promising\ncontributions in the field under a common theoretical lens to better design new\nand improved layers. This paper introduces a novel algebraic perspective\nunifying various types of 1-Lipschitz neural networks, including the ones\npreviously mentioned, along with methods based on orthogonality and spectral\nmethods. Interestingly, we show that many existing techniques can be derived\nand generalized via finding analytical solutions of a common semidefinite\nprogramming (SDP) condition. We also prove that AOL biases the scaled weight to\nthe ones which are close to the set of orthogonal matrices in a certain\nmathematical manner. Moreover, our algebraic condition, combined with the\nGershgorin circle theorem, readily leads to new and diverse parameterizations\nfor 1-Lipschitz network layers. Our approach, called SDP-based Lipschitz Layers\n(SLL), allows us to design non-trivial yet efficient generalization of convex\npotential layers. Finally, the comprehensive set of experiments on image\nclassification shows that SLLs outperform previous approaches on certified\nrobust accuracy. Code is available at\nhttps://github.com/araujoalexandre/Lipschitz-SLL-Networks.\n","authors":["Alexandre Araujo","Aaron Havens","Blaise Delattre","Alexandre Allauzen","Bin Hu"],"pdf_url":"https://arxiv.org/pdf/2303.03169v1.pdf","comment":"ICLR 2023. Spotlight paper"},{"id":"http://arxiv.org/abs/2303.03157v1","updated":"2023-03-06T14:21:42Z","published":"2023-03-06T14:21:42Z","title":"Data-Driven Control with Inherent Lyapunov Stability","summary":"  Recent advances in learning-based control leverage deep function\napproximators, such as neural networks, to model the evolution of controlled\ndynamical systems over time. However, the problem of learning a dynamics model\nand a stabilizing controller persists, since the synthesis of a stabilizing\nfeedback law for known nonlinear systems is a difficult task, let alone for\ncomplex parametric representations that must be fit to data. To this end, we\npropose a method for jointly learning parametric representations of a nonlinear\ndynamics model and a stabilizing controller from data. To do this, our approach\nsimultaneously learns a parametric Lyapunov function which intrinsically\nconstrains the dynamics model to be stabilizable by the learned controller. In\naddition to the stabilizability of the learned dynamics guaranteed by our novel\nconstruction, we show that the learned controller stabilizes the true dynamics\nunder certain assumptions on the fidelity of the learned dynamics. Finally, we\ndemonstrate the efficacy of our method on a variety of simulated nonlinear\ndynamical systems.\n","authors":["Youngjae Min","Spencer M. Richards","Navid Azizan"],"pdf_url":"https://arxiv.org/pdf/2303.03157v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.12108v2","updated":"2023-03-06T13:59:42Z","published":"2022-10-21T17:04:17Z","title":"Adversarial Permutation Invariant Training for Universal Sound\n  Separation","summary":"  Universal sound separation consists of separating mixes with arbitrary sounds\nof different types, and permutation invariant training (PIT) is used to train\nsource agnostic models that do so. In this work, we complement PIT with\nadversarial losses but find it challenging with the standard formulation used\nin speech source separation. We overcome this challenge with a novel\nI-replacement context-based adversarial loss, and by training with multiple\ndiscriminators. Our experiments show that by simply improving the loss (keeping\nthe same model and dataset) we obtain a non-negligible improvement of 1.4 dB\nSI-SNRi in the reverberant FUSS dataset. We also find adversarial PIT to be\neffective at reducing spectral holes, ubiquitous in mask-based separation\nmodels, which highlights the potential relevance of adversarial losses for\nsource separation.\n","authors":["Emilian Postolache","Jordi Pons","Santiago Pascual","Joan Serrà"],"pdf_url":"https://arxiv.org/pdf/2210.12108v2.pdf","comment":"Demo page: http://jordipons.me/apps/adversarialPIT/, Accepted at\n  ICASSP-23"},{"id":"http://arxiv.org/abs/2303.03132v1","updated":"2023-03-06T13:49:41Z","published":"2023-03-06T13:49:41Z","title":"SC-Block: Supervised Contrastive Blocking within Entity Resolution\n  Pipelines","summary":"  The goal of entity resolution is to identify records in multiple datasets\nthat represent the same real-world entity. However, comparing all records\nacross datasets can be computationally intensive, leading to long runtimes. To\nreduce these runtimes, entity resolution pipelines are constructed of two\nparts: a blocker that applies a computationally cheap method to select\ncandidate record pairs, and a matcher that afterwards identifies matching pairs\nfrom this set using more expensive methods. This paper presents SC-Block, a\nblocking method that utilizes supervised contrastive learning for positioning\nrecords in the embedding space, and nearest neighbour search for candidate set\nbuilding. We benchmark SC-Block against eight state-of-the-art blocking\nmethods. In order to relate the training time of SC-Block to the reduction of\nthe overall runtime of the entity resolution pipeline, we combine SC-Block with\nfour matching methods into complete pipelines. For measuring the overall\nruntime, we determine candidate sets with 98% pair completeness and pass them\nto the matcher. The results show that SC-Block is able to create smaller\ncandidate sets and pipelines with SC-Block execute 1.5 to 2 times faster\ncompared to pipelines with other blockers, without sacrificing F1 score.\nBlockers are often evaluated using relatively small datasets which might lead\nto runtime effects resulting from a large vocabulary size being overlooked. In\norder to measure runtimes in a more challenging setting, we introduce a new\nbenchmark dataset that requires large numbers of product offers to be blocked.\nOn this large-scale benchmark dataset, pipelines utilizing SC-Block and the\nbest-performing matcher execute 8 times faster than pipelines utilizing another\nblocker with the same matcher reducing the runtime from 2.5 hours to 18\nminutes, clearly compensating for the 5 minutes required for training SC-Block.\n","authors":["Alexander Brinkmann","Roee Shraga","Christian Bizer"],"pdf_url":"https://arxiv.org/pdf/2303.03132v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2001.05670v4","updated":"2023-03-06T13:42:11Z","published":"2020-01-16T06:27:50Z","title":"Optimization of Convolutional Neural Network Using the Linearly\n  Decreasing Weight Particle Swarm Optimization","summary":"  Convolutional neural network (CNN) is one of the most frequently used deep\nlearning techniques. Various forms of models have been proposed and im-proved\nfor learning at CNN. When learning with CNN, it is necessary to determine the\noptimal hyperparameters. However, the number of hyperparameters is so large\nthat it is difficult to do it manually, so much research has been done on\nautomation. A method that uses metaheuristic algorithms is attracting attention\nin research on hyperparameter optimization. Metaheuristic algorithms are\nnaturally inspired and include evolution strategies, genetic algorithms,\nantcolony optimization and particle swarm optimization. In particular, particle\nswarm optimization converges faster than genetic algorithms, and various models\nhave been proposed. In this paper, we pro-pose CNN hyperparameter optimization\nwith linearly decreasing weight particle swarm optimization (LDWPSO). In the\nexperiment, the MNIST data set and CIFAR-10 data set, which are often used as\nbenchmark data sets, are used. By opti-mizing CNN hyperparameters with LDWPSO,\nlearning the MNIST and CIFAR-10 datasets, we compare the accuracy with a\nstandard CNN based on LeNet-5. As a result, when using the MNIST dataset, the\nbaseline CNN is 94.02% at the 5th epoch, compared to 98.95% for LDWPSO CNN,\nwhich improves accuracy. When using the CIFAR-10 dataset, the Baseline CNN is\n28.07% at the 10th epoch, compared to 69.37% for the LDWPSO CNN, which greatly\nimproves accuracy. This paper is presented at the 36th Annual Conference of the\nJapanese Society for Artificial In-telligence. The final version is available\nat the following URL: https://doi.org/10.11517/pjsai.JSAI2022.0_2S4IS2b03\n","authors":["T. Serizawa","H. Fujita"],"pdf_url":"https://arxiv.org/pdf/2001.05670v4.pdf","comment":"This paper is presented at the 36th Annual Conference of the Japanese\n  Society for Artificial In-telligence"},{"id":"http://arxiv.org/abs/2106.03056v3","updated":"2023-03-06T13:39:15Z","published":"2021-06-06T07:39:01Z","title":"MURANA: A Generic Framework for Stochastic Variance-Reduced Optimization","summary":"  We propose a generic variance-reduced algorithm, which we call MUltiple\nRANdomized Algorithm (MURANA), for minimizing a sum of several smooth functions\nplus a regularizer, in a sequential or distributed manner. Our method is\nformulated with general stochastic operators, which allow us to model various\nstrategies for reducing the computational complexity. For example, MURANA\nsupports sparse activation of the gradients, and also reduction of the\ncommunication load via compression of the update vectors. This versatility\nallows MURANA to cover many existing randomization mechanisms within a unified\nframework, which also makes it possible to design new methods as special cases.\n","authors":["Laurent Condat","Peter Richtárik"],"pdf_url":"https://arxiv.org/pdf/2106.03056v3.pdf","comment":"3rd Annual Conference on Mathematical and Scientific Machine Learning\n  (MSML), Aug. 2022. PMLR 190:81-96"},{"id":"http://arxiv.org/abs/2302.10248v2","updated":"2023-03-06T13:38:57Z","published":"2023-02-20T19:27:14Z","title":"VoxSRC 2022: The Fourth VoxCeleb Speaker Recognition Challenge","summary":"  This paper summarises the findings from the VoxCeleb Speaker Recognition\nChallenge 2022 (VoxSRC-22), which was held in conjunction with INTERSPEECH\n2022. The goal of this challenge was to evaluate how well state-of-the-art\nspeaker recognition systems can diarise and recognise speakers from speech\nobtained \"in the wild\". The challenge consisted of: (i) the provision of\npublicly available speaker recognition and diarisation data from YouTube videos\ntogether with ground truth annotation and standardised evaluation software; and\n(ii) a public challenge and hybrid workshop held at INTERSPEECH 2022. We\ndescribe the four tracks of our challenge along with the baselines, methods,\nand results. We conclude with a discussion on the new domain-transfer focus of\nVoxSRC-22, and on the progression of the challenge from the previous three\neditions.\n","authors":["Jaesung Huh","Andrew Brown","Jee-weon Jung","Joon Son Chung","Arsha Nagrani","Daniel Garcia-Romero","Andrew Zisserman"],"pdf_url":"https://arxiv.org/pdf/2302.10248v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2104.14527v5","updated":"2023-03-06T13:19:14Z","published":"2021-04-29T17:45:27Z","title":"Online certification of preference-based fairness for personalized\n  recommender systems","summary":"  Recommender systems are facing scrutiny because of their growing impact on\nthe opportunities we have access to. Current audits for fairness are limited to\ncoarse-grained parity assessments at the level of sensitive groups. We propose\nto audit for envy-freeness, a more granular criterion aligned with individual\npreferences: every user should prefer their recommendations to those of other\nusers. Since auditing for envy requires to estimate the preferences of users\nbeyond their existing recommendations, we cast the audit as a new pure\nexploration problem in multi-armed bandits. We propose a sample-efficient\nalgorithm with theoretical guarantees that it does not deteriorate user\nexperience. We also study the trade-offs achieved on real-world recommendation\ndatasets.\n","authors":["Virginie Do","Sam Corbett-Davies","Jamal Atif","Nicolas Usunier"],"pdf_url":"https://arxiv.org/pdf/2104.14527v5.pdf","comment":"AAAI 2022"},{"id":"http://arxiv.org/abs/2303.03094v1","updated":"2023-03-06T13:12:43Z","published":"2023-03-06T13:12:43Z","title":"Benchmark of Data Preprocessing Methods for Imbalanced Classification","summary":"  Severe class imbalance is one of the main conditions that make machine\nlearning in cybersecurity difficult. A variety of dataset preprocessing methods\nhave been introduced over the years. These methods modify the training dataset\nby oversampling, undersampling or a combination of both to improve the\npredictive performance of classifiers trained on this dataset. Although these\nmethods are used in cybersecurity occasionally, a comprehensive, unbiased\nbenchmark comparing their performance over a variety of cybersecurity problems\nis missing. This paper presents a benchmark of 16 preprocessing methods on six\ncybersecurity datasets together with 17 public imbalanced datasets from other\ndomains. We test the methods under multiple hyperparameter configurations and\nuse an AutoML system to train classifiers on the preprocessed datasets, which\nreduces potential bias from specific hyperparameter or classifier choices.\nSpecial consideration is also given to evaluating the methods using appropriate\nperformance measures that are good proxies for practical performance in\nreal-world cybersecurity systems. The main findings of our study are: 1) Most\nof the time, a data preprocessing method that improves classification\nperformance exists. 2) Baseline approach of doing nothing outperformed a large\nportion of methods in the benchmark. 3) Oversampling methods generally\noutperform undersampling methods. 4) The most significant performance gains are\nbrought by the standard SMOTE algorithm and more complicated methods provide\nmainly incremental improvements at the cost of often worse computational\nperformance.\n","authors":["Radovan Haluška","Jan Brabec","Tomáš Komárek"],"pdf_url":"https://arxiv.org/pdf/2303.03094v1.pdf","comment":"Published at 2022 IEEE International Conference on Big Data (Big\n  Data) 2022. Extended version with full results in appendix"},{"id":"http://arxiv.org/abs/2303.03092v1","updated":"2023-03-06T13:10:54Z","published":"2023-03-06T13:10:54Z","title":"Environment Invariant Linear Least Squares","summary":"  This paper considers a multiple environments linear regression model in which\ndata from multiple experimental settings are collected. The joint distribution\nof the response variable and covariate may vary across different environments,\nyet the conditional expectation of $y$ given the unknown set of important\nvariables are invariant across environments. Such a statistical model is\nrelated to the problem of endogeneity, causal inference, and transfer learning.\nThe motivation behind it is illustrated by how the goals of prediction and\nattribution are inherent in estimating the true parameter and the important\nvariable set. We construct a novel {\\it environment invariant linear least\nsquares (EILLS)} objective function, a multiple-environment version of linear\nleast squares that leverages the above conditional expectation invariance\nstructure and heterogeneity among different environments to determine the true\nparameter. Our proposed method is applicable without any additional structural\nknowledge and can identify the true parameter under a near-minimal\nidentification condition. We establish non-asymptotic $\\ell_2$ error bounds on\nthe estimation error for the EILLS estimator in the presence of spurious\nvariables. Moreover, we further show that the EILLS estimator is able to\neliminate all endogenous variables and the $\\ell_0$ penalized EILLS estimator\ncan achieve variable selection consistency in high-dimensional regimes. These\nnon-asymptotic results demonstrate the sample efficiency of the EILLS estimator\nand its capability to circumvent the curse of endogeneity in an algorithmic\nmanner without any prior structural knowledge.\n","authors":["Jianqing Fan","Cong Fang","Yihong Gu","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.03092v1.pdf","comment":"65 pages, 4 figures"},{"id":"http://arxiv.org/abs/2303.03084v1","updated":"2023-03-06T12:55:38Z","published":"2023-03-06T12:55:38Z","title":"On Regression in Extreme Regions","summary":"  In the classic regression problem, the value of a real-valued random variable\n$Y$ is to be predicted based on the observation of a random vector $X$, taking\nits values in $\\mathbb{R}^d$ with $d\\geq 1$ say. The statistical learning\nproblem consists in building a predictive function $\\hat{f}:\\mathbb{R}^d\\to\n\\mathbb{R}$ based on independent copies of the pair $(X,Y)$ so that $Y$ is\napproximated by $\\hat{f}(X)$ with minimum error in the mean-squared sense.\nMotivated by various applications, ranging from environmental sciences to\nfinance or insurance, special attention is paid here to the case of extreme\n(i.e. very large) observations $X$. Because of their rarity, they contribute in\na negligible manner to the (empirical) error and the predictive performance of\nempirical quadratic risk minimizers can be consequently very poor in extreme\nregions. In this paper, we develop a general framework for regression in the\nextremes. It is assumed that $X$'s conditional distribution given $Y$ belongs\nto a non parametric class of heavy-tailed probability distributions. It is then\nshown that an asymptotic notion of risk can be tailored to summarize\nappropriately predictive performance in extreme regions of the input space. It\nis also proved that minimization of an empirical and non asymptotic version of\nthis 'extreme risk', based on a fraction of the largest observations solely,\nyields regression functions with good generalization capacity. In addition,\nnumerical results providing strong empirical evidence of the relevance of the\napproach proposed are displayed.\n","authors":["Nathan Huet","Stephan Clémençon","Anne Sabourin"],"pdf_url":"https://arxiv.org/pdf/2303.03084v1.pdf","comment":"10 pages (main paper), 10 pages (appendix)"},{"id":"http://arxiv.org/abs/2205.04180v4","updated":"2023-03-06T12:46:17Z","published":"2022-05-09T10:44:23Z","title":"EF-BV: A Unified Theory of Error Feedback and Variance Reduction\n  Mechanisms for Biased and Unbiased Compression in Distributed Optimization","summary":"  In distributed or federated optimization and learning, communication between\nthe different computing units is often the bottleneck and gradient compression\nis widely used to reduce the number of bits sent within each communication\nround of iterative methods. There are two classes of compression operators and\nseparate algorithms making use of them. In the case of unbiased random\ncompressors with bounded variance (e.g., rand-k), the DIANA algorithm of\nMishchenko et al. (2019), which implements a variance reduction technique for\nhandling the variance introduced by compression, is the current state of the\nart. In the case of biased and contractive compressors (e.g., top-k), the EF21\nalgorithm of Richt\\'arik et al. (2021), which instead implements an\nerror-feedback mechanism, is the current state of the art. These two classes of\ncompression schemes and algorithms are distinct, with different analyses and\nproof techniques. In this paper, we unify them into a single framework and\npropose a new algorithm, recovering DIANA and EF21 as particular cases. Our\ngeneral approach works with a new, larger class of compressors, which has two\nparameters, the bias and the variance, and includes unbiased and biased\ncompressors as particular cases. This allows us to inherit the best of the two\nworlds: like EF21 and unlike DIANA, biased compressors, like top-k, whose good\nperformance in practice is recognized, can be used. And like DIANA and unlike\nEF21, independent randomness at the compressors allows to mitigate the effects\nof compression, with the convergence rate improving when the number of parallel\nworkers is large. This is the first time that an algorithm with all these\nfeatures is proposed. We prove its linear convergence under certain conditions.\nOur approach takes a step towards better understanding of two so-far distinct\nworlds of communication-efficient distributed learning.\n","authors":["Laurent Condat","Kai Yi","Peter Richtárik"],"pdf_url":"https://arxiv.org/pdf/2205.04180v4.pdf","comment":"Conference NeurIPS 2022"},{"id":"http://arxiv.org/abs/2303.03073v1","updated":"2023-03-06T12:31:19Z","published":"2023-03-06T12:31:19Z","title":"A neural network based model for multi-dimensional nonlinear Hawkes\n  processes","summary":"  This paper introduces the Neural Network for Nonlinear Hawkes processes\n(NNNH), a non-parametric method based on neural networks to fit nonlinear\nHawkes processes. Our method is suitable for analyzing large datasets in which\nevents exhibit both mutually-exciting and inhibitive patterns. The NNNH\napproach models the individual kernels and the base intensity of the nonlinear\nHawkes process using feed forward neural networks and jointly calibrates the\nparameters of the networks by maximizing the log-likelihood function. We\nutilize Stochastic Gradient Descent to search for the optimal parameters and\npropose an unbiased estimator for the gradient, as well as an efficient\ncomputation method. We demonstrate the flexibility and accuracy of our method\nthrough numerical experiments on both simulated and real-world data, and\ncompare it with state-of-the-art methods. Our results highlight the\neffectiveness of the NNNH method in accurately capturing the complexities of\nnonlinear Hawkes processes.\n","authors":["Sobin Joseph","Shashi Jain"],"pdf_url":"https://arxiv.org/pdf/2303.03073v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03068v1","updated":"2023-03-06T12:23:23Z","published":"2023-03-06T12:23:23Z","title":"Reinforcement Learning Based Self-play and State Stacking Techniques for\n  Noisy Air Combat Environment","summary":"  Reinforcement learning (RL) has recently proven itself as a powerful\ninstrument for solving complex problems and even surpassed human performance in\nseveral challenging applications. This signifies that RL algorithms can be used\nin the autonomous air combat problem, which has been studied for many years.\nThe complexity of air combat arises from aggressive close-range maneuvers and\nagile enemy behaviors. In addition to these complexities, there may be\nuncertainties in real-life scenarios due to sensor errors, which prevent\nestimation of the actual position of the enemy. In this case, autonomous\naircraft should be successful even in the noisy environments. In this study, we\ndeveloped an air combat simulation, which provides noisy observations to the\nagents, therefore, make the air combat problem even more challenging. Thus, we\npresent a state stacking method for noisy RL environments as a noise reduction\ntechnique. In our extensive set of experiments, the proposed method\nsignificantly outperforms the baseline algorithms in terms of the winning\nratio, where the performance improvement is even more pronounced in the high\nnoise levels. In addition, we incorporate a self-play scheme to our training\nprocess by periodically updating the enemy with a frozen copy of the training\nagent. By this way, the training agent performs air combat simulations to an\nenemy with smarter strategies, which improves the performance and robustness of\nthe agents. In our simulations, we demonstrate that the self-play scheme\nprovides important performance gains compared to the classical RL training.\n","authors":["Ahmet Semih Tasbas","Safa Onur Sahin","Nazim Kemal Ure"],"pdf_url":"https://arxiv.org/pdf/2303.03068v1.pdf","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2303.03052v1","updated":"2023-03-06T11:51:28Z","published":"2023-03-06T11:51:28Z","title":"Masked Images Are Counterfactual Samples for Robust Fine-tuning","summary":"  Deep learning models are challenged by the distribution shift between the\ntraining data and test data. Recently, the large models pre-trained on diverse\ndata demonstrate unprecedented robustness to various distribution shifts.\nHowever, fine-tuning on these models can lead to a trade-off between\nin-distribution (ID) performance and out-of-distribution (OOD) robustness.\nExisting methods for tackling this trade-off do not explicitly address the OOD\nrobustness problem. In this paper, based on causal analysis on the\naforementioned problems, we propose a novel fine-tuning method, which use\nmasked images as counterfactual samples that help improving the robustness of\nthe fine-tuning model. Specifically, we mask either the semantics-related or\nsemantics-unrelated patches of the images based on class activation map to\nbreak the spurious correlation, and refill the masked patches with patches from\nother images. The resulting counterfactual samples are used in feature-based\ndistillation with the pre-trained model. Extensive experiments verify that\nregularizing the fine-tuning with the proposed masked images can achieve a\nbetter trade-off between ID and OOD, surpassing previous methods on the OOD\nperformance. Our code will be publicly available.\n","authors":["Yao Xiao","Ziyi Tang","Pengxu Wei","Cong Liu","Liang Lin"],"pdf_url":"https://arxiv.org/pdf/2303.03052v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2212.02931v2","updated":"2023-03-06T11:48:02Z","published":"2022-12-06T12:40:45Z","title":"Leveraging Different Learning Styles for Improved Knowledge Distillation","summary":"  Learning style refers to a type of training mechanism adopted by an\nindividual to gain new knowledge. As suggested by the VARK model, humans have\ndifferent learning preferences like visual, auditory, etc., for acquiring and\neffectively processing information. Inspired by this concept, our work explores\nthe idea of mixed information sharing with model compression in the context of\nKnowledge Distillation (KD) and Mutual Learning (ML). Unlike conventional\ntechniques that share the same type of knowledge with all networks, we propose\nto train individual networks with different forms of information to enhance the\nlearning process. We formulate a combined KD and ML framework with one teacher\nand two student networks that share or exchange information in the form of\npredictions and feature maps. Our comprehensive experiments with benchmark\nclassification and segmentation datasets demonstrate that with 15% compression,\nthe ensemble performance of networks trained with diverse forms of knowledge\noutperforms the conventional techniques both quantitatively and qualitatively.\n","authors":["Usma Niyaz","Deepti R. Bathula"],"pdf_url":"https://arxiv.org/pdf/2212.02931v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.05751v3","updated":"2023-03-06T11:18:59Z","published":"2022-06-12T14:45:11Z","title":"Consistent Attack: Universal Adversarial Perturbation on Embodied Vision\n  Navigation","summary":"  Embodied agents in vision navigation coupled with deep neural networks have\nattracted increasing attention. However, deep neural networks have been shown\nvulnerable to malicious adversarial noises, which may potentially cause\ncatastrophic failures in Embodied Vision Navigation. Among different\nadversarial noises, universal adversarial perturbations (UAP), i.e., a constant\nimage-agnostic perturbation applied on every input frame of the agent, play a\ncritical role in Embodied Vision Navigation since they are\ncomputation-efficient and application-practical during the attack. However,\nexisting UAP methods ignore the system dynamics of Embodied Vision Navigation\nand might be sub-optimal. In order to extend UAP to the sequential decision\nsetting, we formulate the disturbed environment under the universal noise\n$\\delta$, as a $\\delta$-disturbed Markov Decision Process ($\\delta$-MDP). Based\non the formulation, we analyze the properties of $\\delta$-MDP and propose two\nnovel Consistent Attack methods, named Reward UAP and Trajectory UAP, for\nattacking Embodied agents, which consider the dynamic of the MDP and calculate\nuniversal noises by estimating the disturbed distribution and the disturbed Q\nfunction. For various victim models, our Consistent Attack can cause a\nsignificant drop in their performance in the PointGoal task in Habitat with\ndifferent datasets and different scenes. Extensive experimental results\nindicate that there exist serious potential risks for applying Embodied Vision\nNavigation methods to the real world.\n","authors":["Chengyang Ying","You Qiaoben","Xinning Zhou","Hang Su","Wenbo Ding","Jianyong Ai"],"pdf_url":"https://arxiv.org/pdf/2206.05751v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03042v1","updated":"2023-03-06T11:14:59Z","published":"2023-03-06T11:14:59Z","title":"Convolutional Neural Networks as 2-D systems","summary":"  This paper introduces a novel representation of convolutional Neural Networks\n(CNNs) in terms of 2-D dynamical systems. To this end, the usual description of\nconvolutional layers with convolution kernels, i.e., the impulse responses of\nlinear filters, is realized in state space as a linear time-invariant 2-D\nsystem. The overall convolutional Neural Network composed of convolutional\nlayers and nonlinear activation functions is then viewed as a 2-D version of a\nLur'e system, i.e., a linear dynamical system interconnected with static\nnonlinear components. One benefit of this 2-D Lur'e system perspective on CNNs\nis that we can use robust control theory much more efficiently for Lipschitz\nconstant estimation than previously possible.\n","authors":["Dennis Gramlich","Patricia Pauli","Carsten W. Scherer","Frank Allgöwer","Christian Ebenbauer"],"pdf_url":"https://arxiv.org/pdf/2303.03042v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.08516v2","updated":"2023-03-06T11:06:39Z","published":"2022-06-17T02:36:23Z","title":"MetaFed: Federated Learning among Federations with Cyclic Knowledge\n  Distillation for Personalized Healthcare","summary":"  Federated learning has attracted increasing attention to building models\nwithout accessing the raw user data, especially in healthcare. In real\napplications, different federations can seldom work together due to possible\nreasons such as data heterogeneity and distrust/inexistence of the central\nserver. In this paper, we propose a novel framework called MetaFed to\nfacilitate trustworthy FL between different federations. MetaFed obtains a\npersonalized model for each federation without a central server via the\nproposed Cyclic Knowledge Distillation. Specifically, MetaFed treats each\nfederation as a meta distribution and aggregates knowledge of each federation\nin a cyclic manner. The training is split into two parts: common knowledge\naccumulation and personalization. Comprehensive experiments on three benchmarks\ndemonstrate that MetaFed without a server achieves better accuracy compared to\nstate-of-the-art methods (e.g., 10%+ accuracy improvement compared to the\nbaseline for PAMAP2) with fewer communication costs.\n","authors":["Yiqiang Chen","Wang Lu","Xin Qin","Jindong Wang","Xing Xie"],"pdf_url":"https://arxiv.org/pdf/2206.08516v2.pdf","comment":"IJCAI'22 FTL workshop innovation award; Extended version (12 pages)\n  with more experiments and extensions; code at\n  https://github.com/microsoft/PersonalizedFL"},{"id":"http://arxiv.org/abs/2303.03036v1","updated":"2023-03-06T11:05:21Z","published":"2023-03-06T11:05:21Z","title":"Deep Clustering with a Constraint for Topological Invariance based on\n  Symmetric InfoNCE","summary":"  We consider the scenario of deep clustering, in which the available prior\nknowledge is limited. In this scenario, few existing state-of-the-art deep\nclustering methods can perform well for both non-complex topology and complex\ntopology datasets. To address the problem, we propose a constraint utilizing\nsymmetric InfoNCE, which helps an objective of deep clustering method in the\nscenario train the model so as to be efficient for not only non-complex\ntopology but also complex topology datasets. Additionally, we provide several\ntheoretical explanations of the reason why the constraint can enhances\nperformance of deep clustering methods. To confirm the effectiveness of the\nproposed constraint, we introduce a deep clustering method named MIST, which is\na combination of an existing deep clustering method and our constraint. Our\nnumerical experiments via MIST demonstrate that the constraint is effective. In\naddition, MIST outperforms other state-of-the-art deep clustering methods for\nmost of the commonly used ten benchmark datasets.\n","authors":["Yuhui Zhang","Yuichiro Wada","Hiroki Waida","Kaito Goto","Yusaku Hino","Takafumi Kanamori"],"pdf_url":"https://arxiv.org/pdf/2303.03036v1.pdf","comment":"48 pages, 6 figures"},{"id":"http://arxiv.org/abs/2303.03027v1","updated":"2023-03-06T10:56:14Z","published":"2023-03-06T10:56:14Z","title":"Critical Points and Convergence Analysis of Generative Deep Linear\n  Networks Trained with Bures-Wasserstein Loss","summary":"  We consider a deep matrix factorization model of covariance matrices trained\nwith the Bures-Wasserstein distance. While recent works have made important\nadvances in the study of the optimization problem for overparametrized low-rank\nmatrix approximation, much emphasis has been placed on discriminative settings\nand the square loss. In contrast, our model considers another interesting type\nof loss and connects with the generative setting. We characterize the critical\npoints and minimizers of the Bures-Wasserstein distance over the space of\nrank-bounded matrices. For low-rank matrices the Hessian of this loss can\ntheoretically blow up, which creates challenges to analyze convergence of\noptimizaton methods. We establish convergence results for gradient flow using a\nsmooth perturbative version of the loss and convergence results for finite step\nsize gradient descent under certain assumptions on the initial weights.\n","authors":["Pierre Bréchet","Katerina Papagiannouli","Jing An","Guido Montúfar"],"pdf_url":"https://arxiv.org/pdf/2303.03027v1.pdf","comment":"35 pages, 1 figure"},{"id":"http://arxiv.org/abs/2210.09171v2","updated":"2023-03-06T10:52:25Z","published":"2022-10-17T15:19:26Z","title":"Data-driven Modeling of Mach-Zehnder Interferometer-based Optical Matrix\n  Multipliers","summary":"  Photonic integrated circuits are facilitating the development of optical\nneural networks, which have the potential to be both faster and more energy\nefficient than their electronic counterparts since optical signals are\nespecially well-suited for implementing matrix multiplications. However,\naccurate programming of photonic chips for optical matrix multiplication\nremains a difficult challenge. Here, we describe both simple analytical models\nand data-driven models for offline training of optical matrix multipliers. We\ntrain and evaluate the models using experimental data obtained from a\nfabricated chip featuring a Mach-Zehnder interferometer mesh implementing\n3-by-3 matrix multiplication. The neural network-based models outperform the\nsimple physics-based models in terms of prediction error. Furthermore, the\nneural network models are also able to predict the spectral variations in the\nmatrix weights for up to 100 frequency channels covering the C-band. The use of\nneural network models for programming the chip for optical matrix\nmultiplication yields increased performance on multiple machine learning tasks.\n","authors":["Ali Cem","Siqi Yan","Yunhong Ding","Darko Zibar","Francesco Da Ros"],"pdf_url":"https://arxiv.org/pdf/2210.09171v2.pdf","comment":"12 pages, 17 figures, submitted to Jorunal of Lightwave Technology"},{"id":"http://arxiv.org/abs/2303.03023v1","updated":"2023-03-06T10:50:25Z","published":"2023-03-06T10:50:25Z","title":"Guiding Energy-based Models via Contrastive Latent Variables","summary":"  An energy-based model (EBM) is a popular generative framework that offers\nboth explicit density and architectural flexibility, but training them is\ndifficult since it is often unstable and time-consuming. In recent years,\nvarious training techniques have been developed, e.g., better divergence\nmeasures or stabilization in MCMC sampling, but there often exists a large gap\nbetween EBMs and other generative frameworks like GANs in terms of generation\nquality. In this paper, we propose a novel and effective framework for\nimproving EBMs via contrastive representation learning (CRL). To be specific,\nwe consider representations learned by contrastive methods as the true\nunderlying latent variable. This contrastive latent variable could guide EBMs\nto understand the data structure better, so it can improve and accelerate EBM\ntraining significantly. To enable the joint training of EBM and CRL, we also\ndesign a new class of latent-variable EBMs for learning the joint density of\ndata and the contrastive latent variable. Our experimental results demonstrate\nthat our scheme achieves lower FID scores, compared to prior-art EBM methods\n(e.g., additionally using variational autoencoders or diffusion techniques),\neven with significantly faster and more memory-efficient training. We also show\nconditional and compositional generation abilities of our latent-variable EBMs\nas their additional benefits, even without explicit conditional training. The\ncode is available at https://github.com/hankook/CLEL.\n","authors":["Hankook Lee","Jongheon Jeong","Sejun Park","Jinwoo Shin"],"pdf_url":"https://arxiv.org/pdf/2303.03023v1.pdf","comment":"Accepted to ICLR 2023 (Spotlight). The code is available at\n  https://github.com/hankook/CLEL"},{"id":"http://arxiv.org/abs/2302.07684v2","updated":"2023-03-06T10:48:05Z","published":"2023-02-15T14:21:31Z","title":"A Federated Learning Benchmark for Drug-Target Interaction","summary":"  Aggregating pharmaceutical data in the drug-target interaction (DTI) domain\nhas the potential to deliver life-saving breakthroughs. It is, however,\nnotoriously difficult due to regulatory constraints and commercial interests.\nThis work proposes the application of federated learning, which we argue to be\nreconcilable with the industry's constraints, as it does not require sharing of\nany information that would reveal the entities' data or any other high-level\nsummary of it. When used on a representative GraphDTA model and the KIBA\ndataset it achieves up to 15% improved performance relative to the best\navailable non-privacy preserving alternative. Our extensive battery of\nexperiments shows that, unlike in other domains, the non-IID data distribution\nin the DTI datasets does not deteriorate FL performance. Additionally, we\nidentify a material trade-off between the benefits of adding new data, and the\ncost of adding more clients.\n","authors":["Gianluca Mittone","Filip Svoboda","Marco Aldinucci","Nicholas D. Lane","Pietro Lio"],"pdf_url":"https://arxiv.org/pdf/2302.07684v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03005v1","updated":"2023-03-06T10:15:14Z","published":"2023-03-06T10:15:14Z","title":"Scaling strategies for on-device low-complexity source separation with\n  Conv-Tasnet","summary":"  Recently, several very effective neural approaches for single-channel speech\nseparation have been presented in the literature. However, due to the size and\ncomplexity of these models, their use on low-resource devices, e.g. for hearing\naids, and earphones, is still a challenge and established solutions are not\navailable yet. Although approaches based on either pruning or compressing\nneural models have been proposed, the design of a model architecture suitable\nfor a certain application domain often requires heuristic procedures not easily\nportable to different low-resource platforms. Given the modular nature of the\nwell-known Conv-Tasnet speech separation architecture, in this paper we\nconsider three parameters that directly control the overall size of the model,\nnamely: the number of residual blocks, the number of repetitions of the\nseparation blocks and the number of channels in the depth-wise convolutions,\nand experimentally evaluate how they affect the speech separation performance.\nIn particular, experiments carried out on the Libri2Mix show that the number of\ndilated 1D-Conv blocks is the most critical parameter and that the usage of\nextra-dilation in the residual blocks allows reducing the performance drop.\n","authors":["Mohamed Nabih Ali","Francesco Paissan","Daniele Falavigna","Alessio Brutti"],"pdf_url":"https://arxiv.org/pdf/2303.03005v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.00815v2","updated":"2023-03-06T10:10:19Z","published":"2023-01-01T12:48:12Z","title":"NeuroExplainer: Fine-Grained Attention Decoding to Uncover Cortical\n  Development Patterns of Preterm Infants","summary":"  Deploying reliable deep learning techniques in interdisciplinary applications\nneeds learned models to output accurate and ({even more importantly})\nexplainable predictions. Existing approaches typically explicate network\noutputs in a post-hoc fashion, under an implicit assumption that faithful\nexplanations come from accurate predictions/classifications. We have an\nopposite claim that explanations boost (or even determine) classification. That\nis, end-to-end learning of explanation factors to augment discriminative\nrepresentation extraction could be a more intuitive strategy to inversely\nassure fine-grained explainability, e.g., in those neuroimaging and\nneuroscience studies with high-dimensional data containing noisy, redundant,\nand task-irrelevant information. In this paper, we propose such an explainable\ngeometric deep network dubbed as NeuroExplainer, with applications to uncover\naltered infant cortical development patterns associated with preterm birth.\nGiven fundamental cortical attributes as network input, our NeuroExplainer\nadopts a hierarchical attention-decoding framework to learn fine-grained\nattentions and respective discriminative representations to accurately\nrecognize preterm infants from term-born infants at term-equivalent age.\nNeuroExplainer learns the hierarchical attention-decoding modules under\nsubject-level weak supervision coupled with targeted regularizers deduced from\ndomain knowledge regarding brain development. These prior-guided constraints\nimplicitly maximizes the explainability metrics (i.e., fidelity, sparsity, and\nstability) in network training, driving the learned network to output detailed\nexplanations and accurate classifications. Experimental results on the public\ndHCP benchmark suggest that NeuroExplainer led to quantitatively reliable\nexplanation results that are qualitatively consistent with representative\nneuroimaging studies.\n","authors":["Chenyu Xue","Fan Wang","Yuanzhuo Zhu","Hui Li","Deyu Meng","Dinggang Shen","Chunfeng Lian"],"pdf_url":"https://arxiv.org/pdf/2301.00815v2.pdf","comment":"Some parts of the thesis are still being revised"},{"id":"http://arxiv.org/abs/2303.01954v2","updated":"2023-03-06T10:01:27Z","published":"2023-03-03T14:28:45Z","title":"Synthetic Data Generator for Adaptive Interventions in Global Health","summary":"  Artificial Intelligence and digital health have the potential to transform\nglobal health. However, having access to representative data to test and\nvalidate algorithms in realistic production environments is essential. We\nintroduce HealthSyn, an open-source synthetic data generator of user behavior\nfor testing reinforcement learning algorithms in the context of mobile health\ninterventions. The generator utilizes Markov processes to generate diverse user\nactions, with individual user behavioral patterns that can change in reaction\nto personalized interventions (i.e., reminders, recommendations, and\nincentives). These actions are translated into actual logs using an ML-purposed\ndata schema specific to the mobile health application functionality included\nwith HealthKit, and open-source SDK. The logs can be fed to pipelines to obtain\nuser metrics. The generated data, which is based on real-world behaviors and\nsimulation techniques, can be used to develop, test, and evaluate, both ML\nalgorithms in research and end-to-end operational RL-based intervention\ndelivery frameworks.\n","authors":["Aditya Rastogi","Juan Francisco Garamendi","Ana Fernández del Río","Anna Guitart","Moiz Hassan Khan","Dexian Tang","África Periáñez"],"pdf_url":"https://arxiv.org/pdf/2303.01954v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.11776v2","updated":"2023-03-06T10:00:40Z","published":"2022-12-22T15:12:29Z","title":"Fixed-budget online adaptive learning for physics-informed neural\n  networks. Towards parameterized problem inference","summary":"  Physics-Informed Neural Networks (PINNs) have gained much attention in\nvarious fields of engineering thanks to their capability of incorporating\nphysical laws into the models. PINNs integrate the physical constraints by\nminimizing the partial differential equations (PDEs) residuals on a set of\ncollocation points. The distribution of these collocation points appears to\nhave a huge impact on the performance of PINNs and the assessment of the\nsampling methods for these points is still an active topic. In this paper, we\npropose a Fixed-Budget Online Adaptive Learning (FBOAL) method, which\ndecomposes the domain into sub-domains, for training collocation points based\non local maxima and local minima of the PDEs residuals. The effectiveness of\nFBOAL is demonstrated for non-parameterized and parameterized problems. The\ncomparison with other adaptive sampling methods is also illustrated. The\nnumerical results demonstrate important gains in terms of the accuracy and\ncomputational cost of PINNs with FBOAL over the classical PINNs with\nnon-adaptive collocation points. We also apply FBOAL in a complex industrial\napplication involving coupling between mechanical and thermal fields. We show\nthat FBOAL is able to identify the high-gradient locations and even give better\npredictions for some physical fields than the classical PINNs with collocation\npoints sampled on a pre-adapted finite element mesh built thanks to numerical\nexpert knowledge. From the present study, it is expected that the use of FBOAL\nwill help to improve the conventional numerical solver in the construction of\nthe mesh.\n","authors":["Thi Nguyen Khoa Nguyen","Thibault Dairay","Raphaël Meunier","Christophe Millet","Mathilde Mougeot"],"pdf_url":"https://arxiv.org/pdf/2212.11776v2.pdf","comment":"22 pages, 30 figures, 3 tables"},{"id":"http://arxiv.org/abs/2303.02995v1","updated":"2023-03-06T09:44:01Z","published":"2023-03-06T09:44:01Z","title":"HiCLIP: Contrastive Language-Image Pretraining with Hierarchy-aware\n  Attention","summary":"  The success of large-scale contrastive vision-language pretraining (CLIP) has\nbenefited both visual recognition and multimodal content understanding. The\nconcise design brings CLIP the advantage in inference efficiency against other\nvision-language models with heavier cross-attention fusion layers, making it a\npopular choice for a wide spectrum of downstream tasks. However, CLIP does not\nexplicitly capture the hierarchical nature of high-level and fine-grained\nsemantics conveyed in images and texts, which is arguably critical to\nvision-language understanding and reasoning. To this end, we equip both the\nvisual and language branches in CLIP with hierarchy-aware attentions, namely\nHierarchy-aware CLIP (HiCLIP), to progressively discover semantic hierarchies\nlayer-by-layer from both images and texts in an unsupervised manner. As a\nresult, such hierarchical aggregation significantly improves the cross-modal\nalignment. To demonstrate the advantages of HiCLIP, we conduct qualitative\nanalysis on its unsupervised hierarchy induction during inference, as well as\nextensive quantitative experiments on both visual recognition and\nvision-language downstream tasks.\n","authors":["Shijie Geng","Jianbo Yuan","Yu Tian","Yuxiao Chen","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.02995v1.pdf","comment":"Accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2205.14962v3","updated":"2023-03-06T09:36:15Z","published":"2022-05-30T10:00:59Z","title":"Sampling-free Inference for Ab-Initio Potential Energy Surface Networks","summary":"  Recently, it has been shown that neural networks not only approximate the\nground-state wave functions of a single molecular system well but can also\ngeneralize to multiple geometries. While such generalization significantly\nspeeds up training, each energy evaluation still requires Monte Carlo\nintegration which limits the evaluation to a few geometries. In this work, we\naddress the inference shortcomings by proposing the Potential learning from\nab-initio Networks (PlaNet) framework, in which we simultaneously train a\nsurrogate model in addition to the neural wave function. At inference time, the\nsurrogate avoids expensive Monte-Carlo integration by directly estimating the\nenergy, accelerating the process from hours to milliseconds. In this way, we\ncan accurately model high-resolution multi-dimensional energy surfaces for\nlarger systems that previously were unobtainable via neural wave functions.\nFinally, we explore an additional inductive bias by introducing\nphysically-motivated restricted neural wave function models. We implement such\na function with several additional improvements in the new PESNet++ model. In\nour experimental evaluation, PlaNet accelerates inference by 7 orders of\nmagnitude for larger molecules like ethanol while preserving accuracy. Compared\nto previous energy surface networks, PESNet++ reduces energy errors by up to\n74%.\n","authors":["Nicholas Gao","Stephan Günnemann"],"pdf_url":"https://arxiv.org/pdf/2205.14962v3.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2302.03494v7","updated":"2023-03-06T09:34:38Z","published":"2023-02-06T04:21:59Z","title":"A Categorical Archive of ChatGPT Failures","summary":"  Large language models have been demonstrated to be valuable in different\nfields. ChatGPT, developed by OpenAI, has been trained using massive amounts of\ndata and simulates human conversation by comprehending context and generating\nappropriate responses. It has garnered significant attention due to its ability\nto effectively answer a broad range of human inquiries, with fluent and\ncomprehensive answers surpassing prior public chatbots in both security and\nusefulness. However, a comprehensive analysis of ChatGPT's failures is lacking,\nwhich is the focus of this study. Eleven categories of failures, including\nreasoning, factual errors, math, coding, and bias, are presented and discussed.\nThe risks, limitations, and societal implications of ChatGPT are also\nhighlighted. The goal of this study is to assist researchers and developers in\nenhancing future language models and chatbots.\n","authors":["Ali Borji"],"pdf_url":"https://arxiv.org/pdf/2302.03494v7.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.10080v3","updated":"2023-03-06T09:33:50Z","published":"2022-09-21T02:46:13Z","title":"Deep Double Descent via Smooth Interpolation","summary":"  The ability of overparameterized deep networks to interpolate noisy data,\nwhile at the same time showing good generalization performance, has been\nrecently characterized in terms of the double descent curve for the test error.\nCommon intuition from polynomial regression suggests that overparameterized\nnetworks are able to sharply interpolate noisy data, without considerably\ndeviating from the ground-truth signal, thus preserving their generalization\nability. At present, a precise characterization of the relationship between\ninterpolation and generalization for deep networks is missing. In this work, we\nquantify sharpness of fit of the training data interpolated by neural network\nfunctions, by studying the loss landscape w.r.t.\\ to the input variable locally\nto each training point, over volumes around cleanly- and noisily-labelled\ntraining samples, as we systematically increase the number of model parameters\nand training epochs. Our findings show that loss sharpness in the input space\nfollows both model- and epoch-wise double descent, with worse peaks observed\naround noisy labels. While small interpolating models sharply fit both clean\nand noisy data, large interpolating models express a smooth loss landscape,\nwhere noisy targets are predicted over large volumes around training data\npoints, in contrast to existing intuition.\n","authors":["Matteo Gamba","Erik Englesson","Mårten Björkman","Hossein Azizpour"],"pdf_url":"https://arxiv.org/pdf/2209.10080v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02988v1","updated":"2023-03-06T09:31:42Z","published":"2023-03-06T09:31:42Z","title":"Searching for Effective Neural Network Architectures for Heart Murmur\n  Detection from Phonocardiogram","summary":"  Aim: The George B. Moody PhysioNet Challenge 2022 raised problems of heart\nmurmur detection and related abnormal cardiac function identification from\nphonocardiograms (PCGs). This work describes the novel approaches developed by\nour team, Revenger, to solve these problems.\n  Methods: PCGs were resampled to 1000 Hz, then filtered with a Butterworth\nband-pass filter of order 3, cutoff frequencies 25 - 400 Hz, and z-score\nnormalized. We used the multi-task learning (MTL) method via hard parameter\nsharing to train one neural network (NN) model for all the Challenge tasks. We\nperformed neural architecture searching among a set of network backbones,\nincluding multi-branch convolutional neural networks (CNNs), SE-ResNets,\nTResNets, simplified wav2vec2, etc.\n  Based on a stratified splitting of the subjects, 20% of the public data was\nleft out as a validation set for model selection. The AdamW optimizer was\nadopted, along with the OneCycle scheduler, to optimize the model weights.\n  Results: Our murmur detection classifier received a weighted accuracy score\nof 0.736 (ranked 14th out of 40 teams) and a Challenge cost score of 12944\n(ranked 19th out of 39 teams) on the hidden validation set.\n  Conclusion: We provided a practical solution to the problems of detecting\nheart murmurs and providing clinical diagnosis suggestions from PCGs.\n","authors":["Hao Wen","Jingsu Kang"],"pdf_url":"https://arxiv.org/pdf/2303.02988v1.pdf","comment":"4 pages, 5 figures, Computing in Cardiology 2022, URL:\n  https://github.com/DeepPSP/cinc2022"},{"id":"http://arxiv.org/abs/2303.02984v1","updated":"2023-03-06T09:23:14Z","published":"2023-03-06T09:23:14Z","title":"Learning multi-scale local conditional probability models of images","summary":"  Deep neural networks can learn powerful prior probability models for images,\nas evidenced by the high-quality generations obtained with recent score-based\ndiffusion methods. But the means by which these networks capture complex global\nstatistical structure, apparently without suffering from the curse of\ndimensionality, remain a mystery. To study this, we incorporate diffusion\nmethods into a multi-scale decomposition, reducing dimensionality by assuming a\nstationary local Markov model for wavelet coefficients conditioned on\ncoarser-scale coefficients. We instantiate this model using convolutional\nneural networks (CNNs) with local receptive fields, which enforce both the\nstationarity and Markov properties. Global structures are captured using a CNN\nwith receptive fields covering the entire (but small) low-pass image. We test\nthis model on a dataset of face images, which are highly non-stationary and\ncontain large-scale geometric structures. Remarkably, denoising,\nsuper-resolution, and image synthesis results all demonstrate that these\nstructures can be captured with significantly smaller conditioning\nneighborhoods than required by a Markov model implemented in the pixel domain.\nOur results show that score estimation for large complex images can be reduced\nto low-dimensional Markov conditional models across scales, alleviating the\ncurse of dimensionality.\n","authors":["Zahra Kadkhodaie","Florentin Guth","Stéphane Mallat","Eero P Simoncelli"],"pdf_url":"https://arxiv.org/pdf/2303.02984v1.pdf","comment":"16 pages, 8 figures"},{"id":"http://arxiv.org/abs/2303.02980v1","updated":"2023-03-06T09:15:28Z","published":"2023-03-06T09:15:28Z","title":"KDSM: An uplift modeling framework based on knowledge distillation and\n  sample matching","summary":"  Uplift modeling aims to estimate the treatment effect on individuals, widely\napplied in the e-commerce platform to target persuadable customers and maximize\nthe return of marketing activities. Among the existing uplift modeling methods,\ntree-based methods are adept at fitting increment and generalization, while\nneural-network-based models excel at predicting absolute value and precision,\nand these advantages have not been fully explored and combined. Also, the lack\nof counterfactual sample pairs is the root challenge in uplift modeling. In\nthis paper, we proposed an uplift modeling framework based on Knowledge\nDistillation and Sample Matching (KDSM). The teacher model is the uplift\ndecision tree (UpliftDT), whose structure is exploited to construct\ncounterfactual sample pairs, and the pairwise incremental prediction is treated\nas another objective for the student model. Under the idea of multitask\nlearning, the student model can achieve better performance on generalization\nand even surpass the teacher. Extensive offline experiments validate the\nuniversality of different combinations of teachers and student models and the\nsuperiority of KDSM measured against the baselines. In online A/B testing, the\ncost of each incremental room night is reduced by 6.5\\%.\n","authors":["Chang Sun","Qianying Li","Guanxiang Wang","Sihao Xu","Yitong Liu"],"pdf_url":"https://arxiv.org/pdf/2303.02980v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02970v1","updated":"2023-03-06T08:54:18Z","published":"2023-03-06T08:54:18Z","title":"Rethinking Confidence Calibration for Failure Prediction","summary":"  Reliable confidence estimation for the predictions is important in many\nsafety-critical applications. However, modern deep neural networks are often\noverconfident for their incorrect predictions. Recently, many calibration\nmethods have been proposed to alleviate the overconfidence problem. With\ncalibrated confidence, a primary and practical purpose is to detect\nmisclassification errors by filtering out low-confidence predictions (known as\nfailure prediction). In this paper, we find a general, widely-existed but\nactually-neglected phenomenon that most confidence calibration methods are\nuseless or harmful for failure prediction. We investigate this problem and\nreveal that popular confidence calibration methods often lead to worse\nconfidence separation between correct and incorrect samples, making it more\ndifficult to decide whether to trust a prediction or not. Finally, inspired by\nthe natural connection between flat minima and confidence separation, we\npropose a simple hypothesis: flat minima is beneficial for failure prediction.\nWe verify this hypothesis via extensive experiments and further boost the\nperformance by combining two different flat minima techniques. Our code is\navailable at https://github.com/Impression2805/FMFP\n","authors":["Fei Zhu","Zhen Cheng","Xu-Yao Zhang","Cheng-Lin Liu"],"pdf_url":"https://arxiv.org/pdf/2303.02970v1.pdf","comment":"Accepted to ECCV 2022. Code is available at\n  https://github.com/Impression2805/FMFP"},{"id":"http://arxiv.org/abs/2303.02966v1","updated":"2023-03-06T08:51:00Z","published":"2023-03-06T08:51:00Z","title":"Non-Parametric Outlier Synthesis","summary":"  Out-of-distribution (OOD) detection is indispensable for safely deploying\nmachine learning models in the wild. One of the key challenges is that models\nlack supervision signals from unknown data, and as a result, can produce\noverconfident predictions on OOD data. Recent work on outlier synthesis modeled\nthe feature space as parametric Gaussian distribution, a strong and restrictive\nassumption that might not hold in reality. In this paper, we propose a novel\nframework, Non-Parametric Outlier Synthesis (NPOS), which generates artificial\nOOD training data and facilitates learning a reliable decision boundary between\nID and OOD data. Importantly, our proposed synthesis approach does not make any\ndistributional assumption on the ID embeddings, thereby offering strong\nflexibility and generality. We show that our synthesis approach can be\nmathematically interpreted as a rejection sampling framework. Extensive\nexperiments show that NPOS can achieve superior OOD detection performance,\noutperforming the competitive rivals by a significant margin. Code is publicly\navailable at https://github.com/deeplearning-wisc/npos.\n","authors":["Leitian Tao","Xuefeng Du","Xiaojin Zhu","Yixuan Li"],"pdf_url":"https://arxiv.org/pdf/2303.02966v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.02957v1","updated":"2023-03-06T08:05:08Z","published":"2023-03-06T08:05:08Z","title":"Primal and Dual Analysis of Entropic Fictitious Play for Finite-sum\n  Problems","summary":"  The entropic fictitious play (EFP) is a recently proposed algorithm that\nminimizes the sum of a convex functional and entropy in the space of measures\n-- such an objective naturally arises in the optimization of a two-layer neural\nnetwork in the mean-field regime. In this work, we provide a concise\nprimal-dual analysis of EFP in the setting where the learning problem exhibits\na finite-sum structure. We establish quantitative global convergence guarantees\nfor both the continuous-time and discrete-time dynamics based on properties of\na proximal Gibbs measure introduced in Nitanda et al. (2022). Furthermore, our\nprimal-dual framework entails a memory-efficient particle-based implementation\nof the EFP update, and also suggests a connection to gradient boosting methods.\nWe illustrate the efficiency of our novel implementation in experiments\nincluding neural network optimization and image synthesis.\n","authors":["Atsushi Nitanda","Kazusato Oko","Denny Wu","Nobuhito Takenouchi","Taiji Suzuki"],"pdf_url":"https://arxiv.org/pdf/2303.02957v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02954v1","updated":"2023-03-06T07:54:37Z","published":"2023-03-06T07:54:37Z","title":"Centroid Distance Distillation for Effective Rehearsal in Continual\n  Learning","summary":"  Rehearsal, retraining on a stored small data subset of old tasks, has been\nproven effective in solving catastrophic forgetting in continual learning.\nHowever, due to the sampled data may have a large bias towards the original\ndataset, retraining them is susceptible to driving continual domain drift of\nold tasks in feature space, resulting in forgetting. In this paper, we focus on\ntackling the continual domain drift problem with centroid distance\ndistillation. First, we propose a centroid caching mechanism for sampling data\npoints based on constructed centroids to reduce the sample bias in rehearsal.\nThen, we present a centroid distance distillation that only stores the centroid\ndistance to reduce the continual domain drift. The experiments on four\ncontinual learning datasets show the superiority of the proposed method, and\nthe continual domain drift can be reduced.\n","authors":["Daofeng Liu","Fan Lyu","Linyan Li","Zhenping Xia","Fuyuan Hu"],"pdf_url":"https://arxiv.org/pdf/2303.02954v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03390v2","updated":"2023-03-06T07:11:19Z","published":"2023-02-07T10:51:53Z","title":"Learning Discretized Neural Networks under Ricci Flow","summary":"  In this paper, we consider Discretized Neural Networks (DNNs) consisting of\nlow-precision weights and activations, which suffer from either infinite or\nzero gradients caused by the non-differentiable discrete function in the\ntraining process. In this case, most training-based DNNs use the standard\nStraight-Through Estimator (STE) to approximate the gradient w.r.t. discrete\nvalues. However, the STE will cause the problem of gradient mismatch, which\nimplies that the approximated gradient is with perturbations. We propose an\nanalysis that this mismatch can be viewed as a metric perturbation in a\nRiemannian manifold through the lens of duality theory. To address this\nproblem, based on the information geometry, we construct the Linearly Nearly\nEuclidean (LNE) manifold for DNNs as a background to deal with perturbations.\nBy introducing a partial differential equation on metrics, the Ricci flow, we\nprove the dynamical stability and convergence of the LNE metric with the\n$L^2$-norm perturbation. And unlike the previous perturbation theory which\ngives the rate of convergence is the fractional powers, we yield the metric\nperturbation under the Ricci flow can be exponentially decayed in the LNE\nmanifold. The experimental results on various datasets demonstrate that our\nmethod achieves better and more stable performance for DNNs than other\nrepresentative training-based methods.\n","authors":["Jun Chen","Hanwen Chen","Mengmeng Wang","Guang Dai","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2302.03390v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02918v1","updated":"2023-03-06T06:28:20Z","published":"2023-03-06T06:28:20Z","title":"Graph Positional Encoding via Random Feature Propagation","summary":"  Two main families of node feature augmentation schemes have been explored for\nenhancing GNNs: random features and spectral positional encoding. Surprisingly,\nhowever, there is still no clear understanding of the relation between these\ntwo augmentation schemes. Here we propose a novel family of positional encoding\nschemes which draws a link between the above two approaches and improves over\nboth. The new approach, named Random Feature Propagation (RFP), is inspired by\nthe power iteration method and its generalizations. It concatenates several\nintermediate steps of an iterative algorithm for computing the dominant\neigenvectors of a propagation matrix, starting from random node features.\nNotably, these propagation steps are based on graph-dependent propagation\noperators that can be either predefined or learned. We explore the theoretical\nand empirical benefits of RFP. First, we provide theoretical justifications for\nusing random features, for incorporating early propagation steps, and for using\nmultiple random initializations. Then, we empirically demonstrate that RFP\nsignificantly outperforms both spectral PE and random features in multiple node\nclassification and graph classification benchmarks.\n","authors":["Moshe Eliasof","Fabrizio Frasca","Beatrice Bevilacqua","Eran Treister","Gal Chechik","Haggai Maron"],"pdf_url":"https://arxiv.org/pdf/2303.02918v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.07646v3","updated":"2023-03-06T06:28:18Z","published":"2022-02-15T18:48:31Z","title":"Quantifying Memorization Across Neural Language Models","summary":"  Large language models (LMs) have been shown to memorize parts of their\ntraining data, and when prompted appropriately, they will emit the memorized\ntraining data verbatim. This is undesirable because memorization violates\nprivacy (exposing user data), degrades utility (repeated easy-to-memorize text\nis often low quality), and hurts fairness (some texts are memorized over\nothers).\n  We describe three log-linear relationships that quantify the degree to which\nLMs emit memorized training data. Memorization significantly grows as we\nincrease (1) the capacity of a model, (2) the number of times an example has\nbeen duplicated, and (3) the number of tokens of context used to prompt the\nmodel. Surprisingly, we find the situation becomes more complicated when\ngeneralizing these results across model families. On the whole, we find that\nmemorization in LMs is more prevalent than previously believed and will likely\nget worse as models continues to scale, at least without active mitigations.\n","authors":["Nicholas Carlini","Daphne Ippolito","Matthew Jagielski","Katherine Lee","Florian Tramer","Chiyuan Zhang"],"pdf_url":"https://arxiv.org/pdf/2202.07646v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.10550v2","updated":"2023-03-06T06:28:05Z","published":"2022-06-21T17:27:27Z","title":"(Certified!!) Adversarial Robustness for Free!","summary":"  In this paper we show how to achieve state-of-the-art certified adversarial\nrobustness to 2-norm bounded perturbations by relying exclusively on\noff-the-shelf pretrained models. To do so, we instantiate the denoised\nsmoothing approach of Salman et al. 2020 by combining a pretrained denoising\ndiffusion probabilistic model and a standard high-accuracy classifier. This\nallows us to certify 71% accuracy on ImageNet under adversarial perturbations\nconstrained to be within an 2-norm of 0.5, an improvement of 14 percentage\npoints over the prior certified SoTA using any approach, or an improvement of\n30 percentage points over denoised smoothing. We obtain these results using\nonly pretrained diffusion models and image classifiers, without requiring any\nfine tuning or retraining of model parameters.\n","authors":["Nicholas Carlini","Florian Tramer","Krishnamurthy Dj Dvijotham","Leslie Rice","Mingjie Sun","J. Zico Kolter"],"pdf_url":"https://arxiv.org/pdf/2206.10550v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02902v1","updated":"2023-03-06T05:38:13Z","published":"2023-03-06T05:38:13Z","title":"A Topological Distance Measure between Multi-Fields for Classification\n  and Analysis of Shapes and Data","summary":"  Distance measures play an important role in shape classification and data\nanalysis problems. Topological distances based on Reeb graphs and persistence\ndiagrams have been employed to obtain effective algorithms in shape matching\nand scalar data analysis. In the current paper, we propose an improved distance\nmeasure between two multi-fields by computing a multi-dimensional Reeb graph\n(MDRG) each of which captures the topology of a multi-field through a hierarchy\nof Reeb graphs in different dimensions. A hierarchy of persistence diagrams is\nthen constructed by computing a persistence diagram corresponding to each Reeb\ngraph of the MDRG. Based on this representation, we propose a novel distance\nmeasure between two MDRGs by extending the bottleneck distance between two Reeb\ngraphs. We show that the proposed measure satisfies the pseudo-metric and\nstability properties. We examine the effectiveness of the proposed multi-field\ntopology-based measure on two different applications: (1) shape classification\nand (2) detection of topological features in a time-varying multi-field data.\nIn the shape classification problem, the performance of the proposed measure is\ncompared with the well-known topology-based measures in shape matching. In the\nsecond application, we consider a time-varying volumetric multi-field data from\nthe field of computational chemistry where the goal is to detect the site of\nstable bond formation between Pt and CO molecules. We demonstrate the ability\nof the proposed distance in classifying each of the sites as occurring before\nand after the bond stabilization.\n","authors":["Yashwanth Ramamurthi","Amit Chattopadhyay"],"pdf_url":"https://arxiv.org/pdf/2303.02902v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02901v1","updated":"2023-03-06T05:35:32Z","published":"2023-03-06T05:35:32Z","title":"The $α$-divergence Improves the Entropy Production Estimation via\n  Machine Learning","summary":"  Recent years have seen a surge of interest in the algorithmic estimation of\nstochastic entropy production (EP) from the trajectory data via machine\nlearning. A crucial element of such algorithms is the identification of a loss\nfunction whose minimization guarantees the accurate EP estimation. In this\nstudy, we show that there exists a host of loss functions, namely those\nimplementing a variational representation of the $\\alpha$-divergence, which can\nbe used for the EP estimation. Among these loss functions, the one\ncorresponding to $\\alpha = -0.5$ exhibits the most robust performance against\nstrong nonequilibrium driving or slow dynamics, which adversely affects the\nexisting method based on the Kullback-Leibler divergence ($\\alpha = 0$). To\ncorroborate our findings, we present an exactly solvable simplification of the\nEP estimation problem, whose loss function landscape and stochastic properties\ndemonstrate the optimality of $\\alpha = -0.5$.\n","authors":["Euijoon Kwon","Yongjoo Baek"],"pdf_url":"https://arxiv.org/pdf/2303.02901v1.pdf","comment":"9 pages, 7 figures"},{"id":"http://arxiv.org/abs/2303.02898v1","updated":"2023-03-06T05:23:44Z","published":"2023-03-06T05:23:44Z","title":"Stabilizing the Maximal Entropy Moment Method for Rarefied Gas Dynamics\n  at Single-Precision","summary":"  Developing extended hydrodynamics equations valid for both dense and rarefied\ngases remains a great challenge. A systematical solution for this challenge is\nthe moment method describing both dense and rarefied gas behaviors with moments\nof gas molecule velocity distributions. Among moment methods, the maximal\nentropy moment method (MEM) stands out for its well-posedness and stability,\nwhich utilizes velocity distributions with maximized entropy. However, finding\nsuch distributions requires solving an ill-conditioned and\ncomputation-demanding optimization problem. This problem causes numerical\noverflow and breakdown when the numerical precision is insufficient, especially\nfor flows like high-speed shock waves. It also prevents modern GPUs from\naccelerating optimization with their enormous single floating-point precision\ncomputation power. This paper aims to stabilize MEM, making it practical for\nsimulating very strong normal shock waves on modern GPUs at single precision.\nWe propose the gauge transformations for MEM, making the optimization less\nill-conditioned. We also tackle numerical overflow and breakdown by adopting\nthe canonical form of distribution and Newton's modified optimization method.\nWith these techniques, we achieved a single-precision GPU simulation of a Mach\n10 shock wave with 35 moments MEM, surpassing the previous double-precision\nresults of Mach 4. Moreover, we argued that over-refined spatial mesh degrades\nboth the accuracy and stability of MEM. Overall, this paper makes the maximal\nentropy moment method practical for simulating very strong normal shock waves\non modern GPUs at single-precision, with significant stability improvement\ncompared to previous methods.\n","authors":["Candi Zheng","Wang Yang","Shiyi Chen"],"pdf_url":"https://arxiv.org/pdf/2303.02898v1.pdf","comment":"25 pages, 5 figures"},{"id":"http://arxiv.org/abs/2210.15809v2","updated":"2023-03-06T04:54:25Z","published":"2022-10-28T00:14:00Z","title":"Coverage-centric Coreset Selection for High Pruning Rates","summary":"  One-shot coreset selection aims to select a representative subset of the\ntraining data, given a pruning rate, that can later be used to train future\nmodels while retaining high accuracy. State-of-the-art coreset selection\nmethods pick the highest importance examples based on an importance metric and\nare found to perform well at low pruning rates. However, at high pruning rates,\nthey suffer from a catastrophic accuracy drop, performing worse than even\nrandom sampling. This paper explores the reasons behind this accuracy drop both\ntheoretically and empirically. We first propose a novel metric to measure the\ncoverage of a dataset on a specific distribution by extending the classical\ngeometric set cover problem to a distribution cover problem. This metric helps\nexplain why coresets selected by SOTA methods at high pruning rates perform\npoorly compared to random sampling because of worse data coverage. We then\npropose a novel one-shot coreset selection method, Coverage-centric Coreset\nSelection (CCS), that jointly considers overall data coverage upon a\ndistribution as well as the importance of each example. We evaluate CCS on five\ndatasets and show that, at high pruning rates (e.g., 90%), it achieves\nsignificantly better accuracy than previous SOTA methods (e.g., at least 19.56%\nhigher on CIFAR10) as well as random selection (e.g., 7.04% higher on CIFAR10)\nand comparable accuracy at low pruning rates. We make our code publicly\navailable at\nhttps://github.com/haizhongzheng/Coverage-centric-coreset-selection.\n","authors":["Haizhong Zheng","Rui Liu","Fan Lai","Atul Prakash"],"pdf_url":"https://arxiv.org/pdf/2210.15809v2.pdf","comment":"International Conference on Learning Representations (ICLR) 2023"},{"id":"http://arxiv.org/abs/2303.02891v1","updated":"2023-03-06T04:49:38Z","published":"2023-03-06T04:49:38Z","title":"Perspectives on the Social Impacts of Reinforcement Learning with Human\n  Feedback","summary":"  Is it possible for machines to think like humans? And if it is, how should we\ngo about teaching them to do so? As early as 1950, Alan Turing stated that we\nought to teach machines in the way of teaching a child. Reinforcement learning\nwith human feedback (RLHF) has emerged as a strong candidate toward allowing\nagents to learn from human feedback in a naturalistic manner. RLHF is distinct\nfrom traditional reinforcement learning as it provides feedback from a human\nteacher in addition to a reward signal. It has been catapulted into public view\nby multiple high-profile AI applications, including OpenAI's ChatGPT,\nDeepMind's Sparrow, and Anthropic's Claude. These highly capable chatbots are\nalready overturning our understanding of how AI interacts with humanity. The\nwide applicability and burgeoning success of RLHF strongly motivate the need to\nevaluate its social impacts. In light of recent developments, this paper\nconsiders an important question: can RLHF be developed and used without\nnegatively affecting human societies? Our objectives are threefold: to provide\na systematic study of the social effects of RLHF; to identify key social and\nethical issues of RLHF; and to discuss social impacts for stakeholders.\nAlthough text-based applications of RLHF have received much attention, it is\ncrucial to consider when evaluating its social implications the diverse range\nof areas to which it may be deployed. We describe seven primary ways in which\nRLHF-based technologies will affect society by positively transforming human\nexperiences with AI. This paper ultimately proposes that RLHF has potential to\nnet positively impact areas of misinformation, AI value-alignment, bias, AI\naccess, cross-cultural dialogue, industry, and workforce. As RLHF raises\nconcerns that echo those of existing AI technologies, it will be important for\nall to be aware and intentional in the adoption of RLHF.\n","authors":["Gabrielle Kaili-May Liu"],"pdf_url":"https://arxiv.org/pdf/2303.02891v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02890v1","updated":"2023-03-06T04:45:53Z","published":"2023-03-06T04:45:53Z","title":"An Analysis of Physics-Informed Neural Networks","summary":"  Whilst the partial differential equations that govern the dynamics of our\nworld have been studied in great depth for centuries, solving them for complex,\nhigh-dimensional conditions and domains still presents an incredibly large\nmathematical and computational challenge. Analytical methods can be cumbersome\nto utilise, and numerical methods can lead to errors and inaccuracies. On top\nof this, sometimes we lack the information or knowledge to pose the problem\nwell enough to apply these kinds of methods. Here, we present a new approach to\napproximating the solution to physical systems - physics-informed neural\nnetworks. The concept of artificial neural networks is introduced, the\nobjective function is defined, and optimisation strategies are discussed. The\npartial differential equation is then included as a constraint in the loss\nfunction for the optimisation problem, giving the network access to knowledge\nof the dynamics of the physical system it is modelling. Some intuitive examples\nare displayed, and more complex applications are considered to showcase the\npower of physics informed neural networks, such as in seismic imaging. Solution\nerror is analysed, and suggestions are made to improve convergence and/or\nsolution precision. Problems and limitations are also touched upon in the\nconclusions, as well as some thoughts as to where physics informed neural\nnetworks are most useful, and where they could go next.\n","authors":["Edward Small"],"pdf_url":"https://arxiv.org/pdf/2303.02890v1.pdf","comment":"56 pages"},{"id":"http://arxiv.org/abs/2303.02884v1","updated":"2023-03-06T04:31:36Z","published":"2023-03-06T04:31:36Z","title":"Model Sketching: Centering Concepts in Early-Stage Machine Learning\n  Model Design","summary":"  Machine learning practitioners often end up tunneling on low-level technical\ndetails like model architectures and performance metrics. Could early model\ndevelopment instead focus on high-level questions of which factors a model\nought to pay attention to? Inspired by the practice of sketching in design,\nwhich distills ideas to their minimal representation, we introduce model\nsketching: a technical framework for iteratively and rapidly authoring\nfunctional approximations of a machine learning model's decision-making logic.\nModel sketching refocuses practitioner attention on composing high-level,\nhuman-understandable concepts that the model is expected to reason over (e.g.,\nprofanity, racism, or sarcasm in a content moderation task) using zero-shot\nconcept instantiation. In an evaluation with 17 ML practitioners, model\nsketching reframed thinking from implementation to higher-level exploration,\nprompted iteration on a broader range of model designs, and helped identify\ngaps in the problem formulation$\\unicode{x2014}$all in a fraction of the time\nordinarily required to build a model.\n","authors":["Michelle S. Lam","Zixian Ma","Anne Li","Izequiel Freitas","Dakuo Wang","James A. Landay","Michael S. Bernstein"],"pdf_url":"https://arxiv.org/pdf/2303.02884v1.pdf","comment":"To appear at CHI 2023"},{"id":"http://arxiv.org/abs/2303.02883v1","updated":"2023-03-06T04:29:30Z","published":"2023-03-06T04:29:30Z","title":"Very fast, approximate counterfactual explanations for decision forests","summary":"  We consider finding a counterfactual explanation for a classification or\nregression forest, such as a random forest. This requires solving an\noptimization problem to find the closest input instance to a given instance for\nwhich the forest outputs a desired value. Finding an exact solution has a cost\nthat is exponential on the number of leaves in the forest. We propose a simple\nbut very effective approach: we constrain the optimization to only those input\nspace regions defined by the forest that are populated by actual data points.\nThe problem reduces to a form of nearest-neighbor search using a certain\ndistance on a certain dataset. This has two advantages: first, the solution can\nbe found very quickly, scaling to large forests and high-dimensional data, and\nenabling interactive use. Second, the solution found is more likely to be\nrealistic in that it is guided towards high-density areas of input space.\n","authors":["Miguel Á. Carreira-Perpiñán","Suryabhan Singh Hada"],"pdf_url":"https://arxiv.org/pdf/2303.02883v1.pdf","comment":"A shorter version of this paper appears in AAAI 2023"},{"id":"http://arxiv.org/abs/2303.02880v1","updated":"2023-03-06T04:15:29Z","published":"2023-03-06T04:15:29Z","title":"Spatiotemporal Capsule Neural Network for Vehicle Trajectory Prediction","summary":"  Through advancement of the Vehicle-to-Everything (V2X) network, road safety,\nenergy consumption, and traffic efficiency can be significantly improved. An\naccurate vehicle trajectory prediction benefits communication traffic\nmanagement and network resource allocation for the real-time application of the\nV2X network. Recurrent neural networks and their variants have been reported in\nrecent research to predict vehicle mobility. However, the spatial attribute of\nvehicle movement behavior has been overlooked, resulting in incomplete\ninformation utilization. To bridge this gap, we put forward for the first time\na hierarchical trajectory prediction structure using the capsule neural network\n(CapsNet) with three sequential components. First, the geographic information\nis transformed into a grid map presentation, describing vehicle mobility\ndistribution spatially and temporally. Second, CapsNet serves as the core model\nto embed local temporal and global spatial correlation through hierarchical\ncapsules. Finally, extensive experiments conducted on actual taxi mobility data\ncollected in Porto city (Portugal) and Singapore show that the proposed method\noutperforms the state-of-the-art methods.\n","authors":["Yan Qin","Yong Liang Guan","Chau Yuen"],"pdf_url":"https://arxiv.org/pdf/2303.02880v1.pdf","comment":"IEEE TVT has accepted this paper"},{"id":"http://arxiv.org/abs/2303.02879v1","updated":"2023-03-06T04:14:04Z","published":"2023-03-06T04:14:04Z","title":"A Review of Deep Learning-Powered Mesh Reconstruction Methods","summary":"  With the recent advances in hardware and rendering techniques, 3D models have\nemerged everywhere in our life. Yet creating 3D shapes is arduous and requires\nsignificant professional knowledge. Meanwhile, Deep learning has enabled\nhigh-quality 3D shape reconstruction from various sources, making it a viable\napproach to acquiring 3D shapes with minimal effort. Importantly, to be used in\ncommon 3D applications, the reconstructed shapes need to be represented as\npolygonal meshes, which is a challenge for neural networks due to the\nirregularity of mesh tessellations. In this survey, we provide a comprehensive\nreview of mesh reconstruction methods that are powered by machine learning. We\nfirst describe various representations for 3D shapes in the deep learning\ncontext. Then we review the development of 3D mesh reconstruction methods from\nvoxels, point clouds, single images, and multi-view images. Finally, we\nidentify several challenges in this field and propose potential future\ndirections.\n","authors":["Zhiqin Chen"],"pdf_url":"https://arxiv.org/pdf/2303.02879v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01240v2","updated":"2023-03-06T04:10:12Z","published":"2023-03-01T11:37:43Z","title":"The Point to Which Soft Actor-Critic Converges","summary":"  Soft actor-critic is a successful successor over soft Q-learning. While lived\nunder maximum entropy framework, their relationship is still unclear. In this\npaper, we prove that in the limit they converge to the same solution. This is\nappealing since it translates the optimization from an arduous to an easier\nway. The same justification can also be applied to other regularizers such as\nKL divergence.\n","authors":["Jianfei Ma"],"pdf_url":"https://arxiv.org/pdf/2303.01240v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02876v1","updated":"2023-03-06T04:04:19Z","published":"2023-03-06T04:04:19Z","title":"Finding metastable skyrmionic structures via a metaheuristic\n  perturbation-driven neural network","summary":"  Topological magnetic textures observed in experiments can, in principle, be\npredicted by theoretical calculations and numerical simulations. However, such\ncalculations are, in general, hampered by difficulties in distinguishing\nbetween local and global energy minima. This becomes particularly problematic\nfor magnetic materials that allow for a multitude of topological charges.\nFinding solutions to such problems by means of classical numerical methods can\nbe challenging because either a good initial guess or a gigantic amount of\nrandom sampling is required. In this study, we demonstrate an efficient way to\nidentify those metastable configurations by leveraging the power of gradient\ndescent-based optimization within the framework of a feedforward neural network\ncombined with a heuristic meta-search, which is driven by a random perturbation\nof the neural network's input. We exemplify the power of the method by an\nanalysis of the Pd/Fe/Ir(111) system, an experimentally well characterized\nsystem.\n","authors":["Qichen Xu","I. P. Miranda","Manuel Pereiro","Filipp N. Rybakov","Danny Thonig","Erik Sjöqvist","Pavel Bessarab","Anders Bergman","Olle Eriksson","Pawel Herman","Anna Delin"],"pdf_url":"https://arxiv.org/pdf/2303.02876v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02875v1","updated":"2023-03-06T04:01:28Z","published":"2023-03-06T04:01:28Z","title":"DR-Label: Improving GNN Models for Catalysis Systems by Label\n  Deconstruction and Reconstruction","summary":"  Attaining the equilibrium state of a catalyst-adsorbate system is key to\nfundamentally assessing its effective properties, such as adsorption energy.\nMachine learning methods with finer supervision strategies have been applied to\nboost and guide the relaxation process of an atomic system and better predict\nits properties at the equilibrium state. In this paper, we present a novel\ngraph neural network (GNN) supervision and prediction strategy DR-Label. The\nmethod enhances the supervision signal, reduces the multiplicity of solutions\nin edge representation, and encourages the model to provide node predictions\nthat are graph structural variation robust. DR-Label first Deconstructs\nfiner-grained equilibrium state information to the model by projecting the\nnode-level supervision signal to each edge. Reversely, the model Reconstructs a\nmore robust equilibrium state prediction by transforming edge-level predictions\nto node-level with a sphere-fitting algorithm. The DR-Label strategy was\napplied to three radically distinct models, each of which displayed consistent\nperformance enhancements. Based on the DR-Label strategy, we further proposed\nDRFormer, which achieved a new state-of-the-art performance on the Open\nCatalyst 2020 (OC20) dataset and the Cu-based single-atom-alloyed CO adsorption\n(SAA) dataset. We expect that our work will highlight crucial steps for the\ndevelopment of a more accurate model in equilibrium state property prediction\nof a catalysis system.\n","authors":["Bowen Wang","Chen Liang","Jiaze Wang","Furui Liu","Shaogang Hao","Dong Li","Jianye Hao","Guangyong Chen","Xiaolong Zou","Pheng-Ann Heng"],"pdf_url":"https://arxiv.org/pdf/2303.02875v1.pdf","comment":"11 pages, 3 figures"},{"id":"http://arxiv.org/abs/2303.02874v1","updated":"2023-03-06T03:55:37Z","published":"2023-03-06T03:55:37Z","title":"Adversarial Sampling for Fairness Testing in Deep Neural Network","summary":"  In this research, we focus on the usage of adversarial sampling to test for\nthe fairness in the prediction of deep neural network model across different\nclasses of image in a given dataset. While several framework had been proposed\nto ensure robustness of machine learning model against adversarial attack, some\nof which includes adversarial training algorithm. There is still the pitfall\nthat adversarial training algorithm tends to cause disparity in accuracy and\nrobustness among different group. Our research is aimed at using adversarial\nsampling to test for fairness in the prediction of deep neural network model\nacross different classes or categories of image in a given dataset. We\nsuccessfully demonstrated a new method of ensuring fairness across various\ngroup of input in deep neural network classifier. We trained our neural network\nmodel on the original image, and without training our model on the perturbed or\nattacked image. When we feed the adversarial samplings to our model, it was\nable to predict the original category/ class of the image the adversarial\nsample belongs to. We also introduced and used the separation of concern\nconcept from software engineering whereby there is an additional standalone\nfilter layer that filters perturbed image by heavily removing the noise or\nattack before automatically passing it to the network for classification, we\nwere able to have accuracy of 93.3%. Cifar-10 dataset have ten categories of\ndataset, and so, in order to account for fairness, we applied our hypothesis\nacross each categories of dataset and were able to get a consistent result and\naccuracy.\n","authors":["Tosin Ige","William Marfo","Justin Tonkinson","Sikiru Adewale","Bolanle Hafiz Matti"],"pdf_url":"https://arxiv.org/pdf/2303.02874v1.pdf","comment":"7 pages, 5 figures, International Journal of Advanced Computer\n  Science and Application"},{"id":"http://arxiv.org/abs/2206.08289v2","updated":"2023-03-06T03:54:50Z","published":"2022-06-16T16:46:32Z","title":"Switchable Representation Learning Framework with Self-compatibility","summary":"  Real-world visual search systems involve deployments on multiple platforms\nwith different computing and storage resources. Deploying a unified model that\nsuits the minimal-constrain platforms leads to limited accuracy. It is expected\nto deploy models with different capacities adapting to the resource\nconstraints, which requires features extracted by these models to be aligned in\nthe metric space. The method to achieve feature alignments is called\n``compatible learning''. Existing research mainly focuses on the one-to-one\ncompatible paradigm, which is limited in learning compatibility among multiple\nmodels. We propose a \\textbf{S}witchable representation learning Framework with\nSelf-Compatibility (SFSC). SFSC generates a series of compatible sub-models\nwith different capacities through one training process. The optimization of\nsub-models faces gradients conflict, and we mitigate this problem from the\nperspective of the magnitude and direction. We adjust the priorities of\nsub-models dynamically through uncertainty estimation to co-optimize sub-models\nproperly. Besides, the gradients with conflicting directions are projected to\navoid mutual interference. SFSC achieves state-of-the-art performance on the\nevaluated datasets.\n","authors":["Shengsen Wu","Yan Bai","Yihang Lou","Xiongkun Linghu","Jianzhong He","Ling-Yu Duan"],"pdf_url":"https://arxiv.org/pdf/2206.08289v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01506v2","updated":"2023-03-06T03:41:17Z","published":"2023-03-02T04:50:05Z","title":"Understanding and Unifying Fourteen Attribution Methods with Taylor\n  Interactions","summary":"  Various attribution methods have been developed to explain deep neural\nnetworks (DNNs) by inferring the attribution/importance/contribution score of\neach input variable to the final output. However, existing attribution methods\nare often built upon different heuristics. There remains a lack of a unified\ntheoretical understanding of why these methods are effective and how they are\nrelated. To this end, for the first time, we formulate core mechanisms of\nfourteen attribution methods, which were designed on different heuristics, into\nthe same mathematical system, i.e., the system of Taylor interactions.\nSpecifically, we prove that attribution scores estimated by fourteen\nattribution methods can all be reformulated as the weighted sum of two types of\neffects, i.e., independent effects of each individual input variable and\ninteraction effects between input variables. The essential difference among the\nfourteen attribution methods mainly lies in the weights of allocating different\neffects. Based on the above findings, we propose three principles for a fair\nallocation of effects to evaluate the faithfulness of the fourteen attribution\nmethods.\n","authors":["Huiqi Deng","Na Zou","Mengnan Du","Weifu Chen","Guocan Feng","Ziwei Yang","Zheyang Li","Quanshi Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.01506v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02868v1","updated":"2023-03-06T03:36:26Z","published":"2023-03-06T03:36:26Z","title":"Angel-PTM: A Scalable and Economical Large-scale Pre-training System in\n  Tencent","summary":"  Recent years have witnessed the unprecedented achievements of large-scale\npre-trained models, especially the Transformer models. Many products and\nservices in Tencent Inc., such as WeChat, QQ, and Tencent Advertisement, have\nbeen opted in to gain the power of pre-trained models. In this work, we present\nAngel-PTM, a productive deep learning system designed for pre-training and\nfine-tuning Transformer models. Angel-PTM can train extremely large-scale\nmodels with hierarchical memory efficiently. The key designs of Angel-PTM are\nthe fine-grained memory management via the Page abstraction and a unified\nscheduling method that coordinate the computations, data movements, and\ncommunications. Furthermore, Angel-PTM supports extreme model scaling with SSD\nstorage and implements the lock-free updating mechanism to address the SSD I/O\nbandwidth bottlenecks. Experimental results demonstrate that Angel-PTM\noutperforms existing systems by up to 114.8% in terms of maximum model scale as\nwell as up to 88.9% in terms of training throughput. Additionally, experiments\non GPT3-175B and T5-MoE-1.2T models utilizing hundreds of GPUs verify the\nstrong scalability of Angel-PTM.\n","authors":["Xiaonan Nie","Yi Liu","Fangcheng Fu","Jinbao Xue","Dian Jiao","Xupeng Miao","Yangyu Tao","Bin Cui"],"pdf_url":"https://arxiv.org/pdf/2303.02868v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02110v2","updated":"2023-03-06T03:26:43Z","published":"2023-03-03T17:51:08Z","title":"Need for Objective Task-based Evaluation of Deep Learning-Based\n  Denoising Methods: A Study in the Context of Myocardial Perfusion SPECT","summary":"  Artificial intelligence-based methods have generated substantial interest in\nnuclear medicine. An area of significant interest has been using deep-learning\n(DL)-based approaches for denoising images acquired with lower doses, shorter\nacquisition times, or both. Objective evaluation of these approaches is\nessential for clinical application. DL-based approaches for denoising\nnuclear-medicine images have typically been evaluated using fidelity-based\nfigures of merit (FoMs) such as RMSE and SSIM. However, these images are\nacquired for clinical tasks and thus should be evaluated based on their\nperformance in these tasks. Our objectives were to (1) investigate whether\nevaluation with these FoMs is consistent with objective clinical-task-based\nevaluation; (2) provide a theoretical analysis for determining the impact of\ndenoising on signal-detection tasks; (3) demonstrate the utility of virtual\nclinical trials (VCTs) to evaluate DL-based methods. A VCT to evaluate a\nDL-based method for denoising myocardial perfusion SPECT (MPS) images was\nconducted. The impact of DL-based denoising was evaluated using fidelity-based\nFoMs and AUC, which quantified performance on detecting perfusion defects in\nMPS images as obtained using a model observer with anthropomorphic channels.\nBased on fidelity-based FoMs, denoising using the considered DL-based method\nled to significantly superior performance. However, based on ROC analysis,\ndenoising did not improve, and in fact, often degraded detection-task\nperformance. The results motivate the need for objective task-based evaluation\nof DL-based denoising approaches. Further, this study shows how VCTs provide a\nmechanism to conduct such evaluations using VCTs. Finally, our theoretical\ntreatment reveals insights into the reasons for the limited performance of the\ndenoising approach.\n","authors":["Zitong Yu","Md Ashequr Rahman","Richard Laforest","Thomas H. Schindler","Robert J. Gropler","Richard L. Wahl","Barry A. Siegel","Abhinav K. Jha"],"pdf_url":"https://arxiv.org/pdf/2303.02110v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02860v1","updated":"2023-03-06T03:25:43Z","published":"2023-03-06T03:25:43Z","title":"A Multi-Grained Self-Interpretable Symbolic-Neural Model For\n  Single/Multi-Labeled Text Classification","summary":"  Deep neural networks based on layer-stacking architectures have historically\nsuffered from poor inherent interpretability. Meanwhile, symbolic probabilistic\nmodels function with clear interpretability, but how to combine them with\nneural networks to enhance their performance remains to be explored. In this\npaper, we try to marry these two systems for text classification via a\nstructured language model. We propose a Symbolic-Neural model that can learn to\nexplicitly predict class labels of text spans from a constituency tree without\nrequiring any access to span-level gold labels. As the structured language\nmodel learns to predict constituency trees in a self-supervised manner, only\nraw texts and sentence-level labels are required as training data, which makes\nit essentially a general constituent-level self-interpretable classification\nmodel. Our experiments demonstrate that our approach could achieve good\nprediction accuracy in downstream tasks. Meanwhile, the predicted span labels\nare consistent with human rationales to a certain degree.\n","authors":["Xiang Hu","Xinyu Kong","Kewei Tu"],"pdf_url":"https://arxiv.org/pdf/2303.02860v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.02859v1","updated":"2023-03-06T03:25:30Z","published":"2023-03-06T03:25:30Z","title":"Bayesian inference with finitely wide neural networks","summary":"  The analytic inference, e.g. predictive distribution being in closed form,\nmay be an appealing benefit for machine learning practitioners when they treat\nwide neural networks as Gaussian process in Bayesian setting. The realistic\nwidths, however, are finite and cause weak deviation from the Gaussianity under\nwhich partial marginalization of random variables in a model is\nstraightforward. On the basis of multivariate Edgeworth expansion, we propose a\nnon-Gaussian distribution in differential form to model a finite set of outputs\nfrom a random neural network, and derive the corresponding marginal and\nconditional properties. Thus, we are able to derive the non-Gaussian posterior\ndistribution in Bayesian regression task. In addition, in the bottlenecked deep\nneural networks, a weight space representation of deep Gaussian process, the\nnon-Gaussianity is investigated through the marginal kernel.\n","authors":["Chi-Ken Lu"],"pdf_url":"https://arxiv.org/pdf/2303.02859v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2302.13221v2","updated":"2023-03-06T02:56:19Z","published":"2023-02-26T03:18:45Z","title":"Data-Centric AI: Deep Generative Differentiable Feature Selection via\n  Discrete Subsetting as Continuous Embedding Space Optimization","summary":"  Feature Selection (FS), such as filter, wrapper, and embedded methods, aims\nto find the optimal feature subset for a given downstream task. However, in\nmany real-world practices, 1) the criteria of FS vary across domains; 2) FS is\nbrittle when data is a high-dimensional and small sample size. Can selected\nfeature subsets be more generalized, accurate, and input dimensionality\nagnostic? We generalize this problem into a deep differentiable feature\nselection task and propose a new perspective: discrete feature subsetting as\ncontinuous embedding space optimization. We develop a generic and principled\nframework including a deep feature subset encoder, accuracy evaluator, decoder,\nand gradient ascent optimizer. This framework implements four steps: 1)\nfeatures-accuracy training data preparation; 2) deep feature subset embedding;\n3) gradient-optimized search; 4) feature subset reconstruction. We develop new\ntechnical insights: reinforcement as a training data generator, ensembles of\ndiverse peer and exploratory feature selector knowledge for generalization, an\neffective embedding from feature subsets to continuous space along with joint\noptimizing reconstruction and accuracy losses to select accurate features.\nExperimental results demonstrate the effectiveness of the proposed method.\n","authors":["Meng Xiao","Dongjie Wang","Min Wu","Pengfei Wang","Yuanchun Zhou","Yanjie Fu"],"pdf_url":"https://arxiv.org/pdf/2302.13221v2.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2203.01850v3","updated":"2023-03-06T02:49:45Z","published":"2022-03-03T16:58:54Z","title":"T-Cal: An optimal test for the calibration of predictive models","summary":"  The prediction accuracy of machine learning methods is steadily increasing,\nbut the calibration of their uncertainty predictions poses a significant\nchallenge. Numerous works focus on obtaining well-calibrated predictive models,\nbut less is known about reliably assessing model calibration. This limits our\nability to know when algorithms for improving calibration have a real effect,\nand when their improvements are merely artifacts due to random noise in finite\ndatasets. In this work, we consider detecting mis-calibration of predictive\nmodels using a finite validation dataset as a hypothesis testing problem. The\nnull hypothesis is that the predictive model is calibrated, while the\nalternative hypothesis is that the deviation from calibration is sufficiently\nlarge.\n  We find that detecting mis-calibration is only possible when the conditional\nprobabilities of the classes are sufficiently smooth functions of the\npredictions. When the conditional class probabilities are H\\\"older continuous,\nwe propose T-Cal, a minimax optimal test for calibration based on a debiased\nplug-in estimator of the $\\ell_2$-Expected Calibration Error (ECE). We further\npropose Adaptive T-Cal, a version that is adaptive to unknown smoothness. We\nverify our theoretical findings with a broad range of experiments, including\nwith several popular deep neural net architectures and several standard\npost-hoc calibration methods. T-Cal is a practical general-purpose tool, which\n-- combined with classical tests for discrete-valued predictors -- can be used\nto test the calibration of virtually any probabilistic classification method.\n","authors":["Donghwan Lee","Xinmeng Huang","Hamed Hassani","Edgar Dobriban"],"pdf_url":"https://arxiv.org/pdf/2203.01850v3.pdf","comment":"The implementation of T-Cal is available at\n  https://github.com/dh7401/T-Cal"},{"id":"http://arxiv.org/abs/2303.02844v1","updated":"2023-03-06T02:47:31Z","published":"2023-03-06T02:47:31Z","title":"Knowledge-embedded meta-learning model for lift coefficient prediction\n  of airfoils","summary":"  Aerodynamic performance evaluation is an important part of the aircraft\naerodynamic design optimization process; however, traditional methods are\ncostly and time-consuming. Despite the fact that various machine learning\nmethods can achieve high accuracy, their application in engineering is still\ndifficult due to their poor generalization performance and \"black box\" nature.\nIn this paper, a knowledge-embedded meta learning model, which fully integrates\ndata with the theoretical knowledge of the lift curve, is developed to obtain\nthe lift coefficients of an arbitrary supercritical airfoil under various angle\nof attacks. In the proposed model, a primary network is responsible for\nrepresenting the relationship between the lift and angle of attack, while the\ngeometry information is encoded into a hyper network to predict the unknown\nparameters involved in the primary network. Specifically, three models with\ndifferent architectures are trained to provide various interpretations.\nCompared to the ordinary neural network, our proposed model can exhibit better\ngeneralization capability with competitive prediction accuracy. Afterward,\ninterpretable analysis is performed based on the Integrated Gradients and\nSaliency methods. Results show that the proposed model can tend to assess the\ninfluence of airfoil geometry to the physical characteristics. Furthermore, the\nexceptions and shortcomings caused by the proposed model are analysed and\ndiscussed in detail.\n","authors":["Hairun Xie","Jing Wang","Miao Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.02844v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.08345v2","updated":"2023-03-06T02:46:59Z","published":"2022-10-15T17:36:04Z","title":"Augmentation-Free Graph Contrastive Learning of Invariant-Discriminative\n  Representations","summary":"  The pretasks are mainly built on mutual information estimation, which\nrequires data augmentation to construct positive samples with similar semantics\nto learn invariant signals and negative samples with dissimilar semantics in\norder to empower representation discriminability. However, an appropriate data\naugmentation configuration depends heavily on lots of empirical trials such as\nchoosing the compositions of data augmentation techniques and the corresponding\nhyperparameter settings. We propose an augmentation-free graph contrastive\nlearning method, invariant-discriminative graph contrastive learning (iGCL),\nthat does not intrinsically require negative samples. iGCL designs the\ninvariant-discriminative loss (ID loss) to learn invariant and discriminative\nrepresentations. On the one hand, ID loss learns invariant signals by directly\nminimizing the mean square error between the target samples and positive\nsamples in the representation space. On the other hand, ID loss ensures that\nthe representations are discriminative by an orthonormal constraint forcing the\ndifferent dimensions of representations to be independent of each other. This\nprevents representations from collapsing to a point or subspace. Our\ntheoretical analysis explains the effectiveness of ID loss from the\nperspectives of the redundancy reduction criterion, canonical correlation\nanalysis, and information bottleneck principle. The experimental results\ndemonstrate that iGCL outperforms all baselines on 5 node classification\nbenchmark datasets. iGCL also shows superior performance for different label\nratios and is capable of resisting graph attacks, which indicates that iGCL has\nexcellent generalization and robustness. The source code is available at\nhttps://github.com/lehaifeng/T-GCN/tree/master/iGCL.\n","authors":["Haifeng Li","Jun Cao","Jiawei Zhu","Qinyao Luo","Silu He","Xuyin Wang"],"pdf_url":"https://arxiv.org/pdf/2210.08345v2.pdf","comment":"11 pages 8 figs"},{"id":"http://arxiv.org/abs/2211.05631v2","updated":"2023-03-06T02:31:54Z","published":"2022-11-02T15:39:19Z","title":"Backdoor Defense via Suppressing Model Shortcuts","summary":"  Recent studies have demonstrated that deep neural networks (DNNs) are\nvulnerable to backdoor attacks during the training process. Specifically, the\nadversaries intend to embed hidden backdoors in DNNs so that malicious model\npredictions can be activated through pre-defined trigger patterns. In this\npaper, we explore the backdoor mechanism from the angle of the model structure.\nWe select the skip connection for discussions, inspired by the understanding\nthat it helps the learning of model `shortcuts' where backdoor triggers are\nusually easier to be learned. Specifically, we demonstrate that the attack\nsuccess rate (ASR) decreases significantly when reducing the outputs of some\nkey skip connections. Based on this observation, we design a simple yet\neffective backdoor removal method by suppressing the skip connections in\ncritical layers selected by our method. We also implement fine-tuning on these\nlayers to recover high benign accuracy and to further reduce ASR. Extensive\nexperiments on benchmark datasets verify the effectiveness of our method.\n","authors":["Sheng Yang","Yiming Li","Yong Jiang","Shu-Tao Xia"],"pdf_url":"https://arxiv.org/pdf/2211.05631v2.pdf","comment":"This paper is accepted by ICASSP 2023. 5 pages"},{"id":"http://arxiv.org/abs/2211.01806v2","updated":"2023-03-06T02:26:40Z","published":"2022-11-02T16:03:43Z","title":"BATT: Backdoor Attack with Transformation-based Triggers","summary":"  Deep neural networks (DNNs) are vulnerable to backdoor attacks. The backdoor\nadversaries intend to maliciously control the predictions of attacked DNNs by\ninjecting hidden backdoors that can be activated by adversary-specified trigger\npatterns during the training process. One recent research revealed that most of\nthe existing attacks failed in the real physical world since the trigger\ncontained in the digitized test samples may be different from that of the one\nused for training. Accordingly, users can adopt spatial transformations as the\nimage pre-processing to deactivate hidden backdoors. In this paper, we explore\nthe previous findings from another side. We exploit classical spatial\ntransformations (i.e. rotation and translation) with the specific parameter as\ntrigger patterns to design a simple yet effective poisoning-based backdoor\nattack. For example, only images rotated to a particular angle can activate the\nembedded backdoor of attacked DNNs. Extensive experiments are conducted,\nverifying the effectiveness of our attack under both digital and physical\nsettings and its resistance to existing backdoor defenses.\n","authors":["Tong Xu","Yiming Li","Yong Jiang","Shu-Tao Xia"],"pdf_url":"https://arxiv.org/pdf/2211.01806v2.pdf","comment":"This paper is accepted by ICASSP 2023. 5 pages"},{"id":"http://arxiv.org/abs/2303.02841v1","updated":"2023-03-06T02:24:48Z","published":"2023-03-06T02:24:48Z","title":"Model-Agnostic Meta-Learning for Natural Language Understanding Tasks in\n  Finance","summary":"  Natural language understanding(NLU) is challenging for finance due to the\nlack of annotated data and the specialized language in that domain. As a\nresult, researchers have proposed to use pre-trained language model and\nmulti-task learning to learn robust representations. However, aggressive\nfine-tuning often causes over-fitting and multi-task learning may favor tasks\nwith significantly larger amounts data, etc. To address these problems, in this\npaper, we investigate model-agnostic meta-learning algorithm(MAML) in\nlow-resource financial NLU tasks. Our contribution includes: 1. we explore the\nperformance of MAML method with multiple types of tasks: GLUE datasets, SNLI,\nSci-Tail and Financial PhraseBank; 2. we study the performance of MAML method\nwith multiple single-type tasks: a real scenario stock price prediction problem\nwith twitter text data. Our models achieve the state-of-the-art performance\naccording to the experimental results, which demonstrate that our method can\nadapt fast and well to low-resource situations.\n","authors":["Bixing Yan","Shaoling Chen","Yuxuan He","Zhihan Li"],"pdf_url":"https://arxiv.org/pdf/2303.02841v1.pdf","comment":"13 pages, 6 figures, 8 tables"},{"id":"http://arxiv.org/abs/2211.05638v2","updated":"2023-03-06T02:20:32Z","published":"2022-11-02T17:05:45Z","title":"Untargeted Backdoor Attack against Object Detection","summary":"  Recent studies revealed that deep neural networks (DNNs) are exposed to\nbackdoor threats when training with third-party resources (such as training\nsamples or backbones). The backdoored model has promising performance in\npredicting benign samples, whereas its predictions can be maliciously\nmanipulated by adversaries based on activating its backdoors with pre-defined\ntrigger patterns. Currently, most of the existing backdoor attacks were\nconducted on the image classification under the targeted manner. In this paper,\nwe reveal that these threats could also happen in object detection, posing\nthreatening risks to many mission-critical applications ($e.g.$, pedestrian\ndetection and intelligent surveillance systems). Specifically, we design a\nsimple yet effective poison-only backdoor attack in an untargeted manner, based\non task characteristics. We show that, once the backdoor is embedded into the\ntarget model by our attack, it can trick the model to lose detection of any\nobject stamped with our trigger patterns. We conduct extensive experiments on\nthe benchmark dataset, showing its effectiveness in both digital and\nphysical-world settings and its resistance to potential defenses.\n","authors":["Chengxiao Luo","Yiming Li","Yong Jiang","Shu-Tao Xia"],"pdf_url":"https://arxiv.org/pdf/2211.05638v2.pdf","comment":"This paper is accepted by ICASSP 2023. 5 pages"},{"id":"http://arxiv.org/abs/2103.01400v4","updated":"2023-03-06T02:05:31Z","published":"2021-03-02T01:27:16Z","title":"Smoothness Analysis of Adversarial Training","summary":"  Deep neural networks are vulnerable to adversarial attacks. Recent studies\nabout adversarial robustness focus on the loss landscape in the parameter space\nsince it is related to optimization and generalization performance. These\nstudies conclude that the difficulty of adversarial training is caused by the\nnon-smoothness of the loss function: i.e., its gradient is not Lipschitz\ncontinuous. However, this analysis ignores the dependence of adversarial\nattacks on model parameters. Since adversarial attacks are optimized for\nmodels, they should depend on the parameters. Considering this dependence, we\nanalyze the smoothness of the loss function of adversarial training using the\noptimal attacks for the model parameter in more detail. We reveal that the\nconstraint of adversarial attacks is one cause of the non-smoothness and that\nthe smoothness depends on the types of the constraints. Specifically, the\n$L_\\infty$ constraint can cause non-smoothness more than the $L_2$ constraint.\nMoreover, our analysis implies that if we flatten the loss function with\nrespect to input data, the Lipschitz constant of the gradient of adversarial\nloss tends to increase. To address the non-smoothness, we show that EntropySGD\nsmoothens the non-smooth loss and improves the performance of adversarial\ntraining.\n","authors":["Sekitoshi Kanai","Masanori Yamada","Hiroshi Takahashi","Yuki Yamanaka","Yasutoshi Ida"],"pdf_url":"https://arxiv.org/pdf/2103.01400v4.pdf","comment":"The latest version of this article is published in IEEE Transactions\n  on Neural Networks and Learning Systems (DOI: 10.1109/TNNLS.2023.3244172). 22\n  pages, 7 figures"},{"id":"http://arxiv.org/abs/2303.02833v1","updated":"2023-03-06T01:59:45Z","published":"2023-03-06T01:59:45Z","title":"eCDANs: Efficient Temporal Causal Discovery from Autocorrelated and\n  Non-stationary Data (Student Abstract)","summary":"  Conventional temporal causal discovery (CD) methods suffer from high\ndimensionality, fail to identify lagged causal relationships, and often ignore\ndynamics in relations. In this study, we present a novel constraint-based CD\napproach for autocorrelated and non-stationary time series data (eCDANs)\ncapable of detecting lagged and contemporaneous causal relationships along with\ntemporal changes. eCDANs addresses high dimensionality by optimizing the\nconditioning sets while conducting conditional independence (CI) tests and\nidentifies the changes in causal relations by introducing a surrogate variable\nto represent time dependency. Experiments on synthetic and real-world data show\nthat eCDANs can identify time influence and outperform the baselines.\n","authors":["Muhammad Hasan Ferdous","Uzma Hasan","Md Osman Gani"],"pdf_url":"https://arxiv.org/pdf/2303.02833v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12987v2","updated":"2023-03-06T01:54:22Z","published":"2023-01-30T15:29:40Z","title":"The Optimal Choice of Hypothesis Is the Weakest, Not the Shortest","summary":"  If $A$ and $B$ are sets such that $A \\subset B$, generalisation may be\nunderstood as the inference from $A$ of a hypothesis sufficient to construct\n$B$. One might infer any number of hypotheses from $A$, yet only some of those\nmay generalise to $B$. How can one know which are likely to generalise? One\nstrategy is to choose the shortest, equating the ability to compress\ninformation with the ability to generalise (a proxy for intelligence). We\nexamine this in the context of a mathematical formalism of enactive cognition.\nWe show that compression is neither necessary nor sufficient to maximise\nperformance (measured in terms of the probability of a hypothesis\ngeneralising). We formulate a proxy unrelated to length or simplicity, called\nweakness. We show that if tasks are uniformly distributed, then there is no\nchoice of proxy that performs at least as well as weakness maximisation in all\ntasks while performing strictly better in at least one. In other words,\nweakness is the pareto optimal choice of proxy. In experiments comparing\nmaximum weakness and minimum description length in the context of binary\narithmetic, the former generalised at between $1.1$ and $5$ times the rate of\nthe latter. We argue this demonstrates that weakness is a far better proxy, and\nexplains why Deepmind's Apperception Engine is able to generalise effectively.\n","authors":["Michael Timothy Bennett"],"pdf_url":"https://arxiv.org/pdf/2301.12987v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02829v1","updated":"2023-03-06T01:46:51Z","published":"2023-03-06T01:46:51Z","title":"Attribution-Scores and Causal Counterfactuals as Explanations in\n  Artificial Intelligence","summary":"  In this expository article we highlight the relevance of explanations for\nartificial intelligence, in general, and for the newer developments in {\\em\nexplainable AI}, referring to origins and connections of and among different\napproaches. We describe in simple terms, explanations in data management and\nmachine learning that are based on attribution-scores, and counterfactuals as\nfound in the area of causality. We elaborate on the importance of logical\nreasoning when dealing with counterfactuals, and their use for score\ncomputation.\n","authors":["Leopoldo Bertossi"],"pdf_url":"https://arxiv.org/pdf/2303.02829v1.pdf","comment":"Submitted as chapter contribution"},{"id":"http://arxiv.org/abs/2303.02828v1","updated":"2023-03-06T01:45:32Z","published":"2023-03-06T01:45:32Z","title":"Robust Autoencoders for Collective Corruption Removal","summary":"  Robust PCA is a standard tool for learning a linear subspace in the presence\nof sparse corruption or rare outliers. What about robustly learning manifolds\nthat are more realistic models for natural data, such as images? There have\nbeen several recent attempts to generalize robust PCA to manifold settings. In\nthis paper, we propose $\\ell_1$- and scaling-invariant $\\ell_1/\\ell_2$-robust\nautoencoders based on a surprisingly compact formulation built on the intuition\nthat deep autoencoders perform manifold learning. We demonstrate on several\nstandard image datasets that the proposed formulation significantly outperforms\nall previous methods in collectively removing sparse corruption, without clean\nimages for training. Moreover, we also show that the learned manifold\nstructures can be generalized to unseen data samples effectively.\n","authors":["Taihui Li","Hengkang Wang","Peng Le","XianE Tang","Ju Sun"],"pdf_url":"https://arxiv.org/pdf/2303.02828v1.pdf","comment":"This paper has been accepted to ICASSP2023"},{"id":"http://arxiv.org/abs/2211.07740v3","updated":"2023-03-06T01:35:21Z","published":"2022-11-14T20:35:11Z","title":"Denoising diffusion models for out-of-distribution detection","summary":"  Out-of-distribution detection is crucial to the safe deployment of machine\nlearning systems. Currently, unsupervised out-of-distribution detection is\ndominated by generative-based approaches that make use of estimates of the\nlikelihood or other measurements from a generative model. Reconstruction-based\nmethods offer an alternative approach, in which a measure of reconstruction\nerror is used to determine if a sample is out-of-distribution. However,\nreconstruction-based approaches are less favoured, as they require careful\ntuning of the model's information bottleneck - such as the size of the latent\ndimension - to produce good results. In this work, we exploit the view of\ndenoising diffusion probabilistic models (DDPM) as denoising autoencoders where\nthe bottleneck is controlled externally, by means of the amount of noise\napplied. We propose to use DDPMs to reconstruct an input that has been noised\nto a range of noise levels, and use the resulting multi-dimensional\nreconstruction error to classify out-of-distribution inputs. We validate our\napproach both on standard computer-vision datasets and on higher dimension\nmedical datasets. Our approach outperforms not only reconstruction-based\nmethods, but also state-of-the-art generative-based approaches.\n","authors":["Mark S. Graham","Walter H. L. Pinaya","Petru-Daniel Tudosiu","Parashkev Nachev","Sebastien Ourselin","M. Jorge Cardoso"],"pdf_url":"https://arxiv.org/pdf/2211.07740v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10866v2","updated":"2023-03-06T01:26:15Z","published":"2023-02-21T18:29:25Z","title":"Hyena Hierarchy: Towards Larger Convolutional Language Models","summary":"  Recent advances in deep learning have relied heavily on the use of large\nTransformers due to their ability to learn at scale. However, the core building\nblock of Transformers, the attention operator, exhibits quadratic cost in\nsequence length, limiting the amount of context accessible. Existing\nsubquadratic methods based on low-rank and sparse approximations need to be\ncombined with dense attention layers to match Transformers, indicating a gap in\ncapability. In this work, we propose Hyena, a subquadratic drop-in replacement\nfor attention constructed by interleaving implicitly parametrized long\nconvolutions and data-controlled gating. In recall and reasoning tasks on\nsequences of thousands to hundreds of thousands of tokens, Hyena improves\naccuracy by more than 50 points over operators relying on state-spaces and\nother implicit and explicit methods, matching attention-based models. We set a\nnew state-of-the-art for dense-attention-free architectures on language\nmodeling in standard datasets (WikiText103 and The Pile), reaching Transformer\nquality with a 20% reduction in training compute required at sequence length\n2K. Hyena operators are twice as fast as highly optimized attention at sequence\nlength 8K, and 100x faster at sequence length 64K.\n","authors":["Michael Poli","Stefano Massaroli","Eric Nguyen","Daniel Y. Fu","Tri Dao","Stephen Baccus","Yoshua Bengio","Stefano Ermon","Christopher Ré"],"pdf_url":"https://arxiv.org/pdf/2302.10866v2.pdf","comment":"Additional results (PG-19, LAMBADA)"},{"id":"http://arxiv.org/abs/2210.05367v2","updated":"2023-03-06T01:23:14Z","published":"2022-10-10T16:49:49Z","title":"Learning Explicit Credit Assignment for Cooperative Multi-Agent\n  Reinforcement Learning via Polarization Policy Gradient","summary":"  Cooperative multi-agent policy gradient (MAPG) algorithms have recently\nattracted wide attention and are regarded as a general scheme for the\nmulti-agent system. Credit assignment plays an important role in MAPG and can\ninduce cooperation among multiple agents. However, most MAPG algorithms cannot\nachieve good credit assignment because of the game-theoretic pathology known as\n\\textit{centralized-decentralized mismatch}. To address this issue, this paper\npresents a novel method, \\textit{\\underline{M}ulti-\\underline{A}gent\n\\underline{P}olarization \\underline{P}olicy \\underline{G}radient} (MAPPG).\nMAPPG takes a simple but efficient polarization function to transform the\noptimal consistency of joint and individual actions into easily realized\nconstraints, thus enabling efficient credit assignment in MAPG. Theoretically,\nwe prove that individual policies of MAPPG can converge to the global optimum.\nEmpirically, we evaluate MAPPG on the well-known matrix game and differential\ngame, and verify that MAPPG can converge to the global optimum for both\ndiscrete and continuous action spaces. We also evaluate MAPPG on a set of\nStarCraft II micromanagement tasks and demonstrate that MAPPG outperforms the\nstate-of-the-art MAPG algorithms.\n","authors":["Wubing Chen","Wenbin Li","Xiao Liu","Shangdong Yang","Yang Gao"],"pdf_url":"https://arxiv.org/pdf/2210.05367v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02814v1","updated":"2023-03-06T01:01:56Z","published":"2023-03-06T01:01:56Z","title":"Visual Analytics of Neuron Vulnerability to Adversarial Attacks on\n  Convolutional Neural Networks","summary":"  Adversarial attacks on a convolutional neural network (CNN) -- injecting\nhuman-imperceptible perturbations into an input image -- could fool a\nhigh-performance CNN into making incorrect predictions. The success of\nadversarial attacks raises serious concerns about the robustness of CNNs, and\nprevents them from being used in safety-critical applications, such as medical\ndiagnosis and autonomous driving. Our work introduces a visual analytics\napproach to understanding adversarial attacks by answering two questions: (1)\nwhich neurons are more vulnerable to attacks and (2) which image features do\nthese vulnerable neurons capture during the prediction? For the first question,\nwe introduce multiple perturbation-based measures to break down the attacking\nmagnitude into individual CNN neurons and rank the neurons by their\nvulnerability levels. For the second, we identify image features (e.g., cat\nears) that highly stimulate a user-selected neuron to augment and validate the\nneuron's responsibility. Furthermore, we support an interactive exploration of\na large number of neurons by aiding with hierarchical clustering based on the\nneurons' roles in the prediction. To this end, a visual analytics system is\ndesigned to incorporate visual reasoning for interpreting adversarial attacks.\nWe validate the effectiveness of our system through multiple case studies as\nwell as feedback from domain experts.\n","authors":["Yiran Li","Junpeng Wang","Takanori Fujiwara","Kwan-Liu Ma"],"pdf_url":"https://arxiv.org/pdf/2303.02814v1.pdf","comment":"Accepted by the Special Issue on Human-Centered Explainable AI, ACM\n  Transactions on Interactive Intelligent Systems"},{"id":"http://arxiv.org/abs/2206.01874v2","updated":"2023-03-06T01:00:13Z","published":"2022-06-04T01:59:31Z","title":"An Unpooling Layer for Graph Generation","summary":"  We propose a novel and trainable graph unpooling layer for effective graph\ngeneration. Given a graph with features, the unpooling layer enlarges this\ngraph and learns its desired new structure and features. Since this unpooling\nlayer is trainable, it can be applied to graph generation either in the decoder\nof a variational autoencoder or in the generator of a generative adversarial\nnetwork (GAN). We prove that the unpooled graph remains connected and any\nconnected graph can be sequentially unpooled from a 3-nodes graph. We apply the\nunpooling layer within the GAN generator. Since the most studied instance of\ngraph generation is molecular generation, we test our ideas in this context.\nUsing the QM9 and ZINC datasets, we demonstrate the improvement obtained by\nusing the unpooling layer instead of an adjacency-matrix-based approach.\n","authors":["Yinglong Guo","Dongmian Zou","Gilad Lerman"],"pdf_url":"https://arxiv.org/pdf/2206.01874v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.10475v2","updated":"2023-03-06T00:49:01Z","published":"2022-05-21T00:58:22Z","title":"DeepStruct: Pretraining of Language Models for Structure Prediction","summary":"  We introduce a method for improving the structural understanding abilities of\nlanguage models. Unlike previous approaches that finetune the models with\ntask-specific augmentation, we pretrain language models on a collection of\ntask-agnostic corpora to generate structures from text. Our structure\npretraining enables zero-shot transfer of the learned knowledge that models\nhave about the structure tasks. We study the performance of this approach on 28\ndatasets, spanning 10 structure prediction tasks including open information\nextraction, joint entity and relation extraction, named entity recognition,\nrelation classification, semantic role labeling, event extraction, coreference\nresolution, factual probe, intent detection, and dialogue state tracking. We\nfurther enhance the pretraining with the task-specific training sets. We show\nthat a 10B parameter language model transfers non-trivially to most tasks and\nobtains state-of-the-art performance on 21 of 28 datasets that we evaluate.\n","authors":["Chenguang Wang","Xiao Liu","Zui Chen","Haoyun Hong","Jie Tang","Dawn Song"],"pdf_url":"https://arxiv.org/pdf/2205.10475v2.pdf","comment":"ACL 2022"},{"id":"http://arxiv.org/abs/2102.04615v2","updated":"2023-03-06T00:29:14Z","published":"2021-02-09T02:50:29Z","title":"Benford's law: what does it say on adversarial images?","summary":"  Convolutional neural networks (CNNs) are fragile to small perturbations in\nthe input images. These networks are thus prone to malicious attacks that\nperturb the inputs to force a misclassification. Such slightly manipulated\nimages aimed at deceiving the classifier are known as adversarial images. In\nthis work, we investigate statistical differences between natural images and\nadversarial ones. More precisely, we show that employing a proper image\ntransformation and for a class of adversarial attacks, the distribution of the\nleading digit of the pixels in adversarial images deviates from Benford's law.\nThe stronger the attack, the more distant the resulting distribution is from\nBenford's law. Our analysis provides a detailed investigation of this new\napproach that can serve as a basis for alternative adversarial example\ndetection methods that do not need to modify the original CNN classifier\nneither work on the raw high-dimensional pixels as features to defend against\nattacks.\n","authors":["João G. Zago","Fabio L. Baldissera","Eric A. Antonelo","Rodrigo T. Saad"],"pdf_url":"https://arxiv.org/pdf/2102.04615v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.01275v2","updated":"2023-03-06T00:26:43Z","published":"2023-02-02T18:05:27Z","title":"ReLOAD: Reinforcement Learning with Optimistic Ascent-Descent for\n  Last-Iterate Convergence in Constrained MDPs","summary":"  In recent years, Reinforcement Learning (RL) has been applied to real-world\nproblems with increasing success. Such applications often require to put\nconstraints on the agent's behavior. Existing algorithms for constrained RL\n(CRL) rely on gradient descent-ascent, but this approach comes with a caveat.\nWhile these algorithms are guaranteed to converge on average, they do not\nguarantee last-iterate convergence, i.e., the current policy of the agent may\nnever converge to the optimal solution. In practice, it is often observed that\nthe policy alternates between satisfying the constraints and maximizing the\nreward, rarely accomplishing both objectives simultaneously. Here, we address\nthis problem by introducing Reinforcement Learning with Optimistic\nAscent-Descent (ReLOAD), a principled CRL method with guaranteed last-iterate\nconvergence. We demonstrate its empirical effectiveness on a wide variety of\nCRL problems including discrete MDPs and continuous control. In the process we\nestablish a benchmark of challenging CRL problems.\n","authors":["Ted Moskovitz","Brendan O'Donoghue","Vivek Veeriah","Sebastian Flennerhag","Satinder Singh","Tom Zahavy"],"pdf_url":"https://arxiv.org/pdf/2302.01275v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12495v2","updated":"2023-03-06T23:49:42Z","published":"2023-01-29T17:18:59Z","title":"Time-Series Pattern Recognition in Smart Manufacturing Systems: A\n  Literature Review and Ontology","summary":"  Since the inception of Industry 4.0 in 2012, emerging technologies have\nenabled the acquisition of vast amounts of data from diverse sources such as\nmachine tools, robust and affordable sensor systems with advanced information\nmodels, and other sources within Smart Manufacturing Systems (SMS). As a\nresult, the amount of data that is available in manufacturing settings has\nexploded, allowing data-hungry tools such as Artificial Intelligence (AI) and\nMachine Learning (ML) to be leveraged. Time-series analytics has been\nsuccessfully applied in a variety of industries, and that success is now being\nmigrated to pattern recognition applications in manufacturing to support higher\nquality products, zero defect manufacturing, and improved customer\nsatisfaction. However, the diverse landscape of manufacturing presents a\nchallenge for successfully solving problems in industry using time-series\npattern recognition. The resulting research gap of understanding and applying\nthe subject matter of time-series pattern recognition in manufacturing is a\nmajor limiting factor for adoption in industry. The purpose of this paper is to\nprovide a structured perspective of the current state of time-series pattern\nrecognition in manufacturing with a problem-solving focus. By using an ontology\nto classify and define concepts, how they are structured, their properties, the\nrelationships between them, and considerations when applying them, this paper\naims to provide practical and actionable guidelines for application and\nrecommendations for advancing time-series analytics.\n","authors":["Mojtaba A. Farahani","M. R. McCormick","Robert Gianinny","Frank Hudacheck","Ramy Harik","Zhichao Liu","Thorsten Wuest"],"pdf_url":"https://arxiv.org/pdf/2301.12495v2.pdf","comment":"40 pages, 35 figures, 21 tables, submitted to Elsevier"},{"id":"http://arxiv.org/abs/2303.03553v1","updated":"2023-03-06T23:37:58Z","published":"2023-03-06T23:37:58Z","title":"Robust Dominant Periodicity Detection for Time Series with Missing Data","summary":"  Periodicity detection is an important task in time series analysis, but still\na challenging problem due to the diverse characteristics of time series data\nlike abrupt trend change, outlier, noise, and especially block missing data. In\nthis paper, we propose a robust and effective periodicity detection algorithm\nfor time series with block missing data. We first design a robust trend filter\nto remove the interference of complicated trend patterns under missing data.\nThen, we propose a robust autocorrelation function (ACF) that can handle\nmissing values and outliers effectively. We rigorously prove that the proposed\nrobust ACF can still work well when the length of the missing block is less\nthan $1/3$ of the period length. Last, by combining the time-frequency\ninformation, our algorithm can generate the period length accurately. The\nexperimental results demonstrate that our algorithm outperforms existing\nperiodicity detection algorithms on real-world time series datasets.\n","authors":["Qingsong Wen","Linxiao Yang","Liang Sun"],"pdf_url":"https://arxiv.org/pdf/2303.03553v1.pdf","comment":"Accepted by 2023 IEEE International Conference on Acoustics, Speech\n  and Signal Processing (ICASSP 2023)"},{"id":"http://arxiv.org/abs/2107.14317v2","updated":"2023-03-06T23:34:18Z","published":"2021-07-29T20:31:03Z","title":"Temporal Dependencies in Feature Importance for Time Series Predictions","summary":"  Time series data introduces two key challenges for explainability methods:\nfirstly, observations of the same feature over subsequent time steps are not\nindependent, and secondly, the same feature can have varying importance to\nmodel predictions over time. In this paper, we propose Windowed Feature\nImportance in Time (WinIT), a feature removal based explainability approach to\naddress these issues. Unlike existing feature removal explanation methods,\nWinIT explicitly accounts for the temporal dependence between different\nobservations of the same feature in the construction of its importance score.\nFurthermore, WinIT captures the varying importance of a feature over time, by\nsummarizing its importance over a window of past time steps. We conduct an\nextensive empirical study on synthetic and real-world data, compare against a\nwide range of leading explainability methods, and explore the impact of various\nevaluation strategies. Our results show that WinIT achieves significant gains\nover existing methods, with more consistent performance across different\nevaluation metrics. The code for our work is publicly available at\n\\url{https://github.com/layer6ai-labs/WinIT}.\n","authors":["Kin Kwan Leung","Clayton Rooke","Jonathan Smith","Saba Zuberi","Maksims Volkovs"],"pdf_url":"https://arxiv.org/pdf/2107.14317v2.pdf","comment":"International Conference on Learning Representations 2023 (ICLR'23)"},{"id":"http://arxiv.org/abs/2112.12542v5","updated":"2023-03-06T23:26:47Z","published":"2021-12-22T05:41:50Z","title":"How Much Space Has Been Explored? Measuring the Chemical Space Covered\n  by Databases and Machine-Generated Molecules","summary":"  Forming a molecular candidate set that contains a wide range of potentially\neffective compounds is crucial to the success of drug discovery. While most\ndatabases and machine-learning-based generation models aim to optimize\nparticular chemical properties, there is limited literature on how to properly\nmeasure the coverage of the chemical space by those candidates included or\ngenerated. This problem is challenging due to the lack of formal criteria to\nselect good measures of the chemical space. In this paper, we propose a novel\nevaluation framework for measures of the chemical space based on two analyses:\nan axiomatic analysis with three intuitive axioms that a good measure should\nobey, and an empirical analysis on the correlation between a measure and a\nproxy gold standard. Using this framework, we are able to identify #Circles, a\nnew measure of chemical space coverage, which is superior to existing measures\nboth analytically and empirically. We further evaluate how well the existing\ndatabases and generation models cover the chemical space in terms of #Circles.\nThe results suggest that many generation models fail to explore a larger space\nover existing databases, which leads to new opportunities for improving\ngeneration models by encouraging exploration.\n","authors":["Yutong Xie","Ziqiao Xu","Jiaqi Ma","Qiaozhu Mei"],"pdf_url":"https://arxiv.org/pdf/2112.12542v5.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2209.14860v2","updated":"2023-03-06T23:19:17Z","published":"2022-09-29T15:24:47Z","title":"Bridging the Gap to Real-World Object-Centric Learning","summary":"  Humans naturally decompose their environment into entities at the appropriate\nlevel of abstraction to act in the world. Allowing machine learning algorithms\nto derive this decomposition in an unsupervised way has become an important\nline of research. However, current methods are restricted to simulated data or\nrequire additional information in the form of motion or depth in order to\nsuccessfully discover objects. In this work, we overcome this limitation by\nshowing that reconstructing features from models trained in a self-supervised\nmanner is a sufficient training signal for object-centric representations to\narise in a fully unsupervised way. Our approach, DINOSAUR, significantly\nout-performs existing image-based object-centric learning models on simulated\ndata and is the first unsupervised object-centric model that scales to\nreal-world datasets such as COCO and PASCAL VOC. DINOSAUR is conceptually\nsimple and shows competitive performance compared to more involved pipelines\nfrom the computer vision literature.\n","authors":["Maximilian Seitzer","Max Horn","Andrii Zadaianchuk","Dominik Zietlow","Tianjun Xiao","Carl-Johann Simon-Gabriel","Tong He","Zheng Zhang","Bernhard Schölkopf","Thomas Brox","Francesco Locatello"],"pdf_url":"https://arxiv.org/pdf/2209.14860v2.pdf","comment":"ICLR 2023 camera-ready version"},{"id":"http://arxiv.org/abs/2303.03548v1","updated":"2023-03-06T23:16:24Z","published":"2023-03-06T23:16:24Z","title":"Large Language Models as Zero-Shot Human Models for Human-Robot\n  Interaction","summary":"  Human models play a crucial role in human-robot interaction (HRI), enabling\nrobots to consider the impact of their actions on people and plan their\nbehavior accordingly. However, crafting good human models is challenging;\ncapturing context-dependent human behavior requires significant prior knowledge\nand/or large amounts of interaction data, both of which are difficult to\nobtain. In this work, we explore the potential of large-language models (LLMs)\n-- which have consumed vast amounts of human-generated text data -- to act as\nzero-shot human models for HRI. Our experiments on three social datasets yield\npromising results; the LLMs are able to achieve performance comparable to\npurpose-built models. That said, we also discuss current limitations, such as\nsensitivity to prompts and spatial/numerical reasoning mishaps. Based on our\nfindings, we demonstrate how LLM-based human models can be integrated into a\nsocial robot's planning process and applied in HRI scenarios. Specifically, we\npresent one case study on a simulated trust-based table-clearing task and\nreplicate past results that relied on custom models. Next, we conduct a new\nrobot utensil-passing experiment (n = 65) where preliminary results show that\nplanning with a LLM-based human model can achieve gains over a basic myopic\nplan. In summary, our results show that LLMs offer a promising (but incomplete)\napproach to human modeling for HRI.\n","authors":["Bowen Zhang","Harold Soh"],"pdf_url":"https://arxiv.org/pdf/2303.03548v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2212.06132v2","updated":"2023-03-06T23:13:30Z","published":"2022-12-12T18:58:59Z","title":"Nearly Minimax Optimal Reinforcement Learning for Linear Markov Decision\n  Processes","summary":"  We study reinforcement learning (RL) with linear function approximation. For\nepisodic time-inhomogeneous linear Markov decision processes (linear MDPs)\nwhose transition dynamic can be parameterized as a linear function of a given\nfeature mapping, we propose the first computationally efficient algorithm that\nachieves the nearly minimax optimal regret $\\tilde O(d\\sqrt{H^3K})$, where $d$\nis the dimension of the feature mapping, $H$ is the planning horizon, and $K$\nis the number of episodes. Our algorithm is based on a weighted linear\nregression scheme with a carefully designed weight, which depends on a new\nvariance estimator that (1) directly estimates the variance of the\n\\emph{optimal} value function, (2) monotonically decreases with respect to the\nnumber of episodes to ensure a better estimation accuracy, and (3) uses a\nrare-switching policy to update the value function estimator to control the\ncomplexity of the estimated value function class. Our work provides a complete\nanswer to optimal RL with linear MDPs, and the developed algorithm and\ntheoretical tools may be of independent interest.\n","authors":["Jiafan He","Heyang Zhao","Dongruo Zhou","Quanquan Gu"],"pdf_url":"https://arxiv.org/pdf/2212.06132v2.pdf","comment":"44 pages, 1 table"},{"id":"http://arxiv.org/abs/2302.00845v2","updated":"2023-03-06T23:04:27Z","published":"2023-02-02T03:15:29Z","title":"Scale up with Order: Finding Good Data Permutations for Distributed\n  Training","summary":"  Gradient Balancing (GraB) is a recently proposed technique that finds\nprovably better data permutations when training models with multiple epochs\nover a finite dataset. It converges at a faster rate than the widely adopted\nRandom Reshuffling, by minimizing the discrepancy of the gradients on\nadjacently selected examples. However, GraB only operates under critical\nassumptions such as small batch sizes and centralized data, leaving open the\nquestion of how to order examples at large scale -- i.e. distributed learning\nwith decentralized data. To alleviate the limitation, in this paper we propose\nD-GraB, an algorithm that orders the examples in a parallel setting with\nnegligible overhead, which enjoys linear speed up at rate\n$\\tilde{O}((mnT)^{-2/3})$ on smooth non-convex objectives and\n$\\tilde{O}((mnT)^{-2})$ under PL condition, where $n$ denotes the number of\nparallel workers, $m$ denotes the number of examples per worker and $T$ denotes\nthe number of epochs. D-GraB benefits from both data ordering and parallelism.\nEmpirically, we show on various applications including GLUE, CIFAR10 and\nWikiText-2 that D-GraB outperforms naive parallel GraB and Distributed Random\nReshuffling in terms of both training and validation performance.\n","authors":["Wentao Guo","Khiem Pham","Yucheng Lu","Tiancheng Yuan","Charlie F. Ruan","Christopher De Sa"],"pdf_url":"https://arxiv.org/pdf/2302.00845v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03544v1","updated":"2023-03-06T23:01:53Z","published":"2023-03-06T23:01:53Z","title":"Expressivity of Shallow and Deep Neural Networks for Polynomial\n  Approximation","summary":"  We analyze the number of neurons that a ReLU neural network needs to\napproximate multivariate monomials. We establish an exponential lower bound for\nthe complexity of any shallow network that approximates the product function\n$\\vec{x} \\to \\prod_{i=1}^d x_i$ on a general compact domain. Furthermore, we\nprove that this lower bound does not hold for normalized O(1)-Lipschitz\nmonomials (or equivalently, by restricting to the unit cube). These results\nsuggest shallow ReLU networks suffer from the curse of dimensionality when\nexpressing functions with a Lipschitz parameter scaling with the dimension of\nthe input, and that the expressive power of neural networks lies in their depth\nrather than the overall complexity.\n","authors":["Itai Shapira"],"pdf_url":"https://arxiv.org/pdf/2303.03544v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2303.03543v1","updated":"2023-03-06T23:01:43Z","published":"2023-03-06T23:01:43Z","title":"3D Equivariant Diffusion for Target-Aware Molecule Generation and\n  Affinity Prediction","summary":"  Rich data and powerful machine learning models allow us to design drugs for a\nspecific protein target \\textit{in silico}. Recently, the inclusion of 3D\nstructures during targeted drug design shows superior performance to other\ntarget-free models as the atomic interaction in the 3D space is explicitly\nmodeled. However, current 3D target-aware models either rely on the voxelized\natom densities or the autoregressive sampling process, which are not\nequivariant to rotation or easily violate geometric constraints resulting in\nunrealistic structures. In this work, we develop a 3D equivariant diffusion\nmodel to solve the above challenges. To achieve target-aware molecule design,\nour method learns a joint generative process of both continuous atom\ncoordinates and categorical atom types with a SE(3)-equivariant network.\nMoreover, we show that our model can serve as an unsupervised feature extractor\nto estimate the binding affinity under proper parameterization, which provides\nan effective way for drug screening. To evaluate our model, we propose a\ncomprehensive framework to evaluate the quality of sampled molecules from\ndifferent dimensions. Empirical studies show our model could generate molecules\nwith more realistic 3D structures and better affinities towards the protein\ntargets, and improve binding affinity ranking and prediction without\nretraining.\n","authors":["Jiaqi Guan","Wesley Wei Qian","Xingang Peng","Yufeng Su","Jian Peng","Jianzhu Ma"],"pdf_url":"https://arxiv.org/pdf/2303.03543v1.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2206.02914v2","updated":"2023-03-06T22:55:36Z","published":"2022-06-06T21:31:32Z","title":"Training Subset Selection for Weak Supervision","summary":"  Existing weak supervision approaches use all the data covered by weak signals\nto train a classifier. We show both theoretically and empirically that this is\nnot always optimal. Intuitively, there is a tradeoff between the amount of\nweakly-labeled data and the precision of the weak labels. We explore this\ntradeoff by combining pretrained data representations with the cut statistic\n(Muhlenbach et al., 2004) to select (hopefully) high-quality subsets of the\nweakly-labeled training data. Subset selection applies to any label model and\nclassifier and is very simple to plug in to existing weak supervision\npipelines, requiring just a few lines of code. We show our subset selection\nmethod improves the performance of weak supervision for a wide range of label\nmodels, classifiers, and datasets. Using less weakly-labeled data improves the\naccuracy of weak supervision pipelines by up to 19% (absolute) on benchmark\ntasks.\n","authors":["Hunter Lang","Aravindan Vijayaraghavan","David Sontag"],"pdf_url":"https://arxiv.org/pdf/2206.02914v2.pdf","comment":"NeurIPS 2022"}],"Multimedia":[{"id":"http://arxiv.org/abs/2209.08212v3","updated":"2023-03-06T17:24:33Z","published":"2022-09-17T01:20:59Z","title":"Compose & Embellish: Well-Structured Piano Performance Generation via A\n  Two-Stage Approach","summary":"  Even with strong sequence models like Transformers, generating expressive\npiano performances with long-range musical structures remains challenging.\nMeanwhile, methods to compose well-structured melodies or lead sheets (melody +\nchords), i.e., simpler forms of music, gained more success. Observing the\nabove, we devise a two-stage Transformer-based framework that Composes a lead\nsheet first, and then Embellishes it with accompaniment and expressive touches.\nSuch a factorization also enables pretraining on non-piano data. Our objective\nand subjective experiments show that Compose & Embellish shrinks the gap in\nstructureness between a current state of the art and real performances by half,\nand improves other musical aspects such as richness and coherence as well.\n","authors":["Shih-Lun Wu","Yi-Hsuan Yang"],"pdf_url":"https://arxiv.org/pdf/2209.08212v3.pdf","comment":"Accepted to International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP) 2023"},{"id":"http://arxiv.org/abs/2303.03171v1","updated":"2023-03-06T14:39:54Z","published":"2023-03-06T14:39:54Z","title":"Neighborhood Contrastive Transformer for Change Captioning","summary":"  Change captioning is to describe the semantic change between a pair of\nsimilar images in natural language. It is more challenging than general image\ncaptioning, because it requires capturing fine-grained change information while\nbeing immune to irrelevant viewpoint changes, and solving syntax ambiguity in\nchange descriptions. In this paper, we propose a neighborhood contrastive\ntransformer to improve the model's perceiving ability for various changes under\ndifferent scenes and cognition ability for complex syntax structure.\nConcretely, we first design a neighboring feature aggregating to integrate\nneighboring context into each feature, which helps quickly locate the\ninconspicuous changes under the guidance of conspicuous referents. Then, we\ndevise a common feature distilling to compare two images at neighborhood level\nand extract common properties from each image, so as to learn effective\ncontrastive information between them. Finally, we introduce the explicit\ndependencies between words to calibrate the transformer decoder, which helps\nbetter understand complex syntax structure during training. Extensive\nexperimental results demonstrate that the proposed method achieves the\nstate-of-the-art performance on three public datasets with different change\nscenarios. The code is available at https://github.com/tuyunbin/NCT.\n","authors":["Yunbin Tu","Liang Li","Li Su","Ke Lu","Qingming Huang"],"pdf_url":"https://arxiv.org/pdf/2303.03171v1.pdf","comment":"Accepted by IEEE TMM"},{"id":"http://arxiv.org/abs/2303.03144v1","updated":"2023-03-06T13:59:37Z","published":"2023-03-06T13:59:37Z","title":"IPA-CLIP: Integrating Phonetic Priors into Vision and Language\n  Pretraining","summary":"  Recently, large-scale Vision and Language (V\\&L) pretraining has become the\nstandard backbone of many multimedia systems. While it has shown remarkable\nperformance even in unseen situations, it often performs in ways not intuitive\nto humans. Particularly, they usually do not consider the pronunciation of the\ninput, which humans would utilize to understand language, especially when it\ncomes to unknown words. Thus, this paper inserts phonetic prior into\nContrastive Language-Image Pretraining (CLIP), one of the V\\&L pretrained\nmodels, to make it consider the pronunciation similarity among its\npronunciation inputs. To achieve this, we first propose a phoneme embedding\nthat utilizes the phoneme relationships provided by the International Phonetic\nAlphabet (IPA) chart as a phonetic prior. Next, by distilling the frozen CLIP\ntext encoder, we train a pronunciation encoder employing the IPA-based\nembedding. The proposed model named IPA-CLIP comprises this pronunciation\nencoder and the original CLIP encoders (image and text). Quantitative\nevaluation reveals that the phoneme distribution on the embedding space\nrepresents phonetic relationships more accurately when using the proposed\nphoneme embedding. Furthermore, in some multimodal retrieval tasks, we confirm\nthat the proposed pronunciation encoder enhances the performance of the text\nencoder and that the pronunciation encoder handles nonsense words in a more\nphonetic manner than the text encoder. Finally, qualitative evaluation verifies\nthe correlation between the pronunciation encoder and human perception\nregarding pronunciation similarity.\n","authors":["Chihaya Matsuhira","Marc A. Kastner","Takahiro Komamizu","Takatsugu Hirayama","Keisuke Doman","Yasutomo Kawanishi","Ichiro Ide"],"pdf_url":"https://arxiv.org/pdf/2303.03144v1.pdf","comment":"11 pages, 8 figures, 5 Tables"},{"id":"http://arxiv.org/abs/2303.03131v1","updated":"2023-03-06T13:49:15Z","published":"2023-03-06T13:49:15Z","title":"Video Question Answering Using CLIP-Guided Visual-Text Attention","summary":"  Cross-modal learning of video and text plays a key role in Video Question\nAnswering (VideoQA). In this paper, we propose a visual-text attention\nmechanism to utilize the Contrastive Language-Image Pre-training (CLIP) trained\non lots of general domain language-image pairs to guide the cross-modal\nlearning for VideoQA. Specifically, we first extract video features using a\nTimeSformer and text features using a BERT from the target application domain,\nand utilize CLIP to extract a pair of visual-text features from the\ngeneral-knowledge domain through the domain-specific learning. We then propose\na Cross-domain Learning to extract the attention information between visual and\nlinguistic features across the target domain and general domain. The set of\nCLIP-guided visual-text features are integrated to predict the answer. The\nproposed method is evaluated on MSVD-QA and MSRVTT-QA datasets, and outperforms\nstate-of-the-art methods.\n","authors":["Shuhong Ye","Weikai Kong","Chenglin Yao","Jianfeng Ren","Xudong Jiang"],"pdf_url":"https://arxiv.org/pdf/2303.03131v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03105v1","updated":"2023-03-06T13:16:17Z","published":"2023-03-06T13:16:17Z","title":"Confidence-based Event-centric Online Video Question Answering on a\n  Newly Constructed ATBS Dataset","summary":"  Deep neural networks facilitate video question answering (VideoQA), but the\nreal-world applications on video streams such as CCTV and live cast place\nhigher demands on the solver. To address the challenges of VideoQA on long\nvideos of unknown length, we define a new set of problems called Online\nOpen-ended Video Question Answering (O^2VQA). It requires an online\nstate-updating mechanism for the solver to decide if the collected information\nis sufficient to conclude an answer. We then propose a Confidence-based\nEvent-centric Online Video Question Answering (CEO-VQA) model to solve this\nproblem. Furthermore, a dataset called Answer Target in Background Stream\n(ATBS) is constructed to evaluate this newly developed online VideoQA\napplication. Compared to the baseline VideoQA method that watches the whole\nvideo, the experimental results show that the proposed method achieves a\nsignificant performance gain.\n","authors":["Weikai Kong","Shuhong Ye","Chenglin Yao","Jianfeng Ren"],"pdf_url":"https://arxiv.org/pdf/2303.03105v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.14889v2","updated":"2023-03-06T11:50:26Z","published":"2022-10-24T17:40:07Z","title":"Perfectly Secure Steganography Using Minimum Entropy Coupling","summary":"  Steganography is the practice of encoding secret information into innocuous\ncontent in such a manner that an adversarial third party would not realize that\nthere is hidden meaning. While this problem has classically been studied in\nsecurity literature, recent advances in generative models have led to a shared\ninterest among security and machine learning researchers in developing scalable\nsteganography techniques. In this work, we show that a steganography procedure\nis perfectly secure under \\citet{cachin_perfect}'s information theoretic-model\nof steganography if and only if it is induced by a coupling. Furthermore, we\nshow that, among perfectly secure procedures, a procedure is maximally\nefficient if and only if it is induced by a minimum entropy coupling. These\ninsights yield what are, to the best of our knowledge, the first steganography\nalgorithms to achieve perfect security guarantees with non-trivial efficiency;\nadditionally, these algorithms are highly scalable. To provide empirical\nvalidation, we compare a minimum entropy coupling-based approach to three\nmodern baselines -- arithmetic coding, Meteor, and adaptive dynamic grouping --\nusing GPT-2 and WaveRNN as communication channels. We find that the minimum\nentropy coupling-based approach yields superior encoding efficiency, despite\nits stronger security constraints. In aggregate, these results suggest that it\nmay be natural to view information-theoretic steganography through the lens of\nminimum entropy coupling.\n","authors":["Christian Schroeder de Witt","Samuel Sokota","J. Zico Kolter","Jakob Foerster","Martin Strohmeier"],"pdf_url":"https://arxiv.org/pdf/2210.14889v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02959v1","updated":"2023-03-06T08:19:15Z","published":"2023-03-06T08:19:15Z","title":"Butterfly: Multiple Reference Frames Feature Propagation Mechanism for\n  Neural Video Compression","summary":"  Using more reference frames can significantly improve the compression\nefficiency in neural video compression. However, in low-latency scenarios, most\nexisting neural video compression frameworks usually use the previous one frame\nas reference. Or a few frameworks which use the previous multiple frames as\nreference only adopt a simple multi-reference frames propagation mechanism. In\nthis paper, we present a more reasonable multi-reference frames propagation\nmechanism for neural video compression, called butterfly multi-reference frame\npropagation mechanism (Butterfly), which allows a more effective feature fusion\nof multi-reference frames. By this, we can generate more accurate temporal\ncontext conditional prior for Contextual Coding Module. Besides, when the\nnumber of decoded frames does not meet the required number of reference frames,\nwe duplicate the nearest reference frame to achieve the requirement, which is\nbetter than duplicating the furthest one. Experiment results show that our\nmethod can significantly outperform the previous state-of-the-art (SOTA), and\nour neural codec can achieve -7.6% bitrate save on HEVC Class D dataset when\ncompares with our base single-reference frame model with the same compression\nconfiguration.\n","authors":["Feng Wang","Haihang Ruan","Fei Xiong","Jiayu Yang","Litian Li","Ronggang Wang"],"pdf_url":"https://arxiv.org/pdf/2303.02959v1.pdf","comment":"Accepted by DCC 2023"},{"id":"http://arxiv.org/abs/2207.00056v3","updated":"2023-03-06T19:39:18Z","published":"2022-06-30T18:42:06Z","title":"MultiViz: Towards Visualizing and Understanding Multimodal Models","summary":"  The promise of multimodal models for real-world applications has inspired\nresearch in visualizing and understanding their internal mechanics with the end\ngoal of empowering stakeholders to visualize model behavior, perform model\ndebugging, and promote trust in machine learning models. However, modern\nmultimodal models are typically black-box neural networks, which makes it\nchallenging to understand their internal mechanics. How can we visualize the\ninternal modeling of multimodal interactions in these models? Our paper aims to\nfill this gap by proposing MultiViz, a method for analyzing the behavior of\nmultimodal models by scaffolding the problem of interpretability into 4 stages:\n(1) unimodal importance: how each modality contributes towards downstream\nmodeling and prediction, (2) cross-modal interactions: how different modalities\nrelate with each other, (3) multimodal representations: how unimodal and\ncross-modal interactions are represented in decision-level features, and (4)\nmultimodal prediction: how decision-level features are composed to make a\nprediction. MultiViz is designed to operate on diverse modalities, models,\ntasks, and research areas. Through experiments on 8 trained models across 6\nreal-world tasks, we show that the complementary stages in MultiViz together\nenable users to (1) simulate model predictions, (2) assign interpretable\nconcepts to features, (3) perform error analysis on model misclassifications,\nand (4) use insights from error analysis to debug models. MultiViz is publicly\navailable, will be regularly updated with new interpretation tools and metrics,\nand welcomes inputs from the community.\n","authors":["Paul Pu Liang","Yiwei Lyu","Gunjan Chhablani","Nihal Jain","Zihao Deng","Xingbo Wang","Louis-Philippe Morency","Ruslan Salakhutdinov"],"pdf_url":"https://arxiv.org/pdf/2207.00056v3.pdf","comment":"ICLR 2023. Code available at: https://github.com/pliang279/MultiViz"}]},"2023-03-05T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2302.09908v2","updated":"2023-03-05T23:10:24Z","published":"2023-02-20T11:09:37Z","title":"A Sidecar Separator Can Convert a Single-Talker Speech Recognition\n  System to a Multi-Talker One","summary":"  Although automatic speech recognition (ASR) can perform well in common\nnon-overlapping environments, sustaining performance in multi-talker\noverlapping speech recognition remains challenging. Recent research revealed\nthat ASR model's encoder captures different levels of information with\ndifferent layers -- the lower layers tend to have more acoustic information,\nand the upper layers more linguistic. This inspires us to develop a Sidecar\nseparator to empower a well-trained ASR model for multi-talker scenarios by\nseparating the mixed speech embedding between two suitable layers. We\nexperimented with a wav2vec 2.0-based ASR model with a Sidecar mounted. By\nfreezing the parameters of the original model and training only the Sidecar\n(8.7 M, 8.4% of all parameters), the proposed approach outperforms the previous\nstate-of-the-art by a large margin for the 2-speaker mixed LibriMix dataset,\nreaching a word error rate (WER) of 10.36%; and obtains comparable results\n(7.56%) for LibriSpeechMix dataset when limited training.\n","authors":["Lingwei Meng","Jiawen Kang","Mingyu Cui","Yuejiao Wang","Xixin Wu","Helen Meng"],"pdf_url":"https://arxiv.org/pdf/2302.09908v2.pdf","comment":"Accepted by IEEE International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP), 2023"},{"id":"http://arxiv.org/abs/2303.02758v1","updated":"2023-03-05T19:45:42Z","published":"2023-03-05T19:45:42Z","title":"WADER at SemEval-2023 Task 9: A Weak-labelling framework for Data\n  augmentation in tExt Regression Tasks","summary":"  Intimacy is an essential element of human relationships and language is a\ncrucial means of conveying it. Textual intimacy analysis can reveal social\nnorms in different contexts and serve as a benchmark for testing computational\nmodels' ability to understand social information. In this paper, we propose a\nnovel weak-labeling strategy for data augmentation in text regression tasks\ncalled WADER. WADER uses data augmentation to address the problems of data\nimbalance and data scarcity and provides a method for data augmentation in\ncross-lingual, zero-shot tasks. We benchmark the performance of\nState-of-the-Art pre-trained multilingual language models using WADER and\nanalyze the use of sampling techniques to mitigate bias in data and optimally\nselect augmentation candidates. Our results show that WADER outperforms the\nbaseline model and provides a direction for mitigating data imbalance and\nscarcity in text regression tasks.\n","authors":["Manan Suri","Aaryak Garg","Divya Chaudhary","Ian Gorton","Bijendra Kumar"],"pdf_url":"https://arxiv.org/pdf/2303.02758v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.15432v2","updated":"2023-03-05T19:21:25Z","published":"2022-11-28T15:18:07Z","title":"E2E Segmentation in a Two-Pass Cascaded Encoder ASR Model","summary":"  We explore unifying a neural segmenter with two-pass cascaded encoder ASR\ninto a single model. A key challenge is allowing the segmenter (which runs in\nreal-time, synchronously with the decoder) to finalize the 2nd pass (which runs\n900 ms behind real-time) without introducing user-perceived latency or deletion\nerrors during inference. We propose a design where the neural segmenter is\nintegrated with the causal 1st pass decoder to emit a end-of-segment (EOS)\nsignal in real-time. The EOS signal is then used to finalize the non-causal 2nd\npass. We experiment with different ways to finalize the 2nd pass, and find that\na novel dummy frame injection strategy allows for simultaneous high quality 2nd\npass results and low finalization latency. On a real-world long-form captioning\ntask (YouTube), we achieve 2.4% relative WER and 140 ms EOS latency gains over\na baseline VAD-based segmenter with the same cascaded encoder.\n","authors":["W. Ronny Huang","Shuo-Yiin Chang","Tara N. Sainath","Yanzhang He","David Rybach","Robert David","Rohit Prabhavalkar","Cyril Allauzen","Cal Peyser","Trevor D. Strohman"],"pdf_url":"https://arxiv.org/pdf/2211.15432v2.pdf","comment":"ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.02707v1","updated":"2023-03-05T16:17:56Z","published":"2023-03-05T16:17:56Z","title":"FQP 2.0: Industry Trend Analysis via Hierarchical Financial Data","summary":"  Analyzing trends across industries is critical to maintaining a healthy and\nstable economy. Previous research has mainly analyzed official statistics,\nwhich are more accurate but not necessarily real-time. In this paper, we\npropose a method for analyzing industry trends using stock market data. The\ndifficulty of this task is that the raw data is relatively noisy, which affects\nthe accuracy of statistical analysis. In addition, textual data for industry\nanalysis needs to be better understood through language models. For this\nreason, we introduce the method of industry trend analysis from two\nperspectives of explicit analysis and implicit analysis. For the explicit\nanalysis, we introduce a hierarchical data (industry and listed company)\nanalysis method to reduce the impact of noise. For implicit analysis, we\nfurther pre-train GPT-2 to analyze industry trends with current affairs\nbackground as input, making full use of the knowledge learned in the\npre-training corpus. We conduct experiments based on the proposed method and\nachieve good industry trend analysis results.\n","authors":["Hongyin Zhu"],"pdf_url":"https://arxiv.org/pdf/2303.02707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02677v1","updated":"2023-03-05T14:25:05Z","published":"2023-03-05T14:25:05Z","title":"Mining both Commonality and Specificity from Multiple Documents for\n  Multi-Document Summarization","summary":"  The multi-document summarization task requires the designed summarizer to\ngenerate a short text that covers the important information of original\ndocuments and satisfies content diversity. This paper proposes a multi-document\nsummarization approach based on hierarchical clustering of documents. It\nutilizes the constructed class tree of documents to extract both the sentences\nreflecting the commonality of all documents and the sentences reflecting the\nspecificity of some subclasses of these documents for generating a summary, so\nas to satisfy the coverage and diversity requirements of multi-document\nsummarization. Comparative experiments with different variant approaches on\nDUC'2002-2004 datasets prove the effectiveness of mining both the commonality\nand specificity of documents for multi-document summarization. Experiments on\nDUC'2004 and Multi-News datasets show that our approach achieves competitive\nperformance compared to the state-of-the-art unsupervised and supervised\napproaches.\n","authors":["Bing Ma"],"pdf_url":"https://arxiv.org/pdf/2303.02677v1.pdf","comment":"10 pages, 1 figure"},{"id":"http://arxiv.org/abs/2302.11466v2","updated":"2023-03-05T11:29:10Z","published":"2023-02-22T16:00:27Z","title":"Advancements in Federated Learning: Models, Methods, and Privacy","summary":"  Federated learning (FL) is a promising technique for addressing the rising\nprivacy and security issues. Its main ingredient is to cooperatively learn the\nmodel among the distributed clients without uploading any sensitive data. In\nthis paper, we conducted a thorough review of the related works, following the\ndevelopment context and deeply mining the key technologies behind FL from both\ntheoretical and practical perspectives. Specifically, we first classify the\nexisting works in FL architecture based on the network topology of FL systems\nwith detailed analysis and summarization. Next, we abstract the current\napplication problems, summarize the general techniques and frame the\napplication problems into the general paradigm of FL base models. Moreover, we\nprovide our proposed solutions for model training via FL. We have summarized\nand analyzed the existing FedOpt algorithms, and deeply revealed the\nalgorithmic development principles of many first-order algorithms in depth,\nproposing a more generalized algorithm design framework. Based on these\nframeworks, we have instantiated FedOpt algorithms. As privacy and security is\nthe fundamental requirement in FL, we provide the existing attack scenarios and\nthe defense methods. To the best of our knowledge, we are among the first tier\nto review the theoretical methodology and propose our strategies since there\nare very few works surveying the theoretical approaches. Our survey targets\nmotivating the development of high-performance, privacy-preserving, and secure\nmethods to integrate FL into real-world applications.\n","authors":["Huiming Chen","Huandong Wang","Qingyue Long","Depeng Jin","Yong Li"],"pdf_url":"https://arxiv.org/pdf/2302.11466v2.pdf","comment":"35 pages, submitted to ACM Computing Surveys"},{"id":"http://arxiv.org/abs/2208.05309v2","updated":"2023-03-05T09:28:23Z","published":"2022-08-10T12:44:13Z","title":"Looking for a Needle in a Haystack: A Comprehensive Study of\n  Hallucinations in Neural Machine Translation","summary":"  Although the problem of hallucinations in neural machine translation (NMT)\nhas received some attention, research on this highly pathological phenomenon\nlacks solid ground. Previous work has been limited in several ways: it often\nresorts to artificial settings where the problem is amplified, it disregards\nsome (common) types of hallucinations, and it does not validate adequacy of\ndetection heuristics. In this paper, we set foundations for the study of NMT\nhallucinations. First, we work in a natural setting, i.e., in-domain data\nwithout artificial noise neither in training nor in inference. Next, we\nannotate a dataset of over 3.4k sentences indicating different kinds of\ncritical errors and hallucinations. Then, we turn to detection methods and both\nrevisit methods used previously and propose using glass-box uncertainty-based\ndetectors. Overall, we show that for preventive settings, (i) previously used\nmethods are largely inadequate, (ii) sequence log-probability works best and\nperforms on par with reference-based methods. Finally, we propose\nDeHallucinator, a simple method for alleviating hallucinations at test time\nthat significantly reduces the hallucinatory rate. To ease future research, we\nrelease our annotated dataset for WMT18 German-English data, along with the\nmodel, training data, and code.\n","authors":["Nuno M. Guerreiro","Elena Voita","André F. T. Martins"],"pdf_url":"https://arxiv.org/pdf/2208.05309v2.pdf","comment":"Accepted at EACL23 (main)"},{"id":"http://arxiv.org/abs/2209.15352v2","updated":"2023-03-05T09:14:16Z","published":"2022-09-30T10:17:05Z","title":"AudioGen: Textually Guided Audio Generation","summary":"  We tackle the problem of generating audio samples conditioned on descriptive\ntext captions. In this work, we propose AaudioGen, an auto-regressive\ngenerative model that generates audio samples conditioned on text inputs.\nAudioGen operates on a learnt discrete audio representation. The task of\ntext-to-audio generation poses multiple challenges. Due to the way audio\ntravels through a medium, differentiating ``objects'' can be a difficult task\n(e.g., separating multiple people simultaneously speaking). This is further\ncomplicated by real-world recording conditions (e.g., background noise,\nreverberation, etc.). Scarce text annotations impose another constraint,\nlimiting the ability to scale models. Finally, modeling high-fidelity audio\nrequires encoding audio at high sampling rate, leading to extremely long\nsequences. To alleviate the aforementioned challenges we propose an\naugmentation technique that mixes different audio samples, driving the model to\ninternally learn to separate multiple sources. We curated 10 datasets\ncontaining different types of audio and text annotations to handle the scarcity\nof text-audio data points. For faster inference, we explore the use of\nmulti-stream modeling, allowing the use of shorter sequences while maintaining\na similar bitrate and perceptual quality. We apply classifier-free guidance to\nimprove adherence to text. Comparing to the evaluated baselines, AudioGen\noutperforms over both objective and subjective metrics. Finally, we explore the\nability of the proposed method to generate audio continuation conditionally and\nunconditionally. Samples: https://felixkreuk.github.io/audiogen\n","authors":["Felix Kreuk","Gabriel Synnaeve","Adam Polyak","Uriel Singer","Alexandre Défossez","Jade Copet","Devi Parikh","Yaniv Taigman","Yossi Adi"],"pdf_url":"https://arxiv.org/pdf/2209.15352v2.pdf","comment":"Accepted to ICLR 2023"},{"id":"http://arxiv.org/abs/2302.02676v5","updated":"2023-03-05T08:31:34Z","published":"2023-02-06T10:28:16Z","title":"Chain of Hindsight Aligns Language Models with Feedback","summary":"  Learning from human preferences is important for language models to be\nhelpful and useful for humans, and to align with human and social values. Prior\nwork have achieved remarkable successes by learning from human feedback to\nunderstand and follow instructions. Nonetheless, these methods are either\nfounded on hand-picked model generations that are favored by human annotators,\nrendering them ineffective in terms of data utilization and challenging to\napply in general, or they depend on reward functions and reinforcement\nlearning, which are prone to imperfect reward function and extremely\nchallenging to optimize. In this work, we propose a novel technique, Chain of\nHindsight, that is easy to optimize and can learn from any form of feedback,\nregardless of its polarity. Our idea is inspired by how humans learn from\nextensive feedback presented in the form of languages. We convert all types of\nfeedback into sentences, which are then used to fine-tune the model, allowing\nus to take advantage of the language comprehension capabilities of language\nmodels. We condition the model on a sequence of model generations paired with\nfeedback. By doing so, models are trained to generate outputs based on\nfeedback, and models can learn to identify and correct negative attributes or\nerrors. Applying our method to large language models, we observed that Chain of\nHindsight significantly surpasses previous methods in aligning language models\nwith human preferences. We observed significant improvements on summarization\nand dialogue tasks and our approach is markedly preferred in human evaluations.\n","authors":["Hao Liu","Carmelo Sferrazza","Pieter Abbeel"],"pdf_url":"https://arxiv.org/pdf/2302.02676v5.pdf","comment":"Included a comprehensive list of templates"},{"id":"http://arxiv.org/abs/2303.02601v1","updated":"2023-03-05T08:00:30Z","published":"2023-03-05T08:00:30Z","title":"Knowledge-Based Counterfactual Queries for Visual Question Answering","summary":"  Visual Question Answering (VQA) has been a popular task that combines vision\nand language, with numerous relevant implementations in literature. Even though\nthere are some attempts that approach explainability and robustness issues in\nVQA models, very few of them employ counterfactuals as a means of probing such\nchallenges in a model-agnostic way. In this work, we propose a systematic\nmethod for explaining the behavior and investigating the robustness of VQA\nmodels through counterfactual perturbations. For this reason, we exploit\nstructured knowledge bases to perform deterministic, optimal and controllable\nword-level replacements targeting the linguistic modality, and we then evaluate\nthe model's response against such counterfactual inputs. Finally, we\nqualitatively extract local and global explanations based on counterfactual\nresponses, which are ultimately proven insightful towards interpreting VQA\nmodel behaviors. By performing a variety of perturbation types, targeting\ndifferent parts of speech of the input question, we gain insights to the\nreasoning of the model, through the comparison of its responses in different\nadversarial circumstances. Overall, we reveal possible biases in the\ndecision-making process of the model, as well as expected and unexpected\npatterns, which impact its performance quantitatively and qualitatively, as\nindicated by our analysis.\n","authors":["Theodoti Stoikou","Maria Lymperaiou","Giorgos Stamou"],"pdf_url":"https://arxiv.org/pdf/2303.02601v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02577v1","updated":"2023-03-05T04:12:17Z","published":"2023-03-05T04:12:17Z","title":"Effectiveness of Data Augmentation for Prefix Tuning with Limited Data","summary":"  Recent work has demonstrated that tuning continuous prompts on large, frozen\npretrained language models (i.e., prefix tuning or P-tuning) can yield\nperformance that is comparable or superior to fine-tuning. Nevertheless, the\neffectiveness of such methods under the context of data augmentation, which has\nbeen considered a common strategy to improve learning under low data regimes,\nhas not be studied. In this paper, we examine several popular task-agnostic\ndata augmentation techniques, i.e., EDA, Back Translation, and Mixup, when\nusing prefix tuning under data scarcity. We show that data augmentation can be\nused to boost the performance of prefix tuning models, but the effectiveness of\neach technique varies and certain methods can lead to a notable degradation in\nperformance, particularly when using larger models and on harder tasks. To help\nunderstand the above behaviour, we run experiments which reveal how prefix\ntuning generally presents a limited ability to separate the sentence embeddings\nfrom different classes of augmented data, and displays poorer performance on\nheavily altered data in particular. We also demonstrate that by adding a simple\ncontrastive loss we can help mitigate such issues for prefix tuning, resulting\nin an improvement to augmented data performance.\n","authors":["Stephen Obadinma","Hongyu Guo","Xiaodan Zhu"],"pdf_url":"https://arxiv.org/pdf/2303.02577v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02563v1","updated":"2023-03-05T03:18:56Z","published":"2023-03-05T03:18:56Z","title":"FinXABSA:Explainable Finance through Aspect-Based Sentiment Analysis","summary":"  This paper presents a novel approach for explainability in financial analysis\nby utilizing the Pearson correlation coefficient to establish a relationship\nbetween aspect-based sentiment analysis and stock prices. The proposed\nmethodology involves constructing an aspect list from financial news articles\nand analyzing sentiment intensity scores for each aspect. These scores are then\ncompared to the stock prices for the relevant companies using the Pearson\ncoefficient to determine any significant correlations. The results indicate\nthat the proposed approach provides a more detailed and accurate understanding\nof the relationship between sentiment analysis and stock prices, which can be\nuseful for investors and financial analysts in making informed decisions.\nAdditionally, this methodology offers a transparent and interpretable way to\nexplain the sentiment analysis results and their impact on stock prices.\nOverall, the findings of this paper demonstrate the importance of\nexplainability in financial analysis and highlight the potential benefits of\nutilizing the Pearson coefficient for analyzing aspect-based sentiment analysis\nand stock prices. The proposed approach offers a valuable tool for\nunderstanding the complex relationships between financial news sentiment and\nstock prices, providing a new perspective on the financial market and aiding in\nmaking informed investment decisions.\n","authors":["Keane Ong","Wihan van der Heever","Ranjan Satapathy","Gianmarco Mengaldo","Erik Cambria"],"pdf_url":"https://arxiv.org/pdf/2303.02563v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2205.15361v2","updated":"2023-03-05T23:42:50Z","published":"2022-05-30T18:10:33Z","title":"TubeFormer-DeepLab: Video Mask Transformer","summary":"  We present TubeFormer-DeepLab, the first attempt to tackle multiple core\nvideo segmentation tasks in a unified manner. Different video segmentation\ntasks (e.g., video semantic/instance/panoptic segmentation) are usually\nconsidered as distinct problems. State-of-the-art models adopted in the\nseparate communities have diverged, and radically different approaches dominate\nin each task. By contrast, we make a crucial observation that video\nsegmentation tasks could be generally formulated as the problem of assigning\ndifferent predicted labels to video tubes (where a tube is obtained by linking\nsegmentation masks along the time axis) and the labels may encode different\nvalues depending on the target task. The observation motivates us to develop\nTubeFormer-DeepLab, a simple and effective video mask transformer model that is\nwidely applicable to multiple video segmentation tasks. TubeFormer-DeepLab\ndirectly predicts video tubes with task-specific labels (either pure semantic\ncategories, or both semantic categories and instance identities), which not\nonly significantly simplifies video segmentation models, but also advances\nstate-of-the-art results on multiple video segmentation benchmarks\n","authors":["Dahun Kim","Jun Xie","Huiyu Wang","Siyuan Qiao","Qihang Yu","Hong-Seok Kim","Hartwig Adam","In So Kweon","Liang-Chieh Chen"],"pdf_url":"https://arxiv.org/pdf/2205.15361v2.pdf","comment":"CVPR 2022; arXiv v2: add results on VIPSeg val/test sets and VSPW new\n  test set"},{"id":"http://arxiv.org/abs/2209.07590v2","updated":"2023-03-05T23:30:15Z","published":"2022-09-15T19:57:16Z","title":"Prediction of Gender from Longitudinal MRI data via Deep Learning on\n  Adolescent Data Reveals Unique Patterns Associated with Brain Structure and\n  Change over a Two-year Period","summary":"  Deep learning algorithms for predicting neuroimaging data have shown\nconsiderable promise in various applications. Prior work has demonstrated that\ndeep learning models that take advantage of the data's 3D structure can\noutperform standard machine learning on several learning tasks. However, most\nprior research in this area has focused on neuroimaging data from adults.\nWithin the Adolescent Brain and Cognitive Development (ABCD) dataset, a large\nlongitudinal development study, we examine structural MRI data to predict\ngender and identify gender-related changes in brain structure. Results\ndemonstrate that gender prediction accuracy is exceptionally high (>97%) with\ntraining epochs >200 and that this accuracy increases with age. Brain regions\nidentified as the most discriminative in the task under study include\npredominantly frontal areas and the temporal lobe. When evaluating gender\npredictive changes specific to a two-year increase in age, a broader set of\nvisual, cingulate, and insular regions are revealed. Our findings show a robust\ngender-related structural brain change pattern, even over a small age range.\nThis suggests that it might be possible to study how the brain changes during\nadolescence by looking at how these changes are related to different behavioral\nand environmental factors.\n","authors":["Yuda Bi","Anees Abrol","Zening Fu","Jiayu Chen","Jingyu Liu","Vince Calhoun"],"pdf_url":"https://arxiv.org/pdf/2209.07590v2.pdf","comment":"I submitted the wrong paper"},{"id":"http://arxiv.org/abs/2211.06726v2","updated":"2023-03-05T23:21:41Z","published":"2022-11-12T19:07:25Z","title":"MultiCrossViT: Multimodal Vision Transformer for Schizophrenia\n  Prediction using Structural MRI and Functional Network Connectivity Data","summary":"  Vision Transformer (ViT) is a pioneering deep learning framework that can\naddress real-world computer vision issues, such as image classification and\nobject recognition. Importantly, ViTs are proven to outperform traditional deep\nlearning models, such as convolutional neural networks (CNNs). Relatively\nrecently, a number of ViT mutations have been transplanted into the field of\nmedical imaging, thereby resolving a variety of critical classification and\nsegmentation challenges, especially in terms of brain imaging data. In this\nwork, we provide a novel multimodal deep learning pipeline, MultiCrossViT,\nwhich is capable of analyzing both structural MRI (sMRI) and static functional\nnetwork connectivity (sFNC) data for the prediction of schizophrenia disease.\nOn a dataset with minimal training subjects, our novel model can achieve an AUC\nof 0.832. Finally, we visualize multiple brain regions and covariance patterns\nmost relevant to schizophrenia based on the resulting ViT attention maps by\nextracting features from transformer encoders.\n","authors":["Yuda Bi","Anees Abrol","Zening Fu","Vince Calhoun"],"pdf_url":"https://arxiv.org/pdf/2211.06726v2.pdf","comment":"I submitted the wrong paper"},{"id":"http://arxiv.org/abs/2303.02165v1","updated":"2023-03-05T21:31:49Z","published":"2023-03-05T21:31:49Z","title":"DeepMAD: Mathematical Architecture Design for Deep Convolutional Neural\n  Network","summary":"  The rapid advances in Vision Transformer (ViT) refresh the state-of-the-art\nperformances in various vision tasks, overshadowing the conventional CNN-based\nmodels. This ignites a few recent striking-back research in the CNN world\nshowing that pure CNN models can achieve as good performance as ViT models when\ncarefully tuned. While encouraging, designing such high-performance CNN models\nis challenging, requiring non-trivial prior knowledge of network design. To\nthis end, a novel framework termed Mathematical Architecture Design for Deep\nCNN (DeepMAD) is proposed to design high-performance CNN models in a principled\nway. In DeepMAD, a CNN network is modeled as an information processing system\nwhose expressiveness and effectiveness can be analytically formulated by their\nstructural parameters. Then a constrained mathematical programming (MP) problem\nis proposed to optimize these structural parameters. The MP problem can be\neasily solved by off-the-shelf MP solvers on CPUs with a small memory\nfootprint. In addition, DeepMAD is a pure mathematical framework: no GPU or\ntraining data is required during network design. The superiority of DeepMAD is\nvalidated on multiple large-scale computer vision benchmark datasets. Notably\non ImageNet-1k, only using conventional convolutional layers, DeepMAD achieves\n0.7% and 1.5% higher top-1 accuracy than ConvNeXt and Swin on Tiny level, and\n0.8% and 0.9% higher on Small level.\n","authors":["Xuan Shen","Yaohua Wang","Ming Lin","Yilun Huang","Hao Tang","Xiuyu Sun","Yanzhi Wang"],"pdf_url":"https://arxiv.org/pdf/2303.02165v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2303.02776v1","updated":"2023-03-05T21:30:49Z","published":"2023-03-05T21:30:49Z","title":"A Low-Cost Portable Apparatus to Analyze Oral Fluid Droplets and\n  Quantify the Efficacy of Masks","summary":"  Every year, about 4 million people die from upper respiratory infections.\nMask-wearing is crucial in preventing the spread of pathogen-containing\ndroplets, which is the primary cause of these illnesses. However, most\ntechniques for mask efficacy evaluation are expensive to set up and complex to\noperate. In this work, a novel, low-cost, and quantitative metrology to\nvisualize, track, and analyze orally-generated fluid droplets is developed. The\nproject has four stages: setup optimization, data collection, data analysis,\nand application development. The metrology was initially developed in a dark\ncloset as a proof of concept using common household materials and was\nsubsequently implemented into a portable apparatus. Tonic water and UV\ndarklight tube lights are selected to visualize fluorescent droplet and aerosol\npropagation with automated analysis developed using open-source software. The\ndependencies of oral fluid droplet generation and propagation on various\nfactors are studied in detail and established using this metrology.\nAdditionally, the smallest detectable droplet size was mathematically\ncorrelated to height and airborne time. The efficacy of different types of\nmasks is evaluated and associated with fabric microstructures. It is found that\nmasks with smaller-sized pores and thicker material are more effective. This\ntechnique can easily be constructed at home using materials that total to a\ncost of below \\$60, thereby enabling a low-cost and accurate metrology.\n","authors":["Ava Tan Bhowmik"],"pdf_url":"https://arxiv.org/pdf/2303.02776v1.pdf","comment":"13 pages, 15 figures. arXiv admin note: substantial text overlap with\n  arXiv:2201.03993"},{"id":"http://arxiv.org/abs/2101.02530v2","updated":"2023-03-05T21:16:18Z","published":"2021-01-07T13:08:44Z","title":"MSED: a multi-modal sleep event detection model for clinical sleep\n  analysis","summary":"  Clinical sleep analysis require manual analysis of sleep patterns for correct\ndiagnosis of sleep disorders. However, several studies have shown significant\nvariability in manual scoring of clinically relevant discrete sleep events,\nsuch as arousals, leg movements, and sleep disordered breathing (apneas and\nhypopneas). We investigated whether an automatic method could be used for event\ndetection and if a model trained on all events (joint model) performed better\nthan corresponding event-specific models (single-event models). We trained a\ndeep neural network event detection model on 1653 individual recordings and\ntested the optimized model on 1000 separate hold-out recordings. F1 scores for\nthe optimized joint detection model were 0.70, 0.63, and 0.62 for arousals, leg\nmovements, and sleep disordered breathing, respectively, compared to 0.65,\n0.61, and 0.60 for the optimized single-event models. Index values computed\nfrom detected events correlated positively with manual annotations ($r^2$ =\n0.73, $r^2$ = 0.77, $r^2$ = 0.78, respectively). We furthermore quantified\nmodel accuracy based on temporal difference metrics, which improved overall by\nusing the joint model compared to single-event models. Our automatic model\njointly detects arousals, leg movements and sleep disordered breathing events\nwith high correlation with human annotations. Finally, we benchmark against\nprevious state-of-the-art multi-event detection models and found an overall\nincrease in F1 score with our proposed model despite a 97.5% reduction in model\nsize. Source code for training and inference is available at\nhttps://github.com/neergaard/msed.git.\n","authors":["Alexander Neergaard Olesen","Poul Jennum","Emmanuel Mignot","Helge B. D. Sorensen"],"pdf_url":"https://arxiv.org/pdf/2101.02530v2.pdf","comment":"10 pages, 4 figures. Accepted for publication in IEEE Transactions on\n  Biomedical Engineering"},{"id":"http://arxiv.org/abs/2303.02761v1","updated":"2023-03-05T20:06:19Z","published":"2023-03-05T20:06:19Z","title":"A Study of Augmentation Methods for Handwritten Stenography Recognition","summary":"  One of the factors limiting the performance of handwritten text recognition\n(HTR) for stenography is the small amount of annotated training data. To\nalleviate the problem of data scarcity, modern HTR methods often employ data\naugmentation. However, due to specifics of the stenographic script, such\nsettings may not be directly applicable for stenography recognition. In this\nwork, we study 22 classical augmentation techniques, most of which are commonly\nused for HTR of other scripts, such as Latin handwriting. Through extensive\nexperiments, we identify a group of augmentations, including for example\ncontained ranges of random rotation, shifts and scaling, that are beneficial to\nthe use case of stenography recognition. Furthermore, a number of augmentation\napproaches, leading to a decrease in recognition performance, are identified.\nOur results are supported by statistical hypothesis testing. Links to the\npublicly available dataset and codebase are provided.\n","authors":["Raphaela Heil","Eva Breznik"],"pdf_url":"https://arxiv.org/pdf/2303.02761v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02760v1","updated":"2023-03-05T20:05:21Z","published":"2023-03-05T20:05:21Z","title":"Human-Art: A Versatile Human-Centric Dataset Bridging Natural and\n  Artificial Scenes","summary":"  Humans have long been recorded in a variety of forms since antiquity. For\nexample, sculptures and paintings were the primary media for depicting human\nbeings before the invention of cameras. However, most current human-centric\ncomputer vision tasks like human pose estimation and human image generation\nfocus exclusively on natural images in the real world. Artificial humans, such\nas those in sculptures, paintings, and cartoons, are commonly neglected, making\nexisting models fail in these scenarios. As an abstraction of life, art\nincorporates humans in both natural and artificial scenes. We take advantage of\nit and introduce the Human-Art dataset to bridge related tasks in natural and\nartificial scenarios. Specifically, Human-Art contains 50k high-quality images\nwith over 123k person instances from 5 natural and 15 artificial scenarios,\nwhich are annotated with bounding boxes, keypoints, self-contact points, and\ntext information for humans represented in both 2D and 3D. It is, therefore,\ncomprehensive and versatile for various downstream tasks. We also provide a\nrich set of baseline results and detailed analyses for related tasks, including\nhuman detection, 2D and 3D human pose estimation, image generation, and motion\ntransfer. As a challenging dataset, we hope Human-Art can provide insights for\nrelevant research and open up new research questions.\n","authors":["Xuan Ju","Ailing Zeng","Jianan Wang","Qiang Xu","Lei Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.02760v1.pdf","comment":"CVPR2023"},{"id":"http://arxiv.org/abs/2207.03333v3","updated":"2023-03-05T19:44:47Z","published":"2022-07-06T05:57:24Z","title":"FewSOL: A Dataset for Few-Shot Object Learning in Robotic Environments","summary":"  We introduce the Few-Shot Object Learning (FewSOL) dataset for object\nrecognition with a few images per object. We captured 336 real-world objects\nwith 9 RGB-D images per object from different views. Object segmentation masks,\nobject poses and object attributes are provided. In addition, synthetic images\ngenerated using 330 3D object models are used to augment the dataset. We\ninvestigated (i) few-shot object classification and (ii) joint object\nsegmentation and few-shot classification with the state-of-the-art methods for\nfew-shot learning and meta-learning using our dataset. The evaluation results\nshow that there is still a large margin to be improved for few-shot object\nclassification in robotic environments. Our dataset can be used to study a set\nof few-shot object recognition problems such as classification, detection and\nsegmentation, shape reconstruction, pose estimation, keypoint correspondences\nand attribute recognition. The dataset and code are available at\nhttps://irvlutd.github.io/FewSOL.\n","authors":["Jishnu Jaykumar P","Yu-Wei Chao","Yu Xiang"],"pdf_url":"https://arxiv.org/pdf/2207.03333v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02753v1","updated":"2023-03-05T19:20:55Z","published":"2023-03-05T19:20:55Z","title":"Frequency-domain Blind Quality Assessment of Blurred and\n  Blocking-artefact Images using Gaussian Process Regression model","summary":"  Most of the standard image and video codecs are block-based and depending\nupon the compression ratio the compressed images/videos suffer from different\ndistortions. At low ratios, blurriness is observed and as compression increases\nblocking artifacts occur. Generally, in order to reduce blockiness, images are\nlow-pass filtered which leads to more blurriness. Also, in bokeh mode images\nthey are commonly seen: blurriness as a result of intentional blurred\nbackground while blocking artifact and global blurriness arising due to\ncompression. Therefore, such visual media suffer from both blockiness and\nblurriness distortions. Along with this, noise is also commonly encountered\ndistortion. Most of the existing works on quality assessment quantify these\ndistortions individually. This paper proposes a methodology to blindly measure\noverall quality of an image suffering from these distortions, individually as\nwell as jointly. This is achieved by considering the sum of absolute values of\nlow and high-frequency Discrete Frequency Transform (DFT) coefficients defined\nas sum magnitudes. The number of blocks lying in specific ranges of sum\nmagnitudes including zero-valued AC coefficients and mean of 100 maximum and\n100 minimum values of these sum magnitudes are used as feature vectors. These\nfeatures are then fed to the Machine Learning (ML) based Gaussian Process\nRegression (GPR) model, which quantifies the image quality. The simulation\nresults show that the proposed method can estimate the quality of images\ndistorted with the blockiness, blurriness, noise and their combinations. It is\nrelatively fast compared to many state-of-art methods, and therefore is\nsuitable for real-time quality monitoring applications.\n","authors":["Maryam Viqar","Athar A. Moinuddin","Ekram Khan","M. Ghanbari"],"pdf_url":"https://arxiv.org/pdf/2303.02753v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02741v1","updated":"2023-03-05T18:16:34Z","published":"2023-03-05T18:16:34Z","title":"IDA: Informed Domain Adaptive Semantic Segmentation","summary":"  Mixup-based data augmentation has been validated to be a critical stage in\nthe self-training framework for unsupervised domain adaptive semantic\nsegmentation (UDA-SS), which aims to transfer knowledge from a well-annotated\n(source) domain to an unlabeled (target) domain. Existing self-training methods\nusually adopt the popular region-based mixup techniques with a random sampling\nstrategy, which unfortunately ignores the dynamic evolution of different\nsemantics across various domains as training proceeds. To improve the UDA-SS\nperformance, we propose an Informed Domain Adaptation (IDA) model, a\nself-training framework that mixes the data based on class-level segmentation\nperformance, which aims to emphasize small-region semantics during mixup. In\nour IDA model, the class-level performance is tracked by an expected confidence\nscore (ECS). We then use a dynamic schedule to determine the mixing ratio for\ndata in different domains. Extensive experimental results reveal that our\nproposed method is able to outperform the state-of-the-art UDA-SS method by a\nmargin of 1.1 mIoU in the adaptation of GTA-V to Cityscapes and of 0.9 mIoU in\nthe adaptation of SYNTHIA to Cityscapes.\n","authors":["Zheng Chen","Zhengming Ding","Jason M. Gregory","Lantao Liu"],"pdf_url":"https://arxiv.org/pdf/2303.02741v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.00063v2","updated":"2023-03-05T18:08:42Z","published":"2021-10-29T19:50:48Z","title":"Polyline Generative Navigable Space Segmentation for Autonomous Visual\n  Navigation","summary":"  Detecting navigable space is a fundamental capability for mobile robots\nnavigating in unknown or unmapped environments. In this work, we treat visual\nnavigable space segmentation as a scene decomposition problem and propose\nPolyline Segmentation Variational autoencoder Network (PSV-Net), a\nrepresentation learning-based framework for learning the navigable space\nsegmentation in a self-supervised manner. Current segmentation techniques\nheavily rely on fully-supervised learning strategies which demand a large\namount of pixel-level annotated images. In this work, we propose a framework\nleveraging a Variational AutoEncoder (VAE) and an AutoEncoder (AE) to learn a\npolyline representation that compactly outlines the desired navigable space\nboundary. Through extensive experiments, we validate that the proposed PSV-Net\ncan learn the visual navigable space with no or few labels, producing an\naccuracy comparable to fully-supervised state-of-the-art methods that use all\navailable labels. In addition, we show that integrating the proposed navigable\nspace segmentation model with a visual planner can achieve efficient mapless\nnavigation in real environments.\n","authors":["Zheng Chen","Zhengming Ding","David Crandall","Lantao Liu"],"pdf_url":"https://arxiv.org/pdf/2111.00063v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02737v1","updated":"2023-03-05T18:04:28Z","published":"2023-03-05T18:04:28Z","title":"SePaint: Semantic Map Inpainting via Multinomial Diffusion","summary":"  Prediction beyond partial observations is crucial for robots to navigate in\nunknown environments because it can provide extra information regarding the\nsurroundings beyond the current sensing range or resolution. In this work, we\nconsider the inpainting of semantic Bird's-Eye-View maps. We propose SePaint,\nan inpainting model for semantic data based on generative multinomial\ndiffusion. To maintain semantic consistency, we need to condition the\nprediction for the missing regions on the known regions. We propose a novel and\nefficient condition strategy, Look-Back Condition (LB-Con), which performs\none-step look-back operations during the reverse diffusion process. By doing\nso, we are able to strengthen the harmonization between unknown and known\nparts, leading to better completion performance. We have conducted extensive\nexperiments on different datasets, showing our proposed model outperforms\ncommonly used interpolation methods in various robotic applications.\n","authors":["Zheng Chen","Deepak Duggirala","David Crandall","Lei Jiang","Lantao Liu"],"pdf_url":"https://arxiv.org/pdf/2303.02737v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02735v1","updated":"2023-03-05T18:02:54Z","published":"2023-03-05T18:02:54Z","title":"Scalable Object Detection on Embedded Devices Using Weight Pruning and\n  Singular Value Decomposition","summary":"  This paper presents a method for optimizing object detection models by\ncombining weight pruning and singular value decomposition (SVD). The proposed\nmethod was evaluated on a custom dataset of street work images obtained from\nhttps://universe.roboflow.com/roboflow-100/street-work. The dataset consists of\n611 training images, 175 validation images, and 87 test images with 7 classes.\nWe compared the performance of the optimized models with the original\nunoptimized model in terms of frame rate, mean average precision (mAP@50), and\nweight size. The results show that the weight pruning + SVD model achieved a\n0.724 mAP@50 with a frame rate of 1.48 FPS and a weight size of 12.1 MB,\noutperforming the original model (0.717 mAP@50, 1.50 FPS, and 12.3 MB).\nPrecision-recall curves were also plotted for all models. Our work demonstrates\nthat the proposed method can effectively optimize object detection models while\nbalancing accuracy, speed, and model size.\n","authors":["Dohyun Ham","Jaeyeop Jeong","June-Kyoo Park","Raehyeon Jeong","Seungmin Jeon","Hyeongjun Jeon","Yewon Lim"],"pdf_url":"https://arxiv.org/pdf/2303.02735v1.pdf","comment":"8 pages, 3 figures. A report of the project done as part of the\n  Yonsei-Roboin project for the 2nd semester, 2022"},{"id":"http://arxiv.org/abs/2303.02733v1","updated":"2023-03-05T17:57:33Z","published":"2023-03-05T17:57:33Z","title":"Reparameterization through Spatial Gradient Scaling","summary":"  Reparameterization aims to improve the generalization of deep neural networks\nby transforming convolutional layers into equivalent multi-branched structures\nduring training. However, there exists a gap in understanding how\nreparameterization may change and benefit the learning process of neural\nnetworks. In this paper, we present a novel spatial gradient scaling method to\nredistribute learning focus among weights in convolutional networks. We prove\nthat spatial gradient scaling achieves the same learning dynamics as a branched\nreparameterization yet without introducing structural changes into the network.\nWe further propose an analytical approach that dynamically learns scalings for\neach convolutional layer based on the spatial characteristics of its input\nfeature map gauged by mutual information. Experiments on CIFAR-10, CIFAR-100,\nand ImageNet show that without searching for reparameterized structures, our\nproposed scaling method outperforms the state-of-the-art reparameterization\nstrategies at a lower computational cost.\n","authors":["Alexander Detkov","Mohammad Salameh","Muhammad Fetrat Qharabagh","Jialin Zhang","Wei Lui","Shangling Jui","Di Niu"],"pdf_url":"https://arxiv.org/pdf/2303.02733v1.pdf","comment":"Published at ICLR 2023. Code available\n  $\\href{https://github.com/Ascend-Research/Reparameterization}{here}$"},{"id":"http://arxiv.org/abs/2303.02731v1","updated":"2023-03-05T17:55:15Z","published":"2023-03-05T17:55:15Z","title":"Vision based Virtual Guidance for Navigation","summary":"  This paper explores the impact of virtual guidance on mid-level\nrepresentation-based navigation, where an agent performs navigation tasks based\nsolely on visual observations. Instead of providing distance measures or\nnumerical directions to guide the agent, which may be difficult for it to\ninterpret visually, the paper investigates the potential of different forms of\nvirtual guidance schemes on navigation performance. Three schemes of virtual\nguidance signals are explored: virtual navigation path, virtual waypoints, and\na combination of both. The experiments were conducted using a virtual city\nbuilt with the Unity engine to train the agents while avoiding obstacles. The\nresults show that virtual guidance provides the agent with more meaningful\nnavigation information and achieves better performance in terms of path\ncompletion rates and navigation efficiency. In addition, a set of analyses were\nprovided to investigate the failure cases and the navigated trajectories, and a\npilot study was conducted for the real-world scenarios.\n","authors":["Hsuan-Kung Yang","Yu-Ying Chen","Tsung-Chih Chiang","Chia-Chuan Hsu","Chun-Chia Huang","Chun-Wei Huang","Jou-Min Liu","Ting-Ru Liu","Tsu-Ching Hsiao","Chun-Yi Lee"],"pdf_url":"https://arxiv.org/pdf/2303.02731v1.pdf","comment":"Yu-Ying Chen, Tsung-Chih Chiang, Chia-Chuan Hsu, Chun-Chia Huang,\n  Chun-Wei Huang, Jou-Min Liu, and Ting-Ru Liu contributed equally to this\n  work, names listed in alphabetical order; This work has been submitted to the\n  IEEE for possible publication"},{"id":"http://arxiv.org/abs/2303.02717v1","updated":"2023-03-05T17:12:50Z","published":"2023-03-05T17:12:50Z","title":"Learning to Localize in Unseen Scenes with Relative Pose Regressors","summary":"  Relative pose regressors (RPRs) localize a camera by estimating its relative\ntranslation and rotation to a pose-labelled reference. Unlike scene coordinate\nregression and absolute pose regression methods, which learn absolute scene\nparameters, RPRs can (theoretically) localize in unseen environments, since\nthey only learn the residual pose between camera pairs. In practice, however,\nthe performance of RPRs is significantly degraded in unseen scenes. In this\nwork, we propose to aggregate paired feature maps into latent codes, instead of\noperating on global image descriptors, in order to improve the generalization\nof RPRs. We implement aggregation with concatenation, projection, and attention\noperations (Transformer Encoders) and learn to regress the relative pose\nparameters from the resulting latent codes. We further make use of a recently\nproposed continuous representation of rotation matrices, which alleviates the\nlimitations of the commonly used quaternions. Compared to state-of-the-art\nRPRs, our model is shown to localize significantly better in unseen\nenvironments, across both indoor and outdoor benchmarks, while maintaining\ncompetitive performance in seen scenes. We validate our findings and\narchitecture design through multiple ablations. Our code and pretrained models\nis publicly available.\n","authors":["Ofer Idan","Yoli Shavit","Yosi Keller"],"pdf_url":"https://arxiv.org/pdf/2303.02717v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.02409v2","updated":"2023-03-05T17:08:58Z","published":"2022-12-05T16:47:19Z","title":"Decoding natural image stimuli from fMRI data with a surface-based\n  convolutional network","summary":"  Due to the low signal-to-noise ratio and limited resolution of functional MRI\ndata, and the high complexity of natural images, reconstructing a visual\nstimulus from human brain fMRI measurements is a challenging task. In this\nwork, we propose a novel approach for this task, which we call Cortex2Image, to\ndecode visual stimuli with high semantic fidelity and rich fine-grained detail.\nIn particular, we train a surface-based convolutional network model that maps\nfrom brain response to semantic image features first (Cortex2Semantic). We then\ncombine this model with a high-quality image generator (Instance-Conditioned\nGAN) to train another mapping from brain response to fine-grained image\nfeatures using a variational approach (Cortex2Detail). Image reconstructions\nobtained by our proposed method achieve state-of-the-art semantic fidelity,\nwhile yielding good fine-grained similarity with the ground-truth stimulus. Our\ncode is available at: https://github.com/zijin-gu/meshconv-decoding.git.\n","authors":["Zijin Gu","Keith Jamison","Amy Kuceyeski","Mert Sabuncu"],"pdf_url":"https://arxiv.org/pdf/2212.02409v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02715v1","updated":"2023-03-05T17:06:40Z","published":"2023-03-05T17:06:40Z","title":"Deep Learning in the Field of Biometric Template Protection: An Overview","summary":"  Today, deep learning represents the most popular and successful form of\nmachine learning. Deep learning has revolutionised the field of pattern\nrecognition, including biometric recognition. Biometric systems utilising deep\nlearning have been shown to achieve auspicious recognition accuracy, surpassing\nhuman performance. Apart from said breakthrough advances in terms of biometric\nperformance, the use of deep learning was reported to impact different\ncovariates of biometrics such as algorithmic fairness, vulnerability to\nattacks, or template protection. Technologies of biometric template protection\nare designed to enable a secure and privacy-preserving deployment of\nbiometrics. In the recent past, deep learning techniques have been frequently\napplied in biometric template protection systems for various purposes. This\nwork provides an overview of how advances in deep learning take influence on\nthe field of biometric template protection. The interrelation between improved\nbiometric performance rates and security in biometric template protection is\nelaborated. Further, the use of deep learning for obtaining feature\nrepresentations that are suitable for biometric template protection is\ndiscussed. Novel methods that apply deep learning to achieve various goals of\nbiometric template protection are surveyed along with deep learning-based\nattacks.\n","authors":["Christian Rathgeb","Jascha Kolberg","Andreas Uhl","Christoph Busch"],"pdf_url":"https://arxiv.org/pdf/2303.02715v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12228v3","updated":"2023-03-05T15:48:51Z","published":"2023-02-23T18:46:41Z","title":"Encoder-based Domain Tuning for Fast Personalization of Text-to-Image\n  Models","summary":"  Text-to-image personalization aims to teach a pre-trained diffusion model to\nreason about novel, user provided concepts, embedding them into new scenes\nguided by natural language prompts. However, current personalization approaches\nstruggle with lengthy training times, high storage requirements or loss of\nidentity. To overcome these limitations, we propose an encoder-based\ndomain-tuning approach. Our key insight is that by underfitting on a large set\nof concepts from a given domain, we can improve generalization and create a\nmodel that is more amenable to quickly adding novel concepts from the same\ndomain. Specifically, we employ two components: First, an encoder that takes as\nan input a single image of a target concept from a given domain, e.g. a\nspecific face, and learns to map it into a word-embedding representing the\nconcept. Second, a set of regularized weight-offsets for the text-to-image\nmodel that learn how to effectively ingest additional concepts. Together, these\ncomponents are used to guide the learning of unseen concepts, allowing us to\npersonalize a model using only a single image and as few as 5 training steps -\naccelerating personalization from dozens of minutes to seconds, while\npreserving quality.\n","authors":["Rinon Gal","Moab Arar","Yuval Atzmon","Amit H. Bermano","Gal Chechik","Daniel Cohen-Or"],"pdf_url":"https://arxiv.org/pdf/2302.12228v3.pdf","comment":"Project page at https://tuning-encoder.github.io/"},{"id":"http://arxiv.org/abs/2303.02700v1","updated":"2023-03-05T15:28:13Z","published":"2023-03-05T15:28:13Z","title":"HairStep: Transfer Synthetic to Real Using Strand and Depth Maps for\n  Single-View 3D Hair Modeling","summary":"  In this work, we tackle the challenging problem of learning-based single-view\n3D hair modeling. Due to the great difficulty of collecting paired real image\nand 3D hair data, using synthetic data to provide prior knowledge for real\ndomain becomes a leading solution. This unfortunately introduces the challenge\nof domain gap. Due to the inherent difficulty of realistic hair rendering,\nexisting methods typically use orientation maps instead of hair images as input\nto bridge the gap. We firmly think an intermediate representation is essential,\nbut we argue that orientation map using the dominant filtering-based methods is\nsensitive to uncertain noise and far from a competent representation. Thus, we\nfirst raise this issue up and propose a novel intermediate representation,\ntermed as HairStep, which consists of a strand map and a depth map. It is found\nthat HairStep not only provides sufficient information for accurate 3D hair\nmodeling, but also is feasible to be inferred from real images. Specifically,\nwe collect a dataset of 1,250 portrait images with two types of annotations. A\nlearning framework is further designed to transfer real images to the strand\nmap and depth map. It is noted that, an extra bonus of our new dataset is the\nfirst quantitative metric for 3D hair modeling. Our experiments show that\nHairStep narrows the domain gap between synthetic and real and achieves\nstate-of-the-art performance on single-view 3D hair reconstruction.\n","authors":["Yujian Zheng","Zirong Jin","Moran Li","Haibin Huang","Chongyang Ma","Shuguang Cui","Xiaoguang Han"],"pdf_url":"https://arxiv.org/pdf/2303.02700v1.pdf","comment":"CVPR 2023, project page:\n  https://paulyzheng.github.io/research/hairstep/"},{"id":"http://arxiv.org/abs/2303.02698v1","updated":"2023-03-05T15:27:24Z","published":"2023-03-05T15:27:24Z","title":"Robust affine feature matching via quadratic assignment on Grassmannians","summary":"  GraNNI (Grassmannians for Nearest Neighbours Identification) a new algorithm\nto solve the problem of affine registration is proposed. The algorithm is based\non the Grassmannian of $k$--dimensional planes in $\\mathbb{R}^n$ and minimizing\nthe Frobenius norm between the two elements of the Grassmannian. The Quadratic\nAssignment Problem (QAP) is used to find the matching. The results of the\nexperiments show that the algorithm is more robust to noise and point\ndiscrepancy in point clouds than previous approaches.\n","authors":["Alexander Kolpakov","Michael Werman"],"pdf_url":"https://arxiv.org/pdf/2303.02698v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02693v1","updated":"2023-03-05T15:11:53Z","published":"2023-03-05T15:11:53Z","title":"Maximizing Spatio-Temporal Entropy of Deep 3D CNNs for Efficient Video\n  Recognition","summary":"  3D convolution neural networks (CNNs) have been the prevailing option for\nvideo recognition. To capture the temporal information, 3D convolutions are\ncomputed along the sequences, leading to cubically growing and expensive\ncomputations. To reduce the computational cost, previous methods resort to\nmanually designed 3D/2D CNN structures with approximations or automatic search,\nwhich sacrifice the modeling ability or make training time-consuming. In this\nwork, we propose to automatically design efficient 3D CNN architectures via a\nnovel training-free neural architecture search approach tailored for 3D CNNs\nconsidering the model complexity. To measure the expressiveness of 3D CNNs\nefficiently, we formulate a 3D CNN as an information system and derive an\nanalytic entropy score, based on the Maximum Entropy Principle. Specifically,\nwe propose a spatio-temporal entropy score (STEntr-Score) with a refinement\nfactor to handle the discrepancy of visual information in spatial and temporal\ndimensions, through dynamically leveraging the correlation between the feature\nmap size and kernel size depth-wisely. Highly efficient and expressive 3D CNN\narchitectures, \\ie entropy-based 3D CNNs (E3D family), can then be efficiently\nsearched by maximizing the STEntr-Score under a given computational budget, via\nan evolutionary algorithm without training the network parameters. Extensive\nexperiments on Something-Something V1\\&V2 and Kinetics400 demonstrate that the\nE3D family achieves state-of-the-art performance with higher computational\nefficiency. Code is available at\nhttps://github.com/alibaba/lightweight-neural-architecture-search.\n","authors":["Junyan Wang","Zhenhong Sun","Yichen Qian","Dong Gong","Xiuyu Sun","Ming Lin","Maurice Pagnucco","Yang Song"],"pdf_url":"https://arxiv.org/pdf/2303.02693v1.pdf","comment":"This manuscript has been accepted at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.02688v1","updated":"2023-03-05T15:06:54Z","published":"2023-03-05T15:06:54Z","title":"Text2Face: A Multi-Modal 3D Face Model","summary":"  We present the first 3D morphable modelling approach, whereby 3D face shape\ncan be directly and completely defined using a textual prompt. Building on work\nin multi-modal learning, we extend the FLAME head model to a common\nimage-and-text latent space. This allows for direct 3D Morphable Model (3DMM)\nparameter generation and therefore shape manipulation from textual\ndescriptions. Our method, Text2Face, has many applications; for example:\ngenerating police photofits where the input is already in natural language. It\nfurther enables multi-modal 3DMM image fitting to sketches and sculptures, as\nwell as images.\n","authors":["Will Rowan","Patrik Huber","Nick Pears","Andrew Keeling"],"pdf_url":"https://arxiv.org/pdf/2303.02688v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02672v1","updated":"2023-03-05T13:48:20Z","published":"2023-03-05T13:48:20Z","title":"Continuous-Time Gaussian Process Motion-Compensation for Event-vision\n  Pattern Tracking with Distance Fields","summary":"  This work addresses the issue of motion compensation and pattern tracking in\nevent camera data. An event camera generates asynchronous streams of events\ntriggered independently by each of the pixels upon changes in the observed\nintensity. Providing great advantages in low-light and rapid-motion scenarios,\nsuch unconventional data present significant research challenges as traditional\nvision algorithms are not directly applicable to this sensing modality. The\nproposed method decomposes the tracking problem into a local SE(2)\nmotion-compensation step followed by a homography registration of small\nmotion-compensated event batches. The first component relies on Gaussian\nProcess (GP) theory to model the continuous occupancy field of the events in\nthe image plane and embed the camera trajectory in the covariance kernel\nfunction. In doing so, estimating the trajectory is done similarly to GP\nhyperparameter learning by maximising the log marginal likelihood of the data.\nThe continuous occupancy fields are turned into distance fields and used as\ntemplates for homography-based registration. By benchmarking the proposed\nmethod against other state-of-the-art techniques, we show that our open-source\nimplementation performs high-accuracy motion compensation and produces\nhigh-quality tracks in real-world scenarios.\n","authors":["Cedric Le Gentil","Ignacio Alzugaray","Teresa Vidal-Calleja"],"pdf_url":"https://arxiv.org/pdf/2303.02672v1.pdf","comment":"Accepted for presentation at the 2023 IEEE International Conference\n  on Robotics and Automation"},{"id":"http://arxiv.org/abs/2303.02666v1","updated":"2023-03-05T13:15:28Z","published":"2023-03-05T13:15:28Z","title":"Learned Lossless Compression for JPEG via Frequency-Domain Prediction","summary":"  JPEG images can be further compressed to enhance the storage and transmission\nof large-scale image datasets. Existing learned lossless compressors for RGB\nimages cannot be well transferred to JPEG images due to the distinguishing\ndistribution of DCT coefficients and raw pixels. In this paper, we propose a\nnovel framework for learned lossless compression of JPEG images that achieves\nend-to-end optimized prediction of the distribution of decoded DCT\ncoefficients. To enable learning in the frequency domain, DCT coefficients are\npartitioned into groups to utilize implicit local redundancy. An\nautoencoder-like architecture is designed based on the weight-shared blocks to\nrealize entropy modeling of grouped DCT coefficients and independently compress\nthe priors. We attempt to realize learned lossless compression of JPEG images\nin the frequency domain. Experimental results demonstrate that the proposed\nframework achieves superior or comparable performance in comparison to most\nrecent lossless compressors with handcrafted context modeling for JPEG images.\n","authors":["Jixiang Luo","Shaohui Li","Wenrui Dai","Chenglin Li","Junni Zou","Hongkai Xiong"],"pdf_url":"https://arxiv.org/pdf/2303.02666v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02660v1","updated":"2023-03-05T12:35:58Z","published":"2023-03-05T12:35:58Z","title":"SynthASpoof: Developing Face Presentation Attack Detection Based on\n  Privacy-friendly Synthetic Data","summary":"  Recently, significant progress has been made in face presentation attack\ndetection (PAD), which aims to secure face recognition systems against\npresentation attacks, owing to the availability of several face PAD datasets.\nHowever, all available datasets are based on privacy and legally-sensitive\nauthentic biometric data with a limited number of subjects. To target these\nlegal and technical challenges, this work presents the first synthetic-based\nface PAD dataset, named SynthASpoof, as a large-scale PAD development dataset.\nThe bona fide samples in SynthASpoof are synthetically generated and the attack\nsamples are collected by presenting such synthetic data to capture systems in a\nreal attack scenario. The experimental results demonstrate the feasibility of\nusing SynthASpoof for the development of face PAD. Moreover, we boost the\nperformance of such a solution by incorporating the domain generalization tool\nMixStyle into the PAD solutions. Additionally, we showed the viability of using\nsynthetic data as a supplement to enrich the diversity of limited authentic\ntraining data and consistently enhance PAD performances. The SynthASpoof\ndataset, containing 25,000 bona fide and 78,800 attack samples, the\nimplementation, and the pre-trained weights are made publicly available.\n","authors":["Meiling Fang","Marco Huber","Naser Damer"],"pdf_url":"https://arxiv.org/pdf/2303.02660v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.10368v3","updated":"2023-03-05T12:26:16Z","published":"2022-09-21T14:03:08Z","title":"Improving the Safety of 3D Object Detectors in Autonomous Driving using\n  IoGT and Distance Measures","summary":"  State-of-the-art object detectors are commonly evaluated based on accuracy\nmetrics such as mean Average Precision (mAP). In this paper, inspired by the\nfact that mAP is not a direct safety indicator, we propose a straightforward\nsafety metric, especially for 3D object detectors in Autonomous Driving\ncontexts, by combining the Intersection-over-Ground-Truth (IoGT) measure and a\ndistance ratio. Subsequently, we formulate a safety-aware loss function by\namending IoGT to commonly used accuracy-oriented loss functions. Our\nexperiments using models from the MMDetection3D library, the nuScenes dataset,\nand an in-house simulation dataset demonstrate that the object detector trained\nwith our loss function significantly reduces unsafe predictions while staying\nperformant on accuracy and maintaining good stability in the learning process.\n","authors":["Hsuan-Cheng Liao","Chih-Hong Cheng","Hasan Esen","Alois Knoll"],"pdf_url":"https://arxiv.org/pdf/2209.10368v3.pdf","comment":"8 pages (IEEE double column format), 8 figures, revised with clearer\n  presentation and resubmitted to IROS 2023"},{"id":"http://arxiv.org/abs/2202.13133v2","updated":"2023-03-05T12:16:33Z","published":"2022-02-26T13:02:32Z","title":"Automation of reversible steganographic coding with nonlinear discrete\n  optimisation","summary":"  Authentication mechanisms are at the forefront of defending the world from\nvarious types of cybercrime. Steganography can serve as an authentication\nsolution through the use of a digital signature embedded in a carrier object to\nensure the integrity of the object and simultaneously lighten the burden of\nmetadata management. Nevertheless, despite being generally imperceptible to\nhuman sensory systems, any degree of steganographic distortion might be\ninadmissible in fidelity-sensitive situations such as forensic science, legal\nproceedings, medical diagnosis and military reconnaissance. This has led to the\ndevelopment of reversible steganography. A fundamental element of reversible\nsteganography is predictive analytics, for which powerful neural network models\nhave been effectively deployed. Another core element is reversible\nsteganographic coding. Contemporary coding is based primarily on heuristics,\nwhich offers a shortcut towards sufficient, but not necessarily optimal,\ncapacity--distortion performance. While attempts have been made to realise\nautomatic coding with neural networks, perfect reversibility is unattainable\nvia such learning machinery. Instead of relying on heuristics and machine\nlearning, we aim to derive optimal coding by means of mathematical\noptimisation. In this study, we formulate reversible steganographic coding as a\nnonlinear discrete optimisation problem with a logarithmic capacity constraint\nand a quadratic distortion objective. Linearisation techniques are developed to\nenable iterative mixed-integer linear programming. Experimental results\nvalidate the near-optimality of the proposed optimisation algorithm when\nbenchmarked against a brute-force method.\n","authors":["Ching-Chun Chang"],"pdf_url":"https://arxiv.org/pdf/2202.13133v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.08712v2","updated":"2023-03-05T12:12:53Z","published":"2022-11-16T07:02:12Z","title":"Improving Feature-based Visual Localization by Geometry-Aided Matching","summary":"  Feature matching is crucial in visual localization, where 2D-3D\ncorrespondence plays a major role in determining the accuracy of camera pose. A\nsufficient number of well-distributed 2D-3D correspondences is essential for\naccurate pose estimation due to noise. However, existing 2D-3D feature matching\nmethods rely on finding nearest neighbors in the feature space and removing\noutliers using hand-crafted heuristics, which may lead to potential matches\nbeing missed or the correct matches being filtered out. In this work, we\npropose a novel method called Geometry-Aided Matching (GAM), which incorporates\nboth appearance information and geometric context to address this issue and to\nimprove 2D-3D feature matching. GAM can greatly boost the recall of 2D-3D\nmatches while maintaining high precision. We apply GAM to a new hierarchical\nvisual localization pipeline and show that GAM can effectively improve the\nrobustness and accuracy of localization. Extensive experiments show that GAM\ncan find more real matches than hand-crafted heuristics and learning baselines.\nOur proposed localization method achieves state-of-the-art results on multiple\nvisual localization datasets. Experiments on Cambridge Landmarks dataset show\nthat our method outperforms the existing state-of-the-art methods and is six\ntimes faster than the top-performed method. The source code is available at\nhttps://github.com/openxrlab/xrlocalization.\n","authors":["Hailin Yu","Youji Feng","Weicai Ye","Mingxuan Jiang","Hujun Bao","Guofeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2211.08712v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02655v1","updated":"2023-03-05T12:09:37Z","published":"2023-03-05T12:09:37Z","title":"On Modifying a Neural Network's Perception","summary":"  Artificial neural networks have proven to be extremely useful models that\nhave allowed for multiple recent breakthroughs in the field of Artificial\nIntelligence and many others. However, they are typically regarded as black\nboxes, given how difficult it is for humans to interpret how these models reach\ntheir results. In this work, we propose a method which allows one to modify\nwhat an artificial neural network is perceiving regarding specific\nhuman-defined concepts, enabling the generation of hypothetical scenarios that\ncould help understand and even debug the neural network model. Through\nempirical evaluation, in a synthetic dataset and in the ImageNet dataset, we\ntest the proposed method on different models, assessing whether the performed\nmanipulations are well interpreted by the models, and analyzing how they react\nto them.\n","authors":["Manuel de Sousa Ribeiro","João Leite"],"pdf_url":"https://arxiv.org/pdf/2303.02655v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02648v1","updated":"2023-03-05T11:45:53Z","published":"2023-03-05T11:45:53Z","title":"Comparative study of Transformer and LSTM Network with attention\n  mechanism on Image Captioning","summary":"  In a globalized world at the present epoch of generative intelligence, most\nof the manual labour tasks are automated with increased efficiency. This can\nsupport businesses to save time and money. A crucial component of generative\nintelligence is the integration of vision and language. Consequently, image\ncaptioning become an intriguing area of research. There have been multiple\nattempts by the researchers to solve this problem with different deep learning\narchitectures, although the accuracy has increased, but the results are still\nnot up to standard. This study buckles down to the comparison of Transformer\nand LSTM with attention block model on MS-COCO dataset, which is a standard\ndataset for image captioning. For both the models we have used pretrained\nInception-V3 CNN encoder for feature extraction of the images. The Bilingual\nEvaluation Understudy score (BLEU) is used to checked the accuracy of caption\ngenerated by both models. Along with the transformer and LSTM with attention\nblock models,CLIP-diffusion model, M2-Transformer model and the X-Linear\nAttention model have been discussed with state of the art accuracy.\n","authors":["Pranav Dandwate","Chaitanya Shahane","Vandana Jagtap","Shridevi C. Karande"],"pdf_url":"https://arxiv.org/pdf/2303.02648v1.pdf","comment":"13 pages, 7 figures, 2 tables"},{"id":"http://arxiv.org/abs/2303.02641v1","updated":"2023-03-05T11:06:20Z","published":"2023-03-05T11:06:20Z","title":"CueCAn: Cue Driven Contextual Attention For Identifying Missing Traffic\n  Signs on Unconstrained Roads","summary":"  Unconstrained Asian roads often involve poor infrastructure, affecting\noverall road safety. Missing traffic signs are a regular part of such roads.\nMissing or non-existing object detection has been studied for locating missing\ncurbs and estimating reasonable regions for pedestrians on road scene images.\nSuch methods involve analyzing task-specific single object cues. In this paper,\nwe present the first and most challenging video dataset for missing objects,\nwith multiple types of traffic signs for which the cues are visible without the\nsigns in the scenes. We refer to it as the Missing Traffic Signs Video Dataset\n(MTSVD). MTSVD is challenging compared to the previous works in two aspects i)\nThe traffic signs are generally not present in the vicinity of their cues, ii)\nThe traffic signs cues are diverse and unique. Also, MTSVD is the first\npublicly available missing object dataset. To train the models for identifying\nmissing signs, we complement our dataset with 10K traffic sign tracks, with 40\npercent of the traffic signs having cues visible in the scenes. For identifying\nmissing signs, we propose the Cue-driven Contextual Attention units (CueCAn),\nwhich we incorporate in our model encoder. We first train the encoder to\nclassify the presence of traffic sign cues and then train the entire\nsegmentation model end-to-end to localize missing traffic signs. Quantitative\nand qualitative analysis shows that CueCAn significantly improves the\nperformance of base models.\n","authors":["Varun Gupta","Anbumani Subramanian","C. V. Jawahar","Rohit Saluja"],"pdf_url":"https://arxiv.org/pdf/2303.02641v1.pdf","comment":"International Conference on Robotics and Automation (ICRA'23)"},{"id":"http://arxiv.org/abs/2205.12551v2","updated":"2023-03-05T11:04:12Z","published":"2022-05-25T07:56:18Z","title":"Masked Jigsaw Puzzle: A Versatile Position Embedding for Vision\n  Transformers","summary":"  Position Embeddings (PEs), an arguably indispensable component in Vision\nTransformers (ViTs), have been shown to improve the performance of ViTs on many\nvision tasks. However, PEs have a potentially high risk of privacy leakage\nsince the spatial information of the input patches is exposed. This caveat\nnaturally raises a series of interesting questions about the impact of PEs on\nthe accuracy, privacy, prediction consistency, etc. To tackle these issues, we\npropose a Masked Jigsaw Puzzle (MJP) position embedding method. In particular,\nMJP first shuffles the selected patches via our block-wise random jigsaw puzzle\nshuffle algorithm, and their corresponding PEs are occluded. Meanwhile, for the\nnon-occluded patches, the PEs remain the original ones but their spatial\nrelation is strengthened via our dense absolute localization regressor. The\nexperimental results reveal that 1) PEs explicitly encode the 2D spatial\nrelationship and lead to severe privacy leakage problems under gradient\ninversion attack; 2) Training ViTs with the naively shuffled patches can\nalleviate the problem, but it harms the accuracy; 3) Under a certain shuffle\nratio, the proposed MJP not only boosts the performance and robustness on\nlarge-scale datasets (i.e., ImageNet-1K and ImageNet-C, -A/O) but also improves\nthe privacy preservation ability under typical gradient attacks by a large\nmargin. The source code and trained models are available\nat~\\url{https://github.com/yhlleo/MJP}.\n","authors":["Bin Ren","Yahui Liu","Yue Song","Wei Bi","Rita Cucchiara","Nicu Sebe","Wei Wang"],"pdf_url":"https://arxiv.org/pdf/2205.12551v2.pdf","comment":"Accepted to CVPR2023"},{"id":"http://arxiv.org/abs/2303.02635v1","updated":"2023-03-05T10:32:26Z","published":"2023-03-05T10:32:26Z","title":"VTQA: Visual Text Question Answering via Entity Alignment and\n  Cross-Media Reasoning","summary":"  The ideal form of Visual Question Answering requires understanding, grounding\nand reasoning in the joint space of vision and language and serves as a proxy\nfor the AI task of scene understanding. However, most existing VQA benchmarks\nare limited to just picking the answer from a pre-defined set of options and\nlack attention to text. We present a new challenge with a dataset that contains\n23,781 questions based on 10124 image-text pairs. Specifically, the task\nrequires the model to align multimedia representations of the same entity to\nimplement multi-hop reasoning between image and text and finally use natural\nlanguage to answer the question. The aim of this challenge is to develop and\nbenchmark models that are capable of multimedia entity alignment, multi-step\nreasoning and open-ended answer generation.\n","authors":["Kang Chen","Xiangqian Wu"],"pdf_url":"https://arxiv.org/pdf/2303.02635v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02632v1","updated":"2023-03-05T10:17:10Z","published":"2023-03-05T10:17:10Z","title":"Deep-Learning-based Counting Methods, Datasets, and Applications in\n  Agriculture -- A Review","summary":"  The number of objects is considered an important factor in a variety of tasks\nin the agricultural domain. Automated counting can improve farmers decisions\nregarding yield estimation, stress detection, disease prevention, and more. In\nrecent years, deep learning has been increasingly applied to many\nagriculture-related applications, complementing conventional computer-vision\nalgorithms for counting agricultural objects. This article reviews progress in\nthe past decade and the state of the art for counting methods in agriculture,\nfocusing on deep-learning methods. It presents an overview of counting\nalgorithms, metrics, platforms, and sensors, a list of all publicly available\ndatasets, and an in-depth discussion of various deep-learning methods used for\ncounting. Finally, it discusses open challenges in object counting using deep\nlearning and gives a glimpse into new directions and future perspectives for\ncounting research. The review reveals a major leap forward in object counting\nin agriculture in the past decade, led by the penetration of deep learning\nmethods into counting platforms.\n","authors":["Guy Farjon","Liu Huijun","Yael Edan"],"pdf_url":"https://arxiv.org/pdf/2303.02632v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.02136v2","updated":"2023-03-05T10:09:11Z","published":"2023-02-04T09:14:18Z","title":"Efficient End-to-End Video Question Answering with Pyramidal Multimodal\n  Transformer","summary":"  This paper presents a new method for end-to-end Video Question Answering\n(VideoQA), aside from the current popularity of using large-scale pre-training\nwith huge feature extractors. We achieve this with a pyramidal multimodal\ntransformer (PMT) model, which simply incorporates a learnable word embedding\nlayer, a few convolutional and transformer layers. We use the anisotropic\npyramid to fulfill video-language interactions across different spatio-temporal\nscales. In addition to the canonical pyramid, which includes both bottom-up and\ntop-down pathways with lateral connections, novel strategies are proposed to\ndecompose the visual feature stream into spatial and temporal sub-streams at\ndifferent scales and implement their interactions with the linguistic semantics\nwhile preserving the integrity of local and global semantics. We demonstrate\nbetter or on-par performances with high computational efficiency against\nstate-of-the-art methods on five VideoQA benchmarks. Our ablation study shows\nthe scalability of our model that achieves competitive results for\ntext-to-video retrieval by leveraging feature extractors with reusable\npre-trained weights, and also the effectiveness of the pyramid.\n","authors":["Min Peng","Chongyang Wang","Yu Shi","Xiang-Dong Zhou"],"pdf_url":"https://arxiv.org/pdf/2302.02136v2.pdf","comment":"Accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2206.12455v2","updated":"2023-03-05T10:08:01Z","published":"2022-06-24T18:27:30Z","title":"Ev-NeRF: Event Based Neural Radiance Field","summary":"  We present Ev-NeRF, a Neural Radiance Field derived from event data. While\nevent cameras can measure subtle brightness changes in high frame rates, the\nmeasurements in low lighting or extreme motion suffer from significant domain\ndiscrepancy with complex noise. As a result, the performance of event-based\nvision tasks does not transfer to challenging environments, where the event\ncameras are expected to thrive over normal cameras. We find that the multi-view\nconsistency of NeRF provides a powerful self-supervision signal for eliminating\nthe spurious measurements and extracting the consistent underlying structure\ndespite highly noisy input. Instead of posed images of the original NeRF, the\ninput to Ev-NeRF is the event measurements accompanied by the movements of the\nsensors. Using the loss function that reflects the measurement model of the\nsensor, Ev-NeRF creates an integrated neural volume that summarizes the\nunstructured and sparse data points captured for about 2-4 seconds. The\ngenerated neural volume can also produce intensity images from novel views with\nreasonable depth estimates, which can serve as a high-quality input to various\nvision-based tasks. Our results show that Ev-NeRF achieves competitive\nperformance for intensity image reconstruction under extreme noise conditions\nand high-dynamic-range imaging.\n","authors":["Inwoo Hwang","Junho Kim","Young Min Kim"],"pdf_url":"https://arxiv.org/pdf/2206.12455v2.pdf","comment":"Accepted to WACV 2023"},{"id":"http://arxiv.org/abs/2203.08382v4","updated":"2023-03-05T09:35:06Z","published":"2022-03-16T04:10:45Z","title":"Dual Diffusion Implicit Bridges for Image-to-Image Translation","summary":"  Common image-to-image translation methods rely on joint training over data\nfrom both source and target domains. The training process requires concurrent\naccess to both datasets, which hinders data separation and privacy protection;\nand existing models cannot be easily adapted for translation of new domain\npairs. We present Dual Diffusion Implicit Bridges (DDIBs), an image translation\nmethod based on diffusion models, that circumvents training on domain pairs.\nImage translation with DDIBs relies on two diffusion models trained\nindependently on each domain, and is a two-step process: DDIBs first obtain\nlatent encodings for source images with the source diffusion model, and then\ndecode such encodings using the target model to construct target images. Both\nsteps are defined via ordinary differential equations (ODEs), thus the process\nis cycle consistent only up to discretization errors of the ODE solvers.\nTheoretically, we interpret DDIBs as concatenation of source to latent, and\nlatent to target Schrodinger Bridges, a form of entropy-regularized optimal\ntransport, to explain the efficacy of the method. Experimentally, we apply\nDDIBs on synthetic and high-resolution image datasets, to demonstrate their\nutility in a wide variety of translation tasks and their inherent optimal\ntransport properties.\n","authors":["Xuan Su","Jiaming Song","Chenlin Meng","Stefano Ermon"],"pdf_url":"https://arxiv.org/pdf/2203.08382v4.pdf","comment":"18 pages, 12 figures, in the Eleventh International Conference on\n  Learning Representations (ICLR 2023)"},{"id":"http://arxiv.org/abs/2208.09686v2","updated":"2023-03-05T09:22:53Z","published":"2022-08-20T14:12:06Z","title":"YOLOV: Making Still Image Object Detectors Great at Video Object\n  Detection","summary":"  Video object detection (VID) is challenging because of the high variation of\nobject appearance as well as the diverse deterioration in some frames. On the\npositive side, the detection in a certain frame of a video, compared with that\nin a still image, can draw support from other frames. Hence, how to aggregate\nfeatures across different frames is pivotal to VID problem. Most of existing\naggregation algorithms are customized for two-stage detectors. However, these\ndetectors are usually computationally expensive due to their two-stage nature.\nThis work proposes a simple yet effective strategy to address the above\nconcerns, which costs marginal overheads with significant gains in accuracy.\nConcretely, different from traditional two-stage pipeline, we select important\nregions after the one-stage detection to avoid processing massive low-quality\ncandidates. Besides, we evaluate the relationship between a target frame and\nreference frames to guide the aggregation. We conduct extensive experiments and\nablation studies to verify the efficacy of our design, and reveal its\nsuperiority over other state-of-the-art VID approaches in both effectiveness\nand efficiency. Our YOLOX-based model can achieve promising performance\n(\\emph{e.g.}, 87.5\\% AP50 at over 30 FPS on the ImageNet VID dataset on a\nsingle 2080Ti GPU), making it attractive for large-scale or real-time\napplications. The implementation is simple, we have made the demo codes and\nmodels available at \\url{https://github.com/YuHengsss/YOLOV}.\n","authors":["Yuheng Shi","Naiyan Wang","Xiaojie Guo"],"pdf_url":"https://arxiv.org/pdf/2208.09686v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.08368v5","updated":"2023-03-05T09:08:51Z","published":"2022-03-16T03:23:50Z","title":"Mixed-Precision Neural Network Quantization via Learned Layer-wise\n  Importance","summary":"  The exponentially large discrete search space in mixed-precision quantization\n(MPQ) makes it hard to determine the optimal bit-width for each layer. Previous\nworks usually resort to iterative search methods on the training set, which\nconsume hundreds or even thousands of GPU-hours. In this study, we reveal that\nsome unique learnable parameters in quantization, namely the scale factors in\nthe quantizer, can serve as importance indicators of a layer, reflecting the\ncontribution of that layer to the final accuracy at certain bit-widths. These\nimportance indicators naturally perceive the numerical transformation during\nquantization-aware training, which can precisely provide quantization\nsensitivity metrics of layers. However, a deep network always contains hundreds\nof such indicators, and training them one by one would lead to an excessive\ntime cost. To overcome this issue, we propose a joint training scheme that can\nobtain all indicators at once. It considerably speeds up the indicators\ntraining process by parallelizing the original sequential training processes.\nWith these learned importance indicators, we formulate the MPQ search problem\nas a one-time integer linear programming (ILP) problem. That avoids the\niterative search and significantly reduces search time without limiting the\nbit-width search space. For example, MPQ search on ResNet18 with our indicators\ntakes only 0.06 s, which improves time efficiency exponentially compared to\niterative search methods. Also, extensive experiments show our approach can\nachieve SOTA accuracy on ImageNet for far-ranging models with various\nconstraints (e.g., BitOps, compress rate). Code is available on\nhttps://github.com/1hunters/LIMPQ.\n","authors":["Chen Tang","Kai Ouyang","Zhi Wang","Yifei Zhu","Yaowei Wang","Wen Ji","Wenwu Zhu"],"pdf_url":"https://arxiv.org/pdf/2203.08368v5.pdf","comment":"Published on ECCV 2022, code is available on\n  https://github.com/1hunters/LIMPQ"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2209.07590v2","updated":"2023-03-05T23:30:15Z","published":"2022-09-15T19:57:16Z","title":"Prediction of Gender from Longitudinal MRI data via Deep Learning on\n  Adolescent Data Reveals Unique Patterns Associated with Brain Structure and\n  Change over a Two-year Period","summary":"  Deep learning algorithms for predicting neuroimaging data have shown\nconsiderable promise in various applications. Prior work has demonstrated that\ndeep learning models that take advantage of the data's 3D structure can\noutperform standard machine learning on several learning tasks. However, most\nprior research in this area has focused on neuroimaging data from adults.\nWithin the Adolescent Brain and Cognitive Development (ABCD) dataset, a large\nlongitudinal development study, we examine structural MRI data to predict\ngender and identify gender-related changes in brain structure. Results\ndemonstrate that gender prediction accuracy is exceptionally high (>97%) with\ntraining epochs >200 and that this accuracy increases with age. Brain regions\nidentified as the most discriminative in the task under study include\npredominantly frontal areas and the temporal lobe. When evaluating gender\npredictive changes specific to a two-year increase in age, a broader set of\nvisual, cingulate, and insular regions are revealed. Our findings show a robust\ngender-related structural brain change pattern, even over a small age range.\nThis suggests that it might be possible to study how the brain changes during\nadolescence by looking at how these changes are related to different behavioral\nand environmental factors.\n","authors":["Yuda Bi","Anees Abrol","Zening Fu","Jiayu Chen","Jingyu Liu","Vince Calhoun"],"pdf_url":"https://arxiv.org/pdf/2209.07590v2.pdf","comment":"I submitted the wrong paper"},{"id":"http://arxiv.org/abs/2302.09908v2","updated":"2023-03-05T23:10:24Z","published":"2023-02-20T11:09:37Z","title":"A Sidecar Separator Can Convert a Single-Talker Speech Recognition\n  System to a Multi-Talker One","summary":"  Although automatic speech recognition (ASR) can perform well in common\nnon-overlapping environments, sustaining performance in multi-talker\noverlapping speech recognition remains challenging. Recent research revealed\nthat ASR model's encoder captures different levels of information with\ndifferent layers -- the lower layers tend to have more acoustic information,\nand the upper layers more linguistic. This inspires us to develop a Sidecar\nseparator to empower a well-trained ASR model for multi-talker scenarios by\nseparating the mixed speech embedding between two suitable layers. We\nexperimented with a wav2vec 2.0-based ASR model with a Sidecar mounted. By\nfreezing the parameters of the original model and training only the Sidecar\n(8.7 M, 8.4% of all parameters), the proposed approach outperforms the previous\nstate-of-the-art by a large margin for the 2-speaker mixed LibriMix dataset,\nreaching a word error rate (WER) of 10.36%; and obtains comparable results\n(7.56%) for LibriSpeechMix dataset when limited training.\n","authors":["Lingwei Meng","Jiawen Kang","Mingyu Cui","Yuejiao Wang","Xixin Wu","Helen Meng"],"pdf_url":"https://arxiv.org/pdf/2302.09908v2.pdf","comment":"Accepted by IEEE International Conference on Acoustics, Speech, and\n  Signal Processing (ICASSP), 2023"},{"id":"http://arxiv.org/abs/2303.02794v1","updated":"2023-03-05T23:01:02Z","published":"2023-03-05T23:01:02Z","title":"CoRTX: Contrastive Framework for Real-time Explanation","summary":"  Recent advancements in explainable machine learning provide effective and\nfaithful solutions for interpreting model behaviors. However, many explanation\nmethods encounter efficiency issues, which largely limit their deployments in\npractical scenarios. Real-time explainer (RTX) frameworks have thus been\nproposed to accelerate the model explanation process by learning a\none-feed-forward explainer. Existing RTX frameworks typically build the\nexplainer under the supervised learning paradigm, which requires large amounts\nof explanation labels as the ground truth. Considering that accurate\nexplanation labels are usually hard to obtain due to constrained computational\nresources and limited human efforts, effective explainer training is still\nchallenging in practice. In this work, we propose a COntrastive Real-Time\neXplanation (CoRTX) framework to learn the explanation-oriented representation\nand relieve the intensive dependence of explainer training on explanation\nlabels. Specifically, we design a synthetic strategy to select positive and\nnegative instances for the learning of explanation. Theoretical analysis show\nthat our selection strategy can benefit the contrastive learning process on\nexplanation tasks. Experimental results on three real-world datasets further\ndemonstrate the efficiency and efficacy of our proposed CoRTX framework.\n","authors":["Yu-Neng Chuang","Guanchu Wang","Fan Yang","Quan Zhou","Pushkar Tripathi","Xuanting Cai","Xia Hu"],"pdf_url":"https://arxiv.org/pdf/2303.02794v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.14510v2","updated":"2023-03-05T22:58:53Z","published":"2022-12-30T01:41:48Z","title":"A Machine Learning Case Study for AI-empowered echocardiography of\n  Intensive Care Unit Patients in low- and middle-income countries","summary":"  We present a Machine Learning (ML) study case to illustrate the challenges of\nclinical translation for a real-time AI-empowered echocardiography system with\ndata of ICU patients in LMICs. Such ML case study includes data preparation,\ncuration and labelling from 2D Ultrasound videos of 31 ICU patients in LMICs\nand model selection, validation and deployment of three thinner neural networks\nto classify apical four-chamber view. Results of the ML heuristics showed the\npromising implementation, validation and application of thinner networks to\nclassify 4CV with limited datasets. We conclude this work mentioning the need\nfor (a) datasets to improve diversity of demographics, diseases, and (b) the\nneed of further investigations of thinner models to be run and implemented in\nlow-cost hardware to be clinically translated in the ICU in LMICs. The code and\nother resources to reproduce this work are available at\nhttps://github.com/vital-ultrasound/ai-assisted-echocardiography-for-low-resource-countries.\n","authors":["Miguel Xochicale","Louise Thwaites","Sophie Yacoub","Luigi Pisani","Phung-Nhat Tran-Huy","Hamideh Kerdegari","Andrew King","Alberto Gomez"],"pdf_url":"https://arxiv.org/pdf/2212.14510v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.11108v3","updated":"2023-03-05T22:30:18Z","published":"2023-01-25T16:39:00Z","title":"On the Mathematics of Diffusion Models","summary":"  This paper gives direct derivations of the differential equations and\nlikelihood formulas of diffusion models assuming only knowledge of Gaussian\ndistributions. A VAE analysis derives both forward and backward stochastic\ndifferential equations (SDEs) as well as non-variational integral expressions\nfor likelihood formulas. A score-matching analysis derives the reverse\ndiffusion ordinary differential equation (ODE) and a family of\nreverse-diffusion SDEs parameterized by noise level. The paper presents the\nmathematics directly with attributions saved for a final section.\n","authors":["David McAllester"],"pdf_url":"https://arxiv.org/pdf/2301.11108v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14730v2","updated":"2023-03-05T22:11:56Z","published":"2022-11-27T05:15:42Z","title":"A Time Series is Worth 64 Words: Long-term Forecasting with Transformers","summary":"  We propose an efficient design of Transformer-based models for multivariate\ntime series forecasting and self-supervised representation learning. It is\nbased on two key components: (i) segmentation of time series into\nsubseries-level patches which are served as input tokens to Transformer; (ii)\nchannel-independence where each channel contains a single univariate time\nseries that shares the same embedding and Transformer weights across all the\nseries. Patching design naturally has three-fold benefit: local semantic\ninformation is retained in the embedding; computation and memory usage of the\nattention maps are quadratically reduced given the same look-back window; and\nthe model can attend longer history. Our channel-independent patch time series\nTransformer (PatchTST) can improve the long-term forecasting accuracy\nsignificantly when compared with that of SOTA Transformer-based models. We also\napply our model to self-supervised pre-training tasks and attain excellent\nfine-tuning performance, which outperforms supervised training on large\ndatasets. Transferring of masked pre-trained representation on one dataset to\nothers also produces SOTA forecasting accuracy. Code is available at:\nhttps://github.com/yuqinie98/PatchTST.\n","authors":["Yuqi Nie","Nam H. Nguyen","Phanwadee Sinthong","Jayant Kalagnanam"],"pdf_url":"https://arxiv.org/pdf/2211.14730v2.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2303.02783v1","updated":"2023-03-05T21:47:08Z","published":"2023-03-05T21:47:08Z","title":"Improved Sample Complexity Bounds for Distributionally Robust\n  Reinforcement Learning","summary":"  We consider the problem of learning a control policy that is robust against\nthe parameter mismatches between the training environment and testing\nenvironment. We formulate this as a distributionally robust reinforcement\nlearning (DR-RL) problem where the objective is to learn the policy which\nmaximizes the value function against the worst possible stochastic model of the\nenvironment in an uncertainty set. We focus on the tabular episodic learning\nsetting where the algorithm has access to a generative model of the nominal\n(training) environment around which the uncertainty set is defined. We propose\nthe Robust Phased Value Learning (RPVL) algorithm to solve this problem for the\nuncertainty sets specified by four different divergences: total variation,\nchi-square, Kullback-Leibler, and Wasserstein. We show that our algorithm\nachieves $\\tilde{\\mathcal{O}}(|\\mathcal{S}||\\mathcal{A}| H^{5})$ sample\ncomplexity, which is uniformly better than the existing results by a factor of\n$|\\mathcal{S}|$, where $|\\mathcal{S}|$ is number of states, $|\\mathcal{A}|$ is\nthe number of actions, and $H$ is the horizon length. We also provide the\nfirst-ever sample complexity result for the Wasserstein uncertainty set.\nFinally, we demonstrate the performance of our algorithm using simulation\nexperiments.\n","authors":["Zaiyan Xu","Kishan Panaganti","Dileep Kalathil"],"pdf_url":"https://arxiv.org/pdf/2303.02783v1.pdf","comment":"Appeared in The 26th (2023) International Conference on Artificial\n  Intelligence and Statistics (AISTATS)"}],"Multimedia":[{"id":"http://arxiv.org/abs/2303.02673v1","updated":"2023-03-05T13:48:47Z","published":"2023-03-05T13:48:47Z","title":"Time-frequency Network for Robust Speaker Recognition","summary":"  The wide deployment of speech-based biometric systems usually demands\nhigh-performance speaker recognition algorithms. However, most of the prior\nworks for speaker recognition either process the speech in the frequency domain\nor time domain, which may produce suboptimal results because both time and\nfrequency domains are important for speaker recognition. In this paper, we\nattempt to analyze the speech signal in both time and frequency domains and\npropose the time-frequency network~(TFN) for speaker recognition by extracting\nand fusing the features in the two domains. Based on the recent advance of deep\nneural networks, we propose a convolution neural network to encode the raw\nspeech waveform and the frequency spectrum into domain-specific features, which\nare then fused and transformed into a classification feature space for speaker\nrecognition. Experimental results on the publicly available datasets TIMIT and\nLibriSpeech show that our framework is effective to combine the information in\nthe two domains and performs better than the state-of-the-art methods for\nspeaker recognition.\n","authors":["Jiguo Li","Tianzi Zhang","Xiaobin Liu","Lirong Zheng"],"pdf_url":"https://arxiv.org/pdf/2303.02673v1.pdf","comment":"5pages, 3 figures"},{"id":"http://arxiv.org/abs/2303.02665v1","updated":"2023-03-05T13:06:53Z","published":"2023-03-05T13:06:53Z","title":"Heterogeneous Graph Learning for Acoustic Event Classification","summary":"  Heterogeneous graphs provide a compact, efficient, and scalable way to model\ndata involving multiple disparate modalities. This makes modeling audiovisual\ndata using heterogeneous graphs an attractive option. However, graph structure\ndoes not appear naturally in audiovisual data. Graphs for audiovisual data are\nconstructed manually which is both difficult and sub-optimal. In this work, we\naddress this problem by (i) proposing a parametric graph construction strategy\nfor the intra-modal edges, and (ii) learning the crossmodal edges. To this end,\nwe develop a new model, heterogeneous graph crossmodal network (HGCN) that\nlearns the crossmodal edges. Our proposed model can adapt to various spatial\nand temporal scales owing to its parametric construction, while the learnable\ncrossmodal edges effectively connect the relevant nodes across modalities.\nExperiments on a large benchmark dataset (AudioSet) show that our model is\nstate-of-the-art (0.53 mean average precision), outperforming transformer-based\nmodels and other graph-based models.\n","authors":["Amir Shirian","Mona Ahmadian","Krishna Somandepalli","Tanaya Guha"],"pdf_url":"https://arxiv.org/pdf/2303.02665v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2207.07935"},{"id":"http://arxiv.org/abs/2303.02659v1","updated":"2023-03-05T12:29:44Z","published":"2023-03-05T12:29:44Z","title":"Cyber Vaccine for Deepfake Immunity","summary":"  Deepfakes pose an evolving threat to cybersecurity, which calls for the\ndevelopment of automated countermeasures. While considerable forensic research\nhas been devoted to the detection and localisation of deepfakes, solutions for\nreversing fake to real are yet to be developed. In this study, we introduce\ncyber vaccination for conferring immunity to deepfakes. Analogous to biological\nvaccination that injects antigens to induce immunity prior to infection by an\nactual pathogen, cyber vaccination simulates deepfakes and performs adversarial\ntraining to build a defensive immune system. Aiming at building up\nattack-agnostic immunity with limited computational resources, we propose to\nsimulate various deepfakes with one single overpowered attack: face masking.\nThe proposed immune system consists of a vaccinator for inducing immunity and a\nneutraliser for recovering facial content. Experimental evaluations demonstrate\neffective immunity to face replacement, face reenactment and various types of\ncorruptions.\n","authors":["Ching-Chun Chang","Huy Hong Nguyen","Junichi Yamagishi","Isao Echizen"],"pdf_url":"https://arxiv.org/pdf/2303.02659v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.13133v2","updated":"2023-03-05T12:16:33Z","published":"2022-02-26T13:02:32Z","title":"Automation of reversible steganographic coding with nonlinear discrete\n  optimisation","summary":"  Authentication mechanisms are at the forefront of defending the world from\nvarious types of cybercrime. Steganography can serve as an authentication\nsolution through the use of a digital signature embedded in a carrier object to\nensure the integrity of the object and simultaneously lighten the burden of\nmetadata management. Nevertheless, despite being generally imperceptible to\nhuman sensory systems, any degree of steganographic distortion might be\ninadmissible in fidelity-sensitive situations such as forensic science, legal\nproceedings, medical diagnosis and military reconnaissance. This has led to the\ndevelopment of reversible steganography. A fundamental element of reversible\nsteganography is predictive analytics, for which powerful neural network models\nhave been effectively deployed. Another core element is reversible\nsteganographic coding. Contemporary coding is based primarily on heuristics,\nwhich offers a shortcut towards sufficient, but not necessarily optimal,\ncapacity--distortion performance. While attempts have been made to realise\nautomatic coding with neural networks, perfect reversibility is unattainable\nvia such learning machinery. Instead of relying on heuristics and machine\nlearning, we aim to derive optimal coding by means of mathematical\noptimisation. In this study, we formulate reversible steganographic coding as a\nnonlinear discrete optimisation problem with a logarithmic capacity constraint\nand a quadratic distortion objective. Linearisation techniques are developed to\nenable iterative mixed-integer linear programming. Experimental results\nvalidate the near-optimality of the proposed optimisation algorithm when\nbenchmarked against a brute-force method.\n","authors":["Ching-Chun Chang"],"pdf_url":"https://arxiv.org/pdf/2202.13133v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02635v1","updated":"2023-03-05T10:32:26Z","published":"2023-03-05T10:32:26Z","title":"VTQA: Visual Text Question Answering via Entity Alignment and\n  Cross-Media Reasoning","summary":"  The ideal form of Visual Question Answering requires understanding, grounding\nand reasoning in the joint space of vision and language and serves as a proxy\nfor the AI task of scene understanding. However, most existing VQA benchmarks\nare limited to just picking the answer from a pre-defined set of options and\nlack attention to text. We present a new challenge with a dataset that contains\n23,781 questions based on 10124 image-text pairs. Specifically, the task\nrequires the model to align multimedia representations of the same entity to\nimplement multi-hop reasoning between image and text and finally use natural\nlanguage to answer the question. The aim of this challenge is to develop and\nbenchmark models that are capable of multimedia entity alignment, multi-step\nreasoning and open-ended answer generation.\n","authors":["Kang Chen","Xiangqian Wu"],"pdf_url":"https://arxiv.org/pdf/2303.02635v1.pdf","comment":null}]},"2023-03-04T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2303.02513v1","updated":"2023-03-04T22:28:29Z","published":"2023-03-04T22:28:29Z","title":"Model-Agnostic Meta-Learning for Multilingual Hate Speech Detection","summary":"  Hate speech in social media is a growing phenomenon, and detecting such toxic\ncontent has recently gained significant traction in the research community.\nExisting studies have explored fine-tuning language models (LMs) to perform\nhate speech detection, and these solutions have yielded significant\nperformance. However, most of these studies are limited to detecting hate\nspeech only in English, neglecting the bulk of hateful content that is\ngenerated in other languages, particularly in low-resource languages.\nDeveloping a classifier that captures hate speech and nuances in a low-resource\nlanguage with limited data is extremely challenging. To fill the research gap,\nwe propose HateMAML, a model-agnostic meta-learning-based framework that\neffectively performs hate speech detection in low-resource languages. HateMAML\nutilizes a self-supervision strategy to overcome the limitation of data\nscarcity and produces better LM initialization for fast adaptation to an unseen\ntarget language (i.e., cross-lingual transfer) or other hate speech datasets\n(i.e., domain generalization). Extensive experiments are conducted on five\ndatasets across eight different low-resource languages. The results show that\nHateMAML outperforms the state-of-the-art baselines by more than 3% in the\ncross-domain multilingual transfer setting. We also conduct ablation studies to\nanalyze the characteristics of HateMAML.\n","authors":["Md Rabiul Awal","Roy Ka-Wei Lee","Eshaan Tanwar","Tanmay Garg","Tanmoy Chakraborty"],"pdf_url":"https://arxiv.org/pdf/2303.02513v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.07468v3","updated":"2023-03-04T19:58:34Z","published":"2022-10-14T02:35:19Z","title":"Transparency Helps Reveal When Language Models Learn Meaning","summary":"  Many current NLP systems are built from language models trained to optimize\nunsupervised objectives on large amounts of raw text. Under what conditions\nmight such a procedure acquire meaning? Our systematic experiments with\nsynthetic data reveal that, with languages where all expressions have\ncontext-independent denotations (i.e., languages with strong transparency),\nboth autoregressive and masked language models successfully learn to emulate\nsemantic relations between expressions. However, when denotations are changed\nto be context-dependent with the language otherwise unmodified, this ability\ndegrades. Turning to natural language, our experiments with a specific\nphenomenon -- referential opacity -- add to the growing body of evidence that\ncurrent language models do not represent natural language semantics well. We\nshow this failure relates to the context-dependent nature of natural language\nform-meaning mappings.\n","authors":["Zhaofeng Wu","William Merrill","Hao Peng","Iz Beltagy","Noah A. Smith"],"pdf_url":"https://arxiv.org/pdf/2210.07468v3.pdf","comment":"Accepted for publication in Transactions of the Association for\n  Computational Linguistics (TACL), 2023. Author's final version (pre-MIT Press\n  publication)"},{"id":"http://arxiv.org/abs/2303.02472v1","updated":"2023-03-04T18:06:36Z","published":"2023-03-04T18:06:36Z","title":"ESD: Expected Squared Difference as a Tuning-Free Trainable Calibration\n  Measure","summary":"  Studies have shown that modern neural networks tend to be poorly calibrated\ndue to over-confident predictions. Traditionally, post-processing methods have\nbeen used to calibrate the model after training. In recent years, various\ntrainable calibration measures have been proposed to incorporate them directly\ninto the training process. However, these methods all incorporate internal\nhyperparameters, and the performance of these calibration objectives relies on\ntuning these hyperparameters, incurring more computational costs as the size of\nneural networks and datasets become larger. As such, we present Expected\nSquared Difference (ESD), a tuning-free (i.e., hyperparameter-free) trainable\ncalibration objective loss, where we view the calibration error from the\nperspective of the squared difference between the two expectations. With\nextensive experiments on several architectures (CNNs, Transformers) and\ndatasets, we demonstrate that (1) incorporating ESD into the training improves\nmodel calibration in various batch size settings without the need for internal\nhyperparameter tuning, (2) ESD yields the best-calibrated results compared with\nprevious approaches, and (3) ESD drastically improves the computational costs\nrequired for calibration during training due to the absence of internal\nhyperparameter. The code is publicly accessible at\nhttps://github.com/hee-suk-yoon/ESD.\n","authors":["Hee Suk Yoon","Joshua Tian Jin Tee","Eunseop Yoon","Sunjae Yoon","Gwangsu Kim","Yingzhen Li","Chang D. Yoo"],"pdf_url":"https://arxiv.org/pdf/2303.02472v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.02469v1","updated":"2023-03-04T18:00:05Z","published":"2023-03-04T18:00:05Z","title":"Variational Quantum Classifiers for Natural-Language Text","summary":"  As part of the recent research effort on quantum natural language processing\n(QNLP), variational quantum sentence classifiers (VQSCs) have been implemented\nand supported in lambeq / DisCoPy, based on the DisCoCat model of sentence\nmeaning. We discuss in some detail VQSCs, including category theory, DisCoCat\nfor modeling sentence as string diagram, and DisCoPy for encoding string\ndiagram as parameterized quantum circuit. Many NLP tasks, however, require the\nhandling of text consisting of multiple sentences, which is not supported in\nlambeq / DisCoPy. A good example is sentiment classification of customer\nfeedback or product review. We discuss three potential approaches to\nvariational quantum text classifiers (VQTCs), in line with VQSCs. The first is\na weighted bag-of-sentences approach which treats text as a group of\nindependent sentences with task-specific sentence weighting. The second is a\ncoreference resolution approach which treats text as a consolidation of its\nmember sentences with coreferences among them resolved. Both approaches are\nbased on the DisCoCat model and should be implementable in lambeq / DisCoCat.\nThe third approach, on the other hand, is based on the DisCoCirc model which\nconsiders both ordering of sentences and interaction of words in composing text\nmeaning from word and sentence meanings. DisCoCirc makes fundamental\nmodification of DisCoCat since a sentence in DisCoCirc updates meanings of\nwords, whereas all meanings are static in DisCoCat. It is not clear if\nDisCoCirc can be implemented in lambeq / DisCoCat without breaking DisCoCat.\n","authors":["Daniel T. Chang"],"pdf_url":"https://arxiv.org/pdf/2303.02469v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02468v1","updated":"2023-03-04T17:59:43Z","published":"2023-03-04T17:59:43Z","title":"Lon-eå at SemEval-2023 Task 11: A Comparison of\\\\Activation\n  Functions for Soft and Hard Label Prediction","summary":"  We study the influence of different activation functions in the output layer\nof deep neural network models for soft and hard label prediction in the\nlearning with disagreement task. In this task, the goal is to quantify the\namount of disagreement via predicting soft labels. To predict the soft labels,\nwe use BERT-based preprocessors and encoders and vary the activation function\nused in the output layer, while keeping other parameters constant. The soft\nlabels are then used for the hard label prediction. The activation functions\nconsidered are sigmoid as well as a step-function that is added to the model\npost-training and a sinusoidal activation function, which is introduced for the\nfirst time in this paper.\n","authors":["Peyman Hosseini","Mehran Hosseini","Sana Sabah Al-Azzawi","Marcus Liwicki","Ignacio Castro","Matthew Purver"],"pdf_url":"https://arxiv.org/pdf/2303.02468v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10166v2","updated":"2023-03-04T16:57:44Z","published":"2023-02-20T18:53:56Z","title":"Learning Deep Semantics for Test Completion","summary":"  Writing tests is a time-consuming yet essential task during software\ndevelopment. We propose to leverage recent advances in deep learning for text\nand code generation to assist developers in writing tests. We formalize the\nnovel task of test completion to automatically complete the next statement in a\ntest method based on the context of prior statements and the code under test.\nWe develop TeCo -- a deep learning model using code semantics for test\ncompletion. The key insight underlying TeCo is that predicting the next\nstatement in a test method requires reasoning about code execution, which is\nhard to do with only syntax-level data that existing code completion models\nuse. TeCo extracts and uses six kinds of code semantics data, including the\nexecution result of prior statements and the execution context of the test\nmethod. To provide a testbed for this new task, as well as to evaluate TeCo, we\ncollect a corpus of 130,934 test methods from 1,270 open-source Java projects.\nOur results show that TeCo achieves an exact-match accuracy of 18, which is 29%\nhigher than the best baseline using syntax-level data only. When measuring\nfunctional correctness of generated next statement, TeCo can generate runnable\ncode in 29% of the cases compared to 18% obtained by the best baseline.\nMoreover, TeCo is significantly better than prior work on test oracle\ngeneration.\n","authors":["Pengyu Nie","Rahul Banerjee","Junyi Jessy Li","Raymond J. Mooney","Milos Gligoric"],"pdf_url":"https://arxiv.org/pdf/2302.10166v2.pdf","comment":"Accepted as a conference paper in ICSE 2023"},{"id":"http://arxiv.org/abs/2303.02427v1","updated":"2023-03-04T14:23:02Z","published":"2023-03-04T14:23:02Z","title":"Self-tuning hyper-parameters for unsupervised cross-lingual tokenization","summary":"  We explore the possibility of meta-learning for the language-independent\nunsupervised tokenization problem for English, Russian, and Chinese. We\nimplement the meta-learning approach for automatic determination of\nhyper-parameters of the unsupervised tokenization model proposed in earlier\nworks, relying on various human-independent fitness functions such as\nnormalised anti-entropy, compression factor and cross-split F 1 score, as well\nas additive and multiplicative composite combinations of the three metrics,\ntesting them against the conventional F1 tokenization score. We find a fairly\ngood correlation between the latter and the additive combination of the former\nthree metrics for English and Russian. In case of Chinese, we find a\nsignificant correlation between the F 1 score and the compression factor. Our\nresults suggest the possibility of robust unsupervised tokenization of\nlow-resource and dead languages and allow us to think about human languages in\nterms of the evolution of efficient symbolic communication codes with different\nstructural optimisation schemes that have evolved in different human cultures.\n","authors":["Anton Kolonin"],"pdf_url":"https://arxiv.org/pdf/2303.02427v1.pdf","comment":"5 figures, 2 tables, submitted to AGI-2023 conference"},{"id":"http://arxiv.org/abs/2303.02411v1","updated":"2023-03-04T13:12:18Z","published":"2023-03-04T13:12:18Z","title":"The Contribution of Knowledge in Visiolinguistic Learning: A Survey on\n  Tasks and Challenges","summary":"  Recent advancements in visiolinguistic (VL) learning have allowed the\ndevelopment of multiple models and techniques that offer several impressive\nimplementations, able to currently resolve a variety of tasks that require the\ncollaboration of vision and language. Current datasets used for VL pre-training\nonly contain a limited amount of visual and linguistic knowledge, thus\nsignificantly limiting the generalization capabilities of many VL models.\nExternal knowledge sources such as knowledge graphs (KGs) and Large Language\nModels (LLMs) are able to cover such generalization gaps by filling in missing\nknowledge, resulting in the emergence of hybrid architectures. In the current\nsurvey, we analyze tasks that have benefited from such hybrid approaches.\nMoreover, we categorize existing knowledge sources and types, proceeding to\ndiscussion regarding the KG vs LLM dilemma and its potential impact to future\nhybrid approaches.\n","authors":["Maria Lymperaiou","Giorgos Stamou"],"pdf_url":"https://arxiv.org/pdf/2303.02411v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.10756v2","updated":"2023-03-04T12:57:41Z","published":"2021-11-21T07:22:44Z","title":"TraVLR: Now You See It, Now You Don't! A Bimodal Dataset for Evaluating\n  Visio-Linguisic Reasoning","summary":"  Numerous visio-linguistic (V+L) representation learning methods have been\ndeveloped, yet existing datasets do not adequately evaluate the extent to which\nthey represent visual and linguistic concepts in a unified space. We propose\nseveral novel evaluation settings for V+L models, including cross-modal\ntransfer. Furthermore, existing V+L benchmarks often report global accuracy\nscores on the entire dataset, making it difficult to pinpoint the specific\nreasoning tasks that models fail and succeed at. We present TraVLR, a synthetic\ndataset comprising four V+L reasoning tasks. TraVLR's synthetic nature allows\nus to constrain its training and testing distributions along task-relevant\ndimensions, enabling the evaluation of out-of-distribution generalisation. Each\nexample in TraVLR redundantly encodes the scene in two modalities, allowing\neither to be dropped or added during training or testing without losing\nrelevant information. We compare the performance of four state-of-the-art V+L\nmodels, finding that while they perform well on test examples from the same\nmodality, they all fail at cross-modal transfer and have limited success\naccommodating the addition or deletion of one modality. We release TraVLR as an\nopen challenge for the research community.\n","authors":["Keng Ji Chow","Samson Tan","Min-Yen Kan"],"pdf_url":"https://arxiv.org/pdf/2111.10756v2.pdf","comment":"The first two authors contributed equally"},{"id":"http://arxiv.org/abs/2303.02399v1","updated":"2023-03-04T12:21:45Z","published":"2023-03-04T12:21:45Z","title":"RweetMiner: Automatic identification and categorization of help requests\n  on twitter during disasters","summary":"  Catastrophic events create uncertain situations for humanitarian\norganizations locating and providing aid to affected people. Many people turn\nto social media during disasters for requesting help and/or providing relief to\nothers. However, the majority of social media posts seeking help could not\nproperly be detected and remained concealed because often they are noisy and\nill-formed. Existing systems lack in planning an effective strategy for tweet\npreprocessing and grasping the contexts of tweets. This research, first of all,\nformally defines request tweets in the context of social networking sites,\nhereafter rweets, along with their different primary types and sub-types. Our\nmain contributions are the identification and categorization of rweets. For\nrweet identification, we employ two approaches, namely a rule-based and\nlogistic regression, and show their high precision and F1 scores. The rweets\nclassification into sub-types such as medical, food, and shelter, using\nlogistic regression shows promising results and outperforms existing works.\nFinally, we introduce an architecture to store intermediate data to accelerate\nthe development process of the machine learning classifiers.\n","authors":["Irfan Ullah","Sharifullah Khan","Muhammad Imran","Young-Koo Lee"],"pdf_url":"https://arxiv.org/pdf/2303.02399v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.10305v2","updated":"2023-03-04T09:52:08Z","published":"2022-10-19T05:33:27Z","title":"A Unified Neural Network Model for Readability Assessment with Feature\n  Projection and Length-Balanced Loss","summary":"  For readability assessment, traditional methods mainly employ machine\nlearning classifiers with hundreds of linguistic features. Although the deep\nlearning model has become the prominent approach for almost all NLP tasks, it\nis less explored for readability assessment. In this paper, we propose a\nBERT-based model with feature projection and length-balanced loss (BERT-FP-LBL)\nfor readability assessment. Specially, we present a new difficulty knowledge\nguided semi-supervised method to extract topic features to complement the\ntraditional linguistic features. From the linguistic features, we employ\nprojection filtering to extract orthogonal features to supplement BERT\nrepresentations. Furthermore, we design a new length-balanced loss to handle\nthe greatly varying length distribution of data. Our model achieves\nstate-of-the-art performances on two English benchmark datasets and one dataset\nof Chinese textbooks, and also achieves the near-perfect accuracy of 99\\% on\none English dataset. Moreover, our proposed model obtains comparable results\nwith human experts in consistency test.\n","authors":["Wenbiao Li","Ziyang Wang","Yunfang Wu"],"pdf_url":"https://arxiv.org/pdf/2210.10305v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02357v1","updated":"2023-03-04T08:42:50Z","published":"2023-03-04T08:42:50Z","title":"DiTTO: A Feature Representation Imitation Approach for Improving\n  Cross-Lingual Transfer","summary":"  Zero-shot cross-lingual transfer is promising, however has been shown to be\nsub-optimal, with inferior transfer performance across low-resource languages.\nIn this work, we envision languages as domains for improving zero-shot transfer\nby jointly reducing the feature incongruity between the source and the target\nlanguage and increasing the generalization capabilities of pre-trained\nmultilingual transformers. We show that our approach, DiTTO, significantly\noutperforms the standard zero-shot fine-tuning method on multiple datasets\nacross all languages using solely unlabeled instances in the target language.\nEmpirical results show that jointly reducing feature incongruity for multiple\ntarget languages is vital for successful cross-lingual transfer. Moreover, our\nmodel enables better cross-lingual transfer than standard fine-tuning methods,\neven in the few-shot setting.\n","authors":["Shanu Kumar","Abbaraju Soujanya","Sandipan Dandapat","Sunayana Sitaram","Monojit Choudhury"],"pdf_url":"https://arxiv.org/pdf/2303.02357v1.pdf","comment":"Accepted at EACL 2023"},{"id":"http://arxiv.org/abs/2109.05463v2","updated":"2023-03-04T06:55:13Z","published":"2021-09-12T08:50:17Z","title":"Logic Traps in Evaluating Attribution Scores","summary":"  Modern deep learning models are notoriously opaque, which has motivated the\ndevelopment of methods for interpreting how deep models predict. This goal is\nusually approached with attribution method, which assesses the influence of\nfeatures on model predictions. As an explanation method, the evaluation\ncriteria of attribution methods is how accurately it re-reflects the actual\nreasoning process of the model (faithfulness). Meanwhile, since the reasoning\nprocess of deep models is inaccessible, researchers design various evaluation\nmethods to demonstrate their arguments. However, some crucial logic traps in\nthese evaluation methods are ignored in most works, causing inaccurate\nevaluation and unfair comparison. This paper systematically reviews existing\nmethods for evaluating attribution scores and summarizes the logic traps in\nthese methods. We further conduct experiments to demonstrate the existence of\neach logic trap. Through both the theoretical and experimental analysis, we\nhope to increase attention on the inaccurate evaluation of attribution scores.\nMoreover, with this paper, we suggest stopping focusing on improving\nperformance under unreliable evaluation systems and starting efforts on\nreducing the impact of proposed logic traps\n","authors":["Yiming Ju","Yuanzhe Zhang","Zhao Yang","Zhongtao Jiang","Kang Liu","Jun Zhao"],"pdf_url":"https://arxiv.org/pdf/2109.05463v2.pdf","comment":"12 pages, accepted by ACL 2022"},{"id":"http://arxiv.org/abs/2204.03592v2","updated":"2023-03-04T05:48:24Z","published":"2022-04-07T17:12:57Z","title":"Testing the limits of natural language models for predicting human\n  language judgments","summary":"  Neural network language models can serve as computational hypotheses about\nhow humans process language. We compared the model-human consistency of diverse\nlanguage models using a novel experimental approach: controversial sentence\npairs. For each controversial sentence pair, two language models disagree about\nwhich sentence is more likely to occur in natural text. Considering nine\nlanguage models (including n-gram, recurrent neural networks, and transformer\nmodels), we created hundreds of such controversial sentence pairs by either\nselecting sentences from a corpus or synthetically optimizing sentence pairs to\nbe highly controversial. Human subjects then provided judgments indicating for\neach pair which of the two sentences is more likely. Controversial sentence\npairs proved highly effective at revealing model failures and identifying\nmodels that aligned most closely with human judgments. The most\nhuman-consistent model tested was GPT-2, although experiments also revealed\nsignificant shortcomings of its alignment with human perception.\n","authors":["Tal Golan","Matthew Siegelman","Nikolaus Kriegeskorte","Christopher Baldassano"],"pdf_url":"https://arxiv.org/pdf/2204.03592v2.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2303.02418v1","updated":"2023-03-04T13:41:36Z","published":"2023-03-04T13:41:36Z","title":"Compressed Interaction Graph based Framework for Multi-behavior\n  Recommendation","summary":"  Multi-types of user behavior data (e.g., clicking, adding to cart, and\npurchasing) are recorded in most real-world recommendation scenarios, which can\nhelp to learn users' multi-faceted preferences. However, it is challenging to\nexplore multi-behavior data due to the unbalanced data distribution and sparse\ntarget behavior, which lead to the inadequate modeling of high-order relations\nwhen treating multi-behavior data ''as features'' and gradient conflict in\nmultitask learning when treating multi-behavior data ''as labels''. In this\npaper, we propose CIGF, a Compressed Interaction Graph based Framework, to\novercome the above limitations. Specifically, we design a novel Compressed\nInteraction Graph Convolution Network (CIGCN) to model instance-level\nhigh-order relations explicitly. To alleviate the potential gradient conflict\nwhen treating multi-behavior data ''as labels'', we propose a Multi-Expert with\nSeparate Input (MESI) network with separate input on the top of CIGCN for\nmulti-task learning. Comprehensive experiments on three large-scale real-world\ndatasets demonstrate the superiority of CIGF. Ablation studies and in-depth\nanalysis further validate the effectiveness of our proposed model in capturing\nhigh-order relations and alleviating gradient conflict. The source code and\ndatasets are available at https://github.com/MC-CV/CIGF.\n","authors":["Wei Guo","Chang Meng","Enming Yuan","Zhicheng He","Huifeng Guo","Yingxue Zhang","Bo Chen","Yaochen Hu","Ruiming Tang","Xiu Li","Rui Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.02418v1.pdf","comment":"Wei Guo and Chang Meng are co-first authors and contributed equally\n  to this research. Chang Meng is supervised by Wei Guo when he was a research\n  intern at Huawei Noah's Ark Lab"},{"id":"http://arxiv.org/abs/1910.10086v4","updated":"2023-03-04T05:49:19Z","published":"2019-10-22T16:29:51Z","title":"Meta Matrix Factorization for Federated Rating Predictions","summary":"  Federated recommender systems have distinct advantages in terms of privacy\nprotection over traditional recommender systems that are centralized at a data\ncenter. However, previous work on federated recommender systems does not fully\nconsider the limitations of storage, RAM, energy and communication bandwidth in\na mobile environment. The scales of the models proposed are too large to be\neasily run on mobile devices. And existing federated recommender systems need\nto fine-tune recommendation models on each device, making it hard to\neffectively exploit collaborative filtering information among users/devices.\nOur goal in this paper is to design a novel federated learning framework for\nrating prediction (RP) for mobile environments. We introduce a federated matrix\nfactorization (MF) framework, named meta matrix factorization (MetaMF). Given a\nuser, we first obtain a collaborative vector by collecting useful information\nwith a collaborative memory module. Then, we employ a meta recommender module\nto generate private item embeddings and a RP model based on the collaborative\nvector in the server. To address the challenge of generating a large number of\nhigh-dimensional item embeddings, we devise a rise-dimensional generation\nstrategy that first generates a low-dimensional item embedding matrix and a\nrise-dimensional matrix, and then multiply them to obtain high-dimensional\nembeddings. We use the generated model to produce private RPs for the given\nuser on her device. MetaMF shows a high capacity even with a small RP model,\nwhich can adapt to the limitations of a mobile environment. We conduct\nextensive experiments on four benchmark datasets to compare MetaMF with\nexisting MF methods and find that MetaMF can achieve competitive performance.\nMoreover, we find MetaMF achieves higher RP performance over existing federated\nmethods by better exploiting collaborative filtering among users/devices.\n","authors":["Yujie Lin","Pengjie Ren","Zhumin Chen","Zhaochun Ren","Dongxiao Yu","Jun Ma","Maarten de Rijke","Xiuzhen Cheng"],"pdf_url":"https://arxiv.org/pdf/1910.10086v4.pdf","comment":"Change the url of the code and fix some typos"},{"id":"http://arxiv.org/abs/2303.02297v1","updated":"2023-03-04T02:35:29Z","published":"2023-03-04T02:35:29Z","title":"A Self-Correcting Sequential Recommender","summary":"  Sequential recommendations aim to capture users' preferences from their\nhistorical interactions so as to predict the next item that they will interact\nwith. Sequential recommendation methods usually assume that all items in a\nuser's historical interactions reflect her/his preferences and transition\npatterns between items. However, real-world interaction data is imperfect in\nthat (i) users might erroneously click on items, i.e., so-called misclicks on\nirrelevant items, and (ii) users might miss items, i.e., unexposed relevant\nitems due to inaccurate recommendations. To tackle the two issues listed above,\nwe propose STEAM, a Self-correcTing sEquentiAl recoMmender. STEAM first\ncorrects an input item sequence by adjusting the misclicked and/or missed\nitems. It then uses the corrected item sequence to train a recommender and make\nthe next item prediction.We design an item-wise corrector that can adaptively\nselect one type of operation for each item in the sequence. The operation types\nare 'keep', 'delete' and 'insert.' In order to train the item-wise corrector\nwithout requiring additional labeling, we design two self-supervised learning\nmechanisms: (i) deletion correction (i.e., deleting randomly inserted items),\nand (ii) insertion correction (i.e., predicting randomly deleted items). We\nintegrate the corrector with the recommender by sharing the encoder and by\ntraining them jointly. We conduct extensive experiments on three real-world\ndatasets and the experimental results demonstrate that STEAM outperforms\nstate-of-the-art sequential recommendation baselines. Our in-depth analyses\nconfirm that STEAM benefits from learning to correct the raw item sequences.\n","authors":["Yujie Lin","Chenyang Wang","Zhumin Chen","Zhaochun Ren","Xin Xin","Qiang Yan","Maarten de Rijke","Xiuzhen Cheng","Pengjie Ren"],"pdf_url":"https://arxiv.org/pdf/2303.02297v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2202.03861v3","updated":"2023-03-04T20:39:45Z","published":"2022-02-08T13:46:42Z","title":"Targeted Trojan-Horse Attacks on Language-based Image Retrieval","summary":"  While deep learning based image retrieval is reported to be vulnerable to\nadversarial attacks, existing works are mainly on image-to-image retrieval with\ntheir attacks performed at the front end via query modification. By contrast,\nwe present in this paper the first study about a threat that occurs at the back\nend of a text-to-image retrieval (T2IR) system. Our study is motivated by the\nfact that the image collection indexed by the system will be regularly updated\ndue to the arrival of new images from various sources such as web crawlers and\nadvertisers. With malicious images indexed, it is possible for an attacker to\nindirectly interfere with the retrieval process, letting users see certain\nimages that are completely irrelevant w.r.t. their queries. We put this thought\ninto practice by proposing a novel Trojan-horse attack (THA). In particular, we\nconstruct a set of Trojan-horse images by first embedding word-specific\nadversarial information into a QR code and then putting the code on benign\nadvertising images. A proof-of-concept evaluation, conducted on two popular\nT2IR datasets (Flickr30k and MS-COCO), shows the effectiveness of the proposed\nTHA in a white-box mode.\n","authors":["Fan Hu","Aozhu Chen","Xirong Li"],"pdf_url":"https://arxiv.org/pdf/2202.03861v3.pdf","comment":"Accepted at ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.02446v1","updated":"2023-03-04T16:11:49Z","published":"2023-03-04T16:11:49Z","title":"Comparative Studies of Unsupervised and Supervised Learning Methods\n  based on Multimedia Applications","summary":"  In the mobile communication field, some of the video applications boosted the\ninterest of robust methods for video quality assessment. Out of all existing\nmethods, We Preferred, No Reference Video Quality Assessment is the one which\nis most needed in situations where the handiness of reference video is\npartially available. Our research interest lies in formulating and melding\neffective features into one model based on human visualizing characteristics.\nOur work explores comparative study between Supervised and unsupervised\nlearning methods. Therefore, we implemented support vector regression algorithm\nas NR-based Video Quality Metric(VQM) for quality estimation with simplified\ninput features. We concluded that our proposed model exhibited sparseness even\nafter dimension reduction for objective scores of SSIM quality metric.\n","authors":["Amitesh Kumar Singam","Benny Lövström","Wlodek J. Kulesza"],"pdf_url":"https://arxiv.org/pdf/2303.02446v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02428v1","updated":"2023-03-04T14:32:46Z","published":"2023-03-04T14:32:46Z","title":"Building a Modal-balanced BlockChain with Semantic Reconstruction","summary":"  The current large blockchain systems (BTC Lightning network, Ethereum, etc.)\nare generally facing the problems of low persistence rates and high storage\ncosts. Therefore, users tend to store single modal (textual) information on the\nexisting blockchain systems. Inspired by semantic communication algorithms,\nthis paper presents a new algorithm to solve the serious imbalance between\ntextual and visual modals on blockchains. After semantic sampling of the\noriginal visual image, the resulting semantic text will be stored on the chain,\nand the end users can reconstruct a semantically similar image using the\n\\textbf{R}elative \\textbf{O}ptimal \\textbf{S}emantic \\textbf{I}sotope\n\\textbf{S}election algorithm. Experiments on the DIV2K dataset show that the\nblockchain with our algorithm can achieve 430,000 times the storage capacity\nand 550,000 times the persistence rate for the original visual data with\nacceptable semantic information loss.\n","authors":["Zhijie Tan","Xiang Yuan","Shengwei Meng","Yakun Huang","Weiping Li","Zhonghai Wu","Tong Mo"],"pdf_url":"https://arxiv.org/pdf/2303.02428v1.pdf","comment":"4pages, 1 figure"},{"id":"http://arxiv.org/abs/2212.10846v2","updated":"2023-03-04T12:42:54Z","published":"2022-12-21T08:39:36Z","title":"From Images to Textual Prompts: Zero-shot VQA with Frozen Large Language\n  Models","summary":"  Large language models (LLMs) have demonstrated excellent zero-shot\ngeneralization to new language tasks. However, effective utilization of LLMs\nfor zero-shot visual question-answering (VQA) remains challenging, primarily\ndue to the modality disconnection and task disconnection between LLM and VQA\ntask. End-to-end training on vision and language data may bridge the\ndisconnections, but is inflexible and computationally expensive. To address\nthis issue, we propose \\emph{Img2Prompt}, a plug-and-play module that provides\nthe prompts that can bridge the aforementioned modality and task\ndisconnections, so that LLMs can perform zero-shot VQA tasks without end-to-end\ntraining. In order to provide such prompts, we further employ LLM-agnostic\nmodels to provide prompts that can describe image content and self-constructed\nquestion-answer pairs, which can effectively guide LLM to perform zero-shot VQA\ntasks. Img2Prompt offers the following benefits: 1) It can flexibly work with\nvarious LLMs to perform VQA. 2)~Without the needing of end-to-end training, it\nsignificantly reduces the cost of deploying LLM for zero-shot VQA tasks. 3) It\nachieves comparable or better performance than methods relying on end-to-end\ntraining. For example, we outperform Flamingo \\cite{Deepmind:Flamingo2022} by\n5.6\\% on VQAv2. On the challenging A-OKVQA dataset, our method even outperforms\nfew-shot methods by as much as 20\\%.\n","authors":["Jiaxian Guo","Junnan Li","Dongxu Li","Anthony Meng Huat Tiong","Boyang Li","Dacheng Tao","Steven C. H. Hoi"],"pdf_url":"https://arxiv.org/pdf/2212.10846v2.pdf","comment":"CVPR 2023"},{"id":"http://arxiv.org/abs/2303.02392v1","updated":"2023-03-04T11:49:42Z","published":"2023-03-04T11:49:42Z","title":"Audio-Visual Quality Assessment for User Generated Content: Database and\n  Method","summary":"  With the explosive increase of User Generated Content (UGC), UGC video\nquality assessment (VQA) becomes more and more important for improving users'\nQuality of Experience (QoE). However, most existing UGC VQA studies only focus\non the visual distortions of videos, ignoring that the user's QoE also depends\non the accompanying audio signals. In this paper, we conduct the first study to\naddress the problem of UGC audio and video quality assessment (AVQA).\nSpecifically, we construct the first UGC AVQA database named the SJTU-UAV\ndatabase, which includes 520 in-the-wild UGC audio and video (A/V) sequences,\nand conduct a user study to obtain the mean opinion scores of the A/V\nsequences. The content of the SJTU-UAV database is then analyzed from both the\naudio and video aspects to show the database characteristics. We also design a\nfamily of AVQA models, which fuse the popular VQA methods and audio features\nvia support vector regressor (SVR). We validate the effectiveness of the\nproposed models on the three databases. The experimental results show that with\nthe help of audio signals, the VQA models can evaluate the perceptual quality\nmore accurately. The database will be released to facilitate further research.\n","authors":["Yuqin Cao","Xiongkuo Min","Wei Sun","Xiaoping Zhang","Guangtao Zhai"],"pdf_url":"https://arxiv.org/pdf/2303.02392v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02353v1","updated":"2023-03-04T08:33:46Z","published":"2023-03-04T08:33:46Z","title":"Self-Asymmetric Invertible Network for Compression-Aware Image Rescaling","summary":"  High-resolution (HR) images are usually downscaled to low-resolution (LR)\nones for better display and afterward upscaled back to the original size to\nrecover details. Recent work in image rescaling formulates downscaling and\nupscaling as a unified task and learns a bijective mapping between HR and LR\nvia invertible networks. However, in real-world applications (e.g., social\nmedia), most images are compressed for transmission. Lossy compression will\nlead to irreversible information loss on LR images, hence damaging the inverse\nupscaling procedure and degrading the reconstruction accuracy. In this paper,\nwe propose the Self-Asymmetric Invertible Network (SAIN) for compression-aware\nimage rescaling. To tackle the distribution shift, we first develop an\nend-to-end asymmetric framework with two separate bijective mappings for\nhigh-quality and compressed LR images, respectively. Then, based on empirical\nanalysis of this framework, we model the distribution of the lost information\n(including downscaling and compression) using isotropic Gaussian mixtures and\npropose the Enhanced Invertible Block to derive high-quality/compressed LR\nimages in one forward pass. Besides, we design a set of losses to regularize\nthe learned LR images and enhance the invertibility. Extensive experiments\ndemonstrate the consistent improvements of SAIN across various image rescaling\ndatasets in terms of both quantitative and qualitative evaluation under\nstandard image compression formats (i.e., JPEG and WebP).\n","authors":["Jinhai Yang","Mengxi Guo","Shijie Zhao","Junlin Li","Li Zhang"],"pdf_url":"https://arxiv.org/pdf/2303.02353v1.pdf","comment":"Accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2303.02344v1","updated":"2023-03-04T07:21:37Z","published":"2023-03-04T07:21:37Z","title":"Improving Audio-Visual Video Parsing with Pseudo Visual Labels","summary":"  Audio-Visual Video Parsing is a task to predict the events that occur in\nvideo segments for each modality. It often performs in a weakly supervised\nmanner, where only video event labels are provided, i.e., the modalities and\nthe timestamps of the labels are unknown. Due to the lack of densely annotated\nlabels, recent work attempts to leverage pseudo labels to enrich the\nsupervision. A commonly used strategy is to generate pseudo labels by\ncategorizing the known event labels for each modality. However, the labels are\nstill limited to the video level, and the temporal boundaries of event\ntimestamps remain unlabeled. In this paper, we propose a new pseudo label\ngeneration strategy that can explicitly assign labels to each video segment by\nutilizing prior knowledge learned from the open world. Specifically, we exploit\nthe CLIP model to estimate the events in each video segment based on visual\nmodality to generate segment-level pseudo labels. A new loss function is\nproposed to regularize these labels by taking into account their\ncategory-richness and segmentrichness. A label denoising strategy is adopted to\nimprove the pseudo labels by flipping them whenever high forward binary cross\nentropy loss occurs. We perform extensive experiments on the LLP dataset and\ndemonstrate that our method can generate high-quality segment-level pseudo\nlabels with the help of our newly proposed loss and the label denoising\nstrategy. Our method achieves state-of-the-art audio-visual video parsing\nperformance.\n","authors":["Jinxing Zhou","Dan Guo","Yiran Zhong","Meng Wang"],"pdf_url":"https://arxiv.org/pdf/2303.02344v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.08722v2","updated":"2023-03-04T06:45:27Z","published":"2023-02-17T06:33:06Z","title":"GPT4MIA: Utilizing Generative Pre-trained Transformer (GPT-3) as A\n  Plug-and-Play Transductive Model for Medical Image Analysis","summary":"  In this paper, we propose a novel approach (called GPT4MIA) that utilizes\nGenerative Pre-trained Transformer (GPT) as a plug-and-play transductive\ninference tool for medical image analysis (MIA). We provide theoretical\nanalysis on why a large pre-trained language model such as GPT-3 can be used as\na plug-and-play transductive inference model for MIA. At the methodological\nlevel, we develop several technical treatments to improve the efficiency and\neffectiveness of GPT4MIA, including better prompt structure design, sample\nselection, and prompt ordering of representative samples/features. We present\ntwo concrete use cases (with workflow) of GPT4MIA: (1) detecting prediction\nerrors and (2) improving prediction accuracy, working in conjecture with\nwell-established vision-based models for image classification (e.g., ResNet).\nExperiments validate that our proposed method is effective for these two tasks.\nWe further discuss the opportunities and challenges in utilizing\nTransformer-based large language models for broader MIA applications.\n","authors":["Yizhe Zhang","Danny Z. Chen"],"pdf_url":"https://arxiv.org/pdf/2302.08722v2.pdf","comment":"Version 2: fixed some typos. Questions and suggestions are welcome"}]},"2023-03-07T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2303.04134v1","updated":"2023-03-07T18:49:13Z","published":"2023-03-07T18:49:13Z","title":"A Hybrid Architecture for Out of Domain Intent Detection and Intent\n  Discovery","summary":"  Intent Detection is one of the tasks of the Natural Language Understanding\n(NLU) unit in task-oriented dialogue systems. Out of Scope (OOS) and Out of\nDomain (OOD) inputs may run these systems into a problem. On the other side, a\nlabeled dataset is needed to train a model for Intent Detection in\ntask-oriented dialogue systems. The creation of a labeled dataset is\ntime-consuming and needs human resources. The purpose of this article is to\naddress mentioned problems. The task of identifying OOD/OOS inputs is named\nOOD/OOS Intent Detection. Also, discovering new intents and pseudo-labeling of\nOOD inputs is well known by Intent Discovery. In OOD intent detection part, we\nmake use of a Variational Autoencoder to distinguish between known and unknown\nintents independent of input data distribution. After that, an unsupervised\nclustering method is used to discover different unknown intents underlying\nOOD/OOS inputs. We also apply a non-linear dimensionality reduction on OOD/OOS\nrepresentations to make distances between representations more meaning full for\nclustering. Our results show that the proposed model for both OOD/OOS Intent\nDetection and Intent Discovery achieves great results and passes baselines in\nEnglish and Persian languages.\n","authors":["Masoud Akbari","Ali Mohades","M. Hassan Shirali-Shahreza"],"pdf_url":"https://arxiv.org/pdf/2303.04134v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04132v1","updated":"2023-03-07T18:48:55Z","published":"2023-03-07T18:48:55Z","title":"Exploiting Asymmetry for Synthetic Training Data Generation: SynthIE and\n  the Case of Information Extraction","summary":"  Large language models (LLMs) show great potential for synthetic data\ngeneration. This work shows that useful data can be synthetically generated\neven for tasks that cannot be solved directly by the LLM: we show that, for\nproblems with structured outputs, it is possible to prompt an LLM to perform\nthe task in the opposite direction, to generate plausible text for the target\nstructure. Leveraging the asymmetry in task difficulty makes it possible to\nproduce large-scale, high-quality data for complex tasks. We demonstrate the\neffectiveness of this approach on closed information extraction, where\ncollecting ground-truth data is challenging, and no satisfactory dataset exists\nto date. We synthetically generate a dataset of 1.8M data points, demonstrate\nits superior quality compared to existing datasets in a human evaluation and\nuse it to finetune small models (220M and 770M parameters). The models we\nintroduce, SynthIE, outperform existing baselines of comparable size with a\nsubstantial gap of 57 and 79 absolute points in micro and macro F1,\nrespectively. Code, data, and models are available at\nhttps://github.com/epfl-dlab/SynthIE.\n","authors":["Martin Josifoski","Marija Sakota","Maxime Peyrard","Robert West"],"pdf_url":"https://arxiv.org/pdf/2303.04132v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.11171v4","updated":"2023-03-07T17:57:37Z","published":"2022-03-21T17:48:52Z","title":"Self-Consistency Improves Chain of Thought Reasoning in Language Models","summary":"  Chain-of-thought prompting combined with pre-trained large language models\nhas achieved encouraging results on complex reasoning tasks. In this paper, we\npropose a new decoding strategy, self-consistency, to replace the naive greedy\ndecoding used in chain-of-thought prompting. It first samples a diverse set of\nreasoning paths instead of only taking the greedy one, and then selects the\nmost consistent answer by marginalizing out the sampled reasoning paths.\nSelf-consistency leverages the intuition that a complex reasoning problem\ntypically admits multiple different ways of thinking leading to its unique\ncorrect answer. Our extensive empirical evaluation shows that self-consistency\nboosts the performance of chain-of-thought prompting with a striking margin on\na range of popular arithmetic and commonsense reasoning benchmarks, including\nGSM8K (+17.9%), SVAMP (+11.0%), AQuA (+12.2%), StrategyQA (+6.4%) and\nARC-challenge (+3.9%).\n","authors":["Xuezhi Wang","Jason Wei","Dale Schuurmans","Quoc Le","Ed Chi","Sharan Narang","Aakanksha Chowdhery","Denny Zhou"],"pdf_url":"https://arxiv.org/pdf/2203.11171v4.pdf","comment":"Published at ICLR 2023. V2: added PaLM results; V3: added UL2\n  results; V4: camera ready version at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.04093v1","updated":"2023-03-07T17:53:00Z","published":"2023-03-07T17:53:00Z","title":"Marpa and nullable symbols","summary":"  The Marpa parser was intended to make the best results in the academic\nliterature on Earley's algorithm available as a practical general parser.\nEarley-based parsers have had issues handling nullable symbols. Initially, we\ndealt with nullable symbols by following the approach in Aycock and Horspool's\n2002 paper. This paper reports our experience with the approach in that paper,\nand the approach to handling nullables that we settled on in reaction to that\nexperience.\n","authors":["Jeffrey Kegler"],"pdf_url":"https://arxiv.org/pdf/2303.04093v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04092v1","updated":"2023-03-07T17:52:51Z","published":"2023-03-07T17:52:51Z","title":"CroCoSum: A Benchmark Dataset for Cross-Lingual Code-Switched\n  Summarization","summary":"  Cross-lingual summarization (CLS) has attracted increasing interest in recent\nyears due to the availability of large-scale web-mined datasets and the\nadvancements of multilingual language models. However, given the rareness of\nnaturally occurring CLS resources, the majority of datasets are forced to rely\non translation which can contain overly literal artifacts. This restricts our\nability to observe naturally occurring CLS pairs that capture organic diction,\nincluding instances of code-switching. This alteration between languages in\nmid-message is a common phenomenon in multilingual settings yet has been\nlargely overlooked in cross-lingual contexts due to data scarcity. To address\nthis gap, we introduce CroCoSum, a dataset of cross-lingual code-switched\nsummarization of technology news. It consists of over 24,000 English source\narticles and 18,000 human-curated Chinese news summaries, with more than 92% of\nthe summaries containing code-switched phrases. For reference, we evaluate the\nperformance of existing approaches including pipeline, end-to-end, and\nzero-shot methods. We show that leveraging existing resources as a pretraining\nstep does not improve performance on CroCoSum, indicating the limited\ngeneralizability of existing resources. Finally, we discuss the challenges of\nevaluating cross-lingual summarizers on code-switched generation through\nqualitative error analyses. Our collection and code can be accessed at\nhttps://github.com/RosenZhang/CroCoSum.\n","authors":["Ruochen Zhang","Carsten Eickhoff"],"pdf_url":"https://arxiv.org/pdf/2303.04092v1.pdf","comment":"Work in Progress"},{"id":"http://arxiv.org/abs/2303.04091v1","updated":"2023-03-07T17:52:46Z","published":"2023-03-07T17:52:46Z","title":"Visual Abstraction and Reasoning through Language","summary":"  While Artificial Intelligence (AI) models have achieved human or even\nsuperhuman performance in narrowly defined applications, they still struggle to\nshow signs of broader and more flexible intelligence. The Abstraction and\nReasoning Corpus (ARC), introduced by Fran\\c{c}ois Chollet, aims to assess how\nclose AI systems are to human-like cognitive abilities. Most current approaches\nrely on carefully handcrafted domain-specific languages (DSLs), which are used\nto brute-force solutions to the tasks present in ARC. In this work, we propose\na general framework for solving ARC based on natural language descriptions of\nthe tasks. While not yet beating state-of-the-art DSL models on ARC, we\ndemonstrate the immense potential of our approach hinted at by the ability to\nsolve previously unsolved tasks.\n","authors":["Giacomo Camposampiero","Loic Houmard","Benjamin Estermann","Joël Mathys","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2303.04091v1.pdf","comment":"The first two authors have contributed equally to this work"},{"id":"http://arxiv.org/abs/2303.04053v1","updated":"2023-03-07T17:01:25Z","published":"2023-03-07T17:01:25Z","title":"Describe me an Aucklet: Generating Grounded Perceptual Category\n  Descriptions","summary":"  Human language users can generate descriptions of perceptual concepts beyond\ninstance-level representations and also use such descriptions to learn\nprovisional class-level representations. However, the ability of computational\nmodels to learn and operate with class representations is under-investigated in\nthe language-and-vision field. In this paper, we train separate neural networks\nto generate and interpret class-level descriptions. We then use the zero-shot\nclassification performance of the interpretation model as a measure of\ncommunicative success and class-level conceptual grounding. We investigate the\nperformance of prototype- and exemplar-based neural representations grounded\ncategory description. Finally, we show that communicative success reveals\nperformance issues in the generation model that are not captured by traditional\nintrinsic NLG evaluation metrics, and argue that these issues can be traced to\na failure to properly ground language in vision at the class level. We observe\nthat the interpretation model performs better with descriptions that are low in\ndiversity on the class level, possibly indicating a strong reliance on\nfrequently occurring features.\n","authors":["Bill Noble","Nikolai Ilinykh"],"pdf_url":"https://arxiv.org/pdf/2303.04053v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04048v1","updated":"2023-03-07T16:57:20Z","published":"2023-03-07T16:57:20Z","title":"Is ChatGPT a Good NLG Evaluator? A Preliminary Study","summary":"  Recently, the emergence of ChatGPT has attracted wide attention from the\ncomputational linguistics community. Many prior studies have shown that ChatGPT\nachieves remarkable performance on various NLP tasks in terms of automatic\nevaluation metrics. However, the ability of ChatGPT to serve as an evaluation\nmetric is still underexplored. Considering assessing the quality of NLG models\nis an arduous task and previous statistical metrics notoriously show their poor\ncorrelation with human judgments, we wonder whether ChatGPT is a good NLG\nevaluation metric. In this report, we provide a preliminary meta-evaluation on\nChatGPT to show its reliability as an NLG metric. In detail, we regard ChatGPT\nas a human evaluator and give task-specific (e.g., summarization) and\naspect-specific (e.g., relevance) instruction to prompt ChatGPT to score the\ngeneration of NLG models. We conduct experiments on three widely-used NLG\nmeta-evaluation datasets (including summarization, story generation and\ndata-to-text tasks). Experimental results show that compared with previous\nautomatic metrics, ChatGPT achieves state-of-the-art or competitive correlation\nwith golden human judgments. We hope our preliminary study could prompt the\nemergence of a general-purposed reliable NLG metric.\n","authors":["Jiaan Wang","Yunlong Liang","Fandong Meng","Haoxiang Shi","Zhixu Li","Jinan Xu","Jianfeng Qu","Jie Zhou"],"pdf_url":"https://arxiv.org/pdf/2303.04048v1.pdf","comment":"Technical Report, 8 pages"},{"id":"http://arxiv.org/abs/2303.00628v2","updated":"2023-03-07T16:41:01Z","published":"2023-03-01T16:31:01Z","title":"MuAViC: A Multilingual Audio-Visual Corpus for Robust Speech Recognition\n  and Robust Speech-to-Text Translation","summary":"  We introduce MuAViC, a multilingual audio-visual corpus for robust speech\nrecognition and robust speech-to-text translation providing 1200 hours of\naudio-visual speech in 9 languages. It is fully transcribed and covers 6\nEnglish-to-X translation as well as 6 X-to-English translation directions. To\nthe best of our knowledge, this is the first open benchmark for audio-visual\nspeech-to-text translation and the largest open benchmark for multilingual\naudio-visual speech recognition. Our baseline results show that MuAViC is\neffective for building noise-robust speech recognition and translation models.\nWe make the corpus available at https://github.com/facebookresearch/muavic.\n","authors":["Mohamed Anwar","Bowen Shi","Vedanuj Goswami","Wei-Ning Hsu","Juan Pino","Changhan Wang"],"pdf_url":"https://arxiv.org/pdf/2303.00628v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04001v1","updated":"2023-03-07T16:00:26Z","published":"2023-03-07T16:00:26Z","title":"ELODIN: Naming Concepts in Embedding Spaces","summary":"  Despite recent advancements, the field of text-to-image synthesis still\nsuffers from lack of fine-grained control. Using only text, it remains\nchallenging to deal with issues such as concept coherence and concept\ncontamination. We propose a method to enhance control by generating specific\nconcepts that can be reused throughout multiple images, effectively expanding\nnatural language with new words that can be combined much like a painter's\npalette. Unlike previous contributions, our method does not copy visuals from\ninput data and can generate concepts through text alone. We perform a set of\ncomparisons that finds our method to be a significant improvement over\ntext-only prompts.\n","authors":["Rodrigo Mello","Filipe Calegario","Geber Ramalho"],"pdf_url":"https://arxiv.org/pdf/2303.04001v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03975v1","updated":"2023-03-07T15:23:38Z","published":"2023-03-07T15:23:38Z","title":"GATE: A Challenge Set for Gender-Ambiguous Translation Examples","summary":"  Although recent years have brought significant progress in improving\ntranslation of unambiguously gendered sentences, translation of ambiguously\ngendered input remains relatively unexplored. When source gender is ambiguous,\nmachine translation models typically default to stereotypical gender roles,\nperpetuating harmful bias. Recent work has led to the development of \"gender\nrewriters\" that generate alternative gender translations on such ambiguous\ninputs, but such systems are plagued by poor linguistic coverage. To encourage\nbetter performance on this task we present and release GATE, a linguistically\ndiverse corpus of gender-ambiguous source sentences along with multiple\nalternative target language translations. We also provide tools for evaluation\nand system analysis when using GATE and use them to evaluate our translation\nrewriter system.\n","authors":["Spencer Rarrick","Ranjita Naik","Varun Mathur","Sundar Poudel","Vishal Chowdhary"],"pdf_url":"https://arxiv.org/pdf/2303.03975v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03953v1","updated":"2023-03-07T14:59:33Z","published":"2023-03-07T14:59:33Z","title":"ChatGPT: Beginning of an End of Manual Annotation? Use Case of Automatic\n  Genre Identification","summary":"  ChatGPT has shown strong capabilities in natural language generation tasks,\nwhich naturally leads researchers to explore where its abilities end. In this\npaper, we examine whether ChatGPT can be used for zero-shot text\nclassification, more specifically, automatic genre identification. We compare\nChatGPT with a multilingual XLM-RoBERTa language model that was fine-tuned on\ndatasets, manually annotated with genres. The models are compared on test sets\nin two languages: English and Slovenian. Results show that ChatGPT outperforms\nthe fine-tuned model when applied to the dataset which was not seen before by\neither of the models. Even when applied on Slovenian language as an\nunder-resourced language, ChatGPT's performance is no worse than when applied\nto English. However, if the model is fully prompted in Slovenian, the\nperformance drops significantly, showing the current limitations of ChatGPT\nusage on smaller languages. The presented results lead us to questioning\nwhether this is the beginning of an end of laborious manual annotation\ncampaigns even for smaller languages, such as Slovenian.\n","authors":["Taja Kuzman","Nikola Ljubešić","Igor Mozetič"],"pdf_url":"https://arxiv.org/pdf/2303.03953v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03948v1","updated":"2023-03-07T14:57:06Z","published":"2023-03-07T14:57:06Z","title":"A Meta-Evaluation of Faithfulness Metrics for Long-Form Hospital-Course\n  Summarization","summary":"  Long-form clinical summarization of hospital admissions has real-world\nsignificance because of its potential to help both clinicians and patients. The\nfaithfulness of summaries is critical to their safe usage in clinical settings.\nTo better understand the limitations of abstractive systems, as well as the\nsuitability of existing evaluation metrics, we benchmark faithfulness metrics\nagainst fine-grained human annotations for model-generated summaries of a\npatient's Brief Hospital Course. We create a corpus of patient hospital\nadmissions and summaries for a cohort of HIV patients, each with complex\nmedical histories. Annotators are presented with summaries and source notes,\nand asked to categorize manually highlighted summary elements (clinical\nentities like conditions and medications as well as actions like \"following\nup\") into one of three categories: ``Incorrect,'' ``Missing,'' and ``Not in\nNotes.'' We meta-evaluate a broad set of proposed faithfulness metrics and,\nacross metrics, explore the importance of domain adaptation (e.g. the impact of\nin-domain pre-training and metric fine-tuning), the use of source-summary\nalignments, and the effects of distilling a single metric from an ensemble of\npre-existing metrics. Off-the-shelf metrics with no exposure to clinical text\ncorrelate well yet overly rely on summary extractiveness. As a practical guide\nto long-form clinical narrative summarization, we find that most metrics\ncorrelate best to human judgments when provided with one summary sentence at a\ntime and a minimal set of relevant source context.\n","authors":["Griffin Adams","Jason Zucker","Noémie Elhadad"],"pdf_url":"https://arxiv.org/pdf/2303.03948v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2210.00305v2","updated":"2023-03-07T14:35:33Z","published":"2022-10-01T16:01:53Z","title":"LambdaKG: A Library for Pre-trained Language Model-Based Knowledge Graph\n  Embeddings","summary":"  Knowledge Graphs (KGs) often have two characteristics: heterogeneous graph\nstructure and text-rich entity/relation information. Text-based KG embeddings\ncan represent entities by encoding descriptions with pre-trained language\nmodels, but no open-sourced library is specifically designed for KGs with PLMs\nat present. In this paper, we present LambdaKG, a library for KGE that equips\nwith many pre-trained language models (e.g., BERT, BART, T5, GPT-3), and\nsupports various tasks (e.g., knowledge graph completion, question answering,\nrecommendation, and knowledge probing). LambdaKG is publicly open-sourced at\nhttps://github.com/zjunlp/PromptKG/tree/main/lambdaKG, with a demo video at\nhttp://deepke.zjukg.cn/lambdakg.mp4 and long-term maintenance.\n","authors":["Xin Xie","Zhoubo Li","Xiaohan Wang","Yuqi Zhu","Ningyu Zhang","Jintian Zhang","Siyuan Cheng","Bozhong Tian","Shumin Deng","Feiyu Xiong","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2210.00305v2.pdf","comment":"Work in progress and the project website is\n  https://zjunlp.github.io/project/promptkg/"},{"id":"http://arxiv.org/abs/2303.03926v1","updated":"2023-03-07T14:31:55Z","published":"2023-03-07T14:31:55Z","title":"Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec\n  Language Modeling","summary":"  We propose a cross-lingual neural codec language model, VALL-E X, for\ncross-lingual speech synthesis. Specifically, we extend VALL-E and train a\nmulti-lingual conditional codec language model to predict the acoustic token\nsequences of the target language speech by using both the source language\nspeech and the target language text as prompts. VALL-E X inherits strong\nin-context learning capabilities and can be applied for zero-shot cross-lingual\ntext-to-speech synthesis and zero-shot speech-to-speech translation tasks.\nExperimental results show that it can generate high-quality speech in the\ntarget language via just one speech utterance in the source language as a\nprompt while preserving the unseen speaker's voice, emotion, and acoustic\nenvironment. Moreover, VALL-E X effectively alleviates the foreign accent\nproblems, which can be controlled by a language ID. Audio samples are available\nat \\url{https://aka.ms/vallex}.\n","authors":["Ziqiang Zhang","Long Zhou","Chengyi Wang","Sanyuan Chen","Yu Wu","Shujie Liu","Zhuo Chen","Yanqing Liu","Huaming Wang","Jinyu Li","Lei He","Sheng Zhao","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2303.03926v1.pdf","comment":"We encourage readers to listen to the audio samples on our demo page:\n  \\url{https://aka.ms/vallex}"},{"id":"http://arxiv.org/abs/2303.03915v1","updated":"2023-03-07T14:25:44Z","published":"2023-03-07T14:25:44Z","title":"The BigScience ROOTS Corpus: A 1.6TB Composite Multilingual Dataset","summary":"  As language models grow ever larger, the need for large-scale high-quality\ntext datasets has never been more pressing, especially in multilingual\nsettings. The BigScience workshop, a 1-year international and multidisciplinary\ninitiative, was formed with the goal of researching and training large language\nmodels as a values-driven undertaking, putting issues of ethics, harm, and\ngovernance in the foreground. This paper documents the data creation and\ncuration efforts undertaken by BigScience to assemble the Responsible\nOpen-science Open-collaboration Text Sources (ROOTS) corpus, a 1.6TB dataset\nspanning 59 languages that was used to train the 176-billion-parameter\nBigScience Large Open-science Open-access Multilingual (BLOOM) language model.\nWe further release a large initial subset of the corpus and analyses thereof,\nand hope to empower large-scale monolingual and multilingual modeling projects\nwith both the data and the processing tools, as well as stimulate research\naround this large multilingual corpus.\n","authors":["Hugo Laurençon","Lucile Saulnier","Thomas Wang","Christopher Akiki","Albert Villanova del Moral","Teven Le Scao","Leandro Von Werra","Chenghao Mou","Eduardo González Ponferrada","Huu Nguyen","Jörg Frohberg","Mario Šaško","Quentin Lhoest","Angelina McMillan-Major","Gerard Dupont","Stella Biderman","Anna Rogers","Loubna Ben allal","Francesco De Toni","Giada Pistilli","Olivier Nguyen","Somaieh Nikpoor","Maraim Masoud","Pierre Colombo","Javier de la Rosa","Paulo Villegas","Tristan Thrush","Shayne Longpre","Sebastian Nagel","Leon Weber","Manuel Muñoz","Jian Zhu","Daniel Van Strien","Zaid Alyafeai","Khalid Almubarak","Minh Chien Vu","Itziar Gonzalez-Dios","Aitor Soroa","Kyle Lo","Manan Dey","Pedro Ortiz Suarez","Aaron Gokaslan","Shamik Bose","David Adelani","Long Phan","Hieu Tran","Ian Yu","Suhas Pai","Jenny Chim","Violette Lepercq","Suzana Ilic","Margaret Mitchell","Sasha Alexandra Luccioni","Yacine Jernite"],"pdf_url":"https://arxiv.org/pdf/2303.03915v1.pdf","comment":"NeurIPS 2022, Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2303.03912v1","updated":"2023-03-07T14:14:12Z","published":"2023-03-07T14:14:12Z","title":"Document-level Relation Extraction with Cross-sentence Reasoning Graph","summary":"  Relation extraction (RE) has recently moved from the sentence-level to\ndocument-level, which requires aggregating document information and using\nentities and mentions for reasoning. Existing works put entity nodes and\nmention nodes with similar representations in a document-level graph, whose\ncomplex edges may incur redundant information. Furthermore, existing studies\nonly focus on entity-level reasoning paths without considering global\ninteractions among entities cross-sentence. To these ends, we propose a novel\ndocument-level RE model with a GRaph information Aggregation and Cross-sentence\nReasoning network (GRACR). Specifically, a simplified document-level graph is\nconstructed to model the semantic information of all mentions and sentences in\na document, and an entity-level graph is designed to explore relations of\nlong-distance cross-sentence entity pairs. Experimental results show that GRACR\nachieves excellent performance on two public datasets of document-level RE. It\nis especially effective in extracting potential relations of cross-sentence\nentity pairs. Our code is available at https://github.com/UESTC-LHF/GRACR.\n","authors":["Hongfei Liu","Zhao Kang","Lizong Zhang","Ling Tian","Fujun Hua"],"pdf_url":"https://arxiv.org/pdf/2303.03912v1.pdf","comment":"This paper is accepted by PAKDD 2023"},{"id":"http://arxiv.org/abs/2303.03846v1","updated":"2023-03-07T12:24:17Z","published":"2023-03-07T12:24:17Z","title":"Larger language models do in-context learning differently","summary":"  We study how in-context learning (ICL) in language models is affected by\nsemantic priors versus input-label mappings. We investigate two setups-ICL with\nflipped labels and ICL with semantically-unrelated labels-across various model\nfamilies (GPT-3, InstructGPT, Codex, PaLM, and Flan-PaLM). First, experiments\non ICL with flipped labels show that overriding semantic priors is an emergent\nability of model scale. While small language models ignore flipped labels\npresented in-context and thus rely primarily on semantic priors from\npretraining, large models can override semantic priors when presented with\nin-context exemplars that contradict priors, despite the stronger semantic\npriors that larger models may hold. We next study semantically-unrelated label\nICL (SUL-ICL), in which labels are semantically unrelated to their inputs\n(e.g., foo/bar instead of negative/positive), thereby forcing language models\nto learn the input-label mappings shown in in-context exemplars in order to\nperform the task. The ability to do SUL-ICL also emerges primarily with scale,\nand large-enough language models can even perform linear classification in a\nSUL-ICL setting. Finally, we evaluate instruction-tuned models and find that\ninstruction tuning strengthens both the use of semantic priors and the capacity\nto learn input-label mappings, but more of the former.\n","authors":["Jerry Wei","Jason Wei","Yi Tay","Dustin Tran","Albert Webson","Yifeng Lu","Xinyun Chen","Hanxiao Liu","Da Huang","Denny Zhou","Tengyu Ma"],"pdf_url":"https://arxiv.org/pdf/2303.03846v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.13149v2","updated":"2023-03-07T12:22:00Z","published":"2023-02-25T20:24:58Z","title":"STACC: Code Comment Classification using SentenceTransformers","summary":"  Code comments are a key resource for information about software artefacts.\nDepending on the use case, only some types of comments are useful. Thus,\nautomatic approaches to classify these comments have been proposed. In this\nwork, we address this need by proposing, STACC, a set of\nSentenceTransformers-based binary classifiers. These lightweight classifiers\nare trained and tested on the NLBSE Code Comment Classification tool\ncompetition dataset, and surpass the baseline by a significant margin,\nachieving an average F1 score of 0.74 against the baseline of 0.31, which is an\nimprovement of 139%. A replication package, as well as the models themselves,\nare publicly available.\n","authors":["Ali Al-Kaswan","Maliheh Izadi","Arie van Deursen"],"pdf_url":"https://arxiv.org/pdf/2302.13149v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03840v1","updated":"2023-03-07T12:10:47Z","published":"2023-03-07T12:10:47Z","title":"A Challenging Benchmark for Low-Resource Learning","summary":"  With promising yet saturated results in high-resource settings, low-resource\ndatasets have gradually become popular benchmarks for evaluating the learning\nability of advanced neural networks (e.g., BigBench, superGLUE). Some models\neven surpass humans according to benchmark test results. However, we find that\nthere exists a set of hard examples in low-resource settings that challenge\nneural networks but are not well evaluated, which causes over-estimated\nperformance. We first give a theoretical analysis on which factors bring the\ndifficulty of low-resource learning. It then motivate us to propose a\nchallenging benchmark hardBench to better evaluate the learning ability, which\ncovers 11 datasets, including 3 computer vision (CV) datasets and 8 natural\nlanguage process (NLP) datasets. Experiments on a wide range of models show\nthat neural networks, even pre-trained language models, have sharp performance\ndrops on our benchmark, demonstrating the effectiveness on evaluating the\nweaknesses of neural networks. On NLP tasks, we surprisingly find that despite\nbetter results on traditional low-resource benchmarks, pre-trained networks,\ndoes not show performance improvements on our benchmarks. These results\ndemonstrate that there are still a large robustness gap between existing models\nand human-level performance.\n","authors":["Yudong Wang","Chang Ma","Qingxiu Dong","Lingpeng Kong","Jingjing Xu"],"pdf_url":"https://arxiv.org/pdf/2303.03840v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03836v1","updated":"2023-03-07T12:03:58Z","published":"2023-03-07T12:03:58Z","title":"Exploring the Feasibility of ChatGPT for Event Extraction","summary":"  Event extraction is a fundamental task in natural language processing that\ninvolves identifying and extracting information about events mentioned in text.\nHowever, it is a challenging task due to the lack of annotated data, which is\nexpensive and time-consuming to obtain. The emergence of large language models\n(LLMs) such as ChatGPT provides an opportunity to solve language tasks with\nsimple prompts without the need for task-specific datasets and fine-tuning.\nWhile ChatGPT has demonstrated impressive results in tasks like machine\ntranslation, text summarization, and question answering, it presents challenges\nwhen used for complex tasks like event extraction. Unlike other tasks, event\nextraction requires the model to be provided with a complex set of instructions\ndefining all event types and their schemas. To explore the feasibility of\nChatGPT for event extraction and the challenges it poses, we conducted a series\nof experiments. Our results show that ChatGPT has, on average, only 51.04% of\nthe performance of a task-specific model such as EEQA in long-tail and complex\nscenarios. Our usability testing experiments indicate that ChatGPT is not\nrobust enough, and continuous refinement of the prompt does not lead to stable\nperformance improvements, which can result in a poor user experience. Besides,\nChatGPT is highly sensitive to different prompt styles.\n","authors":["Jun Gao","Huan Zhao","Changlong Yu","Ruifeng Xu"],"pdf_url":"https://arxiv.org/pdf/2303.03836v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.07017v2","updated":"2023-03-07T12:01:36Z","published":"2022-10-13T13:25:22Z","title":"ComSearch: Equation Searching with Combinatorial Strategy for Solving\n  Math Word Problems with Weak Supervision","summary":"  Previous studies have introduced a weakly-supervised paradigm for solving\nmath word problems requiring only the answer value annotation. While these\nmethods search for correct value equation candidates as pseudo labels, they\nsearch among a narrow sub-space of the enormous equation space. To address this\nproblem, we propose a novel search algorithm with combinatorial strategy\n\\textbf{ComSearch}, which can compress the search space by excluding\nmathematically equivalent equations. The compression allows the searching\nalgorithm to enumerate all possible equations and obtain high-quality data. We\ninvestigate the noise in the pseudo labels that hold wrong mathematical logic,\nwhich we refer to as the \\textit{false-matching} problem, and propose a ranking\nmodel to denoise the pseudo labels. Our approach holds a flexible framework to\nutilize two existing supervised math word problem solvers to train pseudo\nlabels, and both achieve state-of-the-art performance in the weak supervision\ntask.\n","authors":["Qianying Liu","Wenyu Guan","Jianhao Shen","Fei Cheng","Sadao Kurohashi"],"pdf_url":"https://arxiv.org/pdf/2210.07017v2.pdf","comment":"EACL 2023 long paper, 14 pages"},{"id":"http://arxiv.org/abs/2301.04388v2","updated":"2023-03-07T11:09:29Z","published":"2023-01-11T10:20:56Z","title":"Perceive and predict: self-supervised speech representation based loss\n  functions for speech enhancement","summary":"  Recent work in the domain of speech enhancement has explored the use of\nself-supervised speech representations to aid in the training of neural speech\nenhancement models. However, much of this work focuses on using the deepest or\nfinal outputs of self supervised speech representation models, rather than the\nearlier feature encodings. The use of self supervised representations in such a\nway is often not fully motivated. In this work it is shown that the distance\nbetween the feature encodings of clean and noisy speech correlate strongly with\npsychoacoustically motivated measures of speech quality and intelligibility, as\nwell as with human Mean Opinion Score (MOS) ratings. Experiments using this\ndistance as a loss function are performed and improved performance over the use\nof STFT spectrogram distance based loss as well as other common loss functions\nfrom speech enhancement literature is demonstrated using objective measures\nsuch as perceptual evaluation of speech quality (PESQ) and short-time objective\nintelligibility (STOI).\n","authors":["George Close","William Ravenscroft","Thomas Hain","Stefan Goetze"],"pdf_url":"https://arxiv.org/pdf/2301.04388v2.pdf","comment":"4 pages, accepted at ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.03750v1","updated":"2023-03-07T09:20:09Z","published":"2023-03-07T09:20:09Z","title":"Preparing the Vuk'uzenzele and ZA-gov-multilingual South African\n  multilingual corpora","summary":"  This paper introduces two multilingual government themed corpora in various\nSouth African languages. The corpora were collected by gathering the South\nAfrican Government newspaper (Vuk'uzenzele), as well as South African\ngovernment speeches (ZA-gov-multilingual), that are translated into all 11\nSouth African official languages. The corpora can be used for a myriad of\ndownstream NLP tasks. The corpora were created to allow researchers to study\nthe language used in South African government publications, with a focus on\nunderstanding how South African government officials communicate with their\nconstituents.\n  In this paper we highlight the process of gathering, cleaning and making\navailable the corpora. We create parallel sentence corpora for Neural Machine\nTranslation (NMT) tasks using Language-Agnostic Sentence Representations\n(LASER) embeddings. With these aligned sentences we then provide NMT benchmarks\nfor 9 indigenous languages by fine-tuning a massively multilingual pre-trained\nlanguage model. \\end{abstra\n","authors":["Richard Lastrucci","Isheanesu Dzingirai","Jenalea Rajab","Andani Madodonga","Matimba Shingange","Daniel Njini","Vukosi Marivate"],"pdf_url":"https://arxiv.org/pdf/2303.03750v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2303.03715v1","updated":"2023-03-07T07:56:38Z","published":"2023-03-07T07:56:38Z","title":"Universal resources for quantum computing","summary":"  Unravelling the source of quantum computing power has been a major goal in\nthe field of quantum information science. In recent years, the quantum resource\ntheory (QRT) has been established to characterize various quantum resources,\nyet their roles in quantum computing tasks still require investigation. The\nso-called universal quantum computing model (UQCM), e.g., the circuit model,\nhas been the main framework to guide the design of quantum algorithms, creation\nof real quantum computers etc. In this work, we combine the study of UQCM\ntogether with QRT. We find on one hand, using QRT can provide a\nresource-theoretic characterization of a UQCM, the relation among models and\ninspire new ones, and on the other hand, using UQCM offers a framework to apply\nresources, study relation among resources and classify them.\n  We develop the theory of universal resources in the setting of UQCM, and find\na rich spectrum of UQCMs and the corresponding universal resources. Depending\non a hierarchical structure of resource theories, we find models can be\nclassified into families. In this work, we study three natural families of\nUQCMs in details: the amplitude family, the quasi-probability family, and the\nHamiltonian family. They include some well known models, like the\nmeasurement-based model and adiabatic model, and also inspire new models such\nas the contextual model we introduce. Each family contains at least a triplet\nof models, and such a succinct structure of families of UQCMs offers a unifying\npicture to investigate resources and design models. It also provides a rigorous\nframework to resolve puzzles, such as the role of entanglement vs.\ninterference, and unravel resource-theoretic features of quantum algorithms.\n","authors":["Dong-Sheng Wang"],"pdf_url":"https://arxiv.org/pdf/2303.03715v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.09856v3","updated":"2023-03-07T07:53:35Z","published":"2023-02-20T09:38:11Z","title":"Knowledge-aware Bayesian Co-attention for Multimodal Emotion Recognition","summary":"  Multimodal emotion recognition is a challenging research area that aims to\nfuse different modalities to predict human emotion. However, most existing\nmodels that are based on attention mechanisms have difficulty in learning\nemotionally relevant parts on their own. To solve this problem, we propose to\nincorporate external emotion-related knowledge in the co-attention based fusion\nof pre-trained models. To effectively incorporate this knowledge, we enhance\nthe co-attention model with a Bayesian attention module (BAM) where a prior\ndistribution is estimated using the emotion-related knowledge. Experimental\nresults on the IEMOCAP dataset show that the proposed approach can outperform\nseveral state-of-the-art approaches by at least 0.7% unweighted accuracy (UA).\n","authors":["Zihan Zhao","Yu Wang","Yanfeng Wang"],"pdf_url":"https://arxiv.org/pdf/2302.09856v3.pdf","comment":"Accepted to IEEE ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.03706v1","updated":"2023-03-07T07:42:26Z","published":"2023-03-07T07:42:26Z","title":"Classifying Text-Based Conspiracy Tweets related to COVID-19 using\n  Contextualized Word Embeddings","summary":"  The FakeNews task in MediaEval 2022 investigates the challenge of finding\naccurate and high-performance models for the classification of conspiracy\ntweets related to COVID-19. In this paper, we used BERT, ELMO, and their\ncombination for feature extraction and RandomForest as classifier. The results\nshow that ELMO performs slightly better than BERT, however their combination at\nfeature level reduces the performance.\n","authors":["Abdul Rehman","Rabeeh Ayaz Abbasi","Irfan ul Haq Qureshi","Akmal Saeed Khattak"],"pdf_url":"https://arxiv.org/pdf/2303.03706v1.pdf","comment":"Published in Multimedia Benchmark Workshop 2022, Bergen, Norway and\n  Online, 12-13 January 2023: https://2022.multimediaeval.com/"},{"id":"http://arxiv.org/abs/2303.03697v1","updated":"2023-03-07T07:26:09Z","published":"2023-03-07T07:26:09Z","title":"Stylometric Detection of AI-Generated Text in Twitter Timelines","summary":"  Recent advancements in pre-trained language models have enabled convenient\nmethods for generating human-like text at a large scale. Though these\ngeneration capabilities hold great potential for breakthrough applications, it\ncan also be a tool for an adversary to generate misinformation. In particular,\nsocial media platforms like Twitter are highly susceptible to AI-generated\nmisinformation. A potential threat scenario is when an adversary hijacks a\ncredible user account and incorporates a natural language generator to generate\nmisinformation. Such threats necessitate automated detectors for AI-generated\ntweets in a given user's Twitter timeline. However, tweets are inherently\nshort, thus making it difficult for current state-of-the-art pre-trained\nlanguage model-based detectors to accurately detect at what point the AI starts\nto generate tweets in a given Twitter timeline. In this paper, we present a\nnovel algorithm using stylometric signals to aid detecting AI-generated tweets.\nWe propose models corresponding to quantifying stylistic changes in human and\nAI tweets in two related tasks: Task 1 - discriminate between human and\nAI-generated tweets, and Task 2 - detect if and when an AI starts to generate\ntweets in a given Twitter timeline. Our extensive experiments demonstrate that\nthe stylometric features are effective in augmenting the state-of-the-art\nAI-generated text detectors.\n","authors":["Tharindu Kumarage","Joshua Garland","Amrita Bhattacharjee","Kirill Trapeznikov","Scott Ruston","Huan Liu"],"pdf_url":"https://arxiv.org/pdf/2303.03697v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.09865v2","updated":"2023-03-07T07:23:38Z","published":"2023-02-20T09:56:51Z","title":"Can discrete information extraction prompts generalize across language\n  models?","summary":"  We study whether automatically-induced prompts that effectively extract\ninformation from a language model can also be used, out-of-the-box, to probe\nother language models for the same information. After confirming that discrete\nprompts induced with the AutoPrompt algorithm outperform manual and semi-manual\nprompts on the slot-filling task, we demonstrate a drop in performance for\nAutoPrompt prompts learned on a model and tested on another. We introduce a way\nto induce prompts by mixing language models at training time that results in\nprompts that generalize well across models. We conduct an extensive analysis of\nthe induced prompts, finding that the more general prompts include a larger\nproportion of existing English words and have a less order-dependent and more\nuniform distribution of information across their component tokens. Our work\nprovides preliminary evidence that it's possible to generate discrete prompts\nthat can be induced once and used with a number of different models, and gives\ninsights on the properties characterizing such prompts.\n","authors":["Nathanaël Carraz Rakotonirina","Roberto Dessì","Fabio Petroni","Sebastian Riedel","Marco Baroni"],"pdf_url":"https://arxiv.org/pdf/2302.09865v2.pdf","comment":"Published as conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2302.08220v2","updated":"2023-03-07T07:00:35Z","published":"2023-02-16T11:05:24Z","title":"Dialogue State Distillation Network with Inter-slot Contrastive Learning\n  for Dialogue State Tracking","summary":"  In task-oriented dialogue systems, Dialogue State Tracking (DST) aims to\nextract users' intentions from the dialogue history. Currently, most existing\napproaches suffer from error propagation and are unable to dynamically select\nrelevant information when utilizing previous dialogue states. Moreover, the\nrelations between the updates of different slots provide vital clues for DST.\nHowever, the existing approaches rely only on predefined graphs to indirectly\ncapture the relations. In this paper, we propose a Dialogue State Distillation\nNetwork (DSDN) to utilize relevant information of previous dialogue states and\nmigrate the gap of utilization between training and testing. Thus, it can\ndynamically exploit previous dialogue states and avoid introducing error\npropagation simultaneously. Further, we propose an inter-slot contrastive\nlearning loss to effectively capture the slot co-update relations from dialogue\ncontext. Experiments are conducted on the widely used MultiWOZ 2.0 and MultiWOZ\n2.1 datasets. The experimental results show that our proposed model achieves\nthe state-of-the-art performance for DST.\n","authors":["Jing Xu","Dandan Song","Chong Liu","Siu Cheung Hui","Fei Li","Qiang Ju","Xiaonan He","Jian Xie"],"pdf_url":"https://arxiv.org/pdf/2302.08220v2.pdf","comment":"Accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2302.10166v3","updated":"2023-03-07T06:47:30Z","published":"2023-02-20T18:53:56Z","title":"Learning Deep Semantics for Test Completion","summary":"  Writing tests is a time-consuming yet essential task during software\ndevelopment. We propose to leverage recent advances in deep learning for text\nand code generation to assist developers in writing tests. We formalize the\nnovel task of test completion to automatically complete the next statement in a\ntest method based on the context of prior statements and the code under test.\nWe develop TeCo -- a deep learning model using code semantics for test\ncompletion. The key insight underlying TeCo is that predicting the next\nstatement in a test method requires reasoning about code execution, which is\nhard to do with only syntax-level data that existing code completion models\nuse. TeCo extracts and uses six kinds of code semantics data, including the\nexecution result of prior statements and the execution context of the test\nmethod. To provide a testbed for this new task, as well as to evaluate TeCo, we\ncollect a corpus of 130,934 test methods from 1,270 open-source Java projects.\nOur results show that TeCo achieves an exact-match accuracy of 18, which is 29%\nhigher than the best baseline using syntax-level data only. When measuring\nfunctional correctness of generated next statement, TeCo can generate runnable\ncode in 29% of the cases compared to 18% obtained by the best baseline.\nMoreover, TeCo is significantly better than prior work on test oracle\ngeneration.\n","authors":["Pengyu Nie","Rahul Banerjee","Junyi Jessy Li","Raymond J. Mooney","Milos Gligoric"],"pdf_url":"https://arxiv.org/pdf/2302.10166v3.pdf","comment":"Accepted as a conference paper in ICSE 2023"},{"id":"http://arxiv.org/abs/2303.01248v2","updated":"2023-03-07T05:35:39Z","published":"2023-03-01T06:16:14Z","title":"Can ChatGPT Assess Human Personalities? A General Evaluation Framework","summary":"  Large Language Models (LLMs) especially ChatGPT have produced impressive\nresults in various areas, but their potential human-like psychology is still\nlargely unexplored. Existing works study the virtual personalities of LLMs but\nrarely explore the possibility of analyzing human personalities via LLMs. This\npaper presents a generic evaluation framework for LLMs to assess human\npersonalities based on Myers Briggs Type Indicator (MBTI) tests. Specifically,\nwe first devise unbiased prompts by randomly permuting options in MBTI\nquestions and adopt the average testing result to encourage more impartial\nanswer generation. Then, we propose to replace the subject in question\nstatements to enable flexible queries and assessments on different subjects\nfrom LLMs. Finally, we re-formulate the question instructions in a manner of\ncorrectness evaluation to facilitate LLMs to generate clearer responses. The\nproposed framework enables LLMs to flexibly assess personalities of different\ngroups of people. We further propose three evaluation metrics to measure the\nconsistency, robustness, and fairness of assessment results from\nstate-of-the-art LLMs including ChatGPT and InstructGPT. Our experiments reveal\nChatGPT's ability to assess human personalities, and the average results\ndemonstrate that it can achieve more consistent and fairer assessments in spite\nof lower robustness against prompt biases compared with InstructGPT.\n","authors":["Haocong Rao","Cyril Leung","Chunyan Miao"],"pdf_url":"https://arxiv.org/pdf/2303.01248v2.pdf","comment":"Our codes are available at https://github.com/Kali-Hac/ChatGPT-MBTI"},{"id":"http://arxiv.org/abs/2303.03628v1","updated":"2023-03-07T03:23:14Z","published":"2023-03-07T03:23:14Z","title":"CoTEVer: Chain of Thought Prompting Annotation Toolkit for Explanation\n  Verification","summary":"  Chain-of-thought (CoT) prompting enables large language models (LLMs) to\nsolve complex reasoning tasks by generating an explanation before the final\nprediction. Despite it's promising ability, a critical downside of CoT\nprompting is that the performance is greatly affected by the factuality of the\ngenerated explanation. To improve the correctness of the explanations,\nfine-tuning language models with explanation data is needed. However, there\nexists only a few datasets that can be used for such approaches, and no data\ncollection tool for building them. Thus, we introduce CoTEVer, a tool-kit for\nannotating the factual correctness of generated explanations and collecting\nrevision data of wrong explanations. Furthermore, we suggest several use cases\nwhere the data collected with CoTEVer can be utilized for enhancing the\nfaithfulness of explanations. Our toolkit is publicly available at\nhttps://github.com/SeungoneKim/CoTEVer.\n","authors":["Seungone Kim","Se June Joo","Yul Jang","Hyungjoo Chae","Jinyoung Yeo"],"pdf_url":"https://arxiv.org/pdf/2303.03628v1.pdf","comment":"Accepted at EACL 2023 Demo"},{"id":"http://arxiv.org/abs/2303.03608v1","updated":"2023-03-07T02:49:50Z","published":"2023-03-07T02:49:50Z","title":"Towards Interpretable and Efficient Automatic Reference-Based\n  Summarization Evaluation","summary":"  Interpretability and efficiency are two important considerations for the\nadoption of neural automatic metrics. In this work, we develop\nstrong-performing automatic metrics for reference-based summarization\nevaluation, based on a two-stage evaluation pipeline that first extracts basic\ninformation units from one text sequence and then checks the extracted units in\nanother sequence. The metrics we developed include two-stage metrics that can\nprovide high interpretability at both the fine-grained unit level and summary\nlevel, and one-stage metrics that achieve a balance between efficiency and\ninteroperability. We make the developed tools publicly available through a\nPython package and GitHub.\n","authors":["Yixin Liu","Alexander R. Fabbri","Yilun Zhao","Pengfei Liu","Shafiq Joty","Chien-Sheng Wu","Caiming Xiong","Dragomir Radev"],"pdf_url":"https://arxiv.org/pdf/2303.03608v1.pdf","comment":"GitHub Repo: https://github.com/Yale-LILY/AutoACU"},{"id":"http://arxiv.org/abs/2303.03600v1","updated":"2023-03-07T02:31:57Z","published":"2023-03-07T02:31:57Z","title":"Adaptive Knowledge Distillation between Text and Speech Pre-trained\n  Models","summary":"  Learning on a massive amount of speech corpus leads to the recent success of\nmany self-supervised speech models. With knowledge distillation, these models\nmay also benefit from the knowledge encoded by language models that are\npre-trained on rich sources of texts. The distillation process, however, is\nchallenging due to the modal disparity between textual and speech embedding\nspaces. This paper studies metric-based distillation to align the embedding\nspace of text and speech with only a small amount of data without modifying the\nmodel structure. Since the semantic and granularity gap between text and speech\nhas been omitted in literature, which impairs the distillation, we propose the\nPrior-informed Adaptive knowledge Distillation (PAD) that adaptively leverages\ntext/speech units of variable granularity and prior distributions to achieve\nbetter global and local alignments between text and speech pre-trained models.\nWe evaluate on three spoken language understanding benchmarks to show that PAD\nis more effective in transferring linguistic knowledge than other metric-based\ndistillation approaches.\n","authors":["Jinjie Ni","Yukun Ma","Wen Wang","Qian Chen","Dianwen Ng","Han Lei","Trung Hieu Nguyen","Chong Zhang","Bin Ma","Erik Cambria"],"pdf_url":"https://arxiv.org/pdf/2303.03600v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03593v1","updated":"2023-03-07T01:57:10Z","published":"2023-03-07T01:57:10Z","title":"ADELT: Transpilation Between Deep Learning Frameworks","summary":"  We propose Adversarial DEep Learning Transpiler (ADELT) for source-to-source\ntranspilation between deep learning frameworks. Unlike prior approaches, we\ndecouple the transpilation of code skeletons and the mapping of API keywords\n(an API function name or a parameter name). ADELT transpile code skeletons\nusing few-shot prompting on big language models. Based on contextual embeddings\nextracted by a BERT for code, we train aligned API embeddings in a\ndomain-adversarial setup, upon which we generate a dictionary for keyword\ntranslation. The model is trained on our unlabeled DL corpus from web crawl\ndata, without using any hand-crafted rules and parallel data. Our method\noutperforms state-of-the-art transpilers on multiple transpilation pairs\nincluding PyTorch-Keras and PyTorch-MXNet by 15.9pts and 12.0pts in exact match\nscores respectively.\n","authors":["Linyuan Gong","Jiayi Wang","Alvin Cheung"],"pdf_url":"https://arxiv.org/pdf/2303.03593v1.pdf","comment":"23 pages"}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2303.04143v1","updated":"2023-03-07T18:56:59Z","published":"2023-03-07T18:56:59Z","title":"Can We Scale Transformers to Predict Parameters of Diverse ImageNet\n  Models?","summary":"  Pretraining a neural network on a large dataset is becoming a cornerstone in\nmachine learning that is within the reach of only a few communities with\nlarge-resources. We aim at an ambitious goal of democratizing pretraining.\nTowards that goal, we train and release a single neural network that can\npredict high quality ImageNet parameters of other neural networks. By using\npredicted parameters for initialization we are able to boost training of\ndiverse ImageNet models available in PyTorch. When transferred to other\ndatasets, models initialized with predicted parameters also converge faster and\nreach competitive final performance.\n","authors":["Boris Knyazev","Doha Hwang","Simon Lacoste-Julien"],"pdf_url":"https://arxiv.org/pdf/2303.04143v1.pdf","comment":"Code and models are available at\n  https://github.com/SamsungSAILMontreal/ghn3"},{"id":"http://arxiv.org/abs/2303.04116v1","updated":"2023-03-07T18:28:41Z","published":"2023-03-07T18:28:41Z","title":"TrafficBots: Towards World Models for Autonomous Driving Simulation and\n  Motion Prediction","summary":"  Data-driven simulation has become a favorable way to train and test\nautonomous driving algorithms. The idea of replacing the actual environment\nwith a learned simulator has also been explored in model-based reinforcement\nlearning in the context of world models. In this work, we show data-driven\ntraffic simulation can be formulated as a world model. We present TrafficBots,\na multi-agent policy built upon motion prediction and end-to-end driving, and\nbased on TrafficBots we obtain a world model tailored for the planning module\nof autonomous vehicles. Existing data-driven traffic simulators are lacking\nconfigurability and scalability. To generate configurable behaviors, for each\nagent we introduce a destination as navigational information, and a\ntime-invariant latent personality that specifies the behavioral style. To\nimprove the scalability, we present a new scheme of positional encoding for\nangles, allowing all agents to share the same vectorized context and the use of\nan architecture based on dot-product attention. As a result, we can simulate\nall traffic participants seen in dense urban scenarios. Experiments on the\nWaymo open motion dataset show TrafficBots can simulate realistic multi-agent\nbehaviors and achieve good performance on the motion prediction task.\n","authors":["Zhejun Zhang","Alexander Liniger","Dengxin Dai","Fisher Yu","Luc Van Gool"],"pdf_url":"https://arxiv.org/pdf/2303.04116v1.pdf","comment":"Accepted at ICRA 2023. The repository is available at\n  https://github.com/SysCV/TrafficBots"},{"id":"http://arxiv.org/abs/2303.04115v1","updated":"2023-03-07T18:28:39Z","published":"2023-03-07T18:28:39Z","title":"Predicted Embedding Power Regression for Large-Scale Out-of-Distribution\n  Detection","summary":"  Out-of-distribution (OOD) inputs can compromise the performance and safety of\nreal world machine learning systems. While many methods exist for OOD detection\nand work well on small scale datasets with lower resolution and few classes,\nfew methods have been developed for large-scale OOD detection. Existing\nlarge-scale methods generally depend on maximum classification probability,\nsuch as the state-of-the-art grouped softmax method. In this work, we develop a\nnovel approach that calculates the probability of the predicted class label\nbased on label distributions learned during the training process. Our method\nperforms better than current state-of-the-art methods with only a negligible\nincrease in compute cost. We evaluate our method against contemporary methods\nacross $14$ datasets and achieve a statistically significant improvement with\nrespect to AUROC (84.2 vs 82.4) and AUPR (96.2 vs 93.7).\n","authors":["Hong Yang","William Gebhardt","Alexander G. Ororbia","Travis Desell"],"pdf_url":"https://arxiv.org/pdf/2303.04115v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04105v1","updated":"2023-03-07T18:12:24Z","published":"2023-03-07T18:12:24Z","title":"Introspective Cross-Attention Probing for Lightweight Transfer of\n  Pre-trained Models","summary":"  We propose InCA, a lightweight method for transfer learning that\ncross-attends to any activation layer of a pre-trained model. During training,\nInCA uses a single forward pass to extract multiple activations, which are\npassed to external cross-attention adapters, trained anew and combined or\nselected for downstream tasks. We show that, even when selecting a single\ntop-scoring adapter, InCA achieves performance comparable to full fine-tuning,\nat a cost comparable to fine-tuning just the last layer. For example, with a\ncross-attention probe 1.3% the size of a pre-trained ViT-L/16 model, we achieve\nperformance within 0.2% of the full fine-tuning paragon at 51% training cost of\nthe baseline, on average across 11 downstream classification tasks. Unlike\nother forms of efficient adaptation, InCA does not require backpropagating\nthrough the pre-trained model, thus leaving its execution unaltered at both\ntraining and inference. The versatility of InCA is best illustrated in\nfine-grained tasks, which may require accessing information absent in the last\nlayer but accessible in intermediate layer activations. Since the backbone is\nfixed, InCA allows parallel ensembling as well as parallel execution of\nmultiple tasks. InCA achieves state-of-the-art performance in the\nImageNet-to-Sketch multi-task benchmark.\n","authors":["Yonatan Dukler","Alessandro Achille","Hao Yang","Varsha Vivek","Luca Zancato","Ben Bowman","Avinash Ravichandran","Charless Fowlkes","Ashwin Swaminathan","Stefano Soatto"],"pdf_url":"https://arxiv.org/pdf/2303.04105v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04086v1","updated":"2023-03-07T17:47:33Z","published":"2023-03-07T17:47:33Z","title":"NEPHELE: A Neural Platform for Highly Realistic Cloud Radiance Rendering","summary":"  We have recently seen tremendous progress in neural rendering (NR) advances,\ni.e., NeRF, for photo-real free-view synthesis. Yet, as a local technique based\non a single computer/GPU, even the best-engineered Instant-NGP or i-NGP cannot\nreach real-time performance when rendering at a high resolution, and often\nrequires huge local computing resources. In this paper, we resort to cloud\nrendering and present NEPHELE, a neural platform for highly realistic cloud\nradiance rendering. In stark contrast with existing NR approaches, our NEPHELE\nallows for more powerful rendering capabilities by combining multiple remote\nGPUs and facilitates collaboration by allowing multiple people to view the same\nNeRF scene simultaneously. We introduce i-NOLF to employ opacity light fields\nfor ultra-fast neural radiance rendering in a one-query-per-ray manner. We\nfurther resemble the Lumigraph with geometry proxies for fast ray querying and\nsubsequently employ a small MLP to model the local opacity lumishperes for\nhigh-quality rendering. We also adopt Perfect Spatial Hashing in i-NOLF to\nenhance cache coherence. As a result, our i-NOLF achieves an order of magnitude\nperformance gain in terms of efficiency than i-NGP, especially for the\nmulti-user multi-viewpoint setting under cloud rendering scenarios. We further\ntailor a task scheduler accompanied by our i-NOLF representation and\ndemonstrate the advance of our methodological design through a comprehensive\ncloud platform, consisting of a series of cooperated modules, i.e., render\nfarms, task assigner, frame composer, and detailed streaming strategies. Using\nsuch a cloud platform compatible with neural rendering, we further showcase the\ncapabilities of our cloud radiance rendering through a series of applications,\nranging from cloud VR/AR rendering.\n","authors":["Haimin Luo","Siyuan Zhang","Fuqiang Zhao","Haotian Jing","Penghao Wang","Zhenxiao Yu","Dongxue Yan","Junran Ding","Boyuan Zhang","Qiang Hu","Shu Yin","Lan Xu","JIngyi Yu"],"pdf_url":"https://arxiv.org/pdf/2303.04086v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04077v1","updated":"2023-03-07T17:39:53Z","published":"2023-03-07T17:39:53Z","title":"Meta-Explore: Exploratory Hierarchical Vision-and-Language Navigation\n  Using Scene Object Spectrum Grounding","summary":"  The main challenge in vision-and-language navigation (VLN) is how to\nunderstand natural-language instructions in an unseen environment. The main\nlimitation of conventional VLN algorithms is that if an action is mistaken, the\nagent fails to follow the instructions or explores unnecessary regions, leading\nthe agent to an irrecoverable path. To tackle this problem, we propose\nMeta-Explore, a hierarchical navigation method deploying an exploitation policy\nto correct misled recent actions. We show that an exploitation policy, which\nmoves the agent toward a well-chosen local goal among unvisited but observable\nstates, outperforms a method which moves the agent to a previously visited\nstate. We also highlight the demand for imagining regretful explorations with\nsemantically meaningful clues. The key to our approach is understanding the\nobject placements around the agent in spectral-domain. Specifically, we present\na novel visual representation, called scene object spectrum (SOS), which\nperforms category-wise 2D Fourier transform of detected objects. Combining\nexploitation policy and SOS features, the agent can correct its path by\nchoosing a promising local goal. We evaluate our method in three VLN\nbenchmarks: R2R, SOON, and REVERIE. Meta-Explore outperforms other baselines\nand shows significant generalization performance. In addition, local goal\nsearch using the proposed spectral-domain SOS features significantly improves\nthe success rate by 17.1% and SPL by 20.6% for the SOON benchmark.\n","authors":["Minyoung Hwang","Jaeyeon Jeong","Minsoo Kim","Yoonseon Oh","Songhwai Oh"],"pdf_url":"https://arxiv.org/pdf/2303.04077v1.pdf","comment":"Accepted by CVPR 2023. Project page:\n  https://rllab-snu.github.io/projects/Meta-Explore/doc.html"},{"id":"http://arxiv.org/abs/2303.04068v1","updated":"2023-03-07T17:26:04Z","published":"2023-03-07T17:26:04Z","title":"VOCALExplore: Pay-as-You-Go Video Data Exploration and Model Building","summary":"  We introduce VOCALExplore, a system designed to support users in building\ndomain-specific models over video datasets. VOCALExplore supports interactive\nlabeling sessions and trains models using user-supplied labels. VOCALExplore\nmaximizes model quality by automatically deciding how to select samples based\non observed skew in the collected labels. It also selects the optimal video\nrepresentations to use when training models by casting feature selection as a\nrising bandit problem. Finally, VOCALExplore implements optimizations to\nachieve low latency without sacrificing model performance. We demonstrate that\nVOCALExplore achieves close to the best possible model quality given candidate\nacquisition functions and feature extractors, and it does so with low visible\nlatency (~1 second per iteration) and no expensive preprocessing.\n","authors":["Maureen Daum","Enhao Zhang","Dong He","Stephen Mussmann","Brandon Haynes","Ranjay Krishna","Magdalena Balazinska"],"pdf_url":"https://arxiv.org/pdf/2303.04068v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.07530v3","updated":"2023-03-07T17:24:32Z","published":"2022-03-14T22:34:10Z","title":"TTCDist: Fast Distance Estimation From an Active Monocular Camera Using\n  Time-to-Contact","summary":"  Distance estimation from vision is fundamental for a myriad of robotic\napplications such as navigation, manipulation, and planning. Inspired by the\nmammal's visual system, which gazes at specific objects, we develop two novel\nconstraints relating time-to-contact, acceleration, and distance that we call\nthe $\\tau$-constraint and $\\Phi$-constraint. They allow an active (moving)\ncamera to estimate depth efficiently and accurately while using only a small\nportion of the image. The constraints are applicable to range sensing, sensor\nfusion, and visual servoing.\n  We successfully validate the proposed constraints with two experiments. The\nfirst applies both constraints in a trajectory estimation task with a monocular\ncamera and an Inertial Measurement Unit (IMU). Our methods achieve 30-70% less\naverage trajectory error while running 25$\\times$ and 6.2$\\times$ faster than\nthe popular Visual-Inertial Odometry methods VINS-Mono and ROVIO respectively.\nThe second experiment demonstrates that when the constraints are used for\nfeedback with efference copies the resulting closed loop system's eigenvalues\nare invariant to scaling of the applied control signal. We believe these\nresults indicate the $\\tau$ and $\\Phi$ constraint's potential as the basis of\nrobust and efficient algorithms for a multitude of robotic applications.\n","authors":["Levi Burner","Nitin J. Sanket","Cornelia Fermüller","Yiannis Aloimonos"],"pdf_url":"https://arxiv.org/pdf/2203.07530v3.pdf","comment":"19 pages, 24 figures, 1 table. To be published in ICRA 2023"},{"id":"http://arxiv.org/abs/2212.12053v2","updated":"2023-03-07T16:41:02Z","published":"2022-12-22T22:05:16Z","title":"On Calibrating Semantic Segmentation Models: Analyses and An Algorithm","summary":"  We study the problem of semantic segmentation calibration. For image\nclassification, lots of existing solutions are proposed to alleviate model\nmiscalibration of confidence. However, to date, confidence calibration research\non semantic segmentation is still limited. We provide a systematic study on the\ncalibration of semantic segmentation models and propose a simple yet effective\napproach. First, we find that model capacity, crop size, multi-scale testing,\nand prediction correctness have impact on calibration. Among them, prediction\ncorrectness, especially misprediction, is more important to miscalibration due\nto over-confidence. Next, we propose a simple, unifying, and effective\napproach, namely selective scaling, by separating correct/incorrect prediction\nfor scaling and more focusing on misprediction logit smoothing. Then, we study\npopular existing calibration methods and compare them with selective scaling on\nsemantic segmentation calibration. We conduct extensive experiments with a\nvariety of benchmarks on both in-domain and domain-shift calibration, and show\nthat selective scaling consistently outperforms other methods.\n","authors":["Dongdong Wang","Boqing Gong","Liqiang Wang"],"pdf_url":"https://arxiv.org/pdf/2212.12053v2.pdf","comment":"Accepted to CVPR2023 (8 pages, 4 figures)"},{"id":"http://arxiv.org/abs/2303.04025v1","updated":"2023-03-07T16:38:50Z","published":"2023-03-07T16:38:50Z","title":"DeepSeeColor: Realtime Adaptive Color Correction for Autonomous\n  Underwater Vehicles via Deep Learning Methods","summary":"  Successful applications of complex vision-based behaviours underwater have\nlagged behind progress in terrestrial and aerial domains. This is largely due\nto the degraded image quality resulting from the physical phenomena involved in\nunderwater image formation. Spectrally-selective light attenuation drains some\ncolors from underwater images while backscattering adds others, making it\nchallenging to perform vision-based tasks underwater. State-of-the-art methods\nfor underwater color correction optimize the parameters of image formation\nmodels to restore the full spectrum of color to underwater imagery. However,\nthese methods have high computational complexity that is unfavourable for\nrealtime use by autonomous underwater vehicles (AUVs), as a result of having\nbeen primarily designed for offline color correction. Here, we present\nDeepSeeColor, a novel algorithm that combines a state-of-the-art underwater\nimage formation model with the computational efficiency of deep learning\nframeworks. In our experiments, we show that DeepSeeColor offers comparable\nperformance to the popular \"Sea-Thru\" algorithm (Akkaynak & Treibitz, 2019)\nwhile being able to rapidly process images at up to 60Hz, thus making it\nsuitable for use onboard AUVs as a preprocessing step to enable more robust\nvision-based behaviours.\n","authors":["Stewart Jamieson","Jonathan P. How","Yogesh Girdhar"],"pdf_url":"https://arxiv.org/pdf/2303.04025v1.pdf","comment":"7 pages, 5 figures, 2 tables. Presented at the 2023 International\n  Conference on Robotics and Automation (ICRA)"},{"id":"http://arxiv.org/abs/2303.04016v1","updated":"2023-03-07T16:31:13Z","published":"2023-03-07T16:31:13Z","title":"Decoupling Skill Learning from Robotic Control for Generalizable Object\n  Manipulation","summary":"  Recent works in robotic manipulation through reinforcement learning (RL) or\nimitation learning (IL) have shown potential for tackling a range of tasks\ne.g., opening a drawer or a cupboard. However, these techniques generalize\npoorly to unseen objects. We conjecture that this is due to the\nhigh-dimensional action space for joint control. In this paper, we take an\nalternative approach and separate the task of learning 'what to do' from 'how\nto do it' i.e., whole-body control. We pose the RL problem as one of\ndetermining the skill dynamics for a disembodied virtual manipulator\ninteracting with articulated objects. The whole-body robotic kinematic control\nis optimized to execute the high-dimensional joint motion to reach the goals in\nthe workspace. It does so by solving a quadratic programming (QP) model with\nrobotic singularity and kinematic constraints. Our experiments on manipulating\ncomplex articulated objects show that the proposed approach is more\ngeneralizable to unseen objects with large intra-class variations,\noutperforming previous approaches. The evaluation results indicate that our\napproach generates more compliant robotic motion and outperforms the pure RL\nand IL baselines in task success rates.\n","authors":["Kai Lu","Bo Yang","Bing Wang","Andrew Markham"],"pdf_url":"https://arxiv.org/pdf/2303.04016v1.pdf","comment":"Accepted to IEEE International Conference on Robotics and Automation\n  (ICRA) 2023"},{"id":"http://arxiv.org/abs/2211.09019v2","updated":"2023-03-07T16:29:49Z","published":"2022-11-16T16:26:48Z","title":"Learning Reward Functions for Robotic Manipulation by Observing Humans","summary":"  Observing a human demonstrator manipulate objects provides a rich, scalable\nand inexpensive source of data for learning robotic policies. However,\ntransferring skills from human videos to a robotic manipulator poses several\nchallenges, not least a difference in action and observation spaces. In this\nwork, we use unlabeled videos of humans solving a wide range of manipulation\ntasks to learn a task-agnostic reward function for robotic manipulation\npolicies. Thanks to the diversity of this training data, the learned reward\nfunction sufficiently generalizes to image observations from a previously\nunseen robot embodiment and environment to provide a meaningful prior for\ndirected exploration in reinforcement learning. We propose two methods for\nscoring states relative to a goal image: through direct temporal regression,\nand through distances in an embedding space obtained with time-contrastive\nlearning. By conditioning the function on a goal image, we are able to reuse\none model across a variety of tasks. Unlike prior work on leveraging human\nvideos to teach robots, our method, Human Offline Learned Distances (HOLD)\nrequires neither a priori data from the robot environment, nor a set of\ntask-specific human demonstrations, nor a predefined notion of correspondence\nacross morphologies, yet it is able to accelerate training of several\nmanipulation tasks on a simulated robot arm compared to using only a sparse\nreward obtained from task completion.\n","authors":["Minttu Alakuijala","Gabriel Dulac-Arnold","Julien Mairal","Jean Ponce","Cordelia Schmid"],"pdf_url":"https://arxiv.org/pdf/2211.09019v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04001v1","updated":"2023-03-07T16:00:26Z","published":"2023-03-07T16:00:26Z","title":"ELODIN: Naming Concepts in Embedding Spaces","summary":"  Despite recent advancements, the field of text-to-image synthesis still\nsuffers from lack of fine-grained control. Using only text, it remains\nchallenging to deal with issues such as concept coherence and concept\ncontamination. We propose a method to enhance control by generating specific\nconcepts that can be reused throughout multiple images, effectively expanding\nnatural language with new words that can be combined much like a painter's\npalette. Unlike previous contributions, our method does not copy visuals from\ninput data and can generate concepts through text alone. We perform a set of\ncomparisons that finds our method to be a significant improvement over\ntext-only prompts.\n","authors":["Rodrigo Mello","Filipe Calegario","Geber Ramalho"],"pdf_url":"https://arxiv.org/pdf/2303.04001v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.13007v2","updated":"2023-03-07T15:56:14Z","published":"2022-10-24T07:55:57Z","title":"Iterative Patch Selection for High-Resolution Image Recognition","summary":"  High-resolution images are prevalent in various applications, such as\nautonomous driving and computer-aided diagnosis. However, training neural\nnetworks on such images is computationally challenging and easily leads to\nout-of-memory errors even on modern GPUs. We propose a simple method, Iterative\nPatch Selection (IPS), which decouples the memory usage from the input size and\nthus enables the processing of arbitrarily large images under tight hardware\nconstraints. IPS achieves this by selecting only the most salient patches,\nwhich are then aggregated into a global representation for image recognition.\nFor both patch selection and aggregation, a cross-attention based transformer\nis introduced, which exhibits a close connection to Multiple Instance Learning.\nOur method demonstrates strong performance and has wide applicability across\ndifferent domains, training regimes and image sizes while using minimal\naccelerator memory. For example, we are able to finetune our model on\nwhole-slide images consisting of up to 250k patches (>16 gigapixels) with only\n5 GB of GPU VRAM at a batch size of 16.\n","authors":["Benjamin Bergner","Christoph Lippert","Aravindh Mahendran"],"pdf_url":"https://arxiv.org/pdf/2210.13007v2.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.03991v1","updated":"2023-03-07T15:43:39Z","published":"2023-03-07T15:43:39Z","title":"OpenOccupancy: A Large Scale Benchmark for Surrounding Semantic\n  Occupancy Perception","summary":"  Semantic occupancy perception is essential for autonomous driving, as\nautomated vehicles require a fine-grained perception of the 3D urban\nstructures. However, existing relevant benchmarks lack diversity in urban\nscenes, and they only evaluate front-view predictions. Towards a comprehensive\nbenchmarking of surrounding perception algorithms, we propose OpenOccupancy,\nwhich is the first surrounding semantic occupancy perception benchmark. In the\nOpenOccupancy benchmark, we extend the large-scale nuScenes dataset with dense\nsemantic occupancy annotations. Previous annotations rely on LiDAR points\nsuperimposition, where some occupancy labels are missed due to sparse LiDAR\nchannels. To mitigate the problem, we introduce the Augmenting And Purifying\n(AAP) pipeline to ~2x densify the annotations, where ~4000 human hours are\ninvolved in the labeling process. Besides, camera-based, LiDAR-based and\nmulti-modal baselines are established for the OpenOccupancy benchmark.\nFurthermore, considering the complexity of surrounding occupancy perception\nlies in the computational burden of high-resolution 3D predictions, we propose\nthe Cascade Occupancy Network (CONet) to refine the coarse prediction, which\nrelatively enhances the performance by ~30% than the baseline. We hope the\nOpenOccupancy benchmark will boost the development of surrounding occupancy\nperception algorithms.\n","authors":["Xiaofeng Wang","Zheng Zhu","Wenbo Xu","Yunpeng Zhang","Yi Wei","Xu Chi","Yun Ye","Dalong Du","Jiwen Lu","Xingang Wang"],"pdf_url":"https://arxiv.org/pdf/2303.03991v1.pdf","comment":"project page: https://github.com/JeffWang987/OpenOccupancy"},{"id":"http://arxiv.org/abs/2303.03988v1","updated":"2023-03-07T15:39:54Z","published":"2023-03-07T15:39:54Z","title":"DINet: Deformation Inpainting Network for Realistic Face Visually\n  Dubbing on High Resolution Video","summary":"  For few-shot learning, it is still a critical challenge to realize\nphoto-realistic face visually dubbing on high-resolution videos. Previous works\nfail to generate high-fidelity dubbing results. To address the above problem,\nthis paper proposes a Deformation Inpainting Network (DINet) for\nhigh-resolution face visually dubbing. Different from previous works relying on\nmultiple up-sample layers to directly generate pixels from latent embeddings,\nDINet performs spatial deformation on feature maps of reference images to\nbetter preserve high-frequency textural details. Specifically, DINet consists\nof one deformation part and one inpainting part. In the first part, five\nreference facial images adaptively perform spatial deformation to create\ndeformed feature maps encoding mouth shapes at each frame, in order to align\nwith the input driving audio and also the head poses of the input source\nimages. In the second part, to produce face visually dubbing, a feature decoder\nis responsible for adaptively incorporating mouth movements from the deformed\nfeature maps and other attributes (i.e., head pose and upper facial expression)\nfrom the source feature maps together. Finally, DINet achieves face visually\ndubbing with rich textural details. We conduct qualitative and quantitative\ncomparisons to validate our DINet on high-resolution videos. The experimental\nresults show that our method outperforms state-of-the-art works.\n","authors":["Zhimeng Zhang","Zhipeng Hu","Wenjin Deng","Changjie Fan","Tangjie Lv","Yu Ding"],"pdf_url":"https://arxiv.org/pdf/2303.03988v1.pdf","comment":"AAAI-23, 9pages"},{"id":"http://arxiv.org/abs/2303.02698v2","updated":"2023-03-07T15:21:14Z","published":"2023-03-05T15:27:24Z","title":"Robust affine feature matching via quadratic assignment on Grassmannians","summary":"  GraNNI (Grassmannians for Nearest Neighbours Identification) a new algorithm\nto solve the problem of affine registration is proposed. The algorithm is based\non the Grassmannian of $k$--dimensional planes in $\\mathbb{R}^n$ and minimizing\nthe Frobenius norm between the two elements of the Grassmannian. The Quadratic\nAssignment Problem (QAP) is used to find the matching. The results of the\nexperiments show that the algorithm is more robust to noise and point\ndiscrepancy in point clouds than previous approaches.\n","authors":["Alexander Kolpakov","Michael Werman"],"pdf_url":"https://arxiv.org/pdf/2303.02698v2.pdf","comment":"12 pages, 18 figures; GitHub repository at\n  (https://github.com/sashakolpakov/granni)"},{"id":"http://arxiv.org/abs/2206.02082v3","updated":"2023-03-07T15:17:57Z","published":"2022-06-05T01:43:52Z","title":"Towards Fast Adaptation of Pretrained Contrastive Models for\n  Multi-channel Video-Language Retrieval","summary":"  Multi-channel video-language retrieval require models to understand\ninformation from different channels (e.g. video$+$question, video$+$speech) to\ncorrectly link a video with a textual response or query. Fortunately,\ncontrastive multimodal models have been shown to be highly effective at\naligning entities in images/videos and text, e.g., CLIP; text contrastive\nmodels have been extensively studied recently for their strong ability of\nproducing discriminative sentence embeddings, e.g., SimCSE. Their abilities are\nexactly needed by multi-channel video-language retrieval. However, there is not\na clear way to quickly adapt these two lines to multi-channel video-language\nretrieval with limited data and resources. In this paper, we identify a\nprincipled model design space with two axes: how to represent videos and how to\nfuse video and text information. Based on categorization of recent methods, we\ninvestigate the options of representing videos using continuous feature vectors\nor discrete text tokens; for the fusion method, we explore the use of a\nmultimodal transformer or a pretrained contrastive text model. We extensively\nevaluate the four combinations on five video-language datasets. We surprisingly\nfind that discrete text tokens coupled with a pretrained contrastive text model\nyields the best performance, which can even outperform state-of-the-art on the\niVQA and How2QA datasets without the additional training on millions of\nvideo-language data. Further analysis shows that this is because representing\nvideos as text tokens captures the key visual information with text tokens that\nare naturally aligned with text models and the text models are strong\nmultimodal retriever after the contrastive pretraining process.\n","authors":["Xudong Lin","Simran Tiwari","Shiyuan Huang","Manling Li","Mike Zheng Shou","Heng Ji","Shih-Fu Chang"],"pdf_url":"https://arxiv.org/pdf/2206.02082v3.pdf","comment":"To appear in CVPR 2023"},{"id":"http://arxiv.org/abs/2302.10768v2","updated":"2023-03-07T15:11:10Z","published":"2023-01-19T11:11:57Z","title":"On the Importance of Sign Labeling: The Hamburg Sign Language Notation\n  System Case Study","summary":"  Labeling is the cornerstone of supervised machine learning, which has been\nexploited in a plethora of various applications, with sign language recognition\nbeing one of them. However, such algorithms must be fed with a huge amount of\nconsistently labeled data during the training process to elaborate a\nwell-generalizing model. In addition, there is a great need for an automated\nsolution that works with any nationally diversified sign language. Although\nthere are language-agnostic transcription systems, such as the Hamburg Sign\nLanguage Notation System (HamNoSys) that describe the signer's initial position\nand body movement instead of the glosses' meanings, there are still issues with\nproviding accurate and reliable labels for every real-world use case. In this\ncontext, the industry relies heavily on manual attribution and labeling of the\navailable video data. In this work, we tackle this issue and thoroughly analyze\nthe HamNoSys labels provided by various maintainers of open sign language\ncorpora in five sign languages, in order to examine the challenges encountered\nin labeling video data. We also investigate the consistency and objectivity of\nHamNoSys-based labels for the purpose of training machine learning models. Our\nfindings provide valuable insights into the limitations of the current labeling\nmethods and pave the way for future research on developing more accurate and\nefficient solutions for sign language recognition.\n","authors":["Maria Ferlin","Sylwia Majchrowska","Marta Plantykow","Alicja Kwaśniwska","Agnieszka Mikołajczyk-Bareła","Milena Olech","Jakub Nalepa"],"pdf_url":"https://arxiv.org/pdf/2302.10768v2.pdf","comment":"20 pages, 13 figures"},{"id":"http://arxiv.org/abs/2303.03965v1","updated":"2023-03-07T15:07:43Z","published":"2023-03-07T15:07:43Z","title":"Comparing 3D deformations between longitudinal daily CBCT acquisitions\n  using CNN for head and neck radiotherapy toxicity prediction","summary":"  Adaptive radiotherapy is a growing field of study in cancer treatment due to\nit's objective in sparing healthy tissue. The standard of care in several\ninstitutions includes longitudinal cone-beam computed tomography (CBCT)\nacquisitions to monitor changes, but have yet to be used to improve tumor\ncontrol while managing side-effects. The aim of this study is to demonstrate\nthe clinical value of pre-treatment CBCT acquired daily during radiation\ntherapy treatment for head and neck cancers for the downstream task of\npredicting severe toxicity occurrence: reactive feeding tube (NG),\nhospitalization and radionecrosis. For this, we propose a deformable 3D\nclassification pipeline that includes a component analyzing the Jacobian matrix\nof the deformation between planning CT and longitudinal CBCT, as well as\nclinical data. The model is based on a multi-branch 3D residual convolutional\nneural network, while the CT to CBCT registration is based on a pair of\nVoxelMorph architectures. Accuracies of 85.8% and 75.3% was found for\nradionecrosis and hospitalization, respectively, with similar performance as\nearly as after the first week of treatment. For NG tube risk, performance\nimproves with increasing the timing of the CBCT fraction, reaching 83.1% after\nthe $5_{th}$ week of treatment.\n","authors":["William Trung Le","Chulmin Bang","Philippine Cordelle","Daniel Markel","Phuc Felix Nguyen-Tan","Houda Bahig","Samuel Kadoury"],"pdf_url":"https://arxiv.org/pdf/2303.03965v1.pdf","comment":"11 pages, 3 figures, 2 equations, 2 tables"},{"id":"http://arxiv.org/abs/2302.06650v2","updated":"2023-03-07T15:03:27Z","published":"2023-02-13T19:30:17Z","title":"Surround-View Vision-based 3D Detection for Autonomous Driving: A Survey","summary":"  Vision-based 3D Detection task is fundamental task for the perception of an\nautonomous driving system, which has peaked interest amongst many researchers\nand autonomous driving engineers. However achieving a rather good 3D BEV\n(Bird's Eye View) performance is not an easy task using 2D sensor input-data\nwith cameras. In this paper we provide a literature survey for the existing\nVision Based 3D detection methods, focused on autonomous driving. We have made\ndetailed analysis of over $60$ papers leveraging Vision BEV detections\napproaches and highlighted different sub-groups for detailed understanding of\ncommon trends. Moreover, we have highlighted how the literature and industry\ntrend have moved towards surround-view image based methods and note down\nthoughts on what special cases this method addresses. In conclusion, we provoke\nthoughts of 3D Vision techniques for future research based on shortcomings of\nthe current techniques including the direction of collaborative perception.\n","authors":["Apoorv Singh","Varun Bankiti"],"pdf_url":"https://arxiv.org/pdf/2302.06650v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.08231v2","updated":"2023-03-07T14:59:28Z","published":"2023-02-16T11:28:30Z","title":"3M3D: Multi-view, Multi-path, Multi-representation for 3D Object\n  Detection","summary":"  3D visual perception tasks based on multi-camera images are essential for\nautonomous driving systems. Latest work in this field performs 3D object\ndetection by leveraging multi-view images as an input and iteratively enhancing\nobject queries (object proposals) by cross-attending multi-view features.\nHowever, individual backbone features are not updated with multi-view features\nand it stays as a mere collection of the output of the single-image backbone\nnetwork. Therefore we propose 3M3D: A Multi-view, Multi-path,\nMulti-representation for 3D Object Detection where we update both multi-view\nfeatures and query features to enhance the representation of the scene in both\nfine panoramic view and coarse global view. Firstly, we update multi-view\nfeatures by multi-view axis self-attention. It will incorporate panoramic\ninformation in the multi-view features and enhance understanding of the global\nscene. Secondly, we update multi-view features by self-attention of the ROI\n(Region of Interest) windows which encodes local finer details in the features.\nIt will help exchange the information not only along the multi-view axis but\nalso along the other spatial dimension. Lastly, we leverage the fact of\nmulti-representation of queries in different domains to further boost the\nperformance. Here we use sparse floating queries along with dense BEV (Bird's\nEye View) queries, which are later post-processed to filter duplicate\ndetections. Moreover, we show performance improvements on nuScenes benchmark\ndataset on top of our baselines.\n","authors":["Jongwoo Park","Apoorv Singh","Varun Bankiti"],"pdf_url":"https://arxiv.org/pdf/2302.08231v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2102.13392v3","updated":"2023-03-07T14:56:18Z","published":"2021-02-26T11:01:30Z","title":"Unifying Remote Sensing Image Retrieval and Classification with Robust\n  Fine-tuning","summary":"  Advances in high resolution remote sensing image analysis are currently\nhampered by the difficulty of gathering enough annotated data for training deep\nlearning methods, giving rise to a variety of small datasets and associated\ndataset-specific methods. Moreover, typical tasks such as classification and\nretrieval lack a systematic evaluation on standard benchmarks and training\ndatasets, which make it hard to identify durable and generalizable scientific\ncontributions. We aim at unifying remote sensing image retrieval and\nclassification with a new large-scale training and testing dataset, SF300,\nincluding both vertical and oblique aerial images and made available to the\nresearch community, and an associated fine-tuning method. We additionally\npropose a new adversarial fine-tuning method for global descriptors. We show\nthat our framework systematically achieves a boost of retrieval and\nclassification performance on nine different datasets compared to an ImageNet\npretrained baseline, with currently no other method to compare to.\n","authors":["Dimitri Gominski","Valérie Gouet-Brunet","Liming Chen"],"pdf_url":"https://arxiv.org/pdf/2102.13392v3.pdf","comment":"Performance margin with the proposed method is not statistically\n  significant. Please refer to http://alegoria.ign.fr/en/SF300_dataset if you\n  are interested in the dataset"},{"id":"http://arxiv.org/abs/2303.03943v1","updated":"2023-03-07T14:52:29Z","published":"2023-03-07T14:52:29Z","title":"CUREE: A Curious Underwater Robot for Ecosystem Exploration","summary":"  The current approach to exploring and monitoring complex underwater\necosystems, such as coral reefs, is to conduct surveys using diver-held or\nstatic cameras, or deploying sensor buoys. These approaches often fail to\ncapture the full variation and complexity of interactions between different\nreef organisms and their habitat. The CUREE platform presented in this paper\nprovides a unique set of capabilities in the form of robot behaviors and\nperception algorithms to enable scientists to explore different aspects of an\necosystem. Examples of these capabilities include low-altitude visual surveys,\nsoundscape surveys, habitat characterization, and animal following. We\ndemonstrate these capabilities by describing two field deployments on coral\nreefs in the US Virgin Islands. In the first deployment, we show that CUREE can\nidentify the preferred habitat type of snapping shrimp in a reef through a\ncombination of a visual survey, habitat characterization, and a soundscape\nsurvey. In the second deployment, we demonstrate CUREE's ability to follow\narbitrary animals by separately following a barracuda and stingray for several\nminutes each in midwater and benthic environments, respectively.\n","authors":["ogesh Girdhar","Nathan McGuire","Levi Cai","Stewart Jamieson","Seth McCammon","Brian Claus","John E. San Soucie","Jessica E. Todd","T. Aran Mooney"],"pdf_url":"https://arxiv.org/pdf/2303.03943v1.pdf","comment":"7 pages"},{"id":"http://arxiv.org/abs/2302.02350v2","updated":"2023-03-07T14:51:01Z","published":"2023-02-05T09:48:57Z","title":"Aggregation of Disentanglement: Reconsidering Domain Variations in\n  Domain Generalization","summary":"  Domain Generalization (DG) is a fundamental challenge for machine learning\nmodels, which aims to improve model generalization on various domains. Previous\nmethods focus on generating domain invariant features from various source\ndomains. However, we argue that the domain variantions also contain useful\ninformation, ie, classification-aware information, for downstream tasks, which\nhas been largely ignored. Different from learning domain invariant features\nfrom source domains, we decouple the input images into Domain Expert Features\nand noise. The proposed domain expert features lie in a learned latent space\nwhere the images in each domain can be classified independently, enabling the\nimplicit use of classification-aware domain variations. Based on the analysis,\nwe proposed a novel paradigm called Domain Disentanglement Network (DDN) to\ndisentangle the domain expert features from the source domain images and\naggregate the source domain expert features for representing the target test\ndomain. We also propound a new contrastive learning method to guide the domain\nexpert features to form a more balanced and separable feature space.\nExperiments on the widely-used benchmarks of PACS, VLCS, OfficeHome, DomainNet,\nand TerraIncognita demonstrate the competitive performance of our method\ncompared to the recently proposed alternatives.\n","authors":["Daoan Zhang","Mingkai Chen","Chenming Li","Lingyun Huang","Jianguo Zhang"],"pdf_url":"https://arxiv.org/pdf/2302.02350v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03003v2","updated":"2023-03-07T14:46:21Z","published":"2023-03-06T10:04:50Z","title":"Efficient Large-scale Scene Representation with a Hybrid of\n  High-resolution Grid and Plane Features","summary":"  Existing neural radiance fields (NeRF) methods for large-scale scene modeling\nrequire days of training using multiple GPUs, hindering their applications in\nscenarios with limited computing resources. Despite fast optimization NeRF\nvariants have been proposed based on the explicit dense or hash grid features,\ntheir effectivenesses are mainly demonstrated in object-scale scene\nrepresentation. In this paper, we point out that the low feature resolution in\nexplicit representation is the bottleneck for large-scale unbounded scene\nrepresentation. To address this problem, we introduce a new and efficient\nhybrid feature representation for NeRF that fuses the 3D hash-grids and\nhigh-resolution 2D dense plane features. Compared with the dense-grid\nrepresentation, the resolution of a dense 2D plane can be scaled up more\nefficiently. Based on this hybrid representation, we propose a fast\noptimization NeRF variant, called GP-NeRF, that achieves better rendering\nresults while maintaining a compact model size. Extensive experiments on\nmultiple large-scale unbounded scene datasets show that our model can converge\nin 1.5 hours using a single GPU while achieving results comparable to or even\nbetter than the existing method that requires about one day's training with 8\nGPUs.\n","authors":["Yuqi Zhang","Guanying Chen","Shuguang Cui"],"pdf_url":"https://arxiv.org/pdf/2303.03003v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.15376v2","updated":"2023-03-07T14:45:08Z","published":"2022-09-30T11:09:54Z","title":"NBV-SC: Next Best View Planning based on Shape Completion for Fruit\n  Mapping and Reconstruction","summary":"  Active perception for fruit mapping and harvesting is a difficult task since\nocclusions occur frequently and the location as well as size of fruits change\nover time. State-of-the-art viewpoint planning approaches utilize\ncomputationally expensive ray casting operations to find good viewpoints aiming\nat maximizing information gain and covering the fruits in the scene. In this\npaper, we present a novel viewpoint planning approach that explicitly uses\ninformation about the predicted fruit shapes to compute targeted viewpoints\nthat observe as yet unobserved parts of the fruits. Furthermore, we formulate\nthe concept of viewpoint dissimilarity to reduce the sampling space for more\nefficient selection of useful, dissimilar viewpoints. Our simulation\nexperiments with a UR5e arm equipped with an RGB-D sensor provide a\nquantitative demonstration of the efficacy of our iterative next best view\nplanning method based on shape completion. In comparative experiments with a\nstate-of-the-art viewpoint planner, we demonstrate improvement not only in the\nestimation of the fruit sizes, but also in their reconstruction, while\nsignificantly reducing the planning time. Finally, we show the viability of our\napproach for mapping sweet peppers plants with a real robotic system in a\ncommercial glasshouse.\n","authors":["Rohit Menon","Tobias Zaenker","Nils Dengler","Maren Bennewitz"],"pdf_url":"https://arxiv.org/pdf/2209.15376v2.pdf","comment":"Agricultural Automation, Viewpoint Planning, Active Perception, Shape\n  Completion"},{"id":"http://arxiv.org/abs/2303.03932v1","updated":"2023-03-07T14:38:28Z","published":"2023-03-07T14:38:28Z","title":"FFT-based Dynamic Token Mixer for Vision","summary":"  Multi-head-self-attention (MHSA)-equipped models have achieved notable\nperformance in computer vision. Their computational complexity is proportional\nto quadratic numbers of pixels in input feature maps, resulting in slow\nprocessing, especially when dealing with high-resolution images. New types of\ntoken-mixer are proposed as an alternative to MHSA to circumvent this problem:\nan FFT-based token-mixer, similar to MHSA in global operation but with lower\ncomputational complexity. However, despite its attractive properties, the\nFFT-based token-mixer has not been carefully examined in terms of its\ncompatibility with the rapidly evolving MetaFormer architecture. Here, we\npropose a novel token-mixer called dynamic filter and DFFormer and CDFFormer,\nimage recognition models using dynamic filters to close the gaps above.\nCDFFormer achieved a Top-1 accuracy of 85.0%, close to the hybrid architecture\nwith convolution and MHSA. Other wide-ranging experiments and analysis,\nincluding object detection and semantic segmentation, demonstrate that they are\ncompetitive with state-of-the-art architectures; Their throughput and memory\nefficiency when dealing with high-resolution image recognition is convolution\nand MHSA, not much different from ConvFormer, and far superior to CAFormer. Our\nresults indicate that the dynamic filter is one of the token-mixer options that\nshould be seriously considered. The code is available at\nhttps://github.com/okojoalg/dfformer\n","authors":["Yuki Tatsunami","Masato Taki"],"pdf_url":"https://arxiv.org/pdf/2303.03932v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00843v2","updated":"2023-03-07T14:28:56Z","published":"2022-10-03T12:08:09Z","title":"Early or Late Fusion Matters: Efficient RGB-D Fusion in Vision\n  Transformers for 3D Object Recognition","summary":"  The Vision Transformer (ViT) architecture has established its place in\ncomputer vision literature, however, training ViTs for RGB-D object recognition\nremains an understudied topic, viewed in recent literature only through the\nlens of multi-task pretraining in multiple vision modalities. Such approaches\nare often computationally intensive, relying on the scale of multiple\npretraining datasets to align RGB with 3D information. In this work, we propose\na simple yet strong recipe for transferring pretrained ViTs in RGB-D domains\nfor 3D object recognition, focusing on fusing RGB and depth representations\nencoded jointly by the ViT. Compared to previous works in multimodal\nTransformers, the key challenge here is to use the attested flexibility of ViTs\nto capture cross-modal interactions at the downstream and not the pretraining\nstage. We explore which depth representation is better in terms of resulting\naccuracy and compare early and late fusion techniques for aligning the RGB and\ndepth modalities within the ViT architecture. Experimental results in the\nWashington RGB-D Objects dataset (ROD) demonstrate that in such RGB -> RGB-D\nscenarios, late fusion techniques work better than most popularly employed\nearly fusion. With our transfer baseline, fusion ViTs score up to 95.4% top-1\naccuracy in ROD, achieving new state-of-the-art results in this benchmark. We\nfurther show the benefits of using our multimodal fusion baseline over unimodal\nfeature extractors in a synthetic-to-real visual adaptation as well as in an\nopen-ended lifelong learning scenario in the ROD benchmark, where our model\noutperforms previous works by a margin of >8%. Finally, we integrate our method\nwith a robot framework and demonstrate how it can serve as a perception utility\nin an interactive robot learning scenario, both in simulation and with a real\nrobot.\n","authors":["Georgios Tziafas","Hamidreza Kasaei"],"pdf_url":"https://arxiv.org/pdf/2210.00843v2.pdf","comment":"Submitted IROS 23. Supplementary video here:\n  https://youtu.be/L2gkDPkHsfo"},{"id":"http://arxiv.org/abs/2303.03916v1","updated":"2023-03-07T14:26:08Z","published":"2023-03-07T14:26:08Z","title":"A survey on automated detection and classification of acute leukemia and\n  WBCs in microscopic blood cells","summary":"  Leukemia (blood cancer) is an unusual spread of White Blood Cells or\nLeukocytes (WBCs) in the bone marrow and blood. Pathologists can diagnose\nleukemia by looking at a person's blood sample under a microscope. They\nidentify and categorize leukemia by counting various blood cells and\nmorphological features. This technique is time-consuming for the prediction of\nleukemia. The pathologist's professional skills and experiences may be\naffecting this procedure, too. In computer vision, traditional machine learning\nand deep learning techniques are practical roadmaps that increase the accuracy\nand speed in diagnosing and classifying medical images such as microscopic\nblood cells. This paper provides a comprehensive analysis of the detection and\nclassification of acute leukemia and WBCs in the microscopic blood cells.\nFirst, we have divided the previous works into six categories based on the\noutput of the models. Then, we describe various steps of detection and\nclassification of acute leukemia and WBCs, including Data Augmentation,\nPreprocessing, Segmentation, Feature Extraction, Feature Selection (Reduction),\nClassification, and focus on classification step in the methods. Finally, we\ndivide automated detection and classification of acute leukemia and WBCs into\nthree categories, including traditional, Deep Neural Network (DNN), and mixture\n(traditional and DNN) methods based on the type of classifier in the\nclassification step and analyze them. The results of this study show that in\nthe diagnosis and classification of acute leukemia and WBCs, the Support Vector\nMachine (SVM) classifier in traditional machine learning models and\nConvolutional Neural Network (CNN) classifier in deep learning models have\nwidely employed. The performance metrics of the models that use these\nclassifiers compared to the others model are higher.\n","authors":["Mohammad Zolfaghari","Hedieh Sajedi"],"pdf_url":"https://arxiv.org/pdf/2303.03916v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03909v1","updated":"2023-03-07T14:12:52Z","published":"2023-03-07T14:12:52Z","title":"InsMOS: Instance-Aware Moving Object Segmentation in LiDAR Data","summary":"  Identifying moving objects is a crucial capability for autonomous navigation,\nconsistent map generation, and future trajectory prediction of objects. In this\npaper, we propose a novel network that addresses the challenge of segmenting\nmoving objects in 3D LiDAR scans. Our approach not only predicts point-wise\nmoving labels but also detects instance information of main traffic\nparticipants. Such a design helps determine which instances are actually moving\nand which ones are temporarily static in the current scene. Our method exploits\na sequence of point clouds as input and quantifies them into 4D voxels. We use\n4D sparse convolutions to extract motion features from the 4D voxels and inject\nthem into the current scan. Then, we extract spatio-temporal features from the\ncurrent scan for instance detection and feature fusion. Finally, we design an\nupsample fusion module to output point-wise labels by fusing the\nspatio-temporal features and predicted instance information. We evaluated our\napproach on the LiDAR-MOS benchmark based on SemanticKITTI and achieved better\nmoving object segmentation performance compared to state-of-the-art methods,\ndemonstrating the effectiveness of our approach in integrating instance\ninformation for moving object segmentation. Furthermore, our method shows\nsuperior performance on the Apollo dataset with a pre-trained model on\nSemanticKITTI, indicating that our method generalizes well in different\nscenes.The code and pre-trained models of our method will be released at\nhttps://github.com/nubot-nudt/InsMOS.\n","authors":["Neng Wang","Chenghao Shi","Ruibin Guo","Huimin Lu","Zhiqiang Zheng","Xieyuanli Chen"],"pdf_url":"https://arxiv.org/pdf/2303.03909v1.pdf","comment":"8 pages, 4 figures, submitted"},{"id":"http://arxiv.org/abs/2106.06924v3","updated":"2023-03-07T14:05:05Z","published":"2021-06-13T05:32:17Z","title":"Deep Learning for Predictive Analytics in Reversible Steganography","summary":"  Deep learning is regarded as a promising solution for reversible\nsteganography. There is an accelerating trend of representing a reversible\nsteo-system by monolithic neural networks, which bypass intermediate operations\nin traditional pipelines of reversible steganography. This end-to-end paradigm,\nhowever, suffers from imperfect reversibility. By contrast, the modular\nparadigm that incorporates neural networks into modules of traditional\npipelines can stably guarantee reversibility with mathematical explainability.\nPrediction-error modulation is a well-established reversible steganography\npipeline for digital images. It consists of a predictive analytics module and a\nreversible coding module. Given that reversibility is governed independently by\nthe coding module, we narrow our focus to the incorporation of neural networks\ninto the analytics module, which serves the purpose of predicting pixel\nintensities and a pivotal role in determining capacity and imperceptibility.\nThe objective of this study is to evaluate the impacts of different training\nconfigurations upon predictive accuracy of neural networks and provide\npractical insights. In particular, we investigate how different initialisation\nstrategies for input images may affect the learning process and how different\ntraining strategies for dual-layer prediction respond to the problem of\ndistributional shift. Furthermore, we compare steganographic performance of\nvarious model architectures with different loss functions.\n","authors":["Ching-Chun Chang","Xu Wang","Sisheng Chen","Isao Echizen","Victor Sanchez","Chang-Tsun Li"],"pdf_url":"https://arxiv.org/pdf/2106.06924v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14085v2","updated":"2023-03-07T13:56:51Z","published":"2022-11-25T13:14:33Z","title":"Positive unlabeled learning with tensor networks","summary":"  Positive unlabeled learning is a binary classification problem with positive\nand unlabeled data. It is common in domains where negative labels are costly or\nimpossible to obtain, e.g., medicine and personalized advertising. We apply the\nlocally purified state tensor network to the positive unlabeled learning\nproblem and test our model on the MNIST image and 15 categorical/mixed\ndatasets. On the MNIST dataset, we obtain close to the state-of-the-art results\neven with very few labeled positive samples. We significantly improve the\nstate-of-the-art on categorical datasets. Further, we show that the agreement\nfraction between outputs of different models on unlabeled samples is a good\nindicator of the model's performance. Finally, our method can generate new\npositive and negative instances, which we demonstrate on simple synthetic\ndatasets.\n","authors":["Bojan Žunkovič"],"pdf_url":"https://arxiv.org/pdf/2211.14085v2.pdf","comment":"12 pages, 5 figures, 4 tables"},{"id":"http://arxiv.org/abs/2302.09598v2","updated":"2023-03-07T13:50:01Z","published":"2023-02-19T15:43:54Z","title":"Guided Depth Map Super-resolution: A Survey","summary":"  Guided depth map super-resolution (GDSR), which aims to reconstruct a\nhigh-resolution (HR) depth map from a low-resolution (LR) observation with the\nhelp of a paired HR color image, is a longstanding and fundamental problem, it\nhas attracted considerable attention from computer vision and image processing\ncommunities. A myriad of novel and effective approaches have been proposed\nrecently, especially with powerful deep learning techniques. This survey is an\neffort to present a comprehensive survey of recent progress in GDSR. We start\nby summarizing the problem of GDSR and explaining why it is challenging. Next,\nwe introduce some commonly used datasets and image quality assessment methods.\nIn addition, we roughly classify existing GDSR methods into three categories,\ni.e., filtering-based methods, prior-based methods, and learning-based methods.\nIn each category, we introduce the general description of the published\nalgorithms and design principles, summarize the representative methods, and\ndiscuss their highlights and limitations. Moreover, the depth related\napplications are introduced. Furthermore, we conduct experiments to evaluate\nthe performance of some representative methods based on unified experimental\nconfigurations, so as to offer a systematic and fair performance evaluation to\nreaders. Finally, we conclude this survey with possible directions and open\nproblems for further research. All the related materials can be found at\n\\url{https://github.com/zhwzhong/Guided-Depth-Map-Super-resolution-A-Survey}.\n","authors":["Zhiwei Zhong","Xianming Liu","Junjun Jiang","Debin Zhao","Xiangyang Ji"],"pdf_url":"https://arxiv.org/pdf/2302.09598v2.pdf","comment":"Accepted by ACM Computing Surveys"},{"id":"http://arxiv.org/abs/2303.03056v2","updated":"2023-03-07T13:31:52Z","published":"2023-03-06T11:59:13Z","title":"MOISST: Multi-modal Optimization of Implicit Scene for SpatioTemporal\n  calibration","summary":"  With the recent advances in autonomous driving and the decreasing cost of\nLiDARs, the use of multi-modal sensor systems is on the rise. However, in order\nto make use of the information provided by a variety of complimentary sensors,\nit is necessary to accurately calibrate them. We take advantage of recent\nadvances in computer graphics and implicit volumetric scene representation to\ntackle the problem of multi-sensor spatial and temporal calibration. Thanks to\na new formulation of the implicit model optimization, we are able to jointly\noptimize calibration parameters along with scene representation based on\nradiometric and geometric measurements. Our method enables accurate and robust\ncalibration from data captured in uncontrolled and unstructured urban\nenvironments, making our solution more scalable than existing calibration\nsolutions. We demonstrate the accuracy and robustness of our method in urban\nscenes typically encountered in autonomous driving scenarios.\n","authors":["Quentin Herau","Nathan Piasco","Moussab Bennehar","Luis Roldão","Dzmitry Tsishkou","Cyrille Migniot","Pascal Vasseur","Cédric Demonceaux"],"pdf_url":"https://arxiv.org/pdf/2303.03056v2.pdf","comment":"Project site: https://qherau.github.io/MOISST/"},{"id":"http://arxiv.org/abs/2303.03879v1","updated":"2023-03-07T13:24:40Z","published":"2023-03-07T13:24:40Z","title":"SpinDOE: A ball spin estimation method for table tennis robot","summary":"  Spin plays a considerable role in table tennis, making a shot's trajectory\nharder to read and predict. However, the spin is challenging to measure because\nof the ball's high velocity and the magnitude of the spin values. Existing\nmethods either require extremely high framerate cameras or are unreliable\nbecause they use the ball's logo, which may not always be visible. Because of\nthis, many table tennis-playing robots ignore the spin, which severely limits\ntheir capabilities. This paper proposes an easily implementable and reliable\nspin estimation method. We developed a dotted-ball orientation estimation (DOE)\nmethod, that can then be used to estimate the spin. The dots are first\nlocalized on the image using a CNN and then identified using geometric hashing.\nThe spin is finally regressed from the estimated orientations. Using our\nalgorithm, the ball's orientation can be estimated with a mean error of\n2.4{\\deg} and the spin estimation has an relative error lower than 1%. Spins up\nto 175 rps are measurable with a camera of 350 fps in real time. Using our\nmethod, we generated a dataset of table tennis ball trajectories with position\nand spin, available on our project page.\n","authors":["Thomas Gossard","Jonas Tebbe","Andreas Ziegler","Andreas Zell"],"pdf_url":"https://arxiv.org/pdf/2303.03879v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03876v1","updated":"2023-03-07T13:23:31Z","published":"2023-03-07T13:23:31Z","title":"Organelle-specific segmentation, spatial analysis, and visualization of\n  volume electron microscopy datasets","summary":"  Volume electron microscopy is the method of choice for the in-situ\ninterrogation of cellular ultrastructure at the nanometer scale. Recent\ntechnical advances have led to a rapid increase in large raw image datasets\nthat require computational strategies for segmentation and spatial analysis. In\nthis protocol, we describe a practical and annotation-efficient pipeline for\norganelle-specific segmentation, spatial analysis, and visualization of large\nvolume electron microscopy datasets using freely available, user-friendly\nsoftware tools that can be run on a single standard workstation. We\nspecifically target researchers in the life sciences with limited computational\nexpertise, who face the following tasks within their volume electron microscopy\nprojects: i) How to generate 3D segmentation labels for different types of cell\norganelles while minimizing manual annotation efforts, ii) how to analyze the\nspatial interactions between organelle instances, and iii) how to best\nvisualize the 3D segmentation results. To meet these demands we give detailed\nguidelines for choosing the most efficient segmentation tools for the specific\ncell organelle. We furthermore provide easily executable components for spatial\nanalysis and 3D rendering and bridge compatibility issues between freely\navailable open-source tools, such that others can replicate our full pipeline\nstarting from a raw dataset up to the final plots and rendered images. We\nbelieve that our detailed description can serve as a valuable reference for\nsimilar projects requiring special strategies for single- or multiple organelle\nanalysis which can be achieved with computational resources commonly available\nto single-user setups.\n","authors":["Andreas Müller","Deborah Schmidt","Lucas Rieckert","Michele Solimena","Martin Weigert"],"pdf_url":"https://arxiv.org/pdf/2303.03876v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.06983v4","updated":"2023-03-07T13:19:13Z","published":"2022-10-10T12:37:59Z","title":"Denoising Masked AutoEncoders Help Robust Classification","summary":"  In this paper, we propose a new self-supervised method, which is called\nDenoising Masked AutoEncoders (DMAE), for learning certified robust classifiers\nof images. In DMAE, we corrupt each image by adding Gaussian noises to each\npixel value and randomly masking several patches. A Transformer-based\nencoder-decoder model is then trained to reconstruct the original image from\nthe corrupted one. In this learning paradigm, the encoder will learn to capture\nrelevant semantics for the downstream tasks, which is also robust to Gaussian\nadditive noises. We show that the pre-trained encoder can naturally be used as\nthe base classifier in Gaussian smoothed models, where we can analytically\ncompute the certified radius for any data point. Although the proposed method\nis simple, it yields significant performance improvement in downstream\nclassification tasks. We show that the DMAE ViT-Base model, which just uses\n1/10 parameters of the model developed in recent work arXiv:2206.10550,\nachieves competitive or better certified accuracy in various settings. The DMAE\nViT-Large model significantly surpasses all previous results, establishing a\nnew state-of-the-art on ImageNet dataset. We further demonstrate that the\npre-trained model has good transferability to the CIFAR-10 dataset, suggesting\nits wide adaptability. Models and code are available at\nhttps://github.com/quanlin-wu/dmae.\n","authors":["Quanlin Wu","Hang Ye","Yuntian Gu","Huishuai Zhang","Liwei Wang","Di He"],"pdf_url":"https://arxiv.org/pdf/2210.06983v4.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2201.02478v2","updated":"2023-03-07T13:11:04Z","published":"2022-01-07T14:56:33Z","title":"Bayesian Neural Networks for Reversible Steganography","summary":"  Recent advances in deep learning have led to a paradigm shift in the field of\nreversible steganography. A fundamental pillar of reversible steganography is\npredictive modelling which can be realised via deep neural networks. However,\nnon-trivial errors exist in inferences about some out-of-distribution and noisy\ndata. In view of this issue, we propose to consider uncertainty in predictive\nmodels based upon a theoretical framework of Bayesian deep learning, thereby\ncreating an adaptive steganographic system. Most modern deep-learning models\nare regarded as deterministic because they only offer predictions while failing\nto provide uncertainty measurement. Bayesian neural networks bring a\nprobabilistic perspective to deep learning and can be regarded as self-aware\nintelligent machinery; that is, a machine that knows its own limitations. To\nquantify uncertainty, we apply Bayesian statistics to model the predictive\ndistribution and approximate it through Monte Carlo sampling with stochastic\nforward passes. We further show that predictive uncertainty can be disentangled\ninto aleatoric and epistemic uncertainties and these quantities can be learnt\nunsupervised. Experimental results demonstrate an improvement delivered by\nBayesian uncertainty analysis upon steganographic rate-distortion performance.\n","authors":["Ching-Chun Chang"],"pdf_url":"https://arxiv.org/pdf/2201.02478v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.02518v2","updated":"2023-03-07T12:55:55Z","published":"2022-02-05T09:04:50Z","title":"On the predictability in reversible steganography","summary":"  Artificial neural networks have advanced the frontiers of reversible\nsteganography. The core strength of neural networks is the ability to render\naccurate predictions for a bewildering variety of data. Residual modulation is\nrecognised as the most advanced reversible steganographic algorithm for digital\nimages. The pivot of this algorithm is predictive analytics in which pixel\nintensities are predicted given some pixel-wise contextual information. This\ntask can be perceived as a low-level vision problem and hence neural networks\nfor addressing a similar class of problems can be deployed. On top of the prior\nart, this paper investigates predictability of pixel intensities based on\nsupervised and unsupervised learning frameworks. Predictability analysis\nenables adaptive data embedding, which in turn leads to a better trade-off\nbetween capacity and imperceptibility. While conventional methods estimate\npredictability by the statistics of local image patterns, learning-based\nframeworks consider further the degree to which correct predictions can be made\nby a designated predictor. Not only should the image patterns be taken into\naccount but also the predictor in use. Experimental results show that\nsteganographic performance can be significantly improved by incorporating the\nlearning-based predictability analysers into a reversible steganographic\nsystem.\n","authors":["Ching-Chun Chang","Xu Wang","Sisheng Chen","Hitoshi Kiya","Isao Echizen"],"pdf_url":"https://arxiv.org/pdf/2202.02518v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03856v1","updated":"2023-03-07T12:48:02Z","published":"2023-03-07T12:48:02Z","title":"Event Voxel Set Transformer for Spatiotemporal Representation Learning\n  on Event Streams","summary":"  Event cameras are neuromorphic vision sensors representing visual information\nas sparse and asynchronous event streams. Most state-of-the-art event-based\nmethods project events into dense frames and process them with conventional\nlearning models. However, these approaches sacrifice the sparsity and high\ntemporal resolution of event data, resulting in a large model size and high\ncomputational complexity. To fit the sparse nature of events and sufficiently\nexplore their implicit relationship, we develop a novel attention-aware\nframework named Event Voxel Set Transformer (EVSTr) for spatiotemporal\nrepresentation learning on event streams. It first converts the event stream\ninto a voxel set and then hierarchically aggregates voxel features to obtain\nrobust representations. The core of EVSTr is an event voxel transformer encoder\nto extract discriminative spatiotemporal features, which consists of two\nwell-designed components, including a multi-scale neighbor embedding layer\n(MNEL) for local information aggregation and a voxel self-attention layer\n(VSAL) for global representation modeling. Enabling the framework to\nincorporate a long-term temporal structure, we introduce a segmental consensus\nstrategy for modeling motion patterns over a sequence of segmented voxel sets.\nWe evaluate the proposed framework on two event-based tasks: object\nclassification and action recognition. Comprehensive experiments show that\nEVSTr achieves state-of-the-art performance while maintaining low model\ncomplexity. Additionally, we present a new dataset (NeuroHAR) recorded in\nchallenging visual scenarios to address the lack of real-world event-based\ndatasets for action recognition.\n","authors":["Bochen Xie","Yongjian Deng","Zhanpeng Shao","Hai Liu","Qingsong Xu","Youfu Li"],"pdf_url":"https://arxiv.org/pdf/2303.03856v1.pdf","comment":"12 pages, 7 figures"},{"id":"http://arxiv.org/abs/2303.03851v1","updated":"2023-03-07T12:32:19Z","published":"2023-03-07T12:32:19Z","title":"Parsing Line Segments of Floor Plan Images Using Graph Neural Networks","summary":"  In this paper, we present a GNN-based Line Segment Parser (GLSP), which uses\na junction heatmap to predict line segments' endpoints, and graph neural\nnetworks to extract line segments and their categories. Different from previous\nfloor plan recognition methods, which rely on semantic segmentation, our\nproposed method is able to output vectorized line segment and requires less\npost-processing steps to be put into practical use. Our experiments show that\nthe methods outperform state-of-the-art line segment detection models on\nmulti-class line segment detection tasks with floor plan images. In the paper,\nwe use our floor plan dataset named Large-scale Residential Floor Plan data\n(LRFP). The dataset contains a total of 271,035 floor plan images. The label\ncorresponding to each picture contains the scale information, the categories\nand outlines of rooms, and the endpoint positions of line segments such as\ndoors, windows, and walls. Our augmentation method makes the dataset adaptable\nto the drawing styles of as many countries and regions as possible.\n","authors":["Mingxiang Chen","Cihui Pan"],"pdf_url":"https://arxiv.org/pdf/2303.03851v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03817v1","updated":"2023-03-07T11:33:22Z","published":"2023-03-07T11:33:22Z","title":"Region and Spatial Aware Anomaly Detection for Fundus Images","summary":"  Recently anomaly detection has drawn much attention in diagnosing ocular\ndiseases. Most existing anomaly detection research in fundus images has\nrelatively large anomaly scores in the salient retinal structures, such as\nblood vessels, optical cups and discs. In this paper, we propose a Region and\nSpatial Aware Anomaly Detection (ReSAD) method for fundus images, which obtains\nlocal region and long-range spatial information to reduce the false positives\nin the normal structure. ReSAD transfers a pre-trained model to extract the\nfeatures of normal fundus images and applies the Region-and-Spatial-Aware\nfeature Combination module (ReSC) for pixel-level features to build a memory\nbank. In the testing phase, ReSAD uses the memory bank to determine\nout-of-distribution samples as abnormalities. Our method significantly\noutperforms the existing anomaly detection methods for fundus images on two\npublicly benchmark datasets.\n","authors":["Jingqi Niu","Shiwen Dong","Qinji Yu","Kang Dang","Xiaowei Ding"],"pdf_url":"https://arxiv.org/pdf/2303.03817v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03808v1","updated":"2023-03-07T11:21:50Z","published":"2023-03-07T11:21:50Z","title":"Multiscale Tensor Decomposition and Rendering Equation Encoding for View\n  Synthesis","summary":"  Rendering novel views from captured multi-view images has made considerable\nprogress since the emergence of the neural radiance field. This paper aims to\nfurther advance the quality of view rendering by proposing a novel approach\ndubbed the neural radiance feature field (NRFF) which represents scenes in the\nfeature space. We first propose a multiscale tensor decomposition scheme to\norganize learnable features so as to represent scenes from coarse to fine\nscales. We demonstrate many benefits of the proposed multiscale representation,\nincluding more accurate scene shape and appearance reconstruction, and faster\nconvergence compared with the single-scale representation. Instead of encoding\nview directions to model view-dependent effects, we further propose to encode\nthe rendering equation in the feature space by employing the anisotropic\nspherical Gaussian mixture predicted from the proposed multiscale\nrepresentation. The proposed NRFF improves state-of-the-art rendering results\nby over 1 dB in PSNR on both the NeRF and NSVF synthetic datasets. A\nsignificant improvement has also been observed on the real-world Tanks and\nTemples dataset.\n","authors":["Kang Han","Wei Xiang"],"pdf_url":"https://arxiv.org/pdf/2303.03808v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03800v1","updated":"2023-03-07T11:10:22Z","published":"2023-03-07T11:10:22Z","title":"Lformer: Text-to-Image Generation with L-shape Block Parallel Decoding","summary":"  Generative transformers have shown their superiority in synthesizing\nhigh-fidelity and high-resolution images, such as good diversity and training\nstability. However, they suffer from the problem of slow generation since they\nneed to generate a long token sequence autoregressively. To better accelerate\nthe generative transformers while keeping good generation quality, we propose\nLformer, a semi-autoregressive text-to-image generation model. Lformer firstly\nencodes an image into $h{\\times}h$ discrete tokens, then divides these tokens\ninto $h$ mirrored L-shape blocks from the top left to the bottom right and\ndecodes the tokens in a block parallelly in each step. Lformer predicts the\narea adjacent to the previous context like autoregressive models thus it is\nmore stable while accelerating. By leveraging the 2D structure of image tokens,\nLformer achieves faster speed than the existing transformer-based methods while\nkeeping good generation quality. Moreover, the pretrained Lformer can edit\nimages without the requirement for finetuning. We can roll back to the early\nsteps for regeneration or edit the image with a bounding box and a text prompt.\n","authors":["Jiacheng Li","Longhui Wei","ZongYuan Zhan","Xin He","Siliang Tang","Qi Tian","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2303.03800v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03797v1","updated":"2023-03-07T11:03:33Z","published":"2023-03-07T11:03:33Z","title":"External Camera-based Mobile Robot Pose Estimation for Collaborative\n  Perception with Smart Edge Sensors","summary":"  We present an approach for estimating a mobile robot's pose w.r.t. the\nallocentric coordinates of a network of static cameras using multi-view RGB\nimages. The images are processed online, locally on smart edge sensors by deep\nneural networks to detect the robot and estimate 2D keypoints defined at\ndistinctive positions of the 3D robot model. Robot keypoint detections are\nsynchronized and fused on a central backend, where the robot's pose is\nestimated via multi-view minimization of reprojection errors. Through the pose\nestimation from external cameras, the robot's localization can be initialized\nin an allocentric map from a completely unknown state (kidnapped robot problem)\nand robustly tracked over time. We conduct a series of experiments evaluating\nthe accuracy and robustness of the camera-based pose estimation compared to the\nrobot's internal navigation stack, showing that our camera-based method\nachieves pose errors below 3 cm and 1{\\deg} and does not drift over time, as\nthe robot is localized allocentrically. With the robot's pose precisely\nestimated, its observations can be fused into the allocentric scene model. We\nshow a real-world application, where observations from mobile robot and static\nsmart edge sensors are fused to collaboratively build a 3D semantic map of a\n$\\sim$240 m$^2$ indoor environment.\n","authors":["Simon Bultmann","Raphael Memmesheimer","Sven Behnke"],"pdf_url":"https://arxiv.org/pdf/2303.03797v1.pdf","comment":"Accepted for ICRA 2023, 7 pages, 8 figures"},{"id":"http://arxiv.org/abs/2303.03794v1","updated":"2023-03-07T11:01:19Z","published":"2023-03-07T11:01:19Z","title":"Hidden Knowledge: Mathematical Methods for the Extraction of the\n  Fingerprint of Medieval Paper from Digital Images","summary":"  Medieval paper, a handmade product, is made with a mould which leaves an\nindelible imprint on the sheet of paper. This imprint includes chain lines,\nlaid lines and watermarks which are often visible on the sheet. Extracting\nthese features allows the identification of paper stock and gives information\nabout chronology, localisation and movement of books and people. Most\ncomputational work for feature extraction of paper analysis has so far focused\non radiography or transmitted light images. While these imaging methods provide\nclear visualisation for the features of interest, they are expensive and time\nconsuming in their acquisition and not feasible for smaller institutions.\nHowever, reflected light images of medieval paper manuscripts are abundant and\npossibly cheaper in their acquisition. In this paper, we propose algorithms to\ndetect and extract the laid and chain lines from reflected light images. We\ntackle the main drawback of reflected light images, that is, the low contrast\nattenuation of lines and intensity jumps due to noise and degradation, by\nemploying the spectral total variation decomposition and develop methods for\nsubsequent line extraction. Our results clearly demonstrate the feasibility of\nusing reflected light images in paper analysis. This work enables the feature\nextraction for paper manuscripts that have otherwise not been analysed due to a\nlack of appropriate images. We also open the door for paper stock\nidentification at scale.\n","authors":["Tamara G. Grossmann","Carola-Bibiane Schönlieb","Orietta Da Rold"],"pdf_url":"https://arxiv.org/pdf/2303.03794v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.11423v2","updated":"2023-03-07T11:00:25Z","published":"2022-11-21T13:10:10Z","title":"Blur Interpolation Transformer for Real-World Motion from Blur","summary":"  This paper studies the challenging problem of recovering motion from blur,\nalso known as joint deblurring and interpolation or blur temporal\nsuper-resolution. The challenges are twofold: 1) the current methods still\nleave considerable room for improvement in terms of visual quality even on the\nsynthetic dataset, and 2) poor generalization to real-world data. To this end,\nwe propose a blur interpolation transformer (BiT) to effectively unravel the\nunderlying temporal correlation encoded in blur. Based on multi-scale residual\nSwin transformer blocks, we introduce dual-end temporal supervision and\ntemporally symmetric ensembling strategies to generate effective features for\ntime-varying motion rendering. In addition, we design a hybrid camera system to\ncollect the first real-world dataset of one-to-many blur-sharp video pairs.\nExperimental results show that BiT has a significant gain over the\nstate-of-the-art methods on the public dataset Adobe240. Besides, the proposed\nreal-world dataset effectively helps the model generalize well to real blurry\nscenarios. Code and data are available at https://github.com/zzh-tech/BiT.\n","authors":["Zhihang Zhong","Mingdeng Cao","Xiang Ji","Yinqiang Zheng","Imari Sato"],"pdf_url":"https://arxiv.org/pdf/2211.11423v2.pdf","comment":"Accepted by CVPR2023"},{"id":"http://arxiv.org/abs/2107.00627v3","updated":"2023-03-07T10:34:32Z","published":"2021-07-01T17:31:42Z","title":"Semi-Sparsity for Smoothing Filters","summary":"  In this paper, we propose an interesting semi-sparsity smoothing algorithm\nbased on a novel sparsity-inducing optimization framework. This method is\nderived from the multiple observations that semi-sparsity prior knowledge is\nmore universally applicable, especially in areas where sparsity is not fully\nadmitted, such as polynomial-smoothing surfaces. We illustrate that this\nsemi-sparsity can be identified into a generalized $L_0$-norm minimization in\nhigher-order gradient domains, thereby giving rise to a new \"feature-aware\"\nfiltering method with a powerful simultaneous-fitting ability in both sparse\nfeatures (singularities and sharpening edges) and non-sparse regions\n(polynomial-smoothing surfaces). Notice that a direct solver is always\nunavailable due to the non-convexity and combinatorial nature of $L_0$-norm\nminimization. Instead, we solve the model based on an efficient half-quadratic\nsplitting minimization with fast Fourier transforms (FFTs) for acceleration. We\nfinally demonstrate its versatility and many benefits to a series of\nsignal/image processing and computer vision applications.\n","authors":["Junqing Huang","Haihui Wang","Xuechao Wang","Michael Ruzhansky"],"pdf_url":"https://arxiv.org/pdf/2107.00627v3.pdf","comment":"Final version but delete the graphic processing part"},{"id":"http://arxiv.org/abs/2303.03770v1","updated":"2023-03-07T10:04:55Z","published":"2023-03-07T10:04:55Z","title":"Guiding Pseudo-labels with Uncertainty Estimation for Test-Time\n  Adaptation","summary":"  Standard Unsupervised Domain Adaptation (UDA) methods assume the availability\nof both source and target data during the adaptation. In this work, we\ninvestigate the Test-Time Adaptation (TTA), a specific case of UDA where a\nmodel is adapted to a target domain without access to source data. We propose a\nnovel approach for the TTA setting based on a loss reweighting strategy that\nbrings robustness against the noise that inevitably affects the pseudo-labels.\nThe classification loss is reweighted based on the reliability of the\npseudo-labels that is measured by estimating their uncertainty. Guided by such\nreweighting strategy, the pseudo-labels are progressively refined by\naggregating knowledge from neighbouring samples. Furthermore, a self-supervised\ncontrastive framework is leveraged as a target space regulariser to enhance\nsuch knowledge aggregation. A novel negative pairs exclusion strategy is\nproposed to identify and exclude negative pairs made of samples sharing the\nsame class, even in presence of some noise in the pseudo-labels. Our method\noutperforms previous methods on three major benchmarks by a large margin. We\nset the new TTA state-of-the-art on VisDA-C and DomainNet with a performance\ngain of +1.8\\% on both benchmarks and on PACS with +12.3\\% in the single-source\nsetting and +6.6\\% in\\ multi-target adaptation. Additional analyses demonstrate\nthat the proposed approach is robust to the noise, which results in\nsignificantly more accurate pseudo-labels compared to state-of-the-art\napproaches.\n","authors":["Mattia Litrico","Alessio Del Bue","Pietro Morerio"],"pdf_url":"https://arxiv.org/pdf/2303.03770v1.pdf","comment":"To be published in Proceedings of the IEEE/CVF Conference on Computer\n  Vision and Pattern Recognition (CVPR) 2023"},{"id":"http://arxiv.org/abs/2303.03767v1","updated":"2023-03-07T10:01:00Z","published":"2023-03-07T10:01:00Z","title":"Proactive Multi-Camera Collaboration For 3D Human Pose Estimation","summary":"  This paper presents a multi-agent reinforcement learning (MARL) scheme for\nproactive Multi-Camera Collaboration in 3D Human Pose Estimation in dynamic\nhuman crowds. Traditional fixed-viewpoint multi-camera solutions for human\nmotion capture (MoCap) are limited in capture space and susceptible to dynamic\nocclusions. Active camera approaches proactively control camera poses to find\noptimal viewpoints for 3D reconstruction. However, current methods still face\nchallenges with credit assignment and environment dynamics. To address these\nissues, our proposed method introduces a novel Collaborative Triangulation\nContribution Reward (CTCR) that improves convergence and alleviates multi-agent\ncredit assignment issues resulting from using 3D reconstruction accuracy as the\nshared reward. Additionally, we jointly train our model with multiple world\ndynamics learning tasks to better capture environment dynamics and encourage\nanticipatory behaviors for occlusion avoidance. We evaluate our proposed method\nin four photo-realistic UE4 environments to ensure validity and\ngeneralizability. Empirical results show that our method outperforms fixed and\nactive baselines in various scenarios with different numbers of cameras and\nhumans.\n","authors":["Hai Ci","Mickel Liu","Xuehai Pan","Fangwei Zhong","Yizhou Wang"],"pdf_url":"https://arxiv.org/pdf/2303.03767v1.pdf","comment":"ICLR 2023 poster"},{"id":"http://arxiv.org/abs/2302.01622v2","updated":"2023-03-07T10:00:43Z","published":"2023-02-03T09:49:13Z","title":"Private, fair and accurate: Training large-scale, privacy-preserving AI\n  models in medical imaging","summary":"  Artificial intelligence (AI) models are increasingly used in the medical\ndomain. However, as medical data is highly sensitive, special precautions to\nensure its protection are required. The gold standard for privacy preservation\nis the introduction of differential privacy (DP) to model training. Prior work\nindicates that DP has negative implications on model accuracy and fairness,\nwhich are unacceptable in medicine and represent a main barrier to the\nwidespread use of privacy-preserving techniques. In this work, we evaluated the\neffect of privacy-preserving training of AI models for chest radiograph\ndiagnosis regarding accuracy and fairness compared to non-private training. For\nthis, we used a large dataset (N=193,311) of high quality clinical chest\nradiographs, which were retrospectively collected and manually labeled by\nexperienced radiologists. We then compared non-private deep convolutional\nneural networks (CNNs) and privacy-preserving (DP) models with respect to\nprivacy-utility trade-offs measured as area under the\nreceiver-operator-characteristic curve (AUROC), and privacy-fairness\ntrade-offs, measured as Pearson's r or Statistical Parity Difference. We found\nthat the non-private CNNs achieved an average AUROC score of 0.90 +- 0.04 over\nall labels, whereas the DP CNNs with a privacy budget of epsilon=7.89 resulted\nin an AUROC of 0.87 +- 0.04, i.e., a mere 2.6% performance decrease compared to\nnon-private training. Furthermore, we found the privacy-preserving training not\nto amplify discrimination against age, sex or co-morbidity. Our study shows\nthat -- under the challenging realistic circumstances of a real-life clinical\ndataset -- the privacy-preserving training of diagnostic deep learning models\nis possible with excellent diagnostic accuracy and fairness.\n","authors":["Soroosh Tayebi Arasteh","Alexander Ziller","Christiane Kuhl","Marcus Makowski","Sven Nebelung","Rickmer Braren","Daniel Rueckert","Daniel Truhn","Georgios Kaissis"],"pdf_url":"https://arxiv.org/pdf/2302.01622v2.pdf","comment":"3 tables, 5 figures, 11 supplementary materials"},{"id":"http://arxiv.org/abs/2208.11451v3","updated":"2023-03-07T09:58:15Z","published":"2022-08-24T11:36:53Z","title":"Q-Net: Query-Informed Few-Shot Medical Image Segmentation","summary":"  Deep learning has achieved tremendous success in computer vision, while\nmedical image segmentation (MIS) remains a challenge, due to the scarcity of\ndata annotations. Meta-learning techniques for few-shot segmentation (Meta-FSS)\nhave been widely used to tackle this challenge, while they neglect possible\ndistribution shifts between the query image and the support set. In contrast,\nan experienced clinician can perceive and address such shifts by borrowing\ninformation from the query image, then fine-tune or calibrate her prior\ncognitive model accordingly. Inspired by this, we propose Q-Net, a\nQuery-informed Meta-FSS approach, which mimics in spirit the learning mechanism\nof an expert clinician. We build Q-Net based on ADNet, a recently proposed\nanomaly detection-inspired method. Specifically, we add two query-informed\ncomputation modules into ADNet, namely a query-informed threshold adaptation\nmodule and a query-informed prototype refinement module. Combining them with a\ndual-path extension of the feature extraction module, Q-Net achieves\nstate-of-the-art performance on widely used abdominal and cardiac magnetic\nresonance (MR) image datasets. Our work sheds light on a novel way to improve\nMeta-FSS techniques by leveraging query information.\n","authors":["Qianqian Shen","Yanan Li","Jiyong Jin","Bin Liu"],"pdf_url":"https://arxiv.org/pdf/2208.11451v3.pdf","comment":"Accpeted by Intelligent Systems Conference (IntelliSys) 2023"},{"id":"http://arxiv.org/abs/2303.03761v1","updated":"2023-03-07T09:56:23Z","published":"2023-03-07T09:56:23Z","title":"Graph Neural Networks in Vision-Language Image Understanding: A Survey","summary":"  2D image understanding is a complex problem within Computer Vision, but it\nholds the key to providing human level scene comprehension. It goes further\nthan identifying the objects in an image, and instead it attempts to understand\nthe scene. Solutions to this problem form the underpinning of a range of tasks,\nincluding image captioning, Visual Question Answering (VQA), and image\nretrieval. Graphs provide a natural way to represent the relational arrangement\nbetween objects in an image, and thus in recent years Graph Neural Networks\n(GNNs) have become a standard component of many 2D image understanding\npipelines, becoming a core architectural component especially in the VQA group\nof tasks. In this survey, we review this rapidly evolving field and we provide\na taxonomy of graph types used in 2D image understanding approaches, a\ncomprehensive list of the GNN models used in this domain, and a roadmap of\nfuture potential developments. To the best of our knowledge, this is the first\ncomprehensive survey that covers image captioning, visual question answering,\nand image retrieval techniques that focus on using GNNs as the main part of\ntheir architecture.\n","authors":["Henry Senior","Gregory Slabaugh","Shanxin Yuan","Luca Rossi"],"pdf_url":"https://arxiv.org/pdf/2303.03761v1.pdf","comment":"19 pages, 5 figures, 6 tables"},{"id":"http://arxiv.org/abs/2103.13201v4","updated":"2023-03-07T09:44:23Z","published":"2021-03-24T13:59:40Z","title":"DRO: Deep Recurrent Optimizer for Video to Depth","summary":"  There are increasing interests of studying the video-to-depth (V2D) problem\nwith machine learning techniques. While earlier methods directly learn a\nmapping from images to depth maps and camera poses, more recent works enforce\nmulti-view geometry constraints through optimization embedded in the learning\nframework. This paper presents a novel optimization method based on recurrent\nneural networks to further exploit the potential of neural networks in V2D.\nSpecifically, our neural optimizer alternately updates the depth and camera\nposes through iterations to minimize a feature-metric cost, and two gated\nrecurrent units iteratively improve the results by tracing historical\ninformation. Extensive experimental results demonstrate that our method\noutperforms previous methods and is more efficient in computation and memory\nconsumption than cost-volume-based methods. In particular, our self-supervised\nmethod outperforms previous supervised methods on the KITTI and ScanNet\ndatasets. Our source code is available at https://github.com/aliyun/dro-sfm.\n","authors":["Xiaodong Gu","Weihao Yuan","Zuozhuo Dai","Siyu Zhu","Chengzhou Tang","Zilong Dong","Ping Tan"],"pdf_url":"https://arxiv.org/pdf/2103.13201v4.pdf","comment":"Accepted by IEEE Robotics and Automation Letters"},{"id":"http://arxiv.org/abs/2303.03758v1","updated":"2023-03-07T09:40:22Z","published":"2023-03-07T09:40:22Z","title":"Patched Diffusion Models for Unsupervised Anomaly Detection in Brain MRI","summary":"  The use of supervised deep learning techniques to detect pathologies in brain\nMRI scans can be challenging due to the diversity of brain anatomy and the need\nfor annotated data sets. An alternative approach is to use unsupervised anomaly\ndetection, which only requires sample-level labels of healthy brains to create\na reference representation. This reference representation can then be compared\nto unhealthy brain anatomy in a pixel-wise manner to identify abnormalities. To\naccomplish this, generative models are needed to create anatomically consistent\nMRI scans of healthy brains. While recent diffusion models have shown promise\nin this task, accurately generating the complex structure of the human brain\nremains a challenge. In this paper, we propose a method that reformulates the\ngeneration task of diffusion models as a patch-based estimation of healthy\nbrain anatomy, using spatial context to guide and improve reconstruction. We\nevaluate our approach on data of tumors and multiple sclerosis lesions and\ndemonstrate a relative improvement of 25.1% compared to existing baselines.\n","authors":["Finn Behrendt","Debayan Bhattacharya","Julia Krüger","Roland Opfer","Alexander Schlaefer"],"pdf_url":"https://arxiv.org/pdf/2303.03758v1.pdf","comment":"Accepted full paper at the MIDL23 conference"},{"id":"http://arxiv.org/abs/2303.03757v1","updated":"2023-03-07T09:33:49Z","published":"2023-03-07T09:33:49Z","title":"Deep Learning for Inertial Positioning: A Survey","summary":"  Inertial sensor has been widely deployed on smartphones, drones, robots and\nIoT devices. Due to its importance in ubiquitous and robust localization,\ninertial sensor based positioning is key in many applications, including\npersonal navigation, location based security, and human-device interaction.\nHowever, inertial positioning suffers from the so-called error drifts problem,\nas the measurements of low-cost MEMS inertial sensor are corrupted with various\ninevitable error sources, leading to unbounded drifts when being integrated\ndoubly in traditional inertial navigation algorithms. Recently, with increasing\nsensor data and computational power, the fast developments in deep learning\nhave spurred a large amount of research works in introducing deep learning to\ntackle the problem of inertial positioning. Relevant literature spans from the\nareas of mobile computing, robotics and machine learning. This article\ncomprehensively reviews relevant works on deep learning based inertial\npositioning, connects the efforts from different fields, and covers how deep\nlearning can be applied to solve sensor calibration, positioning error drifts\nreduction and sensor fusion. Finally, we provide insights on the benefits and\nlimitations of existing works, and indicate the future opportunities in this\ndirection.\n","authors":["Changhao Chen"],"pdf_url":"https://arxiv.org/pdf/2303.03757v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03755v1","updated":"2023-03-07T09:30:43Z","published":"2023-03-07T09:30:43Z","title":"DLT: Conditioned layout generation with Joint Discrete-Continuous\n  Diffusion Layout Transformer","summary":"  Generating visual layouts is an essential ingredient of graphic design. The\nability to condition layout generation on a partial subset of component\nattributes is critical to real-world applications that involve user\ninteraction. Recently, diffusion models have demonstrated high-quality\ngenerative performances in various domains. However, it is unclear how to apply\ndiffusion models to the natural representation of layouts which consists of a\nmix of discrete (class) and continuous (location, size) attributes. To address\nthe conditioning layout generation problem, we introduce DLT, a joint\ndiscrete-continuous diffusion model. DLT is a transformer-based model which has\na flexible conditioning mechanism that allows for conditioning on any given\nsubset of all the layout component classes, locations, and sizes. Our method\noutperforms state-of-the-art generative models on various layout generation\ndatasets with respect to different metrics and conditioning settings.\nAdditionally, we validate the effectiveness of our proposed conditioning\nmechanism and the joint continuous-diffusion process. This joint process can be\nincorporated into a wide range of mixed discrete-continuous generative tasks.\n","authors":["Elad Levi","Eli Brosh","Mykola Mykhailych","Meir Perez"],"pdf_url":"https://arxiv.org/pdf/2303.03755v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03745v1","updated":"2023-03-07T09:09:13Z","published":"2023-03-07T09:09:13Z","title":"At Your Fingertips: Extracting Piano Fingering Instructions from Videos","summary":"  Piano fingering -- knowing which finger to use to play each note in a musical\npiece, is a hard and important skill to master when learning to play the piano.\nWhile some sheet music is available with expert-annotated fingering\ninformation, most pieces lack this information, and people often resort to\nlearning the fingering from demonstrations in online videos. We consider the AI\ntask of automating the extraction of fingering information from videos. This is\na non-trivial task as fingers are often occluded by other fingers, and it is\noften not clear from the video which of the keys were pressed, requiring the\nsynchronization of hand position information and knowledge about the notes that\nwere played. We show how to perform this task with high-accuracy using a\ncombination of deep-learning modules, including a GAN-based approach for\nfine-tuning on out-of-domain data. We extract the fingering information with an\nf1 score of 97\\%. We run the resulting system on 90 videos, resulting in\nhigh-quality piano fingering information of 150K notes, the largest available\ndataset of piano-fingering to date.\n","authors":["Amit Moryossef","Yanai Elazar","Yoav Goldberg"],"pdf_url":"https://arxiv.org/pdf/2303.03745v1.pdf","comment":"6 pages, paper from 2019"},{"id":"http://arxiv.org/abs/2303.03730v1","updated":"2023-03-07T08:42:46Z","published":"2023-03-07T08:42:46Z","title":"LORE: Logical Location Regression Network for Table Structure\n  Recognition","summary":"  Table structure recognition (TSR) aims at extracting tables in images into\nmachine-understandable formats. Recent methods solve this problem by predicting\nthe adjacency relations of detected cell boxes, or learning to generate the\ncorresponding markup sequences from the table images. However, they either\ncount on additional heuristic rules to recover the table structures, or require\na huge amount of training data and time-consuming sequential decoders. In this\npaper, we propose an alternative paradigm. We model TSR as a logical location\nregression problem and propose a new TSR framework called LORE, standing for\nLOgical location REgression network, which for the first time combines logical\nlocation regression together with spatial location regression of table cells.\nOur proposed LORE is conceptually simpler, easier to train and more accurate\nthan previous TSR models of other paradigms. Experiments on standard benchmarks\ndemonstrate that LORE consistently outperforms prior arts. Code is available at\nhttps://\ngithub.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/DocumentUnderstanding/LORE-TSR.\n","authors":["Hangdi Xing","Feiyu Gao","Rujiao Long","Jiajun Bu","Qi Zheng","Liangcheng Li","Cong Yao","Zhi Yu"],"pdf_url":"https://arxiv.org/pdf/2303.03730v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03729v1","updated":"2023-03-07T08:37:48Z","published":"2023-03-07T08:37:48Z","title":"Learning Discriminative Representations for Skeleton Based Action\n  Recognition","summary":"  Human action recognition aims at classifying the category of human action\nfrom a segment of a video. Recently, people dive into designing GCN-based\nmodels to extract features from skeletons for performing this task, because\nskeleton representations are much efficient and robust than other modalities\nsuch as RGB frames. However, when employing the skeleton data, some important\nclues like related items are also dismissed. It results in some ambiguous\nactions that are hard to be distinguished and tend to be misclassified. To\nalleviate this problem, we propose an auxiliary feature refinement head (FR\nHead), which consists of spatial-temporal decoupling and contrastive feature\nrefinement, to obtain discriminative representations of skeletons. Ambiguous\nsamples are dynamically discovered and calibrated in the feature space.\nFurthermore, FR Head could be imposed on different stages of GCNs to build a\nmulti-level refinement for stronger supervision. Extensive experiments are\nconducted on NTU RGB+D, NTU RGB+D 120, and NW-UCLA datasets. Our proposed\nmodels obtain competitive results from state-of-the-art methods and can help to\ndiscriminate those ambiguous samples.\n","authors":["Huanyu Zhou","Qingjie Liu","Yunhong Wang"],"pdf_url":"https://arxiv.org/pdf/2303.03729v1.pdf","comment":"Accepted by CVPR2023. 10 pages, 5 figures, 5 tables"},{"id":"http://arxiv.org/abs/2303.03728v1","updated":"2023-03-07T08:31:42Z","published":"2023-03-07T08:31:42Z","title":"Refined Pseudo labeling for Source-free Domain Adaptive Object Detection","summary":"  Domain adaptive object detection (DAOD) assumes that both labeled source data\nand unlabeled target data are available for training, but this assumption does\nnot always hold in real-world scenarios. Thus, source-free DAOD is proposed to\nadapt the source-trained detectors to target domains with only unlabeled target\ndata. Existing source-free DAOD methods typically utilize pseudo labeling,\nwhere the performance heavily relies on the selection of confidence threshold.\nHowever, most prior works adopt a single fixed threshold for all classes to\ngenerate pseudo labels, which ignore the imbalanced class distribution,\nresulting in biased pseudo labels. In this work, we propose a refined pseudo\nlabeling framework for source-free DAOD. First, to generate unbiased pseudo\nlabels, we present a category-aware adaptive threshold estimation module, which\nadaptively provides the appropriate threshold for each category. Second, to\nalleviate incorrect box regression, a localization-aware pseudo label\nassignment strategy is introduced to divide labels into certain and uncertain\nones and optimize them separately. Finally, extensive experiments on four\nadaptation tasks demonstrate the effectiveness of our method.\n","authors":["Siqi Zhang","Lu Zhang","Zhiyong Liu"],"pdf_url":"https://arxiv.org/pdf/2303.03728v1.pdf","comment":"Accepted to ICASSP 2023"},{"id":"http://arxiv.org/abs/2211.04894v3","updated":"2023-03-07T08:25:24Z","published":"2022-11-09T13:55:50Z","title":"Exploring Video Quality Assessment on User Generated Contents from\n  Aesthetic and Technical Perspectives","summary":"  The rapid increase in user-generated-content (UGC) videos calls for the\ndevelopment of effective video quality assessment (VQA) algorithms. However,\nthe objective of the UGC-VQA problem is still ambiguous and can be viewed from\ntwo perspectives: the technical perspective, measuring the perception of\ndistortions; and the aesthetic perspective, which relates to preference and\nrecommendation on contents. To understand how these two perspectives affect\noverall subjective opinions in UGC-VQA, we conduct a large-scale subjective\nstudy to collect human quality opinions on overall quality of videos as well as\nperceptions from aesthetic and technical perspectives. The collected\nDisentangled Video Quality Database (DIVIDE-3k) confirms that human quality\nopinions on UGC videos are universally and inevitably affected by both\naesthetic and technical perspectives. In light of this, we propose the\nDisentangled Objective Video Quality Evaluator (DOVER) to learn the quality of\nUGC videos based on the two perspectives. The DOVER proves state-of-the-art\nperformance in UGC-VQA under very high efficiency. With perspective opinions in\nDIVIDE-3k, we further propose DOVER++, the first approach to provide reliable\nclear-cut quality evaluations from a single aesthetic or technical perspective.\nCode at https://github.com/VQAssessment/DOVER.\n","authors":["Haoning Wu","Erli Zhang","Liang Liao","Chaofeng Chen","Jingwen Hou","Annan Wang","Wenxiu Sun","Qiong Yan","Weisi Lin"],"pdf_url":"https://arxiv.org/pdf/2211.04894v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03716v1","updated":"2023-03-07T07:57:12Z","published":"2023-03-07T07:57:12Z","title":"Challenges of the Creation of a Dataset for Vision Based Human Hand\n  Action Recognition in Industrial Assembly","summary":"  This work presents the Industrial Hand Action Dataset V1, an industrial\nassembly dataset consisting of 12 classes with 459,180 images in the basic\nversion and 2,295,900 images after spatial augmentation. Compared to other\nfreely available datasets tested, it has an above-average duration and, in\naddition, meets the technical and legal requirements for industrial assembly\nlines. Furthermore, the dataset contains occlusions, hand-object interaction,\nand various fine-grained human hand actions for industrial assembly tasks that\nwere not found in combination in examined datasets. The recorded ground truth\nassembly classes were selected after extensive observation of real-world use\ncases. A Gated Transformer Network, a state-of-the-art model from the\ntransformer domain was adapted, and proved with a test accuracy of 86.25%\nbefore hyperparameter tuning by 18,269,959 trainable parameters, that it is\npossible to train sequential deep learning models with this dataset.\n","authors":["Fabian Sturm","Elke Hergenroether","Julian Reinhardt","Petar Smilevski Vojnovikj","Melanie Siegel"],"pdf_url":"https://arxiv.org/pdf/2303.03716v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03709v1","updated":"2023-03-07T07:47:41Z","published":"2023-03-07T07:47:41Z","title":"Bootstrap The Original Latent: Freeze-and-thaw Adapter for\n  Back-Propagated Black-Box Adaptation","summary":"  In this paper, considering the balance of data/model privacy of model owners\nand user needs, we propose a new setting called Back-Propagated Black-Box\nAdaptation (BPBA) for users to better train their private models via the\nguidance of the back-propagated results of foundation/source models. Our\nsetting can ease the usage of foundation/source models as well as prevent the\nleakage and misuse of foundation/source models. Moreover, we also propose a new\ntraining strategy called Bootstrap The Original Latent (BTOL) to fully utilize\nthe foundation/source models. Our strategy consists of a domain adapter and a\nfreeze-and-thaw strategy. We apply our BTOL under BPBA and Black-box UDA\nsettings on three different datasets. Experiments show that our strategy is\nefficient and robust in various settings without manual augmentations.\n","authors":["Shuai Wang","Daoan Zhang","Jianguo Zhang","Weiwei Zhang","Rui Li"],"pdf_url":"https://arxiv.org/pdf/2303.03709v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03707v1","updated":"2023-03-07T07:42:37Z","published":"2023-03-07T07:42:37Z","title":"Hybrid quantum-classical convolutional neural network for phytoplankton\n  classification","summary":"  The taxonomic composition and abundance of phytoplankton, having direct\nimpact on marine ecosystem dynamic and global environment change, are listed as\nessential ocean variables. Phytoplankton classification is very crucial for\nPhytoplankton analysis, but it is very difficult because of the huge amount and\ntiny volume of Phytoplankton. Machine learning is the principle way of\nperforming phytoplankton image classification automatically. When carrying out\nlarge-scale research on the marine phytoplankton, the volume of data increases\noverwhelmingly and more powerful computational resources are required for the\nsuccess of machine learning algorithms. Recently, quantum machine learning has\nemerged as the potential solution for large-scale data processing by harnessing\nthe exponentially computational power of quantum computer. Here, for the first\ntime, we demonstrate the feasibility of quantum deep neural networks for\nphytoplankton classification. Hybrid quantum-classical convolutional and\nresidual neural networks are developed based on the classical architectures.\nThese models make a proper balance between the limited function of the current\nquantum devices and the large size of phytoplankton images, which make it\npossible to perform phytoplankton classification on the near-term quantum\ncomputers. Better performance is obtained by the quantum-enhanced models\nagainst the classical counterparts. In particular, quantum models converge much\nfaster than classical ones. The present quantum models are versatile, and can\nbe applied for various tasks of image classification in the field of marine\nscience.\n","authors":["Shangshang Shi","Zhimin Wang","Ruimin Shang","Yanan Li","Jiaxin Li","Guoqiang Zhong","Yongjian Gu"],"pdf_url":"https://arxiv.org/pdf/2303.03707v1.pdf","comment":"20 pages, 13 figures"},{"id":"http://arxiv.org/abs/2303.03698v1","updated":"2023-03-07T07:30:08Z","published":"2023-03-07T07:30:08Z","title":"FIT: Frequency-based Image Translation for Domain Adaptive Object\n  Detection","summary":"  Domain adaptive object detection (DAOD) aims to adapt the detector from a\nlabelled source domain to an unlabelled target domain. In recent years, DAOD\nhas attracted massive attention since it can alleviate performance degradation\ndue to the large shift of data distributions in the wild. To align\ndistributions between domains, adversarial learning is widely used in existing\nDAOD methods. However, the decision boundary for the adversarial domain\ndiscriminator may be inaccurate, causing the model biased towards the source\ndomain. To alleviate this bias, we propose a novel Frequency-based Image\nTranslation (FIT) framework for DAOD. First, by keeping domain-invariant\nfrequency components and swapping domain-specific ones, we conduct image\ntranslation to reduce domain shift at the input level. Second, hierarchical\nadversarial feature learning is utilized to further mitigate the domain gap at\nthe feature level. Finally, we design a joint loss to train the entire network\nin an end-to-end manner without extra training to obtain translated images.\nExtensive experiments on three challenging DAOD benchmarks demonstrate the\neffectiveness of our method.\n","authors":["Siqi Zhang","Lu Zhang","Zhiyong Liu","Hangtao Feng"],"pdf_url":"https://arxiv.org/pdf/2303.03698v1.pdf","comment":"Accepted to ICONIP 2022"},{"id":"http://arxiv.org/abs/2210.06575v2","updated":"2023-03-07T07:26:40Z","published":"2022-10-12T20:31:23Z","title":"GraspNeRF: Multiview-based 6-DoF Grasp Detection for Transparent and\n  Specular Objects Using Generalizable NeRF","summary":"  In this work, we tackle 6-DoF grasp detection for transparent and specular\nobjects, which is an important yet challenging problem in vision-based robotic\nsystems, due to the failure of depth cameras in sensing their geometry. We, for\nthe first time, propose a multiview RGB-based 6-DoF grasp detection network,\nGraspNeRF, that leverages the generalizable neural radiance field (NeRF) to\nachieve material-agnostic object grasping in clutter. Compared to the existing\nNeRF-based 3-DoF grasp detection methods that rely on densely captured input\nimages and time-consuming per-scene optimization, our system can perform\nzero-shot NeRF construction with sparse RGB inputs and reliably detect 6-DoF\ngrasps, both in real-time. The proposed framework jointly learns generalizable\nNeRF and grasp detection in an end-to-end manner, optimizing the scene\nrepresentation construction for the grasping. For training data, we generate a\nlarge-scale photorealistic domain-randomized synthetic dataset of grasping in\ncluttered tabletop scenes that enables direct transfer to the real world. Our\nextensive experiments in synthetic and real-world environments demonstrate that\nour method significantly outperforms all the baselines in all the experiments\nwhile remaining in real-time. Project page can be found at\nhttps://pku-epic.github.io/GraspNeRF\n","authors":["Qiyu Dai","Yan Zhu","Yiran Geng","Ciyu Ruan","Jiazhao Zhang","He Wang"],"pdf_url":"https://arxiv.org/pdf/2210.06575v2.pdf","comment":"IEEE International Conference on Robotics and Automation (ICRA), 2023"},{"id":"http://arxiv.org/abs/2109.04100v2","updated":"2023-03-07T07:19:42Z","published":"2021-09-09T08:38:17Z","title":"Taming Self-Supervised Learning for Presentation Attack Detection:\n  In-Image De-Folding and Out-of-Image De-Mixing","summary":"  Biometric systems are vulnerable to Presentation Attacks (PA) performed using\nvarious Presentation Attack Instruments (PAIs). Even though there are numerous\nPresentation Attack Detection (PAD) techniques based on both deep learning and\nhand-crafted features, the generalization of PAD for unknown PAI is still a\nchallenging problem. In this work, we empirically prove that the initialization\nof the PAD model is a crucial factor for the generalization, which is rarely\ndiscussed in the community. Based on such observation, we proposed a\nself-supervised learning-based method, denoted as DF-DM. Specifically, DF-DM is\nbased on a global-local view coupled with De-Folding and De-Mixing to derive\nthe task-specific representation for PAD. During De-Folding, the proposed\ntechnique will learn region-specific features to represent samples in a local\npattern by explicitly minimizing generative loss. While De-Mixing drives\ndetectors to obtain the instance-specific features with global information for\nmore comprehensive representation by minimizing interpolation-based\nconsistency. Extensive experimental results show that the proposed method can\nachieve significant improvements in terms of both face and fingerprint PAD in\nmore complicated and hybrid datasets when compared with state-of-the-art\nmethods. When training in CASIA-FASD and Idiap Replay-Attack, the proposed\nmethod can achieve an 18.60% Equal Error Rate (EER) in OULU-NPU and MSU-MFSD,\nexceeding baseline performance by 9.54%. The source code of the proposed\ntechnique is available at https://github.com/kongzhecn/dfdm.\n","authors":["Zhe Kong","Wentian Zhang","Feng Liu","Wenhan Luo","Haozhe Liu","Linlin Shen","Raghavendra Ramachandra"],"pdf_url":"https://arxiv.org/pdf/2109.04100v2.pdf","comment":"Accepted by IEEE Transactions on Neural Networks and Learning Systems\n  (TNNLS)"},{"id":"http://arxiv.org/abs/2303.03684v1","updated":"2023-03-07T06:54:48Z","published":"2023-03-07T06:54:48Z","title":"MOSO: Decomposing MOtion, Scene and Object for Video Prediction","summary":"  Motion, scene and object are three primary visual components of a video. In\nparticular, objects represent the foreground, scenes represent the background,\nand motion traces their dynamics. Based on this insight, we propose a two-stage\nMOtion, Scene and Object decomposition framework (MOSO) for video prediction,\nconsisting of MOSO-VQVAE and MOSO-Transformer. In the first stage, MOSO-VQVAE\ndecomposes a previous video clip into the motion, scene and object components,\nand represents them as distinct groups of discrete tokens. Then, in the second\nstage, MOSO-Transformer predicts the object and scene tokens of the subsequent\nvideo clip based on the previous tokens and adds dynamic motion at the token\nlevel to the generated object and scene tokens. Our framework can be easily\nextended to unconditional video generation and video frame interpolation tasks.\nExperimental results demonstrate that our method achieves new state-of-the-art\nperformance on five challenging benchmarks for video prediction and\nunconditional video generation: BAIR, RoboNet, KTH, KITTI and UCF101. In\naddition, MOSO can produce realistic videos by combining objects and scenes\nfrom different videos.\n","authors":["Mingzhen Sun","Weining Wang","Xinxin Zhu","Jing Liu"],"pdf_url":"https://arxiv.org/pdf/2303.03684v1.pdf","comment":"Accepted by CVPR 2023"},{"id":"http://arxiv.org/abs/2303.03680v1","updated":"2023-03-07T06:42:52Z","published":"2023-03-07T06:42:52Z","title":"Logit Margin Matters: Improving Transferable Targeted Adversarial Attack\n  by Logit Calibration","summary":"  Previous works have extensively studied the transferability of adversarial\nsamples in untargeted black-box scenarios. However, it still remains\nchallenging to craft targeted adversarial examples with higher transferability\nthan non-targeted ones. Recent studies reveal that the traditional\nCross-Entropy (CE) loss function is insufficient to learn transferable targeted\nadversarial examples due to the issue of vanishing gradient. In this work, we\nprovide a comprehensive investigation of the CE loss function and find that the\nlogit margin between the targeted and untargeted classes will quickly obtain\nsaturation in CE, which largely limits the transferability. Therefore, in this\npaper, we devote to the goal of continually increasing the logit margin along\nthe optimization to deal with the saturation issue and propose two simple and\neffective logit calibration methods, which are achieved by downscaling the\nlogits with a temperature factor and an adaptive margin, respectively. Both of\nthem can effectively encourage optimization to produce a larger logit margin\nand lead to higher transferability. Besides, we show that minimizing the cosine\ndistance between the adversarial examples and the classifier weights of the\ntarget class can further improve the transferability, which is benefited from\ndownscaling logits via L2-normalization. Experiments conducted on the ImageNet\ndataset validate the effectiveness of the proposed methods, which outperform\nthe state-of-the-art methods in black-box targeted attacks. The source code is\navailable at \\href{https://github.com/WJJLL/Target-Attack/}{Link}\n","authors":["Juanjuan Weng","Zhiming Luo","Zhun Zhong","Shaozi Li","Nicu Sebe"],"pdf_url":"https://arxiv.org/pdf/2303.03680v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03679v1","updated":"2023-03-07T06:38:48Z","published":"2023-03-07T06:38:48Z","title":"MAST: Masked Augmentation Subspace Training for Generalizable\n  Self-Supervised Priors","summary":"  Recent Self-Supervised Learning (SSL) methods are able to learn feature\nrepresentations that are invariant to different data augmentations, which can\nthen be transferred to downstream tasks of interest. However, different\ndownstream tasks require different invariances for their best performance, so\nthe optimal choice of augmentations for SSL depends on the target task. In this\npaper, we aim to learn self-supervised features that generalize well across a\nvariety of downstream tasks (e.g., object classification, detection and\ninstance segmentation) without knowing any task information beforehand. We do\nso by Masked Augmentation Subspace Training (or MAST) to encode in the single\nfeature space the priors from different data augmentations in a factorized way.\nSpecifically, we disentangle the feature space into separate subspaces, each\ninduced by a learnable mask that selects relevant feature dimensions to model\ninvariance to a specific augmentation. We show the success of MAST in jointly\ncapturing generalizable priors from different augmentations, using both unique\nand shared features across the subspaces. We further show that MAST benefits\nfrom uncertainty modeling to reweight ambiguous samples from strong\naugmentations that may cause similarity mismatch in each subspace. Experiments\ndemonstrate that MAST consistently improves generalization on various\ndownstream tasks, while being task-agnostic and efficient during SSL. We also\nprovide interesting insights about how different augmentations are related and\nhow uncertainty reflects learning difficulty.\n","authors":["Chen Huang","Hanlin Goh","Jiatao Gu","Josh Susskind"],"pdf_url":"https://arxiv.org/pdf/2303.03679v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2209.02890v3","updated":"2023-03-07T06:37:40Z","published":"2022-09-07T02:23:40Z","title":"Data-Driven Target Localization Using Adaptive Radar Processing and\n  Convolutional Neural Networks","summary":"  Facilitated by the recent emergence of radio frequency (RF) modeling and\nsimulation tools purposed for adaptive radar processing applications,\ndata-driven approaches to classical problems in radar have rapidly grown in\npopularity over the past decade. Despite this surge, limited focus has been\ndirected toward the theoretical foundations of these data-driven approaches. In\nthis regard, using adaptive radar processing techniques, we propose a\ndata-driven approach in this work to address the classical problem of radar\ntarget localization post adaptive radar detection. To give context to the\nperformance of this data-driven approach, we first analyze the asymptotic\nbreakdown signal-to-clutter-plus-noise ratio (SCNR) threshold of the normalized\nadaptive matched filter (NAMF) test statistic within the context of radar\ntarget localization, and augment this analysis through our proposed deep\nlearning framework for target location estimation. In this procedure, we\ngenerate comprehensive datasets by randomly placing targets of variable\nstrengths in predetermined constrained areas using RFView, a site-specific,\ndigital twin, RF modeling and simulation tool. For each radar return from these\npredefined constrained areas, we generate heatmap tensors in range, azimuth,\nand elevation of the NAMF test statistic, and of the output power of a\ngeneralized sidelobe canceller (GSC). Using our deep learning framework, we\nestimate target locations from these heatmap tensors to demonstrate the\nfeasibility of and significant improvements provided by our data-driven\napproach across matched and mismatched settings.\n","authors":["Shyam Venkatasubramanian","Sandeep Gogineni","Bosung Kang","Ali Pezeshki","Muralidhar Rangaswamy","Vahid Tarokh"],"pdf_url":"https://arxiv.org/pdf/2209.02890v3.pdf","comment":"34 pages, 22 figures. Submitted to IEEE Transactions on Aerospace and\n  Electronic Systems"},{"id":"http://arxiv.org/abs/2111.07620v2","updated":"2023-03-07T06:37:09Z","published":"2021-11-15T09:13:21Z","title":"Fingerprint Presentation Attack Detection by Channel-wise Feature\n  Denoising","summary":"  Due to the diversity of attack materials, fingerprint recognition systems\n(AFRSs) are vulnerable to malicious attacks. It is thus important to propose\neffective fingerprint presentation attack detection (PAD) methods for the\nsafety and reliability of AFRSs. However, current PAD methods often exhibit\npoor robustness under new attack types settings. This paper thus proposes a\nnovel channel-wise feature denoising fingerprint PAD (CFD-PAD) method by\nhandling the redundant noise information ignored in previous studies. The\nproposed method learns important features of fingerprint images by weighing the\nimportance of each channel and identifying discriminative channels and \"noise\"\nchannels. Then, the propagation of \"noise\" channels is suppressed in the\nfeature map to reduce interference. Specifically, a PA-Adaptation loss is\ndesigned to constrain the feature distribution to make the feature distribution\nof live fingerprints more aggregate and that of spoof fingerprints more\ndisperse. Experimental results evaluated on the LivDet 2017 dataset showed that\nthe proposed CFD-PAD can achieve a 2.53% average classification error (ACE) and\na 93.83% true detection rate when the false detection rate equals 1.0%\n(TDR@FDR=1%). Also, the proposed method markedly outperforms the best\nsingle-model-based methods in terms of ACE (2.53% vs. 4.56%) and\nTDR@FDR=1%(93.83% vs. 73.32%), which demonstrates its effectiveness. Although\nwe have achieved a comparable result with the state-of-the-art\nmultiple-model-based methods, there still is an increase in TDR@FDR=1% from\n91.19% to 93.83%. In addition, the proposed model is simpler, lighter and more\nefficient and has achieved a 74.76% reduction in computation time compared with\nthe state-of-the-art multiple-model-based method. The source code is available\nat https://github.com/kongzhecn/cfd-pad.\n","authors":["Feng Liu","Zhe Kong","Haozhe Liu","Wentian Zhang","Linlin Shen"],"pdf_url":"https://arxiv.org/pdf/2111.07620v2.pdf","comment":"15 pages, 8 figures, Accepted by TIFS"},{"id":"http://arxiv.org/abs/2303.03672v1","updated":"2023-03-07T06:16:10Z","published":"2023-03-07T06:16:10Z","title":"CIFF-Net: Contextual Image Feature Fusion for Melanoma Diagnosis","summary":"  Melanoma is considered to be the deadliest variant of skin cancer causing\naround 75\\% of total skin cancer deaths. To diagnose Melanoma, clinicians\nassess and compare multiple skin lesions of the same patient concurrently to\ngather contextual information regarding the patterns, and abnormality of the\nskin. So far this concurrent multi-image comparative method has not been\nexplored by existing deep learning-based schemes. In this paper, based on\ncontextual image feature fusion (CIFF), a deep neural network (CIFF-Net) is\nproposed, which integrates patient-level contextual information into the\ntraditional approaches for improved Melanoma diagnosis by concurrent\nmulti-image comparative method. The proposed multi-kernel self attention (MKSA)\nmodule offers better generalization of the extracted features by introducing\nmulti-kernel operations in the self attention mechanisms. To utilize both self\nattention and contextual feature-wise attention, an attention guided module\nnamed contextual feature fusion (CFF) is proposed that integrates extracted\nfeatures from different contextual images into a single feature vector.\nFinally, in comparative contextual feature fusion (CCFF) module, primary and\ncontextual features are compared concurrently to generate comparative features.\nSignificant improvement in performance has been achieved on the ISIC-2020\ndataset over the traditional approaches that validate the effectiveness of the\nproposed contextual learning scheme.\n","authors":["Md Awsafur Rahman","Bishmoy Paul","Tanvir Mahmud","Shaikh Anowarul Fattah"],"pdf_url":"https://arxiv.org/pdf/2303.03672v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.15603v3","updated":"2023-03-07T06:14:56Z","published":"2022-11-28T17:57:48Z","title":"Action-GPT: Leveraging Large-scale Language Models for Improved and\n  Generalized Action Generation","summary":"  We introduce Action-GPT, a plug-and-play framework for incorporating Large\nLanguage Models (LLMs) into text-based action generation models. Action phrases\nin current motion capture datasets contain minimal and to-the-point\ninformation. By carefully crafting prompts for LLMs, we generate richer and\nfine-grained descriptions of the action. We show that utilizing these detailed\ndescriptions instead of the original action phrases leads to better alignment\nof text and motion spaces. We introduce a generic approach compatible with\nstochastic (e.g. VAE-based) and deterministic (e.g. MotionCLIP) text-to-motion\nmodels. In addition, the approach enables multiple text descriptions to be\nutilized. Our experiments show (i) noticeable qualitative and quantitative\nimprovement in the quality of synthesized motions, (ii) benefits of utilizing\nmultiple LLM-generated descriptions, (iii) suitability of the prompt function,\nand (iv) zero-shot generation capabilities of the proposed approach. Project\npage: https://actiongpt.github.io\n","authors":["Sai Shashank Kalakonda","Shubh Maheshwari","Ravi Kiran Sarvadevabhatla"],"pdf_url":"https://arxiv.org/pdf/2211.15603v3.pdf","comment":"Code, pretrained models and sample videos will be made available at\n  \\url{https://actiongpt.github.io}"},{"id":"http://arxiv.org/abs/2303.03667v1","updated":"2023-03-07T06:05:30Z","published":"2023-03-07T06:05:30Z","title":"Run, Don't Walk: Chasing Higher FLOPS for Faster Neural Networks","summary":"  To design fast neural networks, many works have been focusing on reducing the\nnumber of floating-point operations (FLOPs). We observe that such reduction in\nFLOPs, however, does not necessarily lead to a similar level of reduction in\nlatency. This mainly stems from inefficiently low floating-point operations per\nsecond (FLOPS). To achieve faster networks, we revisit popular operators and\ndemonstrate that such low FLOPS is mainly due to frequent memory access of the\noperators, especially the depthwise convolution. We hence propose a novel\npartial convolution (PConv) that extracts spatial features more efficiently, by\ncutting down redundant computation and memory access simultaneously. Building\nupon our PConv, we further propose FasterNet, a new family of neural networks,\nwhich attains substantially higher running speed than others on a wide range of\ndevices, without compromising on accuracy for various vision tasks. For\nexample, on ImageNet-1k, our tiny FasterNet-T0 is $3.1\\times$, $3.1\\times$, and\n$2.5\\times$ faster than MobileViT-XXS on GPU, CPU, and ARM processors,\nrespectively, while being $2.9\\%$ more accurate. Our large FasterNet-L achieves\nimpressive $83.5\\%$ top-1 accuracy, on par with the emerging Swin-B, while\nhaving $49\\%$ higher inference throughput on GPU, as well as saving $42\\%$\ncompute time on CPU. Code is available at\n\\url{https://github.com/JierunChen/FasterNet}.\n","authors":["Jierun Chen","Shiu-hong Kao","Hao He","Weipeng Zhuo","Song Wen","Chul-Ho Lee","S. -H. Gary Chan"],"pdf_url":"https://arxiv.org/pdf/2303.03667v1.pdf","comment":"Accepted to CVPR 2023"},{"id":"http://arxiv.org/abs/2211.03264v3","updated":"2023-03-07T05:43:56Z","published":"2022-11-07T02:18:27Z","title":"Few-shot Image Generation with Diffusion Models","summary":"  Denoising diffusion probabilistic models (DDPMs) have been proven capable of\nsynthesizing high-quality images with remarkable diversity when trained on\nlarge amounts of data. However, to our knowledge, few-shot image generation\ntasks have yet to be studied with DDPM-based approaches. Modern approaches are\nmainly built on Generative Adversarial Networks (GANs) and adapt models\npre-trained on large source domains to target domains using a few available\nsamples. In this paper, we make the first attempt to study when do DDPMs\noverfit and suffer severe diversity degradation as training data become scarce.\nThen we fine-tune DDPMs pre-trained on large source domains to solve the\noverfitting problem when training data is limited. Although the directly\nfine-tuned models accelerate convergence and improve generation quality and\ndiversity compared with training from scratch, they still fail to retain some\ndiverse features and can only produce coarse images. Therefore, we design a\nDDPM pairwise adaptation (DDPM-PA) approach to optimize few-shot DDPM domain\nadaptation. DDPM-PA efficiently preserves information learned from source\ndomains by keeping the relative pairwise distances between generated samples\nduring adaptation. Besides, DDPM-PA enhances the learning of high-frequency\ndetails from source models and limited training data. DDPM-PA further improves\ngeneration quality and diversity and achieves results better than current\nstate-of-the-art GAN-based approaches. We demonstrate the effectiveness of our\napproach on a series of few-shot image generation tasks qualitatively and\nquantitatively.\n","authors":["Jingyuan Zhu","Huimin Ma","Jiansheng Chen","Jian Yuan"],"pdf_url":"https://arxiv.org/pdf/2211.03264v3.pdf","comment":"Updated Version"},{"id":"http://arxiv.org/abs/2303.02968v2","updated":"2023-03-07T05:43:39Z","published":"2023-03-06T08:53:22Z","title":"DwinFormer: Dual Window Transformers for End-to-End Monocular Depth\n  Estimation","summary":"  Depth estimation from a single image is of paramount importance in the realm\nof computer vision, with a multitude of applications. Conventional methods\nsuffer from the trade-off between consistency and fine-grained details due to\nthe local-receptive field limiting their practicality. This lack of long-range\ndependency inherently comes from the convolutional neural network part of the\narchitecture. In this paper, a dual window transformer-based network, namely\nDwinFormer, is proposed, which utilizes both local and global features for\nend-to-end monocular depth estimation. The DwinFormer consists of dual window\nself-attention and cross-attention transformers, Dwin-SAT and Dwin-CAT,\nrespectively. The Dwin-SAT seamlessly extracts intricate, locally aware\nfeatures while concurrently capturing global context. It harnesses the power of\nlocal and global window attention to adeptly capture both short-range and\nlong-range dependencies, obviating the need for complex and computationally\nexpensive operations, such as attention masking or window shifting. Moreover,\nDwin-SAT introduces inductive biases which provide desirable properties, such\nas translational equvariance and less dependence on large-scale data.\nFurthermore, conventional decoding methods often rely on skip connections which\nmay result in semantic discrepancies and a lack of global context when fusing\nencoder and decoder features. In contrast, the Dwin-CAT employs both local and\nglobal window cross-attention to seamlessly fuse encoder and decoder features\nwith both fine-grained local and contextually aware global information,\neffectively amending semantic gap. Empirical evidence obtained through\nextensive experimentation on the NYU-Depth-V2 and KITTI datasets demonstrates\nthe superiority of the proposed method, consistently outperforming existing\napproaches across both indoor and outdoor environments.\n","authors":["Md Awsafur Rahman","Shaikh Anowarul Fattah"],"pdf_url":"https://arxiv.org/pdf/2303.02968v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.12735v3","updated":"2023-03-07T05:29:56Z","published":"2021-06-24T02:52:12Z","title":"Multi-Modal 3D Object Detection in Autonomous Driving: a Survey","summary":"  In this survey, we first introduce the background of popular sensors used for\nself-driving, their data properties, and the corresponding object detection\nalgorithms. Next, we discuss existing datasets that can be used for evaluating\nmulti-modal 3D object detection algorithms. Then we present a review of\nmulti-modal fusion based 3D detection networks, taking a close look at their\nfusion stage, fusion input and fusion granularity, and how these design choices\nevolve with time and technology. After the review, we discuss open challenges\nas well as possible solutions. We hope that this survey can help researchers to\nget familiar with the field and embark on investigations in the area of\nmulti-modal 3D object detection.\n","authors":["Yingjie Wang","Qiuyu Mao","Hanqi Zhu","Jiajun Deng","Yu Zhang","Jianmin Ji","Houqiang Li","Yanyong Zhang"],"pdf_url":"https://arxiv.org/pdf/2106.12735v3.pdf","comment":"Accepted by International Journal of Computer Vision (IJCV)"},{"id":"http://arxiv.org/abs/2211.12046v3","updated":"2023-03-07T05:13:18Z","published":"2022-11-22T06:40:53Z","title":"DP-NeRF: Deblurred Neural Radiance Field with Physical Scene Priors","summary":"  Neural Radiance Field (NeRF) has exhibited outstanding three-dimensional (3D)\nreconstruction quality via the novel view synthesis from multi-view images and\npaired calibrated camera parameters. However, previous NeRF-based systems have\nbeen demonstrated under strictly controlled settings, with little attention\npaid to less ideal scenarios, including with the presence of noise such as\nexposure, illumination changes, and blur. In particular, though blur frequently\noccurs in real situations, NeRF that can handle blurred images has received\nlittle attention. The few studies that have investigated NeRF for blurred\nimages have not considered geometric and appearance consistency in 3D space,\nwhich is one of the most important factors in 3D reconstruction. This leads to\ninconsistency and the degradation of the perceptual quality of the constructed\nscene. Hence, this paper proposes a DP-NeRF, a novel clean NeRF framework for\nblurred images, which is constrained with two physical priors. These priors are\nderived from the actual blurring process during image acquisition by the\ncamera. DP-NeRF proposes rigid blurring kernel to impose 3D consistency\nutilizing the physical priors and adaptive weight proposal to refine the color\ncomposition error in consideration of the relationship between depth and blur.\nWe present extensive experimental results for synthetic and real scenes with\ntwo types of blur: camera motion blur and defocus blur. The results demonstrate\nthat DP-NeRF successfully improves the perceptual quality of the constructed\nNeRF ensuring 3D geometric and appearance consistency. We further demonstrate\nthe effectiveness of our model with comprehensive ablation analysis.\n","authors":["Dogyoon Lee","Minhyeok Lee","Chajin Shin","Sangyoun Lee"],"pdf_url":"https://arxiv.org/pdf/2211.12046v3.pdf","comment":"To be appeared at CVPR 2023, Code:\n  https://github.com/dogyoonlee/DP-NeRF, Project page:\n  https://dogyoonlee.github.io/dpnerf/"},{"id":"http://arxiv.org/abs/2204.11280v3","updated":"2023-03-07T05:01:02Z","published":"2022-04-24T13:54:42Z","title":"Deconstructed Generation-Based Zero-Shot Model","summary":"  Recent research on Generalized Zero-Shot Learning (GZSL) has focused\nprimarily on generation-based methods. However, current literature has\noverlooked the fundamental principles of these methods and has made limited\nprogress in a complex manner. In this paper, we aim to deconstruct the\ngenerator-classifier framework and provide guidance for its improvement and\nextension. We begin by breaking down the generator-learned unseen class\ndistribution into class-level and instance-level distributions. Through our\nanalysis of the role of these two types of distributions in solving the GZSL\nproblem, we generalize the focus of the generation-based approach, emphasizing\nthe importance of (i) attribute generalization in generator learning and (ii)\nindependent classifier learning with partially biased data. We present a simple\nmethod based on this analysis that outperforms SotAs on four public GZSL\ndatasets, demonstrating the validity of our deconstruction. Furthermore, our\nproposed method remains effective even without a generative model, representing\na step towards simplifying the generator-classifier structure. Our code is\navailable at \\url{https://github.com/cdb342/DGZ}.\n","authors":["Dubing Chen","Yuming Shen","Haofeng Zhang","Philip H. S. Torr"],"pdf_url":"https://arxiv.org/pdf/2204.11280v3.pdf","comment":"AAAI 2023"},{"id":"http://arxiv.org/abs/2303.03651v1","updated":"2023-03-07T04:58:57Z","published":"2023-03-07T04:58:57Z","title":"F2BEV: Bird's Eye View Generation from Surround-View Fisheye Camera\n  Images for Automated Driving","summary":"  Bird's Eye View (BEV) representations are tremendously useful for\nperception-related automated driving tasks. However, generating BEVs from\nsurround-view fisheye camera images is challenging due to the strong\ndistortions introduced by such wide-angle lenses. We take the first step in\naddressing this challenge and introduce a baseline, F2BEV, to generate BEV\nheight maps and semantic segmentation maps from fisheye images. F2BEV consists\nof a distortion-aware spatial cross attention module for querying and\nconsolidating spatial information from fisheye image features in a\ntransformer-style architecture followed by a task-specific head. We evaluate\nsingle-task and multi-task variants of F2BEV on our synthetic FB-SSEM dataset,\nall of which generate better BEV height and segmentation maps (in terms of the\nIoU) than a state-of-the-art BEV generation method operating on undistorted\nfisheye images. We also demonstrate height map generation from real-world\nfisheye images using F2BEV. An initial sample of our dataset is publicly\navailable at https://tinyurl.com/58jvnscy\n","authors":["Ekta U. Samani","Feng Tao","Harshavardhan R. Dasari","Sihao Ding","Ashis G. Banerjee"],"pdf_url":"https://arxiv.org/pdf/2303.03651v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03645v1","updated":"2023-03-07T04:26:44Z","published":"2023-03-07T04:26:44Z","title":"Filter Pruning based on Information Capacity and Independence","summary":"  Filter pruning has been widely used in the compression and acceleration of\nconvolutional neural networks (CNNs). However, most existing methods are still\nchallenged by heavy compute cost and biased filter selection. Moreover, most\ndesigns for filter evaluation miss interpretability due to the lack of\nappropriate theoretical guidance. In this paper, we propose a novel filter\npruning method which evaluates filters in a interpretable, multi-persepective\nand data-free manner. We introduce information capacity, a metric that\nrepresents the amount of information contained in a filter. Based on the\ninterpretability and validity of information entropy, we propose to use that as\na quantitative index of information quantity. Besides, we experimently show\nthat the obvious correlation between the entropy of the feature map and the\ncorresponding filter, so as to propose an interpretable, data-driven scheme to\nmeasure the information capacity of the filter. Further, we introduce\ninformation independence, another metric that represents the correlation among\ndifferrent filters. Consequently, the least impotant filters, which have less\ninformation capacity and less information independence, will be pruned. We\nevaluate our method on two benchmarks using multiple representative CNN\narchitectures, including VGG-16 and ResNet. On CIFAR-10, we reduce 71.9% of\nfloating-point operations (FLOPs) and 69.4% of parameters for ResNet-110 with\n0.28% accuracy increase. On ILSVRC-2012, we reduce 76.6% of floating-point\noperations (FLOPs) and 68.6% of parameters for ResNet-50 with only 2.80%\naccuracy decrease, which outperforms the state-of-the-arts.\n","authors":["Xiaolong Tang","Tianheng Hu","Yufeng Shi"],"pdf_url":"https://arxiv.org/pdf/2303.03645v1.pdf","comment":"9 pages, 5 figures"},{"id":"http://arxiv.org/abs/2208.02646v3","updated":"2023-03-07T04:23:53Z","published":"2022-08-04T13:24:04Z","title":"DropKey","summary":"  In this paper, we focus on analyzing and improving the dropout technique for\nself-attention layers of Vision Transformer, which is important while\nsurprisingly ignored by prior works. In particular, we conduct researches on\nthree core questions: First, what to drop in self-attention layers? Different\nfrom dropping attention weights in literature, we propose to move dropout\noperations forward ahead of attention matrix calculation and set the Key as the\ndropout unit, yielding a novel dropout-before-softmax scheme. We theoretically\nverify that this scheme helps keep both regularization and probability features\nof attention weights, alleviating the overfittings problem to specific patterns\nand enhancing the model to globally capture vital information; Second, how to\nschedule the drop ratio in consecutive layers? In contrast to exploit a\nconstant drop ratio for all layers, we present a new decreasing schedule that\ngradually decreases the drop ratio along the stack of self-attention layers. We\nexperimentally validate the proposed schedule can avoid overfittings in\nlow-level features and missing in high-level semantics, thus improving the\nrobustness and stableness of model training; Third, whether need to perform\nstructured dropout operation as CNN? We attempt patch-based block-version of\ndropout operation and find that this useful trick for CNN is not essential for\nViT. Given exploration on the above three questions, we present the novel\nDropKey method that regards Key as the drop unit and exploits decreasing\nschedule for drop ratio, improving ViTs in a general way. Comprehensive\nexperiments demonstrate the effectiveness of DropKey for various ViT\narchitectures, e.g. T2T and VOLO, as well as for various vision tasks, e.g.,\nimage classification, object detection, human-object interaction detection and\nhuman body shape recovery. Codes will be released upon acceptance.\n","authors":["Bonan Li","Yinhan Hu","Xuecheng Nie","Congying Han","Xiangjian Jiang","Tiande Guo","Luoqi Liu"],"pdf_url":"https://arxiv.org/pdf/2208.02646v3.pdf","comment":"Accepted by CVPR2023"},{"id":"http://arxiv.org/abs/2302.13334v2","updated":"2023-03-07T04:01:46Z","published":"2023-02-26T15:34:05Z","title":"Knowledge Restore and Transfer for Multi-label Class-Incremental\n  Learning","summary":"  Current class-incremental learning research mainly focuses on single-label\nclassification tasks while multi-label class-incremental learning (MLCIL) with\nmore practical application scenarios is rarely studied. Although there have\nbeen many anti-forgetting methods to solve the problem of catastrophic\nforgetting in class-incremental learning, these methods have difficulty in\nsolving the MLCIL problem due to label absence and information dilution. In\nthis paper, we propose a knowledge restore and transfer (KRT) framework for\nMLCIL, which includes a dynamic pseudo-label (DPL) module to restore the old\nclass knowledge and an incremental cross-attention(ICA) module to save\nsession-specific knowledge and transfer old class knowledge to the new model\nsufficiently. Besides, we propose a token loss to jointly optimize the\nincremental cross-attention module. Experimental results on MS-COCO and PASCAL\nVOC datasets demonstrate the effectiveness of our method for improving\nrecognition performance and mitigating forgetting on multi-label\nclass-incremental learning tasks.\n","authors":["Songlin Dong","Haoyu Luo","Yuhang He","Xing Wei","Yihong Gong"],"pdf_url":"https://arxiv.org/pdf/2302.13334v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03231v2","updated":"2023-03-07T04:01:11Z","published":"2023-03-06T15:48:33Z","title":"StyO: Stylize Your Face in Only One-Shot","summary":"  This paper focuses on face stylization with a single artistic target.\nExisting works for this task often fail to retain the source content while\nachieving geometry variation. Here, we present a novel StyO model, ie. Stylize\nthe face in only One-shot, to solve the above problem. In particular, StyO\nexploits a disentanglement and recombination strategy. It first disentangles\nthe content and style of source and target images into identifiers, which are\nthen recombined in a cross manner to derive the stylized face image. In this\nway, StyO decomposes complex images into independent and specific attributes,\nand simplifies one-shot face stylization as the combination of different\nattributes from input images, thus producing results better matching face\ngeometry of target image and content of source one. StyO is implemented with\nlatent diffusion models (LDM) and composed of two key modules: 1) Identifier\nDisentanglement Learner (IDL) for disentanglement phase. It represents\nidentifiers as contrastive text prompts, ie. positive and negative\ndescriptions. And it introduces a novel triple reconstruction loss to fine-tune\nthe pre-trained LDM for encoding style and content into corresponding\nidentifiers; 2) Fine-grained Content Controller (FCC) for the recombination\nphase. It recombines disentangled identifiers from IDL to form an augmented\ntext prompt for generating stylized faces. In addition, FCC also constrains the\ncross-attention maps of latent and text features to preserve source face\ndetails in results. The extensive evaluation shows that StyO produces\nhigh-quality images on numerous paintings of various styles and outperforms the\ncurrent state-of-the-art. Code will be released upon acceptance.\n","authors":["Bonan Li","Zicheng Zhang","Xuecheng Nie","Congying Han","Yinhan Hu","Tiande Guo"],"pdf_url":"https://arxiv.org/pdf/2303.03231v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.01032v2","updated":"2023-03-07T03:52:21Z","published":"2023-03-02T07:42:07Z","title":"ESceme: Vision-and-Language Navigation with Episodic Scene Memory","summary":"  Vision-and-language navigation (VLN) simulates a visual agent that follows\nnatural-language navigation instructions in real-world scenes. Existing\napproaches have made enormous progress in navigation in new environments, such\nas beam search, pre-exploration, and dynamic or hierarchical history encoding.\nTo balance generalization and efficiency, we resort to memorizing visited\nscenarios apart from the ongoing route while navigating. In this work, we\nintroduce a mechanism of Episodic Scene memory (ESceme) for VLN that wakes an\nagent's memories of past visits when it enters the current scene. The episodic\nscene memory allows the agent to envision a bigger picture of the next\nprediction. This way, the agent learns to utilize dynamically updated\ninformation instead of merely adapting to static observations. We provide a\nsimple yet effective implementation of ESceme by enhancing the accessible views\nat each location and progressively completing the memory while navigating. We\nverify the superiority of ESceme on short-horizon (R2R), long-horizon (R4R),\nand vision-and-dialog (CVDN) VLN tasks. Our ESceme also wins first place on the\nCVDN leaderboard. Code is available: \\url{https://github.com/qizhust/esceme}.}\n","authors":["Qi Zheng","Daqing Liu","Chaoyue Wang","Jing Zhang","Dadong Wang","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2303.01032v2.pdf","comment":"Tech. report; typos corrected"},{"id":"http://arxiv.org/abs/2303.03633v1","updated":"2023-03-07T03:41:13Z","published":"2023-03-07T03:41:13Z","title":"Sketch-based Medical Image Retrieval","summary":"  The amount of medical images stored in hospitals is increasing faster than\never; however, utilizing the accumulated medical images has been limited. This\nis because existing content-based medical image retrieval (CBMIR) systems\nusually require example images to construct query vectors; nevertheless,\nexample images cannot always be prepared. Besides, there can be images with\nrare characteristics that make it difficult to find similar example images,\nwhich we call isolated samples. Here, we introduce a novel sketch-based medical\nimage retrieval (SBMIR) system that enables users to find images of interest\nwithout example images. The key idea lies in feature decomposition of medical\nimages, whereby the entire feature of a medical image can be decomposed into\nand reconstructed from normal and abnormal features. By extending this idea,\nour SBMIR system provides an easy-to-use two-step graphical user interface:\nusers first select a template image to specify a normal feature and then draw a\nsemantic sketch of the disease on the template image to represent an abnormal\nfeature. Subsequently, it integrates the two kinds of input to construct a\nquery vector and retrieves reference images with the closest reference vectors.\nUsing two datasets, ten healthcare professionals with various clinical\nbackgrounds participated in the user test for evaluation. As a result, our\nSBMIR system enabled users to overcome previous challenges, including image\nretrieval based on fine-grained image characteristics, image retrieval without\nexample images, and image retrieval for isolated samples. Our SBMIR system\nachieves flexible medical image retrieval on demand, thereby expanding the\nutility of medical image databases.\n","authors":["Kazuma Kobayashi","Lin Gu","Ryuichiro Hataya","Takaaki Mizuno","Mototaka Miyake","Hirokazu Watanabe","Masamichi Takahashi","Yasuyuki Takamizawa","Yukihiro Yoshida","Satoshi Nakamura","Nobuji Kouno","Amina Bolatkan","Yusuke Kurose","Tatsuya Harada","Ryuji Hamamoto"],"pdf_url":"https://arxiv.org/pdf/2303.03633v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03630v1","updated":"2023-03-07T03:24:54Z","published":"2023-03-07T03:24:54Z","title":"No One Left Behind: Improving the Worst Categories in Long-Tailed\n  Learning","summary":"  Unlike the case when using a balanced training dataset, the per-class recall\n(i.e., accuracy) of neural networks trained with an imbalanced dataset are\nknown to vary a lot from category to category. The convention in long-tailed\nrecognition is to manually split all categories into three subsets and report\nthe average accuracy within each subset. We argue that under such an evaluation\nsetting, some categories are inevitably sacrificed. On one hand, focusing on\nthe average accuracy on a balanced test set incurs little penalty even if some\nworst performing categories have zero accuracy. On the other hand, classes in\nthe \"Few\" subset do not necessarily perform worse than those in the \"Many\" or\n\"Medium\" subsets. We therefore advocate to focus more on improving the lowest\nrecall among all categories and the harmonic mean of all recall values.\nSpecifically, we propose a simple plug-in method that is applicable to a wide\nrange of methods. By simply re-training the classifier of an existing\npre-trained model with our proposed loss function and using an optional\nensemble trick that combines the predictions of the two classifiers, we achieve\na more uniform distribution of recall values across categories, which leads to\na higher harmonic mean accuracy while the (arithmetic) average accuracy is\nstill high. The effectiveness of our method is justified on widely used\nbenchmark datasets.\n","authors":["Yingxiao Du","Jianxin Wu"],"pdf_url":"https://arxiv.org/pdf/2303.03630v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03625v1","updated":"2023-03-07T03:17:49Z","published":"2023-03-07T03:17:49Z","title":"SGDA: Towards 3D Universal Pulmonary Nodule Detection via Slice Grouped\n  Domain Attention","summary":"  Lung cancer is the leading cause of cancer death worldwide. The best solution\nfor lung cancer is to diagnose the pulmonary nodules in the early stage, which\nis usually accomplished with the aid of thoracic computed tomography (CT). As\ndeep learning thrives, convolutional neural networks (CNNs) have been\nintroduced into pulmonary nodule detection to help doctors in this\nlabor-intensive task and demonstrated to be very effective. However, the\ncurrent pulmonary nodule detection methods are usually domain-specific, and\ncannot satisfy the requirement of working in diverse real-world scenarios. To\naddress this issue, we propose a slice grouped domain attention (SGDA) module\nto enhance the generalization capability of the pulmonary nodule detection\nnetworks. This attention module works in the axial, coronal, and sagittal\ndirections. In each direction, we divide the input feature into groups, and for\neach group, we utilize a universal adapter bank to capture the feature\nsubspaces of the domains spanned by all pulmonary nodule datasets. Then the\nbank outputs are combined from the perspective of domain to modulate the input\ngroup. Extensive experiments demonstrate that SGDA enables substantially better\nmulti-domain pulmonary nodule detection performance compared with the\nstate-of-the-art multi-domain learning methods.\n","authors":["Rui Xu","Zhi Liu","Yong Luo","Han Hu","Li Shen","Bo Du","Kaiming Kuang","Jiancheng Yang"],"pdf_url":"https://arxiv.org/pdf/2303.03625v1.pdf","comment":"Accepted by IEEE/ACM Transactions on Computational Biology and\n  Bioinformatics"},{"id":"http://arxiv.org/abs/2207.09339v2","updated":"2023-03-07T03:17:12Z","published":"2022-07-19T15:49:35Z","title":"Vision Transformers: From Semantic Segmentation to Dense Prediction","summary":"  The emergence of vision transformers (ViTs) in image classification has\nshifted the methodologies for visual representation learning. In particular,\nViTs learn visual representation at full receptive field per layer across all\nthe image patches, in comparison to the increasing receptive fields of CNNs\nacross layers and other alternatives (e.g., large kernels and atrous\nconvolution). In this work, for the first time we explore the global context\nlearning potentials of ViTs for dense visual prediction (e.g., semantic\nsegmentation). Our motivation is that through learning global context at full\nreceptive field layer by layer, ViTs may capture stronger long-range dependency\ninformation, critical for dense prediction tasks. We first demonstrate that\nencoding an image as a sequence of patches, a vanilla ViT without local\nconvolution and resolution reduction can yield stronger visual representation\nfor semantic segmentation. For example, our model, termed as SEgmentation\nTRansformer (SETR), excels on ADE20K (50.28% mIoU, the first position in the\ntest leaderboard on the day of submission) and Pascal Context (55.83% mIoU),\nand performs competitively on Cityscapes. For tackling general dense visual\nprediction tasks in a cost-effective manner, we further formulate a family of\nHierarchical Local-Global (HLG) Transformers, characterized by local attention\nwithin windows and global-attention across windows in a pyramidal architecture.\nExtensive experiments show that our methods achieve appealing performance on a\nvariety of dense prediction tasks (e.g., object detection and instance\nsegmentation and semantic segmentation) as well as image classification. Our\ncode and models are available at https://github.com/fudan-zvg/SETR.\n","authors":["Li Zhang","Jiachen Lu","Sixiao Zheng","Xinxuan Zhao","Xiatian Zhu","Yanwei Fu","Tao Xiang","Jianfeng Feng"],"pdf_url":"https://arxiv.org/pdf/2207.09339v2.pdf","comment":"Extended version of CVPR 2021 paper arXiv:2012.15840"},{"id":"http://arxiv.org/abs/2211.08064v2","updated":"2023-03-07T02:46:34Z","published":"2022-11-15T11:34:30Z","title":"Physics-Informed Machine Learning: A Survey on Problems, Methods and\n  Applications","summary":"  Recent advances of data-driven machine learning have revolutionized fields\nlike computer vision, reinforcement learning, and many scientific and\nengineering domains. In many real-world and scientific problems, systems that\ngenerate data are governed by physical laws. Recent work shows that it provides\npotential benefits for machine learning models by incorporating the physical\nprior and collected data, which makes the intersection of machine learning and\nphysics become a prevailing paradigm. By integrating the data and mathematical\nphysics models seamlessly, it can guide the machine learning model towards\nsolutions that are physically plausible, improving accuracy and efficiency even\nin uncertain and high-dimensional contexts. In this survey, we present this\nlearning paradigm called Physics-Informed Machine Learning (PIML) which is to\nbuild a model that leverages empirical data and available physical prior\nknowledge to improve performance on a set of tasks that involve a physical\nmechanism. We systematically review the recent development of physics-informed\nmachine learning from three perspectives of machine learning tasks,\nrepresentation of physical prior, and methods for incorporating physical prior.\nWe also propose several important open research problems based on the current\ntrends in the field. We argue that encoding different forms of physical prior\ninto model architectures, optimizers, inference algorithms, and significant\ndomain-specific applications like inverse engineering design and robotic\ncontrol is far from being fully explored in the field of physics-informed\nmachine learning. We believe that the interdisciplinary research of\nphysics-informed machine learning will significantly propel research progress,\nfoster the creation of more effective machine learning models, and also offer\ninvaluable assistance in addressing long-standing problems in related\ndisciplines.\n","authors":["Zhongkai Hao","Songming Liu","Yichi Zhang","Chengyang Ying","Yao Feng","Hang Su","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2211.08064v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.12739v2","updated":"2023-03-07T02:32:53Z","published":"2023-01-30T09:03:10Z","title":"FractalAD: A simple industrial anomaly detection method using fractal\n  anomaly generation and backbone knowledge distillation","summary":"  Although industrial anomaly detection (AD) technology has made significant\nprogress in recent years, generating realistic anomalies and learning priors of\nnormal remain challenging tasks. In this study, we propose an end-to-end\nindustrial anomaly detection method called FractalAD. Training samples are\nobtained by synthesizing fractal images and patches from normal samples. This\nfractal anomaly generation method is designed to sample the full morphology of\nanomalies. Moreover, we designed a backbone knowledge distillation structure to\nextract prior knowledge contained in normal samples. The differences between a\nteacher and a student model are converted into anomaly attention using a cosine\nsimilarity attention module. The proposed method enables an end-to-end semantic\nsegmentation network to be used for anomaly detection without adding any\ntrainable parameters to the backbone and segmentation head, and has obvious\nadvantages over other methods in training and inference speed.. The results of\nablation studies confirmed the effectiveness of fractal anomaly generation and\nbackbone knowledge distillation. The results of performance experiments showed\nthat FractalAD achieved competitive results on the MVTec AD dataset and MVTec\n3D-AD dataset compared with other state-of-the-art anomaly detection methods.\n","authors":["Xuan Xia","Weijie Lv","Xing He","Nan Li","Chuanqi Liu","Ning Ding"],"pdf_url":"https://arxiv.org/pdf/2301.12739v2.pdf","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2303.03599v1","updated":"2023-03-07T02:31:08Z","published":"2023-03-07T02:31:08Z","title":"FSVVD: A Dataset of Full Scene Volumetric Video","summary":"  Recent years have witnessed a rapid development of immersive multimedia which\nbridges the gap between the real world and virtual space. Volumetric videos, as\nan emerging representative 3D video paradigm that empowers extended reality,\nstand out to provide unprecedented immersive and interactive video watching\nexperience. Despite the tremendous potential, the research towards 3D\nvolumetric video is still in its infancy, relying on sufficient and complete\ndatasets for further exploration. However, existing related volumetric video\ndatasets mostly only include a single object, lacking details about the scene\nand the interaction between them. In this paper, we focus on the current most\nwidely used data format, point cloud, and for the first time release a\nfull-scene volumetric video dataset that includes multiple people and their\ndaily activities interacting with the external environments. Comprehensive\ndataset description and analysis are conducted, with potential usage of this\ndataset. The dataset and additional tools can be accessed via the following\nwebsite: https://cuhksz-inml.github.io/full_scene_volumetric_video_dataset/.\n","authors":["Kaiyuan Hu","Yili Jin","Haowen Yang","Junhua Liu","Fangxin Wang"],"pdf_url":"https://arxiv.org/pdf/2303.03599v1.pdf","comment":"Accepted by MMSys'23 Open Dataset and Software Track, A preliminary\n  version. The dataset and additional tools can be accessed via\n  https://cuhksz-inml.github.io/full_scene_volumetric_video_dataset/"},{"id":"http://arxiv.org/abs/2210.00030v2","updated":"2023-03-07T02:29:59Z","published":"2022-09-30T18:14:07Z","title":"VIP: Towards Universal Visual Reward and Representation via\n  Value-Implicit Pre-Training","summary":"  Reward and representation learning are two long-standing challenges for\nlearning an expanding set of robot manipulation skills from sensory\nobservations. Given the inherent cost and scarcity of in-domain, task-specific\nrobot data, learning from large, diverse, offline human videos has emerged as a\npromising path towards acquiring a generally useful visual representation for\ncontrol; however, how these human videos can be used for general-purpose reward\nlearning remains an open question. We introduce\n$\\textbf{V}$alue-$\\textbf{I}$mplicit $\\textbf{P}$re-training (VIP), a\nself-supervised pre-trained visual representation capable of generating dense\nand smooth reward functions for unseen robotic tasks. VIP casts representation\nlearning from human videos as an offline goal-conditioned reinforcement\nlearning problem and derives a self-supervised dual goal-conditioned\nvalue-function objective that does not depend on actions, enabling pre-training\non unlabeled human videos. Theoretically, VIP can be understood as a novel\nimplicit time contrastive objective that generates a temporally smooth\nembedding, enabling the value function to be implicitly defined via the\nembedding distance, which can then be used to construct the reward for any\ngoal-image specified downstream task. Trained on large-scale Ego4D human videos\nand without any fine-tuning on in-domain, task-specific data, VIP's frozen\nrepresentation can provide dense visual reward for an extensive set of\nsimulated and $\\textbf{real-robot}$ tasks, enabling diverse reward-based visual\ncontrol methods and significantly outperforming all prior pre-trained\nrepresentations. Notably, VIP can enable simple, $\\textbf{few-shot}$ offline RL\non a suite of real-world robot tasks with as few as 20 trajectories.\n","authors":["Yecheng Jason Ma","Shagun Sodhani","Dinesh Jayaraman","Osbert Bastani","Vikash Kumar","Amy Zhang"],"pdf_url":"https://arxiv.org/pdf/2210.00030v2.pdf","comment":"ICLR 2023, Notable-Top-25% (Spotlight). Project website:\n  https://sites.google.com/view/vip-rl"},{"id":"http://arxiv.org/abs/2303.03598v1","updated":"2023-03-07T02:29:36Z","published":"2023-03-07T02:29:36Z","title":"Guided Image-to-Image Translation by Discriminator-Generator\n  Communication","summary":"  The goal of Image-to-image (I2I) translation is to transfer an image from a\nsource domain to a target domain, which has recently drawn increasing\nattention. One major branch of this research is to formulate I2I translation\nbased on Generative Adversarial Network (GAN). As a zero-sum game, GAN can be\nreformulated as a Partially-observed Markov Decision Process (POMDP) for\ngenerators, where generators cannot access full state information of their\nenvironments. This formulation illustrates the information insufficiency in the\nGAN training. To mitigate this problem, we propose to add a communication\nchannel between discriminators and generators. We explore multiple architecture\ndesigns to integrate the communication mechanism into the I2I translation\nframework. To validate the performance of the proposed approach, we have\nconducted extensive experiments on various benchmark datasets. The experimental\nresults confirm the superiority of our proposed method.\n","authors":["Yuanjiang Cao","Lina Yao","Le Pan","Quan Z. Sheng","Xiaojun Chang"],"pdf_url":"https://arxiv.org/pdf/2303.03598v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.02307v3","updated":"2023-03-07T02:14:39Z","published":"2022-06-06T01:30:03Z","title":"Bootstrapping Semi-supervised Medical Image Segmentation with\n  Anatomical-aware Contrastive Distillation","summary":"  Contrastive learning has shown great promise over annotation scarcity\nproblems in the context of medical image segmentation. Existing approaches\ntypically assume a balanced class distribution for both labeled and unlabeled\nmedical images. However, medical image data in reality is commonly imbalanced\n(i.e., multi-class label imbalance), which naturally yields blurry contours and\nusually incorrectly labels rare objects. Moreover, it remains unclear whether\nall negative samples are equally negative. In this work, we present ACTION, an\nAnatomical-aware ConTrastive dIstillatiON framework, for semi-supervised\nmedical image segmentation. Specifically, we first develop an iterative\ncontrastive distillation algorithm by softly labeling the negatives rather than\nbinary supervision between positive and negative pairs. We also capture more\nsemantically similar features from the randomly chosen negative set compared to\nthe positives to enforce the diversity of the sampled data. Second, we raise a\nmore important question: Can we really handle imbalanced samples to yield\nbetter performance? Hence, the key innovation in ACTION is to learn global\nsemantic relationship across the entire dataset and local anatomical features\namong the neighbouring pixels with minimal additional memory footprint. During\nthe training, we introduce anatomical contrast by actively sampling a sparse\nset of hard negative pixels, which can generate smoother segmentation\nboundaries and more accurate predictions. Extensive experiments across two\nbenchmark datasets and different unlabeled settings show that ACTION\nsignificantly outperforms the current state-of-the-art semi-supervised methods.\n","authors":["Chenyu You","Weicheng Dai","Yifei Min","Lawrence Staib","James S. Duncan"],"pdf_url":"https://arxiv.org/pdf/2206.02307v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.05869v2","updated":"2023-03-07T02:10:21Z","published":"2022-05-12T03:54:35Z","title":"View Synthesis with Sculpted Neural Points","summary":"  We address the task of view synthesis, generating novel views of a scene\ngiven a set of images as input. In many recent works such as NeRF (Mildenhall\net al., 2020), the scene geometry is parameterized using neural implicit\nrepresentations (i.e., MLPs). Implicit neural representations have achieved\nimpressive visual quality but have drawbacks in computational efficiency. In\nthis work, we propose a new approach that performs view synthesis using point\nclouds. It is the first point-based method that achieves better visual quality\nthan NeRF while being 100x faster in rendering speed. Our approach builds on\nexisting works on differentiable point-based rendering but introduces a novel\ntechnique we call \"Sculpted Neural Points (SNP)\", which significantly improves\nthe robustness to errors and holes in the reconstructed point cloud. We further\npropose to use view-dependent point features based on spherical harmonics to\ncapture non-Lambertian surfaces, and new designs in the point-based rendering\npipeline that further boost the performance. Finally, we show that our system\nsupports fine-grained scene editing. Code is available at\nhttps://github.com/princeton-vl/SNP.\n","authors":["Yiming Zuo","Jia Deng"],"pdf_url":"https://arxiv.org/pdf/2205.05869v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02733v2","updated":"2023-03-07T02:07:01Z","published":"2023-03-05T17:57:33Z","title":"Reparameterization through Spatial Gradient Scaling","summary":"  Reparameterization aims to improve the generalization of deep neural networks\nby transforming convolutional layers into equivalent multi-branched structures\nduring training. However, there exists a gap in understanding how\nreparameterization may change and benefit the learning process of neural\nnetworks. In this paper, we present a novel spatial gradient scaling method to\nredistribute learning focus among weights in convolutional networks. We prove\nthat spatial gradient scaling achieves the same learning dynamics as a branched\nreparameterization yet without introducing structural changes into the network.\nWe further propose an analytical approach that dynamically learns scalings for\neach convolutional layer based on the spatial characteristics of its input\nfeature map gauged by mutual information. Experiments on CIFAR-10, CIFAR-100,\nand ImageNet show that without searching for reparameterized structures, our\nproposed scaling method outperforms the state-of-the-art reparameterization\nstrategies at a lower computational cost.\n","authors":["Alexander Detkov","Mohammad Salameh","Muhammad Fetrat Qharabagh","Jialin Zhang","Wei Lui","Shangling Jui","Di Niu"],"pdf_url":"https://arxiv.org/pdf/2303.02733v2.pdf","comment":"Published at ICLR 2023. Code available at\n  https://github.com/Ascend-Research/Reparameterization"},{"id":"http://arxiv.org/abs/2303.03595v1","updated":"2023-03-07T02:00:34Z","published":"2023-03-07T02:00:34Z","title":"LoGoNet: Towards Accurate 3D Object Detection with Local-to-Global\n  Cross-Modal Fusion","summary":"  LiDAR-camera fusion methods have shown impressive performance in 3D object\ndetection. Recent advanced multi-modal methods mainly perform global fusion,\nwhere image features and point cloud features are fused across the whole scene.\nSuch practice lacks fine-grained region-level information, yielding suboptimal\nfusion performance. In this paper, we present the novel Local-to-Global fusion\nnetwork (LoGoNet), which performs LiDAR-camera fusion at both local and global\nlevels. Concretely, the Global Fusion (GoF) of LoGoNet is built upon previous\nliterature, while we exclusively use point centroids to more precisely\nrepresent the position of voxel features, thus achieving better cross-modal\nalignment. As to the Local Fusion (LoF), we first divide each proposal into\nuniform grids and then project these grid centers to the images. The image\nfeatures around the projected grid points are sampled to be fused with\nposition-decorated point cloud features, maximally utilizing the rich\ncontextual information around the proposals. The Feature Dynamic Aggregation\n(FDA) module is further proposed to achieve information interaction between\nthese locally and globally fused features, thus producing more informative\nmulti-modal features. Extensive experiments on both Waymo Open Dataset (WOD)\nand KITTI datasets show that LoGoNet outperforms all state-of-the-art 3D\ndetection methods. Notably, LoGoNet ranks 1st on Waymo 3D object detection\nleaderboard and obtains 81.02 mAPH (L2) detection performance. It is noteworthy\nthat, for the first time, the detection performance on three classes surpasses\n80 APH (L2) simultaneously. Code will be available at\n\\url{https://github.com/sankin97/LoGoNet}.\n","authors":["Xin Li","Tao Ma","Yuenan Hou","Botian Shi","Yucheng Yang","Youquan Liu","Xingjiao Wu","Qin Chen","Yikang Li","Yu Qiao","Liang He"],"pdf_url":"https://arxiv.org/pdf/2303.03595v1.pdf","comment":"Accepted by CVPR2023"},{"id":"http://arxiv.org/abs/2303.03583v1","updated":"2023-03-07T01:31:06Z","published":"2023-03-07T01:31:06Z","title":"Calibration-free BEV Representation for Infrastructure Perception","summary":"  Effective BEV object detection on infrastructure can greatly improve traffic\nscenes understanding and vehicle-toinfrastructure (V2I) cooperative perception.\nHowever, cameras installed on infrastructure have various postures, and\nprevious BEV detection methods rely on accurate calibration, which is difficult\nfor practical applications due to inevitable natural factors (e.g., wind and\nsnow). In this paper, we propose a Calibration-free BEV Representation (CBR)\nnetwork, which achieves 3D detection based on BEV representation without\ncalibration parameters and additional depth supervision. Specifically, we\nutilize two multi-layer perceptrons for decoupling the features from\nperspective view to front view and birdeye view under boxes-induced foreground\nsupervision. Then, a cross-view feature fusion module matches features from\northogonal views according to similarity and conducts BEV feature enhancement\nwith front view features. Experimental results on DAIR-V2X demonstrate that CBR\nachieves acceptable performance without any camera parameters and is naturally\nnot affected by calibration noises. We hope CBR can serve as a baseline for\nfuture research addressing practical challenges of infrastructure perception.\n","authors":["Siqi Fan","Zhe Wang","Xiaoliang Huo","Yan Wang","Jingjing Liu"],"pdf_url":"https://arxiv.org/pdf/2303.03583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03565v1","updated":"2023-03-07T00:26:02Z","published":"2023-03-07T00:26:02Z","title":"CLIP-Layout: Style-Consistent Indoor Scene Synthesis with Semantic\n  Furniture Embedding","summary":"  Indoor scene synthesis involves automatically picking and placing furniture\nappropriately on a floor plan, so that the scene looks realistic and is\nfunctionally plausible. Such scenes can serve as a home for immersive 3D\nexperiences, or be used to train embodied agents. Existing methods for this\ntask rely on labeled categories of furniture, e.g. bed, chair or table, to\ngenerate contextually relevant combinations of furniture. Whether heuristic or\nlearned, these methods ignore instance-level attributes of objects such as\ncolor and style, and as a result may produce visually less coherent scenes. In\nthis paper, we introduce an auto-regressive scene model which can output\ninstance-level predictions, making use of general purpose image embedding based\non CLIP. This allows us to learn visual correspondences such as matching color\nand style, and produce more plausible and aesthetically pleasing scenes.\nEvaluated on the 3D-FRONT dataset, our model achieves SOTA results in scene\ngeneration and improves auto-completion metrics by over 50%. Moreover, our\nembedding-based approach enables zero-shot text-guided scene generation and\nediting, which easily generalizes to furniture not seen at training time.\n","authors":["Jingyu Liu","Wenhan Xiong","Ian Jones","Yixin Nie","Anchit Gupta","Barlas Oğuz"],"pdf_url":"https://arxiv.org/pdf/2303.03565v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2102.13392v3","updated":"2023-03-07T14:56:18Z","published":"2021-02-26T11:01:30Z","title":"Unifying Remote Sensing Image Retrieval and Classification with Robust\n  Fine-tuning","summary":"  Advances in high resolution remote sensing image analysis are currently\nhampered by the difficulty of gathering enough annotated data for training deep\nlearning methods, giving rise to a variety of small datasets and associated\ndataset-specific methods. Moreover, typical tasks such as classification and\nretrieval lack a systematic evaluation on standard benchmarks and training\ndatasets, which make it hard to identify durable and generalizable scientific\ncontributions. We aim at unifying remote sensing image retrieval and\nclassification with a new large-scale training and testing dataset, SF300,\nincluding both vertical and oblique aerial images and made available to the\nresearch community, and an associated fine-tuning method. We additionally\npropose a new adversarial fine-tuning method for global descriptors. We show\nthat our framework systematically achieves a boost of retrieval and\nclassification performance on nine different datasets compared to an ImageNet\npretrained baseline, with currently no other method to compare to.\n","authors":["Dimitri Gominski","Valérie Gouet-Brunet","Liming Chen"],"pdf_url":"https://arxiv.org/pdf/2102.13392v3.pdf","comment":"Performance margin with the proposed method is not statistically\n  significant. Please refer to http://alegoria.ign.fr/en/SF300_dataset if you\n  are interested in the dataset"},{"id":"http://arxiv.org/abs/2210.00305v2","updated":"2023-03-07T14:35:33Z","published":"2022-10-01T16:01:53Z","title":"LambdaKG: A Library for Pre-trained Language Model-Based Knowledge Graph\n  Embeddings","summary":"  Knowledge Graphs (KGs) often have two characteristics: heterogeneous graph\nstructure and text-rich entity/relation information. Text-based KG embeddings\ncan represent entities by encoding descriptions with pre-trained language\nmodels, but no open-sourced library is specifically designed for KGs with PLMs\nat present. In this paper, we present LambdaKG, a library for KGE that equips\nwith many pre-trained language models (e.g., BERT, BART, T5, GPT-3), and\nsupports various tasks (e.g., knowledge graph completion, question answering,\nrecommendation, and knowledge probing). LambdaKG is publicly open-sourced at\nhttps://github.com/zjunlp/PromptKG/tree/main/lambdaKG, with a demo video at\nhttp://deepke.zjukg.cn/lambdakg.mp4 and long-term maintenance.\n","authors":["Xin Xie","Zhoubo Li","Xiaohan Wang","Yuqi Zhu","Ningyu Zhang","Jintian Zhang","Siyuan Cheng","Bozhong Tian","Shumin Deng","Feiyu Xiong","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2210.00305v2.pdf","comment":"Work in progress and the project website is\n  https://zjunlp.github.io/project/promptkg/"},{"id":"http://arxiv.org/abs/2202.12524v4","updated":"2023-03-07T03:21:01Z","published":"2022-02-25T06:58:28Z","title":"MAMDR: A Model Agnostic Learning Method for Multi-Domain Recommendation","summary":"  Large-scale e-commercial platforms in the real-world usually contain various\nrecommendation scenarios (domains) to meet demands of diverse customer groups.\nMulti-Domain Recommendation (MDR), which aims to jointly improve\nrecommendations on all domains and easily scales to thousands of domains, has\nattracted increasing attention from practitioners and researchers. Existing MDR\nmethods usually employ a shared structure and several specific components to\nrespectively leverage reusable features and domain-specific information.\nHowever, data distribution differs across domains, making it challenging to\ndevelop a general model that can be applied to all circumstances. Additionally,\nduring training, shared parameters often suffer from the domain conflict while\nspecific parameters are inclined to overfitting on data sparsity domains. we\nfirst present a scalable MDR platform served in Taobao that enables to provide\nservices for thousands of domains without specialists involved. To address the\nproblems of MDR methods, we propose a novel model agnostic learning framework,\nnamely MAMDR, for the multi-domain recommendation. Specifically, we first\npropose a Domain Negotiation (DN) strategy to alleviate the conflict between\ndomains. Then, we develop a Domain Regularization (DR) to improve the\ngeneralizability of specific parameters by learning from other domains. We\nintegrate these components into a unified framework and present MAMDR, which\ncan be applied to any model structure to perform multi-domain recommendation.\nFinally, we present a large-scale implementation of MAMDR in the Taobao\napplication and construct various public MDR benchmark datasets which can be\nused for following studies. Extensive experiments on both benchmark datasets\nand industry datasets demonstrate the effectiveness and generalizability of\nMAMDR.\n","authors":["Linhao Luo","Yumeng Li","Buyu Gao","Shuai Tang","Sinan Wang","Jiancheng Li","Tanchao Zhu","Jiancai Liu","Zhao Li","Shirui Pan"],"pdf_url":"https://arxiv.org/pdf/2202.12524v4.pdf","comment":"This paper has been accepted by ICDE 2023"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2203.01924v2","updated":"2023-03-07T18:59:48Z","published":"2022-03-03T18:56:13Z","title":"Min-Max Bilevel Multi-objective Optimization with Applications in\n  Machine Learning","summary":"  We consider a generic min-max multi-objective bilevel optimization problem\nwith applications in robust machine learning such as representation learning\nand hyperparameter optimization. We design MORBiT, a novel single-loop gradient\ndescent-ascent bilevel optimization algorithm, to solve the generic problem and\npresent a novel analysis showing that MORBiT converges to the first-order\nstationary point at a rate of $\\widetilde{\\mathcal{O}}(n^{1/2} K^{-2/5})$ for a\nclass of weakly convex problems with $n$ objectives upon $K$ iterations of the\nalgorithm. Our analysis utilizes novel results to handle the non-smooth min-max\nmulti-objective setup and to obtain a sublinear dependence in the number of\nobjectives $n$. Experimental results on robust representation learning and\nrobust hyperparameter optimization showcase (i) the advantages of considering\nthe min-max multi-objective setup, and (ii) convergence properties of the\nproposed MORBiT. Our code is at https://github.com/minimario/MORBiT.\n","authors":["Alex Gu","Songtao Lu","Parikshit Ram","Lily Weng"],"pdf_url":"https://arxiv.org/pdf/2203.01924v2.pdf","comment":"43 pages, 3 figures, ICLR 2023 version"},{"id":"http://arxiv.org/abs/2303.04145v1","updated":"2023-03-07T18:59:38Z","published":"2023-03-07T18:59:38Z","title":"Benign Overfitting for Two-layer ReLU Networks","summary":"  Modern deep learning models with great expressive power can be trained to\noverfit the training data but still generalize well. This phenomenon is\nreferred to as benign overfitting. Recently, a few studies have attempted to\ntheoretically understand benign overfitting in neural networks. However, these\nworks are either limited to neural networks with smooth activation functions or\nto the neural tangent kernel regime. How and when benign overfitting can occur\nin ReLU neural networks remains an open problem. In this work, we seek to\nanswer this question by establishing algorithm-dependent risk bounds for\nlearning two-layer ReLU convolutional neural networks with label-flipping\nnoise. We show that, under mild conditions, the neural network trained by\ngradient descent can achieve near-zero training loss and Bayes optimal test\nrisk. Our result also reveals a sharp transition between benign and harmful\noverfitting under different conditions on data distribution in terms of test\nrisk. Experiments on synthetic data back up our theory.\n","authors":["Yiwen Kou","Zixiang Chen","Yuanzhou Chen","Quanquan Gu"],"pdf_url":"https://arxiv.org/pdf/2303.04145v1.pdf","comment":"54 pages, 2 figures, 2 tables"},{"id":"http://arxiv.org/abs/2303.04143v1","updated":"2023-03-07T18:56:59Z","published":"2023-03-07T18:56:59Z","title":"Can We Scale Transformers to Predict Parameters of Diverse ImageNet\n  Models?","summary":"  Pretraining a neural network on a large dataset is becoming a cornerstone in\nmachine learning that is within the reach of only a few communities with\nlarge-resources. We aim at an ambitious goal of democratizing pretraining.\nTowards that goal, we train and release a single neural network that can\npredict high quality ImageNet parameters of other neural networks. By using\npredicted parameters for initialization we are able to boost training of\ndiverse ImageNet models available in PyTorch. When transferred to other\ndatasets, models initialized with predicted parameters also converge faster and\nreach competitive final performance.\n","authors":["Boris Knyazev","Doha Hwang","Simon Lacoste-Julien"],"pdf_url":"https://arxiv.org/pdf/2303.04143v1.pdf","comment":"Code and models are available at\n  https://github.com/SamsungSAILMontreal/ghn3"},{"id":"http://arxiv.org/abs/2303.04142v1","updated":"2023-03-07T18:56:52Z","published":"2023-03-07T18:56:52Z","title":"From Copilot to Pilot: Towards AI Supported Software Development","summary":"  AI-supported programming has arrived, as shown by the introduction and\nsuccesses of large language models for code, such as Copilot/Codex\n(Github/OpenAI) and AlphaCode (DeepMind). Above human average performance on\nprogramming challenges is now possible. However, software engineering is much\nmore than solving programming contests. Moving beyond code completion to\nAI-supported software engineering will require an AI system that can, among\nother things, understand how to avoid code smells, to follow language idioms,\nand eventually (maybe!) propose rational software designs. In this study, we\nexplore the current limitations of AI-supported code completion tools like\nCopilot and offer a simple taxonomy for understanding the classification of\nAI-supported code completion tools in this space. We first perform an\nexploratory study on Copilot's code suggestions for language idioms and code\nsmells. Copilot does not follow language idioms and avoid code smells in most\nof our test scenarios. We then conduct additional investigation to determine\nthe current boundaries of AI-supported code completion tools like Copilot by\nintroducing a taxonomy of software abstraction hierarchies where 'basic\nprogramming functionality' such as code compilation and syntax checking is at\nthe least abstract level, software architecture analysis and design are at the\nmost abstract level. We conclude by providing a discussion on challenges for\nfuture development of AI-supported code completion tools to reach the design\nlevel of abstraction in our taxonomy.\n","authors":["Rohith Pudari","Neil A. Ernst"],"pdf_url":"https://arxiv.org/pdf/2303.04142v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04136v1","updated":"2023-03-07T18:50:00Z","published":"2023-03-07T18:50:00Z","title":"Domain Randomization for Robust, Affordable and Effective Closed-loop\n  Control of Soft Robots","summary":"  Soft robots are becoming extremely popular thanks to their intrinsic safety\nto contacts and adaptability. However, the potentially infinite number of\nDegrees of Freedom makes their modeling a daunting task, and in many cases only\nan approximated description is available. This challenge makes reinforcement\nlearning (RL) based approaches inefficient when deployed on a realistic\nscenario, due to the large domain gap between models and the real platform. In\nthis work, we demonstrate, for the first time, how Domain Randomization (DR)\ncan solve this problem by enhancing RL policies with: i) a higher robustness\nw.r.t. environmental changes; ii) a higher affordability of learned policies\nwhen the target model differs significantly from the training model; iii) a\nhigher effectiveness of the policy, which can even autonomously learn to\nexploit the environment to increase the robot capabilities (environmental\nconstraints exploitation). Moreover, we introduce a novel algorithmic extension\nof previous adaptive domain randomization methods for the automatic inference\nof dynamics parameters for deformable objects. We provide results on four\ndifferent tasks and two soft robot designs, opening interesting perspectives\nfor future research on Reinforcement Learning for closed-loop soft robot\ncontrol.\n","authors":["Gabriele Tiboni","Andrea Protopapa","Tatiana Tommasi","Giuseppe Averta"],"pdf_url":"https://arxiv.org/pdf/2303.04136v1.pdf","comment":"Project website at https://andreaprotopapa.github.io/dr-soro/"},{"id":"http://arxiv.org/abs/2303.04132v1","updated":"2023-03-07T18:48:55Z","published":"2023-03-07T18:48:55Z","title":"Exploiting Asymmetry for Synthetic Training Data Generation: SynthIE and\n  the Case of Information Extraction","summary":"  Large language models (LLMs) show great potential for synthetic data\ngeneration. This work shows that useful data can be synthetically generated\neven for tasks that cannot be solved directly by the LLM: we show that, for\nproblems with structured outputs, it is possible to prompt an LLM to perform\nthe task in the opposite direction, to generate plausible text for the target\nstructure. Leveraging the asymmetry in task difficulty makes it possible to\nproduce large-scale, high-quality data for complex tasks. We demonstrate the\neffectiveness of this approach on closed information extraction, where\ncollecting ground-truth data is challenging, and no satisfactory dataset exists\nto date. We synthetically generate a dataset of 1.8M data points, demonstrate\nits superior quality compared to existing datasets in a human evaluation and\nuse it to finetune small models (220M and 770M parameters). The models we\nintroduce, SynthIE, outperform existing baselines of comparable size with a\nsubstantial gap of 57 and 79 absolute points in micro and macro F1,\nrespectively. Code, data, and models are available at\nhttps://github.com/epfl-dlab/SynthIE.\n","authors":["Martin Josifoski","Marija Sakota","Maxime Peyrard","Robert West"],"pdf_url":"https://arxiv.org/pdf/2303.04132v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04129v1","updated":"2023-03-07T18:44:07Z","published":"2023-03-07T18:44:07Z","title":"Foundation Models for Decision Making: Problems, Methods, and\n  Opportunities","summary":"  Foundation models pretrained on diverse data at scale have demonstrated\nextraordinary capabilities in a wide range of vision and language tasks. When\nsuch models are deployed in real world environments, they inevitably interface\nwith other entities and agents. For example, language models are often used to\ninteract with human beings through dialogue, and visual perception models are\nused to autonomously navigate neighborhood streets. In response to these\ndevelopments, new paradigms are emerging for training foundation models to\ninteract with other agents and perform long-term reasoning. These paradigms\nleverage the existence of ever-larger datasets curated for multimodal,\nmultitask, and generalist interaction. Research at the intersection of\nfoundation models and decision making holds tremendous promise for creating\npowerful new systems that can interact effectively across a diverse range of\napplications such as dialogue, autonomous driving, healthcare, education, and\nrobotics. In this manuscript, we examine the scope of foundation models for\ndecision making, and provide conceptual tools and technical background for\nunderstanding the problem space and exploring new research directions. We\nreview recent approaches that ground foundation models in practical decision\nmaking applications through a variety of methods such as prompting, conditional\ngenerative modeling, planning, optimal control, and reinforcement learning, and\ndiscuss common challenges and open problems in the field.\n","authors":["Sherry Yang","Ofir Nachum","Yilun Du","Jason Wei","Pieter Abbeel","Dale Schuurmans"],"pdf_url":"https://arxiv.org/pdf/2303.04129v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04124v1","updated":"2023-03-07T18:34:55Z","published":"2023-03-07T18:34:55Z","title":"Wigner kernels: body-ordered equivariant machine learning without a\n  basis","summary":"  Machine-learning models based on a point-cloud representation of a physical\nobject are ubiquitous in scientific applications and particularly well-suited\nto the atomic-scale description of molecules and materials. Among the many\ndifferent approaches that have been pursued, the description of local atomic\nenvironments in terms of their neighbor densities has been used widely and very\nsuccesfully. We propose a novel density-based method which involves computing\n``Wigner kernels''. These are fully equivariant and body-ordered kernels that\ncan be computed iteratively with a cost that is independent of the\nradial-chemical basis and grows only linearly with the maximum body-order\nconsidered. This is in marked contrast to feature-space models, which comprise\nan exponentially-growing number of terms with increasing order of correlations.\nWe present several examples of the accuracy of models based on Wigner kernels\nin chemical applications, for both scalar and tensorial targets, reaching\nstate-of-the-art accuracy on the popular QM9 benchmark dataset, and we discuss\nthe broader relevance of these ideas to equivariant geometric machine-learning.\n","authors":["Filippo Bigi","Sergey N. Pozdnyakov","Michele Ceriotti"],"pdf_url":"https://arxiv.org/pdf/2303.04124v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04118v1","updated":"2023-03-07T18:29:15Z","published":"2023-03-07T18:29:15Z","title":"A Multiplicative Value Function for Safe and Efficient Reinforcement\n  Learning","summary":"  An emerging field of sequential decision problems is safe Reinforcement\nLearning (RL), where the objective is to maximize the reward while obeying\nsafety constraints. Being able to handle constraints is essential for deploying\nRL agents in real-world environments, where constraint violations can harm the\nagent and the environment. To this end, we propose a safe model-free RL\nalgorithm with a novel multiplicative value function consisting of a safety\ncritic and a reward critic. The safety critic predicts the probability of\nconstraint violation and discounts the reward critic that only estimates\nconstraint-free returns. By splitting responsibilities, we facilitate the\nlearning task leading to increased sample efficiency. We integrate our approach\ninto two popular RL algorithms, Proximal Policy Optimization and Soft\nActor-Critic, and evaluate our method in four safety-focused environments,\nincluding classical RL benchmarks augmented with safety constraints and robot\nnavigation tasks with images and raw Lidar scans as observations. Finally, we\nmake the zero-shot sim-to-real transfer where a differential drive robot has to\nnavigate through a cluttered room. Our code can be found at\nhttps://github.com/nikeke19/Safe-Mult-RL.\n","authors":["Nick Bührer","Zhejun Zhang","Alexander Liniger","Fisher Yu","Luc Van Gool"],"pdf_url":"https://arxiv.org/pdf/2303.04118v1.pdf","comment":"Repository available at https://github.com/nikeke19/Safe-Mult-RL"},{"id":"http://arxiv.org/abs/2303.04117v1","updated":"2023-03-07T18:28:45Z","published":"2023-03-07T18:28:45Z","title":"Validation of a Hospital Digital Twin with Machine Learning","summary":"  Recently there has been a surge of interest in developing Digital Twins of\nprocess flows in healthcare to better understand bottlenecks and areas of\nimprovement. A key challenge is in the validation process. We describe a work\nin progress for a digital twin using an agent based simulation model for\ndetermining bed turnaround time for patients in hospitals. We employ a strategy\nusing machine learning for validating the model and implementing sensitivity\nanalysis.\n","authors":["Muhammad Aurangzeb Ahmad","Vijay Chickarmane","Farinaz Ali Sabzpour","Nima Shariari","Taposh Roy"],"pdf_url":"https://arxiv.org/pdf/2303.04117v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04115v1","updated":"2023-03-07T18:28:39Z","published":"2023-03-07T18:28:39Z","title":"Predicted Embedding Power Regression for Large-Scale Out-of-Distribution\n  Detection","summary":"  Out-of-distribution (OOD) inputs can compromise the performance and safety of\nreal world machine learning systems. While many methods exist for OOD detection\nand work well on small scale datasets with lower resolution and few classes,\nfew methods have been developed for large-scale OOD detection. Existing\nlarge-scale methods generally depend on maximum classification probability,\nsuch as the state-of-the-art grouped softmax method. In this work, we develop a\nnovel approach that calculates the probability of the predicted class label\nbased on label distributions learned during the training process. Our method\nperforms better than current state-of-the-art methods with only a negligible\nincrease in compute cost. We evaluate our method against contemporary methods\nacross $14$ datasets and achieve a statistically significant improvement with\nrespect to AUROC (84.2 vs 82.4) and AUPR (96.2 vs 93.7).\n","authors":["Hong Yang","William Gebhardt","Alexander G. Ororbia","Travis Desell"],"pdf_url":"https://arxiv.org/pdf/2303.04115v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2106.11299v6","updated":"2023-03-07T18:26:49Z","published":"2021-06-21T17:56:07Z","title":"Boundary Graph Neural Networks for 3D Simulations","summary":"  The abundance of data has given machine learning considerable momentum in\nnatural sciences and engineering, though modeling of physical processes is\noften difficult. A particularly tough problem is the efficient representation\nof geometric boundaries. Triangularized geometric boundaries are well\nunderstood and ubiquitous in engineering applications. However, it is\nnotoriously difficult to integrate them into machine learning approaches due to\ntheir heterogeneity with respect to size and orientation. In this work, we\nintroduce an effective theory to model particle-boundary interactions, which\nleads to our new Boundary Graph Neural Networks (BGNNs) that dynamically modify\ngraph structures to obey boundary conditions. The new BGNNs are tested on\ncomplex 3D granular flow processes of hoppers, rotating drums and mixers, which\nare all standard components of modern industrial machinery but still have\ncomplicated geometry. BGNNs are evaluated in terms of computational efficiency\nas well as prediction accuracy of particle flows and mixing entropies. BGNNs\nare able to accurately reproduce 3D granular flows within simulation\nuncertainties over hundreds of thousands of simulation timesteps. Most notably,\nin our experiments, particles stay within the geometric objects without using\nhandcrafted conditions or restrictions.\n","authors":["Andreas Mayr","Sebastian Lehner","Arno Mayrhofer","Christoph Kloss","Sepp Hochreiter","Johannes Brandstetter"],"pdf_url":"https://arxiv.org/pdf/2106.11299v6.pdf","comment":"accepted for presentation at the Thirty-Seventh AAAI Conference on\n  Artificial Intelligence (AAAI-23)"},{"id":"http://arxiv.org/abs/2212.01848v2","updated":"2023-03-07T18:26:01Z","published":"2022-12-04T15:26:36Z","title":"Convergence under Lipschitz smoothness of ease-controlled Random\n  Reshuffling gradient Algorithms","summary":"  We consider minimizing the average of a very large number of smooth and\npossibly non-convex functions. This optimization problem has deserved much\nattention in the past years due to the many applications in different fields,\nthe most challenging being training Machine Learning models. Widely used\napproaches for solving this problem are mini-batch gradient methods which, at\neach iteration, update the decision vector moving along the gradient of a\nmini-batch of the component functions. We consider the Incremental Gradient\n(IG) and the Random reshuffling (RR) methods which proceed in cycles, picking\nbatches in a fixed order or by reshuffling the order after each epoch.\nConvergence properties of these schemes have been proved under different\nassumptions, usually quite strong. We aim to define ease-controlled\nmodifications of the IG/RR schemes, which require a light additional\ncomputational effort and can be proved to converge under very weak and standard\nassumptions. In particular, we define two algorithmic schemes, monotone or\nnon-monotone, in which the IG/RR iteration is controlled by using a watchdog\nrule and a derivative-free line search that activates only sporadically to\nguarantee convergence. The two schemes also allow controlling the updating of\nthe stepsize used in the main IG/RR iteration, avoiding the use of preset\nrules. We prove convergence under the lonely assumption of Lipschitz continuity\nof the gradients of the component functions and perform extensive computational\nanalysis using Deep Neural Architectures and a benchmark of datasets. We\ncompare our implementation with both full batch gradient methods and online\nstandard implementation of IG/RR methods, proving that the computational effort\nis comparable with the corresponding online methods and that the control on the\nlearning rate may allow faster decrease.\n","authors":["Giampaolo Liuzzi","Laura Palagi","Ruggiero Seccia"],"pdf_url":"https://arxiv.org/pdf/2212.01848v2.pdf","comment":"Add references, correct typos"},{"id":"http://arxiv.org/abs/2106.09215v4","updated":"2023-03-07T18:23:05Z","published":"2021-06-17T02:37:39Z","title":"Optimum-statistical Collaboration Towards General and Efficient\n  Black-box Optimization","summary":"  In this paper, we make the key delineation on the roles of resolution and\nstatistical uncertainty in hierarchical bandits-based black-box optimization\nalgorithms, guiding a more general analysis and a more efficient algorithm\ndesign. We introduce the \\textit{optimum-statistical collaboration}, an\nalgorithm framework of managing the interaction between optimization error flux\nand statistical error flux evolving in the optimization process. We provide a\ngeneral analysis of this framework without specifying the forms of statistical\nerror and uncertainty quantifier. Our framework and its analysis, due to their\ngenerality, can be applied to a large family of functions and partitions that\nsatisfy different local smoothness assumptions and have different numbers of\nlocal optimums, which is much richer than the class of functions studied in\nprior works. Our framework also inspires us to propose a better measure of the\nstatistical uncertainty and consequently a variance-adaptive algorithm\n\\texttt{VHCT}. In theory, we prove the algorithm enjoys rate-optimal regret\nbounds under different local smoothness assumptions; in experiments, we show\nthe algorithm outperforms prior efforts in different settings.\n","authors":["Wenjie Li","Chi-Hua Wang","Qifan Song","Guang Cheng"],"pdf_url":"https://arxiv.org/pdf/2106.09215v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04105v1","updated":"2023-03-07T18:12:24Z","published":"2023-03-07T18:12:24Z","title":"Introspective Cross-Attention Probing for Lightweight Transfer of\n  Pre-trained Models","summary":"  We propose InCA, a lightweight method for transfer learning that\ncross-attends to any activation layer of a pre-trained model. During training,\nInCA uses a single forward pass to extract multiple activations, which are\npassed to external cross-attention adapters, trained anew and combined or\nselected for downstream tasks. We show that, even when selecting a single\ntop-scoring adapter, InCA achieves performance comparable to full fine-tuning,\nat a cost comparable to fine-tuning just the last layer. For example, with a\ncross-attention probe 1.3% the size of a pre-trained ViT-L/16 model, we achieve\nperformance within 0.2% of the full fine-tuning paragon at 51% training cost of\nthe baseline, on average across 11 downstream classification tasks. Unlike\nother forms of efficient adaptation, InCA does not require backpropagating\nthrough the pre-trained model, thus leaving its execution unaltered at both\ntraining and inference. The versatility of InCA is best illustrated in\nfine-grained tasks, which may require accessing information absent in the last\nlayer but accessible in intermediate layer activations. Since the backbone is\nfixed, InCA allows parallel ensembling as well as parallel execution of\nmultiple tasks. InCA achieves state-of-the-art performance in the\nImageNet-to-Sketch multi-task benchmark.\n","authors":["Yonatan Dukler","Alessandro Achille","Hao Yang","Varsha Vivek","Luca Zancato","Ben Bowman","Avinash Ravichandran","Charless Fowlkes","Ashwin Swaminathan","Stefano Soatto"],"pdf_url":"https://arxiv.org/pdf/2303.04105v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04104v1","updated":"2023-03-07T18:10:05Z","published":"2023-03-07T18:10:05Z","title":"An Inception-Residual-Based Architecture with Multi-Objective Loss for\n  Detecting Respiratory Anomalies","summary":"  This paper presents a deep learning system applied for detecting anomalies\nfrom respiratory sound recordings. Initially, our system begins with audio\nfeature extraction using Gammatone and Continuous Wavelet transformation. This\nstep aims to transform the respiratory sound input into a two-dimensional\nspectrogram where both spectral and temporal features are presented. Then, our\nproposed system integrates Inception-residual-based backbone models combined\nwith multi-head attention and multi-objective loss to classify respiratory\nanomalies. In this work, we conducted experiments over the benchmark dataset of\nSPRSound (The Open-Source SJTU Paediatric Respiratory Sound) proposed by the\nIEEE BioCAS 2022 challenge. As regards the Score computed by an average between\nthe average score and harmonic score, our proposed system gained significant\nimprovements of 9.7%, 15.8%, 17.0%, and 9.4% in Task 1-1, Task 1-2, Task 2-1,\nand Task 2-2 compared to the challenge baseline system. Notably, we achieved\nthe Top-1 performance in Task 2-1 with the highest Score of 73.7%.\n","authors":["Dat Ngo","Lam Pham","Huy Phan","Minh Tran","Delaram Jarchi","Sefki Kolozali"],"pdf_url":"https://arxiv.org/pdf/2303.04104v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2110.03051v3","updated":"2023-03-07T18:05:45Z","published":"2021-10-06T20:13:57Z","title":"Prior and Posterior Networks: A Survey on Evidential Deep Learning\n  Methods For Uncertainty Estimation","summary":"  Popular approaches for quantifying predictive uncertainty in deep neural\nnetworks often involve distributions over weights or multiple models, for\ninstance via Markov Chain sampling, ensembling, or Monte Carlo dropout. These\ntechniques usually incur overhead by having to train multiple model instances\nor do not produce very diverse predictions. This comprehensive and extensive\nsurvey aims to familiarize the reader with an alternative class of models based\non the concept of Evidential Deep Learning: For unfamiliar data, they aim to\nadmit \"what they don't know\", and fall back onto a prior belief. Furthermore,\nthey allow uncertainty estimation in a single model and forward pass by\nparameterizing distributions over distributions. This survey recapitulates\nexisting works, focusing on the implementation in a classification setting,\nbefore surveying the application of the same paradigm to regression. We also\nreflect on the strengths and weaknesses compared to other existing methods and\nprovide the most fundamental derivations using a unified notation to aid future\nresearch.\n","authors":["Dennis Ulmer","Christian Hardmeier","Jes Frellsen"],"pdf_url":"https://arxiv.org/pdf/2110.03051v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04096v1","updated":"2023-03-07T17:55:28Z","published":"2023-03-07T17:55:28Z","title":"Mastering Strategy Card Game (Legends of Code and Magic) via End-to-End\n  Policy and Optimistic Smooth Fictitious Play","summary":"  Deep Reinforcement Learning combined with Fictitious Play shows impressive\nresults on many benchmark games, most of which are, however, single-stage. In\ncontrast, real-world decision making problems may consist of multiple stages,\nwhere the observation spaces and the action spaces can be completely different\nacross stages. We study a two-stage strategy card game Legends of Code and\nMagic and propose an end-to-end policy to address the difficulties that arise\nin multi-stage game. We also propose an optimistic smooth fictitious play\nalgorithm to find the Nash Equilibrium for the two-player game. Our approach\nwins double championships of COG2022 competition. Extensive studies verify and\nshow the advancement of our approach.\n","authors":["Wei Xi","Yongxin Zhang","Changnan Xiao","Xuefeng Huang","Shihong Deng","Haowei Liang","Jie Chen","Peng Sun"],"pdf_url":"https://arxiv.org/pdf/2303.04096v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04091v1","updated":"2023-03-07T17:52:46Z","published":"2023-03-07T17:52:46Z","title":"Visual Abstraction and Reasoning through Language","summary":"  While Artificial Intelligence (AI) models have achieved human or even\nsuperhuman performance in narrowly defined applications, they still struggle to\nshow signs of broader and more flexible intelligence. The Abstraction and\nReasoning Corpus (ARC), introduced by Fran\\c{c}ois Chollet, aims to assess how\nclose AI systems are to human-like cognitive abilities. Most current approaches\nrely on carefully handcrafted domain-specific languages (DSLs), which are used\nto brute-force solutions to the tasks present in ARC. In this work, we propose\na general framework for solving ARC based on natural language descriptions of\nthe tasks. While not yet beating state-of-the-art DSL models on ARC, we\ndemonstrate the immense potential of our approach hinted at by the ability to\nsolve previously unsolved tasks.\n","authors":["Giacomo Camposampiero","Loic Houmard","Benjamin Estermann","Joël Mathys","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2303.04091v1.pdf","comment":"The first two authors have contributed equally to this work"},{"id":"http://arxiv.org/abs/2106.02735v4","updated":"2023-03-07T17:34:29Z","published":"2021-06-04T22:00:53Z","title":"Learning particle swarming models from data with Gaussian processes","summary":"  Interacting particle or agent systems that display a rich variety of swarming\nbehaviours are ubiquitous in science and engineering. A fundamental and\nchallenging goal is to understand the link between individual interaction rules\nand swarming. In this paper, we study the data-driven discovery of a\nsecond-order particle swarming model that describes the evolution of $N$\nparticles in $\\mathbb{R}^d$ under radial interactions. We propose a learning\napproach that models the latent radial interaction function as Gaussian\nprocesses, which can simultaneously fulfill two inference goals: one is the\nnonparametric inference of {the} interaction function with pointwise\nuncertainty quantification, and the other one is the inference of unknown\nscalar parameters in the non-collective friction forces of the system. We\nformulate the learning problem as a statistical inverse problem and provide a\ndetailed analysis of recoverability conditions, establishing that a coercivity\ncondition is sufficient for recoverability. Given data collected from $M$ i.i.d\ntrajectories with independent Gaussian observational noise, we provide a\nfinite-sample analysis, showing that our posterior mean estimator converges in\na Reproducing kernel Hilbert space norm, at an optimal rate in $M$ equal to the\none in the classical 1-dimensional Kernel Ridge regression. As a byproduct, we\nshow we can obtain a parametric learning rate in $M$ for the posterior marginal\nvariance using $L^{\\infty}$ norm, and the rate could also involve $N$ and $L$\n(the number of observation time instances for each trajectory), depending on\nthe condition number of the inverse problem. Numerical results on systems that\nexhibit different swarming behaviors demonstrate efficient learning of our\napproach from scarce noisy trajectory data.\n","authors":["Jinchao Feng","Charles Kulick","Yunxiang Ren","Sui Tang"],"pdf_url":"https://arxiv.org/pdf/2106.02735v4.pdf","comment":"44 pages; Appendix 5 pages"},{"id":"http://arxiv.org/abs/2211.09330v3","updated":"2023-03-07T17:20:45Z","published":"2022-11-17T04:37:24Z","title":"ACon$^2$: Adaptive Conformal Consensus for Provable Blockchain Oracles","summary":"  Blockchains with smart contracts are distributed ledger systems that achieve\nblock-state consistency among distributed nodes by only allowing deterministic\noperations of smart contracts. However, the power of smart contracts is enabled\nby interacting with stochastic off-chain data, which in turn opens the\npossibility to undermine the block-state consistency. To address this issue, an\noracle smart contract is used to provide a single consistent source of external\ndata; but, simultaneously, this introduces a single point of failure, which is\ncalled the oracle problem. To address the oracle problem, we propose an\nadaptive conformal consensus (ACon$^2$) algorithm that derives a consensus set\nof data from multiple oracle contracts via the recent advance in online\nuncertainty quantification learning. Interesting, the consensus set provides a\ndesired correctness guarantee under distribution shift and Byzantine\nadversaries. We demonstrate the efficacy of the proposed algorithm on two price\ndatasets and an Ethereum case study. In particular, the Solidity implementation\nof the proposed algorithm shows the potential practicality of the proposed\nalgorithm, implying that online machine learning algorithms are applicable to\naddress security issues in blockchains.\n","authors":["Sangdon Park","Osbert Bastani","Taesoo Kim"],"pdf_url":"https://arxiv.org/pdf/2211.09330v3.pdf","comment":"Accepted to USENIX Security 2023"},{"id":"http://arxiv.org/abs/2303.04040v1","updated":"2023-03-07T16:49:46Z","published":"2023-03-07T16:49:46Z","title":"Uncertainty Quantification of Spatiotemporal Travel Demand with\n  Probabilistic Graph Neural Networks","summary":"  Recent studies have significantly improved the prediction accuracy of travel\ndemand using graph neural networks. However, these studies largely ignored\nuncertainty that inevitably exists in travel demand prediction. To fill this\ngap, this study proposes a framework of probabilistic graph neural networks\n(Prob-GNN) to quantify the spatiotemporal uncertainty of travel demand. This\nProb-GNN framework is substantiated by deterministic and probabilistic\nassumptions, and empirically applied to the task of predicting the transit and\nridesharing demand in Chicago. We found that the probabilistic assumptions\n(e.g. distribution tail, support) have a greater impact on uncertainty\nprediction than the deterministic ones (e.g. deep modules, depth). Among the\nfamily of Prob-GNNs, the GNNs with truncated Gaussian and Laplace distributions\nachieve the highest performance in transit and ridesharing data. Even under\nsignificant domain shifts, Prob-GNNs can predict the ridership uncertainty in a\nstable manner, when the models are trained on pre-COVID data and tested across\nmultiple periods during and after the COVID-19 pandemic. Prob-GNNs also reveal\nthe spatiotemporal pattern of uncertainty, which is concentrated on the\nafternoon peak hours and the areas with large travel volumes. Overall, our\nfindings highlight the importance of incorporating randomness into deep\nlearning for spatiotemporal ridership prediction. Future research should\ncontinue to investigate versatile probabilistic assumptions to capture\nbehavioral randomness, and further develop methods to quantify uncertainty to\nbuild resilient cities.\n","authors":["Qingyi Wang","Shenhao Wang","Dingyi Zhuang","Haris Koutsopoulos","Jinhua Zhao"],"pdf_url":"https://arxiv.org/pdf/2303.04040v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.08261v2","updated":"2023-03-07T16:48:14Z","published":"2023-02-16T12:38:01Z","title":"Knowledge-augmented Graph Machine Learning for Drug Discovery: A Survey\n  from Precision to Interpretability","summary":"  The integration of Artificial Intelligence (AI) into the field of drug\ndiscovery has been a growing area of interdisciplinary scientific research.\nHowever, conventional AI models are heavily limited in handling complex\nbiomedical structures (such as 2D or 3D protein and molecule structures) and\nproviding interpretations for outputs, which hinders their practical\napplication. As of late, Graph Machine Learning (GML) has gained considerable\nattention for its exceptional ability to model graph-structured biomedical data\nand investigate their properties and functional relationships. Despite\nextensive efforts, GML methods still suffer from several deficiencies, such as\nthe limited ability to handle supervision sparsity and provide interpretability\nin learning and inference processes, and their ineffectiveness in utilising\nrelevant domain knowledge. In response, recent studies have proposed\nintegrating external biomedical knowledge into the GML pipeline to realise more\nprecise and interpretable drug discovery with limited training instances.\nHowever, a systematic definition for this burgeoning research direction is yet\nto be established. This survey presents a comprehensive overview of\nlong-standing drug discovery principles, provides the foundational concepts and\ncutting-edge techniques for graph-structured data and knowledge databases, and\nformally summarises Knowledge-augmented Graph Machine Learning (KaGML) for drug\ndiscovery. we propose a thorough review of related KaGML works, collected\nfollowing a carefully designed search methodology, and organise them into four\ncategories following a novel-defined taxonomy. To facilitate research in this\npromptly emerging field, we also share collected practical resources that are\nvaluable for intelligent drug discovery and provide an in-depth discussion of\nthe potential avenues for future advancements.\n","authors":["Zhiqiang Zhong","Anastasia Barkova","Davide Mottin"],"pdf_url":"https://arxiv.org/pdf/2302.08261v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.04038v1","updated":"2023-03-07T16:47:35Z","published":"2023-03-07T16:47:35Z","title":"Root Cause Identification for Collective Anomalies in Time Series given\n  an Acyclic Summary Causal Graph with Loops","summary":"  This paper presents an approach for identifying the root causes of collective\nanomalies given observational time series and an acyclic summary causal graph\nwhich depicts an abstraction of causal relations present in a dynamic system at\nits normal regime. The paper first shows how the problem of root cause\nidentification can be divided into many independent subproblems by grouping\nrelated anomalies using d-separation. Further, it shows how, under this\nsetting, some root causes can be found directly from the graph and from the\ntime of appearance of anomalies. Finally, it shows, how the rest of the root\ncauses can be found by comparing direct causal effects in the normal and in the\nanomalous regime. To this end, temporal adaptations of the back-door and the\nsingle-door criterions are introduced. Extensive experiments conducted on both\nsimulated and real-world datasets demonstrate the effectiveness of the proposed\nmethod.\n","authors":["Charles K. Assaad","Imad Ez-zejjari","Lei Zan"],"pdf_url":"https://arxiv.org/pdf/2303.04038v1.pdf","comment":"Proceedings of the 26th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2023, Valencia, Spain"},{"id":"http://arxiv.org/abs/2303.04030v1","updated":"2023-03-07T16:43:05Z","published":"2023-03-07T16:43:05Z","title":"PyXAB -- A Python Library for $\\mathcal{X}$-Armed Bandit and Online\n  Blackbox Optimization Algorithms","summary":"  We introduce a Python open-source library for $\\mathcal{X}$-armed bandit and\nonline blackbox optimization named PyXAB. PyXAB contains the implementations\nfor more than 10 $\\mathcal{X}$-armed bandit algorithms, such as HOO, StoSOO,\nHCT, and the most recent works GPO and VHCT. PyXAB also provides the most\ncommonly-used synthetic objectives to evaluate the performance of different\nalgorithms and the various choices of the hierarchical partitions on the\nparameter space. The online documentation for PyXAB includes clear instructions\nfor installation, straight-forward examples, detailed feature descriptions, and\na complete reference of the API. PyXAB is released under the MIT license in\norder to encourage both academic and industrial usage. The library can be\ndirectly installed from PyPI with its source code available at\nhttps://github.com/WilliamLwj/PyXAB\n","authors":["Wenjie Li","Haoze Li","Jean Honorio","Qifan Song"],"pdf_url":"https://arxiv.org/pdf/2303.04030v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.12053v2","updated":"2023-03-07T16:41:02Z","published":"2022-12-22T22:05:16Z","title":"On Calibrating Semantic Segmentation Models: Analyses and An Algorithm","summary":"  We study the problem of semantic segmentation calibration. For image\nclassification, lots of existing solutions are proposed to alleviate model\nmiscalibration of confidence. However, to date, confidence calibration research\non semantic segmentation is still limited. We provide a systematic study on the\ncalibration of semantic segmentation models and propose a simple yet effective\napproach. First, we find that model capacity, crop size, multi-scale testing,\nand prediction correctness have impact on calibration. Among them, prediction\ncorrectness, especially misprediction, is more important to miscalibration due\nto over-confidence. Next, we propose a simple, unifying, and effective\napproach, namely selective scaling, by separating correct/incorrect prediction\nfor scaling and more focusing on misprediction logit smoothing. Then, we study\npopular existing calibration methods and compare them with selective scaling on\nsemantic segmentation calibration. We conduct extensive experiments with a\nvariety of benchmarks on both in-domain and domain-shift calibration, and show\nthat selective scaling consistently outperforms other methods.\n","authors":["Dongdong Wang","Boqing Gong","Liqiang Wang"],"pdf_url":"https://arxiv.org/pdf/2212.12053v2.pdf","comment":"Accepted to CVPR2023 (8 pages, 4 figures)"},{"id":"http://arxiv.org/abs/2303.04020v1","updated":"2023-03-07T16:37:30Z","published":"2023-03-07T16:37:30Z","title":"When is Importance Weighting Correction Needed for Covariate Shift\n  Adaptation?","summary":"  This paper investigates when the importance weighting (IW) correction is\nneeded to address covariate shift, a common situation in supervised learning\nwhere the input distributions of training and test data differ. Classic results\nshow that the IW correction is needed when the model is parametric and\nmisspecified. In contrast, recent results indicate that the IW correction may\nnot be necessary when the model is nonparametric and well-specified. We examine\nthe missing case in the literature where the model is nonparametric and\nmisspecified, and show that the IW correction is needed for obtaining the best\napproximation of the true unknown function for the test distribution. We do\nthis by analyzing IW-corrected kernel ridge regression, covering a variety of\nsettings, including parametric and nonparametric models, well-specified and\nmisspecified settings, and arbitrary weighting functions.\n","authors":["Davit Gogolashvili","Matteo Zecchin","Motonobu Kanagawa","Marios Kountouris","Maurizio Filippone"],"pdf_url":"https://arxiv.org/pdf/2303.04020v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.11485v2","updated":"2023-03-07T16:34:59Z","published":"2021-11-22T19:24:57Z","title":"A Free Lunch from the Noise: Provable and Practical Exploration for\n  Representation Learning","summary":"  Representation learning lies at the heart of the empirical success of deep\nlearning for dealing with the curse of dimensionality. However, the power of\nrepresentation learning has not been fully exploited yet in reinforcement\nlearning (RL), due to i), the trade-off between expressiveness and\ntractability; and ii), the coupling between exploration and representation\nlearning. In this paper, we first reveal the fact that under some noise\nassumption in the stochastic control model, we can obtain the linear spectral\nfeature of its corresponding Markov transition operator in closed-form for\nfree. Based on this observation, we propose Spectral Dynamics Embedding\n(SPEDE), which breaks the trade-off and completes optimistic exploration for\nrepresentation learning by exploiting the structure of the noise. We provide\nrigorous theoretical analysis of SPEDE, and demonstrate the practical superior\nperformance over the existing state-of-the-art empirical algorithms on several\nbenchmarks.\n","authors":["Tongzheng Ren","Tianjun Zhang","Csaba Szepesvári","Bo Dai"],"pdf_url":"https://arxiv.org/pdf/2111.11485v2.pdf","comment":"UAI 2022. The first two authors contribute equally"},{"id":"http://arxiv.org/abs/2303.04016v1","updated":"2023-03-07T16:31:13Z","published":"2023-03-07T16:31:13Z","title":"Decoupling Skill Learning from Robotic Control for Generalizable Object\n  Manipulation","summary":"  Recent works in robotic manipulation through reinforcement learning (RL) or\nimitation learning (IL) have shown potential for tackling a range of tasks\ne.g., opening a drawer or a cupboard. However, these techniques generalize\npoorly to unseen objects. We conjecture that this is due to the\nhigh-dimensional action space for joint control. In this paper, we take an\nalternative approach and separate the task of learning 'what to do' from 'how\nto do it' i.e., whole-body control. We pose the RL problem as one of\ndetermining the skill dynamics for a disembodied virtual manipulator\ninteracting with articulated objects. The whole-body robotic kinematic control\nis optimized to execute the high-dimensional joint motion to reach the goals in\nthe workspace. It does so by solving a quadratic programming (QP) model with\nrobotic singularity and kinematic constraints. Our experiments on manipulating\ncomplex articulated objects show that the proposed approach is more\ngeneralizable to unseen objects with large intra-class variations,\noutperforming previous approaches. The evaluation results indicate that our\napproach generates more compliant robotic motion and outperforms the pure RL\nand IL baselines in task success rates.\n","authors":["Kai Lu","Bo Yang","Bing Wang","Andrew Markham"],"pdf_url":"https://arxiv.org/pdf/2303.04016v1.pdf","comment":"Accepted to IEEE International Conference on Robotics and Automation\n  (ICRA) 2023"},{"id":"http://arxiv.org/abs/2211.09019v2","updated":"2023-03-07T16:29:49Z","published":"2022-11-16T16:26:48Z","title":"Learning Reward Functions for Robotic Manipulation by Observing Humans","summary":"  Observing a human demonstrator manipulate objects provides a rich, scalable\nand inexpensive source of data for learning robotic policies. However,\ntransferring skills from human videos to a robotic manipulator poses several\nchallenges, not least a difference in action and observation spaces. In this\nwork, we use unlabeled videos of humans solving a wide range of manipulation\ntasks to learn a task-agnostic reward function for robotic manipulation\npolicies. Thanks to the diversity of this training data, the learned reward\nfunction sufficiently generalizes to image observations from a previously\nunseen robot embodiment and environment to provide a meaningful prior for\ndirected exploration in reinforcement learning. We propose two methods for\nscoring states relative to a goal image: through direct temporal regression,\nand through distances in an embedding space obtained with time-contrastive\nlearning. By conditioning the function on a goal image, we are able to reuse\none model across a variety of tasks. Unlike prior work on leveraging human\nvideos to teach robots, our method, Human Offline Learned Distances (HOLD)\nrequires neither a priori data from the robot environment, nor a set of\ntask-specific human demonstrations, nor a predefined notion of correspondence\nacross morphologies, yet it is able to accelerate training of several\nmanipulation tasks on a simulated robot arm compared to using only a sparse\nreward obtained from task completion.\n","authors":["Minttu Alakuijala","Gabriel Dulac-Arnold","Julien Mairal","Jean Ponce","Cordelia Schmid"],"pdf_url":"https://arxiv.org/pdf/2211.09019v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.08765v2","updated":"2023-03-07T16:28:18Z","published":"2022-12-17T00:26:31Z","title":"Latent Variable Representation for Reinforcement Learning","summary":"  Deep latent variable models have achieved significant empirical successes in\nmodel-based reinforcement learning (RL) due to their expressiveness in modeling\ncomplex transition dynamics. On the other hand, it remains unclear\ntheoretically and empirically how latent variable models may facilitate\nlearning, planning, and exploration to improve the sample efficiency of RL. In\nthis paper, we provide a representation view of the latent variable models for\nstate-action value functions, which allows both tractable variational learning\nalgorithm and effective implementation of the optimism/pessimism principle in\nthe face of uncertainty for exploration. In particular, we propose a\ncomputationally efficient planning algorithm with UCB exploration by\nincorporating kernel embeddings of latent variable models. Theoretically, we\nestablish the sample complexity of the proposed approach in the online and\noffline settings. Empirically, we demonstrate superior performance over current\nstate-of-the-art algorithms across various benchmarks.\n","authors":["Tongzheng Ren","Chenjun Xiao","Tianjun Zhang","Na Li","Zhaoran Wang","Sujay Sanghavi","Dale Schuurmans","Bo Dai"],"pdf_url":"https://arxiv.org/pdf/2212.08765v2.pdf","comment":"ICLR 2023. The first two authors contribute equally. Project Website:\n  https://rlrep.github.io/lvrep/"},{"id":"http://arxiv.org/abs/2208.09515v2","updated":"2023-03-07T16:26:05Z","published":"2022-08-19T19:01:30Z","title":"Spectral Decomposition Representation for Reinforcement Learning","summary":"  Representation learning often plays a critical role in reinforcement learning\nby managing the curse of dimensionality. A representative class of algorithms\nexploits a spectral decomposition of the stochastic transition dynamics to\nconstruct representations that enjoy strong theoretical properties in an\nidealized setting. However, current spectral methods suffer from limited\napplicability because they are constructed for state-only aggregation and\nderived from a policy-dependent transition kernel, without considering the\nissue of exploration. To address these issues, we propose an alternative\nspectral method, Spectral Decomposition Representation (SPEDER), that extracts\na state-action abstraction from the dynamics without inducing spurious\ndependence on the data collection policy, while also balancing the\nexploration-versus-exploitation trade-off during learning. A theoretical\nanalysis establishes the sample efficiency of the proposed algorithm in both\nthe online and offline settings. In addition, an experimental investigation\ndemonstrates superior performance over current state-of-the-art algorithms\nacross several benchmarks.\n","authors":["Tongzheng Ren","Tianjun Zhang","Lisa Lee","Joseph E. Gonzalez","Dale Schuurmans","Bo Dai"],"pdf_url":"https://arxiv.org/pdf/2208.09515v2.pdf","comment":"ICLR 2023. The first two authors contribute equally"},{"id":"http://arxiv.org/abs/2303.04012v1","updated":"2023-03-07T16:25:52Z","published":"2023-03-07T16:25:52Z","title":"Exploration via Epistemic Value Estimation","summary":"  How to efficiently explore in reinforcement learning is an open problem. Many\nexploration algorithms employ the epistemic uncertainty of their own value\npredictions -- for instance to compute an exploration bonus or upper confidence\nbound. Unfortunately the required uncertainty is difficult to estimate in\ngeneral with function approximation.\n  We propose epistemic value estimation (EVE): a recipe that is compatible with\nsequential decision making and with neural network function approximators. It\nequips agents with a tractable posterior over all their parameters from which\nepistemic value uncertainty can be computed efficiently.\n  We use the recipe to derive an epistemic Q-Learning agent and observe\ncompetitive performance on a series of benchmarks. Experiments confirm that the\nEVE recipe facilitates efficient exploration in hard exploration tasks.\n","authors":["Simon Schmitt","John Shawe-Taylor","Hado van Hasselt"],"pdf_url":"https://arxiv.org/pdf/2303.04012v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.05117v4","updated":"2023-03-07T16:15:11Z","published":"2022-03-10T02:27:45Z","title":"Optimal Methods for Convex Risk Averse Distributed Optimization","summary":"  This paper studies the communication complexity of convex risk-averse\noptimization over a network. The problem generalizes the well-studied\nrisk-neutral finite-sum distributed optimization problem and its importance\nstems from the need to handle risk in an uncertain environment. For algorithms\nin the literature, there exists a gap in communication complexities for solving\nrisk-averse and risk-neutral problems. We propose two distributed algorithms,\nnamely the distributed risk averse optimization (DRAO) method and the\ndistributed risk averse optimization with sliding (DRAO-S) method, to close the\ngap. Specifically, the DRAO method achieves the optimal communication\ncomplexity by assuming a certain saddle point subproblem can be easily solved\nin the server node. The DRAO-S method removes the strong assumption by\nintroducing a novel saddle point sliding subroutine which only requires the\nprojection over the ambiguity set $P$. We observe that the number of\n$P$-projections performed by DRAO-S is optimal. Moreover, we develop matching\nlower complexity bounds to show the communication complexities of both DRAO and\nDRAO-S to be improvable. Numerical experiments are conducted to demonstrate the\nencouraging empirical performance of the DRAO-S method.\n","authors":["Guanghui Lan","Zhe Zhang"],"pdf_url":"https://arxiv.org/pdf/2203.05117v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.06718v2","updated":"2023-03-07T16:12:58Z","published":"2022-10-13T04:19:05Z","title":"Hybrid RL: Using Both Offline and Online Data Can Make RL Efficient","summary":"  We consider a hybrid reinforcement learning setting (Hybrid RL), in which an\nagent has access to an offline dataset and the ability to collect experience\nvia real-world online interaction. The framework mitigates the challenges that\narise in both pure offline and online RL settings, allowing for the design of\nsimple and highly effective algorithms, in both theory and practice. We\ndemonstrate these advantages by adapting the classical Q learning/iteration\nalgorithm to the hybrid setting, which we call Hybrid Q-Learning or Hy-Q. In\nour theoretical results, we prove that the algorithm is both computationally\nand statistically efficient whenever the offline dataset supports a\nhigh-quality policy and the environment has bounded bilinear rank. Notably, we\nrequire no assumptions on the coverage provided by the initial distribution, in\ncontrast with guarantees for policy gradient/iteration methods. In our\nexperimental results, we show that Hy-Q with neural network function\napproximation outperforms state-of-the-art online, offline, and hybrid RL\nbaselines on challenging benchmarks, including Montezuma's Revenge.\n","authors":["Yuda Song","Yifei Zhou","Ayush Sekhari","J. Andrew Bagnell","Akshay Krishnamurthy","Wen Sun"],"pdf_url":"https://arxiv.org/pdf/2210.06718v2.pdf","comment":"42 pages, 6 figures. Published at ICLR 2023. Code available at\n  https://github.com/yudasong/HyQ"},{"id":"http://arxiv.org/abs/2303.04001v1","updated":"2023-03-07T16:00:26Z","published":"2023-03-07T16:00:26Z","title":"ELODIN: Naming Concepts in Embedding Spaces","summary":"  Despite recent advancements, the field of text-to-image synthesis still\nsuffers from lack of fine-grained control. Using only text, it remains\nchallenging to deal with issues such as concept coherence and concept\ncontamination. We propose a method to enhance control by generating specific\nconcepts that can be reused throughout multiple images, effectively expanding\nnatural language with new words that can be combined much like a painter's\npalette. Unlike previous contributions, our method does not copy visuals from\ninput data and can generate concepts through text alone. We perform a set of\ncomparisons that finds our method to be a significant improvement over\ntext-only prompts.\n","authors":["Rodrigo Mello","Filipe Calegario","Geber Ramalho"],"pdf_url":"https://arxiv.org/pdf/2303.04001v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.13007v2","updated":"2023-03-07T15:56:14Z","published":"2022-10-24T07:55:57Z","title":"Iterative Patch Selection for High-Resolution Image Recognition","summary":"  High-resolution images are prevalent in various applications, such as\nautonomous driving and computer-aided diagnosis. However, training neural\nnetworks on such images is computationally challenging and easily leads to\nout-of-memory errors even on modern GPUs. We propose a simple method, Iterative\nPatch Selection (IPS), which decouples the memory usage from the input size and\nthus enables the processing of arbitrarily large images under tight hardware\nconstraints. IPS achieves this by selecting only the most salient patches,\nwhich are then aggregated into a global representation for image recognition.\nFor both patch selection and aggregation, a cross-attention based transformer\nis introduced, which exhibits a close connection to Multiple Instance Learning.\nOur method demonstrates strong performance and has wide applicability across\ndifferent domains, training regimes and image sizes while using minimal\naccelerator memory. For example, we are able to finetune our model on\nwhole-slide images consisting of up to 250k patches (>16 gigapixels) with only\n5 GB of GPU VRAM at a batch size of 16.\n","authors":["Benjamin Bergner","Christoph Lippert","Aravindh Mahendran"],"pdf_url":"https://arxiv.org/pdf/2210.13007v2.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2303.03995v1","updated":"2023-03-07T15:51:03Z","published":"2023-03-07T15:51:03Z","title":"Group conditional validity via multi-group learning","summary":"  We consider the problem of distribution-free conformal prediction and the\ncriterion of group conditional validity. This criterion is motivated by many\npractical scenarios including hidden stratification and group fairness.\nExisting methods achieve such guarantees under either restrictive grouping\nstructure or distributional assumptions, or they are overly-conservative under\nheteroskedastic noise. We propose a simple reduction to the problem of\nachieving validity guarantees for individual populations by leveraging\nalgorithms for a problem called multi-group learning. This allows us to port\ntheoretical guarantees from multi-group learning to obtain obtain sample\ncomplexity guarantees for conformal prediction. We also provide a new algorithm\nfor multi-group learning for groups with hierarchical structure. Using this\nalgorithm in our reduction leads to improved sample complexity guarantees with\na simpler predictor structure.\n","authors":["Samuel Deng","Navid Ardeshir","Daniel Hsu"],"pdf_url":"https://arxiv.org/pdf/2303.03995v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2207.00378v2","updated":"2023-03-07T15:47:13Z","published":"2022-07-01T12:29:33Z","title":"Rapid training of quantum recurrent neural networks","summary":"  Time series prediction is essential for human activities in diverse areas. A\ncommon approach to this task is to harness Recurrent Neural Networks (RNNs).\nHowever, while their predictions are quite accurate, their learning process is\ncomplex and, thus, time and energy consuming. Here, we propose to extend the\nconcept of RRNs by including continuous-variable quantum resources in it, and\nto use a quantum-enhanced RNN to overcome these obstacles. The design of the\nContinuous-Variable Quantum RNN (CV-QRNN) is rooted in the continuous-variable\nquantum computing paradigm. By performing extensive numerical simulations, we\ndemonstrate that the quantum network is capable of learning-time dependence of\nseveral types of temporal data, and that it converges to the optimal weights in\nfewer epochs than a classical network. Furthermore, for a small number of\ntrainable parameters, it can achieve lower losses than its classical\ncounterpart. CV-QRNN can be implemented using commercially available\nquantum-photonic hardware.\n","authors":["Michał Siemaszko","Adam Buraczewski","Bertrand Le Saux","Magdalena Stobińska"],"pdf_url":"https://arxiv.org/pdf/2207.00378v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03984v1","updated":"2023-03-07T15:33:12Z","published":"2023-03-07T15:33:12Z","title":"Enhanced Adaptive Gradient Algorithms for Nonconvex-PL Minimax\n  Optimization","summary":"  In the paper, we study a class of nonconvex nonconcave minimax optimization\nproblems (i.e., $\\min_x\\max_y f(x,y)$), where $f(x,y)$ is possible nonconvex in\n$x$, and it is nonconcave and satisfies the Polyak-Lojasiewicz (PL) condition\nin $y$. Moreover, we propose a class of enhanced momentum-based gradient\ndescent ascent methods (i.e., MSGDA and AdaMSGDA) to solve these stochastic\nNonconvex-PL minimax problems. In particular, our AdaMSGDA algorithm can use\nvarious adaptive learning rates in updating the variables $x$ and $y$ without\nrelying on any global and coordinate-wise adaptive learning rates.\nTheoretically, we present an effective convergence analysis framework for our\nmethods. Specifically, we prove that our MSGDA and AdaMSGDA methods have the\nbest known sample (gradient) complexity of $O(\\epsilon^{-3})$ only requiring\none sample at each loop in finding an $\\epsilon$-stationary solution (i.e.,\n$\\mathbb{E}\\|\\nabla F(x)\\|\\leq \\epsilon$, where $F(x)=\\max_y f(x,y)$). This\nmanuscript commemorates the mathematician Boris Polyak (1935-2023).\n","authors":["Feihu Huang"],"pdf_url":"https://arxiv.org/pdf/2303.03984v1.pdf","comment":"30 pages"},{"id":"http://arxiv.org/abs/2303.03982v1","updated":"2023-03-07T15:32:18Z","published":"2023-03-07T15:32:18Z","title":"Structured State Space Models for In-Context Reinforcement Learning","summary":"  Structured state space sequence (S4) models have recently achieved\nstate-of-the-art performance on long-range sequence modeling tasks. These\nmodels also have fast inference speeds and parallelisable training, making them\npotentially useful in many reinforcement learning settings. We propose a\nmodification to a variant of S4 that enables us to initialise and reset the\nhidden state in parallel, allowing us to tackle reinforcement learning tasks.\nWe show that our modified architecture runs asymptotically faster than\nTransformers and performs better than LSTM models on a simple memory-based\ntask. Then, by leveraging the model's ability to handle long-range sequences,\nwe achieve strong performance on a challenging meta-learning task in which the\nagent is given a randomly-sampled continuous control environment, combined with\na randomly-sampled linear projection of the environment's observations and\nactions. Furthermore, we show the resulting model can adapt to\nout-of-distribution held-out tasks. Overall, the results presented in this\npaper suggest that the S4 models are a strong contender for the default\narchitecture used for in-context reinforcement learning\n","authors":["Chris Lu","Yannick Schroecker","Albert Gu","Emilio Parisotto","Jakob Foerster","Satinder Singh","Feryal Behbahani"],"pdf_url":"https://arxiv.org/pdf/2303.03982v1.pdf","comment":null},{"id":"http://arxiv.org/abs/1906.07801v4","updated":"2023-03-07T15:17:24Z","published":"2019-06-18T20:39:27Z","title":"Safe Testing","summary":"  We develop the theory of hypothesis testing based on the e-value, a notion of\nevidence that, unlike the p-value, allows for effortlessly combining results\nfrom several studies in the common scenario where the decision to perform a new\nstudy may depend on previous outcomes. Tests based on e-values are safe, i.e.\nthey preserve Type-I error guarantees, under such optional continuation. We\ndefine growth-rate optimality (GRO) as an analogue of power in an optional\ncontinuation context, and we show how to construct GRO e-variables for general\ntesting problems with composite null and alternative, emphasizing models with\nnuisance parameters. GRO e-values take the form of Bayes factors with special\npriors. We illustrate the theory using several classic examples including a\none-sample safe t-test and the 2 x 2 contingency table. Sharing Fisherian,\nNeymanian and Jeffreys-Bayesian interpretations, e-values may provide a\nmethodology acceptable to adherents of all three schools.\n","authors":["Peter Grünwald","Rianne de Heide","Wouter Koolen"],"pdf_url":"https://arxiv.org/pdf/1906.07801v4.pdf","comment":"Accepted as discussion paper to the Journal of the Royal Statistical\n  Society series B"},{"id":"http://arxiv.org/abs/2302.10768v2","updated":"2023-03-07T15:11:10Z","published":"2023-01-19T11:11:57Z","title":"On the Importance of Sign Labeling: The Hamburg Sign Language Notation\n  System Case Study","summary":"  Labeling is the cornerstone of supervised machine learning, which has been\nexploited in a plethora of various applications, with sign language recognition\nbeing one of them. However, such algorithms must be fed with a huge amount of\nconsistently labeled data during the training process to elaborate a\nwell-generalizing model. In addition, there is a great need for an automated\nsolution that works with any nationally diversified sign language. Although\nthere are language-agnostic transcription systems, such as the Hamburg Sign\nLanguage Notation System (HamNoSys) that describe the signer's initial position\nand body movement instead of the glosses' meanings, there are still issues with\nproviding accurate and reliable labels for every real-world use case. In this\ncontext, the industry relies heavily on manual attribution and labeling of the\navailable video data. In this work, we tackle this issue and thoroughly analyze\nthe HamNoSys labels provided by various maintainers of open sign language\ncorpora in five sign languages, in order to examine the challenges encountered\nin labeling video data. We also investigate the consistency and objectivity of\nHamNoSys-based labels for the purpose of training machine learning models. Our\nfindings provide valuable insights into the limitations of the current labeling\nmethods and pave the way for future research on developing more accurate and\nefficient solutions for sign language recognition.\n","authors":["Maria Ferlin","Sylwia Majchrowska","Marta Plantykow","Alicja Kwaśniwska","Agnieszka Mikołajczyk-Bareła","Milena Olech","Jakub Nalepa"],"pdf_url":"https://arxiv.org/pdf/2302.10768v2.pdf","comment":"20 pages, 13 figures"},{"id":"http://arxiv.org/abs/2303.03965v1","updated":"2023-03-07T15:07:43Z","published":"2023-03-07T15:07:43Z","title":"Comparing 3D deformations between longitudinal daily CBCT acquisitions\n  using CNN for head and neck radiotherapy toxicity prediction","summary":"  Adaptive radiotherapy is a growing field of study in cancer treatment due to\nit's objective in sparing healthy tissue. The standard of care in several\ninstitutions includes longitudinal cone-beam computed tomography (CBCT)\nacquisitions to monitor changes, but have yet to be used to improve tumor\ncontrol while managing side-effects. The aim of this study is to demonstrate\nthe clinical value of pre-treatment CBCT acquired daily during radiation\ntherapy treatment for head and neck cancers for the downstream task of\npredicting severe toxicity occurrence: reactive feeding tube (NG),\nhospitalization and radionecrosis. For this, we propose a deformable 3D\nclassification pipeline that includes a component analyzing the Jacobian matrix\nof the deformation between planning CT and longitudinal CBCT, as well as\nclinical data. The model is based on a multi-branch 3D residual convolutional\nneural network, while the CT to CBCT registration is based on a pair of\nVoxelMorph architectures. Accuracies of 85.8% and 75.3% was found for\nradionecrosis and hospitalization, respectively, with similar performance as\nearly as after the first week of treatment. For NG tube risk, performance\nimproves with increasing the timing of the CBCT fraction, reaching 83.1% after\nthe $5_{th}$ week of treatment.\n","authors":["William Trung Le","Chulmin Bang","Philippine Cordelle","Daniel Markel","Phuc Felix Nguyen-Tan","Houda Bahig","Samuel Kadoury"],"pdf_url":"https://arxiv.org/pdf/2303.03965v1.pdf","comment":"11 pages, 3 figures, 2 equations, 2 tables"},{"id":"http://arxiv.org/abs/2303.03955v1","updated":"2023-03-07T15:01:52Z","published":"2023-03-07T15:01:52Z","title":"Diminishing Return of Value Expansion Methods in Model-Based\n  Reinforcement Learning","summary":"  Model-based reinforcement learning is one approach to increase sample\nefficiency. However, the accuracy of the dynamics model and the resulting\ncompounding error over modelled trajectories are commonly regarded as key\nlimitations. A natural question to ask is: How much more sample efficiency can\nbe gained by improving the learned dynamics models? Our paper empirically\nanswers this question for the class of model-based value expansion methods in\ncontinuous control problems. Value expansion methods should benefit from\nincreased model accuracy by enabling longer rollout horizons and better value\nfunction approximations. Our empirical study, which leverages oracle dynamics\nmodels to avoid compounding model errors, shows that (1) longer horizons\nincrease sample efficiency, but the gain in improvement decreases with each\nadditional expansion step, and (2) the increased model accuracy only marginally\nincreases the sample efficiency compared to learned models with identical\nhorizons. Therefore, longer horizons and increased model accuracy yield\ndiminishing returns in terms of sample efficiency. These improvements in sample\nefficiency are particularly disappointing when compared to model-free value\nexpansion methods. Even though they introduce no computational overhead, we\nfind their performance to be on-par with model-based value expansion methods.\nTherefore, we conclude that the limitation of model-based value expansion\nmethods is not the model accuracy of the learned models. While higher model\naccuracy is beneficial, our experiments show that even a perfect model will not\nprovide an un-rivalled sample efficiency but that the bottleneck lies\nelsewhere.\n","authors":["Daniel Palenicek","Michael Lutter","Joao Carvalho","Jan Peters"],"pdf_url":"https://arxiv.org/pdf/2303.03955v1.pdf","comment":"Published as a conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2302.11864v2","updated":"2023-03-07T15:01:39Z","published":"2023-02-23T09:06:42Z","title":"Grounding Graph Network Simulators using Physical Sensor Observations","summary":"  Physical simulations that accurately model reality are crucial for many\nengineering disciplines such as mechanical engineering and robotic motion\nplanning. In recent years, learned Graph Network Simulators produced accurate\nmesh-based simulations while requiring only a fraction of the computational\ncost of traditional simulators. Yet, the resulting predictors are confined to\nlearning from data generated by existing mesh-based simulators and thus cannot\ninclude real world sensory information such as point cloud data. As these\npredictors have to simulate complex physical systems from only an initial\nstate, they exhibit a high error accumulation for long-term predictions. In\nthis work, we integrate sensory information to ground Graph Network Simulators\non real world observations. In particular, we predict the mesh state of\ndeformable objects by utilizing point cloud data. The resulting model allows\nfor accurate predictions over longer time horizons, even under uncertainties in\nthe simulation, such as unknown material properties. Since point clouds are\nusually not available for every time step, especially in online settings, we\nemploy an imputation-based model. The model can make use of such additional\ninformation only when provided, and resorts to a standard Graph Network\nSimulator, otherwise. We experimentally validate our approach on a suite of\nprediction tasks for mesh-based interactions between soft and rigid bodies. Our\nmethod results in utilization of additional point cloud information to\naccurately predict stable simulations where existing Graph Network Simulators\nfail.\n","authors":["Jonas Linkerhägner","Niklas Freymuth","Paul Maria Scheikl","Franziska Mathis-Ullrich","Gerhard Neumann"],"pdf_url":"https://arxiv.org/pdf/2302.11864v2.pdf","comment":"Accepted as a poster at the 11th International Conference on Learning\n  Representations (ICLR), 2023"},{"id":"http://arxiv.org/abs/2303.03953v1","updated":"2023-03-07T14:59:33Z","published":"2023-03-07T14:59:33Z","title":"ChatGPT: Beginning of an End of Manual Annotation? Use Case of Automatic\n  Genre Identification","summary":"  ChatGPT has shown strong capabilities in natural language generation tasks,\nwhich naturally leads researchers to explore where its abilities end. In this\npaper, we examine whether ChatGPT can be used for zero-shot text\nclassification, more specifically, automatic genre identification. We compare\nChatGPT with a multilingual XLM-RoBERTa language model that was fine-tuned on\ndatasets, manually annotated with genres. The models are compared on test sets\nin two languages: English and Slovenian. Results show that ChatGPT outperforms\nthe fine-tuned model when applied to the dataset which was not seen before by\neither of the models. Even when applied on Slovenian language as an\nunder-resourced language, ChatGPT's performance is no worse than when applied\nto English. However, if the model is fully prompted in Slovenian, the\nperformance drops significantly, showing the current limitations of ChatGPT\nusage on smaller languages. The presented results lead us to questioning\nwhether this is the beginning of an end of laborious manual annotation\ncampaigns even for smaller languages, such as Slovenian.\n","authors":["Taja Kuzman","Nikola Ljubešić","Igor Mozetič"],"pdf_url":"https://arxiv.org/pdf/2303.03953v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03951v1","updated":"2023-03-07T14:58:18Z","published":"2023-03-07T14:58:18Z","title":"Probing Graph Representations","summary":"  Today we have a good theoretical understanding of the representational power\nof Graph Neural Networks (GNNs). For example, their limitations have been\ncharacterized in relation to a hierarchy of Weisfeiler-Lehman (WL) isomorphism\ntests. However, we do not know what is encoded in the learned representations.\nThis is our main question. We answer it using a probing framework to quantify\nthe amount of meaningful information captured in graph representations. Our\nfindings on molecular datasets show the potential of probing for understanding\nthe inductive biases of graph-based models. We compare different families of\nmodels and show that transformer-based models capture more chemically relevant\ninformation compared to models based on message passing. We also study the\neffect of different design choices such as skip connections and virtual nodes.\nWe advocate for probing as a useful diagnostic tool for evaluating graph-based\nmodels.\n","authors":["Mohammad Sadegh Akhondzadeh","Vijay Lingam","Aleksandar Bojchevski"],"pdf_url":"https://arxiv.org/pdf/2303.03951v1.pdf","comment":"20 pages, 12 figures, AISTATS 2023"},{"id":"http://arxiv.org/abs/2303.03944v1","updated":"2023-03-07T14:55:05Z","published":"2023-03-07T14:55:05Z","title":"On Momentum-Based Gradient Methods for Bilevel Optimization with\n  Nonconvex Lower-Level","summary":"  Bilevel optimization is a popular two-level hierarchical optimization, which\nhas been widely applied to many machine learning tasks such as hyperparameter\nlearning, meta learning and continual learning. Although many bilevel\noptimization methods recently have been developed, the bilevel methods are not\nwell studied when the lower-level problem is nonconvex. To fill this gap, in\nthe paper, we study a class of nonconvex bilevel optimization problems, which\nboth upper-level and lower-level problems are nonconvex, and the lower-level\nproblem satisfies Polyak-Lojasiewicz (PL) condition. We propose an efficient\nmomentum-based gradient bilevel method (MGBiO) to solve these deterministic\nproblems. Meanwhile, we propose a class of efficient momentum-based stochastic\ngradient bilevel methods (MSGBiO and VR-MSGBiO) to solve these stochastic\nproblems. Moreover, we provide a useful convergence analysis framework for our\nmethods. Specifically, under some mild conditions, we prove that our MGBiO\nmethod has a sample (or gradient) complexity of $O(\\epsilon^{-2})$ for finding\nan $\\epsilon$-stationary solution of the deterministic bilevel problems (i.e.,\n$\\|\\nabla F(x)\\|\\leq \\epsilon$), which improves the existing best results by a\nfactor of $O(\\epsilon^{-1})$. Meanwhile, we prove that our MSGBiO and VR-MSGBiO\nmethods have sample complexities of $\\tilde{O}(\\epsilon^{-4})$ and\n$\\tilde{O}(\\epsilon^{-3})$, respectively, in finding an $\\epsilon$-stationary\nsolution of the stochastic bilevel problems (i.e., $\\mathbb{E}\\|\\nabla\nF(x)\\|\\leq \\epsilon$), which improves the existing best results by a factor of\n$O(\\epsilon^{-3})$. This manuscript commemorates the mathematician Boris Polyak\n(1935 -2023).\n","authors":["Feihu Huang"],"pdf_url":"https://arxiv.org/pdf/2303.03944v1.pdf","comment":"37 pages"},{"id":"http://arxiv.org/abs/2303.03941v1","updated":"2023-03-07T14:51:09Z","published":"2023-03-07T14:51:09Z","title":"Fast Latent Factor Analysis via a Fuzzy PID-Incorporated Stochastic\n  Gradient Descent Algorithm","summary":"  A high-dimensional and incomplete (HDI) matrix can describe the complex\ninteractions among numerous nodes in various big data-related applications. A\nstochastic gradient descent (SGD)-based latent factor analysis (LFA) model is\nremarkably effective in extracting valuable information from an HDI matrix.\nHowever, such a model commonly encounters the problem of slow convergence\nbecause a standard SGD algorithm learns a latent factor relying on the\nstochastic gradient of current instance error only without considering past\nupdate information. To address this critical issue, this paper innovatively\nproposes a Fuzzy PID-incorporated SGD (FPS) algorithm with two-fold ideas: 1)\nrebuilding the instance learning error by considering the past update\ninformation in an efficient way following the principle of PID, and 2)\nimplementing hyper-parameters and gain parameters adaptation following the\nfuzzy rules. With it, an FPS-incorporated LFA model is further achieved for\nfast processing an HDI matrix. Empirical studies on six HDI datasets\ndemonstrate that the proposed FPS-incorporated LFA model significantly\noutperforms the state-of-the-art LFA models in terms of computational\nefficiency for predicting the missing data of an HDI matrix with competitive\naccuracy.\n","authors":["Li Jinli","Yuan Ye"],"pdf_url":"https://arxiv.org/pdf/2303.03941v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2303.03932v1","updated":"2023-03-07T14:38:28Z","published":"2023-03-07T14:38:28Z","title":"FFT-based Dynamic Token Mixer for Vision","summary":"  Multi-head-self-attention (MHSA)-equipped models have achieved notable\nperformance in computer vision. Their computational complexity is proportional\nto quadratic numbers of pixels in input feature maps, resulting in slow\nprocessing, especially when dealing with high-resolution images. New types of\ntoken-mixer are proposed as an alternative to MHSA to circumvent this problem:\nan FFT-based token-mixer, similar to MHSA in global operation but with lower\ncomputational complexity. However, despite its attractive properties, the\nFFT-based token-mixer has not been carefully examined in terms of its\ncompatibility with the rapidly evolving MetaFormer architecture. Here, we\npropose a novel token-mixer called dynamic filter and DFFormer and CDFFormer,\nimage recognition models using dynamic filters to close the gaps above.\nCDFFormer achieved a Top-1 accuracy of 85.0%, close to the hybrid architecture\nwith convolution and MHSA. Other wide-ranging experiments and analysis,\nincluding object detection and semantic segmentation, demonstrate that they are\ncompetitive with state-of-the-art architectures; Their throughput and memory\nefficiency when dealing with high-resolution image recognition is convolution\nand MHSA, not much different from ConvFormer, and far superior to CAFormer. Our\nresults indicate that the dynamic filter is one of the token-mixer options that\nshould be seriously considered. The code is available at\nhttps://github.com/okojoalg/dfformer\n","authors":["Yuki Tatsunami","Masato Taki"],"pdf_url":"https://arxiv.org/pdf/2303.03932v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00305v2","updated":"2023-03-07T14:35:33Z","published":"2022-10-01T16:01:53Z","title":"LambdaKG: A Library for Pre-trained Language Model-Based Knowledge Graph\n  Embeddings","summary":"  Knowledge Graphs (KGs) often have two characteristics: heterogeneous graph\nstructure and text-rich entity/relation information. Text-based KG embeddings\ncan represent entities by encoding descriptions with pre-trained language\nmodels, but no open-sourced library is specifically designed for KGs with PLMs\nat present. In this paper, we present LambdaKG, a library for KGE that equips\nwith many pre-trained language models (e.g., BERT, BART, T5, GPT-3), and\nsupports various tasks (e.g., knowledge graph completion, question answering,\nrecommendation, and knowledge probing). LambdaKG is publicly open-sourced at\nhttps://github.com/zjunlp/PromptKG/tree/main/lambdaKG, with a demo video at\nhttp://deepke.zjukg.cn/lambdakg.mp4 and long-term maintenance.\n","authors":["Xin Xie","Zhoubo Li","Xiaohan Wang","Yuqi Zhu","Ningyu Zhang","Jintian Zhang","Siyuan Cheng","Bozhong Tian","Shumin Deng","Feiyu Xiong","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2210.00305v2.pdf","comment":"Work in progress and the project website is\n  https://zjunlp.github.io/project/promptkg/"},{"id":"http://arxiv.org/abs/2303.03912v1","updated":"2023-03-07T14:14:12Z","published":"2023-03-07T14:14:12Z","title":"Document-level Relation Extraction with Cross-sentence Reasoning Graph","summary":"  Relation extraction (RE) has recently moved from the sentence-level to\ndocument-level, which requires aggregating document information and using\nentities and mentions for reasoning. Existing works put entity nodes and\nmention nodes with similar representations in a document-level graph, whose\ncomplex edges may incur redundant information. Furthermore, existing studies\nonly focus on entity-level reasoning paths without considering global\ninteractions among entities cross-sentence. To these ends, we propose a novel\ndocument-level RE model with a GRaph information Aggregation and Cross-sentence\nReasoning network (GRACR). Specifically, a simplified document-level graph is\nconstructed to model the semantic information of all mentions and sentences in\na document, and an entity-level graph is designed to explore relations of\nlong-distance cross-sentence entity pairs. Experimental results show that GRACR\nachieves excellent performance on two public datasets of document-level RE. It\nis especially effective in extracting potential relations of cross-sentence\nentity pairs. Our code is available at https://github.com/UESTC-LHF/GRACR.\n","authors":["Hongfei Liu","Zhao Kang","Lizong Zhang","Ling Tian","Fujun Hua"],"pdf_url":"https://arxiv.org/pdf/2303.03912v1.pdf","comment":"This paper is accepted by PAKDD 2023"},{"id":"http://arxiv.org/abs/2303.03908v1","updated":"2023-03-07T14:11:01Z","published":"2023-03-07T14:11:01Z","title":"Client-specific Property Inference against Secure Aggregation in\n  Federated Learning","summary":"  Federated learning has become a widely used paradigm for collaboratively\ntraining a common model among different participants with the help of a central\nserver that coordinates the training. Although only the model parameters or\nother model updates are exchanged during the federated training instead of the\nparticipant's data, many attacks have shown that it is still possible to infer\nsensitive information such as membership, property, or outright reconstruction\nof participant data. Although differential privacy is considered an effective\nsolution to protect against privacy attacks, it is also criticized for its\nnegative effect on utility. Another possible defense is to use secure\naggregation which allows the server to only access the aggregated update\ninstead of each individual one, and it is often more appealing because it does\nnot degrade model quality. However, combining only the aggregated updates,\nwhich are generated by a different composition of clients in every round, may\nstill allow the inference of some client-specific information.\n  In this paper, we show that simple linear models can effectively capture\nclient-specific properties only from the aggregated model updates due to the\nlinearity of aggregation. We formulate an optimization problem across different\nrounds in order to infer a tested property of every client from the output of\nthe linear models, for example, whether they have a specific sample in their\ntraining data (membership inference) or whether they misbehave and attempt to\ndegrade the performance of the common model by poisoning attacks. Our\nreconstruction technique is completely passive and undetectable. We demonstrate\nthe efficacy of our approach on several scenarios which shows that secure\naggregation provides very limited privacy guarantees in practice. The source\ncode will be released upon publication.\n","authors":["Raouf Kerkouche","Gergely Ács","Mario Fritz"],"pdf_url":"https://arxiv.org/pdf/2303.03908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03907v1","updated":"2023-03-07T14:09:08Z","published":"2023-03-07T14:09:08Z","title":"GaussianMLR: Learning Implicit Class Significance via Calibrated\n  Multi-Label Ranking","summary":"  Existing multi-label frameworks only exploit the information deduced from the\nbipartition of the labels into a positive and negative set. Therefore, they do\nnot benefit from the ranking order between positive labels, which is the\nconcept we introduce in this paper. We propose a novel multi-label ranking\nmethod: GaussianMLR, which aims to learn implicit class significance values\nthat determine the positive label ranks instead of treating them as of equal\nimportance, by following an approach that unifies ranking and classification\ntasks associated with multi-label ranking. Due to the scarcity of public\ndatasets, we introduce eight synthetic datasets generated under varying\nimportance factors to provide an enriched and controllable experimental\nenvironment for this study. On both real-world and synthetic datasets, we carry\nout extensive comparisons with relevant baselines and evaluate the performance\non both of the two sub-tasks. We show that our method is able to accurately\nlearn a representation of the incorporated positive rank order, which is not\nonly consistent with the ground truth but also proportional to the underlying\ninformation. We strengthen our claims empirically by conducting comprehensive\nexperimental studies. Code is available at\nhttps://github.com/MrGranddy/GaussianMLR.\n","authors":["V. Bugra Yesilkaynak","Emine Dari","Alican Mertan","Gozde Unal"],"pdf_url":"https://arxiv.org/pdf/2303.03907v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.14085v2","updated":"2023-03-07T13:56:51Z","published":"2022-11-25T13:14:33Z","title":"Positive unlabeled learning with tensor networks","summary":"  Positive unlabeled learning is a binary classification problem with positive\nand unlabeled data. It is common in domains where negative labels are costly or\nimpossible to obtain, e.g., medicine and personalized advertising. We apply the\nlocally purified state tensor network to the positive unlabeled learning\nproblem and test our model on the MNIST image and 15 categorical/mixed\ndatasets. On the MNIST dataset, we obtain close to the state-of-the-art results\neven with very few labeled positive samples. We significantly improve the\nstate-of-the-art on categorical datasets. Further, we show that the agreement\nfraction between outputs of different models on unlabeled samples is a good\nindicator of the model's performance. Finally, our method can generate new\npositive and negative instances, which we demonstrate on simple synthetic\ndatasets.\n","authors":["Bojan Žunkovič"],"pdf_url":"https://arxiv.org/pdf/2211.14085v2.pdf","comment":"12 pages, 5 figures, 4 tables"},{"id":"http://arxiv.org/abs/2303.03894v1","updated":"2023-03-07T13:38:04Z","published":"2023-03-07T13:38:04Z","title":"Manually Selecting The Data Function for Supervised Learning of small\n  datasets","summary":"  Supervised learning problems may become ill-posed when there is a lack of\ninformation, resulting in unstable and non-unique solutions. However, instead\nof solely relying on regularization, initializing an informative ill-posed\noperator is akin to posing better questions to achieve more accurate answers.\nThe Fredholm integral equation of the first kind (FIFK) is a reliable ill-posed\noperator that can integrate distributions and prior knowledge as input\ninformation. By incorporating input distributions and prior knowledge, the FIFK\noperator can address the limitations of using high-dimensional input\ndistributions by semi-supervised assumptions, leading to more precise\napproximations of the integral operator. Additionally, the FIFK's incorporation\nof probabilistic principles can further enhance the accuracy and effectiveness\nof solutions. In cases of noisy operator equations and limited data, the FIFK's\nflexibility in defining problems using prior information or cross-validation\nwith various kernel designs is especially advantageous. This capability allows\nfor detailed problem definitions and facilitates achieving high levels of\naccuracy and stability in solutions. In our study, we examined the FIFK through\ntwo different approaches. Firstly, we implemented a semi-supervised assumption\nby using the same Fredholm operator kernel and data function kernel and\nincorporating unlabeled information. Secondly, we used the MSDF method, which\ninvolves selecting different kernels on both sides of the equation to define\nwhen the mapping kernel is different from the data function kernel. To assess\nthe effectiveness of the FIFK and the proposed methods in solving ill-posed\nproblems, we conducted experiments on a real-world dataset. Our goal was to\ncompare the performance of these methods against the widely used least-squares\nmethod and other comparable methods.\n","authors":["Amir Khanjari","Saeid Pourmand","Mohammad Reza Faridrohani"],"pdf_url":"https://arxiv.org/pdf/2303.03894v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03876v1","updated":"2023-03-07T13:23:31Z","published":"2023-03-07T13:23:31Z","title":"Organelle-specific segmentation, spatial analysis, and visualization of\n  volume electron microscopy datasets","summary":"  Volume electron microscopy is the method of choice for the in-situ\ninterrogation of cellular ultrastructure at the nanometer scale. Recent\ntechnical advances have led to a rapid increase in large raw image datasets\nthat require computational strategies for segmentation and spatial analysis. In\nthis protocol, we describe a practical and annotation-efficient pipeline for\norganelle-specific segmentation, spatial analysis, and visualization of large\nvolume electron microscopy datasets using freely available, user-friendly\nsoftware tools that can be run on a single standard workstation. We\nspecifically target researchers in the life sciences with limited computational\nexpertise, who face the following tasks within their volume electron microscopy\nprojects: i) How to generate 3D segmentation labels for different types of cell\norganelles while minimizing manual annotation efforts, ii) how to analyze the\nspatial interactions between organelle instances, and iii) how to best\nvisualize the 3D segmentation results. To meet these demands we give detailed\nguidelines for choosing the most efficient segmentation tools for the specific\ncell organelle. We furthermore provide easily executable components for spatial\nanalysis and 3D rendering and bridge compatibility issues between freely\navailable open-source tools, such that others can replicate our full pipeline\nstarting from a raw dataset up to the final plots and rendered images. We\nbelieve that our detailed description can serve as a valuable reference for\nsimilar projects requiring special strategies for single- or multiple organelle\nanalysis which can be achieved with computational resources commonly available\nto single-user setups.\n","authors":["Andreas Müller","Deborah Schmidt","Lucas Rieckert","Michele Solimena","Martin Weigert"],"pdf_url":"https://arxiv.org/pdf/2303.03876v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.06983v4","updated":"2023-03-07T13:19:13Z","published":"2022-10-10T12:37:59Z","title":"Denoising Masked AutoEncoders Help Robust Classification","summary":"  In this paper, we propose a new self-supervised method, which is called\nDenoising Masked AutoEncoders (DMAE), for learning certified robust classifiers\nof images. In DMAE, we corrupt each image by adding Gaussian noises to each\npixel value and randomly masking several patches. A Transformer-based\nencoder-decoder model is then trained to reconstruct the original image from\nthe corrupted one. In this learning paradigm, the encoder will learn to capture\nrelevant semantics for the downstream tasks, which is also robust to Gaussian\nadditive noises. We show that the pre-trained encoder can naturally be used as\nthe base classifier in Gaussian smoothed models, where we can analytically\ncompute the certified radius for any data point. Although the proposed method\nis simple, it yields significant performance improvement in downstream\nclassification tasks. We show that the DMAE ViT-Base model, which just uses\n1/10 parameters of the model developed in recent work arXiv:2206.10550,\nachieves competitive or better certified accuracy in various settings. The DMAE\nViT-Large model significantly surpasses all previous results, establishing a\nnew state-of-the-art on ImageNet dataset. We further demonstrate that the\npre-trained model has good transferability to the CIFAR-10 dataset, suggesting\nits wide adaptability. Models and code are available at\nhttps://github.com/quanlin-wu/dmae.\n","authors":["Quanlin Wu","Hang Ye","Yuntian Gu","Huishuai Zhang","Liwei Wang","Di He"],"pdf_url":"https://arxiv.org/pdf/2210.06983v4.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2201.02478v2","updated":"2023-03-07T13:11:04Z","published":"2022-01-07T14:56:33Z","title":"Bayesian Neural Networks for Reversible Steganography","summary":"  Recent advances in deep learning have led to a paradigm shift in the field of\nreversible steganography. A fundamental pillar of reversible steganography is\npredictive modelling which can be realised via deep neural networks. However,\nnon-trivial errors exist in inferences about some out-of-distribution and noisy\ndata. In view of this issue, we propose to consider uncertainty in predictive\nmodels based upon a theoretical framework of Bayesian deep learning, thereby\ncreating an adaptive steganographic system. Most modern deep-learning models\nare regarded as deterministic because they only offer predictions while failing\nto provide uncertainty measurement. Bayesian neural networks bring a\nprobabilistic perspective to deep learning and can be regarded as self-aware\nintelligent machinery; that is, a machine that knows its own limitations. To\nquantify uncertainty, we apply Bayesian statistics to model the predictive\ndistribution and approximate it through Monte Carlo sampling with stochastic\nforward passes. We further show that predictive uncertainty can be disentangled\ninto aleatoric and epistemic uncertainties and these quantities can be learnt\nunsupervised. Experimental results demonstrate an improvement delivered by\nBayesian uncertainty analysis upon steganographic rate-distortion performance.\n","authors":["Ching-Chun Chang"],"pdf_url":"https://arxiv.org/pdf/2201.02478v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.10669v2","updated":"2023-03-07T13:06:51Z","published":"2023-02-21T13:39:40Z","title":"UAV Path Planning Employing MPC- Reinforcement Learning Method\n  Considering Collision Avoidance","summary":"  In this paper, we tackle the problem of Unmanned Aerial (UA V) path planning\nin complex and uncertain environments by designing a Model Predictive Control\n(MPC), based on a Long-Short-Term Memory (LSTM) network integrated into the\nDeep Deterministic Policy Gradient algorithm. In the proposed solution,\nLSTM-MPC operates as a deterministic policy within the DDPG network, and it\nleverages a predicting pool to store predicted future states and actions for\nimproved robustness and efficiency. The use of the predicting pool also enables\nthe initialization of the critic network, leading to improved convergence speed\nand reduced failure rate compared to traditional reinforcement learning and\ndeep reinforcement learning methods. The effectiveness of the proposed solution\nis evaluated by numerical simulations.\n","authors":["Mahya Ramezani","Hamed Habibi","Jose luis Sanchez Lopez","Holger Voos"],"pdf_url":"https://arxiv.org/pdf/2302.10669v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.01893v3","updated":"2023-03-07T12:28:59Z","published":"2022-08-03T07:44:48Z","title":"Flow Annealed Importance Sampling Bootstrap","summary":"  Normalizing flows are tractable density models that can approximate\ncomplicated target distributions, e.g. Boltzmann distributions of physical\nsystems. However, current methods for training flows either suffer from\nmode-seeking behavior, use samples from the target generated beforehand by\nexpensive MCMC methods, or use stochastic losses that have high variance. To\navoid these problems, we augment flows with annealed importance sampling (AIS)\nand minimize the mass-covering $\\alpha$-divergence with $\\alpha=2$, which\nminimizes importance weight variance. Our method, Flow AIS Bootstrap (FAB),\nuses AIS to generate samples in regions where the flow is a poor approximation\nof the target, facilitating the discovery of new modes. We apply FAB to\nmultimodal targets and show that we can approximate them very accurately where\nprevious methods fail. To the best of our knowledge, we are the first to learn\nthe Boltzmann distribution of the alanine dipeptide molecule using only the\nunnormalized target density, without access to samples generated via Molecular\nDynamics (MD) simulations: FAB produces better results than training via\nmaximum likelihood on MD samples while using 100 times fewer target\nevaluations. After reweighting the samples, we obtain unbiased histograms of\ndihedral angles that are almost identical to the ground truth.\n","authors":["Laurence Illing Midgley","Vincent Stimper","Gregor N. C. Simm","Bernhard Schölkopf","José Miguel Hernández-Lobato"],"pdf_url":"https://arxiv.org/pdf/2208.01893v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2105.03875v2","updated":"2023-03-07T12:14:55Z","published":"2021-05-09T08:49:14Z","title":"Bounding Information Leakage in Machine Learning","summary":"  Recently, it has been shown that Machine Learning models can leak sensitive\ninformation about their training data. This information leakage is exposed\nthrough membership and attribute inference attacks. Although many attack\nstrategies have been proposed, little effort has been made to formalize these\nproblems. We present a novel formalism, generalizing membership and attribute\ninference attack setups previously studied in the literature and connecting\nthem to memorization and generalization. First, we derive a universal bound on\nthe success rate of inference attacks and connect it to the generalization gap\nof the target model. Second, we study the question of how much sensitive\ninformation is stored by the algorithm about its training set and we derive\nbounds on the mutual information between the sensitive attributes and model\nparameters. Experimentally, we illustrate the potential of our approach by\napplying it to both synthetic data and classification tasks on natural images.\nFinally, we apply our formalism to different attribute inference strategies,\nwith which an adversary is able to recover the identity of writers in the\nPenDigits dataset.\n","authors":["Ganesh Del Grosso","Georg Pichler","Catuscia Palamidessi","Pablo Piantanida"],"pdf_url":"https://arxiv.org/pdf/2105.03875v2.pdf","comment":"Published in [Elsevier\n  Neurocomputing](https://doi.org/10.1016/j.neucom.2023.02.058)"},{"id":"http://arxiv.org/abs/2202.09657v4","updated":"2023-03-07T11:59:50Z","published":"2022-02-19T18:40:55Z","title":"Survey of Machine Learning Based Intrusion Detection Methods for\n  Internet of Medical Things","summary":"  The Internet of Medical Things (IoMT) has revolutionized the healthcare\nindustry by enabling physiological data collection using sensors, which are\ntransmitted to remote servers for continuous analysis by physicians and\nhealthcare professionals. This technology offers numerous benefits, including\nearly disease detection and automatic medication for patients with chronic\nillnesses. However, IoMT technology also presents significant security risks,\nsuch as violating patient privacy or exposing sensitive data to interception\nattacks due to wireless communication, which could be fatal for the patient.\nAdditionally, traditional security measures, such as cryptography, are\nchallenging to implement in medical equipment due to the heterogeneous\ncommunication and their limited computation, storage, and energy capacity.\nThese protection methods are also ineffective against new and zero-day attacks.\nIt is essential to adopt robust security measures to ensure data integrity,\nconfidentiality, and availability during data collection, transmission,\nstorage, and processing. In this context, using Intrusion Detection Systems\n(IDS) based on Machine Learning (ML) can bring a complementary security\nsolution adapted to the unique characteristics of IoMT systems. Therefore, this\npaper investigates how IDS based on ML can address security and privacy issues\nin IoMT systems. First, the generic three-layer architecture of IoMT is\nprovided, and the security requirements of IoMT systems are outlined. Then, the\nvarious threats that can affect IoMT security are identified, and the\nadvantages, disadvantages, methods, and datasets used in each solution based on\nML at the three layers that make up IoMT are presented. Finally, the paper\ndiscusses the challenges and limitations of applying IDS based on ML at each\nlayer of IoMT, which can serve as a future research direction.\n","authors":["Ayoub Si-Ahmed","Mohammed Ali Al-Garadi","Narhimene Boustia"],"pdf_url":"https://arxiv.org/pdf/2202.09657v4.pdf","comment":"40 pages, 3 figures, and 6 tables"},{"id":"http://arxiv.org/abs/2303.03829v1","updated":"2023-03-07T11:53:37Z","published":"2023-03-07T11:53:37Z","title":"Can Decentralized Learning be more robust than Federated Learning?","summary":"  Decentralized Learning (DL) is a peer--to--peer learning approach that allows\na group of users to jointly train a machine learning model. To ensure\ncorrectness, DL should be robust, i.e., Byzantine users must not be able to\ntamper with the result of the collaboration. In this paper, we introduce two\n\\textit{new} attacks against DL where a Byzantine user can: make the network\nconverge to an arbitrary model of their choice, and exclude an arbitrary user\nfrom the learning process. We demonstrate our attacks' efficiency against\nSelf--Centered Clipping, the state--of--the--art robust DL protocol. Finally,\nwe show that the capabilities decentralization grants to Byzantine users result\nin decentralized learning \\emph{always} providing less robustness than\nfederated learning.\n","authors":["Mathilde Raynal","Dario Pasquini","Carmela Troncoso"],"pdf_url":"https://arxiv.org/pdf/2303.03829v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.01141v2","updated":"2023-03-07T11:39:26Z","published":"2022-12-02T12:42:53Z","title":"MHCCL: Masked Hierarchical Cluster-wise Contrastive Learning for\n  Multivariate Time Series","summary":"  Learning semantic-rich representations from raw unlabeled time series data is\ncritical for downstream tasks such as classification and forecasting.\nContrastive learning has recently shown its promising representation learning\ncapability in the absence of expert annotations. However, existing contrastive\napproaches generally treat each instance independently, which leads to false\nnegative pairs that share the same semantics. To tackle this problem, we\npropose MHCCL, a Masked Hierarchical Cluster-wise Contrastive Learning model,\nwhich exploits semantic information obtained from the hierarchical structure\nconsisting of multiple latent partitions for multivariate time series.\nMotivated by the observation that fine-grained clustering preserves higher\npurity while coarse-grained one reflects higher-level semantics, we propose a\nnovel downward masking strategy to filter out fake negatives and supplement\npositives by incorporating the multi-granularity information from the\nclustering hierarchy. In addition, a novel upward masking strategy is designed\nin MHCCL to remove outliers of clusters at each partition to refine prototypes,\nwhich helps speed up the hierarchical clustering process and improves the\nclustering quality. We conduct experimental evaluations on seven widely-used\nmultivariate time series datasets. The results demonstrate the superiority of\nMHCCL over the state-of-the-art approaches for unsupervised time series\nrepresentation learning.\n","authors":["Qianwen Meng","Hangwei Qian","Yong Liu","Lizhen Cui","Yonghui Xu","Zhiqi Shen"],"pdf_url":"https://arxiv.org/pdf/2212.01141v2.pdf","comment":"accepted by AAAI 2023"},{"id":"http://arxiv.org/abs/2303.03811v1","updated":"2023-03-07T11:26:09Z","published":"2023-03-07T11:26:09Z","title":"ENTROPY: Environment Transformer and Offline Policy Optimization","summary":"  Model-based methods provide an effective approach to offline reinforcement\nlearning (RL). They learn an environmental dynamics model from interaction\nexperiences and then perform policy optimization based on the learned model.\nHowever, previous model-based offline RL methods lack long-term prediction\ncapability, resulting in large errors when generating multi-step trajectories.\nWe address this issue by developing a sequence modeling architecture,\nEnvironment Transformer, which can generate reliable long-horizon trajectories\nbased on offline datasets. We then propose a novel model-based offline RL\nalgorithm, ENTROPY, that learns the dynamics model and reward function by\nENvironment TRansformer and performs Offline PolicY optimization. We evaluate\nthe proposed method on MuJoCo continuous control RL environments. Results show\nthat ENTROPY performs comparably or better than the state-of-the-art\nmodel-based and model-free offline RL methods and demonstrates more powerful\nlong-term trajectory prediction capability compared to existing model-based\noffline methods.\n","authors":["Pengqin Wang","Meixin Zhu","Shaojie Shen"],"pdf_url":"https://arxiv.org/pdf/2303.03811v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.04388v2","updated":"2023-03-07T11:09:29Z","published":"2023-01-11T10:20:56Z","title":"Perceive and predict: self-supervised speech representation based loss\n  functions for speech enhancement","summary":"  Recent work in the domain of speech enhancement has explored the use of\nself-supervised speech representations to aid in the training of neural speech\nenhancement models. However, much of this work focuses on using the deepest or\nfinal outputs of self supervised speech representation models, rather than the\nearlier feature encodings. The use of self supervised representations in such a\nway is often not fully motivated. In this work it is shown that the distance\nbetween the feature encodings of clean and noisy speech correlate strongly with\npsychoacoustically motivated measures of speech quality and intelligibility, as\nwell as with human Mean Opinion Score (MOS) ratings. Experiments using this\ndistance as a loss function are performed and improved performance over the use\nof STFT spectrogram distance based loss as well as other common loss functions\nfrom speech enhancement literature is demonstrated using objective measures\nsuch as perceptual evaluation of speech quality (PESQ) and short-time objective\nintelligibility (STOI).\n","authors":["George Close","William Ravenscroft","Thomas Hain","Stefan Goetze"],"pdf_url":"https://arxiv.org/pdf/2301.04388v2.pdf","comment":"4 pages, accepted at ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.03789v1","updated":"2023-03-07T10:52:59Z","published":"2023-03-07T10:52:59Z","title":"Fast and Multi-aspect Mining of Complex Time-stamped Event Streams","summary":"  Given a huge, online stream of time-evolving events with multiple attributes,\nsuch as online shopping logs: (item, price, brand, time), and local mobility\nactivities: (pick-up and drop-off locations, time), how can we summarize large,\ndynamic high-order tensor streams? How can we see any hidden patterns, rules,\nand anomalies? Our answer is to focus on two types of patterns, i.e.,\n''regimes'' and ''components'', for which we present CubeScope, an efficient\nand effective method over high-order tensor streams. Specifically, it\nidentifies any sudden discontinuity and recognizes distinct dynamical patterns,\n''regimes'' (e.g., weekday/weekend/holiday patterns). In each regime, it also\nperforms multi-way summarization for all attributes (e.g., item, price, brand,\nand time) and discovers hidden ''components'' representing latent groups (e.g.,\nitem/brand groups) and their relationship. Thanks to its concise but effective\nsummarization, CubeScope can also detect the sudden appearance of anomalies and\nidentify the types of anomalies that occur in practice. Our proposed method has\nthe following properties: (a) Effective: it captures dynamical multi-aspect\npatterns, i.e., regimes and components, and statistically summarizes all the\nevents; (b) General: it is practical for successful application to data\ncompression, pattern discovery, and anomaly detection on various types of\ntensor streams; (c) Scalable: our algorithm does not depend on the length of\nthe data stream and its dimensionality. Extensive experiments on real datasets\ndemonstrate that CubeScope finds meaningful patterns and anomalies correctly,\nand consistently outperforms the state-of-the-art methods as regards accuracy\nand execution speed.\n","authors":["Kota Nakamura","Yasuko Matsubara","Koki Kawabata","Yuhei Umeda","Yuichiro Wada","Yasushi Sakurai"],"pdf_url":"https://arxiv.org/pdf/2303.03789v1.pdf","comment":"Accepted by WWW 2023"},{"id":"http://arxiv.org/abs/2303.03787v1","updated":"2023-03-07T10:48:20Z","published":"2023-03-07T10:48:20Z","title":"Sample-efficient Real-time Planning with Curiosity Cross-Entropy Method\n  and Contrastive Learning","summary":"  Model-based reinforcement learning (MBRL) with real-time planning has shown\ngreat potential in locomotion and manipulation control tasks. However, the\nexisting planning methods, such as the Cross-Entropy Method (CEM), do not scale\nwell to complex high-dimensional environments. One of the key reasons for\nunderperformance is the lack of exploration, as these planning methods only aim\nto maximize the cumulative extrinsic reward over the planning horizon.\nFurthermore, planning inside the compact latent space in the absence of\nobservations makes it challenging to use curiosity-based intrinsic motivation.\nWe propose Curiosity CEM (CCEM), an improved version of the CEM algorithm for\nencouraging exploration via curiosity. Our proposed method maximizes the sum of\nstate-action Q values over the planning horizon, in which these Q values\nestimate the future extrinsic and intrinsic reward, hence encouraging reaching\nnovel observations. In addition, our model uses contrastive representation\nlearning to efficiently learn latent representations. Experiments on\nimage-based continuous control tasks from the DeepMind Control suite show that\nCCEM is by a large margin more sample-efficient than previous MBRL algorithms\nand compares favorably with the best model-free RL methods.\n","authors":["Mostafa Kotb","Cornelius Weber","Stefan Wermter"],"pdf_url":"https://arxiv.org/pdf/2303.03787v1.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2302.12526v2","updated":"2023-03-07T10:31:42Z","published":"2023-02-24T09:18:27Z","title":"Model-Based Uncertainty in Value Functions","summary":"  We consider the problem of quantifying uncertainty over expected cumulative\nrewards in model-based reinforcement learning. In particular, we focus on\ncharacterizing the variance over values induced by a distribution over MDPs.\nPrevious work upper bounds the posterior variance over values by solving a\nso-called uncertainty Bellman equation, but the over-approximation may result\nin inefficient exploration. We propose a new uncertainty Bellman equation whose\nsolution converges to the true posterior variance over values and explicitly\ncharacterizes the gap in previous work. Moreover, our uncertainty\nquantification technique is easily integrated into common exploration\nstrategies and scales naturally beyond the tabular setting by using standard\ndeep reinforcement learning architectures. Experiments in difficult exploration\ntasks, both in tabular and continuous control settings, show that our sharper\nuncertainty estimates improve sample-efficiency.\n","authors":["Carlos E. Luis","Alessandro G. Bottero","Julia Vinogradska","Felix Berkenkamp","Jan Peters"],"pdf_url":"https://arxiv.org/pdf/2302.12526v2.pdf","comment":"AISTATS 2023"},{"id":"http://arxiv.org/abs/2209.15430v2","updated":"2023-03-07T10:08:04Z","published":"2022-09-30T12:37:03Z","title":"Relative representations enable zero-shot latent space communication","summary":"  Neural networks embed the geometric structure of a data manifold lying in a\nhigh-dimensional space into latent representations. Ideally, the distribution\nof the data points in the latent space should depend only on the task, the\ndata, the loss, and other architecture-specific constraints. However, factors\nsuch as the random weights initialization, training hyperparameters, or other\nsources of randomness in the training phase may induce incoherent latent spaces\nthat hinder any form of reuse. Nevertheless, we empirically observe that, under\nthe same data and modeling choices, the angles between the encodings within\ndistinct latent spaces do not change. In this work, we propose the latent\nsimilarity between each sample and a fixed set of anchors as an alternative\ndata representation, demonstrating that it can enforce the desired invariances\nwithout any additional training. We show how neural architectures can leverage\nthese relative representations to guarantee, in practice, invariance to latent\nisometries and rescalings, effectively enabling latent space communication:\nfrom zero-shot model stitching to latent space comparison between diverse\nsettings. We extensively validate the generalization capability of our approach\non different datasets, spanning various modalities (images, text, graphs),\ntasks (e.g., classification, reconstruction) and architectures (e.g., CNNs,\nGCNs, transformers).\n","authors":["Luca Moschella","Valentino Maiorca","Marco Fumero","Antonio Norelli","Francesco Locatello","Emanuele Rodolà"],"pdf_url":"https://arxiv.org/pdf/2209.15430v2.pdf","comment":"ICLR 2023 notable top 5%, 26 pages, 11 figures, 18 tables"},{"id":"http://arxiv.org/abs/2303.03770v1","updated":"2023-03-07T10:04:55Z","published":"2023-03-07T10:04:55Z","title":"Guiding Pseudo-labels with Uncertainty Estimation for Test-Time\n  Adaptation","summary":"  Standard Unsupervised Domain Adaptation (UDA) methods assume the availability\nof both source and target data during the adaptation. In this work, we\ninvestigate the Test-Time Adaptation (TTA), a specific case of UDA where a\nmodel is adapted to a target domain without access to source data. We propose a\nnovel approach for the TTA setting based on a loss reweighting strategy that\nbrings robustness against the noise that inevitably affects the pseudo-labels.\nThe classification loss is reweighted based on the reliability of the\npseudo-labels that is measured by estimating their uncertainty. Guided by such\nreweighting strategy, the pseudo-labels are progressively refined by\naggregating knowledge from neighbouring samples. Furthermore, a self-supervised\ncontrastive framework is leveraged as a target space regulariser to enhance\nsuch knowledge aggregation. A novel negative pairs exclusion strategy is\nproposed to identify and exclude negative pairs made of samples sharing the\nsame class, even in presence of some noise in the pseudo-labels. Our method\noutperforms previous methods on three major benchmarks by a large margin. We\nset the new TTA state-of-the-art on VisDA-C and DomainNet with a performance\ngain of +1.8\\% on both benchmarks and on PACS with +12.3\\% in the single-source\nsetting and +6.6\\% in\\ multi-target adaptation. Additional analyses demonstrate\nthat the proposed approach is robust to the noise, which results in\nsignificantly more accurate pseudo-labels compared to state-of-the-art\napproaches.\n","authors":["Mattia Litrico","Alessio Del Bue","Pietro Morerio"],"pdf_url":"https://arxiv.org/pdf/2303.03770v1.pdf","comment":"To be published in Proceedings of the IEEE/CVF Conference on Computer\n  Vision and Pattern Recognition (CVPR) 2023"},{"id":"http://arxiv.org/abs/2303.03769v1","updated":"2023-03-07T10:04:51Z","published":"2023-03-07T10:04:51Z","title":"Learning Hamiltonian Systems with Mono-Implicit Runge-Kutta Methods","summary":"  Numerical integrators could be used to form interpolation conditions when\ntraining neural networks to approximate the vector field of an ordinary\ndifferential equation (ODE) from data. When numerical one-step schemes such as\nthe Runge-Kutta methods are used to approximate the temporal discretization of\nan ODE with a known vector field, properties such as symmetry and stability are\nmuch studied. Here, we show that using mono-implicit Runge-Kutta methods of\nhigh order allows for accurate training of Hamiltonian neural networks on small\ndatasets. This is demonstrated by numerical experiments where the Hamiltonian\nof the chaotic double pendulum in addition to the Fermi-Pasta-Ulam-Tsingou\nsystem is learned from data.\n","authors":["Håkon Noren"],"pdf_url":"https://arxiv.org/pdf/2303.03769v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2303.03767v1","updated":"2023-03-07T10:01:00Z","published":"2023-03-07T10:01:00Z","title":"Proactive Multi-Camera Collaboration For 3D Human Pose Estimation","summary":"  This paper presents a multi-agent reinforcement learning (MARL) scheme for\nproactive Multi-Camera Collaboration in 3D Human Pose Estimation in dynamic\nhuman crowds. Traditional fixed-viewpoint multi-camera solutions for human\nmotion capture (MoCap) are limited in capture space and susceptible to dynamic\nocclusions. Active camera approaches proactively control camera poses to find\noptimal viewpoints for 3D reconstruction. However, current methods still face\nchallenges with credit assignment and environment dynamics. To address these\nissues, our proposed method introduces a novel Collaborative Triangulation\nContribution Reward (CTCR) that improves convergence and alleviates multi-agent\ncredit assignment issues resulting from using 3D reconstruction accuracy as the\nshared reward. Additionally, we jointly train our model with multiple world\ndynamics learning tasks to better capture environment dynamics and encourage\nanticipatory behaviors for occlusion avoidance. We evaluate our proposed method\nin four photo-realistic UE4 environments to ensure validity and\ngeneralizability. Empirical results show that our method outperforms fixed and\nactive baselines in various scenarios with different numbers of cameras and\nhumans.\n","authors":["Hai Ci","Mickel Liu","Xuehai Pan","Fangwei Zhong","Yizhou Wang"],"pdf_url":"https://arxiv.org/pdf/2303.03767v1.pdf","comment":"ICLR 2023 poster"},{"id":"http://arxiv.org/abs/2302.01622v2","updated":"2023-03-07T10:00:43Z","published":"2023-02-03T09:49:13Z","title":"Private, fair and accurate: Training large-scale, privacy-preserving AI\n  models in medical imaging","summary":"  Artificial intelligence (AI) models are increasingly used in the medical\ndomain. However, as medical data is highly sensitive, special precautions to\nensure its protection are required. The gold standard for privacy preservation\nis the introduction of differential privacy (DP) to model training. Prior work\nindicates that DP has negative implications on model accuracy and fairness,\nwhich are unacceptable in medicine and represent a main barrier to the\nwidespread use of privacy-preserving techniques. In this work, we evaluated the\neffect of privacy-preserving training of AI models for chest radiograph\ndiagnosis regarding accuracy and fairness compared to non-private training. For\nthis, we used a large dataset (N=193,311) of high quality clinical chest\nradiographs, which were retrospectively collected and manually labeled by\nexperienced radiologists. We then compared non-private deep convolutional\nneural networks (CNNs) and privacy-preserving (DP) models with respect to\nprivacy-utility trade-offs measured as area under the\nreceiver-operator-characteristic curve (AUROC), and privacy-fairness\ntrade-offs, measured as Pearson's r or Statistical Parity Difference. We found\nthat the non-private CNNs achieved an average AUROC score of 0.90 +- 0.04 over\nall labels, whereas the DP CNNs with a privacy budget of epsilon=7.89 resulted\nin an AUROC of 0.87 +- 0.04, i.e., a mere 2.6% performance decrease compared to\nnon-private training. Furthermore, we found the privacy-preserving training not\nto amplify discrimination against age, sex or co-morbidity. Our study shows\nthat -- under the challenging realistic circumstances of a real-life clinical\ndataset -- the privacy-preserving training of diagnostic deep learning models\nis possible with excellent diagnostic accuracy and fairness.\n","authors":["Soroosh Tayebi Arasteh","Alexander Ziller","Christiane Kuhl","Marcus Makowski","Sven Nebelung","Rickmer Braren","Daniel Rueckert","Daniel Truhn","Georgios Kaissis"],"pdf_url":"https://arxiv.org/pdf/2302.01622v2.pdf","comment":"3 tables, 5 figures, 11 supplementary materials"},{"id":"http://arxiv.org/abs/2303.03761v1","updated":"2023-03-07T09:56:23Z","published":"2023-03-07T09:56:23Z","title":"Graph Neural Networks in Vision-Language Image Understanding: A Survey","summary":"  2D image understanding is a complex problem within Computer Vision, but it\nholds the key to providing human level scene comprehension. It goes further\nthan identifying the objects in an image, and instead it attempts to understand\nthe scene. Solutions to this problem form the underpinning of a range of tasks,\nincluding image captioning, Visual Question Answering (VQA), and image\nretrieval. Graphs provide a natural way to represent the relational arrangement\nbetween objects in an image, and thus in recent years Graph Neural Networks\n(GNNs) have become a standard component of many 2D image understanding\npipelines, becoming a core architectural component especially in the VQA group\nof tasks. In this survey, we review this rapidly evolving field and we provide\na taxonomy of graph types used in 2D image understanding approaches, a\ncomprehensive list of the GNN models used in this domain, and a roadmap of\nfuture potential developments. To the best of our knowledge, this is the first\ncomprehensive survey that covers image captioning, visual question answering,\nand image retrieval techniques that focus on using GNNs as the main part of\ntheir architecture.\n","authors":["Henry Senior","Gregory Slabaugh","Shanxin Yuan","Luca Rossi"],"pdf_url":"https://arxiv.org/pdf/2303.03761v1.pdf","comment":"19 pages, 5 figures, 6 tables"},{"id":"http://arxiv.org/abs/2209.03997v2","updated":"2023-03-07T09:35:11Z","published":"2022-09-08T18:49:10Z","title":"Online Low Rank Matrix Completion","summary":"  We study the problem of {\\em online} low-rank matrix completion with\n$\\mathsf{M}$ users, $\\mathsf{N}$ items and $\\mathsf{T}$ rounds. In each round,\nthe algorithm recommends one item per user, for which it gets a (noisy) reward\nsampled from a low-rank user-item preference matrix. The goal is to design a\nmethod with sub-linear regret (in $\\mathsf{T}$) and nearly optimal dependence\non $\\mathsf{M}$ and $\\mathsf{N}$. The problem can be easily mapped to the\nstandard multi-armed bandit problem where each item is an {\\em independent}\narm, but that leads to poor regret as the correlation between arms and users is\nnot exploited. On the other hand, exploiting the low-rank structure of reward\nmatrix is challenging due to non-convexity of the low-rank manifold. We first\ndemonstrate that the low-rank structure can be exploited using a simple\nexplore-then-commit (ETC) approach that ensures a regret of $O(\\mathsf{polylog}\n(\\mathsf{M}+\\mathsf{N}) \\mathsf{T}^{2/3})$. That is, roughly only\n$\\mathsf{polylog} (\\mathsf{M}+\\mathsf{N})$ item recommendations are required\nper user to get a non-trivial solution. We then improve our result for the\nrank-$1$ setting which in itself is quite challenging and encapsulates some of\nthe key issues. Here, we propose \\textsc{OCTAL} (Online Collaborative filTering\nusing iterAtive user cLustering) that guarantees nearly optimal regret of\n$O(\\mathsf{polylog} (\\mathsf{M}+\\mathsf{N}) \\mathsf{T}^{1/2})$. OCTAL is based\non a novel technique of clustering users that allows iterative elimination of\nitems and leads to a nearly optimal minimax rate.\n","authors":["Prateek Jain","Soumyabrata Pal"],"pdf_url":"https://arxiv.org/pdf/2209.03997v2.pdf","comment":"37 pages, 7 figures (Accepted at ICLR 2023)"},{"id":"http://arxiv.org/abs/2303.03755v1","updated":"2023-03-07T09:30:43Z","published":"2023-03-07T09:30:43Z","title":"DLT: Conditioned layout generation with Joint Discrete-Continuous\n  Diffusion Layout Transformer","summary":"  Generating visual layouts is an essential ingredient of graphic design. The\nability to condition layout generation on a partial subset of component\nattributes is critical to real-world applications that involve user\ninteraction. Recently, diffusion models have demonstrated high-quality\ngenerative performances in various domains. However, it is unclear how to apply\ndiffusion models to the natural representation of layouts which consists of a\nmix of discrete (class) and continuous (location, size) attributes. To address\nthe conditioning layout generation problem, we introduce DLT, a joint\ndiscrete-continuous diffusion model. DLT is a transformer-based model which has\na flexible conditioning mechanism that allows for conditioning on any given\nsubset of all the layout component classes, locations, and sizes. Our method\noutperforms state-of-the-art generative models on various layout generation\ndatasets with respect to different metrics and conditioning settings.\nAdditionally, we validate the effectiveness of our proposed conditioning\nmechanism and the joint continuous-diffusion process. This joint process can be\nincorporated into a wide range of mixed discrete-continuous generative tasks.\n","authors":["Elad Levi","Eli Brosh","Mykola Mykhailych","Meir Perez"],"pdf_url":"https://arxiv.org/pdf/2303.03755v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03751v1","updated":"2023-03-07T09:20:43Z","published":"2023-03-07T09:20:43Z","title":"Zeroth-Order Optimization Meets Human Feedback: Provable Learning via\n  Ranking Oracles","summary":"  In this paper, we focus on a novel optimization problem in which the\nobjective function is a black-box and can only be evaluated through a ranking\noracle. This problem is common in real-world applications, particularly in\ncases where the function is assessed by human judges. Reinforcement Learning\nwith Human Feedback (RLHF) is a prominent example of such an application, which\nis adopted by the recent works\n\\cite{ouyang2022training,liu2023languages,chatgpt,bai2022training} to improve\nthe quality of Large Language Models (LLMs) with human guidance. We propose\nZO-RankSGD, a first-of-its-kind zeroth-order optimization algorithm, to solve\nthis optimization problem with a theoretical guarantee. Specifically, our\nalgorithm employs a new rank-based random estimator for the descent direction\nand is proven to converge to a stationary point. ZO-RankSGD can also be\ndirectly applied to the policy search problem in reinforcement learning when\nonly a ranking oracle of the episode reward is available. This makes ZO-RankSGD\na promising alternative to existing RLHF methods, as it optimizes in an online\nfashion and thus can work without any pre-collected data. Furthermore, we\ndemonstrate the effectiveness of ZO-RankSGD in a novel application: improving\nthe quality of images generated by a diffusion generative model with human\nranking feedback. Throughout experiments, we found that ZO-RankSGD can\nsignificantly enhance the detail of generated images with only a few rounds of\nhuman feedback. Overall, our work advances the field of zeroth-order\noptimization by addressing the problem of optimizing functions with only\nranking feedback, and offers an effective approach for aligning human and\nmachine intentions in a wide range of domains. Our code is released here\n\\url{https://github.com/TZW1998/Taming-Stable-Diffusion-with-Human-Ranking-Feedback}.\n","authors":["Zhiwei Tang","Dmitry Rybin","Tsung-Hui Chang"],"pdf_url":"https://arxiv.org/pdf/2303.03751v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03748v1","updated":"2023-03-07T09:14:16Z","published":"2023-03-07T09:14:16Z","title":"Computing formation enthalpies through an explainable machine learning\n  method: the case of Lanthanide Orthophosphates solid solutions","summary":"  In the last decade, the use of Machine and Deep Learning (MDL) methods in\nCondensed Matter physics has seen a steep increase in the number of problems\ntackled and methods employed. A number of distinct MDL approaches have been\nemployed in many different topics; from prediction of materials properties to\ncomputation of Density Functional Theory potentials and inter-atomic force\nfields. In many cases the result is a surrogate model which returns promising\npredictions but is opaque on the inner mechanisms of its success. On the other\nhand, the typical practitioner looks for answers that are explainable and\nprovide a clear insight on the mechanisms governing a physical phenomena. In\nthis work, we describe a proposal to use a sophisticated combination of\ntraditional Machine Learning methods to obtain an explainable model that\noutputs an explicit functional formulation for the material property of\ninterest. We demonstrate the effectiveness of our methodology in deriving a new\nhighly accurate expression for the enthalpy of formation of solid solutions of\nlanthanides orthophosphates.\n","authors":["Edoardo Di Napoli","Xinzhe Wu","Thomas Bornhake","Piotr M. Kowalski"],"pdf_url":"https://arxiv.org/pdf/2303.03748v1.pdf","comment":"24 pages, 5 figures"},{"id":"http://arxiv.org/abs/2303.03747v1","updated":"2023-03-07T09:10:34Z","published":"2023-03-07T09:10:34Z","title":"Graph Decision Transformer","summary":"  Offline reinforcement learning (RL) is a challenging task, whose objective is\nto learn policies from static trajectory data without interacting with the\nenvironment. Recently, offline RL has been viewed as a sequence modeling\nproblem, where an agent generates a sequence of subsequent actions based on a\nset of static transition experiences. However, existing approaches that use\ntransformers to attend to all tokens naively can overlook the dependencies\nbetween different tokens and limit long-term dependency learning. In this\npaper, we propose the Graph Decision Transformer (GDT), a novel offline RL\napproach that models the input sequence into a causal graph to capture\npotential dependencies between fundamentally different concepts and facilitate\ntemporal and causal relationship learning. GDT uses a graph transformer to\nprocess the graph inputs with relation-enhanced mechanisms, and an optional\nsequence transformer to handle fine-grained spatial information in visual\ntasks. Our experiments show that GDT matches or surpasses the performance of\nstate-of-the-art offline RL methods on image-based Atari and OpenAI Gym.\n","authors":["Shengchao Hu","Li Shen","Ya Zhang","Dacheng Tao"],"pdf_url":"https://arxiv.org/pdf/2303.03747v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2303.03743v1","updated":"2023-03-07T09:07:42Z","published":"2023-03-07T09:07:42Z","title":"High-Precision Machine-Learning Based Indoor Localization with Massive\n  MIMO System","summary":"  High-precision cellular-based localization is one of the key technologies for\nnext-generation communication systems. In this paper, we investigate the\npotential of applying machine learning (ML) to a massive multiple-input\nmultiple-output (MIMO) system to enhance localization accuracy. We analyze a\nnew ML-based localization pipeline that has two parallel fully connected neural\nnetworks (FCNN). The first FCNN takes the instantaneous spatial covariance\nmatrix to capture angular information, while the second FCNN takes the channel\nimpulse responses to capture delay information. We fuse the estimated\ncoordinates of these two FCNNs for further accuracy improvement. To test the\nlocalization algorithm, we performed an indoor measurement campaign with a\nmassive MIMO testbed at 3.7GHz. In the measured scenario, the proposed pipeline\ncan achieve centimeter-level accuracy by combining delay and angular\ninformation.\n","authors":["Guoda Tian","Ilayda Yaman","Michiel Sandra","Xuesong Cai","Liang Liu","Fredrik Tufvesson"],"pdf_url":"https://arxiv.org/pdf/2303.03743v1.pdf","comment":"6 pages, 8 figures"},{"id":"http://arxiv.org/abs/2303.03737v1","updated":"2023-03-07T08:53:20Z","published":"2023-03-07T08:53:20Z","title":"Multi-Dimensional and Multi-Scale Modeling for Speech Separation\n  Optimized by Discriminative Learning","summary":"  Transformer has shown advanced performance in speech separation, benefiting\nfrom its ability to capture global features. However, capturing local features\nand channel information of audio sequences in speech separation is equally\nimportant. In this paper, we present a novel approach named Intra-SE-Conformer\nand Inter-Transformer (ISCIT) for speech separation. Specifically, we design a\nnew network SE-Conformer that can model audio sequences in multiple dimensions\nand scales, and apply it to the dual-path speech separation framework.\nFurthermore, we propose Multi-Block Feature Aggregation to improve the\nseparation effect by selectively utilizing information from the intermediate\nblocks of the separation network. Meanwhile, we propose a speaker similarity\ndiscriminative loss to optimize the speech separation model to address the\nproblem of poor performance when speakers have similar voices. Experimental\nresults on the benchmark datasets WSJ0-2mix and WHAM! show that ISCIT can\nachieve state-of-the-art results.\n","authors":["Zhaoxi Mu","Xinyu Yang","Wenjing Zhu"],"pdf_url":"https://arxiv.org/pdf/2303.03737v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.03732v1","updated":"2023-03-07T08:44:58Z","published":"2023-03-07T08:44:58Z","title":"A Multi-Stage Triple-Path Method for Speech Separation in Noisy and\n  Reverberant Environments","summary":"  In noisy and reverberant environments, the performance of deep learning-based\nspeech separation methods drops dramatically because previous methods are not\ndesigned and optimized for such situations. To address this issue, we propose a\nmulti-stage end-to-end learning method that decouples the difficult speech\nseparation problem in noisy and reverberant environments into three\nsub-problems: speech denoising, separation, and de-reverberation. The\nprobability and speed of searching for the optimal solution of the speech\nseparation model are improved by reducing the solution space. Moreover, since\nthe channel information of the audio sequence in the time domain is crucial for\nspeech separation, we propose a triple-path structure capable of modeling the\nchannel dimension of audio sequences. Experimental results show that the\nproposed multi-stage triple-path method can improve the performance of speech\nseparation models at the cost of little model parameter increment.\n","authors":["Zhaoxi Mu","Xinyu Yang","Xiangyuan Yang","Wenjing Zhu"],"pdf_url":"https://arxiv.org/pdf/2303.03732v1.pdf","comment":"Accepted by ICASSP 2023"},{"id":"http://arxiv.org/abs/2211.04894v3","updated":"2023-03-07T08:25:24Z","published":"2022-11-09T13:55:50Z","title":"Exploring Video Quality Assessment on User Generated Contents from\n  Aesthetic and Technical Perspectives","summary":"  The rapid increase in user-generated-content (UGC) videos calls for the\ndevelopment of effective video quality assessment (VQA) algorithms. However,\nthe objective of the UGC-VQA problem is still ambiguous and can be viewed from\ntwo perspectives: the technical perspective, measuring the perception of\ndistortions; and the aesthetic perspective, which relates to preference and\nrecommendation on contents. To understand how these two perspectives affect\noverall subjective opinions in UGC-VQA, we conduct a large-scale subjective\nstudy to collect human quality opinions on overall quality of videos as well as\nperceptions from aesthetic and technical perspectives. The collected\nDisentangled Video Quality Database (DIVIDE-3k) confirms that human quality\nopinions on UGC videos are universally and inevitably affected by both\naesthetic and technical perspectives. In light of this, we propose the\nDisentangled Objective Video Quality Evaluator (DOVER) to learn the quality of\nUGC videos based on the two perspectives. The DOVER proves state-of-the-art\nperformance in UGC-VQA under very high efficiency. With perspective opinions in\nDIVIDE-3k, we further propose DOVER++, the first approach to provide reliable\nclear-cut quality evaluations from a single aesthetic or technical perspective.\nCode at https://github.com/VQAssessment/DOVER.\n","authors":["Haoning Wu","Erli Zhang","Liang Liao","Chaofeng Chen","Jingwen Hou","Annan Wang","Wenxiu Sun","Qiong Yan","Weisi Lin"],"pdf_url":"https://arxiv.org/pdf/2211.04894v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.16307v3","updated":"2023-03-07T08:18:26Z","published":"2022-10-24T06:19:43Z","title":"Investigation of chemical structure recognition by encoder-decoder\n  models in learning progress","summary":"  Descriptor generation methods using latent representations of\nencoder$-$decoder (ED) models with SMILES as input are useful because of the\ncontinuity of descriptor and restorability to the structure. However, it is not\nclear how the structure is recognized in the learning progress of ED models. In\nthis work, we created ED models of various learning progress and investigated\nthe relationship between structural information and learning progress. We\nshowed that compound substructures were learned early in ED models by\nmonitoring the accuracy of downstream tasks and input$-$output substructure\nsimilarity using substructure$-$based descriptors, which suggests that existing\nevaluation methods based on the accuracy of downstream tasks may not be\nsensitive enough to evaluate the performance of ED models with SMILES as\ndescriptor generation methods. On the other hand, we showed that structure\nrestoration was time$-$consuming, and in particular, insufficient learning led\nto the estimation of a larger structure than the actual one. It can be inferred\nthat determining the endpoint of the structure is a difficult task for the\nmodel. To our knowledge, this is the first study to link the learning progress\nof SMILES by ED model to chemical structures for a wide range of chemicals.\n","authors":["Shumpei Nemoto","Tadahaya Mizuno","Hiroyuki Kusuhara"],"pdf_url":"https://arxiv.org/pdf/2210.16307v3.pdf","comment":"17 pages, 4 figures"},{"id":"http://arxiv.org/abs/2303.03724v1","updated":"2023-03-07T08:16:46Z","published":"2023-03-07T08:16:46Z","title":"Learning Bipedal Walking for Humanoids with Current Feedback","summary":"  Recent advances in deep reinforcement learning (RL) based techniques combined\nwith training in simulation have offered a new approach to developing control\npolicies for legged robots. However, the application of such approaches to real\nhardware has largely been limited to quadrupedal robots with direct-drive\nactuators and light-weight bipedal robots with low gear-ratio transmission\nsystems. Application to life-sized humanoid robots has been elusive due to the\nlarge sim-to-real gap arising from their large size, heavier limbs, and a high\ngear-ratio transmission systems. In this paper, we present an approach for\neffectively overcoming the sim-to-real gap issue for humanoid robots arising\nfrom inaccurate torque tracking at the actuator level. Our key idea is to\nutilize the current feedback from the motors on the real robot, after training\nthe policy in a simulation environment artificially degraded with poor torque\ntracking. Our approach successfully trains an end-to-end policy in simulation\nthat can be deployed on a real HRP-5P humanoid robot for bipedal locomotion on\nchallenging terrain. We also perform robustness tests on the RL policy and\ncompare its performance against a conventional model-based controller for\nwalking on uneven terrain. YouTube video: https://youtu.be/IeUaSsBRbNY\n","authors":["Rohan Pratap Singh","Zhaoming Xie","Pierre Gergondet","Fumio Kanehiro"],"pdf_url":"https://arxiv.org/pdf/2303.03724v1.pdf","comment":"Submitted to the 2023 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS 2023). YouTube video:\n  https://youtu.be/IeUaSsBRbNY"},{"id":"http://arxiv.org/abs/2110.09140v2","updated":"2023-03-07T08:06:56Z","published":"2021-10-18T09:49:05Z","title":"Learning Prototype-oriented Set Representations for Meta-Learning","summary":"  Learning from set-structured data is a fundamental problem that has recently\nattracted increasing attention, where a series of summary networks are\nintroduced to deal with the set input. In fact, many meta-learning problems can\nbe treated as set-input tasks. Most existing summary networks aim to design\ndifferent architectures for the input set in order to enforce permutation\ninvariance. However, scant attention has been paid to the common cases where\ndifferent sets in a meta-distribution are closely related and share certain\nstatistical properties. Viewing each set as a distribution over a set of global\nprototypes, this paper provides a novel prototype-oriented optimal transport\n(POT) framework to improve existing summary networks. To learn the distribution\nover the global prototypes, we minimize its regularized optimal transport\ndistance to the set empirical distribution over data points, providing a\nnatural unsupervised way to improve the summary network. Since our\nplug-and-play framework can be applied to many meta-learning problems, we\nfurther instantiate it to the cases of few-shot classification and implicit\nmeta generative modeling. Extensive experiments demonstrate that our framework\nsignificantly improves the existing summary networks on learning more powerful\nsummary statistics from sets and can be successfully integrated into\nmetric-based few-shot classification and generative modeling applications,\nproviding a promising tool for addressing set-input and meta-learning problems.\n","authors":["Dandan Guo","Long Tian","Minghe Zhang","Mingyuan Zhou","Hongyuan Zha"],"pdf_url":"https://arxiv.org/pdf/2110.09140v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.08405v3","updated":"2023-03-07T08:02:52Z","published":"2022-10-26T17:44:03Z","title":"Using multimodal learning and deep generative models for corporate\n  bankruptcy prediction","summary":"  This research introduces for the first time, to the best of our knowledge,\nthe concept of multimodal learning in bankruptcy prediction models. We use the\nConditional Multimodal Discriminative (CMMD) model to learn multimodal\nrepresentations that embed information from accounting, market, and textual\nmodalities. The CMMD model needs a sample with all data modalities for model\ntraining. At test time, the CMMD model only needs access to accounting and\nmarket modalities to generate multimodal representations, which are further\nused to make bankruptcy predictions. This fact makes the use of bankruptcy\nprediction models using textual data realistic and possible, since accounting\nand market data are available for all companies unlike textual data. The\nempirical results in this research show that the classification performance of\nour proposed methodology is superior compared to that of a large number of\ntraditional classifier models. We also show that our proposed methodology\nsolves the limitation of previous bankruptcy models using textual data, as they\ncan only make predictions for a small proportion of companies. Finally, based\non multimodal representations, we introduce an index that is able to capture\nthe uncertainty of the financial situation of companies during periods of\nfinancial distress.\n","authors":["Rogelio A. Mancisidor"],"pdf_url":"https://arxiv.org/pdf/2211.08405v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03714v1","updated":"2023-03-07T07:55:52Z","published":"2023-03-07T07:55:52Z","title":"Generative Modeling with Flow-Guided Density Ratio Learning","summary":"  We present Flow-Guided Density Ratio Learning (FDRL), a simple and scalable\napproach to generative modeling which builds on the stale (time-independent)\napproximation of the gradient flow of entropy-regularized f-divergences\nintroduced in DGflow. In DGflow, the intractable time-dependent density ratio\nis approximated by a stale estimator given by a GAN discriminator. This is\nsufficient in the case of sample refinement, where the source and target\ndistributions of the flow are close to each other. However, this assumption is\ninvalid for generation and a naive application of the stale estimator fails due\nto the large chasm between the two distributions. FDRL proposes to train a\ndensity ratio estimator such that it learns from progressively improving\nsamples during the training process. We show that this simple method alleviates\nthe density chasm problem, allowing FDRL to generate images of dimensions as\nhigh as $128\\times128$, as well as outperform existing gradient flow baselines\non quantitative benchmarks. We also show the flexibility of FDRL with two use\ncases. First, unconditional FDRL can be easily composed with external\nclassifiers to perform class-conditional generation. Second, FDRL can be\ndirectly applied to unpaired image-to-image translation with no modifications\nneeded to the framework. Code is publicly available at\nhttps://github.com/ajrheng/FDRL.\n","authors":["Alvin Heng","Abdul Fatir Ansari","Harold Soh"],"pdf_url":"https://arxiv.org/pdf/2303.03714v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2203.11049v2","updated":"2023-03-07T07:44:11Z","published":"2022-03-21T15:14:44Z","title":"AutoTTS: End-to-End Text-to-Speech Synthesis through Differentiable\n  Duration Modeling","summary":"  Parallel text-to-speech (TTS) models have recently enabled fast and\nhighly-natural speech synthesis. However, they typically require external\nalignment models, which are not necessarily optimized for the decoder as they\nare not jointly trained. In this paper, we propose a differentiable duration\nmethod for learning monotonic alignments between input and output sequences.\nOur method is based on a soft-duration mechanism that optimizes a stochastic\nprocess in expectation. Using this differentiable duration method, we introduce\nAutoTTS, a direct text-to-waveform speech synthesis model. AutoTTS enables\nhigh-fidelity speech synthesis through a combination of adversarial training\nand matching the total ground-truth duration. Experimental results show that\nour model obtains competitive results while enjoying a much simpler training\npipeline. Audio samples are available online.\n","authors":["Bac Nguyen","Fabien Cardinaux","Stefan Uhlich"],"pdf_url":"https://arxiv.org/pdf/2203.11049v2.pdf","comment":"ICASSP 2023"},{"id":"http://arxiv.org/abs/2303.03707v1","updated":"2023-03-07T07:42:37Z","published":"2023-03-07T07:42:37Z","title":"Hybrid quantum-classical convolutional neural network for phytoplankton\n  classification","summary":"  The taxonomic composition and abundance of phytoplankton, having direct\nimpact on marine ecosystem dynamic and global environment change, are listed as\nessential ocean variables. Phytoplankton classification is very crucial for\nPhytoplankton analysis, but it is very difficult because of the huge amount and\ntiny volume of Phytoplankton. Machine learning is the principle way of\nperforming phytoplankton image classification automatically. When carrying out\nlarge-scale research on the marine phytoplankton, the volume of data increases\noverwhelmingly and more powerful computational resources are required for the\nsuccess of machine learning algorithms. Recently, quantum machine learning has\nemerged as the potential solution for large-scale data processing by harnessing\nthe exponentially computational power of quantum computer. Here, for the first\ntime, we demonstrate the feasibility of quantum deep neural networks for\nphytoplankton classification. Hybrid quantum-classical convolutional and\nresidual neural networks are developed based on the classical architectures.\nThese models make a proper balance between the limited function of the current\nquantum devices and the large size of phytoplankton images, which make it\npossible to perform phytoplankton classification on the near-term quantum\ncomputers. Better performance is obtained by the quantum-enhanced models\nagainst the classical counterparts. In particular, quantum models converge much\nfaster than classical ones. The present quantum models are versatile, and can\nbe applied for various tasks of image classification in the field of marine\nscience.\n","authors":["Shangshang Shi","Zhimin Wang","Ruimin Shang","Yanan Li","Jiaxin Li","Guoqiang Zhong","Yongjian Gu"],"pdf_url":"https://arxiv.org/pdf/2303.03707v1.pdf","comment":"20 pages, 13 figures"},{"id":"http://arxiv.org/abs/2303.03706v1","updated":"2023-03-07T07:42:26Z","published":"2023-03-07T07:42:26Z","title":"Classifying Text-Based Conspiracy Tweets related to COVID-19 using\n  Contextualized Word Embeddings","summary":"  The FakeNews task in MediaEval 2022 investigates the challenge of finding\naccurate and high-performance models for the classification of conspiracy\ntweets related to COVID-19. In this paper, we used BERT, ELMO, and their\ncombination for feature extraction and RandomForest as classifier. The results\nshow that ELMO performs slightly better than BERT, however their combination at\nfeature level reduces the performance.\n","authors":["Abdul Rehman","Rabeeh Ayaz Abbasi","Irfan ul Haq Qureshi","Akmal Saeed Khattak"],"pdf_url":"https://arxiv.org/pdf/2303.03706v1.pdf","comment":"Published in Multimedia Benchmark Workshop 2022, Bergen, Norway and\n  Online, 12-13 January 2023: https://2022.multimediaeval.com/"},{"id":"http://arxiv.org/abs/2303.03701v1","updated":"2023-03-07T07:32:10Z","published":"2023-03-07T07:32:10Z","title":"Variational Inference for Neyman-Scott Processes","summary":"  Neyman-Scott processes (NSPs) have been applied across a range of fields to\nmodel points or temporal events with a hierarchy of clusters. Markov chain\nMonte Carlo (MCMC) is typically used for posterior sampling in the model.\nHowever, MCMC's mixing time can cause the resulting inference to be slow, and\nthereby slow down model learning and prediction. We develop the first\nvariational inference (VI) algorithm for NSPs, and give two examples of\nsuitable variational posterior point process distributions. Our method\nminimizes the inclusive Kullback-Leibler (KL) divergence for VI to obtain the\nvariational parameters. We generate samples from the approximate posterior\npoint processes much faster than MCMC, as we can directly estimate the\napproximate posterior point processes without any MCMC steps or gradient\ndescent. We include synthetic and real-world data experiments that demonstrate\nour VI algorithm achieves better prediction performance than MCMC when\ncomputational time is limited.\n","authors":["Chengkuan Hong","Christian R. Shelton"],"pdf_url":"https://arxiv.org/pdf/2303.03701v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.00930v2","updated":"2023-03-07T07:28:09Z","published":"2023-01-03T02:19:20Z","title":"Data Valuation Without Training of a Model","summary":"  Many recent works on understanding deep learning try to quantify how much\nindividual data instances influence the optimization and generalization of a\nmodel. Such attempts reveal characteristics and importance of individual\ninstances, which may provide useful information in diagnosing and improving\ndeep learning. However, most of the existing works on data valuation require\nactual training of a model, which often demands high-computational cost. In\nthis paper, we provide a training-free data valuation score, called\ncomplexity-gap score, which is a data-centric score to quantify the influence\nof individual instances in generalization of two-layer overparameterized neural\nnetworks. The proposed score can quantify irregularity of the instances and\nmeasure how much each data instance contributes in the total movement of the\nnetwork parameters during training. We theoretically analyze and empirically\ndemonstrate the effectiveness of the complexity-gap score in finding `irregular\nor mislabeled' data instances, and also provide applications of the score in\nanalyzing datasets and diagnosing training dynamics. Our code is publicly\navailable at https://github.com/JJchy/CG_score\n","authors":["Nohyun Ki","Hoyong Choi","Hye Won Chung"],"pdf_url":"https://arxiv.org/pdf/2301.00930v2.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.03697v1","updated":"2023-03-07T07:26:09Z","published":"2023-03-07T07:26:09Z","title":"Stylometric Detection of AI-Generated Text in Twitter Timelines","summary":"  Recent advancements in pre-trained language models have enabled convenient\nmethods for generating human-like text at a large scale. Though these\ngeneration capabilities hold great potential for breakthrough applications, it\ncan also be a tool for an adversary to generate misinformation. In particular,\nsocial media platforms like Twitter are highly susceptible to AI-generated\nmisinformation. A potential threat scenario is when an adversary hijacks a\ncredible user account and incorporates a natural language generator to generate\nmisinformation. Such threats necessitate automated detectors for AI-generated\ntweets in a given user's Twitter timeline. However, tweets are inherently\nshort, thus making it difficult for current state-of-the-art pre-trained\nlanguage model-based detectors to accurately detect at what point the AI starts\nto generate tweets in a given Twitter timeline. In this paper, we present a\nnovel algorithm using stylometric signals to aid detecting AI-generated tweets.\nWe propose models corresponding to quantifying stylistic changes in human and\nAI tweets in two related tasks: Task 1 - discriminate between human and\nAI-generated tweets, and Task 2 - detect if and when an AI starts to generate\ntweets in a given Twitter timeline. Our extensive experiments demonstrate that\nthe stylometric features are effective in augmenting the state-of-the-art\nAI-generated text detectors.\n","authors":["Tharindu Kumarage","Joshua Garland","Amrita Bhattacharjee","Kirill Trapeznikov","Scott Ruston","Huan Liu"],"pdf_url":"https://arxiv.org/pdf/2303.03697v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.09865v2","updated":"2023-03-07T07:23:38Z","published":"2023-02-20T09:56:51Z","title":"Can discrete information extraction prompts generalize across language\n  models?","summary":"  We study whether automatically-induced prompts that effectively extract\ninformation from a language model can also be used, out-of-the-box, to probe\nother language models for the same information. After confirming that discrete\nprompts induced with the AutoPrompt algorithm outperform manual and semi-manual\nprompts on the slot-filling task, we demonstrate a drop in performance for\nAutoPrompt prompts learned on a model and tested on another. We introduce a way\nto induce prompts by mixing language models at training time that results in\nprompts that generalize well across models. We conduct an extensive analysis of\nthe induced prompts, finding that the more general prompts include a larger\nproportion of existing English words and have a less order-dependent and more\nuniform distribution of information across their component tokens. Our work\nprovides preliminary evidence that it's possible to generate discrete prompts\nthat can be induced once and used with a number of different models, and gives\ninsights on the properties characterizing such prompts.\n","authors":["Nathanaël Carraz Rakotonirina","Roberto Dessì","Fabio Petroni","Sebastian Riedel","Marco Baroni"],"pdf_url":"https://arxiv.org/pdf/2302.09865v2.pdf","comment":"Published as conference paper at ICLR 2023"},{"id":"http://arxiv.org/abs/2212.01689v2","updated":"2023-03-07T07:04:32Z","published":"2022-12-03T20:56:29Z","title":"Learning-Assisted Algorithm Unrolling for Online Optimization with\n  Budget Constraints","summary":"  Online optimization with multiple budget constraints is challenging since the\nonline decisions over a short time horizon are coupled together by strict\ninventory constraints. The existing manually-designed algorithms cannot achieve\nsatisfactory average performance for this setting because they often need a\nlarge number of time steps for convergence and/or may violate the inventory\nconstraints. In this paper, we propose a new machine learning (ML) assisted\nunrolling approach, called LAAU (Learning-Assisted Algorithm Unrolling), which\nunrolls the online decision pipeline and leverages an ML model for updating the\nLagrangian multiplier online. For efficient training via backpropagation, we\nderive gradients of the decision pipeline over time. We also provide the\naverage cost bounds for two cases when training data is available offline and\ncollected online, respectively. Finally, we present numerical results to\nhighlight that LAAU can outperform the existing baselines.\n","authors":["Jianyi Yang","Shaolei Ren"],"pdf_url":"https://arxiv.org/pdf/2212.01689v2.pdf","comment":"Accepted by AAAI'23"},{"id":"http://arxiv.org/abs/2302.10166v3","updated":"2023-03-07T06:47:30Z","published":"2023-02-20T18:53:56Z","title":"Learning Deep Semantics for Test Completion","summary":"  Writing tests is a time-consuming yet essential task during software\ndevelopment. We propose to leverage recent advances in deep learning for text\nand code generation to assist developers in writing tests. We formalize the\nnovel task of test completion to automatically complete the next statement in a\ntest method based on the context of prior statements and the code under test.\nWe develop TeCo -- a deep learning model using code semantics for test\ncompletion. The key insight underlying TeCo is that predicting the next\nstatement in a test method requires reasoning about code execution, which is\nhard to do with only syntax-level data that existing code completion models\nuse. TeCo extracts and uses six kinds of code semantics data, including the\nexecution result of prior statements and the execution context of the test\nmethod. To provide a testbed for this new task, as well as to evaluate TeCo, we\ncollect a corpus of 130,934 test methods from 1,270 open-source Java projects.\nOur results show that TeCo achieves an exact-match accuracy of 18, which is 29%\nhigher than the best baseline using syntax-level data only. When measuring\nfunctional correctness of generated next statement, TeCo can generate runnable\ncode in 29% of the cases compared to 18% obtained by the best baseline.\nMoreover, TeCo is significantly better than prior work on test oracle\ngeneration.\n","authors":["Pengyu Nie","Rahul Banerjee","Junyi Jessy Li","Raymond J. Mooney","Milos Gligoric"],"pdf_url":"https://arxiv.org/pdf/2302.10166v3.pdf","comment":"Accepted as a conference paper in ICSE 2023"},{"id":"http://arxiv.org/abs/2303.03679v1","updated":"2023-03-07T06:38:48Z","published":"2023-03-07T06:38:48Z","title":"MAST: Masked Augmentation Subspace Training for Generalizable\n  Self-Supervised Priors","summary":"  Recent Self-Supervised Learning (SSL) methods are able to learn feature\nrepresentations that are invariant to different data augmentations, which can\nthen be transferred to downstream tasks of interest. However, different\ndownstream tasks require different invariances for their best performance, so\nthe optimal choice of augmentations for SSL depends on the target task. In this\npaper, we aim to learn self-supervised features that generalize well across a\nvariety of downstream tasks (e.g., object classification, detection and\ninstance segmentation) without knowing any task information beforehand. We do\nso by Masked Augmentation Subspace Training (or MAST) to encode in the single\nfeature space the priors from different data augmentations in a factorized way.\nSpecifically, we disentangle the feature space into separate subspaces, each\ninduced by a learnable mask that selects relevant feature dimensions to model\ninvariance to a specific augmentation. We show the success of MAST in jointly\ncapturing generalizable priors from different augmentations, using both unique\nand shared features across the subspaces. We further show that MAST benefits\nfrom uncertainty modeling to reweight ambiguous samples from strong\naugmentations that may cause similarity mismatch in each subspace. Experiments\ndemonstrate that MAST consistently improves generalization on various\ndownstream tasks, while being task-agnostic and efficient during SSL. We also\nprovide interesting insights about how different augmentations are related and\nhow uncertainty reflects learning difficulty.\n","authors":["Chen Huang","Hanlin Goh","Jiatao Gu","Josh Susskind"],"pdf_url":"https://arxiv.org/pdf/2303.03679v1.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2303.03678v1","updated":"2023-03-07T06:34:04Z","published":"2023-03-07T06:34:04Z","title":"A Comparative Study of Deep Learning and Iterative Algorithms for Joint\n  Channel Estimation and Signal Detection","summary":"  Joint channel estimation and signal detection (JCESD) is crucial in wireless\ncommunication systems, but traditional algorithms perform poorly in low\nsignal-to-noise ratio (SNR) scenarios. Deep learning (DL) methods have been\ninvestigated, but concerns regarding computational expense and lack of\nvalidation in low-SNR settings remain. Hence, the development of a robust and\nlow-complexity model that can deliver excellent performance across a wide range\nof SNRs is highly desirable. In this paper, we aim to establish a benchmark\nwhere traditional algorithms and DL methods are validated on different channel\nmodels, Doppler, and SNR settings. In particular, we propose a new DL model\nwhere the backbone network is formed by unrolling the iterative algorithm, and\nthe hyperparameters are estimated by hypernetworks. Additionally, we adapt a\nlightweight DenseNet to the task of JCESD for comparison. We evaluate different\nmethods in three aspects: generalization in terms of bit error rate (BER),\nrobustness, and complexity. Our results indicate that DL approaches outperform\ntraditional algorithms in the challenging low-SNR setting, while the iterative\nalgorithm performs better in highSNR settings. Furthermore, the iterative\nalgorithm is more robust in the presence of carrier frequency offset, whereas\nDL methods excel when signals are corrupted by asymmetric Gaussian noise.\n","authors":["Haocheng Ju","Haimiao Zhang","Lin Li","Xiao Li","Bin Dong"],"pdf_url":"https://arxiv.org/pdf/2303.03678v1.pdf","comment":"25 pages, this work has been submitted to the IEEE for possible\n  publication. Code is available at https://github.com/j991222/MIMO_JCESD"},{"id":"http://arxiv.org/abs/2303.03677v1","updated":"2023-03-07T06:33:40Z","published":"2023-03-07T06:33:40Z","title":"Training Machine Learning Models to Characterize Temporal Evolution of\n  Disadvantaged Communities","summary":"  Disadvantaged communities (DAC), as defined by the Justice40 initiative of\nthe Department of Energy (DOE), USA, identifies census tracts across the USA to\ndetermine where benefits of climate and energy investments are or are not\ncurrently accruing. The DAC status not only helps in determining the\neligibility for future Justice40-related investments but is also critical for\nexploring ways to achieve equitable distribution of resources. However,\ndesigning inclusive and equitable strategies not just requires a good\nunderstanding of current demographics, but also a deeper analysis of the\ntransformations that happened in those demographics over the years. In this\npaper, machine learning (ML) models are trained on publicly available census\ndata from recent years to classify the DAC status at the census tracts level\nand then the trained model is used to classify DAC status for historical years.\nA detailed analysis of the feature and model selection along with the evolution\nof disadvantaged communities between 2013 and 2018 is presented in this study.\n","authors":["Milan Jain","Narmadha Meenu Mohankumar","Heng Wan","Sumitrra Ganguly","Kyle D Wilson","David M Anderson"],"pdf_url":"https://arxiv.org/pdf/2303.03677v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03666v1","updated":"2023-03-07T06:04:58Z","published":"2023-03-07T06:04:58Z","title":"Face: Fast, Accurate and Context-Aware Audio Annotation and\n  Classification","summary":"  This paper presents a context-aware framework for feature selection and\nclassification procedures to realize a fast and accurate audio event annotation\nand classification. The context-aware design starts with exploring feature\nextraction techniques to find an appropriate combination to select a set\nresulting in remarkable classification accuracy with minimal computational\neffort. The exploration for feature selection also embraces an investigation of\naudio Tempo representation, an advantageous feature extraction method missed by\nprevious works in the environmental audio classification research scope. The\nproposed annotation method considers outlier, inlier, and hard-to-predict data\nsamples to realize context-aware Active Learning, leading to the average\naccuracy of 90% when only 15% of data possess initial annotation. Our proposed\nalgorithm for sound classification obtained average prediction accuracy of\n98.05% on the UrbanSound8K dataset. The notebooks containing our source codes\nand implementation results are available at https://github.com/gitmehrdad/FACE.\n","authors":["M. Mehrdad Morsali","Hoda Mohammadzade","Saeed Bagheri Shouraki"],"pdf_url":"https://arxiv.org/pdf/2303.03666v1.pdf","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2211.05385v2","updated":"2023-03-07T05:54:27Z","published":"2022-11-10T07:24:09Z","title":"GANStrument: Adversarial Instrument Sound Synthesis with Pitch-invariant\n  Instance Conditioning","summary":"  We propose GANStrument, a generative adversarial model for instrument sound\nsynthesis. Given a one-shot sound as input, it is able to generate pitched\ninstrument sounds that reflect the timbre of the input within an interactive\ntime. By exploiting instance conditioning, GANStrument achieves better fidelity\nand diversity of synthesized sounds and generalization ability to various\ninputs. In addition, we introduce an adversarial training scheme for a\npitch-invariant feature extractor that significantly improves the pitch\naccuracy and timbre consistency. Experimental results show that GANStrument\noutperforms strong baselines that do not use instance conditioning in terms of\ngeneration quality and input editability. Qualitative examples are available\nonline.\n","authors":["Gaku Narita","Junichi Shimizu","Taketo Akama"],"pdf_url":"https://arxiv.org/pdf/2211.05385v2.pdf","comment":"5 pages, 4 figures, Accepted to 2023 IEEE International Conference on\n  Acoustics, Speech, and Signal Processing (ICASSP), Audio examples:\n  https://ganstrument.github.io/ganstrument-demo/"},{"id":"http://arxiv.org/abs/2303.03660v1","updated":"2023-03-07T05:48:28Z","published":"2023-03-07T05:48:28Z","title":"ECG Classification System for Arrhythmia Detection Using Convolutional\n  Neural Networks","summary":"  Arrhythmia is just one of the many cardiovascular illnesses that have been\nextensively studied throughout the years. Using a multi-lead ECG data, this\nresearch describes a deep learning (DL) technique based on a convolutional\nneural network (CNN) algorithm to detect cardiovascular arrhythmia in patients.\nThe suggested CNN model has six layers total, two convolution layers, two\npooling layers, and two fully linked layers within a residual block, in\naddition to the input and output layers. In this study, the classification of\nthe ECG signals into five groups, Left Bundle Branch Block (LBBB), Right Bundle\nBranch Block (RBBB), Atrial Premature Contraction (APC), Premature Ventricular\nContraction (PVC), and Normal Beat is the main goal (N). Using the MIT-BIH\narrhythmia dataset, we assessed the suggested technique. The findings show that\nour suggested strategy classified 15000 cases with an average accuracy of\n98.2%.\n","authors":["Aryan Odugoudar","Jaskaran Singh Walia"],"pdf_url":"https://arxiv.org/pdf/2303.03660v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.10243v2","updated":"2023-03-07T05:46:46Z","published":"2022-10-19T01:45:29Z","title":"CLUTR: Curriculum Learning via Unsupervised Task Representation Learning","summary":"  Reinforcement Learning (RL) algorithms are often known for sample\ninefficiency and difficult generalization. Recently, Unsupervised Environment\nDesign (UED) emerged as a new paradigm for zero-shot generalization by\nsimultaneously learning a task distribution and agent policies on the generated\ntasks. This is a non-stationary process where the task distribution evolves\nalong with agent policies; creating an instability over time. While past works\ndemonstrated the potential of such approaches, sampling effectively from the\ntask space remains an open challenge, bottlenecking these approaches. To this\nend, we introduce CLUTR: a novel unsupervised curriculum learning algorithm\nthat decouples task representation and curriculum learning into a two-stage\noptimization. It first trains a recurrent variational autoencoder on randomly\ngenerated tasks to learn a latent task manifold. Next, a teacher agent creates\na curriculum by maximizing a minimax REGRET-based objective on a set of latent\ntasks sampled from this manifold. Using the fixed-pretrained task manifold, we\nshow that CLUTR successfully overcomes the non-stationarity problem and\nimproves stability. Our experimental results show CLUTR outperforms PAIRED, a\nprincipled and popular UED method, in the challenging CarRacing and navigation\nenvironments: achieving 10.6X and 45\\% improvement in zero-shot generalization,\nrespectively. CLUTR also performs comparably to the non-UED state-of-the-art\nfor CarRacing, while requiring 500X fewer environment interactions.\n","authors":["Abdus Salam Azad","Izzeddin Gur","Jasper Emhoff","Nathaniel Alexis","Aleksandra Faust","Pieter Abbeel","Ion Stoica"],"pdf_url":"https://arxiv.org/pdf/2210.10243v2.pdf","comment":"Preprint, Currently Under Review"},{"id":"http://arxiv.org/abs/2110.05887v3","updated":"2023-03-07T05:32:23Z","published":"2021-10-12T10:56:54Z","title":"Discovery of Single Independent Latent Variable","summary":"  Latent variable discovery is a central problem in data analysis with a broad\nrange of applications in applied science. In this work, we consider data given\nas an invertible mixture of two statistically independent components and assume\nthat one of the components is observed while the other is hidden. Our goal is\nto recover the hidden component. For this purpose, we propose an autoencoder\nequipped with a discriminator. Unlike the standard nonlinear ICA problem, which\nwas shown to be non-identifiable, in the special case of ICA we consider here,\nwe show that our approach can recover the component of interest up to\nentropy-preserving transformation. We demonstrate the performance of the\nproposed approach in several tasks, including image synthesis, voice cloning,\nand fetal ECG extraction.\n","authors":["Uri Shaham","Jonathan Svirsky","Ori Katz","Ronen Talmon"],"pdf_url":"https://arxiv.org/pdf/2110.05887v3.pdf","comment":"Published as a conference paper at Neurips 2022. In the current\n  version the proof of the lemma is modified"},{"id":"http://arxiv.org/abs/2303.03654v1","updated":"2023-03-07T05:21:15Z","published":"2023-03-07T05:21:15Z","title":"MPool: Motif-Based Graph Pooling","summary":"  Graph Neural networks (GNNs) have recently become a powerful technique for\nmany graph-related tasks including graph classification. Current GNN models\napply different graph pooling methods that reduce the number of nodes and edges\nto learn the higher-order structure of the graph in a hierarchical way. All\nthese methods primarily rely on the one-hop neighborhood. However, they do not\nconsider the higher- order structure of the graph. In this work, we propose a\nmulti-channel Motif-based Graph Pooling method named (MPool) captures the\nhigher-order graph structure with motif and local and global graph structure\nwith a combination of selection and clustering-based pooling operations. As the\nfirst channel, we develop node selection-based graph pooling by designing a\nnode ranking model considering the motif adjacency of nodes. As the second\nchannel, we develop cluster-based graph pooling by designing a spectral\nclustering model using motif adjacency. As the final layer, the result of each\nchannel is aggregated into the final graph representation. We perform extensive\nexperiments on eight benchmark datasets and show that our proposed method shows\nbetter accuracy than the baseline methods for graph classification tasks.\n","authors":["Muhammad Ifte Khairul Islam","Max Khanov","Esra Akbas"],"pdf_url":"https://arxiv.org/pdf/2303.03654v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2204.11280v3","updated":"2023-03-07T05:01:02Z","published":"2022-04-24T13:54:42Z","title":"Deconstructed Generation-Based Zero-Shot Model","summary":"  Recent research on Generalized Zero-Shot Learning (GZSL) has focused\nprimarily on generation-based methods. However, current literature has\noverlooked the fundamental principles of these methods and has made limited\nprogress in a complex manner. In this paper, we aim to deconstruct the\ngenerator-classifier framework and provide guidance for its improvement and\nextension. We begin by breaking down the generator-learned unseen class\ndistribution into class-level and instance-level distributions. Through our\nanalysis of the role of these two types of distributions in solving the GZSL\nproblem, we generalize the focus of the generation-based approach, emphasizing\nthe importance of (i) attribute generalization in generator learning and (ii)\nindependent classifier learning with partially biased data. We present a simple\nmethod based on this analysis that outperforms SotAs on four public GZSL\ndatasets, demonstrating the validity of our deconstruction. Furthermore, our\nproposed method remains effective even without a generative model, representing\na step towards simplifying the generator-classifier structure. Our code is\navailable at \\url{https://github.com/cdb342/DGZ}.\n","authors":["Dubing Chen","Yuming Shen","Haofeng Zhang","Philip H. S. Torr"],"pdf_url":"https://arxiv.org/pdf/2204.11280v3.pdf","comment":"AAAI 2023"},{"id":"http://arxiv.org/abs/2205.03699v2","updated":"2023-03-07T04:59:51Z","published":"2022-05-07T18:28:20Z","title":"Rate-Optimal Contextual Online Matching Bandit","summary":"  Two-sided online matching platforms have been employed in various markets.\nHowever, agents' preferences in present market are usually implicit and unknown\nand must be learned from data. With the growing availability of side\ninformation involved in the decision process, modern online matching\nmethodology demands the capability to track preference dynamics for agents\nbased on their contextual information. This motivates us to consider a novel\nContextual Online Matching Bandit prOblem (COMBO), which allows dynamic\npreferences in matching decisions. Existing works focus on multi-armed bandit\nwith static preference, but this is insufficient: the two-sided preference\nchanges as along as one-side's contextual information updates, resulting in\nnon-static matching. In this paper, we propose a Centralized Contextual -\nExplore Then Commit (CC-ETC) algorithm to adapt to the COMBO. CC-ETC solves\nonline matching with dynamic preference. In theory, we show that CC-ETC\nachieves a sublinear regret upper bound O(log(T)) and is a rate-optimal\nalgorithm by proving a matching lower bound. In the experiments, we demonstrate\nthat CC-ETC is robust to variant preference schemes, dimensions of contexts,\nreward noise levels, and contexts variation levels.\n","authors":["Yuantong Li","Chi-hua Wang","Guang Cheng","Will Wei Sun"],"pdf_url":"https://arxiv.org/pdf/2205.03699v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03648v1","updated":"2023-03-07T04:36:35Z","published":"2023-03-07T04:36:35Z","title":"Can Membership Inferencing be Refuted?","summary":"  Membership inference (MI) attack is currently the most popular test for\nmeasuring privacy leakage in machine learning models. Given a machine learning\nmodel, a data point and some auxiliary information, the goal of an MI~attack is\nto determine whether the data point was used to train the model. In this work,\nwe study the reliability of membership inference attacks in practice.\nSpecifically, we show that a model owner can plausibly refute the result of a\nmembership inference test on a data point $x$ by constructing a \\textit{proof\nof repudiation} that proves that the model was trained \\textit{without} $x$. We\ndesign efficient algorithms to construct proofs of repudiation for all data\npoints of the training dataset. Our empirical evaluation demonstrates the\npractical feasibility of our algorithm by constructing proofs of repudiation\nfor popular machine learning models on MNIST and CIFAR-10. Consequently, our\nresults call for a re-evaluation of the implications of membership inference\nattacks in practice.\n","authors":["Zhifeng Kong","Amrita Roy Chowdhury","Kamalika Chaudhuri"],"pdf_url":"https://arxiv.org/pdf/2303.03648v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.14051v2","updated":"2023-03-07T04:06:45Z","published":"2022-10-25T14:30:48Z","title":"Bridging Distributional and Risk-sensitive Reinforcement Learning with\n  Provable Regret Bounds","summary":"  We study the regret guarantee for risk-sensitive reinforcement learning\n(RSRL) via distributional reinforcement learning (DRL) methods. In particular,\nwe consider finite episodic Markov decision processes whose objective is the\nentropic risk measure (EntRM) of return. We identify a key property of the\nEntRM, the monotonicity-preserving property, which enables the risk-sensitive\ndistributional dynamic programming framework. We then propose two novel DRL\nalgorithms that implement optimism through two different schemes, including a\nmodel-free one and a model-based one.\n  We prove that both of them attain $\\tilde{\\mathcal{O}}(\\frac{\\exp(|\\beta|\nH)-1}{|\\beta|H}H\\sqrt{HS^2AT})$ regret upper bound, where $S$ is the number of\nstates, $A$ the number of states, $H$ the time horizon and $T$ the number of\ntotal time steps. It matches RSVI2 proposed in \\cite{fei2021exponential} with a\nmuch simpler regret analysis. To the best of our knowledge, this is the first\nregret analysis of DRL, which bridges DRL and RSRL in terms of sample\ncomplexity. Finally, we improve the existing lower bound by proving a tighter\nbound of $\\Omega(\\frac{\\exp(\\beta H/6)-1}{\\beta H}H\\sqrt{SAT})$ for $\\beta>0$\ncase, which recovers the tight lower bound $\\Omega(H\\sqrt{SAT})$ in the\nrisk-neutral setting.\n","authors":["Hao Liang","Zhi-Quan Luo"],"pdf_url":"https://arxiv.org/pdf/2210.14051v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03640v1","updated":"2023-03-07T04:04:23Z","published":"2023-03-07T04:04:23Z","title":"AHPA: Adaptive Horizontal Pod Autoscaling Systems on Alibaba Cloud\n  Container Service for Kubernetes","summary":"  The existing resource allocation policy for application instances in\nKubernetes cannot dynamically adjust according to the requirement of business,\nwhich would cause an enormous waste of resources during fluctuations. Moreover,\nthe emergence of new cloud services puts higher resource management\nrequirements. This paper discusses horizontal POD resources management in\nAlibaba Cloud Container Services with a newly deployed AI algorithm framework\nnamed AHPA -- the adaptive horizontal pod auto-scaling system. Based on a\nrobust decomposition forecasting algorithm and performance training model, AHPA\noffers an optimal pod number adjustment plan that could reduce POD resources\nand maintain business stability. Since being deployed in April 2021, this\nsystem has expanded to multiple customer scenarios, including logistics, social\nnetworks, AI audio and video, e-commerce, etc. Compared with the previous\nalgorithms, AHPA solves the elastic lag problem, increasing CPU usage by 10%\nand reducing resource cost by more than 20%. In addition, AHPA can\nautomatically perform flexible planning according to the predicted business\nvolume without manual intervention, significantly saving operation and\nmaintenance costs.\n","authors":["Zhiqiang Zhou","Chaoli Zhang","Lingna Ma","Jing Gu","Huajie Qian","Qingsong Wen","Liang Sun","Peng Li","Zhimin Tang"],"pdf_url":"https://arxiv.org/pdf/2303.03640v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03634v1","updated":"2023-03-07T03:46:53Z","published":"2023-03-07T03:46:53Z","title":"PreFallKD: Pre-Impact Fall Detection via CNN-ViT Knowledge Distillation","summary":"  Fall accidents are critical issues in an aging and aged society. Recently,\nmany researchers developed pre-impact fall detection systems using deep\nlearning to support wearable-based fall protection systems for preventing\nsevere injuries. However, most works only employed simple neural network models\ninstead of complex models considering the usability in resource-constrained\nmobile devices and strict latency requirements. In this work, we propose a\nnovel pre-impact fall detection via CNN-ViT knowledge distillation, namely\nPreFallKD, to strike a balance between detection performance and computational\ncomplexity. The proposed PreFallKD transfers the detection knowledge from the\npre-trained teacher model (vision transformer) to the student model\n(lightweight convolutional neural networks). Additionally, we apply data\naugmentation techniques to tackle issues of data imbalance. We conduct the\nexperiment on the KFall public dataset and compare PreFallKD with other\nstate-of-the-art models. The experiment results show that PreFallKD could boost\nthe student model during the testing phase and achieves reliable F1-score\n(92.66%) and lead time (551.3 ms).\n","authors":["Tin-Han Chi","Kai-Chun Liu","Chia-Yeh Hsieh"," Yu-Tsao","Chia-Tai Chan"],"pdf_url":"https://arxiv.org/pdf/2303.03634v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00102v2","updated":"2023-03-07T03:38:56Z","published":"2022-09-30T21:33:51Z","title":"MLPInit: Embarrassingly Simple GNN Training Acceleration with MLP\n  Initialization","summary":"  Training graph neural networks (GNNs) on large graphs is complex and\nextremely time consuming. This is attributed to overheads caused by sparse\nmatrix multiplication, which are sidestepped when training multi-layer\nperceptrons (MLPs) with only node features. MLPs, by ignoring graph context,\nare simple and faster for graph data, however they usually sacrifice prediction\naccuracy, limiting their applications for graph data. We observe that for most\nmessage passing-based GNNs, we can trivially derive an analog MLP (we call this\na PeerMLP) with an equivalent weight space, by setting the trainable parameters\nwith the same shapes, making us curious about \\textbf{\\emph{how do GNNs using\nweights from a fully trained PeerMLP perform?}} Surprisingly, we find that GNNs\ninitialized with such weights significantly outperform their PeerMLPs,\nmotivating us to use PeerMLP training as a precursor, initialization step to\nGNN training. To this end, we propose an embarrassingly simple, yet hugely\neffective initialization method for GNN training acceleration, called MLPInit.\nOur extensive experiments on multiple large-scale graph datasets with diverse\nGNN architectures validate that MLPInit can accelerate the training of GNNs (up\nto 33X speedup on OGB-Products) and often improve prediction performance (e.g.,\nup to $7.97\\%$ improvement for GraphSAGE across $7$ datasets for node\nclassification, and up to $17.81\\%$ improvement across $4$ datasets for link\nprediction on metric Hits@10). The code is available at\n\\href{https://github.com/snap-research/MLPInit-for-GNNs}.\n","authors":["Xiaotian Han","Tong Zhao","Yozen Liu","Xia Hu","Neil Shah"],"pdf_url":"https://arxiv.org/pdf/2210.00102v2.pdf","comment":"Accepted by ICLR2023"},{"id":"http://arxiv.org/abs/2303.03628v1","updated":"2023-03-07T03:23:14Z","published":"2023-03-07T03:23:14Z","title":"CoTEVer: Chain of Thought Prompting Annotation Toolkit for Explanation\n  Verification","summary":"  Chain-of-thought (CoT) prompting enables large language models (LLMs) to\nsolve complex reasoning tasks by generating an explanation before the final\nprediction. Despite it's promising ability, a critical downside of CoT\nprompting is that the performance is greatly affected by the factuality of the\ngenerated explanation. To improve the correctness of the explanations,\nfine-tuning language models with explanation data is needed. However, there\nexists only a few datasets that can be used for such approaches, and no data\ncollection tool for building them. Thus, we introduce CoTEVer, a tool-kit for\nannotating the factual correctness of generated explanations and collecting\nrevision data of wrong explanations. Furthermore, we suggest several use cases\nwhere the data collected with CoTEVer can be utilized for enhancing the\nfaithfulness of explanations. Our toolkit is publicly available at\nhttps://github.com/SeungoneKim/CoTEVer.\n","authors":["Seungone Kim","Se June Joo","Yul Jang","Hyungjoo Chae","Jinyoung Yeo"],"pdf_url":"https://arxiv.org/pdf/2303.03628v1.pdf","comment":"Accepted at EACL 2023 Demo"},{"id":"http://arxiv.org/abs/2110.06482v3","updated":"2023-03-07T03:01:00Z","published":"2021-10-13T04:03:51Z","title":"Parallel Deep Neural Networks Have Zero Duality Gap","summary":"  Training deep neural networks is a challenging non-convex optimization\nproblem. Recent work has proven that the strong duality holds (which means zero\nduality gap) for regularized finite-width two-layer ReLU networks and\nconsequently provided an equivalent convex training problem. However, extending\nthis result to deeper networks remains to be an open problem. In this paper, we\nprove that the duality gap for deeper linear networks with vector outputs is\nnon-zero. In contrast, we show that the zero duality gap can be obtained by\nstacking standard deep networks in parallel, which we call a parallel\narchitecture, and modifying the regularization. Therefore, we prove the strong\nduality and existence of equivalent convex problems that enable globally\noptimal training of deep networks. As a by-product of our analysis, we\ndemonstrate that the weight decay regularization on the network parameters\nexplicitly encourages low-rank solutions via closed-form expressions. In\naddition, we show that strong duality holds for three-layer standard ReLU\nnetworks given rank-1 data matrices.\n","authors":["Yifei Wang","Tolga Ergen","Mert Pilanci"],"pdf_url":"https://arxiv.org/pdf/2110.06482v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03611v1","updated":"2023-03-07T02:56:15Z","published":"2023-03-07T02:56:15Z","title":"TinyAD: Memory-efficient anomaly detection for time series data in\n  Industrial IoT","summary":"  Monitoring and detecting abnormal events in cyber-physical systems is crucial\nto industrial production. With the prevalent deployment of the Industrial\nInternet of Things (IIoT), an enormous amount of time series data is collected\nto facilitate machine learning models for anomaly detection, and it is of the\nutmost importance to directly deploy the trained models on the IIoT devices.\nHowever, it is most challenging to deploy complex deep learning models such as\nConvolutional Neural Networks (CNNs) on these memory-constrained IIoT devices\nembedded with microcontrollers (MCUs). To alleviate the memory constraints of\nMCUs, we propose a novel framework named Tiny Anomaly Detection (TinyAD) to\nefficiently facilitate onboard inference of CNNs for real-time anomaly\ndetection. First, we conduct a comprehensive analysis of depthwise separable\nCNNs and regular CNNs for anomaly detection and find that the depthwise\nseparable convolution operation can reduce the model size by 50-90% compared\nwith the traditional CNNs. Then, to reduce the peak memory consumption of CNNs,\nwe explore two complementary strategies, in-place, and patch-by-patch memory\nrescheduling, and integrate them into a unified framework. The in-place method\ndecreases the peak memory of the depthwise convolution by sparing a temporary\nbuffer to transfer the activation results, while the patch-by-patch method\nfurther reduces the peak memory of layer-wise execution by slicing the input\ndata into corresponding receptive fields and executing in order. Furthermore,\nby adjusting the dimension of convolution filters, these strategies apply to\nboth univariate time series and multidomain time series features. Extensive\nexperiments on real-world industrial datasets show that our framework can\nreduce peak memory consumption by 2-5x with negligible computation overhead.\n","authors":["Yuting Sun","Tong Chen","Quoc Viet Hung Nguyen","Hongzhi Yin"],"pdf_url":"https://arxiv.org/pdf/2303.03611v1.pdf","comment":"Accepted by IEEE Transactions on Industrial Informatics"},{"id":"http://arxiv.org/abs/2211.08064v2","updated":"2023-03-07T02:46:34Z","published":"2022-11-15T11:34:30Z","title":"Physics-Informed Machine Learning: A Survey on Problems, Methods and\n  Applications","summary":"  Recent advances of data-driven machine learning have revolutionized fields\nlike computer vision, reinforcement learning, and many scientific and\nengineering domains. In many real-world and scientific problems, systems that\ngenerate data are governed by physical laws. Recent work shows that it provides\npotential benefits for machine learning models by incorporating the physical\nprior and collected data, which makes the intersection of machine learning and\nphysics become a prevailing paradigm. By integrating the data and mathematical\nphysics models seamlessly, it can guide the machine learning model towards\nsolutions that are physically plausible, improving accuracy and efficiency even\nin uncertain and high-dimensional contexts. In this survey, we present this\nlearning paradigm called Physics-Informed Machine Learning (PIML) which is to\nbuild a model that leverages empirical data and available physical prior\nknowledge to improve performance on a set of tasks that involve a physical\nmechanism. We systematically review the recent development of physics-informed\nmachine learning from three perspectives of machine learning tasks,\nrepresentation of physical prior, and methods for incorporating physical prior.\nWe also propose several important open research problems based on the current\ntrends in the field. We argue that encoding different forms of physical prior\ninto model architectures, optimizers, inference algorithms, and significant\ndomain-specific applications like inverse engineering design and robotic\ncontrol is far from being fully explored in the field of physics-informed\nmachine learning. We believe that the interdisciplinary research of\nphysics-informed machine learning will significantly propel research progress,\nfoster the creation of more effective machine learning models, and also offer\ninvaluable assistance in addressing long-standing problems in related\ndisciplines.\n","authors":["Zhongkai Hao","Songming Liu","Yichi Zhang","Chengyang Ying","Yao Feng","Hang Su","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2211.08064v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.17244v2","updated":"2023-03-07T02:43:20Z","published":"2022-11-30T18:46:00Z","title":"Tight Certification of Adversarially Trained Neural Networks via\n  Nonconvex Low-Rank Semidefinite Relaxations","summary":"  Adversarial training is well-known to produce high-quality neural network\nmodels that are empirically robust against adversarial perturbations.\nNevertheless, once a model has been adversarially trained, one often desires a\ncertification that the model is truly robust against all future attacks.\nUnfortunately, when faced with adversarially trained models, all existing\napproaches have significant trouble making certifications that are strong\nenough to be practically useful. Linear programming (LP) techniques in\nparticular face a \"convex relaxation barrier\" that prevent them from making\nhigh-quality certifications, even after refinement with mixed-integer linear\nprogramming (MILP) techniques, and even when using state-of-the-art\ncomputational facilities. In this paper, we propose a nonconvex certification\ntechnique, based on a low-rank restriction of a semidefinite programming (SDP)\nrelaxation. The nonconvex relaxation makes strong certifications comparable to\nmuch more expensive SDP methods, while optimizing over dramatically fewer\nvariables comparable to much weaker LP methods. Despite nonconvexity, we show\nhow off-the-shelf local optimization algorithms can be used to achieve and to\ncertify global optimality in polynomial time. Our experiments find that the\nnonconvex relaxation almost completely closes the gap towards exact\ncertification of adversarially trained models.\n","authors":["Hong-Ming Chiu","Richard Y. Zhang"],"pdf_url":"https://arxiv.org/pdf/2211.17244v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2209.04526v2","updated":"2023-03-07T02:42:45Z","published":"2022-09-09T21:03:43Z","title":"Gluformer: Transformer-Based Personalized Glucose Forecasting with\n  Uncertainty Quantification","summary":"  Deep learning models achieve state-of-the art results in predicting blood\nglucose trajectories, with a wide range of architectures being proposed.\nHowever, the adaptation of such models in clinical practice is slow, largely\ndue to the lack of uncertainty quantification of provided predictions. In this\nwork, we propose to model the future glucose trajectory conditioned on the past\nas an infinite mixture of basis distributions (i.e., Gaussian, Laplace, etc.).\nThis change allows us to learn the uncertainty and predict more accurately in\nthe cases when the trajectory has a heterogeneous or multi-modal distribution.\nTo estimate the parameters of the predictive distribution, we utilize the\nTransformer architecture. We empirically demonstrate the superiority of our\nmethod over existing state-of-the-art techniques both in terms of accuracy and\nuncertainty on the synthetic and benchmark glucose data sets.\n","authors":["Renat Sergazinov","Mohammadreza Armandpour","Irina Gaynanova"],"pdf_url":"https://arxiv.org/pdf/2209.04526v2.pdf","comment":"5 pages, 2 figures, IEEE ICASSP"},{"id":"http://arxiv.org/abs/2303.03600v1","updated":"2023-03-07T02:31:57Z","published":"2023-03-07T02:31:57Z","title":"Adaptive Knowledge Distillation between Text and Speech Pre-trained\n  Models","summary":"  Learning on a massive amount of speech corpus leads to the recent success of\nmany self-supervised speech models. With knowledge distillation, these models\nmay also benefit from the knowledge encoded by language models that are\npre-trained on rich sources of texts. The distillation process, however, is\nchallenging due to the modal disparity between textual and speech embedding\nspaces. This paper studies metric-based distillation to align the embedding\nspace of text and speech with only a small amount of data without modifying the\nmodel structure. Since the semantic and granularity gap between text and speech\nhas been omitted in literature, which impairs the distillation, we propose the\nPrior-informed Adaptive knowledge Distillation (PAD) that adaptively leverages\ntext/speech units of variable granularity and prior distributions to achieve\nbetter global and local alignments between text and speech pre-trained models.\nWe evaluate on three spoken language understanding benchmarks to show that PAD\nis more effective in transferring linguistic knowledge than other metric-based\ndistillation approaches.\n","authors":["Jinjie Ni","Yukun Ma","Wen Wang","Qian Chen","Dianwen Ng","Han Lei","Trung Hieu Nguyen","Chong Zhang","Bin Ma","Erik Cambria"],"pdf_url":"https://arxiv.org/pdf/2303.03600v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.00030v2","updated":"2023-03-07T02:29:59Z","published":"2022-09-30T18:14:07Z","title":"VIP: Towards Universal Visual Reward and Representation via\n  Value-Implicit Pre-Training","summary":"  Reward and representation learning are two long-standing challenges for\nlearning an expanding set of robot manipulation skills from sensory\nobservations. Given the inherent cost and scarcity of in-domain, task-specific\nrobot data, learning from large, diverse, offline human videos has emerged as a\npromising path towards acquiring a generally useful visual representation for\ncontrol; however, how these human videos can be used for general-purpose reward\nlearning remains an open question. We introduce\n$\\textbf{V}$alue-$\\textbf{I}$mplicit $\\textbf{P}$re-training (VIP), a\nself-supervised pre-trained visual representation capable of generating dense\nand smooth reward functions for unseen robotic tasks. VIP casts representation\nlearning from human videos as an offline goal-conditioned reinforcement\nlearning problem and derives a self-supervised dual goal-conditioned\nvalue-function objective that does not depend on actions, enabling pre-training\non unlabeled human videos. Theoretically, VIP can be understood as a novel\nimplicit time contrastive objective that generates a temporally smooth\nembedding, enabling the value function to be implicitly defined via the\nembedding distance, which can then be used to construct the reward for any\ngoal-image specified downstream task. Trained on large-scale Ego4D human videos\nand without any fine-tuning on in-domain, task-specific data, VIP's frozen\nrepresentation can provide dense visual reward for an extensive set of\nsimulated and $\\textbf{real-robot}$ tasks, enabling diverse reward-based visual\ncontrol methods and significantly outperforming all prior pre-trained\nrepresentations. Notably, VIP can enable simple, $\\textbf{few-shot}$ offline RL\non a suite of real-world robot tasks with as few as 20 trajectories.\n","authors":["Yecheng Jason Ma","Shagun Sodhani","Dinesh Jayaraman","Osbert Bastani","Vikash Kumar","Amy Zhang"],"pdf_url":"https://arxiv.org/pdf/2210.00030v2.pdf","comment":"ICLR 2023, Notable-Top-25% (Spotlight). Project website:\n  https://sites.google.com/view/vip-rl"},{"id":"http://arxiv.org/abs/2207.08894v3","updated":"2023-03-07T02:26:25Z","published":"2022-07-18T19:07:56Z","title":"A Deep Reinforcement Learning Approach for Finding Non-Exploitable\n  Strategies in Two-Player Atari Games","summary":"  This paper proposes new, end-to-end deep reinforcement learning algorithms\nfor learning two-player zero-sum Markov games. Different from prior efforts on\ntraining agents to beat a fixed set of opponents, our objective is to find the\nNash equilibrium policies that are free from exploitation by even the\nadversarial opponents. We propose (a) Nash-DQN algorithm, which integrates the\ndeep learning techniques from single DQN into the classic Nash Q-learning\nalgorithm for solving tabular Markov games; (b) Nash-DQN-Exploiter algorithm,\nwhich additionally adopts an exploiter to guide the exploration of the main\nagent. We conduct experimental evaluation on tabular examples as well as\nvarious two-player Atari games. Our empirical results demonstrate that (i) the\npolicies found by many existing methods including Neural Fictitious Self Play\nand Policy Space Response Oracle can be prone to exploitation by adversarial\nopponents; (ii) the output policies of our algorithms are robust to\nexploitation, and thus outperform existing methods.\n","authors":["Zihan Ding","Dijia Su","Qinghua Liu","Chi Jin"],"pdf_url":"https://arxiv.org/pdf/2207.08894v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.14311v2","updated":"2023-03-07T02:18:36Z","published":"2023-02-28T05:01:01Z","title":"Towards Memory- and Time-Efficient Backpropagation for Training Spiking\n  Neural Networks","summary":"  Spiking Neural Networks (SNNs) are promising energy-efficient models for\nneuromorphic computing. For training the non-differentiable SNN models, the\nbackpropagation through time (BPTT) with surrogate gradients (SG) method has\nachieved high performance. However, this method suffers from considerable\nmemory cost and training time during training. In this paper, we propose the\nSpatial Learning Through Time (SLTT) method that can achieve high performance\nwhile greatly improving training efficiency compared with BPTT. First, we show\nthat the backpropagation of SNNs through the temporal domain contributes just a\nlittle to the final calculated gradients. Thus, we propose to ignore the\nunimportant routes in the computational graph during backpropagation. The\nproposed method reduces the number of scalar multiplications and achieves a\nsmall memory occupation that is independent of the total time steps.\nFurthermore, we propose a variant of SLTT, called SLTT-K, that allows\nbackpropagation only at K time steps, then the required number of scalar\nmultiplications is further reduced and is independent of the total time steps.\nExperiments on both static and neuromorphic datasets demonstrate superior\ntraining efficiency and performance of our SLTT. In particular, our method\nachieves state-of-the-art accuracy on ImageNet, while the memory cost and\ntraining time are reduced by more than 70% and 50%, respectively, compared with\nBPTT.\n","authors":["Qingyan Meng","Mingqing Xiao","Shen Yan","Yisen Wang","Zhouchen Lin","Zhi-Quan Luo"],"pdf_url":"https://arxiv.org/pdf/2302.14311v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.02307v3","updated":"2023-03-07T02:14:39Z","published":"2022-06-06T01:30:03Z","title":"Bootstrapping Semi-supervised Medical Image Segmentation with\n  Anatomical-aware Contrastive Distillation","summary":"  Contrastive learning has shown great promise over annotation scarcity\nproblems in the context of medical image segmentation. Existing approaches\ntypically assume a balanced class distribution for both labeled and unlabeled\nmedical images. However, medical image data in reality is commonly imbalanced\n(i.e., multi-class label imbalance), which naturally yields blurry contours and\nusually incorrectly labels rare objects. Moreover, it remains unclear whether\nall negative samples are equally negative. In this work, we present ACTION, an\nAnatomical-aware ConTrastive dIstillatiON framework, for semi-supervised\nmedical image segmentation. Specifically, we first develop an iterative\ncontrastive distillation algorithm by softly labeling the negatives rather than\nbinary supervision between positive and negative pairs. We also capture more\nsemantically similar features from the randomly chosen negative set compared to\nthe positives to enforce the diversity of the sampled data. Second, we raise a\nmore important question: Can we really handle imbalanced samples to yield\nbetter performance? Hence, the key innovation in ACTION is to learn global\nsemantic relationship across the entire dataset and local anatomical features\namong the neighbouring pixels with minimal additional memory footprint. During\nthe training, we introduce anatomical contrast by actively sampling a sparse\nset of hard negative pixels, which can generate smoother segmentation\nboundaries and more accurate predictions. Extensive experiments across two\nbenchmark datasets and different unlabeled settings show that ACTION\nsignificantly outperforms the current state-of-the-art semi-supervised methods.\n","authors":["Chenyu You","Weicheng Dai","Yifei Min","Lawrence Staib","James S. Duncan"],"pdf_url":"https://arxiv.org/pdf/2206.02307v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.02733v2","updated":"2023-03-07T02:07:01Z","published":"2023-03-05T17:57:33Z","title":"Reparameterization through Spatial Gradient Scaling","summary":"  Reparameterization aims to improve the generalization of deep neural networks\nby transforming convolutional layers into equivalent multi-branched structures\nduring training. However, there exists a gap in understanding how\nreparameterization may change and benefit the learning process of neural\nnetworks. In this paper, we present a novel spatial gradient scaling method to\nredistribute learning focus among weights in convolutional networks. We prove\nthat spatial gradient scaling achieves the same learning dynamics as a branched\nreparameterization yet without introducing structural changes into the network.\nWe further propose an analytical approach that dynamically learns scalings for\neach convolutional layer based on the spatial characteristics of its input\nfeature map gauged by mutual information. Experiments on CIFAR-10, CIFAR-100,\nand ImageNet show that without searching for reparameterized structures, our\nproposed scaling method outperforms the state-of-the-art reparameterization\nstrategies at a lower computational cost.\n","authors":["Alexander Detkov","Mohammad Salameh","Muhammad Fetrat Qharabagh","Jialin Zhang","Wei Lui","Shangling Jui","Di Niu"],"pdf_url":"https://arxiv.org/pdf/2303.02733v2.pdf","comment":"Published at ICLR 2023. Code available at\n  https://github.com/Ascend-Research/Reparameterization"},{"id":"http://arxiv.org/abs/2303.03593v1","updated":"2023-03-07T01:57:10Z","published":"2023-03-07T01:57:10Z","title":"ADELT: Transpilation Between Deep Learning Frameworks","summary":"  We propose Adversarial DEep Learning Transpiler (ADELT) for source-to-source\ntranspilation between deep learning frameworks. Unlike prior approaches, we\ndecouple the transpilation of code skeletons and the mapping of API keywords\n(an API function name or a parameter name). ADELT transpile code skeletons\nusing few-shot prompting on big language models. Based on contextual embeddings\nextracted by a BERT for code, we train aligned API embeddings in a\ndomain-adversarial setup, upon which we generate a dictionary for keyword\ntranslation. The model is trained on our unlabeled DL corpus from web crawl\ndata, without using any hand-crafted rules and parallel data. Our method\noutperforms state-of-the-art transpilers on multiple transpilation pairs\nincluding PyTorch-Keras and PyTorch-MXNet by 15.9pts and 12.0pts in exact match\nscores respectively.\n","authors":["Linyuan Gong","Jiayi Wang","Alvin Cheung"],"pdf_url":"https://arxiv.org/pdf/2303.03593v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2303.02219v2","updated":"2023-03-07T01:56:56Z","published":"2023-03-03T21:24:51Z","title":"NSGA-PINN: A Multi-Objective Optimization Method for Physics-Informed\n  Neural Network Training","summary":"  This paper presents NSGA-PINN, a multi-objective optimization framework for\neffective training of Physics-Informed Neural Networks (PINNs). The proposed\nframework uses the Non-dominated Sorting Genetic Algorithm (NSGA-II) to enable\ntraditional stochastic gradient optimization algorithms (e.g., ADAM) to escape\nlocal minima effectively. Additionally, the NSGA-II algorithm enables\nsatisfying the initial and boundary conditions encoded into the loss function\nduring physics-informed training precisely. We demonstrate the effectiveness of\nour framework by applying NSGA-PINN to several ordinary and partial\ndifferential equation problems. In particular, we show that the proposed\nframework can handle challenging inverse problems with noisy data.\n","authors":["Binghang Lu","Christian B. Moya","Guang Lin"],"pdf_url":"https://arxiv.org/pdf/2303.02219v2.pdf","comment":"13 pages, 35 figures"},{"id":"http://arxiv.org/abs/2303.03592v1","updated":"2023-03-07T01:55:26Z","published":"2023-03-07T01:55:26Z","title":"Exploring the Limits of Indiscriminate Data Poisoning Attacks","summary":"  Indiscriminate data poisoning attacks aim to decrease a model's test accuracy\nby injecting a small amount of corrupted training data. Despite significant\ninterest, existing attacks remain relatively ineffective against modern machine\nlearning (ML) architectures. In this work, we introduce the notion of model\npoisonability as a technical tool to explore the intrinsic limits of data\npoisoning attacks. We derive an easily computable threshold to establish and\nquantify a surprising phase transition phenomenon among popular ML models: data\npoisoning attacks become effective only when the poisoning ratio exceeds our\nthreshold. Building on existing parameter corruption attacks and refining the\nGradient Canceling attack, we perform extensive experiments to confirm our\ntheoretical findings, test the predictability of our transition threshold, and\nsignificantly improve existing data poisoning baselines over a range of\ndatasets and models. Our work highlights the critical role played by the\npoisoning ratio, and sheds new insights on existing empirical results, attacks\nand mitigation strategies in data poisoning.\n","authors":["Yiwei Lu","Gautam Kamth","Yaoliang Yu"],"pdf_url":"https://arxiv.org/pdf/2303.03592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03591v1","updated":"2023-03-07T01:54:24Z","published":"2023-03-07T01:54:24Z","title":"Approach to Learning Generalized Audio Representation Through Batch\n  Embedding Covariance Regularization and Constant-Q Transforms","summary":"  General-purpose embedding is highly desirable for few-shot even zero-shot\nlearning in many application scenarios, including audio tasks. In order to\nunderstand representations better, we conducted a thorough error analysis and\nvisualization of HEAR 2021 submission results. Inspired by the analysis, this\nwork experiments with different front-end audio preprocessing methods,\nincluding Constant-Q Transform (CQT) and Short-time Fourier transform (STFT),\nand proposes a Batch Embedding Covariance Regularization (BECR) term to uncover\na more holistic simulation of the frequency information received by the human\nauditory system. We tested the models on the suite of HEAR 2021 tasks, which\nencompass a broad category of tasks. Preliminary results show (1) the proposed\nBECR can incur a more dispersed embedding on the test set, (2) BECR improves\nthe PaSST model without extra computation complexity, and (3) STFT\npreprocessing outperforms CQT in all tasks we tested.\nGithub:https://github.com/ankitshah009/general_audio_embedding_hear_2021\n","authors":["Ankit Shah","Shuyi Chen","Kejun Zhou","Yue Chen","Bhiksha Raj"],"pdf_url":"https://arxiv.org/pdf/2303.03591v1.pdf","comment":"Technical report, 10 pages"},{"id":"http://arxiv.org/abs/2303.03590v1","updated":"2023-03-07T01:52:55Z","published":"2023-03-07T01:52:55Z","title":"Research on Efficient Fuzzy Clustering Method Based on Local Fuzzy\n  Granules","summary":"  In recent years, the problem of fuzzy clustering has been widely concerned.\nThe membership iteration of existing methods is mostly considered globally,\nwhich has considerable problems in noisy environments, and iterative\ncalculations for clusters with a large number of different sample sizes are not\naccurate and efficient. In this paper, starting from the strategy of\nlarge-scale priority, the data is fuzzy iterated using granular-balls, and the\nmembership degree of data only considers the two granular-balls where it is\nlocated, thus improving the efficiency of iteration. The formed fuzzy\ngranular-balls set can use more processing methods in the face of different\ndata scenarios, which enhances the practicability of fuzzy clustering\ncalculations.\n","authors":["Jiang Xie","Qiao Deng","Shuyin Xia","Yangzhou Zhao","Guoyin Wang","Xinbo Gao"],"pdf_url":"https://arxiv.org/pdf/2303.03590v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03577v1","updated":"2023-03-07T01:14:54Z","published":"2023-03-07T01:14:54Z","title":"A Review of and Roadmap for Data Science and Machine Learning for the\n  Neuropsychiatric Phenotype of Autism","summary":"  Autism Spectrum Disorder (autism) is a neurodevelopmental delay which affects\nat least 1 in 44 children. Like many neurological disorder phenotypes, the\ndiagnostic features are observable, can be tracked over time, and can be\nmanaged or even eliminated through proper therapy and treatments. Yet, there\nare major bottlenecks in the diagnostic, therapeutic, and longitudinal tracking\npipelines for autism and related delays, creating an opportunity for novel data\nscience solutions to augment and transform existing workflows and provide\naccess to services for more affected families. Several prior efforts conducted\nby a multitude of research labs have spawned great progress towards improved\ndigital diagnostics and digital therapies for children with autism. We review\nthe literature of digital health methods for autism behavior quantification\nusing data science. We describe both case-control studies and classification\nsystems for digital phenotyping. We then discuss digital diagnostics and\ntherapeutics which integrate machine learning models of autism-related\nbehaviors, including the factors which must be addressed for translational use.\nFinally, we describe ongoing challenges and potent opportunities for the field\nof autism data science. Given the heterogeneous nature of autism and the\ncomplexities of the relevant behaviors, this review contains insights which are\nrelevant to neurological behavior analysis and digital psychiatry more broadly.\n","authors":["Peter Washington","Dennis P. Wall"],"pdf_url":"https://arxiv.org/pdf/2303.03577v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.08987v2","updated":"2023-03-07T01:10:53Z","published":"2023-01-21T18:05:59Z","title":"Tier Balancing: Towards Dynamic Fairness over Underlying Causal Factors","summary":"  The pursuit of long-term fairness involves the interplay between\ndecision-making and the underlying data generating process. In this paper,\nthrough causal modeling with a directed acyclic graph (DAG) on the\ndecision-distribution interplay, we investigate the possibility of achieving\nlong-term fairness from a dynamic perspective. We propose Tier Balancing, a\ntechnically more challenging but more natural notion to achieve in the context\nof long-term, dynamic fairness analysis. Different from previous fairness\nnotions that are defined purely on observed variables, our notion goes one step\nfurther, capturing behind-the-scenes situation changes on the unobserved latent\ncausal factors that directly carry out the influence from the current decision\nto the future data distribution. Under the specified dynamics, we prove that in\ngeneral one cannot achieve the long-term fairness goal only through one-step\ninterventions. Furthermore, in the effort of approaching long-term fairness, we\nconsider the mission of \"getting closer to\" the long-term fairness goal and\npresent possibility and impossibility results accordingly.\n","authors":["Zeyu Tang","Yatong Chen","Yang Liu","Kun Zhang"],"pdf_url":"https://arxiv.org/pdf/2301.08987v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2010.13934v3","updated":"2023-03-07T00:58:23Z","published":"2020-10-26T22:37:49Z","title":"Accelerate the Warm-up Stage in the Lasso Computation via a Homotopic\n  Approach","summary":"  In optimization, it is known that when the objective functions are strictly\nconvex and well-conditioned, gradient-based approaches can be extremely\neffective, e.g., achieving the exponential rate of convergence. On the other\nhand, the existing Lasso-type estimator in general cannot achieve the optimal\nrate due to the undesirable behavior of the absolute function at the origin. A\nhomotopic method is to use a sequence of surrogate functions to approximate the\n$\\ell_1$ penalty that is used in the Lasso-type of estimators. The surrogate\nfunctions will converge to the $\\ell_1$ penalty in the Lasso estimator. At the\nsame time, each surrogate function is strictly convex, which enables a provable\nfaster numerical rate of convergence. In this paper, we demonstrate that by\nmeticulously defining the surrogate functions, one can prove a faster numerical\nconvergence rate than any existing methods in computing for the Lasso-type of\nestimators. Namely, the state-of-the-art algorithms can only guarantee\n$O(1/\\epsilon)$ or $O(1/\\sqrt{\\epsilon})$ convergence rates, while we can prove\nan $O([\\log(1/\\epsilon)]^2)$ for the newly proposed algorithm. Our numerical\nsimulations show that the new algorithm also performs better empirically.\n","authors":["Yujie Zhao","Xiaoming Huo"],"pdf_url":"https://arxiv.org/pdf/2010.13934v3.pdf","comment":"19 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2303.03572v1","updated":"2023-03-07T00:46:04Z","published":"2023-03-07T00:46:04Z","title":"Learning When to Treat Business Processes: Prescriptive Process\n  Monitoring with Causal Inference and Reinforcement Learning","summary":"  Increasing the success rate of a process, i.e. the percentage of cases that\nend in a positive outcome, is a recurrent process improvement goal. At runtime,\nthere are often certain actions (a.k.a. treatments) that workers may execute to\nlift the probability that a case ends in a positive outcome. For example, in a\nloan origination process, a possible treatment is to issue multiple loan offers\nto increase the probability that the customer takes a loan. Each treatment has\na cost. Thus, when defining policies for prescribing treatments to cases,\nmanagers need to consider the net gain of the treatments. Also, the effect of a\ntreatment varies over time: treating a case earlier may be more effective than\nlater in a case. This paper presents a prescriptive monitoring method that\nautomates this decision-making task. The method combines causal inference and\nreinforcement learning to learn treatment policies that maximize the net gain.\nThe method leverages a conformal prediction technique to speed up the\nconvergence of the reinforcement learning mechanism by separating cases that\nare likely to end up in a positive or negative outcome, from uncertain cases.\nAn evaluation on two real-life datasets shows that the proposed method\noutperforms a state-of-the-art baseline.\n","authors":["Zahra Dasht Bozorgi","Marlon Dumas","Marcello La Rosa","Artem Polyvyanyy","Mahmoud Shoush","Irene Teinemaa"],"pdf_url":"https://arxiv.org/pdf/2303.03572v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2205.09244v4","updated":"2023-03-07T00:12:00Z","published":"2022-05-18T23:32:20Z","title":"Riemannian Metric Learning via Optimal Transport","summary":"  We introduce an optimal transport-based model for learning a metric tensor\nfrom cross-sectional samples of evolving probability measures on a common\nRiemannian manifold. We neurally parametrize the metric as a spatially-varying\nmatrix field and efficiently optimize our model's objective using a simple\nalternating scheme. Using this learned metric, we can nonlinearly interpolate\nbetween probability measures and compute geodesics on the manifold. We show\nthat metrics learned using our method improve the quality of trajectory\ninference on scRNA and bird migration data at the cost of little additional\ncross-sectional data.\n","authors":["Christopher Scarvelis","Justin Solomon"],"pdf_url":"https://arxiv.org/pdf/2205.09244v4.pdf","comment":"ICLR 2023"},{"id":"http://arxiv.org/abs/2106.02968v4","updated":"2023-03-07T00:09:11Z","published":"2021-06-05T21:25:03Z","title":"Low Budget Active Learning via Wasserstein Distance: An Integer\n  Programming Approach","summary":"  Active learning is the process of training a model with limited labeled data\nby selecting a core subset of an unlabeled data pool to label. The large scale\nof data sets used in deep learning forces most sample selection strategies to\nemploy efficient heuristics. This paper introduces an integer optimization\nproblem for selecting a core set that minimizes the discrete Wasserstein\ndistance from the unlabeled pool. We demonstrate that this problem can be\ntractably solved with a Generalized Benders Decomposition algorithm. Our\nstrategy uses high-quality latent features that can be obtained by unsupervised\nlearning on the unlabeled pool. Numerical results on several data sets show\nthat our optimization approach is competitive with baselines and particularly\noutperforms them in the low budget regime where less than one percent of the\ndata set is labeled.\n","authors":["Rafid Mahmood","Sanja Fidler","Marc T. Law"],"pdf_url":"https://arxiv.org/pdf/2106.02968v4.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2303.04027v1","updated":"2023-03-07T16:39:09Z","published":"2023-03-07T16:39:09Z","title":"BIRD-PCC: Bi-directional Range Image-based Deep LiDAR Point Cloud\n  Compression","summary":"  The large amount of data collected by LiDAR sensors brings the issue of LiDAR\npoint cloud compression (PCC). Previous works on range image-based LiDAR PCC\nfollow the predictive coding paradigm, structuring a simple prototype of a\ncoding framework. However, their prediction methods give an inaccurate result\ndue to the negligence of invalid pixels in range images and the omission of\nfuture frames in the time step. Moreover, their handcrafted design of residual\ncoding methods could not fully exploit spatial redundancy. To remedy this, we\npropose a coding framework BIRD-PCC. Our prediction module is aware of the\ncoordinates of invalid pixels in range images and takes a bidirectional scheme.\nAlso, we introduce a deep-learned residual coding module that can further\nexploit spatial redundancy within a residual frame. Experiments conducted on\nSemanticKITTI and KITTI-360 datasets show that BIRD-PCC outperforms other\nmethods in most bitrate conditions and generalizes well to unseen environments.\n","authors":["Chia-Sheng Liu","Jia-Fong Yeh","Hao Hsu","Hung-Ting Su","Ming-Sui Lee","Winston H. Hsu"],"pdf_url":"https://arxiv.org/pdf/2303.04027v1.pdf","comment":"Accepted to ICASSP 2023"},{"id":"http://arxiv.org/abs/2209.08212v4","updated":"2023-03-07T14:19:17Z","published":"2022-09-17T01:20:59Z","title":"Compose & Embellish: Well-Structured Piano Performance Generation via A\n  Two-Stage Approach","summary":"  Even with strong sequence models like Transformers, generating expressive\npiano performances with long-range musical structures remains challenging.\nMeanwhile, methods to compose well-structured melodies or lead sheets (melody +\nchords), i.e., simpler forms of music, gained more success. Observing the\nabove, we devise a two-stage Transformer-based framework that Composes a lead\nsheet first, and then Embellishes it with accompaniment and expressive touches.\nSuch a factorization also enables pretraining on non-piano data. Our objective\nand subjective experiments show that Compose & Embellish shrinks the gap in\nstructureness between a current state of the art and real performances by half,\nand improves other musical aspects such as richness and coherence as well.\n","authors":["Shih-Lun Wu","Yi-Hsuan Yang"],"pdf_url":"https://arxiv.org/pdf/2209.08212v4.pdf","comment":"Accepted to International Conference on Acoustics, Speech, and Signal\n  Processing (ICASSP) 2023"},{"id":"http://arxiv.org/abs/2106.06924v3","updated":"2023-03-07T14:05:05Z","published":"2021-06-13T05:32:17Z","title":"Deep Learning for Predictive Analytics in Reversible Steganography","summary":"  Deep learning is regarded as a promising solution for reversible\nsteganography. There is an accelerating trend of representing a reversible\nsteo-system by monolithic neural networks, which bypass intermediate operations\nin traditional pipelines of reversible steganography. This end-to-end paradigm,\nhowever, suffers from imperfect reversibility. By contrast, the modular\nparadigm that incorporates neural networks into modules of traditional\npipelines can stably guarantee reversibility with mathematical explainability.\nPrediction-error modulation is a well-established reversible steganography\npipeline for digital images. It consists of a predictive analytics module and a\nreversible coding module. Given that reversibility is governed independently by\nthe coding module, we narrow our focus to the incorporation of neural networks\ninto the analytics module, which serves the purpose of predicting pixel\nintensities and a pivotal role in determining capacity and imperceptibility.\nThe objective of this study is to evaluate the impacts of different training\nconfigurations upon predictive accuracy of neural networks and provide\npractical insights. In particular, we investigate how different initialisation\nstrategies for input images may affect the learning process and how different\ntraining strategies for dual-layer prediction respond to the problem of\ndistributional shift. Furthermore, we compare steganographic performance of\nvarious model architectures with different loss functions.\n","authors":["Ching-Chun Chang","Xu Wang","Sisheng Chen","Isao Echizen","Victor Sanchez","Chang-Tsun Li"],"pdf_url":"https://arxiv.org/pdf/2106.06924v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2201.02478v2","updated":"2023-03-07T13:11:04Z","published":"2022-01-07T14:56:33Z","title":"Bayesian Neural Networks for Reversible Steganography","summary":"  Recent advances in deep learning have led to a paradigm shift in the field of\nreversible steganography. A fundamental pillar of reversible steganography is\npredictive modelling which can be realised via deep neural networks. However,\nnon-trivial errors exist in inferences about some out-of-distribution and noisy\ndata. In view of this issue, we propose to consider uncertainty in predictive\nmodels based upon a theoretical framework of Bayesian deep learning, thereby\ncreating an adaptive steganographic system. Most modern deep-learning models\nare regarded as deterministic because they only offer predictions while failing\nto provide uncertainty measurement. Bayesian neural networks bring a\nprobabilistic perspective to deep learning and can be regarded as self-aware\nintelligent machinery; that is, a machine that knows its own limitations. To\nquantify uncertainty, we apply Bayesian statistics to model the predictive\ndistribution and approximate it through Monte Carlo sampling with stochastic\nforward passes. We further show that predictive uncertainty can be disentangled\ninto aleatoric and epistemic uncertainties and these quantities can be learnt\nunsupervised. Experimental results demonstrate an improvement delivered by\nBayesian uncertainty analysis upon steganographic rate-distortion performance.\n","authors":["Ching-Chun Chang"],"pdf_url":"https://arxiv.org/pdf/2201.02478v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.02518v2","updated":"2023-03-07T12:55:55Z","published":"2022-02-05T09:04:50Z","title":"On the predictability in reversible steganography","summary":"  Artificial neural networks have advanced the frontiers of reversible\nsteganography. The core strength of neural networks is the ability to render\naccurate predictions for a bewildering variety of data. Residual modulation is\nrecognised as the most advanced reversible steganographic algorithm for digital\nimages. The pivot of this algorithm is predictive analytics in which pixel\nintensities are predicted given some pixel-wise contextual information. This\ntask can be perceived as a low-level vision problem and hence neural networks\nfor addressing a similar class of problems can be deployed. On top of the prior\nart, this paper investigates predictability of pixel intensities based on\nsupervised and unsupervised learning frameworks. Predictability analysis\nenables adaptive data embedding, which in turn leads to a better trade-off\nbetween capacity and imperceptibility. While conventional methods estimate\npredictability by the statistics of local image patterns, learning-based\nframeworks consider further the degree to which correct predictions can be made\nby a designated predictor. Not only should the image patterns be taken into\naccount but also the predictor in use. Experimental results show that\nsteganographic performance can be significantly improved by incorporating the\nlearning-based predictability analysers into a reversible steganographic\nsystem.\n","authors":["Ching-Chun Chang","Xu Wang","Sisheng Chen","Hitoshi Kiya","Isao Echizen"],"pdf_url":"https://arxiv.org/pdf/2202.02518v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.03857v1","updated":"2023-03-07T12:49:45Z","published":"2023-03-07T12:49:45Z","title":"Leveraging Pre-trained AudioLDM for Sound Generation: A Benchmark Study","summary":"  Deep neural networks have recently achieved breakthroughs in sound\ngeneration. Despite the outstanding sample quality, current sound generation\nmodels face issues on small-scale datasets (e.g., overfitting and low coverage\nof sound classes), significantly limiting performance. In this paper, we make\nthe first attempt to investigate the benefits of pre-training on sound\ngeneration with AudioLDM, the cutting-edge model for audio generation, as the\nbackbone. Our study demonstrates the advantages of the pre-trained AudioLDM,\nespecially in data-scarcity scenarios. In addition, the baselines and\nevaluation protocol for sound generation systems are not consistent enough to\ncompare different studies directly. Aiming to facilitate further study on sound\ngeneration tasks, we benchmark the sound generation task on various\nfrequently-used datasets. We hope our results on transfer learning and\nbenchmarks can provide references for further research on conditional sound\ngeneration.\n","authors":["Yi Yuan","Haohe Liu","Jinhua Liang","Xubo Liu","Mark D. Plumbley","Wenwu Wang"],"pdf_url":"https://arxiv.org/pdf/2303.03857v1.pdf","comment":"EUSIPCO 2023"},{"id":"http://arxiv.org/abs/2211.04894v3","updated":"2023-03-07T08:25:24Z","published":"2022-11-09T13:55:50Z","title":"Exploring Video Quality Assessment on User Generated Contents from\n  Aesthetic and Technical Perspectives","summary":"  The rapid increase in user-generated-content (UGC) videos calls for the\ndevelopment of effective video quality assessment (VQA) algorithms. However,\nthe objective of the UGC-VQA problem is still ambiguous and can be viewed from\ntwo perspectives: the technical perspective, measuring the perception of\ndistortions; and the aesthetic perspective, which relates to preference and\nrecommendation on contents. To understand how these two perspectives affect\noverall subjective opinions in UGC-VQA, we conduct a large-scale subjective\nstudy to collect human quality opinions on overall quality of videos as well as\nperceptions from aesthetic and technical perspectives. The collected\nDisentangled Video Quality Database (DIVIDE-3k) confirms that human quality\nopinions on UGC videos are universally and inevitably affected by both\naesthetic and technical perspectives. In light of this, we propose the\nDisentangled Objective Video Quality Evaluator (DOVER) to learn the quality of\nUGC videos based on the two perspectives. The DOVER proves state-of-the-art\nperformance in UGC-VQA under very high efficiency. With perspective opinions in\nDIVIDE-3k, we further propose DOVER++, the first approach to provide reliable\nclear-cut quality evaluations from a single aesthetic or technical perspective.\nCode at https://github.com/VQAssessment/DOVER.\n","authors":["Haoning Wu","Erli Zhang","Liang Liao","Chaofeng Chen","Jingwen Hou","Annan Wang","Wenxiu Sun","Qiong Yan","Weisi Lin"],"pdf_url":"https://arxiv.org/pdf/2211.04894v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2211.15603v3","updated":"2023-03-07T06:14:56Z","published":"2022-11-28T17:57:48Z","title":"Action-GPT: Leveraging Large-scale Language Models for Improved and\n  Generalized Action Generation","summary":"  We introduce Action-GPT, a plug-and-play framework for incorporating Large\nLanguage Models (LLMs) into text-based action generation models. Action phrases\nin current motion capture datasets contain minimal and to-the-point\ninformation. By carefully crafting prompts for LLMs, we generate richer and\nfine-grained descriptions of the action. We show that utilizing these detailed\ndescriptions instead of the original action phrases leads to better alignment\nof text and motion spaces. We introduce a generic approach compatible with\nstochastic (e.g. VAE-based) and deterministic (e.g. MotionCLIP) text-to-motion\nmodels. In addition, the approach enables multiple text descriptions to be\nutilized. Our experiments show (i) noticeable qualitative and quantitative\nimprovement in the quality of synthesized motions, (ii) benefits of utilizing\nmultiple LLM-generated descriptions, (iii) suitability of the prompt function,\nand (iv) zero-shot generation capabilities of the proposed approach. Project\npage: https://actiongpt.github.io\n","authors":["Sai Shashank Kalakonda","Shubh Maheshwari","Ravi Kiran Sarvadevabhatla"],"pdf_url":"https://arxiv.org/pdf/2211.15603v3.pdf","comment":"Code, pretrained models and sample videos will be made available at\n  \\url{https://actiongpt.github.io}"},{"id":"http://arxiv.org/abs/2303.03105v2","updated":"2023-03-07T05:39:39Z","published":"2023-03-06T13:16:17Z","title":"Confidence-based Event-centric Online Video Question Answering on a\n  Newly Constructed ATBS Dataset","summary":"  Deep neural networks facilitate video question answering (VideoQA), but the\nreal-world applications on video streams such as CCTV and live cast place\nhigher demands on the solver. To address the challenges of VideoQA on long\nvideos of unknown length, we define a new set of problems called Online\nOpen-ended Video Question Answering (O^2VQA). It requires an online\nstate-updating mechanism for the solver to decide if the collected information\nis sufficient to conclude an answer. We then propose a Confidence-based\nEvent-centric Online Video Question Answering (CEO-VQA) model to solve this\nproblem. Furthermore, a dataset called Answer Target in Background Stream\n(ATBS) is constructed to evaluate this newly developed online VideoQA\napplication. Compared to the baseline VideoQA method that watches the whole\nvideo, the experimental results show that the proposed method achieves a\nsignificant performance gain.\n","authors":["Weikai Kong","Shuhong Ye","Chenglin Yao","Jianfeng Ren"],"pdf_url":"https://arxiv.org/pdf/2303.03105v2.pdf","comment":"Accepted for publication at the 2023 IEEE International Conference on\n  Acoustics, Speech, and Signal Processing (ICASSP 2023)"},{"id":"http://arxiv.org/abs/2303.02673v2","updated":"2023-03-07T02:38:16Z","published":"2023-03-05T13:48:47Z","title":"Time-frequency Network for Robust Speaker Recognition","summary":"  The wide deployment of speech-based biometric systems usually demands\nhigh-performance speaker recognition algorithms. However, most of the prior\nworks for speaker recognition either process the speech in the frequency domain\nor time domain, which may produce suboptimal results because both time and\nfrequency domains are important for speaker recognition. In this paper, we\nattempt to analyze the speech signal in both time and frequency domains and\npropose the time-frequency network~(TFN) for speaker recognition by extracting\nand fusing the features in the two domains. Based on the recent advance of deep\nneural networks, we propose a convolution neural network to encode the raw\nspeech waveform and the frequency spectrum into domain-specific features, which\nare then fused and transformed into a classification feature space for speaker\nrecognition. Experimental results on the publicly available datasets TIMIT and\nLibriSpeech show that our framework is effective to combine the information in\nthe two domains and performs better than the state-of-the-art methods for\nspeaker recognition.\n","authors":["Jiguo Li","Tianzi Zhang","Xiaobin Liu","Lirong Zheng"],"pdf_url":"https://arxiv.org/pdf/2303.02673v2.pdf","comment":"5pages, 3 figures"},{"id":"http://arxiv.org/abs/2303.03599v1","updated":"2023-03-07T02:31:08Z","published":"2023-03-07T02:31:08Z","title":"FSVVD: A Dataset of Full Scene Volumetric Video","summary":"  Recent years have witnessed a rapid development of immersive multimedia which\nbridges the gap between the real world and virtual space. Volumetric videos, as\nan emerging representative 3D video paradigm that empowers extended reality,\nstand out to provide unprecedented immersive and interactive video watching\nexperience. Despite the tremendous potential, the research towards 3D\nvolumetric video is still in its infancy, relying on sufficient and complete\ndatasets for further exploration. However, existing related volumetric video\ndatasets mostly only include a single object, lacking details about the scene\nand the interaction between them. In this paper, we focus on the current most\nwidely used data format, point cloud, and for the first time release a\nfull-scene volumetric video dataset that includes multiple people and their\ndaily activities interacting with the external environments. Comprehensive\ndataset description and analysis are conducted, with potential usage of this\ndataset. The dataset and additional tools can be accessed via the following\nwebsite: https://cuhksz-inml.github.io/full_scene_volumetric_video_dataset/.\n","authors":["Kaiyuan Hu","Yili Jin","Haowen Yang","Junhua Liu","Fangxin Wang"],"pdf_url":"https://arxiv.org/pdf/2303.03599v1.pdf","comment":"Accepted by MMSys'23 Open Dataset and Software Track, A preliminary\n  version. The dataset and additional tools can be accessed via\n  https://cuhksz-inml.github.io/full_scene_volumetric_video_dataset/"},{"id":"http://arxiv.org/abs/2303.03591v1","updated":"2023-03-07T01:54:24Z","published":"2023-03-07T01:54:24Z","title":"Approach to Learning Generalized Audio Representation Through Batch\n  Embedding Covariance Regularization and Constant-Q Transforms","summary":"  General-purpose embedding is highly desirable for few-shot even zero-shot\nlearning in many application scenarios, including audio tasks. In order to\nunderstand representations better, we conducted a thorough error analysis and\nvisualization of HEAR 2021 submission results. Inspired by the analysis, this\nwork experiments with different front-end audio preprocessing methods,\nincluding Constant-Q Transform (CQT) and Short-time Fourier transform (STFT),\nand proposes a Batch Embedding Covariance Regularization (BECR) term to uncover\na more holistic simulation of the frequency information received by the human\nauditory system. We tested the models on the suite of HEAR 2021 tasks, which\nencompass a broad category of tasks. Preliminary results show (1) the proposed\nBECR can incur a more dispersed embedding on the test set, (2) BECR improves\nthe PaSST model without extra computation complexity, and (3) STFT\npreprocessing outperforms CQT in all tasks we tested.\nGithub:https://github.com/ankitshah009/general_audio_embedding_hear_2021\n","authors":["Ankit Shah","Shuyi Chen","Kejun Zhou","Yue Chen","Bhiksha Raj"],"pdf_url":"https://arxiv.org/pdf/2303.03591v1.pdf","comment":"Technical report, 10 pages"}]}}